<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>TVM Learning (6)-Exercise of End to End Model Execution | WITHER</title>
<meta name="keywords" content="TVM">
<meta name="description" content="Personal notebook 5.">
<meta name="author" content="WITHER">
<link rel="canonical" href="http://localhost:1313/blogs/courselearning/tvm/tvm-ch5/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5989807471fe399ba380d3b1501334cf52bf92768fffdd44127d22f5eeae9f42.css" integrity="sha256-WYmAdHH&#43;OZujgNOxUBM0z1K/knaP/91EEn0i9e6un0I=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/blogs/courselearning/tvm/tvm-ch5/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]  
    }
  };
</script>


<meta property="og:url" content="http://localhost:1313/blogs/courselearning/tvm/tvm-ch5/">
  <meta property="og:site_name" content="WITHER">
  <meta property="og:title" content="TVM Learning (6)-Exercise of End to End Model Execution">
  <meta property="og:description" content="Personal notebook 5.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2024-08-20T12:45:00+08:00">
    <meta property="article:modified_time" content="2025-06-07T16:41:56+08:00">
    <meta property="article:tag" content="Autotuning">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TVM Learning (6)-Exercise of End to End Model Execution">
<meta name="twitter:description" content="Personal notebook 5.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "http://localhost:1313/blogs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Course Learning",
      "item": "http://localhost:1313/blogs/courselearning/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Tensor Virtual Machine",
      "item": "http://localhost:1313/blogs/courselearning/tvm/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "TVM Learning (6)-Exercise of End to End Model Execution",
      "item": "http://localhost:1313/blogs/courselearning/tvm/tvm-ch5/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "TVM Learning (6)-Exercise of End to End Model Execution",
  "name": "TVM Learning (6)-Exercise of End to End Model Execution",
  "description": "Personal notebook 5.",
  "keywords": [
    "TVM"
  ],
  "articleBody": "Model Preparation æˆ‘ä»¬é‡‡ç”¨Pytorchæ¡†æ¶å…ˆå®šä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ¥å—ä¸€æ‰¹å›¾åƒä¸ºè¾“å…¥ï¼Œç„¶åå¯¹å®ƒä»¬ä¾æ¬¡ä½œç”¨å·ç§¯å±‚ï¼Œæ¿€æ´»å±‚ï¼Œæ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ï¼Œå¾—åˆ°åˆ†ç±»ç»“æœã€‚å¹¶ä»è®­ç»ƒå¥½çš„æ¨¡å‹é‡ŒåŠ è½½æƒé‡ï¼Œè¾“å…¥å›¾åƒæ¥è‡ªFashionMNISTæ•°æ®é›†ï¼Œshapeä¸º(1, 28, 28)ï¼Œæˆ‘ä»¬è®¾ç½®batch size=4.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Load the weight map from file. weight_map = pkl.load(open(\"fasionmnist_mlp_assignment_params.pkl\", \"rb\")) class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] def pytorch_model(): list = [] list.append(nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), bias=True)) list.append(nn.ReLU()) list.append(nn.MaxPool2d(kernel_size=(2, 2))) list.append(nn.Flatten()) list.append(nn.Linear(in_features=5408, out_features=100, bias=True)) list.append(nn.ReLU()) list.append(nn.Linear(in_features=100, out_features=10, bias=True)) list.append(nn.Softmax(dim=1)) model = nn.Sequential(*list).cuda() name_map = { \"0.weight\": \"conv2d_weight\", \"0.bias\": \"conv2d_bias\", \"4.weight\": \"linear0_weight\", \"4.bias\": \"linear0_bias\", \"6.weight\": \"linear1_weight\", \"6.bias\": \"linear1_bias\", } for name, param in model.named_parameters(): param.data = torch.from_numpy(weight_map[name_map[name]]).cuda() return model Ingest Model From Pytorch ä¹‹å‰æˆ‘ä»¬éƒ½æ˜¯æ‰‹å†™T.prim_funcæ¥å®ç°ç¥ç»ç½‘ç»œçš„æ¯ä¸€å±‚ï¼Œè¿™æ ·å¾ˆå®¹æ˜“å‡ºé”™å¹¶ä¸”ä¸æ˜“äºè°ƒè¯•ã€‚TVMæä¾›äº† relax.BlockBuilderç±»å¯ä»¥ä»å¤´å¼€å§‹ä¸€æ­¥æ­¥æ„é€ ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªåä¸º emit_teçš„APIï¼Œå®ƒå¯ä»¥å°†ä¸€ä¸ªå¼ é‡è¡¨è¾¾å¼çš„ç®—å­æè¿°è½¬å˜æˆä¸€ä¸ªå¯¹åº”TensorIRå‡½æ•°çš„ call_tiræ“ä½œã€‚\nåœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œä¸ºäº†æ„å»ºä¸€ä¸ªæ‰§è¡Œå•ä¸ªReLUç®—å­çš„Relaxå‡½æ•°ï¼Œåœ¨ emit_te_exampleä¸­æˆ‘ä»¬é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ª BlockBuilderå®ä¾‹ bbã€‚åŒæ ·å®šä¹‰äº†ä¸€ä¸ª 128x128å¤§å°çš„å¼ é‡å˜é‡ xï¼Œå®ƒå°†ä½œä¸ºReLUæ“ä½œçš„è¾“å…¥ï¼ˆåŒæ—¶ä¹Ÿæ˜¯Relaxå‡½æ•°çš„è¾“å…¥ï¼‰ã€‚\nåœ¨è¿™ä¹‹åï¼Œæˆ‘ä»¬ç”¨ with bb.function(name, [*input]) APIæ„å»ºä¸€ä¸ªä»¥ xä¸ºè¾“å…¥çš„Relaxå‡½æ•° mainã€‚ç„¶åæˆ‘ä»¬æ„å»ºä¸€ä¸ªdataflow blockã€‚åœ¨è¿™ä¸ªdataflow blocké‡Œï¼Œæˆ‘ä»¬é¦–å…ˆç”¨ emit_teç”Ÿæˆä¸€ä¸ªè°ƒç”¨ReLUç®—å­çš„ call_tirã€‚ emit_teä¼šåœ¨IRModuleä¸­ç”Ÿæˆä¸€ä¸ªåå­—ä¸º reluçš„TensorIRå‡½æ•°ï¼Œç„¶ååœ¨dataflow blockä¸­ç”Ÿæˆ call_tir(relu, (x,), (128, 128), dtype=\"float32\")æ“ä½œã€‚call_tirä¹‹åæ˜¯å‡½æ•°è¿”å›ã€‚åœ¨è¿™ä¸€æ„é€ ä¹‹åï¼ŒBlockBuilderå®ä¾‹ bbåŒ…å«æ„å»ºå®Œçš„IRModuleï¼Œå¯ä»¥é€šè¿‡ bb.get()å¾—åˆ°ã€‚\nemit_te çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ª TVM å¼ é‡è¡¨è¾¾å¼ï¼ˆTEï¼‰å‡½æ•°è½¬æ¢ä¸º Relax ä¸­çš„è°ƒç”¨èŠ‚ç‚¹ï¼ˆCall Nodeï¼‰ã€‚å®ƒå…è®¸ä½ åœ¨ Relax ä¸­ä½¿ç”¨ TE å‡½æ•°æ¥è¿›è¡Œè®¡ç®—ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„ TVM Script ä»£ç ã€‚è¯¥å‡½æ•°é¦–å…ˆå°† Relax è¡¨è¾¾å¼çš„å‚æ•°è½¬æ¢ä¸º TE å¼ é‡ã€‚ç„¶åï¼Œå®ƒè°ƒç”¨ TE å‡½æ•°ï¼Œå¹¶å°†è½¬æ¢åçš„ TE å¼ é‡ä½œä¸ºå‚æ•°ä¼ é€’ç»™å®ƒã€‚TE å‡½æ•°æ‰§è¡Œè®¡ç®—å¹¶è¿”å›ä¸€ä¸ª TE å¼ é‡æˆ– TE å¼ é‡åˆ—è¡¨ã€‚è¯¥å‡½æ•°å°†è¿”å›çš„ TE å¼ é‡è½¬æ¢ä¸º Relax ä¸­çš„ Call Node. æœ€åï¼Œå®ƒä½¿ç”¨ self.emit æ–¹æ³•å°†è°ƒç”¨èŠ‚ç‚¹æ·»åŠ åˆ° Relax BlockBuilder ä¸­ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–°çš„ Relax å˜é‡ï¼Œè¯¥å˜é‡ç»‘å®šåˆ° Call Node.\nå‡½æ•°å‚æ•°ï¼š\nfunc: ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œå®ƒä»£è¡¨ä¸€ä¸ª TE å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å— Relax å¼ é‡ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ª TE å¼ é‡æˆ– TE å¼ é‡åˆ—è¡¨ã€‚ *args: funcè¾“å…¥çš„ä½ç½®å‚æ•° (relax Tensor)ã€‚ **kwargs: funcè¾“å…¥çš„çš„å…³é”®å­—å‚æ•° (relax Tensor)ã€‚ name_hint: å¯é€‰å‚æ•°ï¼Œç”¨äºæŒ‡å®šç”Ÿæˆçš„ PrimFunc çš„åç§°ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def relu(A): B = te.compute(shape=(128, 128), fcompute=lambda i, j: te.max(A[i, j], 0), name=\"B\") return B def emit_te_example(): # relax.BlockBuilder can construct e2e models # step by step in an IRModule that starts empty. bb =relax.BlockBuilder() # relax.DynTensorType is the type assigned to tensors with a known dtype and unknown shape. x = relax.Var(\"x\", relax.TensorStructInfo((128, 128), \"float32\")) with bb.function(\"main\", [x]): # construct a Relax function main with x as input with bb.dataflow(): # Emit a call node according to the te function # which should return a te tensor or a list of te tensors. lv0 = bb.emit_te(relu, x) gv = bb.emit_output(lv0) # mark the dataflow output bb.emit_func_output(gv) # mark the function output return bb.get() # return the constructed IRModule å¯ä»¥çœ‹åˆ°é€šè¿‡BlockBuilderç”Ÿæˆçš„IRModuleåŒ…å«äº†ReLUçš„TensorIRå®ç°å’Œä¸€ä¸ªå«æœ‰è°ƒç”¨ReLUå®ç°çš„ call_tirçš„Relaxå‡½æ•°\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @I.ir_module class Module: @T.prim_func(private=True) def relu(x: T.Buffer((T.int64(128), T.int64(128)), \"float32\"), B: T.Buffer((T.int64(128), T.int64(128)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): for i, j in T.grid(T.int64(128), T.int64(128)): with T.block(\"B\"): v_i, v_j = T.axis.remap(\"SS\", [i, j]) T.reads(x[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = T.max(x[v_i, v_j], T.float32(0.0)) @R.function def main(x: R.Tensor((128, 128), dtype=\"float32\")) -\u003e R.Tensor((128, 128), dtype=\"float32\"): cls = Module with R.dataflow(): lv = R.call_tir(cls.relu, (x,), out_sinfo=R.Tensor((128, 128), dtype=\"float32\")) gv: R.Tensor((128, 128), dtype=\"float32\") = lv R.output(gv) return gv Construct IRModule Equals to Pytorch æˆ‘ä»¬å¯ä»¥ç”¨ BlockBuilderå’Œ emit_teæ¥åˆ›å»ºä¸€ä¸ªå’Œä¹‹å‰å®šä¹‰çš„PyTorchæ¨¡å‹ç­‰ä»·çš„IRModuleã€‚é¦–å…ˆæˆ‘ä»¬è¦å®ç°è¿™äº›ç®—å­çš„å¼ é‡è¡¨è¾¾å¼è¿ç®—å‡½æ•°ã€‚\nåœ¨åŠ ä¸Šbiasçš„æ—¶å€™è¦å’Œreductionæ“ä½œåˆ†å¼€è¿›è¡Œï¼Œå³ä¸èƒ½åœ¨ä¸€ä¸ªte.computeé‡Œé¢è¿›è¡Œ te.sum+bias[...]çš„æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥é”™\n1 2 3 4 TVMError Traceback (most recent call last): File \"D:\\Work\\tvm\\tvm0.18\\tvm\\src\\te\\operation\\compute_op.cc\", line 566 InternalError: Check failed: (0 == level_) is false: Reductions are only allowed at the top level of compute. Please create another tensor for further composition. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def my_conv2d(X, K, B): # No padding, stride = 1 N, CI, H, W = X.shape CO, _, KH, KW = K.shape k = te.reduce_axis((0, CI), name=\"k\") r = te.reduce_axis((0, KH), name=\"r\") s = te.reduce_axis((0, KW), name=\"s\") OH = (H - KH) + 1 OW = (W - KW) + 1 conv2d_te = te.compute(shape=(N, CO, OH, OW), fcompute=lambda n, co, oh, ow: te.sum( X[n, k, oh + r, ow + s] * K[co, k, r, s], axis=[k, r, s]), name=\"conv2d\") out = te.compute(shape=(N, CO, OH, OW), fcompute=lambda n, co, oh, ow: conv2d_te[n, co, oh, ow] + B[0, co, 0, 0]) return out def my_relu(X): return te.compute(shape=X.shape, fcompute=lambda *i: te.max(X(*i), 0)) def my_maxpool2d(X, S): N, C, H, W = X.shape i = te.reduce_axis((0, S), name=\"i\") j = te.reduce_axis((0, S), name=\"j\") maxpool2d_te = te.compute(shape=(N, C, H//2, W//2), fcompute=lambda n, co, oh, ow: te.max( X[n, co, oh*S+i, ow*S+j], axis=[i, j]), name=\"maxpool2d\") return maxpool2d_te def my_flatten(X): N, C, H, W = X.shape flatten_te = te.compute(shape=(N, C*H*W), fcompute=lambda n, i: X[n, i//(H*W), i//(W)%(H), i%(W)]) return flatten_te def my_linear(X, W, B=None): FO, FI = W.shape N, _ = X.shape fi = te.reduce_axis((0, FI), name=\"FI\") linear_te = te.compute(shape=(N, FO), fcompute=lambda i, j: te.sum( X[i, fi] * W[j, fi], axis=fi)) if B is not None: out = te.compute(shape=(N, FO), fcompute=lambda i, j: B[0, j] + linear_te[i, j]) else: out = linear_te return out def my_softmax(X): N, C = X.shape c = te.reduce_axis((0, C), name=\"c\") max_val = te.compute(shape=(N, ), fcompute=lambda i: te.max(X[i, c], axis=c)) exp_te = te.compute(shape=(N, C), fcompute=lambda i, j: te.exp(X[i, j] - max_val[i])) sum_exp_te = te.compute(shape=(N, ), fcompute=lambda i: te.sum(exp_te[i, c], axis=c)) softmax_te = te.compute(shape=(N, C), fcompute=lambda i, j: exp_te[i, j] / sum_exp_te[i]) return softmax_te ç„¶åæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨ BlockBuilderæ„å»ºIRModule\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def create_model_via_emit_te(): batch_size = 4 input_shape = (batch_size, 1, 28, 28) # BCHW bb = relax.BlockBuilder() x = relax.Var(\"x\", relax.TensorStructInfo(input_shape, \"float32\")) conv2d_weight = relax.const(weight_map[\"conv2d_weight\"], \"float32\") conv2d_bias = relax.const(weight_map[\"conv2d_bias\"].reshape(1, 32, 1, 1), \"float32\") linear0_weight = relax.const(weight_map[\"linear0_weight\"], \"float32\") linear0_bias = relax.const(weight_map[\"linear0_bias\"].reshape(1, 100), \"float32\") linear1_weight = relax.const(weight_map[\"linear1_weight\"], \"float32\") linear1_bias = relax.const(weight_map[\"linear1_bias\"].reshape(1, 10), \"float32\") # Build the model using BlockBuilder with bb.function(\"main\", [x]): with bb.dataflow(): gv_conv = bb.emit_te(my_conv2d, x, conv2d_weight, conv2d_bias) gv_relu1 = bb.emit_te(my_relu, gv_conv) gv_pool = bb.emit_te(my_maxpool2d, gv_relu1, 2) gv_flatten = bb.emit_te(my_flatten, gv_pool) gv_dense1 = bb.emit_te(my_linear, gv_flatten, linear0_weight, linear0_bias) gv_relu2 = bb.emit_te(my_relu, gv_dense1) gv_dense2 = bb.emit_te(my_linear, gv_relu2, linear1_weight, linear1_bias) gv_softmax = bb.emit_te(my_softmax, gv_dense2) out = bb.emit_output(gv_softmax) bb.emit_func_output(out) return bb.get() å¾—åˆ°çš„IRModuleçš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 mod = create_model_via_emit_te() exec = relax.build(mod, \"llvm\") dev = tvm.cpu() vm = relax.VirtualMachine(exec, dev) print(mod.script()) mod.script 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @I.ir_module class Module: @T.prim_func(private=True) def my_conv2d(x: T.Buffer((T.int64(4), T.int64(1), T.int64(28), T.int64(28)), \"float32\"), B: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3)), \"float32\"), C: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), \"float32\"), compute: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): conv2d = T.alloc_buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26))) for n, co, oh, ow, k, r, s in T.grid(T.int64(4), T.int64(32), T.int64(26), T.int64(26), T.int64(1), T.int64(3), T.int64(3)): with T.block(\"conv2d\"): v_n, v_co, v_oh, v_ow, v_k, v_r, v_s = T.axis.remap(\"SSSSRRR\", [n, co, oh, ow, k, r, s]) T.reads(x[v_n, v_k, v_oh + v_r, v_ow + v_s], B[v_co, v_k, v_r, v_s]) T.writes(conv2d[v_n, v_co, v_oh, v_ow]) with T.init(): conv2d[v_n, v_co, v_oh, v_ow] = T.float32(0.0) conv2d[v_n, v_co, v_oh, v_ow] = conv2d[v_n, v_co, v_oh, v_ow] + x[v_n, v_k, v_oh + v_r, v_ow + v_s] * B[v_co, v_k, v_r, v_s] for n, co, oh, ow in T.grid(T.int64(4), T.int64(32), T.int64(26), T.int64(26)): with T.block(\"compute\"): v_n, v_co, v_oh, v_ow = T.axis.remap(\"SSSS\", [n, co, oh, ow]) T.reads(conv2d[v_n, v_co, v_oh, v_ow], C[T.int64(0), v_co, T.int64(0), T.int64(0)]) T.writes(compute[v_n, v_co, v_oh, v_ow]) compute[v_n, v_co, v_oh, v_ow] = conv2d[v_n, v_co, v_oh, v_ow] + C[T.int64(0), v_co, T.int64(0), T.int64(0)] @T.prim_func(private=True) def my_flatten(lv2: T.Buffer((T.int64(4), T.int64(32), T.int64(13), T.int64(13)), \"float32\"), compute: T.Buffer((T.int64(4), T.int64(5408)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): for n, i in T.grid(T.int64(4), T.int64(5408)): with T.block(\"compute\"): v_n, v_i = T.axis.remap(\"SS\", [n, i]) T.reads(lv2[v_n, v_i // T.int64(169), v_i % T.int64(169) // T.int64(13), v_i % T.int64(13)]) T.writes(compute[v_n, v_i]) compute[v_n, v_i] = lv2[v_n, v_i // T.int64(169), v_i % T.int64(169) // T.int64(13), v_i % T.int64(13)] @T.prim_func(private=True) def my_linear(lv3: T.Buffer((T.int64(4), T.int64(5408)), \"float32\"), B: T.Buffer((T.int64(100), T.int64(5408)), \"float32\"), C: T.Buffer((T.int64(1), T.int64(100)), \"float32\"), compute: T.Buffer((T.int64(4), T.int64(100)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): compute_1 = T.alloc_buffer((T.int64(4), T.int64(100))) for i, j, FI in T.grid(T.int64(4), T.int64(100), T.int64(5408)): with T.block(\"compute\"): v_i, v_j, v_FI = T.axis.remap(\"SSR\", [i, j, FI]) T.reads(lv3[v_i, v_FI], B[v_j, v_FI]) T.writes(compute_1[v_i, v_j]) with T.init(): compute_1[v_i, v_j] = T.float32(0.0) compute_1[v_i, v_j] = compute_1[v_i, v_j] + lv3[v_i, v_FI] * B[v_j, v_FI] for i, j in T.grid(T.int64(4), T.int64(100)): with T.block(\"compute_1\"): v_i, v_j = T.axis.remap(\"SS\", [i, j]) T.reads(C[T.int64(0), v_j], compute_1[v_i, v_j]) T.writes(compute[v_i, v_j]) compute[v_i, v_j] = C[T.int64(0), v_j] + compute_1[v_i, v_j] @T.prim_func(private=True) def my_linear1(lv5: T.Buffer((T.int64(4), T.int64(100)), \"float32\"), B: T.Buffer((T.int64(10), T.int64(100)), \"float32\"), C: T.Buffer((T.int64(1), T.int64(10)), \"float32\"), compute: T.Buffer((T.int64(4), T.int64(10)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): compute_1 = T.alloc_buffer((T.int64(4), T.int64(10))) for i, j, FI in T.grid(T.int64(4), T.int64(10), T.int64(100)): with T.block(\"compute\"): v_i, v_j, v_FI = T.axis.remap(\"SSR\", [i, j, FI]) T.reads(lv5[v_i, v_FI], B[v_j, v_FI]) T.writes(compute_1[v_i, v_j]) with T.init(): compute_1[v_i, v_j] = T.float32(0.0) compute_1[v_i, v_j] = compute_1[v_i, v_j] + lv5[v_i, v_FI] * B[v_j, v_FI] for i, j in T.grid(T.int64(4), T.int64(10)): with T.block(\"compute_1\"): v_i, v_j = T.axis.remap(\"SS\", [i, j]) T.reads(C[T.int64(0), v_j], compute_1[v_i, v_j]) T.writes(compute[v_i, v_j]) compute[v_i, v_j] = C[T.int64(0), v_j] + compute_1[v_i, v_j] @T.prim_func(private=True) def my_maxpool2d(lv1: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \"float32\"), maxpool2d: T.Buffer((T.int64(4), T.int64(32), T.int64(13), T.int64(13)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): for n, co, oh, ow, i, j in T.grid(T.int64(4), T.int64(32), T.int64(13), T.int64(13), T.int64(2), T.int64(2)): with T.block(\"maxpool2d\"): v_n, v_co, v_oh, v_ow, v_i, v_j = T.axis.remap(\"SSSSRR\", [n, co, oh, ow, i, j]) T.reads(lv1[v_n, v_co, v_oh * T.int64(2) + v_i, v_ow * T.int64(2) + v_j]) T.writes(maxpool2d[v_n, v_co, v_oh, v_ow]) with T.init(): maxpool2d[v_n, v_co, v_oh, v_ow] = T.float32(-340282346638528859811704183484516925440.0) maxpool2d[v_n, v_co, v_oh, v_ow] = T.max(maxpool2d[v_n, v_co, v_oh, v_ow], lv1[v_n, v_co, v_oh * T.int64(2) + v_i, v_ow * T.int64(2) + v_j]) @T.prim_func(private=True) def my_relu(lv: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \"float32\"), compute: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): for i0, i1, i2, i3 in T.grid(T.int64(4), T.int64(32), T.int64(26), T.int64(26)): with T.block(\"compute\"): v_i0, v_i1, v_i2, v_i3 = T.axis.remap(\"SSSS\", [i0, i1, i2, i3]) T.reads(lv[v_i0, v_i1, v_i2, v_i3]) T.writes(compute[v_i0, v_i1, v_i2, v_i3]) compute[v_i0, v_i1, v_i2, v_i3] = T.max(lv[v_i0, v_i1, v_i2, v_i3], T.float32(0.0)) @T.prim_func(private=True) def my_relu1(lv4: T.Buffer((T.int64(4), T.int64(100)), \"float32\"), compute: T.Buffer((T.int64(4), T.int64(100)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): for i0, i1 in T.grid(T.int64(4), T.int64(100)): with T.block(\"compute\"): v_i0, v_i1 = T.axis.remap(\"SS\", [i0, i1]) T.reads(lv4[v_i0, v_i1]) T.writes(compute[v_i0, v_i1]) compute[v_i0, v_i1] = T.max(lv4[v_i0, v_i1], T.float32(0.0)) @T.prim_func(private=True) def my_softmax(lv6: T.Buffer((T.int64(4), T.int64(10)), \"float32\"), compute: T.Buffer((T.int64(4), T.int64(10)), \"float32\")): T.func_attr({\"tir.noalias\": T.bool(True)}) # with T.block(\"root\"): compute_1 = T.alloc_buffer((T.int64(4),)) compute_2 = T.alloc_buffer((T.int64(4), T.int64(10))) compute_3 = T.alloc_buffer((T.int64(4),)) for i, c in T.grid(T.int64(4), T.int64(10)): with T.block(\"compute\"): v_i, v_c = T.axis.remap(\"SR\", [i, c]) T.reads(lv6[v_i, v_c]) T.writes(compute_1[v_i]) with T.init(): compute_1[v_i] = T.float32(-340282346638528859811704183484516925440.0) compute_1[v_i] = T.max(compute_1[v_i], lv6[v_i, v_c]) for i, j in T.grid(T.int64(4), T.int64(10)): with T.block(\"compute_1\"): v_i, v_j = T.axis.remap(\"SS\", [i, j]) T.reads(lv6[v_i, v_j], compute_1[v_i]) T.writes(compute_2[v_i, v_j]) compute_2[v_i, v_j] = T.exp(lv6[v_i, v_j] - compute_1[v_i]) for i, c in T.grid(T.int64(4), T.int64(10)): with T.block(\"compute_2\"): v_i, v_c = T.axis.remap(\"SR\", [i, c]) T.reads(compute_2[v_i, v_c]) T.writes(compute_3[v_i]) with T.init(): compute_3[v_i] = T.float32(0.0) compute_3[v_i] = compute_3[v_i] + compute_2[v_i, v_c] for i, j in T.grid(T.int64(4), T.int64(10)): with T.block(\"compute_3\"): v_i, v_j = T.axis.remap(\"SS\", [i, j]) T.reads(compute_2[v_i, v_j], compute_3[v_i]) T.writes(compute[v_i, v_j]) compute[v_i, v_j] = compute_2[v_i, v_j] / compute_3[v_i] @R.function def main(x: R.Tensor((4, 1, 28, 28), dtype=\"float32\")) -\u003e R.Tensor((4, 10), dtype=\"float32\"): cls = Module with R.dataflow(): lv = R.call_tir(cls.my_conv2d, (x, metadata[\"relax.expr.Constant\"][0], metadata[\"relax.expr.Constant\"][1]), out_sinfo=R.Tensor((4, 32, 26, 26), dtype=\"float32\")) lv1 = R.call_tir(cls.my_relu, (lv,), out_sinfo=R.Tensor((4, 32, 26, 26), dtype=\"float32\")) lv2 = R.call_tir(cls.my_maxpool2d, (lv1,), out_sinfo=R.Tensor((4, 32, 13, 13), dtype=\"float32\")) lv3 = R.call_tir(cls.my_flatten, (lv2,), out_sinfo=R.Tensor((4, 5408), dtype=\"float32\")) lv4 = R.call_tir(cls.my_linear, (lv3, metadata[\"relax.expr.Constant\"][2], metadata[\"relax.expr.Constant\"][3]), out_sinfo=R.Tensor((4, 100), dtype=\"float32\")) lv5 = R.call_tir(cls.my_relu1, (lv4,), out_sinfo=R.Tensor((4, 100), dtype=\"float32\")) lv6 = R.call_tir(cls.my_linear1, (lv5, metadata[\"relax.expr.Constant\"][4], metadata[\"relax.expr.Constant\"][5]), out_sinfo=R.Tensor((4, 10), dtype=\"float32\")) lv7 = R.call_tir(cls.my_softmax, (lv6,), out_sinfo=R.Tensor((4, 10), dtype=\"float32\")) gv: R.Tensor((4, 10), dtype=\"float32\") = lv7 R.output(gv) return gv æˆ‘ä»¬å¯ä»¥ä¸Pytorchæ¨¡å‹çš„æ‰§è¡Œç»“æœè¿›è¡Œæ¯”è¾ƒæ¥éªŒè¯æ­£ç¡®æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def build_mod(mod): exec = relax.vm.build(mod, \"llvm\") dev = tvm.cpu() vm = relax.VirtualMachine(exec, dev) return vm def check_equivalence(mod, torch_model, test_loader): torch_model.eval() with torch.no_grad(): rt_mod = build_mod(mod) for data, label in test_loader: data, label = data.cpu(), label.cpu() output_from_pytorch = torch_model(data).numpy() output_from_relax = rt_mod[\"main\"](tvm.nd.array(data, tvm.cpu())).numpy() tvm.testing.assert_allclose(output_from_pytorch, output_from_relax, rtol=1e-4) test_data = torchvision.datasets.FashionMNIST( \"./data\", download=True, train=False, transform=transforms.Compose([transforms.ToTensor()]) ) test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False) mod = create_model_via_emit_te() torch_model = pytorch_model() check_equivalence(mod, torch_model, test_loader) ",
  "wordCount" : "3271",
  "inLanguage": "en",
  "datePublished": "2024-08-20T12:45:00+08:00",
  "dateModified": "2025-06-07T16:41:56+08:00",
  "author":[{
    "@type": "Person",
    "name": "WITHER"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/blogs/courselearning/tvm/tvm-ch5/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "WITHER",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="WITHER (Alt + H)">WITHER</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="http://localhost:1313/zh/" title="ç®€ä½“ä¸­æ–‡"
                            aria-label="ç®€ä½“ä¸­æ–‡">ç®€ä½“ä¸­æ–‡</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="ğŸ  Home">
                    <span>ğŸ  Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about_me/" title="ğŸ™‹ğŸ»â€â™‚ï¸ Me">
                    <span>ğŸ™‹ğŸ»â€â™‚ï¸ Me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blogs/" title="ğŸ“š Blogs">
                    <span>ğŸ“š Blogs</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="ğŸ§© Categories">
                    <span>ğŸ§© Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="ğŸ”– Tags">
                    <span>ğŸ”– Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="â± Archive">
                    <span>â± Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="ğŸ” Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ” Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/friends/" title="ğŸ¤ Friends">
                    <span>ğŸ¤ Friends</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;Â»&nbsp;<a href="http://localhost:1313/blogs/">Blogs</a>&nbsp;Â»&nbsp;<a href="http://localhost:1313/blogs/courselearning/">Course Learning</a>&nbsp;Â»&nbsp;<a href="http://localhost:1313/blogs/courselearning/tvm/">Tensor Virtual Machine</a></div>
    <h1 class="post-title entry-hint-parent">
      TVM Learning (6)-Exercise of End to End Model Execution
    </h1>
    <div class="post-description">
      Personal notebook 5.
    </div>
    <div class="post-meta"><span title='2024-08-20 12:45:00 +0800 CST'>Aug-20-2024</span>&nbsp;Â·&nbsp;7 min&nbsp;Â·&nbsp;3271 words&nbsp;Â·&nbsp;WITHER

</div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#model-preparation" aria-label="Model Preparation">Model Preparation</a></li>
                    <li>
                        <a href="#ingest-model-from-pytorch" aria-label="Ingest Model From Pytorch">Ingest Model From Pytorch</a></li>
                    <li>
                        <a href="#construct-irmodule-equals-to-pytorch" aria-label="Construct IRModule Equals to Pytorch">Construct IRModule Equals to Pytorch</a>
                    </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>
  <div class="post-content"><h1 id="model-preparation">Model Preparation<a hidden class="anchor" aria-hidden="true" href="#model-preparation">#</a></h1>
<p>æˆ‘ä»¬é‡‡ç”¨Pytorchæ¡†æ¶å…ˆå®šä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ¥å—ä¸€æ‰¹å›¾åƒä¸ºè¾“å…¥ï¼Œç„¶åå¯¹å®ƒä»¬ä¾æ¬¡ä½œç”¨å·ç§¯å±‚ï¼Œæ¿€æ´»å±‚ï¼Œæ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ï¼Œå¾—åˆ°åˆ†ç±»ç»“æœã€‚å¹¶ä»è®­ç»ƒå¥½çš„æ¨¡å‹é‡ŒåŠ è½½æƒé‡ï¼Œè¾“å…¥å›¾åƒæ¥è‡ªFashionMNISTæ•°æ®é›†ï¼Œshapeä¸º(1, 28, 28)ï¼Œæˆ‘ä»¬è®¾ç½®batch size=4.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Load the weight map from file.</span>
</span></span><span class="line"><span class="cl"><span class="n">weight_map</span> <span class="o">=</span> <span class="n">pkl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&#34;fasionmnist_mlp_assignment_params.pkl&#34;</span><span class="p">,</span> <span class="s2">&#34;rb&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T-shirt/top&#39;</span><span class="p">,</span> <span class="s1">&#39;Trouser&#39;</span><span class="p">,</span> <span class="s1">&#39;Pullover&#39;</span><span class="p">,</span> <span class="s1">&#39;Dress&#39;</span><span class="p">,</span> <span class="s1">&#39;Coat&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">               <span class="s1">&#39;Sandal&#39;</span><span class="p">,</span> <span class="s1">&#39;Shirt&#39;</span><span class="p">,</span> <span class="s1">&#39;Sneaker&#39;</span><span class="p">,</span> <span class="s1">&#39;Bag&#39;</span><span class="p">,</span> <span class="s1">&#39;Ankle boot&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">pytorch_model</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">5408</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">name_map</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;0.weight&#34;</span><span class="p">:</span> <span class="s2">&#34;conv2d_weight&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;0.bias&#34;</span><span class="p">:</span> <span class="s2">&#34;conv2d_bias&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;4.weight&#34;</span><span class="p">:</span> <span class="s2">&#34;linear0_weight&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;4.bias&#34;</span><span class="p">:</span> <span class="s2">&#34;linear0_bias&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;6.weight&#34;</span><span class="p">:</span> <span class="s2">&#34;linear1_weight&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;6.bias&#34;</span><span class="p">:</span> <span class="s2">&#34;linear1_bias&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weight_map</span><span class="p">[</span><span class="n">name_map</span><span class="p">[</span><span class="n">name</span><span class="p">]])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="ingest-model-from-pytorch">Ingest Model From Pytorch<a hidden class="anchor" aria-hidden="true" href="#ingest-model-from-pytorch">#</a></h1>
<p>ä¹‹å‰æˆ‘ä»¬éƒ½æ˜¯æ‰‹å†™T.prim_funcæ¥å®ç°ç¥ç»ç½‘ç»œçš„æ¯ä¸€å±‚ï¼Œè¿™æ ·å¾ˆå®¹æ˜“å‡ºé”™å¹¶ä¸”ä¸æ˜“äºè°ƒè¯•ã€‚TVMæä¾›äº† <code>relax.BlockBuilder</code>ç±»å¯ä»¥ä»å¤´å¼€å§‹ä¸€æ­¥æ­¥æ„é€ ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªåä¸º <code>emit_te</code>çš„APIï¼Œå®ƒå¯ä»¥å°†ä¸€ä¸ªå¼ é‡è¡¨è¾¾å¼çš„ç®—å­æè¿°è½¬å˜æˆä¸€ä¸ªå¯¹åº”TensorIRå‡½æ•°çš„ <code>call_tir</code>æ“ä½œã€‚</p>
<p>åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œä¸ºäº†æ„å»ºä¸€ä¸ªæ‰§è¡Œå•ä¸ªReLUç®—å­çš„Relaxå‡½æ•°ï¼Œåœ¨ <code>emit_te_example</code>ä¸­æˆ‘ä»¬é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ª <code>BlockBuilder</code>å®ä¾‹ <code>bb</code>ã€‚åŒæ ·å®šä¹‰äº†ä¸€ä¸ª <code>128x128</code>å¤§å°çš„å¼ é‡å˜é‡ <code>x</code>ï¼Œå®ƒå°†ä½œä¸ºReLUæ“ä½œçš„è¾“å…¥ï¼ˆåŒæ—¶ä¹Ÿæ˜¯Relaxå‡½æ•°çš„è¾“å…¥ï¼‰ã€‚</p>
<p>åœ¨è¿™ä¹‹åï¼Œæˆ‘ä»¬ç”¨ <code>with bb.function(name, [*input])</code> APIæ„å»ºä¸€ä¸ªä»¥ <code>x</code>ä¸ºè¾“å…¥çš„Relaxå‡½æ•° <code>main</code>ã€‚ç„¶åæˆ‘ä»¬æ„å»ºä¸€ä¸ªdataflow blockã€‚åœ¨è¿™ä¸ªdataflow blocké‡Œï¼Œæˆ‘ä»¬é¦–å…ˆç”¨ <code>emit_te</code>ç”Ÿæˆä¸€ä¸ªè°ƒç”¨ReLUç®—å­çš„ <code>call_tir</code>ã€‚ <code>emit_te</code>ä¼šåœ¨IRModuleä¸­ç”Ÿæˆä¸€ä¸ªåå­—ä¸º <code>relu</code>çš„TensorIRå‡½æ•°ï¼Œç„¶ååœ¨dataflow blockä¸­ç”Ÿæˆ <code>call_tir(relu, (x,), (128, 128), dtype=&quot;float32&quot;)</code>æ“ä½œã€‚<code>call_tir</code>ä¹‹åæ˜¯å‡½æ•°è¿”å›ã€‚åœ¨è¿™ä¸€æ„é€ ä¹‹åï¼ŒBlockBuilderå®ä¾‹ <code>bb</code>åŒ…å«æ„å»ºå®Œçš„IRModuleï¼Œå¯ä»¥é€šè¿‡ <code>bb.get()</code>å¾—åˆ°ã€‚</p>
<p><code>emit_te</code> çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ª TVM å¼ é‡è¡¨è¾¾å¼ï¼ˆTEï¼‰å‡½æ•°è½¬æ¢ä¸º Relax ä¸­çš„è°ƒç”¨èŠ‚ç‚¹ï¼ˆCall Nodeï¼‰ã€‚å®ƒå…è®¸ä½ åœ¨ Relax ä¸­ä½¿ç”¨ TE å‡½æ•°æ¥è¿›è¡Œè®¡ç®—ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„ TVM Script ä»£ç ã€‚è¯¥å‡½æ•°é¦–å…ˆå°† Relax è¡¨è¾¾å¼çš„å‚æ•°è½¬æ¢ä¸º TE å¼ é‡ã€‚ç„¶åï¼Œå®ƒè°ƒç”¨ TE å‡½æ•°ï¼Œå¹¶å°†è½¬æ¢åçš„ TE å¼ é‡ä½œä¸ºå‚æ•°ä¼ é€’ç»™å®ƒã€‚TE å‡½æ•°æ‰§è¡Œè®¡ç®—å¹¶è¿”å›ä¸€ä¸ª TE å¼ é‡æˆ– TE å¼ é‡åˆ—è¡¨ã€‚è¯¥å‡½æ•°å°†è¿”å›çš„ TE å¼ é‡è½¬æ¢ä¸º Relax ä¸­çš„ Call Node. æœ€åï¼Œå®ƒä½¿ç”¨ <code>self.emit</code> æ–¹æ³•å°†è°ƒç”¨èŠ‚ç‚¹æ·»åŠ åˆ° Relax BlockBuilder ä¸­ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–°çš„ Relax å˜é‡ï¼Œè¯¥å˜é‡ç»‘å®šåˆ° Call Node.</p>
<p><strong>å‡½æ•°å‚æ•°ï¼š</strong></p>
<ul>
<li><code>func</code>: ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œå®ƒä»£è¡¨ä¸€ä¸ª TE å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å— Relax å¼ é‡ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ª TE å¼ é‡æˆ– TE å¼ é‡åˆ—è¡¨ã€‚</li>
<li><code>*args</code>: <code>func</code>è¾“å…¥çš„ä½ç½®å‚æ•° (relax Tensor)ã€‚</li>
<li><code>**kwargs</code>: <code>func</code>è¾“å…¥çš„çš„å…³é”®å­—å‚æ•° (relax Tensor)ã€‚</li>
<li><code>name_hint</code>: å¯é€‰å‚æ•°ï¼Œç”¨äºæŒ‡å®šç”Ÿæˆçš„ PrimFunc çš„åç§°ã€‚</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">B</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;B&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">B</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">emit_te_example</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># relax.BlockBuilder can construct e2e models </span>
</span></span><span class="line"><span class="cl">    <span class="c1"># step by step in an IRModule that starts empty.</span>
</span></span><span class="line"><span class="cl">    <span class="n">bb</span> <span class="o">=</span><span class="n">relax</span><span class="o">.</span><span class="n">BlockBuilder</span><span class="p">()</span>  
</span></span><span class="line"><span class="cl">    <span class="c1"># relax.DynTensorType is the type assigned to tensors with a known dtype and unknown shape.</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="s2">&#34;x&#34;</span><span class="p">,</span> <span class="n">relax</span><span class="o">.</span><span class="n">TensorStructInfo</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">bb</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="s2">&#34;main&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">]):</span>  <span class="c1"># construct a Relax function main with x as input</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">bb</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Emit a call node according to the te function</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># which should return a te tensor or a list of te tensors. </span>
</span></span><span class="line"><span class="cl">            <span class="n">lv0</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">relu</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_output</span><span class="p">(</span><span class="n">lv0</span><span class="p">)</span>  <span class="c1"># mark the dataflow output </span>
</span></span><span class="line"><span class="cl">        <span class="n">bb</span><span class="o">.</span><span class="n">emit_func_output</span><span class="p">(</span><span class="n">gv</span><span class="p">)</span>  <span class="c1"># mark the function output </span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">bb</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>  <span class="c1"># return the constructed IRModule</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>å¯ä»¥çœ‹åˆ°é€šè¿‡BlockBuilderç”Ÿæˆçš„IRModuleåŒ…å«äº†ReLUçš„TensorIRå®ç°å’Œä¸€ä¸ªå«æœ‰è°ƒç”¨ReLUå®ç°çš„ <code>call_tir</code>çš„Relaxå‡½æ•°</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@I.ir_module</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Module</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">128</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">128</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">128</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;B&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">B</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@R.function</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">cls</span> <span class="o">=</span> <span class="n">Module</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">)</span> <span class="o">=</span> <span class="n">lv</span>
</span></span><span class="line"><span class="cl">            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">gv</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">gv</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="construct-irmodule-equals-to-pytorch">Construct IRModule Equals to Pytorch<a hidden class="anchor" aria-hidden="true" href="#construct-irmodule-equals-to-pytorch">#</a></h1>
<p>æˆ‘ä»¬å¯ä»¥ç”¨ <code>BlockBuilder</code>å’Œ <code>emit_te</code>æ¥åˆ›å»ºä¸€ä¸ªå’Œä¹‹å‰å®šä¹‰çš„PyTorchæ¨¡å‹ç­‰ä»·çš„IRModuleã€‚é¦–å…ˆæˆ‘ä»¬è¦å®ç°è¿™äº›ç®—å­çš„å¼ é‡è¡¨è¾¾å¼è¿ç®—å‡½æ•°ã€‚</p>
<p><strong>åœ¨åŠ ä¸Šbiasçš„æ—¶å€™è¦å’Œreductionæ“ä½œåˆ†å¼€è¿›è¡Œ</strong>ï¼Œå³ä¸èƒ½åœ¨ä¸€ä¸ªte.computeé‡Œé¢è¿›è¡Œ <code>te.sum+bias[...]</code>çš„æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥é”™</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">TVMError
</span></span><span class="line"><span class="cl">Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
</span></span><span class="line"><span class="cl">File <span class="s2">&#34;D:\Work\tvm\tvm0.18\tvm\src\te\operation\compute_op.cc&#34;</span>, line <span class="m">566</span>
</span></span><span class="line"><span class="cl">InternalError: Check failed: <span class="o">(</span><span class="nv">0</span> <span class="o">==</span> level_<span class="o">)</span> is false: Reductions are only allowed at the top level of compute. Please create another tensor <span class="k">for</span> further composition.
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_conv2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>  <span class="c1"># No padding, stride = 1</span>
</span></span><span class="line"><span class="cl">    <span class="n">N</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="n">CO</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">KH</span><span class="p">,</span> <span class="n">KW</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="n">k</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">CI</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;k&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">r</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">KH</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;r&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">s</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">KW</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;s&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">OH</span> <span class="o">=</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="n">KH</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">OW</span> <span class="o">=</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">KW</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">conv2d_te</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">CO</span><span class="p">,</span> <span class="n">OH</span><span class="p">,</span> <span class="n">OW</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                           <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">X</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">oh</span> <span class="o">+</span> <span class="n">r</span><span class="p">,</span> <span class="n">ow</span> <span class="o">+</span> <span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">K</span><span class="p">[</span><span class="n">co</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">]),</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">name</span><span class="o">=</span><span class="s2">&#34;conv2d&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">CO</span><span class="p">,</span> <span class="n">OH</span><span class="p">,</span> <span class="n">OW</span><span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">conv2d_te</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">out</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">i</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">),</span> <span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_maxpool2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="n">i</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">S</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;i&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">j</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">S</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;j&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">maxpool2d_te</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">W</span><span class="o">//</span><span class="mi">2</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">                              <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                                  <span class="n">X</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="o">*</span><span class="n">S</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">ow</span><span class="o">*</span><span class="n">S</span><span class="o">+</span><span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;maxpool2d&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">maxpool2d_te</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_flatten</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="n">flatten_te</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="o">*</span><span class="n">H</span><span class="o">*</span><span class="n">W</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">                            <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">X</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="o">//</span><span class="p">(</span><span class="n">H</span><span class="o">*</span><span class="n">W</span><span class="p">),</span> <span class="n">i</span><span class="o">//</span><span class="p">(</span><span class="n">W</span><span class="p">)</span><span class="o">%</span><span class="p">(</span><span class="n">H</span><span class="p">),</span> <span class="n">i</span><span class="o">%</span><span class="p">(</span><span class="n">W</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">flatten_te</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_linear</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">FO</span><span class="p">,</span> <span class="n">FI</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span> 
</span></span><span class="line"><span class="cl">    <span class="n">N</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>  
</span></span><span class="line"><span class="cl">    <span class="n">fi</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">FI</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;FI&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">linear_te</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">FO</span><span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                                                <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">fi</span><span class="p">]</span> <span class="o">*</span> <span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">fi</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">fi</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">FO</span><span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">B</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">linear_te</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">linear_te</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">out</span>   
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_softmax</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;c&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_val</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">c</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">exp_te</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_val</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>  
</span></span><span class="line"><span class="cl">    <span class="n">sum_exp_te</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_te</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">c</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">softmax_te</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">exp_te</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="n">sum_exp_te</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">softmax_te</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ç„¶åæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨ <code>BlockBuilder</code>æ„å»ºIRModule</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_model_via_emit_te</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>  <span class="c1"># BCHW</span>
</span></span><span class="line"><span class="cl">    <span class="n">bb</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">BlockBuilder</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="s2">&#34;x&#34;</span><span class="p">,</span> <span class="n">relax</span><span class="o">.</span><span class="n">TensorStructInfo</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="n">conv2d_weight</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">weight_map</span><span class="p">[</span><span class="s2">&#34;conv2d_weight&#34;</span><span class="p">],</span> <span class="s2">&#34;float32&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">conv2d_bias</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">weight_map</span><span class="p">[</span><span class="s2">&#34;conv2d_bias&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">linear0_weight</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">weight_map</span><span class="p">[</span><span class="s2">&#34;linear0_weight&#34;</span><span class="p">],</span> <span class="s2">&#34;float32&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">linear0_bias</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">weight_map</span><span class="p">[</span><span class="s2">&#34;linear0_bias&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">linear1_weight</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">weight_map</span><span class="p">[</span><span class="s2">&#34;linear1_weight&#34;</span><span class="p">],</span> <span class="s2">&#34;float32&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">linear1_bias</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">weight_map</span><span class="p">[</span><span class="s2">&#34;linear1_bias&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="c1"># Build the model using BlockBuilder</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">bb</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="s2">&#34;main&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">bb</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv_conv</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_conv2d</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">conv2d_weight</span><span class="p">,</span> <span class="n">conv2d_bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv_relu1</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_relu</span><span class="p">,</span> <span class="n">gv_conv</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv_pool</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_maxpool2d</span><span class="p">,</span> <span class="n">gv_relu1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv_flatten</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_flatten</span><span class="p">,</span> <span class="n">gv_pool</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv_dense1</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_linear</span><span class="p">,</span> <span class="n">gv_flatten</span><span class="p">,</span> <span class="n">linear0_weight</span><span class="p">,</span> <span class="n">linear0_bias</span><span class="p">)</span>   
</span></span><span class="line"><span class="cl">            <span class="n">gv_relu2</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_relu</span><span class="p">,</span> <span class="n">gv_dense1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv_dense2</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_linear</span><span class="p">,</span> <span class="n">gv_relu2</span><span class="p">,</span> <span class="n">linear1_weight</span><span class="p">,</span> <span class="n">linear1_bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv_softmax</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_te</span><span class="p">(</span><span class="n">my_softmax</span><span class="p">,</span> <span class="n">gv_dense2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="n">bb</span><span class="o">.</span><span class="n">emit_output</span><span class="p">(</span><span class="n">gv_softmax</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">bb</span><span class="o">.</span><span class="n">emit_func_output</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">bb</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>å¾—åˆ°çš„IRModuleçš„TensorIRå¦‚ä¸‹</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mod</span> <span class="o">=</span> <span class="n">create_model_via_emit_te</span><span class="p">()</span>   
</span></span><span class="line"><span class="cl"><span class="n">exec</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s2">&#34;llvm&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">vm</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">VirtualMachine</span><span class="p">(</span><span class="n">exec</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">script</span><span class="p">())</span>
</span></span></code></pre></td></tr></table>
</div>
</div><details class="custom-details">
    <summary class="custom-summary">mod.script</summary>
    <div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@I.ir_module</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Module</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">28</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">28</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">3</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">compute</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="n">conv2d</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">3</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;conv2d&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">,</span> <span class="n">v_k</span><span class="p">,</span> <span class="n">v_r</span><span class="p">,</span> <span class="n">v_s</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SSSSRRR&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_k</span><span class="p">,</span> <span class="n">v_oh</span> <span class="o">+</span> <span class="n">v_r</span><span class="p">,</span> <span class="n">v_ow</span> <span class="o">+</span> <span class="n">v_s</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">v_co</span><span class="p">,</span> <span class="n">v_k</span><span class="p">,</span> <span class="n">v_r</span><span class="p">,</span> <span class="n">v_s</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">conv2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                    <span class="n">conv2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">conv2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_k</span><span class="p">,</span> <span class="n">v_oh</span> <span class="o">+</span> <span class="n">v_r</span><span class="p">,</span> <span class="n">v_ow</span> <span class="o">+</span> <span class="n">v_s</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">v_co</span><span class="p">,</span> <span class="n">v_k</span><span class="p">,</span> <span class="n">v_r</span><span class="p">,</span> <span class="n">v_s</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SSSS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">conv2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">],</span> <span class="n">C</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">]</span> <span class="o">+</span> <span class="n">C</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_flatten</span><span class="p">(</span><span class="n">lv2</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">compute</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">5408</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">5408</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_n</span><span class="p">,</span> <span class="n">v_i</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv2</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_i</span> <span class="o">//</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">169</span><span class="p">),</span> <span class="n">v_i</span> <span class="o">%</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">169</span><span class="p">)</span> <span class="o">//</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">),</span> <span class="n">v_i</span> <span class="o">%</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">lv2</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_i</span> <span class="o">//</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">169</span><span class="p">),</span> <span class="n">v_i</span> <span class="o">%</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">169</span><span class="p">)</span> <span class="o">//</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">),</span> <span class="n">v_i</span> <span class="o">%</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_linear</span><span class="p">(</span><span class="n">lv3</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">5408</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">5408</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">compute</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="n">compute_1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">FI</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">5408</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">,</span> <span class="n">v_FI</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SSR&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">FI</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv3</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">v_j</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                    <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">+</span> <span class="n">lv3</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">v_j</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute_1&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">v_j</span><span class="p">],</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">+</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_linear1</span><span class="p">(</span><span class="n">lv5</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">B</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">C</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">compute</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="n">compute_1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">FI</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">,</span> <span class="n">v_FI</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SSR&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">FI</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv5</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">v_j</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                    <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">+</span> <span class="n">lv5</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">v_j</span><span class="p">,</span> <span class="n">v_FI</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute_1&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">v_j</span><span class="p">],</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">+</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_maxpool2d</span><span class="p">(</span><span class="n">lv1</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">maxpool2d</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">13</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">2</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;maxpool2d&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">,</span> <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SSSSRR&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">co</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv1</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">v_i</span><span class="p">,</span> <span class="n">v_ow</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">maxpool2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                    <span class="n">maxpool2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="o">-</span><span class="mf">340282346638528859811704183484516925440.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">maxpool2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">maxpool2d</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span><span class="p">,</span> <span class="n">v_ow</span><span class="p">],</span> <span class="n">lv1</span><span class="p">[</span><span class="n">v_n</span><span class="p">,</span> <span class="n">v_co</span><span class="p">,</span> <span class="n">v_oh</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">v_i</span><span class="p">,</span> <span class="n">v_ow</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_relu</span><span class="p">(</span><span class="n">lv</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">compute</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">i3</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">26</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">,</span> <span class="n">v_i2</span><span class="p">,</span> <span class="n">v_i3</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SSSS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">i3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">,</span> <span class="n">v_i2</span><span class="p">,</span> <span class="n">v_i3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">,</span> <span class="n">v_i2</span><span class="p">,</span> <span class="n">v_i3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">,</span> <span class="n">v_i2</span><span class="p">,</span> <span class="n">v_i3</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">lv</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">,</span> <span class="n">v_i2</span><span class="p">,</span> <span class="n">v_i3</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_relu1</span><span class="p">(</span><span class="n">lv4</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">compute</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i0</span><span class="p">,</span> <span class="n">i1</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">100</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i0</span><span class="p">,</span> <span class="n">i1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv4</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">lv4</span><span class="p">[</span><span class="n">v_i0</span><span class="p">,</span> <span class="n">v_i1</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@T.prim_func</span><span class="p">(</span><span class="n">private</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">my_softmax</span><span class="p">(</span><span class="n">lv6</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">),</span> <span class="n">compute</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">Buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span> <span class="s2">&#34;float32&#34;</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">T</span><span class="o">.</span><span class="n">func_attr</span><span class="p">({</span><span class="s2">&#34;tir.noalias&#34;</span><span class="p">:</span> <span class="n">T</span><span class="o">.</span><span class="n">bool</span><span class="p">(</span><span class="kc">True</span><span class="p">)})</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># with T.block(&#34;root&#34;):</span>
</span></span><span class="line"><span class="cl">        <span class="n">compute_1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),))</span>
</span></span><span class="line"><span class="cl">        <span class="n">compute_2</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="n">compute_3</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">alloc_buffer</span><span class="p">((</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_c</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SR&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv6</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_c</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                    <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="o">-</span><span class="mf">340282346638528859811704183484516925440.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">],</span> <span class="n">lv6</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_c</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute_1&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">lv6</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">],</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute_2</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute_2</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lv6</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">-</span> <span class="n">compute_1</span><span class="p">[</span><span class="n">v_i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute_2&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_c</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SR&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">compute_2</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_c</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute_3</span><span class="p">[</span><span class="n">v_i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">init</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                    <span class="n">compute_3</span><span class="p">[</span><span class="n">v_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute_3</span><span class="p">[</span><span class="n">v_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_3</span><span class="p">[</span><span class="n">v_i</span><span class="p">]</span> <span class="o">+</span> <span class="n">compute_2</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_c</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">T</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">T</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">T</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s2">&#34;compute_3&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">remap</span><span class="p">(</span><span class="s2">&#34;SS&#34;</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">reads</span><span class="p">(</span><span class="n">compute_2</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">],</span> <span class="n">compute_3</span><span class="p">[</span><span class="n">v_i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">T</span><span class="o">.</span><span class="n">writes</span><span class="p">(</span><span class="n">compute</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">compute</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_2</span><span class="p">[</span><span class="n">v_i</span><span class="p">,</span> <span class="n">v_j</span><span class="p">]</span> <span class="o">/</span> <span class="n">compute_3</span><span class="p">[</span><span class="n">v_i</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@R.function</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">cls</span> <span class="o">=</span> <span class="n">Module</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">R</span><span class="o">.</span><span class="n">dataflow</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_conv2d</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&#34;relax.expr.Constant&#34;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&#34;relax.expr.Constant&#34;</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv1</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_relu</span><span class="p">,</span> <span class="p">(</span><span class="n">lv</span><span class="p">,),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv2</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_maxpool2d</span><span class="p">,</span> <span class="p">(</span><span class="n">lv1</span><span class="p">,),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv3</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_flatten</span><span class="p">,</span> <span class="p">(</span><span class="n">lv2</span><span class="p">,),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5408</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv4</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_linear</span><span class="p">,</span> <span class="p">(</span><span class="n">lv3</span><span class="p">,</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&#34;relax.expr.Constant&#34;</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&#34;relax.expr.Constant&#34;</span><span class="p">][</span><span class="mi">3</span><span class="p">]),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv5</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_relu1</span><span class="p">,</span> <span class="p">(</span><span class="n">lv4</span><span class="p">,),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv6</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_linear1</span><span class="p">,</span> <span class="p">(</span><span class="n">lv5</span><span class="p">,</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&#34;relax.expr.Constant&#34;</span><span class="p">][</span><span class="mi">4</span><span class="p">],</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&#34;relax.expr.Constant&#34;</span><span class="p">][</span><span class="mi">5</span><span class="p">]),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">lv7</span> <span class="o">=</span> <span class="n">R</span><span class="o">.</span><span class="n">call_tir</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">my_softmax</span><span class="p">,</span> <span class="p">(</span><span class="n">lv6</span><span class="p">,),</span> <span class="n">out_sinfo</span><span class="o">=</span><span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">gv</span><span class="p">:</span> <span class="n">R</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&#34;float32&#34;</span><span class="p">)</span> <span class="o">=</span> <span class="n">lv7</span>
</span></span><span class="line"><span class="cl">            <span class="n">R</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">gv</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">gv</span>
</span></span></code></pre></td></tr></table>
</div>
</div></div>
</details><br>
<p>æˆ‘ä»¬å¯ä»¥ä¸Pytorchæ¨¡å‹çš„æ‰§è¡Œç»“æœè¿›è¡Œæ¯”è¾ƒæ¥éªŒè¯æ­£ç¡®æ€§ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">build_mod</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">exec</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s2">&#34;llvm&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">vm</span> <span class="o">=</span> <span class="n">relax</span><span class="o">.</span><span class="n">VirtualMachine</span><span class="p">(</span><span class="n">exec</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">vm</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">check_equivalence</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">torch_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">rt_mod</span> <span class="o">=</span> <span class="n">build_mod</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">label</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">output_from_pytorch</span> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">output_from_relax</span> <span class="o">=</span> <span class="n">rt_mod</span><span class="p">[</span><span class="s2">&#34;main&#34;</span><span class="p">](</span><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">tvm</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">output_from_pytorch</span><span class="p">,</span> <span class="n">output_from_relax</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;./data&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">mod</span> <span class="o">=</span> <span class="n">create_model_via_emit_te</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">torch_model</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">check_equivalence</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">torch_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/autotuning/">Autotuning</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/blogs/courselearning/tvm/tvm-ch6/">
    <span class="title">Â« Prev</span>
    <br>
    <span>TVM Learning (8)-GPU and Hardware Acceleration, Part 1</span>
  </a>
  <a class="next" href="http://localhost:1313/blogs/courselearning/tvm/tvm-ch4/">
    <span class="title">Next Â»</span>
    <br>
    <span>TVM Learning (5)-Automatic Program Optimization</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share TVM Learning (6)-Exercise of End to End Model Execution on x"
            href="https://x.com/intent/tweet/?text=TVM%20Learning%20%286%29-Exercise%20of%20End%20to%20End%20Model%20Execution&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fcourselearning%2ftvm%2ftvm-ch5%2f&amp;hashtags=Autotuning">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share TVM Learning (6)-Exercise of End to End Model Execution on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fcourselearning%2ftvm%2ftvm-ch5%2f&amp;title=TVM%20Learning%20%286%29-Exercise%20of%20End%20to%20End%20Model%20Execution&amp;summary=TVM%20Learning%20%286%29-Exercise%20of%20End%20to%20End%20Model%20Execution&amp;source=http%3a%2f%2flocalhost%3a1313%2fblogs%2fcourselearning%2ftvm%2ftvm-ch5%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share TVM Learning (6)-Exercise of End to End Model Execution on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fcourselearning%2ftvm%2ftvm-ch5%2f&title=TVM%20Learning%20%286%29-Exercise%20of%20End%20to%20End%20Model%20Execution">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share TVM Learning (6)-Exercise of End to End Model Execution on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fblogs%2fcourselearning%2ftvm%2ftvm-ch5%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share TVM Learning (6)-Exercise of End to End Model Execution on telegram"
            href="https://telegram.me/share/url?text=TVM%20Learning%20%286%29-Exercise%20of%20End%20to%20End%20Model%20Execution&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fcourselearning%2ftvm%2ftvm-ch5%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
</ul>

  </footer><script src="https://giscus.app/client.js"
        data-repo="jamesnulliu/jamesnulliu.github.io"
        data-repo-id="R_kgDOMPCQIw"
        data-category="Announcements"
        data-category-id="DIC_kwDOMPCQI84Cgb2t"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>Â© 2024-2025 WITHER</span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
