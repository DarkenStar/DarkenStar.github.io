<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>DistriFusion | WITHER</title>
<meta name="keywords" content="DistriFusion">
<meta name="description" content="Paper reading about DistriFusion.">
<meta name="author" content="WITHER">
<link rel="canonical" href="http://localhost:1313/blogs/distrifusion/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.dd3b5b907a50db3238b81d49d094cf1c04a091227797dc9cfde4e2fa3f35df49.css" integrity="sha256-3TtbkHpQ2zI4uB1J0JTPHASgkSJ3l9yc/eTi&#43;j8130k=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/blogs/distrifusion/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]  
    }
  };
</script>




<script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.1.6/mermaid.min.js"></script>
<script>
    mermaid.initialize({
        startOnLoad: true,
        theme: localStorage.getItem("pref-theme") === "dark" ? "dark" : "forest" 
    });
</script>

<meta property="og:url" content="http://localhost:1313/blogs/distrifusion/">
  <meta property="og:site_name" content="WITHER">
  <meta property="og:title" content="DistriFusion">
  <meta property="og:description" content="Paper reading about DistriFusion.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2024-10-23T14:28:37+08:00">
    <meta property="article:modified_time" content="2025-06-07T23:40:58+08:00">
    <meta property="article:tag" content="Diffusion Models">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DistriFusion">
<meta name="twitter:description" content="Paper reading about DistriFusion.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "http://localhost:1313/blogs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "DistriFusion",
      "item": "http://localhost:1313/blogs/distrifusion/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DistriFusion",
  "name": "DistriFusion",
  "description": "Paper reading about DistriFusion.",
  "keywords": [
    "DistriFusion"
  ],
  "articleBody": "Abstract DistriFusion å°†æ¨¡å‹è¾“å…¥åˆ†å‰²æˆå¤šä¸ª patch ååˆ†é…ç»™ GPUã€‚ä½†æ˜¯ç›´æ¥å®ç°è¿™æ ·çš„ç®—æ³•ä¼šç ´å patch ä¹‹é—´çš„äº¤äº’å¹¶å¤±å»ä¿çœŸåº¦ï¼Œè€ŒåŒæ­¥ GPU ä¹‹é—´çš„æ¿€æ´»å°†äº§ç”Ÿå·¨å¤§çš„é€šä¿¡å¼€é”€ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å›°å¢ƒï¼Œæ ¹æ®è§‚å¯Ÿåˆ°çš„ç›¸é‚»æ‰©æ•£æ­¥è¾“å…¥ä¹‹é—´çš„é«˜åº¦ç›¸ä¼¼æ€§æå‡ºäº† displaced patch parallelismï¼Œè¯¥æ–¹æ³•é€šè¿‡é‡ç”¨å‰ä¸€ä¸ªæ—¶é—´æ­¥éª¤ä¸­é¢„å…ˆè®¡ç®—çš„ feature map æ¥åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§ï¼Œä¸ºå½“å‰æ­¥æä¾› context. è¯¥æ–¹æ³•æ”¯æŒå¼‚æ­¥é€šä¿¡ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—å®ç°æµæ°´çº¿åŒ–ã€‚\nIntroduction Original, Navie Patch \u0026 DistriFusion\nåŠ é€Ÿæ‰©æ•£æ¨¡å‹æ¨ç†ä¸»è¦é›†ä¸­åœ¨ä¸¤ç§æ–¹æ³•ä¸Šï¼šå‡å°‘é‡‡æ ·æ­¥éª¤å’Œä¼˜åŒ–ç½‘ç»œæ¨ç†ã€‚éšç€è®¡ç®—èµ„æºçš„å¿«é€Ÿå¢é•¿ï¼Œåˆ©ç”¨å¤šä¸ª GPU æ¥åŠ é€Ÿæ¨ç†æ˜¯å¾ˆæœ‰å¸å¼•åŠ›çš„ã€‚ä¾‹å¦‚åœ¨ NLP ä¸­ï¼Œ LLM å·²ç»æˆåŠŸåœ°åˆ©ç”¨äº† GPU ä¹‹é—´çš„å¼ é‡å¹¶è¡Œæ€§ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†å»¶è¿Ÿã€‚ç„¶è€Œï¼Œå¯¹äºæ‰©æ•£æ¨¡å‹ï¼Œç”±äºæ¿€æ´»å°ºå¯¸å¤§ï¼Œå¼ é‡å¹¶è¡Œè¿™æ ·çš„æŠ€æœ¯ä¸å¤ªé€‚åˆæ‰©æ•£æ¨¡å‹ã€‚å¤šä¸ª GPU é€šå¸¸åªç”¨äº batch æ¨ç†ï¼Œå½“ç”Ÿæˆå•ä¸ªå›¾åƒæ—¶ï¼Œé€šå¸¸åªæ¶‰åŠä¸€ä¸ªGPU.\nTechniques like tensor parallelism are less suitable for diffusion models due to the large activation size, as communication costs outweigh savings from distributed computation.\nè‡ªç„¶è€Œç„¶çš„ä¸€ç§æ–¹æ³•æ˜¯å°†å›¾åƒåˆ†æˆå‡ ä¸ª patch ååˆ†é…ç»™ä¸åŒçš„è®¾å¤‡è¿›è¡Œç”Ÿæˆã€‚ç”±äºå„ä¸ª patch ä¹‹é—´ç¼ºä¹ç›¸äº’ä½œç”¨ï¼Œå®ƒåœ¨æ¯ä¸ª patch çš„è¾¹ç•Œå¤„éƒ½æœ‰ä¸€ä¸ªæ¸…æ™°å¯è§çš„åˆ†ç•Œçº¿ã€‚\nDistriFusion ä¹Ÿæ˜¯åŸºäº patch parallelism. å…³é”®åœ¨äºæ‰©æ•£æ¨¡å‹ä¸­ç›¸é‚»å»å™ªæ­¥éª¤çš„è¾“å…¥æ˜¯ç›¸ä¼¼çš„ï¼Œå› æ­¤ï¼Œåªåœ¨ç¬¬ä¸€æ­¥é‡‡ç”¨åŒæ­¥é€šä¿¡ã€‚åç»­æ­¥éª¤é‡ç”¨å‰ä¸€æ­¥ä¸­é¢„å…ˆè®¡ç®—çš„æ¿€æ´»ï¼Œä¸ºå½“å‰æ­¥éª¤æä¾›å…¨å±€ä¸Šä¸‹æ–‡å’Œ patch äº¤äº’ã€‚é€šè¿‡å¼‚æ­¥é€šä¿¡æœ‰æ•ˆåœ°éšè—äº†è®¡ç®—ä¸­çš„é€šä¿¡å¼€é”€ã€‚å¹¶ä¸”è¿˜ç¨€ç–åœ°åœ¨æŒ‡å®šçš„åŒºåŸŸä¸Šè¿›è¡Œå·ç§¯å’Œæ³¨æ„åŠ›è®¡ç®—ï¼Œä»è€ŒæŒ‰æ¯”ä¾‹å‡å°‘æ¯ä¸ªè®¾å¤‡çš„è®¡ç®—é‡ã€‚\nMethod Displaced Patch Parallelism. åœ¨é¢„æµ‹ $\\epsilon_{\\theta}(\\mathbf{x}_{t})$ æ—¶ (å¿½ç•¥æ¡ä»¶ c å’Œæ—¶é—´æ­¥ t çš„è¾“å…¥) ï¼Œé¦–å…ˆå°† $\\mathbf{x}_{t}$ åˆ†å‰²æˆå¤šä¸ª patch $\\mathbf{x}_t^{(1)},\\mathbf{x}_t^{(2)},\\ldots,\\mathbf{x}_t^{(N)}$ ï¼Œå¯¹äºæ¯ä¸€å±‚ l å’Œè®¾å¤‡ iï¼Œåœ¨è·å¾—è¾“å…¥æ¿€æ´» patch $\\mathbf{A}_{t}^{l,(i)}$ åå¼‚æ­¥å¤„ç†ä¸¤ä¸ªæ“ä½œï¼šé¦–å…ˆï¼Œå¯¹äºè®¾å¤‡iï¼Œ æ¿€æ´» $\\mathbf{A}_{t}^{l,(i)}$ é¦–å…ˆ scatter åˆ°ä¸Šä¸€æ­¥æ—§çš„æ¿€æ´» $\\mathbf{A}_{t+1}^{l}$ ä¸­ã€‚ç„¶åå°†æ­¤åˆ†æ•£æ“ä½œçš„è¾“å‡ºé€å…¥ç¨€ç–ç®—å­ Fl (çº¿æ€§ã€å·ç§¯æˆ–æ³¨æ„å±‚)ï¼Œè¯¥ç®—å­ä¸“é—¨å¯¹æ–°åŒºåŸŸæ‰§è¡Œè®¡ç®—å¹¶äº§ç”Ÿç›¸åº”çš„è¾“å‡ºã€‚åŒæ—¶ï¼Œå¯¹ $\\mathbf{A}_{t}^{l,(i)}$ æ‰§è¡Œ AllGather æ“ä½œï¼Œä¸ºä¸‹ä¸€æ­¥çš„å…¨å°ºå¯¸æ¿€æ´» $\\mathbf{A}_{t}^{l}$ åšå‡†å¤‡ã€‚\nOverview of DistriFusion\næˆ‘ä»¬å¯¹é™¤ç¬¬ä¸€å±‚ (é‡‡ç”¨åŒæ­¥é€šä¿¡è·å¾—å…¶ä»–è®¾å¤‡ä¸Šçš„è¾“å…¥) å¤–çš„æ¯ä¸€å±‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ã€‚ç„¶åå°†æœ€ç»ˆè¾“å‡º Gather åœ¨ä¸€èµ·ä»¥è¿‘ä¼¼ $\\epsilon_{\\theta}(\\mathbf{x}_{t})$ï¼Œç”¨äºè®¡ç®— $\\mathbf{x}_{t-1}$\nTimeline Visualization on Each Device\nSparse Operations å¯¹äºæ¯ä¸€å±‚ lï¼Œå¦‚æœåŸå§‹ç®—å­ Fl æ˜¯ä¸€ä¸ªå·ç§¯å±‚ã€çº¿æ€§å±‚æˆ–äº¤å‰æ³¨æ„å±‚ï¼Œè°ƒæ•´ä½¿å…¶ä¸“é—¨ä½œç”¨äºæ–°æ¿€æ´»çš„åŒºåŸŸã€‚è¿™å¯ä»¥é€šè¿‡ä» scatter è¾“å‡ºä¸­æå–æœ€æ–°éƒ¨åˆ†å¹¶å°†å…¶è¾“å…¥åˆ° Fl ä¸­æ¥å®ç°ã€‚å¯¹äº self-attentionï¼Œå°†å…¶è½¬æ¢ä¸º cross-attentionï¼Œä»…åœ¨è®¾å¤‡ä¸Šä¿ç•™æ¥è‡ªæ–°æ¿€æ´»çš„ Qï¼Œè€Œ KV ä»ç„¶åŒ…å«æ•´ä¸ªç‰¹å¾å›¾ã€‚\nCorrected Asynchronous GroupNorm ä»…å¯¹æ–° patch è¿›è¡Œå½’ä¸€åŒ–æˆ–é‡ç”¨æ—§ç‰¹å¾éƒ½ä¼šé™ä½å›¾åƒè´¨é‡ã€‚åŒæ­¥ AllGather æ‰€æœ‰å‡å€¼å’Œæ–¹å·®å°†äº§ç”Ÿç›¸å½“å¤§çš„å¼€é”€ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å›°å¢ƒï¼ŒDistriFusion åœ¨é™ˆæ—§çš„ç»Ÿè®¡æ•°æ®ä¸­å¼•å…¥äº†ä¸€ä¸ªæ ¡æ­£é¡¹ã€‚è®¡ç®—å…¬å¼å¦‚ä¸‹\n$$\r\\mathbb{E}[\\mathbf{A}_t]\\approx\\underbrace{\\mathbb{E}[\\mathbf{A}_{t+1}]}_{\\text{stale global mean}}+\\underbrace{\\mathbb{E}[\\mathbf{A}_t^{(i)}]-\\mathbb{E}[\\mathbf{A}_{t+1}^{(i)}]}_{\\text{correction}}\r$$åŒæ ·å¯¹äºŒé˜¶çŸ© $\\mathbb{E}[\\mathbf{A}^2_t]$ ä¹Ÿé‡‡ç”¨è¿™ç§è®¡ç®—æ–¹å¼ï¼Œç„¶åé€šè¿‡ $\\mathbb{E}[\\mathbf{A}^2_t] - \\mathbb{E}[\\mathbf{A}_t]^2$ æ¥è®¡ç®—æ–¹å·®ã€‚å¯¹äºæ–¹å·®ç»“æœä¸ºè´Ÿçš„éƒ¨åˆ†ï¼Œå°†ä½¿ç”¨æ–°é²œ patch çš„å±€éƒ¨æ–¹å·®ä»£æ›¿ã€‚\nCode Implementation Distrifusion ä¸­ä¸»è¦å°±æ˜¯å°† UNet2DConditionModel ä¸­çš„ Conv2d, Attention å’Œ GroupNorm æ›¿æ¢æˆå¯¹åº”çš„ patch å®ç°çš„ç½‘ç»œç»“æ„ DistriUNetPP. è¿™é‡Œç»§æ‰¿çš„ BaseModel ç±»ä¸ºé›†æˆäº† PatchParallelismCommManager ç±» (ä»‹ç»è§åæ–‡) çš„ç½‘ç»œã€‚\nUNet2DConditionModel\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class DistriUNetPP(BaseModel): # for Patch Parallelism def __init__(self, model: UNet2DConditionModel, distri_config: DistriConfig): assert isinstance(model, UNet2DConditionModel) if distri_config.world_size \u003e 1 and distri_config.n_device_per_batch \u003e 1: for name, module in model.named_modules(): if isinstance(module, BaseModule): continue ''' Substitute Conv2d, Attention, GroupNorm with DistriConv2dPP, DistriSelfAttentionPP, DistriCrossAttentionPP, DistriGroupNorm ''' for subname, submodule in module.named_children(): if isinstance(submodule, nn.Conv2d): kernel_size = submodule.kernel_size if kernel_size == (1, 1) or kernel_size == 1: continue wrapped_submodule = DistriConv2dPP( submodule, distri_config, is_first_layer=subname == \"conv_in\" ) setattr(module, subname, wrapped_submodule) elif isinstance(submodule, Attention): if subname == \"attn1\": # self attention wrapped_submodule = DistriSelfAttentionPP(submodule, distri_config) else: # cross attention assert subname == \"attn2\" wrapped_submodule = DistriCrossAttentionPP(submodule, distri_config) setattr(module, subname, wrapped_submodule) elif isinstance(submodule, nn.GroupNorm): wrapped_submodule = DistriGroupNorm(submodule, distri_config) setattr(module, subname, wrapped_submodule) super(DistriUNetPP, self).__init__(model, distri_config) PatchParallelismCommManager PatchParallelismCommManager ç±»ä¸»è¦å¤„ç†å¼‚æ­¥é€šä¿¡çš„éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class PatchParallelismCommManager: def __init__(self, distri_config: DistriConfig): self.distri_config = distri_config self.torch_dtype = None self.numel = 0 # å·²ç»æ³¨å†Œçš„å¼ é‡çš„ç´¯è®¡æ€»å…ƒç´ æ•°é‡ self.numel_dict = {} # è®°å½•æ¯ä¸ª layer_type æ‰€æ³¨å†Œçš„å¼ é‡çš„ç´¯è®¡å…ƒç´ æ•°é‡ self.buffer_list = None # åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šå­˜å‚¨æ‰€æœ‰æ³¨å†Œå¼ é‡çš„æ•°æ®ï¼Œé€šä¿¡æ‰€ç”¨çš„ buffer self.starts = [] # è®°å½•æ¯ä¸ªæ³¨å†Œå¼ é‡çš„èµ·å§‹ä½ç½® (åœ¨ buffer_list ä¸­çš„èµ·å§‹ç´¢å¼•) self.ends = [] # ç»“æŸ ç»“æŸ self.shapes = [] # è®°å½•æ¯ä¸ªæ³¨å†Œå¼ é‡çš„ shape self.idx_queue = [] # éœ€è¦è¿›è¡Œé€šä¿¡çš„å¼ é‡ç´¢å¼•çš„é˜Ÿåˆ— self.handles = None # å­˜å‚¨æ¯ä¸ªè®¾å¤‡é€šä¿¡æ“ä½œçš„å¥æŸ„çš„ list, ç”¨äºæ£€æŸ¥é€šä¿¡æ˜¯å¦å®Œæˆ æˆå‘˜å‡½æ•°åŠŸèƒ½ä»‹ç»å¦‚ä¸‹\nregister_tensor(self, shape: tuple[int, ...] or list[int], torch_dtype: torch.dtype, layer_type: str = None) -\u003e int: ç”¨äºæ³¨å†Œå¼ é‡çš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹ï¼ŒåŒæ—¶è®¡ç®—å¹¶è®°å½•å¼ é‡åœ¨ç¼“å†²åŒºä¸­çš„èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®ã€‚\nå¦‚æœå°šæœªæŒ‡å®š torch_dtypeï¼Œåˆ™å°†ä¼ å…¥çš„ torch_dtype è®¾ä¸ºç±»æˆå‘˜çš„é»˜è®¤æ•°æ®ç±»å‹ã€‚ è®¡ç®—ä¼ å…¥å¼ é‡å½¢çŠ¶çš„æ€»å…ƒç´ æ•° numelï¼Œå¹¶æ›´æ–° startsã€ends å’Œ shapes åˆ—è¡¨ã€‚ å¦‚æœæŒ‡å®šäº† layer_typeï¼Œæ›´æ–° numel_dict ä¸­è¯¥å±‚ç±»å‹å¯¹åº”çš„å…ƒç´ æ•°ç›®ã€‚ create_buffer(self) : æ¯ä¸ªè®¾å¤‡ä¸Šä¸ºæ‰€æœ‰æ³¨å†Œçš„å¼ é‡åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç¼“å†²åŒºã€‚\nä¸ºæ¯ä¸ªè®¾å¤‡åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º (numel,) çš„å¼ é‡ï¼Œå¹¶å°†å…¶æ”¾å…¥ buffer_list ä¸­ã€‚ è¾“å‡ºåœ¨å„è®¾å¤‡ä¸Šåˆ›å»ºçš„ç¼“å†²åŒºæ€»å‚æ•°é‡ã€‚ get_buffer_list(self, idx: int) -\u003e list[torch.Tensor]: è¿”å›æ¯ä¸ªè®¾å¤‡ä¸Šå¯¹åº”äºæŒ‡å®šç´¢å¼• idx çš„ç¼“å†²åŒºå¼ é‡ã€‚\næ ¹æ® starts å’Œ ends ä¿¡æ¯ï¼Œä» buffer_list ä¸­æå–æŒ‡å®šç´¢å¼• idx çš„å¼ é‡ç‰‡æ®µå¹¶è°ƒæ•´å…¶å½¢çŠ¶ã€‚ communicate(self): è°ƒç”¨ dist.all_gather å°†ç¼“å†²åŒºä¸­çš„å¼ é‡åœ¨ä¸åŒè®¾å¤‡é—´è¿›è¡Œå¹¿æ’­ã€‚\nç¡®å®šå½“å‰éœ€è¦é€šä¿¡çš„å¼ é‡èŒƒå›´ (æ ¹æ® idx_queue ä¸­çš„ç´¢å¼•). è°ƒç”¨ dist.all_gather åœ¨è®¾å¤‡ç»„å†…è¿›è¡Œå¼‚æ­¥å¹¿æ’­é€šä¿¡ï¼Œå¹¶å°†å¥æŸ„å­˜å‚¨åœ¨ handles ä¸­ã€‚ enqueue(self, idx: int, tensor: torch.Tensor): å°†æŒ‡å®šç´¢å¼• idx å¤„çš„å¼ é‡æ•°æ®å¤åˆ¶åˆ° buffer_list ä¸­ï¼Œå¹¶å°†ç´¢å¼•æ·»åŠ åˆ°é€šä¿¡é˜Ÿåˆ— idx_queueã€‚\nå¦‚æœé€šä¿¡é˜Ÿåˆ—ä¸ä¸ºç©ºä¸”ç´¢å¼•ä¸º 0ï¼Œåˆ™å…ˆæ‰§è¡Œä¸€æ¬¡é€šä¿¡æ“ä½œã€‚ å°†å¼ é‡æ•°æ®å¤åˆ¶åˆ° buffer_list ä¸­çš„å¯¹åº”ä½ç½®ã€‚ å½“é€šä¿¡é˜Ÿåˆ—é•¿åº¦è¾¾åˆ° distri_config ä¸­è®¾å®šçš„é€šä¿¡æ£€æŸ¥ç‚¹å€¼æ—¶ï¼Œè¿›è¡Œé€šä¿¡ã€‚ clear(self): æ‰§è¡Œä¸€æ¬¡æ‰€æœ‰å¾…é€šä¿¡å¼ é‡çš„é€šä¿¡ï¼Œå¹¶ç­‰å¾…æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆã€‚\nå¦‚æœé€šä¿¡é˜Ÿåˆ—ä¸ä¸ºç©ºï¼Œåˆ™è¿›è¡Œé€šä¿¡æ“ä½œã€‚ éå†æ‰€æœ‰å¥æŸ„ï¼Œç­‰å¾…æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆåï¼Œå°†å¥æŸ„è®¾ä¸º None. DistriConv2dPP DistriConv2dPP è®¡ç®—è‡ªå·±è´Ÿè´£ patch éƒ¨åˆ†çš„å·ç§¯ï¼Œéœ€è¦é€šä¿¡å…¶ä»–è®¾å¤‡éœ€è¦è‡ªå·±è´Ÿè´£ patch çš„ä¸Šä¸‹ padding éƒ¨åˆ†ã€‚\n__init__ï¼šæ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–æˆå‘˜å˜é‡ï¼Œè®¾ç½®æ˜¯å¦ä¸ºç¬¬ä¸€å±‚å·ç§¯ã€‚ naive_forwardï¼šæ‰§è¡Œæ ‡å‡†çš„å‰å‘ä¼ æ’­ï¼Œä¸è¿›è¡Œä»»ä½•åˆ‡ç‰‡æ“ä½œã€‚è¿™æ˜¯å•ä¸ªè®¾å¤‡å¤„ç†æ—¶çš„æ™®é€šå·ç§¯æ“ä½œã€‚ sliced_forwardï¼šå¤„ç†è¾“å…¥å¼ é‡çš„åˆ‡ç‰‡æ“ä½œã€‚æ ¹æ®å½“å‰è®¾å¤‡ç´¢å¼• (split_idx) è®¡ç®—è¾“å…¥å¼ é‡åœ¨é«˜åº¦æ–¹å‘çš„èµ·å§‹å’Œç»“æŸä½ç½®ï¼Œå¹¶åœ¨å¿…è¦æ—¶ä¸ºåˆ‡ç‰‡åçš„å¼ é‡æ·»åŠ  padding åè¿›è¡Œå·ç§¯æ“ä½œã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class DistriConv2dPP(BaseModule): def __init__(self, module: nn.Conv2d, distri_config: DistriConfig, is_first_layer: bool = False): super(DistriConv2dPP, self).__init__(module, distri_config) self.is_first_layer = is_first_layer def naive_forward(self, x: torch.Tensor) -\u003e torch.Tensor: # x: [B, C, H, W] output = self.module(x) return output def sliced_forward(self, x: torch.Tensor) -\u003e torch.Tensor: '''...''' def forward(self, x: torch.Tensor, *args, **kwargs) -\u003e torch.Tensor: distri_config = self.distri_config # ç­‰å¾…ä¸Šä¸€æ­¥é€šä¿¡å®Œæˆ if self.comm_manager is not None and self.comm_manager.handles is not None and self.idx is not None: if self.comm_manager.handles[self.idx] is not None: self.comm_manager.handles[self.idx].wait() self.comm_manager.handles[self.idx] = None boundary_size = self.module.padding[0] if self.buffer_list is None: # buffer_list å­˜å‚¨çš„æ˜¯æ¯ä¸ª devive è¿›è¡Œå·ç§¯æ‰€éœ€è¦çš„å…¶ä»– devive çš„æ•°æ® if self.comm_manager.buffer_list is None: self.idx = self.comm_manager.register_tensor( shape=[2, x.shape[0], x.shape[1], boundary_size, x.shape[3]], torch_dtype=x.dtype, layer_type=\"conv2d\", ) else: self.buffer_list = self.comm_manager.get_buffer_list(self.idx) def create_padded_x(): '''æ‹¼æ¥æ¥æ”¶åˆ°çš„æ•°æ®''' if distri_config.split_idx() == 0: # rank 0 concat_x = torch.cat([x, self.buffer_list[distri_config.split_idx() + 1][0]], dim=2) padded_x = F.pad(concat_x, [0, 0, boundary_size, 0], mode=\"constant\") elif distri_config.split_idx() == distri_config.n_device_per_batch - 1: # rank n-1 concat_x = torch.cat([self.buffer_list[distri_config.split_idx() - 1][1], x], dim=2) padded_x = F.pad(concat_x, [0, 0, 0, boundary_size], mode=\"constant\") else: # other ranks padded_x = torch.cat( [ self.buffer_list[distri_config.split_idx() - 1][1], x, self.buffer_list[distri_config.split_idx() + 1][0], ], dim=2, ) return padded_x # æå–å½“å‰è¾“å…¥å¼ é‡éœ€è¦å‘é€ç»™å…¶ä»–è®¾å¤‡çš„éƒ¨åˆ† boundary = torch.stack([x[:, :, :boundary_size, :], x[:, :, -boundary_size:, :]], dim=0) # ç›´æ¥ç”¨ä¸Šä¸€æ­¥çš„ buffer æ‹¼æ¥ padded_x = create_padded_x() output = F.conv2d( padded_x, self.module.weight, self.module.bias, stride=self.module.stride[0], padding=(0, self.module.padding[1]), ) if distri_config.mode != \"no_sync\": self.comm_manager.enqueue(self.idx, boundary) # æ’å…¥è‡ªå·±è¦å‘é€çš„æ•°æ® self.counter += 1 return output DistriSelfAttentionPP DistriSelfAttentionPP åªè´Ÿè´£è®¡ç®—è‡ªå·± patch çš„è¾“å‡ºï¼Œéœ€è¦å®Œæ•´çš„ KVï¼Œå°† self attention è¿ç®—å˜æˆ cross-attention è®¡ç®—ã€‚éœ€è¦é€šä¿¡è‡ªå·±çš„ KV.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class DistriSelfAttentionPP(DistriAttentionPP): def __init__(self, module: Attention, distri_config: DistriConfig): super(DistriSelfAttentionPP, self).__init__(module, distri_config) def _forward(self, hidden_states: torch.FloatTensor, scale: float = 1.0): attn = self.module # è·å– Attention æ¨¡å— distri_config = self.distri_config residual = hidden_states # æ®‹å·®è¿æ¥ batch_size, sequence_length, _ = hidden_states.shape args = () if USE_PEFT_BACKEND else (scale,) query = attn.to_q(hidden_states, *args) # Q Projection encoder_hidden_states = hidden_states kv = self.to_kv(encoder_hidden_states) # KV Projection if self.buffer_list is None: # å¦‚æœç¼“å†²åŒºæœªåˆ›å»º full_kv = torch.cat([kv for _ in range(distri_config.n_device_per_batch)], dim=1) new_buffer_list = [buffer for buffer in self.buffer_list] new_buffer_list[distri_config.split_idx()] = kv full_kv = torch.cat(new_buffer_list, dim=1) if distri_config.mode != \"no_sync\": self.comm_manager.enqueue(self.idx, kv) # å°† full_kv åˆ†å‰²ä¸º key å’Œ value key, value = torch.split(full_kv, full_kv.shape[-1] // 2, dim=-1) inner_dim = key.shape[-1] head_dim = inner_dim // attn.heads # multi-head attention query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2) key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2) value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2) hidden_states = F.scaled_dot_product_attention(query, key, value, dropout_p=0.0, is_causal=False) hidden_states = hidden_states.transpose(1, 2).reshape(batch_size, -1, attn.heads * head_dim) hidden_states = hidden_states.to(query.dtype) hidden_states = attn.to_out[0](hidden_states, *args) # O Projection hidden_states = attn.to_out[1](hidden_states) # Dropout if attn.residual_connection: hidden_states = hidden_states + residual hidden_states = hidden_states / attn.rescale_output_factor return hidden_states DistriGroupNorm DistriGroupNorm æ ¹æ®ä¸Šä¸€æ­¥å…¨ç‰¹å¾å›¾çš„ä»¥åŠå½“å‰æ­¥ patch çš„å‡å€¼å’ŒäºŒé˜¶çŸ©è¿‘ä¼¼å½“å‰æ­¥çš„å…¨ç‰¹å¾å›¾å‡å€¼å’Œæ–¹å·®ã€‚éœ€è¦é€šä¿¡ patch å‡å€¼å’ŒäºŒé˜¶çŸ©ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class DistriGroupNorm(BaseModule): def __init__(self, module: nn.GroupNorm, distri_config: DistriConfig): assert isinstance(module, nn.GroupNorm) super(DistriGroupNorm, self).__init__(module, distri_config) def forward(self, x: torch.Tensor) -\u003e torch.Tensor: module = self.module distri_config = self.distri_config if self.comm_manager is not None and self.comm_manager.handles is not None and self.idx is not None: if self.comm_manager.handles[self.idx] is not None: self.comm_manager.handles[self.idx].wait() self.comm_manager.handles[self.idx] = None assert x.ndim == 4 n, c, h, w = x.shape num_groups = module.num_groups group_size = c // num_groups if self.buffer_list is None: if self.comm_manager.buffer_list is None: n, c, h, w = x.shape self.idx = self.comm_manager.register_tensor( # register for E[x], E[x^2] shape=[2, n, num_groups, 1, 1, 1], torch_dtype=x.dtype, layer_type=\"gn\" ) else: self.buffer_list = self.comm_manager.get_buffer_list(self.idx) x = x.view([n, num_groups, group_size, h, w]) # è®¡ç®— patch å‡å€¼å’ŒäºŒé˜¶çŸ© x_mean = x.mean(dim=[2, 3, 4], keepdim=True) # [1, num_groups, 1, 1, 1] x2_mean = (x**2).mean(dim=[2, 3, 4], keepdim=True) # [1, num_groups, 1, 1, 1] slice_mean = torch.stack([x_mean, x2_mean], dim=0) if self.buffer_list is None: full_mean = slice_mean else: # Equation 2 in the paper E[A_t] = E[A_(t+1)] + (E[A^i_t] - E[A^i_(t+1)]), same for E[A^2_t] correction = slice_mean - self.buffer_list[distri_config.split_idx()] full_mean = sum(self.buffer_list) / distri_config.n_device_per_batch + correction self.comm_manager.enqueue(self.idx, slice_mean) full_x_mean, full_x2_mean = full_mean[0], full_mean[1] var = full_x2_mean - full_x_mean**2 # è®¡ç®—æ–¹å·® slice_x_mean, slice_x2_mean = slice_mean[0], slice_mean[1] slice_var = slice_x2_mean - slice_x_mean**2 var = torch.where(var \u003c 0, slice_var, var) # Correct negative variance num_elements = group_size * h * w var = var * (num_elements / (num_elements - 1)) std = (var + module.eps).sqrt() output = (x - full_x_mean) / std output = output.view([n, c, h, w]) # scale and shift if module.affine: output = output * module.weight.view([1, -1, 1, 1]) output = output + module.bias.view([1, -1, 1, 1]) self.counter += 1 return output ",
  "wordCount" : "3399",
  "inLanguage": "en",
  "datePublished": "2024-10-23T14:28:37+08:00",
  "dateModified": "2025-06-07T23:40:58+08:00",
  "author":[{
    "@type": "Person",
    "name": "WITHER"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/blogs/distrifusion/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "WITHER",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="WITHER (Alt + H)">WITHER</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="http://localhost:1313/zh/" title="ç®€ä½“ä¸­æ–‡"
                            aria-label="ç®€ä½“ä¸­æ–‡">ç®€ä½“ä¸­æ–‡</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="ğŸ  Home">
                    <span>ğŸ  Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about_me/" title="ğŸ™‹ğŸ»â€â™‚ï¸ Me">
                    <span>ğŸ™‹ğŸ»â€â™‚ï¸ Me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blogs/" title="ğŸ“š Blogs">
                    <span>ğŸ“š Blogs</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="ğŸ§© Categories">
                    <span>ğŸ§© Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="ğŸ”– Tags">
                    <span>ğŸ”– Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="â± Archive">
                    <span>â± Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="ğŸ” Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ” Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/friends/" title="ğŸ¤ Friends">
                    <span>ğŸ¤ Friends</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;Â»&nbsp;<a href="http://localhost:1313/blogs/">Blogs</a></div>
    <h1 class="post-title entry-hint-parent">
      DistriFusion
    </h1>
    <div class="post-description">
      Paper reading about DistriFusion.
    </div>
    <div class="post-meta"><span title='2024-10-23 14:28:37 +0800 CST'>Oct-23-2024</span>&nbsp;Â·&nbsp;7 min&nbsp;Â·&nbsp;3399 words&nbsp;Â·&nbsp;WITHER

</div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                    <li>
                        <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                    <li>
                        <a href="#method" aria-label="Method">Method</a><ul>
                            
                    <li>
                        <a href="#displaced-patch-parallelism" aria-label="Displaced Patch Parallelism.">Displaced Patch Parallelism.</a></li>
                    <li>
                        <a href="#sparse-operations" aria-label="Sparse Operations">Sparse Operations</a></li>
                    <li>
                        <a href="#corrected-asynchronous-groupnorm" aria-label="Corrected Asynchronous GroupNorm">Corrected Asynchronous GroupNorm</a></li></ul>
                    </li>
                    <li>
                        <a href="#code-implementation" aria-label="Code Implementation">Code Implementation</a><ul>
                            
                    <li>
                        <a href="#patchparallelismcommmanager" aria-label="PatchParallelismCommManager">PatchParallelismCommManager</a></li>
                    <li>
                        <a href="#districonv2dpp" aria-label="DistriConv2dPP">DistriConv2dPP</a></li>
                    <li>
                        <a href="#distriselfattentionpp" aria-label="DistriSelfAttentionPP">DistriSelfAttentionPP</a></li>
                    <li>
                        <a href="#distrigroupnorm" aria-label="DistriGroupNorm">DistriGroupNorm</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    
    document.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();
    
        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        if (elements.length > 0) {
            
            activeElement = elements[0];
            const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
            document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
        }
    
        
        const topLink = document.getElementById('top-link');
        if (topLink) {
            topLink.addEventListener('click', (event) => {
                
                event.preventDefault();
    
                
                window.scrollTo({ top: 0, behavior: 'smooth' });
            });
        }
    }, false);
    
    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);
    
    window.addEventListener('scroll', () => {
        
        const scrollPosition = window.pageYOffset || document.documentElement.scrollTop;
    
        
        if (scrollPosition === 0) {
            return;
        }
    
        
        if (elements && elements.length > 0) {
            
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - scrollPosition) > 0 && 
                    (getOffsetTop(element) - scrollPosition) < window.innerHeight / 2) {
                    return element;
                }
            }) || activeElement;
    
            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                const tocLink = document.querySelector(`.inner ul li a[href="#${id}"]`);
                if (element === activeElement){
                    tocLink.classList.add('active');
    
                    
                    const tocContainer = document.querySelector('.toc .inner');
                    const linkOffsetTop = tocLink.offsetTop;
                    const containerHeight = tocContainer.clientHeight;
                    const linkHeight = tocLink.clientHeight;
    
                    
                    const scrollPosition = linkOffsetTop - (containerHeight / 2) + (linkHeight / 2);
                    tocContainer.scrollTo({ top: scrollPosition, behavior: 'smooth' });
                } else {
                    tocLink.classList.remove('active');
                }
            });
        }
    }, false);
    
    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);
    
    function checkTocPosition() {
        const width = document.body.scrollWidth;
    
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }
    
    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
    
</script>

  <div class="post-content"><h1 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h1>
<p>DistriFusion å°†æ¨¡å‹è¾“å…¥åˆ†å‰²æˆå¤šä¸ª patch ååˆ†é…ç»™ GPUã€‚ä½†æ˜¯ç›´æ¥å®ç°è¿™æ ·çš„ç®—æ³•ä¼šç ´å patch ä¹‹é—´çš„äº¤äº’å¹¶å¤±å»ä¿çœŸåº¦ï¼Œè€ŒåŒæ­¥ GPU ä¹‹é—´çš„æ¿€æ´»å°†äº§ç”Ÿå·¨å¤§çš„é€šä¿¡å¼€é”€ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å›°å¢ƒï¼Œæ ¹æ®è§‚å¯Ÿåˆ°çš„ç›¸é‚»æ‰©æ•£æ­¥è¾“å…¥ä¹‹é—´çš„é«˜åº¦ç›¸ä¼¼æ€§æå‡ºäº† <strong>displaced patch parallelism</strong>ï¼Œè¯¥æ–¹æ³•é€šè¿‡é‡ç”¨å‰ä¸€ä¸ªæ—¶é—´æ­¥éª¤ä¸­é¢„å…ˆè®¡ç®—çš„ feature map æ¥åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§ï¼Œä¸ºå½“å‰æ­¥æä¾› context. è¯¥æ–¹æ³•æ”¯æŒå¼‚æ­¥é€šä¿¡ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—å®ç°æµæ°´çº¿åŒ–ã€‚</p>
<h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBdce9158a9908f3ebe7782f7bf5b29f61?method=download&amp;shareKey=a571f8710a6ac4e8b859402edd5c069b" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBdce9158a9908f3ebe7782f7bf5b29f61?method=download&amp;shareKey=a571f8710a6ac4e8b859402edd5c069b" alt="Original, Navie Patch &amp; DistriFusion">
    </a><figcaption>Original, Navie Patch &amp; DistriFusion</figcaption></figure></p>
<p>åŠ é€Ÿæ‰©æ•£æ¨¡å‹æ¨ç†ä¸»è¦é›†ä¸­åœ¨ä¸¤ç§æ–¹æ³•ä¸Šï¼šå‡å°‘é‡‡æ ·æ­¥éª¤å’Œä¼˜åŒ–ç½‘ç»œæ¨ç†ã€‚éšç€è®¡ç®—èµ„æºçš„å¿«é€Ÿå¢é•¿ï¼Œåˆ©ç”¨å¤šä¸ª GPU æ¥åŠ é€Ÿæ¨ç†æ˜¯å¾ˆæœ‰å¸å¼•åŠ›çš„ã€‚ä¾‹å¦‚åœ¨ NLP ä¸­ï¼Œ LLM å·²ç»æˆåŠŸåœ°åˆ©ç”¨äº† GPU ä¹‹é—´çš„å¼ é‡å¹¶è¡Œæ€§ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†å»¶è¿Ÿã€‚ç„¶è€Œï¼Œå¯¹äºæ‰©æ•£æ¨¡å‹ï¼Œç”±äºæ¿€æ´»å°ºå¯¸å¤§ï¼Œå¼ é‡å¹¶è¡Œè¿™æ ·çš„æŠ€æœ¯ä¸å¤ªé€‚åˆæ‰©æ•£æ¨¡å‹ã€‚å¤šä¸ª GPU é€šå¸¸åªç”¨äº batch æ¨ç†ï¼Œå½“ç”Ÿæˆå•ä¸ªå›¾åƒæ—¶ï¼Œé€šå¸¸åªæ¶‰åŠä¸€ä¸ªGPU.</p>
<blockquote>
<p>Techniques like tensor parallelism are less suitable for diffusion models due to the large activation size, as communication costs outweigh savings from distributed computation.</p></blockquote>
<p>è‡ªç„¶è€Œç„¶çš„ä¸€ç§æ–¹æ³•æ˜¯å°†å›¾åƒåˆ†æˆå‡ ä¸ª patch ååˆ†é…ç»™ä¸åŒçš„è®¾å¤‡è¿›è¡Œç”Ÿæˆã€‚ç”±äºå„ä¸ª patch ä¹‹é—´ç¼ºä¹ç›¸äº’ä½œç”¨ï¼Œå®ƒåœ¨æ¯ä¸ª patch çš„è¾¹ç•Œå¤„éƒ½æœ‰ä¸€ä¸ªæ¸…æ™°å¯è§çš„åˆ†ç•Œçº¿ã€‚</p>
<p>DistriFusion ä¹Ÿæ˜¯åŸºäº patch parallelism. å…³é”®åœ¨äºæ‰©æ•£æ¨¡å‹ä¸­ç›¸é‚»å»å™ªæ­¥éª¤çš„è¾“å…¥æ˜¯ç›¸ä¼¼çš„ï¼Œå› æ­¤ï¼Œåªåœ¨ç¬¬ä¸€æ­¥é‡‡ç”¨åŒæ­¥é€šä¿¡ã€‚åç»­æ­¥éª¤é‡ç”¨å‰ä¸€æ­¥ä¸­é¢„å…ˆè®¡ç®—çš„æ¿€æ´»ï¼Œä¸ºå½“å‰æ­¥éª¤æä¾›å…¨å±€ä¸Šä¸‹æ–‡å’Œ patch äº¤äº’ã€‚é€šè¿‡å¼‚æ­¥é€šä¿¡æœ‰æ•ˆåœ°éšè—äº†è®¡ç®—ä¸­çš„é€šä¿¡å¼€é”€ã€‚å¹¶ä¸”è¿˜ç¨€ç–åœ°åœ¨æŒ‡å®šçš„åŒºåŸŸä¸Šè¿›è¡Œå·ç§¯å’Œæ³¨æ„åŠ›è®¡ç®—ï¼Œä»è€ŒæŒ‰æ¯”ä¾‹å‡å°‘æ¯ä¸ªè®¾å¤‡çš„è®¡ç®—é‡ã€‚</p>
<h1 id="method">Method<a hidden class="anchor" aria-hidden="true" href="#method">#</a></h1>
<h2 id="displaced-patch-parallelism">Displaced Patch Parallelism.<a hidden class="anchor" aria-hidden="true" href="#displaced-patch-parallelism">#</a></h2>
<p>åœ¨é¢„æµ‹ $\epsilon_{\theta}(\mathbf{x}_{t})$ æ—¶ (å¿½ç•¥æ¡ä»¶ c å’Œæ—¶é—´æ­¥ t çš„è¾“å…¥) ï¼Œé¦–å…ˆå°† $\mathbf{x}_{t}$ åˆ†å‰²æˆå¤šä¸ª patch $\mathbf{x}_t^{(1)},\mathbf{x}_t^{(2)},\ldots,\mathbf{x}_t^{(N)}$ ï¼Œå¯¹äºæ¯ä¸€å±‚ l å’Œè®¾å¤‡ iï¼Œåœ¨è·å¾—è¾“å…¥æ¿€æ´» patch $\mathbf{A}_{t}^{l,(i)}$ åå¼‚æ­¥å¤„ç†ä¸¤ä¸ªæ“ä½œï¼šé¦–å…ˆï¼Œå¯¹äºè®¾å¤‡iï¼Œ æ¿€æ´» $\mathbf{A}_{t}^{l,(i)}$ é¦–å…ˆ scatter åˆ°ä¸Šä¸€æ­¥æ—§çš„æ¿€æ´» $\mathbf{A}_{t+1}^{l}$ ä¸­ã€‚ç„¶åå°†æ­¤åˆ†æ•£æ“ä½œçš„è¾“å‡ºé€å…¥ç¨€ç–ç®—å­ Fl (çº¿æ€§ã€å·ç§¯æˆ–æ³¨æ„å±‚)ï¼Œè¯¥ç®—å­ä¸“é—¨å¯¹æ–°åŒºåŸŸæ‰§è¡Œè®¡ç®—å¹¶äº§ç”Ÿç›¸åº”çš„è¾“å‡ºã€‚åŒæ—¶ï¼Œå¯¹ $\mathbf{A}_{t}^{l,(i)}$ æ‰§è¡Œ AllGather æ“ä½œï¼Œä¸ºä¸‹ä¸€æ­¥çš„å…¨å°ºå¯¸æ¿€æ´» $\mathbf{A}_{t}^{l}$ åšå‡†å¤‡ã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBfee0ed5c1a6065b8adb21371ea3cbc31?method=download&amp;shareKey=66860ad5956c2a8afb949b3fd821015d" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBfee0ed5c1a6065b8adb21371ea3cbc31?method=download&amp;shareKey=66860ad5956c2a8afb949b3fd821015d" alt="Overview of DistriFusion">
    </a><figcaption>Overview of DistriFusion</figcaption></figure></p>
<p>æˆ‘ä»¬å¯¹é™¤ç¬¬ä¸€å±‚ (é‡‡ç”¨åŒæ­¥é€šä¿¡è·å¾—å…¶ä»–è®¾å¤‡ä¸Šçš„è¾“å…¥) å¤–çš„æ¯ä¸€å±‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ã€‚ç„¶åå°†æœ€ç»ˆè¾“å‡º Gather åœ¨ä¸€èµ·ä»¥è¿‘ä¼¼ $\epsilon_{\theta}(\mathbf{x}_{t})$ï¼Œç”¨äºè®¡ç®— $\mathbf{x}_{t-1}$</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB41fa5a52bf206399a49358ada4f5c07b?method=download&amp;shareKey=686b36b99eb8ced2b48594a380d17d62" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB41fa5a52bf206399a49358ada4f5c07b?method=download&amp;shareKey=686b36b99eb8ced2b48594a380d17d62" alt="Timeline Visualization on Each Device">
    </a><figcaption>Timeline Visualization on Each Device</figcaption></figure></p>
<h2 id="sparse-operations">Sparse Operations<a hidden class="anchor" aria-hidden="true" href="#sparse-operations">#</a></h2>
<p>å¯¹äºæ¯ä¸€å±‚ lï¼Œå¦‚æœåŸå§‹ç®—å­ Fl æ˜¯ä¸€ä¸ªå·ç§¯å±‚ã€çº¿æ€§å±‚æˆ–äº¤å‰æ³¨æ„å±‚ï¼Œè°ƒæ•´ä½¿å…¶ä¸“é—¨ä½œç”¨äºæ–°æ¿€æ´»çš„åŒºåŸŸã€‚è¿™å¯ä»¥é€šè¿‡ä» scatter è¾“å‡ºä¸­æå–æœ€æ–°éƒ¨åˆ†å¹¶å°†å…¶è¾“å…¥åˆ° Fl ä¸­æ¥å®ç°ã€‚å¯¹äº self-attentionï¼Œå°†å…¶è½¬æ¢ä¸º cross-attentionï¼Œä»…åœ¨è®¾å¤‡ä¸Šä¿ç•™æ¥è‡ªæ–°æ¿€æ´»çš„ Qï¼Œè€Œ KV ä»ç„¶åŒ…å«æ•´ä¸ªç‰¹å¾å›¾ã€‚</p>
<h2 id="corrected-asynchronous-groupnorm">Corrected Asynchronous GroupNorm<a hidden class="anchor" aria-hidden="true" href="#corrected-asynchronous-groupnorm">#</a></h2>
<p>ä»…å¯¹æ–° patch è¿›è¡Œå½’ä¸€åŒ–æˆ–é‡ç”¨æ—§ç‰¹å¾éƒ½ä¼šé™ä½å›¾åƒè´¨é‡ã€‚åŒæ­¥ AllGather æ‰€æœ‰å‡å€¼å’Œæ–¹å·®å°†äº§ç”Ÿç›¸å½“å¤§çš„å¼€é”€ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å›°å¢ƒï¼ŒDistriFusion åœ¨é™ˆæ—§çš„ç»Ÿè®¡æ•°æ®ä¸­å¼•å…¥äº†ä¸€ä¸ªæ ¡æ­£é¡¹ã€‚è®¡ç®—å…¬å¼å¦‚ä¸‹</p>
$$
\mathbb{E}[\mathbf{A}_t]\approx\underbrace{\mathbb{E}[\mathbf{A}_{t+1}]}_{\text{stale global mean}}+\underbrace{\mathbb{E}[\mathbf{A}_t^{(i)}]-\mathbb{E}[\mathbf{A}_{t+1}^{(i)}]}_{\text{correction}}
$$<p>åŒæ ·å¯¹äºŒé˜¶çŸ© $\mathbb{E}[\mathbf{A}^2_t]$ ä¹Ÿé‡‡ç”¨è¿™ç§è®¡ç®—æ–¹å¼ï¼Œç„¶åé€šè¿‡ $\mathbb{E}[\mathbf{A}^2_t] - \mathbb{E}[\mathbf{A}_t]^2$ æ¥è®¡ç®—æ–¹å·®ã€‚å¯¹äºæ–¹å·®ç»“æœä¸ºè´Ÿçš„éƒ¨åˆ†ï¼Œå°†ä½¿ç”¨æ–°é²œ patch çš„å±€éƒ¨æ–¹å·®ä»£æ›¿ã€‚</p>
<h1 id="code-implementation">Code Implementation<a hidden class="anchor" aria-hidden="true" href="#code-implementation">#</a></h1>
<p>Distrifusion ä¸­ä¸»è¦å°±æ˜¯å°† <a href="https://github.com/huggingface/diffusers/blob/9366c8f84bfe47099ff047272661786ebb54721d/src/diffusers/models/unets/unet_2d_condition.py#L71">UNet2DConditionModel</a> ä¸­çš„ Conv2d, Attention å’Œ GroupNorm æ›¿æ¢æˆå¯¹åº”çš„ patch å®ç°çš„ç½‘ç»œç»“æ„ <a href="https://github.com/mit-han-lab/distrifuser/blob/cfb9ea624ef95020aafcda929a69ba4100f99e9d/distrifuser/models/distri_sdxl_unet_pp.py#L15">DistriUNetPP</a>. è¿™é‡Œç»§æ‰¿çš„ BaseModel ç±»ä¸ºé›†æˆäº† PatchParallelismCommManager ç±» (ä»‹ç»è§åæ–‡) çš„ç½‘ç»œã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB6bd750d9e4b5d582be9d1f41cc267bc5?method=download&amp;shareKey=39d825554b65a9c57f59a1dd9a23fb28" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB6bd750d9e4b5d582be9d1f41cc267bc5?method=download&amp;shareKey=39d825554b65a9c57f59a1dd9a23fb28" alt="UNet2DConditionModel">
    </a><figcaption>UNet2DConditionModel</figcaption></figure></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DistriUNetPP</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>  <span class="c1"># for Patch Parallelism</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">UNet2DConditionModel</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">:</span> <span class="n">DistriConfig</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">UNet2DConditionModel</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">n_device_per_batch</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">BaseModule</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                <span class="s1">&#39;&#39;&#39; 
</span></span></span><span class="line"><span class="cl"><span class="s1">                Substitute Conv2d, Attention, GroupNorm with DistriConv2dPP, DistriSelfAttentionPP, DistriCrossAttentionPP, DistriGroupNorm 
</span></span></span><span class="line"><span class="cl"><span class="s1">                &#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">subname</span><span class="p">,</span> <span class="n">submodule</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>  
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">submodule</span><span class="o">.</span><span class="n">kernel_size</span>
</span></span><span class="line"><span class="cl">                        <span class="k">if</span> <span class="n">kernel_size</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">kernel_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                            <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                        <span class="n">wrapped_submodule</span> <span class="o">=</span> <span class="n">DistriConv2dPP</span><span class="p">(</span>  
</span></span><span class="line"><span class="cl">                            <span class="n">submodule</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">,</span> <span class="n">is_first_layer</span><span class="o">=</span><span class="n">subname</span> <span class="o">==</span> <span class="s2">&#34;conv_in&#34;</span>
</span></span><span class="line"><span class="cl">                        <span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">subname</span><span class="p">,</span> <span class="n">wrapped_submodule</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">Attention</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="k">if</span> <span class="n">subname</span> <span class="o">==</span> <span class="s2">&#34;attn1&#34;</span><span class="p">:</span>  <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">                            <span class="n">wrapped_submodule</span> <span class="o">=</span> <span class="n">DistriSelfAttentionPP</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="k">else</span><span class="p">:</span>  <span class="c1"># cross attention</span>
</span></span><span class="line"><span class="cl">                            <span class="k">assert</span> <span class="n">subname</span> <span class="o">==</span> <span class="s2">&#34;attn2&#34;</span>
</span></span><span class="line"><span class="cl">                            <span class="n">wrapped_submodule</span> <span class="o">=</span> <span class="n">DistriCrossAttentionPP</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">subname</span><span class="p">,</span> <span class="n">wrapped_submodule</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="n">wrapped_submodule</span> <span class="o">=</span> <span class="n">DistriGroupNorm</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">subname</span><span class="p">,</span> <span class="n">wrapped_submodule</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">DistriUNetPP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="patchparallelismcommmanager">PatchParallelismCommManager<a hidden class="anchor" aria-hidden="true" href="#patchparallelismcommmanager">#</a></h2>
<p><a href="https://github.com/mit-han-lab/distrifuser/blob/cfb9ea624ef95020aafcda929a69ba4100f99e9d/distrifuser/utils.py#L112">PatchParallelismCommManager</a> ç±»ä¸»è¦å¤„ç†å¼‚æ­¥é€šä¿¡çš„éƒ¨åˆ†ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">PatchParallelismCommManager</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">:</span> <span class="n">DistriConfig</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">distri_config</span> <span class="o">=</span> <span class="n">distri_config</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">torch_dtype</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">numel</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># å·²ç»æ³¨å†Œçš„å¼ é‡çš„ç´¯è®¡æ€»å…ƒç´ æ•°é‡</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">numel_dict</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># è®°å½•æ¯ä¸ª layer_type æ‰€æ³¨å†Œçš„å¼ é‡çš„ç´¯è®¡å…ƒç´ æ•°é‡</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šå­˜å‚¨æ‰€æœ‰æ³¨å†Œå¼ é‡çš„æ•°æ®ï¼Œé€šä¿¡æ‰€ç”¨çš„ buffer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">starts</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># è®°å½•æ¯ä¸ªæ³¨å†Œå¼ é‡çš„èµ·å§‹ä½ç½® (åœ¨ buffer_list ä¸­çš„èµ·å§‹ç´¢å¼•)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ends</span> <span class="o">=</span> <span class="p">[]</span>    <span class="c1">#                 ç»“æŸ                       ç»“æŸ</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">shapes</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># è®°å½•æ¯ä¸ªæ³¨å†Œå¼ é‡çš„ shape</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">idx_queue</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># éœ€è¦è¿›è¡Œé€šä¿¡çš„å¼ é‡ç´¢å¼•çš„é˜Ÿåˆ—</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">handles</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># å­˜å‚¨æ¯ä¸ªè®¾å¤‡é€šä¿¡æ“ä½œçš„å¥æŸ„çš„ list, ç”¨äºæ£€æŸ¥é€šä¿¡æ˜¯å¦å®Œæˆ</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>æˆå‘˜å‡½æ•°åŠŸèƒ½ä»‹ç»å¦‚ä¸‹</p>
<ol>
<li>
<p><code>register_tensor(self, shape: tuple[int, ...] or list[int], torch_dtype: torch.dtype, layer_type: str = None) -&gt; int</code>: ç”¨äºæ³¨å†Œå¼ é‡çš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹ï¼ŒåŒæ—¶è®¡ç®—å¹¶è®°å½•å¼ é‡åœ¨ç¼“å†²åŒºä¸­çš„èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®ã€‚</p>
<ul>
<li>å¦‚æœå°šæœªæŒ‡å®š <code>torch_dtype</code>ï¼Œåˆ™å°†ä¼ å…¥çš„ <code>torch_dtype</code> è®¾ä¸ºç±»æˆå‘˜çš„é»˜è®¤æ•°æ®ç±»å‹ã€‚</li>
<li>è®¡ç®—ä¼ å…¥å¼ é‡å½¢çŠ¶çš„æ€»å…ƒç´ æ•° <code>numel</code>ï¼Œå¹¶æ›´æ–° <code>starts</code>ã€<code>ends</code> å’Œ <code>shapes</code> åˆ—è¡¨ã€‚</li>
<li>å¦‚æœæŒ‡å®šäº† <code>layer_type</code>ï¼Œæ›´æ–° <code>numel_dict</code> ä¸­è¯¥å±‚ç±»å‹å¯¹åº”çš„å…ƒç´ æ•°ç›®ã€‚</li>
</ul>
</li>
<li>
<p><code>create_buffer(self)</code> : æ¯ä¸ªè®¾å¤‡ä¸Šä¸ºæ‰€æœ‰æ³¨å†Œçš„å¼ é‡åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç¼“å†²åŒºã€‚</p>
<ul>
<li>ä¸ºæ¯ä¸ªè®¾å¤‡åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º <code>(numel,)</code> çš„å¼ é‡ï¼Œå¹¶å°†å…¶æ”¾å…¥ <code>buffer_list</code> ä¸­ã€‚</li>
<li>è¾“å‡ºåœ¨å„è®¾å¤‡ä¸Šåˆ›å»ºçš„ç¼“å†²åŒºæ€»å‚æ•°é‡ã€‚</li>
</ul>
</li>
<li>
<p><code>get_buffer_list(self, idx: int) -&gt; list[torch.Tensor]</code>: è¿”å›æ¯ä¸ªè®¾å¤‡ä¸Šå¯¹åº”äºæŒ‡å®šç´¢å¼• <code>idx</code> çš„ç¼“å†²åŒºå¼ é‡ã€‚</p>
<ul>
<li>æ ¹æ® <code>starts</code> å’Œ <code>ends</code> ä¿¡æ¯ï¼Œä» <code>buffer_list</code> ä¸­æå–æŒ‡å®šç´¢å¼• <code>idx</code> çš„å¼ é‡ç‰‡æ®µå¹¶è°ƒæ•´å…¶å½¢çŠ¶ã€‚</li>
</ul>
</li>
<li>
<p><code>communicate(self)</code>: è°ƒç”¨ <code>dist.all_gather</code> å°†ç¼“å†²åŒºä¸­çš„å¼ é‡åœ¨ä¸åŒè®¾å¤‡é—´è¿›è¡Œå¹¿æ’­ã€‚</p>
<ul>
<li>ç¡®å®šå½“å‰éœ€è¦é€šä¿¡çš„å¼ é‡èŒƒå›´ (æ ¹æ® <code>idx_queue</code> ä¸­çš„ç´¢å¼•).</li>
<li>è°ƒç”¨ <code>dist.all_gather</code> åœ¨è®¾å¤‡ç»„å†…è¿›è¡Œå¼‚æ­¥å¹¿æ’­é€šä¿¡ï¼Œå¹¶å°†å¥æŸ„å­˜å‚¨åœ¨ <code>handles</code> ä¸­ã€‚</li>
</ul>
</li>
<li>
<p><code>enqueue(self, idx: int, tensor: torch.Tensor)</code>: å°†æŒ‡å®šç´¢å¼• <code>idx</code> å¤„çš„å¼ é‡æ•°æ®å¤åˆ¶åˆ° <code>buffer_list</code> ä¸­ï¼Œå¹¶å°†ç´¢å¼•æ·»åŠ åˆ°é€šä¿¡é˜Ÿåˆ— <code>idx_queue</code>ã€‚</p>
<ul>
<li>å¦‚æœé€šä¿¡é˜Ÿåˆ—ä¸ä¸ºç©ºä¸”ç´¢å¼•ä¸º 0ï¼Œåˆ™å…ˆæ‰§è¡Œä¸€æ¬¡é€šä¿¡æ“ä½œã€‚</li>
<li>å°†å¼ é‡æ•°æ®å¤åˆ¶åˆ° <code>buffer_list</code> ä¸­çš„å¯¹åº”ä½ç½®ã€‚</li>
<li>å½“é€šä¿¡é˜Ÿåˆ—é•¿åº¦è¾¾åˆ° <code>distri_config</code> ä¸­è®¾å®šçš„é€šä¿¡æ£€æŸ¥ç‚¹å€¼æ—¶ï¼Œè¿›è¡Œé€šä¿¡ã€‚</li>
</ul>
</li>
<li>
<p><code>clear(self)</code>: æ‰§è¡Œä¸€æ¬¡æ‰€æœ‰å¾…é€šä¿¡å¼ é‡çš„é€šä¿¡ï¼Œå¹¶ç­‰å¾…æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆã€‚</p>
<ul>
<li>å¦‚æœé€šä¿¡é˜Ÿåˆ—ä¸ä¸ºç©ºï¼Œåˆ™è¿›è¡Œé€šä¿¡æ“ä½œã€‚</li>
<li>éå†æ‰€æœ‰å¥æŸ„ï¼Œç­‰å¾…æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆåï¼Œå°†å¥æŸ„è®¾ä¸º <code>None</code>.</li>
</ul>
</li>
</ol>
<h2 id="districonv2dpp">DistriConv2dPP<a hidden class="anchor" aria-hidden="true" href="#districonv2dpp">#</a></h2>
<p><a href="https://github.com/mit-han-lab/distrifuser/blob/cfb9ea624ef95020aafcda929a69ba4100f99e9d/distrifuser/models/distri_sdxl_unet_pp.py#L10">DistriConv2dPP</a> è®¡ç®—è‡ªå·±è´Ÿè´£ patch éƒ¨åˆ†çš„å·ç§¯ï¼Œéœ€è¦é€šä¿¡å…¶ä»–è®¾å¤‡éœ€è¦è‡ªå·±è´Ÿè´£ patch çš„ä¸Šä¸‹ padding éƒ¨åˆ†ã€‚</p>
<ul>
<li><code>__init__</code>ï¼šæ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–æˆå‘˜å˜é‡ï¼Œè®¾ç½®æ˜¯å¦ä¸ºç¬¬ä¸€å±‚å·ç§¯ã€‚</li>
<li><code>naive_forward</code>ï¼šæ‰§è¡Œæ ‡å‡†çš„å‰å‘ä¼ æ’­ï¼Œä¸è¿›è¡Œä»»ä½•åˆ‡ç‰‡æ“ä½œã€‚è¿™æ˜¯å•ä¸ªè®¾å¤‡å¤„ç†æ—¶çš„æ™®é€šå·ç§¯æ“ä½œã€‚</li>
<li><code>sliced_forward</code>ï¼šå¤„ç†è¾“å…¥å¼ é‡çš„åˆ‡ç‰‡æ“ä½œã€‚æ ¹æ®å½“å‰è®¾å¤‡ç´¢å¼• (<code>split_idx</code>) è®¡ç®—è¾“å…¥å¼ é‡åœ¨é«˜åº¦æ–¹å‘çš„èµ·å§‹å’Œç»“æŸä½ç½®ï¼Œå¹¶åœ¨å¿…è¦æ—¶ä¸ºåˆ‡ç‰‡åçš„å¼ é‡æ·»åŠ  padding åè¿›è¡Œå·ç§¯æ“ä½œã€‚</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DistriConv2dPP</span><span class="p">(</span><span class="n">BaseModule</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">:</span> <span class="n">DistriConfig</span><span class="p">,</span> <span class="n">is_first_layer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">DistriConv2dPP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">is_first_layer</span> <span class="o">=</span> <span class="n">is_first_layer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">naive_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1">#  x: [B, C, H, W]</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">sliced_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;&#39;&#39;...&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">distri_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distri_config</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ç­‰å¾…ä¸Šä¸€æ­¥é€šä¿¡å®Œæˆ</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">boundary_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># buffer_list å­˜å‚¨çš„æ˜¯æ¯ä¸ª devive è¿›è¡Œå·ç§¯æ‰€éœ€è¦çš„å…¶ä»– devive çš„æ•°æ®</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">buffer_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">register_tensor</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">boundary_size</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">                    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">layer_type</span><span class="o">=</span><span class="s2">&#34;conv2d&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">get_buffer_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    
</span></span><span class="line"><span class="cl">            <span class="k">def</span> <span class="nf">create_padded_x</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                <span class="s1">&#39;&#39;&#39;æ‹¼æ¥æ¥æ”¶åˆ°çš„æ•°æ®&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># rank 0</span>
</span></span><span class="line"><span class="cl">                    <span class="n">concat_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span><span class="p">[</span><span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padded_x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">concat_x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">boundary_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;constant&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">elif</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()</span> <span class="o">==</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">n_device_per_batch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># rank n-1</span>
</span></span><span class="line"><span class="cl">                    <span class="n">concat_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span><span class="p">[</span><span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padded_x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">concat_x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">boundary_size</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;constant&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">else</span><span class="p">:</span>  <span class="c1"># other ranks</span>
</span></span><span class="line"><span class="cl">                    <span class="n">padded_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                        <span class="p">[</span>
</span></span><span class="line"><span class="cl">                            <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span><span class="p">[</span><span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                            <span class="n">x</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                            <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span><span class="p">[</span><span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                        <span class="p">],</span>
</span></span><span class="line"><span class="cl">                        <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">return</span> <span class="n">padded_x</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">            <span class="c1"># æå–å½“å‰è¾“å…¥å¼ é‡éœ€è¦å‘é€ç»™å…¶ä»–è®¾å¤‡çš„éƒ¨åˆ†</span>
</span></span><span class="line"><span class="cl">            <span class="n">boundary</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">boundary_size</span><span class="p">,</span> <span class="p">:],</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="n">boundary_size</span><span class="p">:,</span> <span class="p">:]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># ç›´æ¥ç”¨ä¸Šä¸€æ­¥çš„ buffer æ‹¼æ¥</span>
</span></span><span class="line"><span class="cl">            <span class="n">padded_x</span> <span class="o">=</span> <span class="n">create_padded_x</span><span class="p">()</span>  
</span></span><span class="line"><span class="cl">            <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">padded_x</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">mode</span> <span class="o">!=</span> <span class="s2">&#34;no_sync&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="n">boundary</span><span class="p">)</span>  <span class="c1"># æ’å…¥è‡ªå·±è¦å‘é€çš„æ•°æ®</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="distriselfattentionpp">DistriSelfAttentionPP<a hidden class="anchor" aria-hidden="true" href="#distriselfattentionpp">#</a></h2>
<p><a href="https://github.com/mit-han-lab/distrifuser/blob/cfb9ea624ef95020aafcda929a69ba4100f99e9d/distrifuser/modules/pp/attn.py#L107">DistriSelfAttentionPP</a> åªè´Ÿè´£è®¡ç®—è‡ªå·± patch çš„è¾“å‡ºï¼Œéœ€è¦å®Œæ•´çš„ KVï¼Œå°† self attention è¿ç®—å˜æˆ cross-attention è®¡ç®—ã€‚éœ€è¦é€šä¿¡è‡ªå·±çš„ KV.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DistriSelfAttentionPP</span><span class="p">(</span><span class="n">DistriAttentionPP</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Attention</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">:</span> <span class="n">DistriConfig</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">DistriSelfAttentionPP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span>  <span class="c1"># è·å– Attention æ¨¡å—</span>
</span></span><span class="line"><span class="cl">        <span class="n">distri_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distri_config</span>
</span></span><span class="line"><span class="cl">        <span class="n">residual</span> <span class="o">=</span> <span class="n">hidden_states</span>  <span class="c1"># æ®‹å·®è¿æ¥</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">args</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">USE_PEFT_BACKEND</span> <span class="k">else</span> <span class="p">(</span><span class="n">scale</span><span class="p">,)</span>
</span></span><span class="line"><span class="cl">        <span class="n">query</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">to_q</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># Q Projection</span>
</span></span><span class="line"><span class="cl">        <span class="n">encoder_hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span>
</span></span><span class="line"><span class="cl">        <span class="n">kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_kv</span><span class="p">(</span><span class="n">encoder_hidden_states</span><span class="p">)</span>  <span class="c1"># KV Projection</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># å¦‚æœç¼“å†²åŒºæœªåˆ›å»º</span>
</span></span><span class="line"><span class="cl">            <span class="n">full_kv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">kv</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">distri_config</span><span class="o">.</span><span class="n">n_device_per_batch</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">new_buffer_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">buffer</span> <span class="k">for</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_buffer_list</span><span class="p">[</span><span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()]</span> <span class="o">=</span> <span class="n">kv</span>
</span></span><span class="line"><span class="cl">        <span class="n">full_kv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">new_buffer_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">mode</span> <span class="o">!=</span> <span class="s2">&#34;no_sync&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="n">kv</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># å°† full_kv åˆ†å‰²ä¸º key å’Œ value</span>
</span></span><span class="line"><span class="cl">        <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">full_kv</span><span class="p">,</span> <span class="n">full_kv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">inner_dim</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">head_dim</span> <span class="o">=</span> <span class="n">inner_dim</span> <span class="o">//</span> <span class="n">attn</span><span class="o">.</span><span class="n">heads</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># multi-head attention</span>
</span></span><span class="line"><span class="cl">        <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">attn</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">attn</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">attn</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">attn</span><span class="o">.</span><span class="n">heads</span> <span class="o">*</span> <span class="n">head_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">to_out</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">hidden_states</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># O Projection</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">to_out</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">hidden_states</span><span class="p">)</span>  <span class="c1"># Dropout</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">attn</span><span class="o">.</span><span class="n">residual_connection</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span> <span class="o">+</span> <span class="n">residual</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span> <span class="o">/</span> <span class="n">attn</span><span class="o">.</span><span class="n">rescale_output_factor</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">hidden_states</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="distrigroupnorm">DistriGroupNorm<a hidden class="anchor" aria-hidden="true" href="#distrigroupnorm">#</a></h2>
<p><a href="https://github.com/mit-han-lab/distrifuser/blob/cfb9ea624ef95020aafcda929a69ba4100f99e9d/distrifuser/modules/pp/groupnorm.py#L9">DistriGroupNorm</a> æ ¹æ®ä¸Šä¸€æ­¥å…¨ç‰¹å¾å›¾çš„ä»¥åŠå½“å‰æ­¥ patch çš„å‡å€¼å’ŒäºŒé˜¶çŸ©è¿‘ä¼¼å½“å‰æ­¥çš„å…¨ç‰¹å¾å›¾å‡å€¼å’Œæ–¹å·®ã€‚éœ€è¦é€šä¿¡ patch å‡å€¼å’ŒäºŒé˜¶çŸ©ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DistriGroupNorm</span><span class="p">(</span><span class="n">BaseModule</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">:</span> <span class="n">DistriConfig</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">DistriGroupNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">distri_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span>
</span></span><span class="line"><span class="cl">        <span class="n">distri_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distri_config</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">handles</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl">        <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_groups</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">num_groups</span>
</span></span><span class="line"><span class="cl">        <span class="n">group_size</span> <span class="o">=</span> <span class="n">c</span> <span class="o">//</span> <span class="n">num_groups</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">buffer_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">register_tensor</span><span class="p">(</span>  <span class="c1"># register for E[x], E[x^2]</span>
</span></span><span class="line"><span class="cl">                    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">layer_type</span><span class="o">=</span><span class="s2">&#34;gn&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">get_buffer_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># è®¡ç®— patch å‡å€¼å’ŒäºŒé˜¶çŸ©</span>
</span></span><span class="line"><span class="cl">        <span class="n">x_mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># [1, num_groups, 1, 1, 1]</span>
</span></span><span class="line"><span class="cl">        <span class="n">x2_mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># [1, num_groups, 1, 1, 1]</span>
</span></span><span class="line"><span class="cl">        <span class="n">slice_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x_mean</span><span class="p">,</span> <span class="n">x2_mean</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">full_mean</span> <span class="o">=</span> <span class="n">slice_mean</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Equation 2 in the paper E[A_t] = E[A_(t+1)] + (E[A^i_t] - E[A^i_(t+1)]), same for E[A^2_t]</span>
</span></span><span class="line"><span class="cl">            <span class="n">correction</span> <span class="o">=</span> <span class="n">slice_mean</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span><span class="p">[</span><span class="n">distri_config</span><span class="o">.</span><span class="n">split_idx</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl">            <span class="n">full_mean</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer_list</span><span class="p">)</span> <span class="o">/</span> <span class="n">distri_config</span><span class="o">.</span><span class="n">n_device_per_batch</span> <span class="o">+</span> <span class="n">correction</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">comm_manager</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="n">slice_mean</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">full_x_mean</span><span class="p">,</span> <span class="n">full_x2_mean</span> <span class="o">=</span> <span class="n">full_mean</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">full_mean</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">var</span> <span class="o">=</span> <span class="n">full_x2_mean</span> <span class="o">-</span> <span class="n">full_x_mean</span><span class="o">**</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># è®¡ç®—æ–¹å·®</span>
</span></span><span class="line"><span class="cl">        <span class="n">slice_x_mean</span><span class="p">,</span> <span class="n">slice_x2_mean</span> <span class="o">=</span> <span class="n">slice_mean</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">slice_mean</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">slice_var</span> <span class="o">=</span> <span class="n">slice_x2_mean</span> <span class="o">-</span> <span class="n">slice_x_mean</span><span class="o">**</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">var</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">slice_var</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>  <span class="c1"># Correct negative variance</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">num_elements</span> <span class="o">=</span> <span class="n">group_size</span> <span class="o">*</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span>
</span></span><span class="line"><span class="cl">        <span class="n">var</span> <span class="o">=</span> <span class="n">var</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_elements</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_elements</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span> <span class="o">=</span> <span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">module</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">full_x_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># scale and shift</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">module</span><span class="o">.</span><span class="n">affine</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">*</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span>
</span></span></code></pre></td></tr></table>
</div>
</div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/diffusion-models/">Diffusion Models</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/blogs/courselearning/mlir/mlir-ch2-writing-our-first-pass/">
    <span class="title">Â« Prev</span>
    <br>
    <span>MLIR-Ch2 Writing Our First Pass</span>
  </a>
  <a class="next" href="http://localhost:1313/blogs/deepspeedulysses/">
    <span class="title">Next Â»</span>
    <br>
    <span>DeepSpeedUlysses</span>
  </a>
</nav>

  </footer><script src="https://giscus.app/client.js"
        data-repo="jamesnulliu/jamesnulliu.github.io"
        data-repo-id="R_kgDOMPCQIw"
        data-category="Announcements"
        data-category-id="DIC_kwDOMPCQI84Cgb2t"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>Â© 2024-2025 WITHER</span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
