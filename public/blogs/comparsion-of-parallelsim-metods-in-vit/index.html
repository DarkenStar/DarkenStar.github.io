<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Comparsion of Parallelsim Metods in ViT | WITHER</title>
<meta name="keywords" content="Parallel">
<meta name="description" content="Paper reading of .">
<meta name="author" content="WITHER">
<link rel="canonical" href="http://localhost:1313/blogs/comparsion-of-parallelsim-metods-in-vit/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.dd3b5b907a50db3238b81d49d094cf1c04a091227797dc9cfde4e2fa3f35df49.css" integrity="sha256-3TtbkHpQ2zI4uB1J0JTPHASgkSJ3l9yc/eTi&#43;j8130k=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/blogs/comparsion-of-parallelsim-metods-in-vit/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]  
    }
  };
</script>




<script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.1.6/mermaid.min.js"></script>
<script>
    mermaid.initialize({
        startOnLoad: true,
        theme: localStorage.getItem("pref-theme") === "dark" ? "dark" : "forest" 
    });
</script>

<meta property="og:url" content="http://localhost:1313/blogs/comparsion-of-parallelsim-metods-in-vit/">
  <meta property="og:site_name" content="WITHER">
  <meta property="og:title" content="Comparsion of Parallelsim Metods in ViT">
  <meta property="og:description" content="Paper reading of .">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2023-11-13T16:05:23+08:00">
    <meta property="article:modified_time" content="2025-06-07T23:40:58+08:00">
    <meta property="article:tag" content="Distributed Training">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Comparsion of Parallelsim Metods in ViT">
<meta name="twitter:description" content="Paper reading of .">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "http://localhost:1313/blogs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Comparsion of Parallelsim Metods in ViT",
      "item": "http://localhost:1313/blogs/comparsion-of-parallelsim-metods-in-vit/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Comparsion of Parallelsim Metods in ViT",
  "name": "Comparsion of Parallelsim Metods in ViT",
  "description": "Paper reading of .",
  "keywords": [
    "Parallel"
  ],
  "articleBody": "Basic Transformer Block ç¬¦å·å«ä¹‰è¡¨ç¤ºå¦‚ä¸‹\nSymbol Description Symbol Description a æ³¨æ„åŠ›å¤´æ•° n å¹¶è¡Œåº¦å¤§å° b batchsize s åºåˆ—é•¿åº¦ h éšè—å±‚ç»´åº¦ v è¯æ±‡è¡¨å¤§å° L tranformer layer å±‚æ•°æ•° åŸºæœ¬ transformer block ç»“æ„å¦‚ä¸‹ï¼Œè¾“å…¥æ˜¯å½¢çŠ¶ä¸º (b, s, h) çš„ä¸‰ç»´å¼ é‡ï¼Œå…¶ä¸­ b ä¸º batchsize. æ¯ä¸ªå˜å‹å™¨å±‚ç”±ä¸€ä¸ªå…·æœ‰æ³¨æ„å¤´çš„è‡ªæ³¨æ„å—ç»„æˆï¼Œéšåæ˜¯ä¸€ä¸ªå…·æœ‰ä¸¤å±‚çš„ MLPï¼Œç¬¬ä¸€å±‚å°†éšè—ç»´åº¦å¢åŠ åˆ° 4hï¼Œç„¶ç¬¬äºŒå±‚å°†å…¶å‡å°‘åˆ° h. æ¯ä¸ªå˜å‹å™¨å±‚çš„è¾“å…¥å’Œè¾“å‡ºå…·æœ‰ç›¸åŒçš„å½¢çŠ¶.\nBasic Transformer Architecture Self-attention Block\nModel Parameters QKVO Linear çš„æƒé‡å½¢çŠ¶å‡ä¸º h*h, åç½®å½¢çŠ¶å‡ä¸º h*1ï¼›MLP ä¸¤ä¸ª Linear çš„æƒé‡å½¢åˆ†åˆ«ä¸º h*4h å’Œ 4h*hï¼Œåç½®å½¢çŠ¶åˆ†åˆ«ä¸º 4h*1 å’Œ h*1. å› æ­¤æ¯ä¸ªæ¨¡å‹çš„å‚æ•°é‡ä¸º (12hh+13h)Lï¼Œå ç”¨å¤§å°è¿˜è¦ x2.\nNote\nåœ¨ä¼ ç»Ÿçš„ LLM ä¸­æœ€åè¿˜éœ€è¦ç»è¿‡ logits layerï¼Œå°†éšè—å±‚ç»´åº¦ h è½¬æ¢æˆè¯æ±‡è¡¨å¤§å° vï¼Œå‚æ•°é‡è¿˜è¦åŠ ä¸Š hv.\nFLOPs Calculation å¯¹äºæµ®ç‚¹æ•°è®¡ç®—é‡ (FLOPs)ï¼Œåªè€ƒè™‘å ä¸»è¦éƒ¨åˆ†çš„é€šç”¨çŸ©é˜µä¹˜æ³• (GEMMs). å¯¹äº Attention éƒ¨åˆ†ï¼ŒQKV Linear çš„è®¡ç®—é‡ä¸º 6bshhï¼Œattention matrix (Q@K.T) çš„è®¡ç®—é‡ä¸º 2bssh, attention@V çš„è®¡ç®—é‡ä¸º 2bssh, O Linear çš„è®¡ç®—é‡ä¸º 2bshh. MLP çš„ä¸¤ä¸ªçº¿æ€§å±‚çš„æ¯ä¸€ä¸ªè®¡ç®—é‡éƒ½ä¸º 8shh. ç›¸åŠ åå¾—åˆ°æ­£å‘ä¼ æ’­ä¸­æ€»è®¡ç®—é‡ä¸º (24bshh + 4bssh)L bytes.\nNote\nåœ¨ä¼ ç»Ÿçš„ LLM ä¸­æœ€åè¿˜éœ€è¦ç»è¿‡ logits layerï¼Œå°†éšè—å±‚ç»´åº¦ h è½¬æ¢æˆè¯æ±‡è¡¨å¤§å° vï¼Œå…¶è®¡ç®—é‡ä¸º 2bshv.\nåå‘ä¼ æ’­å› ä¸ºè¦è®¡ç®—è¾“å…¥å’Œæƒé‡çš„æ¢¯åº¦ï¼Œå…¶è®¡ç®—é‡ä¸ºæ­£å‘ä¼ æ’­çš„ä¸¤å€ï¼Œå› æ­¤æ•´ä¸ªæ¨¡å‹çš„è®¡ç®—é‡ä¸º 72BLshh(1+s/(6h)).\nActivation Memory æ¿€æ´»çš„å®šä¹‰ä¸ºåœ¨å‰å‘ä¼ æ’­ä¸­äº§ç”Ÿå¹¶ä¸”éœ€è¦åœ¨åå‘ä¼ æ’­ä¸­è¿›è¡Œæ¢¯åº¦è®¡ç®—çš„å¼ é‡ï¼Œå³ä¸åŒ…æ‹¬æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚å¹¶ä¸”ä¸è€ƒè™‘ç›¸å¯¹éå¸¸å°çš„æ¿€æ´»ã€‚ä¾‹å¦‚ LayerNorm å±‚çš„è¾“å…¥è¿˜éœ€è¦å¼ é‡æ¯ä¸ªé€šé“çš„å‡å€¼å’Œæ–¹å·® (å¤§å°å‡ä¸º bs)ï¼Œç”±äº h å¤§å°é€šå¸¸è¶…è¿‡ 1kï¼Œå› æ­¤åªè€ƒè™‘è¾“å…¥å¼ é‡æ‰€å æ¿€æ´»çš„å¤§å° bshï¼Œå¿½ç•¥æ‰ 2bs. å‡è®¾æ•°æ®æ ¼å¼ä¸º fp16/bf16ï¼Œå³æ¯ä¸ªæ•°æ®å ç”¨ 2 bytes çš„å­˜å‚¨ç©ºé—´ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†çš„æ˜¯ dropout å±‚çš„ makï¼Œæ¯ä¸ªå…ƒç´ å‡ä¸º unsigned intï¼Œåªå ç”¨ 1 byte.\nAttention éƒ¨åˆ†æ¿€æ´»å ç”¨å¦‚ä¸‹ (å…±è®¡ 11bsh + 5bssa)\nQKV Linear: ä¸‰ä¸ªçº¿æ€§å±‚éœ€è¦çš„è¾“å…¥ç›¸åŒï¼Œå ç”¨ 2bsh bytes. Q@K.T: éœ€è¦å­˜å‚¨ Q å’Œ Kï¼Œå ç”¨ 4bsh bytes. Softmax: éœ€è¦å­˜å‚¨å¤§å°ä¸º 2bssa bytes çš„è¾“å…¥ Softmax droppot: éœ€è¦å­˜å‚¨ä¸€ä¸ªå¤§å°ä¸º bssa bytes çš„ mask. attention@V: éœ€è¦å­˜å‚¨ dropout çš„è¾“å‡ºå’Œ Vï¼Œåˆ†åˆ«å ç”¨ 2bssa å’Œ 2bsh bytes. O Linear: éœ€è¦å­˜å‚¨æ³¨æ„åŠ›çš„è¾“å‡ºï¼Œå ç”¨ 2bsh bytes. O dropout éœ€è¦å­˜å‚¨ä¸€ä¸ªå¤§å°ä¸º bsh bytes çš„ mask; MLP (å…±è®¡ 18bsh): ç¬¬ä¸€å±‚å’Œç¬¬äºŒå±‚çš„è¾“å…¥åˆ†åˆ«å ç”¨ 2bsh å’Œ 8bsh bytes. GeLU å±‚éœ€è¦ç¬¬äºŒå±‚çš„è¾“å…¥ç”¨äºåå‘ä¼ æ’­ï¼Œå ç”¨å¤§å°ä¸º 8bsh bytes. dropout éœ€è¦ä¸€ä¸ªå¤§å°ä¸º bsh bytes çš„ mask.\nLayerNorm (å…±è®¡ 4bsh): éœ€è¦å­˜å‚¨è¯¥å±‚çš„è¾“å…¥ï¼Œå ç”¨ 2bsh bytes. ä¸€å…±æœ‰ä¸¤ä¸ª LayerNorm.\nåŠ èµ·æ¥å°±å¯ä»¥å¾—åˆ°æ¯ä¸ª transformer block éœ€è¦æ¿€æ´»å¤§å°ä¸º bsh(34+5sa/h) bytes.\nTensor Parallelsim Megatron å¼ é‡å¹¶è¡Œ çš„æ€æƒ³æ˜¯å°†è¾“å…¥è¿›è¡Œè¿ç»­çš„ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•çš„ç¬¬ä¸€ä¸ªæŒ‰åˆ—åˆ‡åˆ†æˆ t ä»½ï¼Œç¬¬äºŒä¸ªæŒ‰è¡Œåˆ‡åˆ†æˆ t ä»½. åœ¨ Transformer block ä¸­ä½“ç°ä¸ºåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æœ¬èº«çš„å¹¶è¡Œæ€§å°† Attention è®¡ç®—ä¸­çš„ QKV æŒ‰åˆ—è¿›è¡Œåˆ‡åˆ†ï¼ŒO Linear çš„æƒé‡æŒ‰è¡Œè¿›è¡Œåˆ‡åˆ†ï¼›MLP ä¸­ç¬¬ä¸€ä¸ªçº¿æ€§å±‚çš„æƒé‡æŒ‰åˆ—è¿›è¡Œåˆ‡åˆ†ï¼Œç¬¬äºŒä¸ªæƒé‡æŒ‰è¡Œè¿›è¡Œåˆ‡åˆ†ã€‚\nåœ¨è¿™ç§å¹¶è¡Œæ–¹å¼ä¸‹ï¼Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­å‡éœ€è¦è¿›è¡Œ 2 æ¬¡ All-Reduce é€šä¿¡ï¼Œç”±äºæ¯æ¬¡ All-Reduce é€šä¿¡å¯ä»¥çœ‹ä½œ Reduce-Scatter + All-Gather, å› æ­¤æ¯æ¬¡æ¯ä¸ªè®¾å¤‡çš„é€šä¿¡é‡ä¸º 8Î±bsh bytesï¼Œå…¶ä¸­ Î±=(n-1)/n.\nå¯¹äºæ¿€æ´»ï¼Œ2*LayerNorm, QKV Linear çš„è¾“å…¥, O dropout maskï¼ŒMLP ç¬¬ä¸€å±‚çš„è¾“å…¥å’Œ MLP dropout ä¸ä¼šè¢«åˆ‡åˆ†ï¼Œå› æ­¤æ¯ä¸ªè®¾å¤‡æ¯ä¸ª block è¦å ç”¨çš„æ¿€æ´»ä¸º bsh(10+24/n+5as/(hn))\n2D Tensor Parallelsim\n2Då¼ é‡å¹¶è¡Œå°†æ¿€æ´»ç¬¬ä¸€ä¸ªçŸ©é˜µçš„åˆ—åˆ‡åˆ†æˆ m*n ä»½ï¼Œç¬¬äºŒä¸ªæƒé‡ (æƒé‡å½¢çŠ¶ä¸º he) çš„è¡Œè¢«åˆ‡åˆ†æˆ m ä»½ï¼Œåˆ—è¢«åˆ‡åˆ†æˆ n ä»½ã€‚ä»¥ä¸‹å›¾ä¸ºä¾‹ï¼ŒRank0-Rank2ä¸ºé€šä¿¡ç»„ xï¼ŒRank0-Rank1ä¸º é€šä¿¡ç»„ y. ç¬¬ä¸€ä¸ªçŸ©é˜µç»è¿‡ä¸€æ¬¡é€šä¿¡ç»„ y çš„ AllGather åä¸æœ¬è®¾å¤‡ç¬¬äºŒä¸ªçŸ©é˜µè¿›è¡ŒçŸ©é˜µä¹˜ç§¯ï¼Œå¾—åˆ°çš„éƒ¨åˆ†å’Œç»è¿‡ä¸€æ¬¡é€šä¿¡ç»„ x é—´çš„ReduceScatterï¼Œè®¡ç®—å‡ºæ­£ç¡®ç»“æœã€‚ç¬¬ä¸€æ¬¡ AllGather é€šä¿¡æ¯ä¸ªè®¾å¤‡é€šä¿¡çš„å¤§å°ä¸º bsh(n-1)/(mn). ç¬¬äºŒæ¬¡ ReduceScatter é€šä¿¡æ¯ä¸ªè®¾å¤‡é€šä¿¡çš„å¤§å°ä¸º bse(m-1)/n.\nMegatron Sequence Parallelsim Megatron å¼ é‡å¹¶è¡Œä¸­ LayerNorm ä»¥åŠ O Linear å’Œ MLP ä¹‹åçš„ dropouts åœ¨æ¯ä¸ªè®¾å¤‡ä¸­éƒ½æœ‰ä¸€ä¸ªå‰¯æœ¬ã€‚è¿™äº›æ¨¡å—ä¸éœ€è¦å¤§é‡çš„è®¡ç®—ï¼Œä½†éœ€è¦å ç”¨ 10bsh bytes å¤§å°çš„æ¿€æ´»å†…å­˜ã€‚Megatron-SP æ²¿ç€åºåˆ—ç»´åº¦åˆ’åˆ†è¿™äº›æ¨¡å—æ¥å‡å°‘æ¿€æ´»å†…å­˜ï¼Œä½†éœ€è¦é…åˆ TP ä¸€èµ·ä½¿ç”¨ï¼Œæœ¬è´¨ä¸Šæ˜¯å°† TP ä¸­çš„ All-Reduce æ‹†æˆäº†åœ¨ TP å‰è¿›è¡Œ All-Gather å’Œåœ¨ TP åè¿›è¡Œ Reduce-Scatter. ä½†é™¤å»ç¬¬ä¸€ä¸ª LayerNorm å¤–çš„æ¯ä¸€ä¸ªæ¨¡å—çš„æ¿€æ´»éƒ½å¾—åˆ°äº†åˆ‡åˆ†ã€‚Megatron-SP è¿™é‡Œé€‰æ‹©æ¯ä¸ªè®¾å¤‡å­˜å‚¨è‡ªå·±çš„éƒ¨åˆ†å¹¶åœ¨åå‘ä¼ æ’­ä¸­æ’å…¥ä¸€æ¬¡é¢å¤–çš„ All-Gather é€šä¿¡ã€‚å› æ­¤é€šä¿¡é‡ä¸º 10bsh, æ¯ä¸ªè®¾å¤‡æ¯ä¸ª block éœ€è¦å ç”¨çš„æ¿€æ´»ä¸º bsh/n*(34+5as/h)\nTransformer layer with Megatron-SP\nPipeline Parallelsim æµæ°´çº¿å¼ é‡å¹¶è¡Œä»…ä»…å°† L ä¸ª Transformer block å¹³å‡åˆ†åˆ° p ä¸ªè®¾å¤‡ä¸Šï¼Œå¹¶æ²¡æœ‰åˆ’åˆ†æ¿€æ´»æ‰€è¦å ç”¨çš„å†…å­˜ã€‚åœ¨è€ƒè™‘ 1F1B ç­–ç•¥ä¸‹ batchsize è¿›ä¸€æ­¥è¢«åˆ’åˆ†æˆ p ä¸ª micro batch. ç¬¬ä¸€ä¸ª stage å¿…é¡»å­˜å‚¨ p ä¸ª micro batch çš„æ¿€æ´»ã€‚æ¯ä¸ª stage åŒ…å« L/p å±‚ï¼Œæ‰€ä»¥æ— è®ºæµæ°´çº¿å¹¶è¡Œå¤§å° p å¦‚ä½•ï¼Œç¬¬ä¸€ä¸ª stage å¿…é¡»å­˜å‚¨ p Ã— L/p = L å±‚çš„æ¿€æ´»å€¼ã€‚åœ¨ Megatron-LM ä¸­çš„ interleaving schedule éœ€è¦å­˜å‚¨ L(1 + (pâˆ’1)/(pm)) å±‚çš„æ¿€æ´»ï¼Œå…¶ä¸­ m æ˜¯ interleaving çš„æ•°é‡ã€‚\nNote\nåœ¨ä½¿ç”¨ output-tensor-deallocation ä¼˜åŒ– (è¾“å‡ºä¼ åˆ°ä¸‹ä¸€ä¸ª stage åå°±é‡Šæ”¾) çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä¸ºä¸ºæ¯ä¸ªè®¾å¤‡èŠ‚çœ bshr å†…å­˜ï¼Œå…¶ä¸­ r æ˜¯æ¯ä¸ªè®¾å¤‡æ­£åœ¨è¿è¡Œçš„ micro batch çš„æ•°é‡ï¼Œåœ¨ç¬¬ä¸€ä¸ª stage r=p æ—¶è¾¾åˆ°å³°å€¼ã€‚\nDeepseed-Ulysses Sequence Parallel DS-SP ä¹Ÿæ˜¯åˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›çš„å¹¶è¡Œæ€§ï¼Œé¦–å…ˆå°†è¾“å…¥æŒ‰åºåˆ—ç»´åº¦åˆ‡åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œæ¯ä¸ªè®¾å¤‡å æœ‰çš„è¾“å…¥å½¢çŠ¶ä¸º b*(s/n)*h. åœ¨è®¡ç®— Attention ä¹‹å‰å¯¹ QKV è¿›è¡Œ All-to-All é€šä¿¡å˜æˆæŒ‰éšè—å±‚ç»´åº¦åˆ‡åˆ† ((a è¦èƒ½æ•´é™¤ n))ï¼Œé€šä¿¡é‡ä¸º 6Î±bsh/n bytes. è®¡ç®—å®Œ score@v ä¹‹åå†è¿›è¡Œä¸€æ¬¡ All-to-All é€šä¿¡ï¼Œé€šä¿¡é‡ä¸º 2Î±bsh/n bytesï¼Œæ€»è®¡é€šä¿¡é‡ä¸º 8Î±bsh/n bytes. æ¿€æ´»å ç”¨ä¸Š Attention ä¸­ Softmax åŠå…¶ dropout mask å’Œ attention æ²¡æœ‰è¢«åˆ‡åˆ†ï¼Œæ¿€æ´»å ç”¨é‡ä¸º bsh(34/n+5sa/h). å› æ­¤ï¼Œå®ƒä¸é€‚åˆ GQA å’Œ MQA æƒ…å†µ, GQA çš„å¹¶è¡Œåº¦è¢«é™åˆ¶åœ¨äº†ç»„æ•°ï¼ŒMQA åˆ™å®Œå…¨æ²¡æ³•ä½¿ç”¨ã€‚è€Œä¸”ç”±äºå¼ é‡å¹¶è¡Œä¹Ÿéœ€è¦åœ¨ a ç»´åº¦ä¸Šè¿›è¡Œåˆ’åˆ†ï¼ŒSP-Ulysses å’Œ TP æ˜¯å†²çªçš„ã€‚\nRing-Attention Sequence Parallel Ring-SP å®é™…ä¸Šä¸ºç¯çŠ¶çš„ FlashAttentionï¼Œå°†è¾“å…¥æ²¿ç€åºåˆ—ç»´åº¦åˆ‡åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œåœ¨ Attention è®¡ç®—è¿‡ç¨‹ä¸­æ¯ä¸ªè®¾å¤‡å‘ç›¸é‚»è®¾å¤‡é€šä¿¡ KV å¹¶æ›´æ–°è‡ªå·±çš„ Softmax çŸ©é˜µï¼Œé€šä¿¡é‡ä¸º 4bsh bytes. æ¿€æ´»å ç”¨å’Œ DS-SP ä¸€æ ·ä¸º bsh(34/n+5sa/h).\nUnified Sequence Parallel USP å°† SP è¿›ç¨‹ç»„åˆ†å‰²æˆä¸¤ä¸ªæ­£äº¤çš„è¿›ç¨‹ç»„ï¼šSP-Ring è¿›ç¨‹ç»„å’Œ SP-Ulysses è¿›ç¨‹ç»„ã€‚å¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ª 2D mesh ï¼Œæ¯ä¸€åˆ—ä¸Šè¿è¡Œ SP-Ringï¼Œæ¯ä¸€è¡Œä¸Šè¿è¡Œ SP-Ulysses. å…·ä½“æ–¹æ³•ä¸º QKV çš„åˆ‡åˆ† å’Œ All-to-All å’Œ DS-Ulysses ç›¸åŒï¼Œç„¶åé‡‡ç”¨ Ring-Attention çš„æ–¹å¼è¿›è¡Œè®¡ç®—ã€‚å¦‚æœé‡åˆ°ä½¿ç”¨ casual mask çš„æƒ…å†µéœ€è¦åŠ ä¸Š balance load ç­–ç•¥ï¼ŒæŠŠåºåˆ—é•¿åº¦åˆ†ä¸º 2*(ring_degree) å¤§å°ï¼ŒæŒ‰ç…§ 0-\u003e1-\u003eâ€¦-\u003e(ring_degree-1)-\u003e(ring_degree-1)-\u003eâ€¦-\u003e0 çš„é¡ºåºè¿›è¡Œåˆ†é…ã€‚USP æ¶ˆé™¤äº† SP-ulyssesçš„å¤´æ•°é™åˆ¶ã€‚å¹¶ä¸” USPå¯ä»¥é€šè¿‡è°ƒæ•´ SP-Ulysses è¿›ç¨‹ç»„æ•°ç›®æ¥æ›´å¥½çš„é€‚åº”ä¸åŒå¸¦å®½çš„ç½‘ç»œç»“æ„ï¼Œå¯ä»¥è®© All-to-All æ“ä½œåœ¨é«˜å¸¦å®½ä¸­è¿è¡Œï¼Œè€Œå¼‚æ­¥ P2P é€šä¿¡åœ¨ä½å¸¦å®½éƒ¨åˆ†è¿è¡Œã€‚\nComparsion of Different Parallelsim in Training Communication (FWD+BWD)\rSplit Dim\rMemory\rParam\rCost\rAct\rCost\rP/G\rOS\rAct\rDS-SP\rAllReduce\r12O(hÂ²)\r8*All2All\r(8/N)O(bsh)\ra/s\rP+G\r6P\rA/N\rRing-SP\rAllReduce\r12O(hÂ²)\rP2P\r4O(bsh)\rL/L\rP+G\r6P\rA/N\rDP\rAllReduce\r12O(hÂ²)\r0\r0\rb/b\rP+G\r6P\rA/N\rZeRO1\rAllGather + ReduceScatter\r12O(hÂ²)\r0\r0\ra/s\rP+G\r6P/N A/N\rUSP + ZeRO1\rAllGather + ReduceScatter\r12O(hÂ²)\rP2P + 8*All2All\râ‰¤ 4O(bsh)\ra/s\rP+G\r6P/N\rA/N\rUSP + ZeRO2\rAllGather + ReduceScatter\r12O(hÂ²)\rP2P + 8*All2All\râ‰¤ 4O(bsh)\ra/s\rP+(G/N)\r6P/N\rA/N\rUSP + ZeRO3\r2*AllGather + ReduceScatter\r18O(hÂ²)\rP2P + 8*All2All\râ‰¤ 4O(bsh)\ra/s\r(P+G)/N\r6P/N\rA/N\rTP\r0\r0\r4*AllReduce\r8O(bsh)\ra/h\r(P+G)/N\r6P/N\rÎ±A\rMegatron-SP\r0\r0\r6*AllGather + 4*ReduceScatter\r10O(bsh)\ra/h\r(P+G)/N\r6P/N\rA/N\rAnalysis All2All é€šä¿¡ä½¿å¾— DS-SP çš„é€šä¿¡å¼€é”€å¤§äº DP. ä½¿ç”¨ Ring-SP æ—¶ï¼Œå°½ç®¡å¼‚æ­¥çš„ P2P é€šä¿¡æ˜¯å¯ä»¥é‡å çš„ï¼Œç†æƒ³çš„æ€§èƒ½ä¹Ÿæ˜¯åªä¸ DP ç›¸åŒã€‚å› æ­¤åªæœ‰å½“æ‰¹ batchsize ä¸è¶³ä»¥è¿›è¡Œåˆ‡åˆ†æ—¶æ‰è€ƒè™‘ä½¿ç”¨ SP. Megatron-SP é€šä¿¡é‡é«˜äº DS-SP å’Œ Ring-SP. SP-Ring å¯¹äº KV çš„é€šä¿¡å¯ä»¥ä¸è®¡ç®—é‡å ã€‚Megatron-SP çš„é€šä¿¡é‡ä¸ä¼šéšç€å¹¶è¡Œåº¦çš„å¢åŠ è€Œå‡å°‘ï¼Œè€Œ DS-SP å¯ä»¥åšåˆ°ã€‚ DS-SP å’Œ Ring-SP å…·æœ‰è¾ƒä½çš„æ¿€æ´»é€šä¿¡æˆæœ¬ï¼Œä½†éœ€è¦åŒæ­¥æ¢¯åº¦å’Œå‚æ•°ã€‚ä¸è¿‡å‚æ•°é€šä¿¡é‡ç›¸å¯¹äºæ¿€æ´»é€šä¿¡é‡è¾ƒå°ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—è¿›è¡Œé‡å ã€‚GQA/MQA ä¹Ÿå¯ä»¥é™ä½å®ƒä¿©çš„é€šä¿¡æˆæœ¬ï¼Œè€Œ Megatron-SP ä¸å—å½±å“ã€‚ ç›¸åŒé…ç½®ä¸‹ä½¿ç”¨ USP+Zero3 æ¥ä»£æ›¿ Megatron-SP å¹¶ä¸ä¼šå¢åŠ å¯è®­ç»ƒåºåˆ—çš„é•¿åº¦ã€‚ä½†ä¸ Megatron-SP ç›¸æ¯”ï¼ŒUSP èƒ½åœ¨é€šè¿‡æé«˜å¹¶è¡Œåº¦æ¥å¢åŠ å¯ä»¥è®­ç»ƒçš„åºåˆ—é•¿åº¦ã€‚ Megatron-SP å¹¶è¡Œç»´åº¦å—é™äºæ³¨æ„åŠ›å¤´æ•°ç›®ã€‚USP å¯ä»¥é€šè¿‡æé«˜ Ring-SP çš„å¹¶è¡Œåº¦æ¥æ‰©å±•ï¼Œä»¥åœ¨å¤§è§„æ¨¡é…ç½®ä¸‹è®­ç»ƒæ›´å¤§æ¨¡å‹ã€‚ Sora Inference Modeling Analysis Process æˆ‘ä»¬éœ€è¦å‡†å¤‡æ¨¡å‹çš„è¾“å…¥ï¼š\néšç©ºé—´é‡‡æ ·çš„å™ªå£° zï¼Œå½¢çŠ¶ä¸æƒ³ç”Ÿæˆçš„è§†é¢‘æ—¶å¸¸å’Œåˆ†è¾¨ç‡ç›¸å…³ã€‚ç”Ÿæˆ 1s çš„è§†é¢‘ä¸º 25.5 framesï¼Œç»è¿‡ VAE Encoder åè¾“å‡ºçš„é€šé“æ•°ä¸º 4ï¼Œå¸§æ•°ä¼šè¢«å‹ç¼©åˆ° num_frame*5//17ï¼Œåˆ†è¾¨ç‡çš„é•¿å®½åˆ†åˆ«è¢«å‹ç¼©åˆ°åŸæ¥çš„ 1/8. å› æ­¤ z çš„å½¢çŠ¶åº”è¯¥ä¸º (B, 4, num_frame*5//17, img_size[0]//8, img_size[1]//8). è¾“å…¥çš„ prompt ä¼šç»è¿‡ DeepFloyd/t5-v1_1-xxl ç¼–ç ï¼Œè¯¥ç¼–ç å™¨æœ€å¤§çš„ token æ•°ä¸º 300ï¼Œç¼–ç ç»´åº¦ä¸º 4096ï¼Œæ–‡æœ¬é•¿åº¦ä¸è¶³æ—¶ä¼šå¡«å……åˆ° 300. å› æ­¤ç¼–ç åçš„ prompt çš„å½¢çŠ¶ä¸º (B, 1, 300, 4096). å½“å‰å»å™ªçš„æ—¶é—´æ­¥ tï¼Œå½¢çŠ¶ä¸º (B, ) ç”Ÿæˆè§†é¢‘çš„ fpsï¼Œå½¢çŠ¶ä¸º (1, ) è¿˜éœ€è¦å‡†å¤‡ç›¸å…³çš„æ¨¡å‹é…ç½®ï¼ŒåŒ…æ‹¬ mesh å½¢çŠ¶ï¼Œsub_mesh çš„å½¢çŠ¶ï¼Œå¹¶è¡Œç­–ç•¥ä»¥åŠ stage_ids. å¦‚æœéœ€è¦å°†æ¨¡å‹çš„ transformer block åˆ‡åˆ†æˆå¤šæ®µï¼Œåˆ™éœ€è¦é…ç½® sub_mesh å’Œ stage_ids.\nmesh_shape: (num_x, num_y) submesh_shape: [(num_x, num_y, loc_x, loc_y), ] stage_ids: [(submesh0_start, submesh0_end), ] strategy: å¹¶è¡Œç­–ç•¥ ç„¶ååˆå§‹åŒ–æ¨¡å‹ï¼ŒSora çš„æ•´ä½“ç»“æ„å¦‚ä¸‹ æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ª Pipeline(åŒ…å«æ•´ä¸ªæµç¨‹çš„å‡½æ•°)ï¼Œå®ƒä¼šæœ‰ä¸€ä¸ªæˆ–å¤šä¸ª Stage ç”¨äºä¿å­˜æ¨¡å‹çš„ä¸åŒå±‚ï¼Œä¸ stage_ids ä¸­å¯¹åº”ã€‚æˆ‘ä»¬å°†æ¨¡å‹åˆ†è§£æˆ Embedding_blocks(PatchEmbed3D, TimestepEmbedder, SizeEmbedder, Captionembedder, t_block), STDiT3_blocks å’Œ T2IFinalLayer. å°†è¿™ä¸ªåˆ†è§£å‡½æ•°ä½œä¸º Pipeline çš„ sharding_func.\nOpen-Sora\nInit Pipeline æˆ‘ä»¬éœ€è¦æ ¹æ®é…ç½®ä»¥åŠ PipePatch å¹¶è¡Œåº¦å’Œ SP å¹¶è¡Œåº¦åˆå§‹åŒ– Pipeline. è¿™å…¶ä¸­ä¼šæ ¹æ® stage_ids åˆ†é…æ¯ä¸ª Stage ä¿å­˜æ¨¡å‹çš„å“ªäº›å±‚ä»¥åŠå¯¹åº”çš„ submesh å¤§å°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def construct_stages(self, submeshes: List[Tuple], stages_ids: List[Tuple]): # construct layers for each stage first_part, module_list, last_part = self.parse_func(self.model) modules = list() num = len(stages_ids) for idx in range(num): submesh = submeshes[idx] stage_id = stages_ids[idx] # get stage layers from user config stage ids in module list layers = list(module_list[stage_id[0]: stage_id[1] + 1]) if idx == 0 and first_part is not None: # concat module first part(if exists) bef module list to stage_0 layers = first_part + layers if idx == num - 1 and last_part is not None: # concat module last part(if exists) aft module list to last stage layers.extend(last_part) modules.append(layers) # deepcopy module for xla device tracing use stage_module = [copy.deepcopy(layer) for layer in layers] self.stages.append( Stage(idx, stage_module, submesh, self, )) return modules Write Sharding Function è¦æ ¹æ®é€‰æ‹©çš„ä¸åŒçš„å¹¶è¡Œç­–ç•¥å¯¹æ¯ä¸ª Stage çš„æ¨¡å‹æƒé‡ï¼Œè¾“å…¥ï¼Œè¾“å‡ºè¿›è¡Œåˆ‡åˆ†ã€‚è¿™é‡ŒåŒæ ·æˆ‘ä»¬å•ç‹¬å¤„ç† Embedding_blocks, STDiT3_blocks å’Œ T2IFinalLayer. è®© stage0 åŒ…æ‹¬å¯¹ Embedding_blocks çš„å¤„ç†ï¼Œstage(N-1) åŒ…æ‹¬å¯¹ T2IFinalLayer çš„å¤„ç†ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ DS-ulysses æˆ‘ä»¬éœ€è¦å¯¹ Q@K.T çš„ç»“æœ å’Œ S@V çš„ç»“æœä¹Ÿè¿›è¡Œåˆ‡åˆ† SPMD æ‰ä¼šæ’å…¥æ­£ç¡®çš„ All2Allï¼Œå› æ­¤è¿™éƒ¨åˆ†åªèƒ½æ”¾åœ¨ç½‘ç»œçš„ forward é‡Œé¢è¿›è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def shard_sora_one_stage(modules, shard_strategy, mesh): total_len = len(modules) # first 5 modules are embedding layers for i in range(0, 5): shard_sora_embedding(modules[i], shard_strategy, mesh) for i in range(5, total_len - 2): shard_sora_block(modules[i][0], shard_strategy, mesh) # shard spatial shard_sora_block(modules[i][1], shard_strategy, mesh) # shard temporal shard_sora_final(modules[-1], shard_strategy, mesh) def shard_sora_first_stage(modules, shard_strategy, mesh): for i in range(0, 5): shard_sora_embedding(modules[i], shard_strategy, mesh) for i in range(5, len(modules)): shard_sora_block(modules[i][0], shard_strategy, mesh) # shard spatial shard_sora_block(modules[i][1], shard_strategy, mesh) # shard temporal def shard_sora_stage(modules, shard_strategy, mesh): for module in modules: shard_sora_block(module[0], shard_strategy, mesh) # shard spatial shard_sora_block(module[1], shard_strategy, mesh) # shard temporal def shard_sora_last_stage(modules, shard_strategy, mesh): total_len = len(modules) for i in range(0, total_len - 2): shard_sora_block(modules[i][0], shard_strategy, mesh) # shard spatial shard_sora_block(modules[i][1], shard_strategy, mesh) # shard temporal # skip norm layer mark sharding shard_sora_final(modules[total_len - 1], shard_strategy, mesh) Construct Pipeline ç„¶åä¸ºäº†å¤„ç†å¤š stage çš„æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æ¯ä¸ª stage çš„è¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶ã€‚è¿™ä¸€æ­¥ç›¸å½“äºæ”¾åˆ° cuda ä¸Šé‡èµ°ä¸€éæ•´ä¸ªæ¨¡å‹çš„ forwardï¼Œè®°å½•ä¸‹æ¯ä¸€å±‚è¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶ï¼Œä¿å­˜ä¸º json ä¸€éã€‚å®é™…ä¸Šå¯¹äºæ¯ä¸ªå›ºå®šç”Ÿæˆå¤§å°çš„è§†é¢‘è¿›è¡Œä¸€æ¬¡å°±è¡Œï¼Œä¸‹æ¬¡ç›´æ¥è¯»å–è¿™ä¸ªæ–‡ä»¶ã€‚å› ä¸ºç°åœ¨éƒ½é‡‡ç”¨ xformers.ops.memory_efficient_attentionï¼Œéœ€è¦è¾“å…¥å¼ é‡åœ¨ cuda ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åœ¨æ¨¡å‹çš„ forward å‡½æ•°ä¸­å†™ä¸€ä¸ª navie çš„ attention è®¡ç®—æµç¨‹å¥½è®© torch_xla èƒ½å¯¹å¼ é‡è¿›è¡Œè·Ÿè¸ªã€‚\nTrace mhlo Graph æ ¹æ®ä¸Šä¸€æ­¥å¾—åˆ°çš„æ¯ä¸ª Stage çš„è¾“å…¥å½¢çŠ¶ï¼Œåˆ›å»ºè¾“å…¥å¼ é‡ï¼Œæ”¾å…¥ xla_device ä¸Šï¼Œæ‰§è¡Œ forward. æœ€åå¯¼å‡ºè¾“å‡ºçš„ mhlo è®¡ç®—å›¾ã€‚è¿™é‡Œéœ€è¦æ³¨æ„ç¬¬ä¸€ä¸ª stage åŒ…å«å¤šä¸ªéè¿ç»­çš„æ¨¡å—ï¼Œå› æ­¤éœ€è¦å•ç‹¬å¤„ç†ï¼Œæœ€åä¸€ä¸ª stage æœ€åä¸€å±‚çš„è¾“å…¥ä¸å…¶ä»– block ä¸åŒï¼Œå› æ­¤ä¹Ÿè¦å•ç‹¬å¤„ç†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def trace_stage_mhlo_graph(self, check_res=False): \"\"\" trace stage nn modules to mhlo graph \"\"\" # (NOTE): construct xla mesh before trace tensors generate, # i.e., before any xla device call to avoid xla computation client construct xla_mesh = None if self.shard_func is not None: xla_mesh = self._construct_stage_xla_mesh() # create mesh from submesh info # Create xla device trace tensors, move module to xla device if self.stage_id == 0: self.trace_tensors = self._generate_trace_tensors() else: z = self.parent_pipeline.stages[self.stage_id -1].outputs y = self.parent_pipeline.stages[0].y_embedded.to('cpu').to(xm.xla_device()) t_mlp = self.parent_pipeline.stages[0].t_mlp.to('cpu').to(xm.xla_device()) self.trace_tensors = [z, y, t_mlp] for module in self.modules: if isinstance(module, tuple): for mod in module: mod.to('cpu').to(xm.xla_device()) # first load to cpu else: module.to('cpu').to(xm.xla_device()) # get pipeline exec mode assert self.parent_pipeline is not None exec_mode = self.parent_pipeline.exec_mode # load lora cofifg lora_config = self.parent_pipeline.lora_config print(\"Enter trace mhlo graph for stage: \", self.stage_id) # Trigger shard func to mark sharding the model if self.shard_func is not None: self.shard_func(self.modules, self.shard_strategy, xla_mesh) if exec_mode == EXEC_MODE.INFER: # set stage name \u0026 dump file path self._set_stage_name_dump_file( exec_mode, \"fw\") num_sampling_steps = 30 num_timesteps = 1000 timesteps = [(1.0 - i / num_sampling_steps) * num_timesteps for i in range(num_sampling_steps)] # FIXME: åŸå…ˆæ˜¯ä¸ºæ¯ä¸ªstageå•ç‹¬ç”Ÿæˆtrace_tensor, ç°åœ¨è¦æŠŠä¸Šä¸€ä¸ªçš„ç»“æœä¼ ç»™ä¸‹ä¸€ä¸ª stage #for i in range(30): start = sum(self.parent_pipeline.pipeline_patches_height_list[:self.stage_id - 1]) if self.stage_id != 0 else 0 end = start + self.parent_pipeline.pipeline_patches_height_list[self.stage_id] if self.stage_id == 0: outputs = self._forward([self.trace_tensors[0][...,start:end,:]] + self.trace_tensors[1:], xla_mesh) # outputs is a list else: outputs = self._forward(self.trace_tensors, xla_mesh) if check_res: # check xla results compared to gpu results check_result_error(self.outputs, outputs) else: # use torch xla _get_xla_tensors_hlo interface # to eliminate redundant live tensors as ret values os.environ[\"XLA_DUMP_POST_OPTIMIZATIONS\"] = \"true\" torch_xla._XLAC._get_xla_tensors_hlo(outputs) Analyze mhlo Graph æ¥ä¸‹æ¥æˆ‘ä»¬è¦éå†ä¸Šä¸€æ­¥å¾—å‡ºçš„ mhlo å›¾ã€‚\nOpView ä»æ ¹èŠ‚ç‚¹çš„ ir å¼€å§‹éå†ä¸Šä¸€æ­¥å¯¼å‡ºçš„æ•´ä¸ªè®¡ç®—å›¾ã€‚æ ¹æ®ä¼ å…¥ ir çš„ç±»å‹å®šä¹‰è°ƒç”¨å¯¹åº”çš„ visit å‡½æ•°è¯»å–å…¶å±æ€§è¿›è¡Œæ“ä½œã€‚ä¸»è¦é€šè¿‡ rsqrt çš„ä½ç½®æ¥åˆ’åˆ†ä¸€ä¸ª Transformer block ä¸­ç¬¬å‡ ä¸ª dot å’Œ dot_general å¯¹åº”çš„æ˜¯ä»€ä¹ˆæ“ä½œã€‚å¯¹äº Sora æ¥è¯´åˆ’åˆ†æƒ…å†µå¦‚ä¸‹ã€‚è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ mhlo å›¾è®°å½•çš„æ˜¯æ‹“æ‰‘æ’åºçš„é¡ºåºï¼Œä¸æ˜¯ç¨‹åºé¡ºåºæ‰§è¡Œçš„é¡ºåºï¼Œå› æ­¤ç¬¬ä¸€ä¸ª block ä¼šæºæ‚ç€ Embedding_blocks çš„ä¸€äº› dot æ“ä½œã€‚å› æ­¤æˆ‘ä»¬ä»ç¬¬äºŒä¸ª block çš„ç¬¬ä¸€ä¸ª rsqrt ä½ç½®å¼€å§‹ç»Ÿè®¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def collect_rms_ops(self): rms_collector = RMSCollector() rms_collector.visit(self.root_op) self.rms_locs = rms_collector.rms_locs # construct attention block \u0026 ffn block ranges # exclude the rsqrt in T2IFinalLayer att_rm_locs = self.rms_locs if len(self.rms_locs) % 2 == 0 else self.rms_locs[:-1] for i in range(8, len(att_rm_locs), 4): # a block has 4 rsqrt, start from 2nd block to avoid embedding self.spt_qkv_ranges.append((att_rm_locs[i+0], att_rm_locs[i+1])) self.spt_attn_ranges.append((att_rm_locs[i+2], att_rm_locs[i+3])) self.cro_attn_ranges.append((att_rm_locs[i+2], att_rm_locs[i+3])) for i in range(8, len(att_rm_locs), 4): # ORG: range(8, len(att_rm_locs), 4): start = self.rms_locs[i+3] if i+4 \u003e= len(self.rms_locs): end = None else: end = self.rms_locs[i+4] self.ffn_ranges.append((start, end)) module operator RMSNorm(x) Self Attention dot(x, qkvLinear.weight) RMSNorm(q) RMSNorm(k) dot_general(q, k) dot_general(s, v) dot(attn, oLinear.weight) Cross Attention dot(x, qLinear.weight) dot(y, kvLinear.weight) dot_general(q, k) dot_general(s, v) dot(attn, oLinear.weight) RMSNorm(x) Feed Forward Network dot(x, upLinear.weight) dot(x, downLinear.weight) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def visit_dot(self, node): dot_lineno = _parse_loc_lineno(node) if self.block_cnt \u003c len(self.spt_attn_ranges): spt_att_range = self.spt_attn_ranges[self.block_cnt] cro_att_range = self.cro_attn_ranges[self.block_cnt] spt_qkv_range = self.spt_qkv_ranges[self.block_cnt] ffn_range = self.ffn_ranges[self.block_cnt] # lie in RMS ops closed attention block if dot_lineno \u003e spt_att_range[0] and dot_lineno \u003c spt_att_range[1]: #import pdb;pdb.set_trace() self.att_block_dots.append(node) self.spt_dot_cnt += 1 elif dot_lineno \u003e cro_att_range[0] and dot_lineno \u003c cro_att_range[1]: self.att_block_dots.append(node) self.cro_att_dot_cnt += 1 # lie ffn block if dot_lineno \u003e spt_qkv_range[0] and dot_lineno \u003c spt_qkv_range[1]: self.spt_qkv_cnt += 1 self.ffn_block_dots.append(node) # pixart pass elif dot_lineno \u003e ffn_range[0]: if ffn_range[1] is not None: if dot_lineno \u003c ffn_range[1]: self.ffn_block_dots.append(node) self.ffn_dot_cnt += 1 else: if self.ffn_dot_cnt \u003c 2: self.ffn_block_dots.append(node) self.ffn_dot_cnt += 1 # Traversal of one block if self.spt_qkv_cnt == 1 and self.spt_att_dot_cnt == 4 and \\ self.spt_dot_cnt == 4 and self.ffn_dot_cnt == 2: self.attention_blocks.append(self.att_block_dots) self.ffn_blocks.append(self.ffn_block_dots) self.block_cnt += 1 # reset each block level counters self.spt_qkv_cnt = 0 self.spt_att_dot_cnt = 0 self.spt_dot_cnt = 0 self.ffn_dot_cnt = 0 self.att_block_dots = [] self.ffn_block_dots = [] self.generic_visit(node) ä¿å­˜å¥½ä¸€ä¸ª Transformer block ä¸­æ¯ä¸ª dot æˆ– dotgeneral å¯¹åº”çš„æ˜¯ä»€ä¹ˆæ“ä½œåï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥è®¿é—®è¿™ä¸ª ir. è¿™é‡Œéœ€è¦æ³¨æ„åªè¦ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µæœ‰ä¸€ä¸ªæ˜¯äºŒç»´å¼ é‡ (æ¯”å¦‚çº¿æ€§å±‚çš„æƒé‡)ï¼Œmhlo éƒ½ä¼šå°†å¦ä¸€ä¸ª reshape æˆäºŒç»´å¼ é‡ã€‚dot ç®—å­ (jaxlib.mlir.dialects._mhlo_ops_gen.DotOp) ä¸¤ä¸ªæ“ä½œæ•°éƒ½æ˜¯äºŒç»´çš„å¼ é‡ï¼ŒqkvLinear å¯¹åº”çš„æ˜¯ç¬¬ä¸€ä¸ª dot æ“ä½œã€‚å·¦æ“ä½œæ•°çš„ shape ä¸º (BST,3C). å½“ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µéƒ½æ˜¯ 3 ç»´åŠä»¥ä¸Šå¼ é‡çš„æ—¶å€™å°±ä¼šç”Ÿæˆ dot_general è¯¥ç®—å­çš„ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µéƒ½ä¼šè¢« reshape æˆä¸‰ç»´å¼ é‡ã€‚Self-Attention çš„ç¬¬ä¸€ä¸ª dot_general å·¦æ“ä½œæ•°çš„ shape ä¸º (BTN_A,S,C). è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ° BT=(BST)/S, N_A=(BTN_A)/(BT). åŒæ ·æˆ‘ä»¬å¯ä»¥å¾—åˆ° OLinear, FFN ä¸­ upLinear å’Œ downLinear æƒé‡çš„å½¢çŠ¶. ä»¥åŠ Cross-Attention æ¨¡å—çš„å¯¹åº”ä¿¡æ¯ã€‚ç”±äºä¹‹å‰éå†æ˜¯ä»ç¬¬äºŒä¸ª block å¼€å§‹çš„ï¼Œå› æ­¤æ€»å±‚æ•°è¦ ï¼‹1. æœ€åå°†å¾—åˆ°çš„å‚æ•°æ‰“åŒ…æˆä¸€ä¸ªå­—å…¸è¿”å›ã€‚\nCommunication View æˆ‘ä»¬ä»¥åŒæ ·çš„æ–¹å¼å®šä¹‰å„ç§é›†åˆé€šä¿¡ç®—å­çš„ visit å‡½æ•°ç”¨äºè¯„ä¼°è¯¥ç®—å­çš„é€šä¿¡é‡ï¼Œéå†åˆ°å¯¹åº”çš„ ir åè°ƒç”¨å®ƒã€‚\nAllReduce å°†æ‰€æœ‰çš„æ•°æ®é€šè¿‡è§„çº¦æ“ä½œé›†æˆåˆ°å„ä¸ªè®¾å¤‡ä¸­ã€‚\nAllReduce\nåœ¨ Ring-AllReduce çš„ ReduceScatter æ­¥éª¤ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹å‘é€ M ä¸ªå…ƒç´  N-1 æ¬¡ï¼Œæ€»å…±ä¸º M(N-1). åœ¨ AllGather æ­¥éª¤ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹å‘é€å®ƒè®¡ç®—çš„å—çš„ç»“æœã€‚è¿™æ˜¯é¢å¤–çš„ M ä¸ªå…ƒç´ å‘é€äº† N-1 æ¬¡ã€‚æ€»çš„é€šä¿¡é‡åŠ èµ·æ¥æ˜¯ 2M(N-1).\nRing-AllReduce\nAll-Gather ç¤ºæ„å›¾å¦‚ä¸‹ï¼Œæ¯ä¸ªè®¾å¤‡å¼€å§‹æ‹¥æœ‰åˆå§‹çš„ä¸€éƒ¨åˆ†æ•°æ®ï¼Œé€šä¿¡åæ¯ä¸ªè®¾å¤‡éƒ½æœ‰ä¸€ä»½å®Œæ•´çš„æ•°æ®ã€‚æ€»çš„é€šä¿¡é‡ä¸º M(N-1).\nAllGather\nAll2All ç¤ºæ„å›¾å¦‚ä¸‹ï¼Œæ¯ä¸ªè®¾å¤‡æŠŠè‡ªå·±çš„ç¬¬ i å—æ•°æ®å‘é€ç»™ç¬¬ i ä¸ªè®¾å¤‡ã€‚\nAll2All\nåŸºäº Bruck ç®—æ³•çš„ All2All æµç¨‹å¦‚ä¸‹\nå±€éƒ¨å¾ªç¯ç§»ä½ (Local Shift of Data-Blocks) æ¯ä¸ªè¿›ç¨‹å°†å…¶æœ¬åœ°çš„æ•°æ®å—é‡æ–°æ’åˆ—ï¼Œè¿›è¡Œåˆå§‹çš„å¾ªç¯ç§»ä½ã€‚å¯¹äºè¿›ç¨‹ p å’Œæ•°æ®å—ç´¢å¼• i: R[i]=S[(p+i)%P]. å…¶ä¸­ S[i] æ˜¯è¿›ç¨‹æœ¬åœ°åˆå§‹çš„æ•°æ®ï¼ŒR[i] æ˜¯ç§»ä½åçš„æ•°æ®ã€‚ å…¨å±€é€šä¿¡ (Global Communication) ä¸€å…±è¿›è¡Œ log(P) æ¬¡é€šä¿¡ã€‚ æ¯ä¸€æ­¥ä¸­æ¯ä¸ªè¿›ç¨‹å°†ä¸€éƒ¨åˆ†æ•°æ®å‘é€ç»™ç›¸é‚»çš„è¿›ç¨‹ï¼Œå¹¶æ¥æ”¶ç›¸é‚»è¿›ç¨‹å‘é€çš„æ•°æ®ã€‚è‹¥æ•°æ®å—ç´¢å¼• i ç”¨ radix-2 è¡¨ç¤ºçš„ç¬¬ k ä½ä¸º 1ï¼Œåˆ™æ•°æ®å—ä¼šè¢«å‘é€åˆ°ç›®æ ‡è¿›ç¨‹ã€‚ å¯¹äºè¿›ç¨‹ p: å‘é€æ•°æ®åˆ°è¿›ç¨‹ ((p + 2^k) % P)ï¼Œæ¥æ”¶æ¥è‡ªè¿›ç¨‹ ((p - 2^k) % P) çš„æ•°æ®ã€‚ æ¯æ¬¡å‘é€åï¼Œè¿›ç¨‹å°†æ¥æ”¶åˆ°çš„æ•°æ®æ›´æ–°åˆ°å…¶æœ¬åœ°æ•°æ®ä¸­ã€‚ å±€éƒ¨é€†å‘ç§»ä½ (Local Inverse Shift of Data-Blocks) åœ¨å®Œæˆæ‰€æœ‰å…¨å±€é€šä¿¡ä¹‹åï¼Œæ¯ä¸ªè¿›ç¨‹æ‰§è¡Œé€†å‘ç§»ä½ï¼Œä»¥æ¢å¤æ•°æ®å—çš„æ­£ç¡®é¡ºåºã€‚å¯¹äºæ¯ä¸ªæ•°æ®å—ç´¢å¼• i: R[i]=R[(pâˆ’i+P)%P] åœ¨è¿›ç¨‹æ˜¯ 2 æ¬¡å¹‚çš„æƒ…å†µä¸‹æ¯ä¸ªè®¾å¤‡æ¯æ¬¡è¦é€šä¿¡ M*P/2å¤§å°çš„æ•°æ®ï¼Œæ€»å…±ä¸º MPlog(P)/2.\nExample of the Bruck Algorithm with 4 Processes\nTFLOPS View è®¡ç®—é‡ä¸»è¦åˆ†æˆä¸¤ç§ï¼Œelement-wise çš„æ“ä½œè®¡ç®—é‡ä¸ºå…ƒç´ ä¸ªæ•°ã€‚ä¸¤ä¸ªå½¢çŠ¶åˆ†åˆ«ä¸º mxk å’Œ kxn çš„çŸ©é˜µç›¸ä¹˜è®¡ç®—é‡ä¸º 2mkn. è¢«è®¡å…¥ element-wise æ“ä½œçš„ç®—å­æœ‰ add, subtract, multiply, divide, rsqrt, negate, exponential. è¢«è®¡å…¥çŸ©é˜µä¹˜æ³•çš„ç®—å­æœ‰ dot, dot_general.\nPerformance Analysis æˆ‘ä»¬æ ¹æ®æå–å‡ºçš„ Transformer block çš„ä¿¡æ¯é€å…¥æ€§èƒ½åˆ†æå™¨è¿›è¡Œåˆ†æ. tx8 çš„é…ç½®å¦‚ä¸‹\nParameter Value TILE_NUM 16 SRAM (MB) 3 NOC BW (GB/s) 128 DRAM BW (GB/s) 100 DRAM LATENCY (us) 0.1 GEMM (TFLOPS) 8 VECTOR (TOPS) 0.0625 HOP LATENCY (us) 0.01 æ ¹æ®æå–å‡ºçš„ä¿¡æ¯æ„å»ºçš„ STDiT çš„ spt_blk, tmp_blk, cross_blk çš„å‚æ•°å­—å…¸å¦‚ä¸‹.\n1 2 3 4 5 6 7 spatial_config = {\"B\": self.config[\"B_spt\"], \"S_Q\": self.config[\"S_Q_spt\"], \"S_KV\": self.config[\"S_KV_spt\"], \"D_QKV\": self.config[\"D_QKV\"], \"H_QKV\": self.config[\"H_QKV\"], \"N_A\": self.config[\"N_A\"], \"H_A\": self.config[\"H_A\"], \"D_O\": self.config[\"D_O_spt\"], \"H_O\": self.config[\"H_O_spt\"] } temporal_config = {\"B\": self.config[\"B_tmp\"], \"S_Q\": self.config[\"S_Q_tmp\"], \"S_KV\": self.config[\"S_KV_tmp\"], \"D_QKV\": self.config[\"D_QKV\"], \"H_QKV\": self.config[\"H_QKV\"], \"N_A\": self.config[\"N_A\"], \"H_A\": self.config[\"H_A\"], \"D_O\": self.config[\"D_O_tmp\"], \"H_O\": self.config[\"H_O_tmp\"] } cross_config = {\"B\": self.config[\"B_cro\"], \"S_Q\": self.config[\"S_Q_cro\"], \"S_KV\": self.config[\"S_KV_cro\"], \"D_QKV\": self.config[\"D_QKV\"], \"H_QKV\": self.config[\"H_QKV\"],\"N_A\": self.config[\"N_A\"], \"H_A\": self.config[\"H_A\"], \"D_O\": self.config[\"D_O_cro\"], \"H_O\": self.config[\"H_O_cro\"], \"D_FU\": self.config[\"D_FU\"], \"H_FU\": self.config[\"H_FU\"], \"D_FD\": self.config[\"D_FD\"], \"H_FD\": self.config[\"H_FD\"]} æ ¹æ®è¿™äº›å‚æ•°å†æ„å»ºæ¯ä¸ªå±‚çš„è¾“å…¥è¾“å‡ºå½¢çŠ¶ï¼Œè®¡ç®—ç±»å‹å’Œè®¡ç®—é‡ï¼Œä»¥ Gate_ResAdd ä¸ºä¾‹:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 GB = 2**30 class Gate_ResAdd(): ''' Construct each op after MHSA on the config file ''' def __init__(self, config: dict, name: str) -\u003e None: self.config = config self.name = name # {name:{type:\"\", size:\"\", ishape:[], wshape:[]/None, oshape:[]}} self.ops = {} self.construct_model() def construct_model(self): GB = 2**30 ResAdd_input_shape = [self.config['B'], self.config['S_Q'], self.config['D_O']] ResAdd_weight_shape = [1, self.config['D_O']] ResAdd_output_shape = ResAdd_input_shape ResAdd_compute = 2*ResAdd_input_shape[0]*ResAdd_input_shape[1]*ResAdd_input_shape[2]/GB self.ops[self.name+\"_\"+\"ResAdd\"] = {\"name\":\"ResAdd\", \"type\": \"Vector\", \"ishape\": ResAdd_input_shape, \"wshape\": ResAdd_weight_shape, \"oshape\": ResAdd_output_shape, \"compute\": ResAdd_compute} å°±åƒè¿™æ ·æ„å»ºæ•´ä¸ª Transformer block çš„æ‰€æœ‰æ“ä½œ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class STDIT2_block(): def __init__(self, config) -\u003e None: self.config = config # {name:{type:\"\", size:\"\", ishape:[], wshape:[]/None, oshape:[]}} self.ops = {} self.construct_model() def construct_model(self): spatial_config = {\"B\": self.config[\"B_spt\"], \"S_Q\": self.config[\"S_Q_spt\"], \"S_KV\": self.config[\"S_KV_spt\"], \"D_QKV\": self.config[\"D_QKV\"], \"H_QKV\": self.config[\"H_QKV\"], \"N_A\": self.config[\"N_A\"], \"H_A\": self.config[\"H_A\"], \"D_O\": self.config[\"D_O_spt\"], \"H_O\": self.config[\"H_O_spt\"] } temporal_config = {\"B\": self.config[\"B_tmp\"], \"S_Q\": self.config[\"S_Q_tmp\"], \"S_KV\": self.config[\"S_KV_tmp\"], \"D_QKV\": self.config[\"D_QKV\"], \"H_QKV\": self.config[\"H_QKV\"], \"N_A\": self.config[\"N_A\"], \"H_A\": self.config[\"H_A\"], \"D_O\": self.config[\"D_O_tmp\"], \"H_O\": self.config[\"H_O_tmp\"] } cross_config = {\"B\": self.config[\"B_cro\"], \"S_Q\": self.config[\"S_Q_cro\"], \"S_KV\": self.config[\"S_KV_cro\"], \"D_QKV\": self.config[\"D_QKV\"], \"H_QKV\": self.config[\"H_QKV\"],\"N_A\": self.config[\"N_A\"], \"H_A\": self.config[\"H_A\"], \"D_O\": self.config[\"D_O_cro\"], \"H_O\": self.config[\"H_O_cro\"], \"D_FU\": self.config[\"D_FU\"], \"H_FU\": self.config[\"H_FU\"], \"D_FD\": self.config[\"D_FD\"], \"H_FD\": self.config[\"H_FD\"]} self.spatial_modulate = Modulate(spatial_config, name=\"spatial\") self.spatial_block = MHSA_block(spatial_config, name=\"spatial\") self.spatial_gate_resadd = Gate_ResAdd(spatial_config, name=\"spatial\") self.temporal_modulate = Modulate(temporal_config, name=\"temporal\") self.temporal_block = MHSA_block(temporal_config, name=\"temporal\") self.temporal_gate_resadd = Gate_ResAdd(temporal_config, name=\"temporal\") self.cross_block = MHSA_block(cross_config, name=\"cross\") self.cross_gate_resadd = Gate_ResAdd(cross_config, name=\"cross\") self.mlp_modulate = Modulate(cross_config, name=\"mlp\") self.ffn_block = FFN_block(cross_config) self.mlp_gate_resadd = Gate_ResAdd(cross_config, name=\"mlp\") op_list = [self.spatial_modulate.ops, self.spatial_block.ops, self.spatial_gate_resadd.ops, self.temporal_modulate.ops, self.temporal_block.ops, self.temporal_gate_resadd.ops, self.cross_block.ops, self.cross_gate_resadd.ops, self.mlp_modulate.ops, self.ffn_block.ops, self.mlp_gate_resadd.ops] for op_dict in op_list: self.ops.update(op_dict) print(self.ops.keys()) ç„¶åå°±å¯ä»¥å°†æ„å»ºå¥½çš„ ops æ”¾å…¥ mapper è¿›è¡Œåˆ†æã€‚åˆšæ‰é‚£äº›æ“ä½œä¼šè¢«åˆ†æˆ 3 ç±» vector_mapper, gemm_auto_opt_mapper å’Œ flashatten_mapper. æˆ‘ä»¬æ ¹æ®æ“ä½œçš„ç±»å‹é€å…¥å¯¹åº”çš„ mapper è¿›è¡Œåˆ†æï¼Œå…·ä½“å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def STDIT2_mapper(model, arch, QKV_fusion=True, preset=True, details=True): config = model.config Layers = config['L'] spatial_config = {'B': config['B_spt'], 'S_Q': config['S_Q_spt'], 'S_KV': config['S_KV_spt'], 'H_A': config['H_A'], 'N_A': config['N_A'], 'Q': config['Q']} temporal_config = {'B': config['B_tmp'], 'S_Q': config['S_Q_tmp'], 'S_KV': config['S_KV_tmp'], 'H_A': config['H_A'], 'N_A': config['N_A'], 'Q': config['Q']} cross_config = {'B': config['B_cro'], 'S_Q': config['S_Q_cro'], 'S_KV': config['S_KV_cro'], 'H_A': config['H_A'], 'N_A': config['N_A'], 'Q': config['Q']} ops = model.ops mapping_result = {} '''========================= == Spatial Branch Mapping == =========================''' TmTn = [256, 32] if preset else None mapping_result['spatial_Modulate'] = vector_mapper(ops['spatial_Modulate'],arch,splits=None,details=details) mapping_result['spatial_RMSNorm']= vector_mapper(ops['spatial_RMSNorm'],arch,splits=None,details=details) mapping_result['spatial_Q_proj'] = gemm_auto_opt_mapper(ops['spatial_Q_proj'], arch, TmTn=TmTn, details=details) mapping_result['spatial_K_proj'] = gemm_auto_opt_mapper(ops['spatial_K_proj'], arch, TmTn=TmTn, details=details) mapping_result['spatial_V_proj'] = gemm_auto_opt_mapper(ops['spatial_V_proj'], arch, TmTn=TmTn, details=details) Tx_Ty = [256, 256] if preset else None mapping_result['spatial_Flashatten'] = flashatten_mapper(spatial_config, arch, Tx_Ty=Tx_Ty, details=details, Head_fused=True) # FIXME mapping_result['spatial_ResAdd']=vector_mapper(ops['spatial_ResAdd'],arch,splits=None,details=details) '''========================== == Temporal Branch Mapping == ==========================''' mapping_result['temporal_Modulate'] = vector_mapper(ops['temporal_Modulate'],arch,splits=None,details=details) # åˆ‡åˆ† 30 ä»½ä¹Ÿæ— æ³•æ»¡è¶³SRAMè¦æ±‚ mapping_result['temporal_RMSNorm']= vector_mapper(ops['temporal_RMSNorm'],arch,splits=None,details=details) mapping_result['temporal_Q_proj'] = gemm_auto_opt_mapper(ops['temporal_Q_proj'], arch, TmTn=TmTn, details=details) mapping_result['temporal_K_proj'] = gemm_auto_opt_mapper(ops['temporal_K_proj'], arch, TmTn=TmTn, details=details) mapping_result['temporal_V_proj'] = gemm_auto_opt_mapper(ops['temporal_V_proj'], arch, TmTn=TmTn, details=details) Tx_Ty = [256, 256] if preset else None mapping_result['temporal_Flashatten'] = flashatten_mapper(temporal_config, arch, Tx_Ty=Tx_Ty, details=details, Head_fused=True) # FIXME mapping_result['temporal_ResAdd']=vector_mapper(ops['temporal_ResAdd'],arch,splits=None,details=details) '''==================================== == Cross Branch Mapping 2x per block == ====================================''' #mapping_result['spatial_RMSNorm']= vector_mapper(ops['spatial_RMSNorm'],arch,splits=None,details=details) mapping_result['cross_Q_proj'] = gemm_auto_opt_mapper(ops['cross_Q_proj'], arch, TmTn=TmTn, details=details) mapping_result['cross_Q_proj_2'] = mapping_result['cross_Q_proj'] mapping_result['cross_K_proj'] = gemm_auto_opt_mapper(ops['cross_K_proj'], arch, TmTn=TmTn, details=details) mapping_result['cross_K_proj_2'] = mapping_result['cross_K_proj'] mapping_result['cross_V_proj'] = gemm_auto_opt_mapper(ops['cross_V_proj'], arch, TmTn=TmTn, details=details) mapping_result['cross_V_proj_2'] = mapping_result['cross_V_proj'] Tx_Ty = [256, 256] if preset else None mapping_result['cross_Flashatten'] = flashatten_mapper(cross_config, arch, Tx_Ty=Tx_Ty, details=details, Head_fused=True) # FIXME mapping_result['cross_Flashatten_2'] = mapping_result['cross_Flashatten'] mapping_result['cross_ResAdd'] = vector_mapper(ops['cross_ResAdd'],arch,splits=None,details=details) # HACK: Gate_ResAdd *2 äº†, cross æ— gate è¿™é‡Œæ—  _2 '''==================================== == Feed Forward Network 2x per block == ====================================''' mapping_result['mlp_Modulate'] = vector_mapper(ops['mlp_Modulate'],arch,splits=None,details=details) mapping_result['mlp_Modulate_2'] = mapping_result['mlp_Modulate'] mapping_result['FFNup\u0026SiLU'] = gemm_auto_opt_mapper(ops['FFNup'],arch,TmTn=TmTn,fusion_op2=ops['SiLU'],details=details) mapping_result['FFNup\u0026SiLU_2'] = mapping_result['FFNup\u0026SiLU'] # mapping_result['FFNgate'] = gemm_auto_opt_mapper(ops['FFNgate'], arch, TmTn=TmTn, details=details) # mapping_result['Hadamard'] = vector_mapper(ops['Hadamard'], arch, splits=None) TmTn = [4, 128] if preset else None mapping_result['FFNdown'] = gemm_auto_opt_mapper(ops['FFNdown'], arch, TmTn=TmTn, details=details) mapping_result['FFNdown_2'] = mapping_result['FFNdown'] mapping_result['mlp_ResAdd'] = vector_mapper(ops['mlp_ResAdd'], arch, splits=None, details=details) mapping_result['mlp_ResAdd_2'] = mapping_result['mlp_ResAdd'] mapper ä¼šéå†æ‰€æœ‰å¯èƒ½çš„åˆ‡åˆ†ç­–ç•¥æ”¾å…¥ tx8 æ‰§è¡Œå¹¶é€‰æ‹©æœ€å¥½çš„é‚£ä¸€ä¸ªã€‚å¯¹äº vector ç±»å‹çš„ç®—å­åªä¼šæ²¿ç€ sequence ç»´åº¦åˆ‡åˆ†ï¼›å¯¹äº GEMM ç®—å­åˆ™ä¼šæ²¿ç€ m, k, n ç»´åº¦éƒ½è¿›è¡Œåˆ‡åˆ†ï¼›å¯¹äº flash-attention çš„åˆ‡åˆ†åˆ™ä¸åŸç®—æ³•ç›¸åŒï¼Œå¤–å¾ªç¯éå† K, V çš„æ¯ä¸€å—ï¼Œå†…å¾ªç¯éå† Q çš„æ¯ä¸€å—ã€‚è¿™æ ·å°±å¯ä»¥å¾—åˆ°æ¯ä¸ª tx8 ä¸Šæœ€ä¼˜çš„åˆ‡åˆ†æ–¹å¼å¯¹åº”çš„é€šä¿¡ç”¨æ—¶ï¼Œè®¡ç®—ç”¨æ—¶å’Œåˆ©ç”¨ç‡ã€‚å†ç”¨ä¹‹å‰ç»Ÿè®¡å‡ºçš„æ¯ä¸ª die ä¸Šé€šä¿¡é‡é™¤ä»¥ die2die å¸¦å®½å¾—åˆ°é€šä¿¡ç”¨æ—¶ï¼Œç”±æ­¤å¾—åˆ°æ€»çš„æ¨ç†ç”¨æ—¶ã€‚\n",
  "wordCount" : "7045",
  "inLanguage": "en",
  "datePublished": "2023-11-13T16:05:23+08:00",
  "dateModified": "2025-06-07T23:40:58+08:00",
  "author":[{
    "@type": "Person",
    "name": "WITHER"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/blogs/comparsion-of-parallelsim-metods-in-vit/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "WITHER",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="WITHER (Alt + H)">WITHER</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="http://localhost:1313/zh/" title="ç®€ä½“ä¸­æ–‡"
                            aria-label="ç®€ä½“ä¸­æ–‡">ç®€ä½“ä¸­æ–‡</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="ğŸ  Home">
                    <span>ğŸ  Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about_me/" title="ğŸ™‹ğŸ»â€â™‚ï¸ Me">
                    <span>ğŸ™‹ğŸ»â€â™‚ï¸ Me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blogs/" title="ğŸ“š Blogs">
                    <span>ğŸ“š Blogs</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="ğŸ§© Categories">
                    <span>ğŸ§© Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="ğŸ”– Tags">
                    <span>ğŸ”– Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="â± Archive">
                    <span>â± Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="ğŸ” Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ” Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/friends/" title="ğŸ¤ Friends">
                    <span>ğŸ¤ Friends</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;Â»&nbsp;<a href="http://localhost:1313/blogs/">Blogs</a></div>
    <h1 class="post-title entry-hint-parent">
      Comparsion of Parallelsim Metods in ViT
    </h1>
    <div class="post-description">
      Paper reading of .
    </div>
    <div class="post-meta"><span title='2023-11-13 16:05:23 +0800 CST'>Nov-13-2023</span>&nbsp;Â·&nbsp;15 min&nbsp;Â·&nbsp;7045 words&nbsp;Â·&nbsp;WITHER

</div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#basic-transformer-block" aria-label="Basic Transformer Block">Basic Transformer Block</a><ul>
                            
                    <li>
                        <a href="#model-parameters" aria-label="Model Parameters">Model Parameters</a></li>
                    <li>
                        <a href="#flops-calculation" aria-label="FLOPs Calculation">FLOPs Calculation</a></li></ul>
                    </li>
                    <li>
                        <a href="#activation-memory" aria-label="Activation Memory">Activation Memory</a></li>
                    <li>
                        <a href="#tensor-parallelsim" aria-label="Tensor Parallelsim">Tensor Parallelsim</a></li>
                    <li>
                        <a href="#megatron-sequence-parallelsim" aria-label="Megatron Sequence Parallelsim">Megatron Sequence Parallelsim</a></li>
                    <li>
                        <a href="#pipeline-parallelsim" aria-label="Pipeline Parallelsim">Pipeline Parallelsim</a></li>
                    <li>
                        <a href="#deepseed-ulysses-sequence-parallel" aria-label="Deepseed-Ulysses Sequence Parallel">Deepseed-Ulysses Sequence Parallel</a></li>
                    <li>
                        <a href="#ring-attention-sequence-parallel" aria-label="Ring-Attention Sequence Parallel">Ring-Attention Sequence Parallel</a></li>
                    <li>
                        <a href="#unified-sequence-parallel" aria-label="Unified Sequence Parallel">Unified Sequence Parallel</a></li>
                    <li>
                        <a href="#comparsion-of-different-parallelsim-in-training" aria-label="Comparsion of Different Parallelsim in Training">Comparsion of Different Parallelsim in Training</a></li>
                    <li>
                        <a href="#analysis" aria-label="Analysis">Analysis</a></li>
                    <li>
                        <a href="#sora-inference-modeling-analysis-process" aria-label="Sora Inference Modeling Analysis Process">Sora Inference Modeling Analysis Process</a><ul>
                            
                    <li>
                        <a href="#init-pipeline" aria-label="Init Pipeline">Init Pipeline</a></li>
                    <li>
                        <a href="#write-sharding-function" aria-label="Write Sharding Function">Write Sharding Function</a></li>
                    <li>
                        <a href="#construct-pipeline" aria-label="Construct Pipeline">Construct Pipeline</a></li>
                    <li>
                        <a href="#trace-mhlo-graph" aria-label="Trace mhlo Graph">Trace mhlo Graph</a></li>
                    <li>
                        <a href="#analyze-mhlo-graph" aria-label="Analyze mhlo Graph">Analyze mhlo Graph</a><ul>
                            
                    <li>
                        <a href="#opview" aria-label="OpView">OpView</a></li>
                    <li>
                        <a href="#communication-view" aria-label="Communication View">Communication View</a></li>
                    <li>
                        <a href="#tflops-view" aria-label="TFLOPS View">TFLOPS View</a></li></ul>
                    </li>
                    <li>
                        <a href="#performance-analysis" aria-label="Performance Analysis">Performance Analysis</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    
    document.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();
    
        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        if (elements.length > 0) {
            
            activeElement = elements[0];
            const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
            document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
        }
    
        
        const topLink = document.getElementById('top-link');
        if (topLink) {
            topLink.addEventListener('click', (event) => {
                
                event.preventDefault();
    
                
                window.scrollTo({ top: 0, behavior: 'smooth' });
            });
        }
    }, false);
    
    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);
    
    window.addEventListener('scroll', () => {
        
        const scrollPosition = window.pageYOffset || document.documentElement.scrollTop;
    
        
        if (scrollPosition === 0) {
            return;
        }
    
        
        if (elements && elements.length > 0) {
            
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - scrollPosition) > 0 && 
                    (getOffsetTop(element) - scrollPosition) < window.innerHeight / 2) {
                    return element;
                }
            }) || activeElement;
    
            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                const tocLink = document.querySelector(`.inner ul li a[href="#${id}"]`);
                if (element === activeElement){
                    tocLink.classList.add('active');
    
                    
                    const tocContainer = document.querySelector('.toc .inner');
                    const linkOffsetTop = tocLink.offsetTop;
                    const containerHeight = tocContainer.clientHeight;
                    const linkHeight = tocLink.clientHeight;
    
                    
                    const scrollPosition = linkOffsetTop - (containerHeight / 2) + (linkHeight / 2);
                    tocContainer.scrollTo({ top: scrollPosition, behavior: 'smooth' });
                } else {
                    tocLink.classList.remove('active');
                }
            });
        }
    }, false);
    
    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);
    
    function checkTocPosition() {
        const width = document.body.scrollWidth;
    
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }
    
    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
    
</script>

  <div class="post-content"><h1 id="basic-transformer-block">Basic Transformer Block<a hidden class="anchor" aria-hidden="true" href="#basic-transformer-block">#</a></h1>
<p>ç¬¦å·å«ä¹‰è¡¨ç¤ºå¦‚ä¸‹</p>
<table>
  <thead>
      <tr>
          <th>Symbol</th>
          <th>Description</th>
          <th>Symbol</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>a</td>
          <td>æ³¨æ„åŠ›å¤´æ•°</td>
          <td>n</td>
          <td>å¹¶è¡Œåº¦å¤§å°</td>
      </tr>
      <tr>
          <td>b</td>
          <td>batchsize</td>
          <td>s</td>
          <td>åºåˆ—é•¿åº¦</td>
      </tr>
      <tr>
          <td>h</td>
          <td>éšè—å±‚ç»´åº¦</td>
          <td>v</td>
          <td>è¯æ±‡è¡¨å¤§å°</td>
      </tr>
      <tr>
          <td>L</td>
          <td>tranformer layer å±‚æ•°æ•°</td>
          <td></td>
          <td></td>
      </tr>
  </tbody>
</table>
<p>åŸºæœ¬ transformer block ç»“æ„å¦‚ä¸‹ï¼Œè¾“å…¥æ˜¯å½¢çŠ¶ä¸º (b, s, h) çš„ä¸‰ç»´å¼ é‡ï¼Œå…¶ä¸­ b ä¸º batchsize. æ¯ä¸ªå˜å‹å™¨å±‚ç”±ä¸€ä¸ªå…·æœ‰æ³¨æ„å¤´çš„è‡ªæ³¨æ„å—ç»„æˆï¼Œéšåæ˜¯ä¸€ä¸ªå…·æœ‰ä¸¤å±‚çš„ MLPï¼Œç¬¬ä¸€å±‚å°†éšè—ç»´åº¦å¢åŠ åˆ° 4hï¼Œç„¶ç¬¬äºŒå±‚å°†å…¶å‡å°‘åˆ° h. æ¯ä¸ªå˜å‹å™¨å±‚çš„è¾“å…¥å’Œè¾“å‡ºå…·æœ‰ç›¸åŒçš„å½¢çŠ¶.</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB6446c9e0a905932db1f9e39fa91c01ba?method=download&amp;shareKey=f26e075bcfc51b8c093388f69d39b40d" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB6446c9e0a905932db1f9e39fa91c01ba?method=download&amp;shareKey=f26e075bcfc51b8c093388f69d39b40d" alt="Basic Transformer Architecture">
    </a><figcaption>Basic Transformer Architecture</figcaption></figure>

<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBfbdc229aca70349939d6e3306e78c434?method=download&amp;shareKey=cff3f2903a8e16c5c46d607749a4b3c1" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBfbdc229aca70349939d6e3306e78c434?method=download&amp;shareKey=cff3f2903a8e16c5c46d607749a4b3c1" alt="Self-attention Block">
    </a><figcaption>Self-attention Block</figcaption></figure></p>
<h2 id="model-parameters">Model Parameters<a hidden class="anchor" aria-hidden="true" href="#model-parameters">#</a></h2>
<p>QKVO Linear çš„æƒé‡å½¢çŠ¶å‡ä¸º <code>h*h</code>, åç½®å½¢çŠ¶å‡ä¸º <code>h*1</code>ï¼›MLP ä¸¤ä¸ª Linear çš„æƒé‡å½¢åˆ†åˆ«ä¸º <code>h*4h</code> å’Œ <code>4h*h</code>ï¼Œåç½®å½¢çŠ¶åˆ†åˆ«ä¸º <code>4h*1</code> å’Œ <code>h*1</code>. å› æ­¤æ¯ä¸ªæ¨¡å‹çš„å‚æ•°é‡ä¸º <code>(12hh+13h)L</code>ï¼Œå ç”¨å¤§å°è¿˜è¦ <code>x2</code>.</p>
<style type="text/css">
     
    .notice {
        --title-color: #fff;
        --title-background-color: #6be;
        --content-color: #444;
        --content-background-color: #e7f2fa;
    }

    .notice.info {
        --title-background-color: #fb7;
        --content-background-color: #fec;
    }

    .notice.tip {
        --title-background-color: #5a5;
        --content-background-color: #efe;
    }

    .notice.warning {
        --title-background-color: #c33;
        --content-background-color: #fee;
    }

     
    @media (prefers-color-scheme:dark) {
        .notice {
            --title-color: #fff;
            --title-background-color: #069;
            --content-color: #ddd;
            --content-background-color: #023;
        }

        .notice.info {
            --title-background-color: #a50;
            --content-background-color: #420;
        }

        .notice.tip {
            --title-background-color: #363;
            --content-background-color: #121;
        }

        .notice.warning {
            --title-background-color: #800;
            --content-background-color: #400;
        }
    }

    body.dark .notice {
        --title-color: #fff;
        --title-background-color: #069;
        --content-color: #ddd;
        --content-background-color: #023;
    }

    body.dark .notice.info {
        --title-background-color: #a50;
        --content-background-color: #420;
    }

    body.dark .notice.tip {
        --title-background-color: #363;
        --content-background-color: #121;
    }

    body.dark .notice.warning {
        --title-background-color: #800;
        --content-background-color: #400;
    }

     
    .notice {
        padding: 18px;
        line-height: 24px;
        margin-bottom: 24px;
        border-radius: 4px;
        color: var(--content-color);
        background: var(--content-background-color);
    }

    .notice p:last-child {
        margin-bottom: 0
    }

     
    .notice-title {
        margin: -18px -18px 12px;
        padding: 4px 18px;
        border-radius: 4px 4px 0 0;
        font-weight: 700;
        color: var(--title-color);
        background: var(--title-background-color);
    }

     
    .icon-notice {
        display: inline-flex;
        align-self: center;
        margin-right: 8px;
    }

    .icon-notice img,
    .icon-notice svg {
        height: 1em;
        width: 1em;
        fill: currentColor;
    }

    .icon-notice img,
    .icon-notice.baseline svg {
        top: .125em;
        position: relative;
    }
</style><div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>åœ¨ä¼ ç»Ÿçš„ LLM ä¸­æœ€åè¿˜éœ€è¦ç»è¿‡ logits layerï¼Œå°†éšè—å±‚ç»´åº¦ <code>h</code> è½¬æ¢æˆè¯æ±‡è¡¨å¤§å° <code>v</code>ï¼Œå‚æ•°é‡è¿˜è¦åŠ ä¸Š <code>hv</code>.</p></div>

<h2 id="flops-calculation">FLOPs Calculation<a hidden class="anchor" aria-hidden="true" href="#flops-calculation">#</a></h2>
<p>å¯¹äºæµ®ç‚¹æ•°è®¡ç®—é‡ (FLOPs)ï¼Œåªè€ƒè™‘å ä¸»è¦éƒ¨åˆ†çš„é€šç”¨çŸ©é˜µä¹˜æ³• (GEMMs). å¯¹äº Attention éƒ¨åˆ†ï¼ŒQKV Linear çš„è®¡ç®—é‡ä¸º <code>6bshh</code>ï¼Œattention matrix (<a href="mailto:Q@K.T">Q@K.T</a>) çš„è®¡ç®—é‡ä¸º <code>2bssh</code>, attention@V çš„è®¡ç®—é‡ä¸º <code>2bssh</code>, O Linear çš„è®¡ç®—é‡ä¸º <code>2bshh</code>. MLP çš„ä¸¤ä¸ªçº¿æ€§å±‚çš„æ¯ä¸€ä¸ªè®¡ç®—é‡éƒ½ä¸º <code>8shh</code>. ç›¸åŠ åå¾—åˆ°æ­£å‘ä¼ æ’­ä¸­æ€»è®¡ç®—é‡ä¸º <code>(24bshh + 4bssh)L</code> bytes.</p>
<div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>åœ¨ä¼ ç»Ÿçš„ LLM ä¸­æœ€åè¿˜éœ€è¦ç»è¿‡ logits layerï¼Œå°†éšè—å±‚ç»´åº¦ <code>h</code> è½¬æ¢æˆè¯æ±‡è¡¨å¤§å° <code>v</code>ï¼Œå…¶è®¡ç®—é‡ä¸º <code>2bshv</code>.</p></div>

<p>åå‘ä¼ æ’­å› ä¸ºè¦è®¡ç®—è¾“å…¥å’Œæƒé‡çš„æ¢¯åº¦ï¼Œå…¶è®¡ç®—é‡ä¸ºæ­£å‘ä¼ æ’­çš„ä¸¤å€ï¼Œå› æ­¤æ•´ä¸ªæ¨¡å‹çš„è®¡ç®—é‡ä¸º <code>72BLshh(1+s/(6h))</code>.</p>
<h1 id="activation-memory">Activation Memory<a hidden class="anchor" aria-hidden="true" href="#activation-memory">#</a></h1>
<p>æ¿€æ´»çš„å®šä¹‰ä¸ºåœ¨å‰å‘ä¼ æ’­ä¸­äº§ç”Ÿå¹¶ä¸”éœ€è¦åœ¨åå‘ä¼ æ’­ä¸­è¿›è¡Œæ¢¯åº¦è®¡ç®—çš„å¼ é‡ï¼Œå³ä¸åŒ…æ‹¬æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚å¹¶ä¸”ä¸è€ƒè™‘ç›¸å¯¹éå¸¸å°çš„æ¿€æ´»ã€‚ä¾‹å¦‚ LayerNorm å±‚çš„è¾“å…¥è¿˜éœ€è¦å¼ é‡æ¯ä¸ªé€šé“çš„å‡å€¼å’Œæ–¹å·® (å¤§å°å‡ä¸º bs)ï¼Œç”±äº h å¤§å°é€šå¸¸è¶…è¿‡ 1kï¼Œå› æ­¤åªè€ƒè™‘è¾“å…¥å¼ é‡æ‰€å æ¿€æ´»çš„å¤§å° bshï¼Œå¿½ç•¥æ‰ 2bs. å‡è®¾æ•°æ®æ ¼å¼ä¸º fp16/bf16ï¼Œå³æ¯ä¸ªæ•°æ®å ç”¨ 2 bytes çš„å­˜å‚¨ç©ºé—´ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†çš„æ˜¯ dropout å±‚çš„ makï¼Œæ¯ä¸ªå…ƒç´ å‡ä¸º unsigned intï¼Œåªå ç”¨ 1 byte.</p>
<p>Attention éƒ¨åˆ†æ¿€æ´»å ç”¨å¦‚ä¸‹ (å…±è®¡ 11bsh + 5bssa)</p>
<ul>
<li>QKV Linear: ä¸‰ä¸ªçº¿æ€§å±‚éœ€è¦çš„è¾“å…¥ç›¸åŒï¼Œå ç”¨ 2bsh bytes.</li>
<li><a href="mailto:Q@K.T">Q@K.T</a>: éœ€è¦å­˜å‚¨ Q å’Œ Kï¼Œå ç”¨ 4bsh bytes.</li>
<li>Softmax: éœ€è¦å­˜å‚¨å¤§å°ä¸º 2bssa bytes çš„è¾“å…¥</li>
<li>Softmax droppot: éœ€è¦å­˜å‚¨ä¸€ä¸ªå¤§å°ä¸º bssa bytes çš„ mask.</li>
<li>attention@V: éœ€è¦å­˜å‚¨ dropout çš„è¾“å‡ºå’Œ Vï¼Œåˆ†åˆ«å ç”¨ 2bssa å’Œ 2bsh bytes.</li>
<li>O Linear: éœ€è¦å­˜å‚¨æ³¨æ„åŠ›çš„è¾“å‡ºï¼Œå ç”¨ 2bsh bytes.</li>
<li>O dropout éœ€è¦å­˜å‚¨ä¸€ä¸ªå¤§å°ä¸º bsh bytes çš„ mask;</li>
</ul>
<p>MLP (å…±è®¡ 18bsh): ç¬¬ä¸€å±‚å’Œç¬¬äºŒå±‚çš„è¾“å…¥åˆ†åˆ«å ç”¨ 2bsh å’Œ 8bsh bytes. GeLU å±‚éœ€è¦ç¬¬äºŒå±‚çš„è¾“å…¥ç”¨äºåå‘ä¼ æ’­ï¼Œå ç”¨å¤§å°ä¸º 8bsh bytes. dropout éœ€è¦ä¸€ä¸ªå¤§å°ä¸º bsh bytes çš„ mask.</p>
<p>LayerNorm (å…±è®¡ 4bsh): éœ€è¦å­˜å‚¨è¯¥å±‚çš„è¾“å…¥ï¼Œå ç”¨ 2bsh bytes. ä¸€å…±æœ‰ä¸¤ä¸ª LayerNorm.</p>
<p>åŠ èµ·æ¥å°±å¯ä»¥å¾—åˆ°æ¯ä¸ª transformer block éœ€è¦æ¿€æ´»å¤§å°ä¸º bsh(34+5sa/h) bytes.</p>
<h1 id="tensor-parallelsim">Tensor Parallelsim<a hidden class="anchor" aria-hidden="true" href="#tensor-parallelsim">#</a></h1>
<p><a href="https://darkenstar.github.io/2024/10/02/MegatronLM/#Model-Parallel-Transformers">Megatron å¼ é‡å¹¶è¡Œ</a> çš„æ€æƒ³æ˜¯å°†è¾“å…¥è¿›è¡Œè¿ç»­çš„ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•çš„ç¬¬ä¸€ä¸ªæŒ‰åˆ—åˆ‡åˆ†æˆ t ä»½ï¼Œç¬¬äºŒä¸ªæŒ‰è¡Œåˆ‡åˆ†æˆ t ä»½. åœ¨ Transformer block ä¸­ä½“ç°ä¸ºåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æœ¬èº«çš„å¹¶è¡Œæ€§å°† Attention è®¡ç®—ä¸­çš„ QKV æŒ‰åˆ—è¿›è¡Œåˆ‡åˆ†ï¼ŒO Linear çš„æƒé‡æŒ‰è¡Œè¿›è¡Œåˆ‡åˆ†ï¼›MLP ä¸­ç¬¬ä¸€ä¸ªçº¿æ€§å±‚çš„æƒé‡æŒ‰åˆ—è¿›è¡Œåˆ‡åˆ†ï¼Œç¬¬äºŒä¸ªæƒé‡æŒ‰è¡Œè¿›è¡Œåˆ‡åˆ†ã€‚</p>
<p>åœ¨è¿™ç§å¹¶è¡Œæ–¹å¼ä¸‹ï¼Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­å‡éœ€è¦è¿›è¡Œ 2 æ¬¡ All-Reduce é€šä¿¡ï¼Œç”±äºæ¯æ¬¡ All-Reduce é€šä¿¡å¯ä»¥çœ‹ä½œ Reduce-Scatter + All-Gather, å› æ­¤æ¯æ¬¡æ¯ä¸ªè®¾å¤‡çš„é€šä¿¡é‡ä¸º 8Î±bsh bytesï¼Œå…¶ä¸­ Î±=(n-1)/n.</p>
<p>å¯¹äºæ¿€æ´»ï¼Œ2*LayerNorm, QKV Linear çš„è¾“å…¥, O dropout maskï¼ŒMLP ç¬¬ä¸€å±‚çš„è¾“å…¥å’Œ MLP dropout ä¸ä¼šè¢«åˆ‡åˆ†ï¼Œå› æ­¤æ¯ä¸ªè®¾å¤‡æ¯ä¸ª block è¦å ç”¨çš„æ¿€æ´»ä¸º bsh(10+24/n+5as/(hn))</p>
<p>2D Tensor Parallelsim</p>
<p>2Då¼ é‡å¹¶è¡Œå°†æ¿€æ´»ç¬¬ä¸€ä¸ªçŸ©é˜µçš„åˆ—åˆ‡åˆ†æˆ m*n ä»½ï¼Œç¬¬äºŒä¸ªæƒé‡ (æƒé‡å½¢çŠ¶ä¸º he) çš„è¡Œè¢«åˆ‡åˆ†æˆ m ä»½ï¼Œåˆ—è¢«åˆ‡åˆ†æˆ n ä»½ã€‚ä»¥ä¸‹å›¾ä¸ºä¾‹ï¼ŒRank0-Rank2ä¸ºé€šä¿¡ç»„ xï¼ŒRank0-Rank1ä¸º é€šä¿¡ç»„ y. ç¬¬ä¸€ä¸ªçŸ©é˜µç»è¿‡ä¸€æ¬¡é€šä¿¡ç»„ y çš„ AllGather åä¸æœ¬è®¾å¤‡ç¬¬äºŒä¸ªçŸ©é˜µè¿›è¡ŒçŸ©é˜µä¹˜ç§¯ï¼Œå¾—åˆ°çš„éƒ¨åˆ†å’Œç»è¿‡ä¸€æ¬¡é€šä¿¡ç»„ x é—´çš„ReduceScatterï¼Œè®¡ç®—å‡ºæ­£ç¡®ç»“æœã€‚ç¬¬ä¸€æ¬¡ AllGather é€šä¿¡æ¯ä¸ªè®¾å¤‡é€šä¿¡çš„å¤§å°ä¸º bsh(n-1)/(mn). ç¬¬äºŒæ¬¡ ReduceScatter é€šä¿¡æ¯ä¸ªè®¾å¤‡é€šä¿¡çš„å¤§å°ä¸º bse(m-1)/n.</p>
<h1 id="megatron-sequence-parallelsim">Megatron Sequence Parallelsim<a hidden class="anchor" aria-hidden="true" href="#megatron-sequence-parallelsim">#</a></h1>
<p>Megatron å¼ é‡å¹¶è¡Œä¸­ LayerNorm ä»¥åŠ O Linear å’Œ MLP ä¹‹åçš„ dropouts åœ¨æ¯ä¸ªè®¾å¤‡ä¸­éƒ½æœ‰ä¸€ä¸ªå‰¯æœ¬ã€‚è¿™äº›æ¨¡å—ä¸éœ€è¦å¤§é‡çš„è®¡ç®—ï¼Œä½†éœ€è¦å ç”¨ 10bsh bytes å¤§å°çš„æ¿€æ´»å†…å­˜ã€‚<a href="">Megatron-SP</a> æ²¿ç€åºåˆ—ç»´åº¦åˆ’åˆ†è¿™äº›æ¨¡å—æ¥å‡å°‘æ¿€æ´»å†…å­˜ï¼Œä½†éœ€è¦é…åˆ TP ä¸€èµ·ä½¿ç”¨ï¼Œæœ¬è´¨ä¸Šæ˜¯å°† TP ä¸­çš„ All-Reduce æ‹†æˆäº†åœ¨ TP å‰è¿›è¡Œ All-Gather å’Œåœ¨ TP åè¿›è¡Œ Reduce-Scatter. ä½†é™¤å»ç¬¬ä¸€ä¸ª LayerNorm å¤–çš„æ¯ä¸€ä¸ªæ¨¡å—çš„æ¿€æ´»éƒ½å¾—åˆ°äº†åˆ‡åˆ†ã€‚Megatron-SP è¿™é‡Œé€‰æ‹©æ¯ä¸ªè®¾å¤‡å­˜å‚¨è‡ªå·±çš„éƒ¨åˆ†å¹¶åœ¨åå‘ä¼ æ’­ä¸­æ’å…¥ä¸€æ¬¡é¢å¤–çš„ All-Gather é€šä¿¡ã€‚å› æ­¤é€šä¿¡é‡ä¸º 10bsh, æ¯ä¸ªè®¾å¤‡æ¯ä¸ª block éœ€è¦å ç”¨çš„æ¿€æ´»ä¸º bsh/n*(34+5as/h)</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB6800d68e35ee4215289de6aa75f01884?method=download&amp;shareKey=e67ffd54e4d1fe7cf3a10e81108af366" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB6800d68e35ee4215289de6aa75f01884?method=download&amp;shareKey=e67ffd54e4d1fe7cf3a10e81108af366" alt="Transformer layer with Megatron-SP">
    </a><figcaption>Transformer layer with Megatron-SP</figcaption></figure></p>
<h1 id="pipeline-parallelsim">Pipeline Parallelsim<a hidden class="anchor" aria-hidden="true" href="#pipeline-parallelsim">#</a></h1>
<p>æµæ°´çº¿å¼ é‡å¹¶è¡Œä»…ä»…å°† L ä¸ª Transformer block å¹³å‡åˆ†åˆ° p ä¸ªè®¾å¤‡ä¸Šï¼Œå¹¶æ²¡æœ‰åˆ’åˆ†æ¿€æ´»æ‰€è¦å ç”¨çš„å†…å­˜ã€‚åœ¨è€ƒè™‘ 1F1B ç­–ç•¥ä¸‹ batchsize è¿›ä¸€æ­¥è¢«åˆ’åˆ†æˆ p ä¸ª micro batch. ç¬¬ä¸€ä¸ª stage å¿…é¡»å­˜å‚¨ p ä¸ª micro batch çš„æ¿€æ´»ã€‚æ¯ä¸ª stage åŒ…å« L/p å±‚ï¼Œæ‰€ä»¥æ— è®ºæµæ°´çº¿å¹¶è¡Œå¤§å° p å¦‚ä½•ï¼Œç¬¬ä¸€ä¸ª stage å¿…é¡»å­˜å‚¨ p Ã— L/p = L å±‚çš„æ¿€æ´»å€¼ã€‚åœ¨ Megatron-LM ä¸­çš„ interleaving schedule éœ€è¦å­˜å‚¨ L(1 + (pâˆ’1)/(pm)) å±‚çš„æ¿€æ´»ï¼Œå…¶ä¸­ m æ˜¯ interleaving çš„æ•°é‡ã€‚</p>
<div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>åœ¨ä½¿ç”¨ output-tensor-deallocation ä¼˜åŒ– (è¾“å‡ºä¼ åˆ°ä¸‹ä¸€ä¸ª stage åå°±é‡Šæ”¾) çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä¸ºä¸ºæ¯ä¸ªè®¾å¤‡èŠ‚çœ bshr å†…å­˜ï¼Œå…¶ä¸­ r æ˜¯æ¯ä¸ªè®¾å¤‡æ­£åœ¨è¿è¡Œçš„ micro batch çš„æ•°é‡ï¼Œåœ¨ç¬¬ä¸€ä¸ª stage r=p æ—¶è¾¾åˆ°å³°å€¼ã€‚</p></div>

<h1 id="deepseed-ulysses-sequence-parallel">Deepseed-Ulysses Sequence Parallel<a hidden class="anchor" aria-hidden="true" href="#deepseed-ulysses-sequence-parallel">#</a></h1>
<p><a href="https://darkenstar.github.io/2024/10/21/Deepseed%20Ulysses/">DS-SP</a> ä¹Ÿæ˜¯åˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›çš„å¹¶è¡Œæ€§ï¼Œé¦–å…ˆå°†è¾“å…¥æŒ‰åºåˆ—ç»´åº¦åˆ‡åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œæ¯ä¸ªè®¾å¤‡å æœ‰çš„è¾“å…¥å½¢çŠ¶ä¸º b*(s/n)*h. åœ¨è®¡ç®— Attention ä¹‹å‰å¯¹ QKV è¿›è¡Œ All-to-All é€šä¿¡å˜æˆæŒ‰éšè—å±‚ç»´åº¦åˆ‡åˆ† ((a è¦èƒ½æ•´é™¤ n))ï¼Œé€šä¿¡é‡ä¸º 6Î±bsh/n bytes. è®¡ç®—å®Œ score@v ä¹‹åå†è¿›è¡Œä¸€æ¬¡ All-to-All é€šä¿¡ï¼Œé€šä¿¡é‡ä¸º 2Î±bsh/n bytesï¼Œæ€»è®¡é€šä¿¡é‡ä¸º 8Î±bsh/n bytes. æ¿€æ´»å ç”¨ä¸Š Attention ä¸­ Softmax åŠå…¶ dropout mask å’Œ attention æ²¡æœ‰è¢«åˆ‡åˆ†ï¼Œæ¿€æ´»å ç”¨é‡ä¸º bsh(34/n+5sa/h). å› æ­¤ï¼Œå®ƒä¸é€‚åˆ GQA å’Œ MQA æƒ…å†µ, GQA çš„å¹¶è¡Œåº¦è¢«é™åˆ¶åœ¨äº†ç»„æ•°ï¼ŒMQA åˆ™å®Œå…¨æ²¡æ³•ä½¿ç”¨ã€‚è€Œä¸”ç”±äºå¼ é‡å¹¶è¡Œä¹Ÿéœ€è¦åœ¨ a ç»´åº¦ä¸Šè¿›è¡Œåˆ’åˆ†ï¼ŒSP-Ulysses å’Œ TP æ˜¯å†²çªçš„ã€‚</p>
<h1 id="ring-attention-sequence-parallel">Ring-Attention Sequence Parallel<a hidden class="anchor" aria-hidden="true" href="#ring-attention-sequence-parallel">#</a></h1>
<p><a href="https://darkenstar.github.io/2024/09/26/Ring_Attention/#Putting-it-Together">Ring-SP</a> å®é™…ä¸Šä¸ºç¯çŠ¶çš„ FlashAttentionï¼Œå°†è¾“å…¥æ²¿ç€åºåˆ—ç»´åº¦åˆ‡åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œåœ¨ Attention è®¡ç®—è¿‡ç¨‹ä¸­æ¯ä¸ªè®¾å¤‡å‘ç›¸é‚»è®¾å¤‡é€šä¿¡ KV å¹¶æ›´æ–°è‡ªå·±çš„ Softmax çŸ©é˜µï¼Œé€šä¿¡é‡ä¸º 4bsh bytes. æ¿€æ´»å ç”¨å’Œ DS-SP ä¸€æ ·ä¸º bsh(34/n+5sa/h).</p>
<h1 id="unified-sequence-parallel">Unified Sequence Parallel<a hidden class="anchor" aria-hidden="true" href="#unified-sequence-parallel">#</a></h1>
<p><a href="https://darkenstar.github.io/2024/11/14/USP-A%20Unified%20Sequence%20Parallelism%20Approach%20for%20Long%20Context%20Generative%20AI/#Unified-Ulysses-Ring-Sequence-Parallelism">USP</a> å°† SP è¿›ç¨‹ç»„åˆ†å‰²æˆä¸¤ä¸ªæ­£äº¤çš„è¿›ç¨‹ç»„ï¼šSP-Ring è¿›ç¨‹ç»„å’Œ SP-Ulysses è¿›ç¨‹ç»„ã€‚å¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ª 2D mesh ï¼Œæ¯ä¸€åˆ—ä¸Šè¿è¡Œ SP-Ringï¼Œæ¯ä¸€è¡Œä¸Šè¿è¡Œ SP-Ulysses. å…·ä½“æ–¹æ³•ä¸º QKV çš„åˆ‡åˆ† å’Œ All-to-All å’Œ DS-Ulysses ç›¸åŒï¼Œç„¶åé‡‡ç”¨ Ring-Attention çš„æ–¹å¼è¿›è¡Œè®¡ç®—ã€‚å¦‚æœé‡åˆ°ä½¿ç”¨ casual mask çš„æƒ…å†µéœ€è¦åŠ ä¸Š balance load ç­–ç•¥ï¼ŒæŠŠåºåˆ—é•¿åº¦åˆ†ä¸º 2*(ring_degree) å¤§å°ï¼ŒæŒ‰ç…§ 0-&gt;1-&gt;&hellip;-&gt;(ring_degree-1)-&gt;(ring_degree-1)-&gt;&hellip;-&gt;0 çš„é¡ºåºè¿›è¡Œåˆ†é…ã€‚USP æ¶ˆé™¤äº† SP-ulyssesçš„å¤´æ•°é™åˆ¶ã€‚å¹¶ä¸” USPå¯ä»¥é€šè¿‡è°ƒæ•´ SP-Ulysses è¿›ç¨‹ç»„æ•°ç›®æ¥æ›´å¥½çš„é€‚åº”ä¸åŒå¸¦å®½çš„ç½‘ç»œç»“æ„ï¼Œå¯ä»¥è®© All-to-All æ“ä½œåœ¨é«˜å¸¦å®½ä¸­è¿è¡Œï¼Œè€Œå¼‚æ­¥ P2P é€šä¿¡åœ¨ä½å¸¦å®½éƒ¨åˆ†è¿è¡Œã€‚</p>
<h1 id="comparsion-of-different-parallelsim-in-training">Comparsion of Different Parallelsim in Training<a hidden class="anchor" aria-hidden="true" href="#comparsion-of-different-parallelsim-in-training">#</a></h1>
<table border="1">
  <tr>
    <th rowspan="2"></th>
    <th colspan="4" style="text-align: center;">Communication (FWD+BWD)</th>
    <th rowspan="2">Split Dim</th>
    <th colspan="3" style="text-align: center;">Memory</th>
  </tr>
  <tr>
    <th>Param</th>
    <th>Cost</th>
    <th>Act</th>
    <th>Cost</th>
    <th>P/G</th>
    <th>OS</th>
    <th>Act</th>
  </tr>
  <tr>
    <td>DS-SP</td>
    <td>AllReduce</td>
    <td>12O(hÂ²)</td>
    <td>8*All2All</td>
    <td>(8/N)O(bsh)</td>
    <td>a/s</td>
    <td>P+G</td>
    <td>6P</td>
    <td>A/N</td>
  </tr>
  <tr>
    <td>Ring-SP</td>
    <td>AllReduce</td>
    <td>12O(hÂ²)</td>
    <td>P2P</td>
    <td>4O(bsh)</td>
    <td>L/L</td>
    <td>P+G</td>
    <td>6P</td>
    <td>A/N</td>
  </tr>
  <tr>
    <td>DP</td>
    <td>AllReduce</td>
    <td>12O(hÂ²)</td>
    <td>0</td>
    <td>0</td>
    <td>b/b</td>
    <td>P+G</td>
    <td>6P</td>
    <td>A/N</td>
  </tr>
  <tr>
    <td>ZeRO1</td>
    <td>AllGather + ReduceScatter</td>
    <td>12O(hÂ²)</td>
    <td>0</td>
    <td>0</td>
    <td>a/s</td>
    <td>P+G</td>
    <td>6P/N </td>
    <td>A/N</td>
  </tr>
  <tr>
    <td>USP + ZeRO1</td>
    <td>AllGather + ReduceScatter</td>
    <td>12O(hÂ²)</td>
    <td>P2P + 8*All2All</td>
    <td>â‰¤ 4O(bsh)</td>
    <td>a/s</td>
    <td>P+G</td>
    <td>6P/N</td>
    <td>A/N</td>
  </tr>
  <tr>
    <td>USP + ZeRO2</td>
    <td>AllGather + ReduceScatter</td>
    <td>12O(hÂ²)</td>
    <td>P2P + 8*All2All</td>
    <td>â‰¤ 4O(bsh)</td>
    <td>a/s</td>
    <td>P+(G/N)</td>
    <td>6P/N</td>
    <td>A/N</td>
  </tr>
  <tr>
    <td>USP + ZeRO3</td>
    <td>2*AllGather + ReduceScatter</td>
    <td>18O(hÂ²)</td>
    <td>P2P + 8*All2All</td>
    <td>â‰¤ 4O(bsh)</td>
    <td>a/s</td>
    <td>(P+G)/N</td>
    <td>6P/N</td>
    <td>A/N</td>
  </tr>
  <tr>
    <td>TP</td>
    <td>0</td>
    <td>0</td>
    <td>4*AllReduce</td>
    <td>8O(bsh)</td>
    <td>a/h</td>
    <td>(P+G)/N</td>
    <td>6P/N</td>
    <td>Î±A</td>
  </tr>
  <tr>
    <td>Megatron-SP</td>
    <td>0</td>
    <td>0</td>
    <td>6*AllGather + 4*ReduceScatter</td>
    <td>10O(bsh)</td>
    <td>a/h</td>
    <td>(P+G)/N</td>
    <td>6P/N</td>
    <td>A/N</td>
  </tr>
</table>
<h1 id="analysis">Analysis<a hidden class="anchor" aria-hidden="true" href="#analysis">#</a></h1>
<ol>
<li>All2All é€šä¿¡ä½¿å¾— DS-SP çš„é€šä¿¡å¼€é”€å¤§äº DP. ä½¿ç”¨ Ring-SP æ—¶ï¼Œå°½ç®¡å¼‚æ­¥çš„ P2P é€šä¿¡æ˜¯å¯ä»¥é‡å çš„ï¼Œç†æƒ³çš„æ€§èƒ½ä¹Ÿæ˜¯åªä¸ DP ç›¸åŒã€‚å› æ­¤åªæœ‰å½“æ‰¹ batchsize ä¸è¶³ä»¥è¿›è¡Œåˆ‡åˆ†æ—¶æ‰è€ƒè™‘ä½¿ç”¨ SP.</li>
<li>Megatron-SP é€šä¿¡é‡é«˜äº DS-SP å’Œ Ring-SP. SP-Ring å¯¹äº KV çš„é€šä¿¡å¯ä»¥ä¸è®¡ç®—é‡å ã€‚Megatron-SP çš„é€šä¿¡é‡ä¸ä¼šéšç€å¹¶è¡Œåº¦çš„å¢åŠ è€Œå‡å°‘ï¼Œè€Œ DS-SP å¯ä»¥åšåˆ°ã€‚ DS-SP å’Œ Ring-SP å…·æœ‰è¾ƒä½çš„æ¿€æ´»é€šä¿¡æˆæœ¬ï¼Œä½†éœ€è¦åŒæ­¥æ¢¯åº¦å’Œå‚æ•°ã€‚ä¸è¿‡å‚æ•°é€šä¿¡é‡ç›¸å¯¹äºæ¿€æ´»é€šä¿¡é‡è¾ƒå°ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—è¿›è¡Œé‡å ã€‚GQA/MQA ä¹Ÿå¯ä»¥é™ä½å®ƒä¿©çš„é€šä¿¡æˆæœ¬ï¼Œè€Œ Megatron-SP ä¸å—å½±å“ã€‚</li>
<li>ç›¸åŒé…ç½®ä¸‹ä½¿ç”¨ USP+Zero3 æ¥ä»£æ›¿ Megatron-SP å¹¶ä¸ä¼šå¢åŠ å¯è®­ç»ƒåºåˆ—çš„é•¿åº¦ã€‚ä½†ä¸ Megatron-SP ç›¸æ¯”ï¼ŒUSP èƒ½åœ¨é€šè¿‡æé«˜å¹¶è¡Œåº¦æ¥å¢åŠ å¯ä»¥è®­ç»ƒçš„åºåˆ—é•¿åº¦ã€‚</li>
<li>Megatron-SP å¹¶è¡Œç»´åº¦å—é™äºæ³¨æ„åŠ›å¤´æ•°ç›®ã€‚USP å¯ä»¥é€šè¿‡æé«˜ Ring-SP çš„å¹¶è¡Œåº¦æ¥æ‰©å±•ï¼Œä»¥åœ¨å¤§è§„æ¨¡é…ç½®ä¸‹è®­ç»ƒæ›´å¤§æ¨¡å‹ã€‚</li>
</ol>
<h1 id="sora-inference-modeling-analysis-process">Sora Inference Modeling Analysis Process<a hidden class="anchor" aria-hidden="true" href="#sora-inference-modeling-analysis-process">#</a></h1>
<p>æˆ‘ä»¬éœ€è¦å‡†å¤‡æ¨¡å‹çš„è¾“å…¥ï¼š</p>
<ol>
<li>éšç©ºé—´é‡‡æ ·çš„å™ªå£° zï¼Œå½¢çŠ¶ä¸æƒ³ç”Ÿæˆçš„è§†é¢‘æ—¶å¸¸å’Œåˆ†è¾¨ç‡ç›¸å…³ã€‚ç”Ÿæˆ 1s çš„è§†é¢‘ä¸º 25.5 framesï¼Œç»è¿‡ VAE Encoder åè¾“å‡ºçš„é€šé“æ•°ä¸º 4ï¼Œå¸§æ•°ä¼šè¢«å‹ç¼©åˆ° <code>num_frame*5//17</code>ï¼Œåˆ†è¾¨ç‡çš„é•¿å®½åˆ†åˆ«è¢«å‹ç¼©åˆ°åŸæ¥çš„ 1/8. å› æ­¤ z çš„å½¢çŠ¶åº”è¯¥ä¸º <code>(B, 4, num_frame*5//17, img_size[0]//8, img_size[1]//8)</code>.</li>
<li>è¾“å…¥çš„ prompt ä¼šç»è¿‡ DeepFloyd/t5-v1_1-xxl ç¼–ç ï¼Œè¯¥ç¼–ç å™¨æœ€å¤§çš„ token æ•°ä¸º 300ï¼Œç¼–ç ç»´åº¦ä¸º 4096ï¼Œæ–‡æœ¬é•¿åº¦ä¸è¶³æ—¶ä¼šå¡«å……åˆ° 300. å› æ­¤ç¼–ç åçš„ prompt çš„å½¢çŠ¶ä¸º <code>(B, 1, 300, 4096)</code>.</li>
<li>å½“å‰å»å™ªçš„æ—¶é—´æ­¥ tï¼Œå½¢çŠ¶ä¸º <code>(B, )</code></li>
<li>ç”Ÿæˆè§†é¢‘çš„ fpsï¼Œå½¢çŠ¶ä¸º <code>(1, )</code></li>
</ol>
<p>è¿˜éœ€è¦å‡†å¤‡ç›¸å…³çš„æ¨¡å‹é…ç½®ï¼ŒåŒ…æ‹¬ mesh å½¢çŠ¶ï¼Œsub_mesh çš„å½¢çŠ¶ï¼Œå¹¶è¡Œç­–ç•¥ä»¥åŠ stage_ids. å¦‚æœéœ€è¦å°†æ¨¡å‹çš„ transformer block åˆ‡åˆ†æˆå¤šæ®µï¼Œåˆ™éœ€è¦é…ç½® sub_mesh å’Œ stage_ids.</p>
<ul>
<li>mesh_shape: (num_x, num_y)</li>
<li>submesh_shape: <code>[(num_x, num_y, loc_x, loc_y), ]</code></li>
<li>stage_ids: <code>[(submesh0_start, submesh0_end), ]</code></li>
<li>strategy: å¹¶è¡Œç­–ç•¥</li>
</ul>
<p>ç„¶ååˆå§‹åŒ–æ¨¡å‹ï¼ŒSora çš„æ•´ä½“ç»“æ„å¦‚ä¸‹ æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ª Pipeline(åŒ…å«æ•´ä¸ªæµç¨‹çš„å‡½æ•°)ï¼Œå®ƒä¼šæœ‰ä¸€ä¸ªæˆ–å¤šä¸ª Stage ç”¨äºä¿å­˜æ¨¡å‹çš„ä¸åŒå±‚ï¼Œä¸ stage_ids ä¸­å¯¹åº”ã€‚æˆ‘ä»¬å°†æ¨¡å‹åˆ†è§£æˆ Embedding_blocks(PatchEmbed3D, TimestepEmbedder, SizeEmbedder, Captionembedder, t_block), STDiT3_blocks å’Œ T2IFinalLayer. å°†è¿™ä¸ªåˆ†è§£å‡½æ•°ä½œä¸º Pipeline çš„ sharding_func.</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB9688e46ada2523df1ec522a7649be19a?method=download&amp;shareKey=991eba9aad6eca9f41599d2ad4f75c34" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB9688e46ada2523df1ec522a7649be19a?method=download&amp;shareKey=991eba9aad6eca9f41599d2ad4f75c34" alt="Open-Sora">
    </a><figcaption>Open-Sora</figcaption></figure></p>
<h2 id="init-pipeline">Init Pipeline<a hidden class="anchor" aria-hidden="true" href="#init-pipeline">#</a></h2>
<p>æˆ‘ä»¬éœ€è¦æ ¹æ®é…ç½®ä»¥åŠ PipePatch å¹¶è¡Œåº¦å’Œ SP å¹¶è¡Œåº¦åˆå§‹åŒ– Pipeline. è¿™å…¶ä¸­ä¼šæ ¹æ® stage_ids åˆ†é…æ¯ä¸ª Stage ä¿å­˜æ¨¡å‹çš„å“ªäº›å±‚ä»¥åŠå¯¹åº”çš„ submesh å¤§å°ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">construct_stages</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">submeshes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">],</span> <span class="n">stages_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># construct layers for each stage</span>
</span></span><span class="line"><span class="cl">    <span class="n">first_part</span><span class="p">,</span> <span class="n">module_list</span><span class="p">,</span> <span class="n">last_part</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">modules</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stages_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">submesh</span> <span class="o">=</span> <span class="n">submeshes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">stage_id</span> <span class="o">=</span> <span class="n">stages_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># get stage layers from user config stage ids in module list</span>
</span></span><span class="line"><span class="cl">        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">module_list</span><span class="p">[</span><span class="n">stage_id</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">stage_id</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">first_part</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># concat module first part(if exists) bef module list to stage_0</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span> <span class="o">=</span> <span class="n">first_part</span> <span class="o">+</span> <span class="n">layers</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="n">num</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">last_part</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># concat module last part(if exists) aft module list to last stage</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">last_part</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># deepcopy module for xla device tracing use</span>
</span></span><span class="line"><span class="cl">        <span class="n">stage_module</span> <span class="o">=</span> <span class="p">[</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">Stage</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">stage_module</span><span class="p">,</span> <span class="n">submesh</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">modules</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="write-sharding-function">Write Sharding Function<a hidden class="anchor" aria-hidden="true" href="#write-sharding-function">#</a></h2>
<p>è¦æ ¹æ®é€‰æ‹©çš„ä¸åŒçš„å¹¶è¡Œç­–ç•¥å¯¹æ¯ä¸ª Stage çš„æ¨¡å‹æƒé‡ï¼Œè¾“å…¥ï¼Œè¾“å‡ºè¿›è¡Œåˆ‡åˆ†ã€‚è¿™é‡ŒåŒæ ·æˆ‘ä»¬å•ç‹¬å¤„ç† Embedding_blocks, STDiT3_blocks å’Œ T2IFinalLayer. è®© stage0 åŒ…æ‹¬å¯¹ Embedding_blocks çš„å¤„ç†ï¼Œstage(N-1) åŒ…æ‹¬å¯¹ T2IFinalLayer çš„å¤„ç†ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ DS-ulysses æˆ‘ä»¬éœ€è¦å¯¹ <a href="mailto:Q@K.T">Q@K.T</a> çš„ç»“æœ å’Œ S@V çš„ç»“æœä¹Ÿè¿›è¡Œåˆ‡åˆ† SPMD æ‰ä¼šæ’å…¥æ­£ç¡®çš„ All2Allï¼Œå› æ­¤è¿™éƒ¨åˆ†åªèƒ½æ”¾åœ¨ç½‘ç»œçš„ forward é‡Œé¢è¿›è¡Œã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">shard_sora_one_stage</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># first 5 modules are embedding layers</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_embedding</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">total_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard spatial</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard temporal</span>
</span></span><span class="line"><span class="cl">    <span class="n">shard_sora_final</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">shard_sora_first_stage</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_embedding</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">modules</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard spatial</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard temporal</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">shard_sora_stage</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard spatial</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard temporal</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">shard_sora_last_stage</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_len</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard spatial</span>
</span></span><span class="line"><span class="cl">        <span class="n">shard_sora_block</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>  <span class="c1"># shard temporal</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># skip norm layer mark sharding</span>
</span></span><span class="line"><span class="cl">    <span class="n">shard_sora_final</span><span class="p">(</span><span class="n">modules</span><span class="p">[</span><span class="n">total_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">shard_strategy</span><span class="p">,</span> <span class="n">mesh</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="construct-pipeline">Construct Pipeline<a hidden class="anchor" aria-hidden="true" href="#construct-pipeline">#</a></h2>
<p>ç„¶åä¸ºäº†å¤„ç†å¤š stage çš„æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æ¯ä¸ª stage çš„è¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶ã€‚è¿™ä¸€æ­¥ç›¸å½“äºæ”¾åˆ° cuda ä¸Šé‡èµ°ä¸€éæ•´ä¸ªæ¨¡å‹çš„ forwardï¼Œè®°å½•ä¸‹æ¯ä¸€å±‚è¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶ï¼Œä¿å­˜ä¸º json ä¸€éã€‚å®é™…ä¸Šå¯¹äºæ¯ä¸ªå›ºå®šç”Ÿæˆå¤§å°çš„è§†é¢‘è¿›è¡Œä¸€æ¬¡å°±è¡Œï¼Œä¸‹æ¬¡ç›´æ¥è¯»å–è¿™ä¸ªæ–‡ä»¶ã€‚å› ä¸ºç°åœ¨éƒ½é‡‡ç”¨ <a href="https://facebookresearch.github.io/xformers/components/ops.html">xformers.ops.memory_efficient_attention</a>ï¼Œéœ€è¦è¾“å…¥å¼ é‡åœ¨ cuda ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åœ¨æ¨¡å‹çš„ forward å‡½æ•°ä¸­å†™ä¸€ä¸ª navie çš„ attention è®¡ç®—æµç¨‹å¥½è®© torch_xla èƒ½å¯¹å¼ é‡è¿›è¡Œè·Ÿè¸ªã€‚</p>
<h2 id="trace-mhlo-graph">Trace mhlo Graph<a hidden class="anchor" aria-hidden="true" href="#trace-mhlo-graph">#</a></h2>
<p>æ ¹æ®ä¸Šä¸€æ­¥å¾—åˆ°çš„æ¯ä¸ª Stage çš„è¾“å…¥å½¢çŠ¶ï¼Œåˆ›å»ºè¾“å…¥å¼ é‡ï¼Œæ”¾å…¥ xla_device ä¸Šï¼Œæ‰§è¡Œ forward. æœ€åå¯¼å‡ºè¾“å‡ºçš„ mhlo è®¡ç®—å›¾ã€‚è¿™é‡Œéœ€è¦æ³¨æ„ç¬¬ä¸€ä¸ª stage åŒ…å«å¤šä¸ªéè¿ç»­çš„æ¨¡å—ï¼Œå› æ­¤éœ€è¦å•ç‹¬å¤„ç†ï¼Œæœ€åä¸€ä¸ª stage æœ€åä¸€å±‚çš„è¾“å…¥ä¸å…¶ä»– block ä¸åŒï¼Œå› æ­¤ä¹Ÿè¦å•ç‹¬å¤„ç†ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">trace_stage_mhlo_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">check_res</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    trace stage nn modules to mhlo graph
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (NOTE): construct xla mesh before trace tensors generate,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># i.e., before any xla device call to avoid xla computation client construct</span>
</span></span><span class="line"><span class="cl">    <span class="n">xla_mesh</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">xla_mesh</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_stage_xla_mesh</span><span class="p">()</span>  <span class="c1"># create mesh from submesh info</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Create xla device trace tensors, move module to xla device</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">trace_tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_trace_tensors</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_id</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">outputs</span>
</span></span><span class="line"><span class="cl">        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">y_embedded</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">xm</span><span class="o">.</span><span class="n">xla_device</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">t_mlp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">t_mlp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">xm</span><span class="o">.</span><span class="n">xla_device</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">trace_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">t_mlp</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">module</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">mod</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">xm</span><span class="o">.</span><span class="n">xla_device</span><span class="p">())</span>  <span class="c1"># first load to cpu</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">module</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">xm</span><span class="o">.</span><span class="n">xla_device</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># get pipeline exec mode</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="n">exec_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span><span class="o">.</span><span class="n">exec_mode</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># load lora cofifg</span>
</span></span><span class="line"><span class="cl">    <span class="n">lora_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span><span class="o">.</span><span class="n">lora_config</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Enter trace mhlo graph for stage: &#34;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Trigger shard func to mark sharding the model</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">shard_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard_strategy</span><span class="p">,</span> <span class="n">xla_mesh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">exec_mode</span> <span class="o">==</span> <span class="n">EXEC_MODE</span><span class="o">.</span><span class="n">INFER</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># set stage name &amp; dump file path</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_set_stage_name_dump_file</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">exec_mode</span><span class="p">,</span> <span class="s2">&#34;fw&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_sampling_steps</span> <span class="o">=</span> <span class="mi">30</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_timesteps</span> <span class="o">=</span> <span class="mi">1000</span>
</span></span><span class="line"><span class="cl">        <span class="n">timesteps</span> <span class="o">=</span> <span class="p">[(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">i</span> <span class="o">/</span> <span class="n">num_sampling_steps</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_timesteps</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sampling_steps</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># FIXME: åŸå…ˆæ˜¯ä¸ºæ¯ä¸ªstageå•ç‹¬ç”Ÿæˆtrace_tensor, ç°åœ¨è¦æŠŠä¸Šä¸€ä¸ªçš„ç»“æœä¼ ç»™ä¸‹ä¸€ä¸ª stage</span>
</span></span><span class="line"><span class="cl">        <span class="c1">#for i in range(30):</span>
</span></span><span class="line"><span class="cl">        <span class="n">start</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span><span class="o">.</span><span class="n">pipeline_patches_height_list</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_id</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_id</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_pipeline</span><span class="o">.</span><span class="n">pipeline_patches_height_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_id</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">trace_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">...</span><span class="p">,</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">,:]]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">xla_mesh</span><span class="p">)</span>  <span class="c1"># outputs is a list</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trace_tensors</span><span class="p">,</span> <span class="n">xla_mesh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">check_res</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># check xla results compared to gpu results</span>
</span></span><span class="line"><span class="cl">            <span class="n">check_result_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># use torch xla _get_xla_tensors_hlo interface</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># to eliminate redundant live tensors as ret values</span>
</span></span><span class="line"><span class="cl">            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;XLA_DUMP_POST_OPTIMIZATIONS&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;true&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch_xla</span><span class="o">.</span><span class="n">_XLAC</span><span class="o">.</span><span class="n">_get_xla_tensors_hlo</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="analyze-mhlo-graph">Analyze mhlo Graph<a hidden class="anchor" aria-hidden="true" href="#analyze-mhlo-graph">#</a></h2>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬è¦éå†ä¸Šä¸€æ­¥å¾—å‡ºçš„ mhlo å›¾ã€‚</p>
<h3 id="opview">OpView<a hidden class="anchor" aria-hidden="true" href="#opview">#</a></h3>
<p>ä»æ ¹èŠ‚ç‚¹çš„ ir å¼€å§‹éå†ä¸Šä¸€æ­¥å¯¼å‡ºçš„æ•´ä¸ªè®¡ç®—å›¾ã€‚æ ¹æ®ä¼ å…¥ ir çš„ç±»å‹å®šä¹‰è°ƒç”¨å¯¹åº”çš„ visit å‡½æ•°è¯»å–å…¶å±æ€§è¿›è¡Œæ“ä½œã€‚ä¸»è¦é€šè¿‡ rsqrt çš„ä½ç½®æ¥åˆ’åˆ†ä¸€ä¸ª Transformer block ä¸­ç¬¬å‡ ä¸ª dot å’Œ dot_general å¯¹åº”çš„æ˜¯ä»€ä¹ˆæ“ä½œã€‚å¯¹äº Sora æ¥è¯´åˆ’åˆ†æƒ…å†µå¦‚ä¸‹ã€‚è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ mhlo å›¾è®°å½•çš„æ˜¯æ‹“æ‰‘æ’åºçš„é¡ºåºï¼Œä¸æ˜¯ç¨‹åºé¡ºåºæ‰§è¡Œçš„é¡ºåºï¼Œå› æ­¤ç¬¬ä¸€ä¸ª block ä¼šæºæ‚ç€ Embedding_blocks çš„ä¸€äº› dot æ“ä½œã€‚å› æ­¤æˆ‘ä»¬ä»ç¬¬äºŒä¸ª block çš„ç¬¬ä¸€ä¸ª rsqrt ä½ç½®å¼€å§‹ç»Ÿè®¡ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">collect_rms_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">rms_collector</span> <span class="o">=</span> <span class="n">RMSCollector</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">rms_collector</span><span class="o">.</span><span class="n">visit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root_op</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="bp">self</span><span class="o">.</span><span class="n">rms_locs</span> <span class="o">=</span> <span class="n">rms_collector</span><span class="o">.</span><span class="n">rms_locs</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># construct attention block &amp; ffn block ranges</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># exclude the rsqrt in T2IFinalLayer</span>
</span></span><span class="line"><span class="cl">  <span class="n">att_rm_locs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rms_locs</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rms_locs</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">rms_locs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">att_rm_locs</span><span class="p">),</span> <span class="mi">4</span><span class="p">):</span>  <span class="c1"># a block has 4 rsqrt, start from 2nd block to avoid embedding</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">spt_qkv_ranges</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">att_rm_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">0</span><span class="p">],</span> <span class="n">att_rm_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">spt_attn_ranges</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">att_rm_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">],</span> <span class="n">att_rm_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">cro_attn_ranges</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">att_rm_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">],</span> <span class="n">att_rm_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">att_rm_locs</span><span class="p">),</span> <span class="mi">4</span><span class="p">):</span>  <span class="c1"># ORG: range(8, len(att_rm_locs), 4): </span>
</span></span><span class="line"><span class="cl">      <span class="n">start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rms_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">i</span><span class="o">+</span><span class="mi">4</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rms_locs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">          <span class="n">end</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">      <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rms_locs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">4</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">ffn_ranges</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><table>
  <thead>
      <tr>
          <th>module</th>
          <th>operator</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td></td>
          <td><code>RMSNorm(x)</code></td>
      </tr>
      <tr>
          <td><strong>Self Attention</strong></td>
          <td><code>dot(x, qkvLinear.weight)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>RMSNorm(q)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>RMSNorm(k)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot_general(q, k)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot_general(s, v)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot(attn, oLinear.weight)</code></td>
      </tr>
      <tr>
          <td><strong>Cross Attention</strong></td>
          <td><code>dot(x, qLinear.weight)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot(y, kvLinear.weight)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot_general(q, k)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot_general(s, v)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot(attn, oLinear.weight)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>RMSNorm(x) </code></td>
      </tr>
      <tr>
          <td><strong>Feed Forward Network</strong></td>
          <td><code>dot(x, upLinear.weight)</code></td>
      </tr>
      <tr>
          <td></td>
          <td><code>dot(x, downLinear.weight)</code></td>
      </tr>
  </tbody>
</table>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">visit_dot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">dot_lineno</span> <span class="o">=</span> <span class="n">_parse_loc_lineno</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_cnt</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spt_attn_ranges</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">spt_att_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spt_attn_ranges</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">block_cnt</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">cro_att_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cro_attn_ranges</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">block_cnt</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">spt_qkv_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spt_qkv_ranges</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">block_cnt</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">ffn_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_ranges</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">block_cnt</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># lie in RMS ops closed attention block</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">dot_lineno</span> <span class="o">&gt;</span> <span class="n">spt_att_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">dot_lineno</span> <span class="o">&lt;</span> <span class="n">spt_att_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="c1">#import pdb;pdb.set_trace()</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">att_block_dots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">spt_dot_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="k">elif</span> <span class="n">dot_lineno</span> <span class="o">&gt;</span> <span class="n">cro_att_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">dot_lineno</span> <span class="o">&lt;</span> <span class="n">cro_att_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">att_block_dots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">cro_att_dot_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># lie ffn block</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">dot_lineno</span> <span class="o">&gt;</span> <span class="n">spt_qkv_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">dot_lineno</span> <span class="o">&lt;</span> <span class="n">spt_qkv_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">spt_qkv_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ffn_block_dots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># pixart pass</span>
</span></span><span class="line"><span class="cl">        <span class="k">elif</span> <span class="n">dot_lineno</span> <span class="o">&gt;</span> <span class="n">ffn_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">ffn_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">dot_lineno</span> <span class="o">&lt;</span> <span class="n">ffn_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                    <span class="bp">self</span><span class="o">.</span><span class="n">ffn_block_dots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dot_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dot_cnt</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>                 
</span></span><span class="line"><span class="cl">                    <span class="bp">self</span><span class="o">.</span><span class="n">ffn_block_dots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dot_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Traversal of one block</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spt_qkv_cnt</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">spt_att_dot_cnt</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> \
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">spt_dot_cnt</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dot_cnt</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">attention_blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att_block_dots</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ffn_blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffn_block_dots</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">block_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># reset each block level counters</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">spt_qkv_cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">spt_att_dot_cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">spt_dot_cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dot_cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">att_block_dots</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ffn_block_dots</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">generic_visit</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ä¿å­˜å¥½ä¸€ä¸ª Transformer block ä¸­æ¯ä¸ª dot æˆ– dotgeneral å¯¹åº”çš„æ˜¯ä»€ä¹ˆæ“ä½œåï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥è®¿é—®è¿™ä¸ª ir. è¿™é‡Œéœ€è¦æ³¨æ„åªè¦ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µæœ‰ä¸€ä¸ªæ˜¯äºŒç»´å¼ é‡ (æ¯”å¦‚çº¿æ€§å±‚çš„æƒé‡)ï¼Œmhlo éƒ½ä¼šå°†å¦ä¸€ä¸ª reshape æˆäºŒç»´å¼ é‡ã€‚dot ç®—å­ (<code>jaxlib.mlir.dialects._mhlo_ops_gen.DotOp</code>) ä¸¤ä¸ªæ“ä½œæ•°éƒ½æ˜¯äºŒç»´çš„å¼ é‡ï¼ŒqkvLinear å¯¹åº”çš„æ˜¯ç¬¬ä¸€ä¸ª dot æ“ä½œã€‚å·¦æ“ä½œæ•°çš„ shape ä¸º <code>(BST,3C)</code>. å½“ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µéƒ½æ˜¯ 3 ç»´åŠä»¥ä¸Šå¼ é‡çš„æ—¶å€™å°±ä¼šç”Ÿæˆ dot_general è¯¥ç®—å­çš„ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µéƒ½ä¼šè¢« reshape æˆä¸‰ç»´å¼ é‡ã€‚Self-Attention çš„ç¬¬ä¸€ä¸ª dot_general å·¦æ“ä½œæ•°çš„ shape ä¸º <code>(BTN_A,S,C)</code>. è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ° <code>BT=(BST)/S, N_A=(BTN_A)/(BT)</code>. åŒæ ·æˆ‘ä»¬å¯ä»¥å¾—åˆ° OLinear, FFN ä¸­ upLinear å’Œ downLinear æƒé‡çš„å½¢çŠ¶. ä»¥åŠ Cross-Attention æ¨¡å—çš„å¯¹åº”ä¿¡æ¯ã€‚ç”±äºä¹‹å‰éå†æ˜¯ä»ç¬¬äºŒä¸ª block å¼€å§‹çš„ï¼Œå› æ­¤æ€»å±‚æ•°è¦ ï¼‹1. æœ€åå°†å¾—åˆ°çš„å‚æ•°æ‰“åŒ…æˆä¸€ä¸ªå­—å…¸è¿”å›ã€‚</p>
<h3 id="communication-view">Communication View<a hidden class="anchor" aria-hidden="true" href="#communication-view">#</a></h3>
<p>æˆ‘ä»¬ä»¥åŒæ ·çš„æ–¹å¼å®šä¹‰å„ç§é›†åˆé€šä¿¡ç®—å­çš„ visit å‡½æ•°ç”¨äºè¯„ä¼°è¯¥ç®—å­çš„é€šä¿¡é‡ï¼Œéå†åˆ°å¯¹åº”çš„ ir åè°ƒç”¨å®ƒã€‚</p>
<p>AllReduce å°†æ‰€æœ‰çš„æ•°æ®é€šè¿‡è§„çº¦æ“ä½œé›†æˆåˆ°å„ä¸ªè®¾å¤‡ä¸­ã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB6e4d9c026bc0632af5040321998fb3ab?method=download&amp;shareKey=f901430ac6bfa781d0b462f0170981d3" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB6e4d9c026bc0632af5040321998fb3ab?method=download&amp;shareKey=f901430ac6bfa781d0b462f0170981d3" alt="AllReduce">
    </a><figcaption>AllReduce</figcaption></figure></p>
<p>åœ¨ Ring-AllReduce çš„ ReduceScatter æ­¥éª¤ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹å‘é€ M ä¸ªå…ƒç´  N-1 æ¬¡ï¼Œæ€»å…±ä¸º M(N-1). åœ¨ AllGather æ­¥éª¤ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹å‘é€å®ƒè®¡ç®—çš„å—çš„ç»“æœã€‚è¿™æ˜¯é¢å¤–çš„ M ä¸ªå…ƒç´ å‘é€äº† N-1 æ¬¡ã€‚æ€»çš„é€šä¿¡é‡åŠ èµ·æ¥æ˜¯ 2M(N-1).</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB69d2b3957cd1863481bff0e785dc9a82?method=download&amp;shareKey=32e60903bafe5dbf240af91c67486e1b" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB69d2b3957cd1863481bff0e785dc9a82?method=download&amp;shareKey=32e60903bafe5dbf240af91c67486e1b" alt="Ring-AllReduce">
    </a><figcaption>Ring-AllReduce</figcaption></figure></p>
<p>All-Gather ç¤ºæ„å›¾å¦‚ä¸‹ï¼Œæ¯ä¸ªè®¾å¤‡å¼€å§‹æ‹¥æœ‰åˆå§‹çš„ä¸€éƒ¨åˆ†æ•°æ®ï¼Œé€šä¿¡åæ¯ä¸ªè®¾å¤‡éƒ½æœ‰ä¸€ä»½å®Œæ•´çš„æ•°æ®ã€‚æ€»çš„é€šä¿¡é‡ä¸º M(N-1).</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBe7e6e7a1230ed9ba7ba037556e489d51?method=download&amp;shareKey=5afdf2b669a500a6844aa9e281fe1ac3" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBe7e6e7a1230ed9ba7ba037556e489d51?method=download&amp;shareKey=5afdf2b669a500a6844aa9e281fe1ac3" alt="AllGather">
    </a><figcaption>AllGather</figcaption></figure></p>
<p>All2All ç¤ºæ„å›¾å¦‚ä¸‹ï¼Œæ¯ä¸ªè®¾å¤‡æŠŠè‡ªå·±çš„ç¬¬ i å—æ•°æ®å‘é€ç»™ç¬¬ i ä¸ªè®¾å¤‡ã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBddc785dcc80dd741fc1f469a85823cd4?method=download&amp;shareKey=085c0a5681116b4e1683d4d6ae5d080f" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBddc785dcc80dd741fc1f469a85823cd4?method=download&amp;shareKey=085c0a5681116b4e1683d4d6ae5d080f" alt="All2All">
    </a><figcaption>All2All</figcaption></figure></p>
<p>åŸºäº Bruck ç®—æ³•çš„ All2All æµç¨‹å¦‚ä¸‹</p>
<ol>
<li>å±€éƒ¨å¾ªç¯ç§»ä½ (Local Shift of Data-Blocks)
æ¯ä¸ªè¿›ç¨‹å°†å…¶æœ¬åœ°çš„æ•°æ®å—é‡æ–°æ’åˆ—ï¼Œè¿›è¡Œåˆå§‹çš„å¾ªç¯ç§»ä½ã€‚å¯¹äºè¿›ç¨‹ p å’Œæ•°æ®å—ç´¢å¼• i: R[i]=S[(p+i)%P]. å…¶ä¸­ S[i] æ˜¯è¿›ç¨‹æœ¬åœ°åˆå§‹çš„æ•°æ®ï¼ŒR[i] æ˜¯ç§»ä½åçš„æ•°æ®ã€‚</li>
<li>å…¨å±€é€šä¿¡ (Global Communication)
ä¸€å…±è¿›è¡Œ log(P) æ¬¡é€šä¿¡ã€‚
æ¯ä¸€æ­¥ä¸­æ¯ä¸ªè¿›ç¨‹å°†ä¸€éƒ¨åˆ†æ•°æ®å‘é€ç»™ç›¸é‚»çš„è¿›ç¨‹ï¼Œå¹¶æ¥æ”¶ç›¸é‚»è¿›ç¨‹å‘é€çš„æ•°æ®ã€‚è‹¥æ•°æ®å—ç´¢å¼• i ç”¨ radix-2 è¡¨ç¤ºçš„ç¬¬ k ä½ä¸º 1ï¼Œåˆ™æ•°æ®å—ä¼šè¢«å‘é€åˆ°ç›®æ ‡è¿›ç¨‹ã€‚
å¯¹äºè¿›ç¨‹ p: å‘é€æ•°æ®åˆ°è¿›ç¨‹ ((p + 2^k) % P)ï¼Œæ¥æ”¶æ¥è‡ªè¿›ç¨‹ ((p - 2^k) % P) çš„æ•°æ®ã€‚
æ¯æ¬¡å‘é€åï¼Œè¿›ç¨‹å°†æ¥æ”¶åˆ°çš„æ•°æ®æ›´æ–°åˆ°å…¶æœ¬åœ°æ•°æ®ä¸­ã€‚</li>
<li>å±€éƒ¨é€†å‘ç§»ä½ (Local Inverse Shift of Data-Blocks)
åœ¨å®Œæˆæ‰€æœ‰å…¨å±€é€šä¿¡ä¹‹åï¼Œæ¯ä¸ªè¿›ç¨‹æ‰§è¡Œé€†å‘ç§»ä½ï¼Œä»¥æ¢å¤æ•°æ®å—çš„æ­£ç¡®é¡ºåºã€‚å¯¹äºæ¯ä¸ªæ•°æ®å—ç´¢å¼• i: R[i]=R[(pâˆ’i+P)%P]</li>
</ol>
<p>åœ¨è¿›ç¨‹æ˜¯ 2 æ¬¡å¹‚çš„æƒ…å†µä¸‹æ¯ä¸ªè®¾å¤‡æ¯æ¬¡è¦é€šä¿¡ M*P/2å¤§å°çš„æ•°æ®ï¼Œæ€»å…±ä¸º MPlog(P)/2.</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBa083a4c6002019e62b23c0b24b59a812?method=download&amp;shareKey=58f1b8055307d53e43ce86b9e1762989" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBa083a4c6002019e62b23c0b24b59a812?method=download&amp;shareKey=58f1b8055307d53e43ce86b9e1762989" alt="Example of the Bruck Algorithm with 4 Processes">
    </a><figcaption>Example of the Bruck Algorithm with 4 Processes</figcaption></figure></p>
<h3 id="tflops-view">TFLOPS View<a hidden class="anchor" aria-hidden="true" href="#tflops-view">#</a></h3>
<p>è®¡ç®—é‡ä¸»è¦åˆ†æˆä¸¤ç§ï¼Œelement-wise çš„æ“ä½œè®¡ç®—é‡ä¸ºå…ƒç´ ä¸ªæ•°ã€‚ä¸¤ä¸ªå½¢çŠ¶åˆ†åˆ«ä¸º mxk å’Œ kxn çš„çŸ©é˜µç›¸ä¹˜è®¡ç®—é‡ä¸º 2mkn. è¢«è®¡å…¥ element-wise æ“ä½œçš„ç®—å­æœ‰ add, subtract, multiply, divide, rsqrt, negate, exponential. è¢«è®¡å…¥çŸ©é˜µä¹˜æ³•çš„ç®—å­æœ‰ dot, dot_general.</p>
<h2 id="performance-analysis">Performance Analysis<a hidden class="anchor" aria-hidden="true" href="#performance-analysis">#</a></h2>
<p>æˆ‘ä»¬æ ¹æ®æå–å‡ºçš„ Transformer block çš„ä¿¡æ¯é€å…¥æ€§èƒ½åˆ†æå™¨è¿›è¡Œåˆ†æ. tx8 çš„é…ç½®å¦‚ä¸‹</p>
<table>
  <thead>
      <tr>
          <th>Parameter</th>
          <th>Value</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>TILE_NUM</td>
          <td>16</td>
      </tr>
      <tr>
          <td>SRAM (MB)</td>
          <td>3</td>
      </tr>
      <tr>
          <td>NOC BW (GB/s)</td>
          <td>128</td>
      </tr>
      <tr>
          <td>DRAM BW (GB/s)</td>
          <td>100</td>
      </tr>
      <tr>
          <td>DRAM LATENCY (us)</td>
          <td>0.1</td>
      </tr>
      <tr>
          <td>GEMM (TFLOPS)</td>
          <td>8</td>
      </tr>
      <tr>
          <td>VECTOR (TOPS)</td>
          <td>0.0625</td>
      </tr>
      <tr>
          <td>HOP LATENCY (us)</td>
          <td>0.01</td>
      </tr>
  </tbody>
</table>
<p>æ ¹æ®æå–å‡ºçš„ä¿¡æ¯æ„å»ºçš„ STDiT çš„ spt_blk, tmp_blk, cross_blk çš„å‚æ•°å­—å…¸å¦‚ä¸‹.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">spatial_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;B&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;B_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;S_Q&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_Q_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;S_KV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_KV_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;D_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_QKV&#34;</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                  <span class="s2">&#34;H_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_QKV&#34;</span><span class="p">],</span> <span class="s2">&#34;N_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;N_A&#34;</span><span class="p">],</span> <span class="s2">&#34;H_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_A&#34;</span><span class="p">],</span> <span class="s2">&#34;D_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_O_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;H_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_O_spt&#34;</span><span class="p">]</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="n">temporal_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;B&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;B_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;S_Q&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_Q_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;S_KV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_KV_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;D_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_QKV&#34;</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                  <span class="s2">&#34;H_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_QKV&#34;</span><span class="p">],</span> <span class="s2">&#34;N_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;N_A&#34;</span><span class="p">],</span> <span class="s2">&#34;H_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_A&#34;</span><span class="p">],</span> <span class="s2">&#34;D_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_O_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;H_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_O_tmp&#34;</span><span class="p">]</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="n">cross_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;B&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;B_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;S_Q&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_Q_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;S_KV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_KV_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;D_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_QKV&#34;</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;H_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_QKV&#34;</span><span class="p">],</span><span class="s2">&#34;N_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;N_A&#34;</span><span class="p">],</span> <span class="s2">&#34;H_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_A&#34;</span><span class="p">],</span> <span class="s2">&#34;D_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_O_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;H_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_O_cro&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;D_FU&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_FU&#34;</span><span class="p">],</span> <span class="s2">&#34;H_FU&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_FU&#34;</span><span class="p">],</span> <span class="s2">&#34;D_FD&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_FD&#34;</span><span class="p">],</span> <span class="s2">&#34;H_FD&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_FD&#34;</span><span class="p">]}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>æ ¹æ®è¿™äº›å‚æ•°å†æ„å»ºæ¯ä¸ªå±‚çš„è¾“å…¥è¾“å‡ºå½¢çŠ¶ï¼Œè®¡ç®—ç±»å‹å’Œè®¡ç®—é‡ï¼Œä»¥ <code>Gate_ResAdd</code> ä¸ºä¾‹:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">GB</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">30</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Gate_ResAdd</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">  Construct each op after MHSA on the config file
</span></span></span><span class="line"><span class="cl"><span class="s1">  &#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># {name:{type:&#34;&#34;, size:&#34;&#34;, ishape:[], wshape:[]/None, oshape:[]}}</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">ops</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">construct_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">construct_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">GB</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">30</span>
</span></span><span class="line"><span class="cl">      <span class="n">ResAdd_input_shape</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;S_Q&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;D_O&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">      <span class="n">ResAdd_weight_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;D_O&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">      <span class="n">ResAdd_output_shape</span> <span class="o">=</span> <span class="n">ResAdd_input_shape</span>
</span></span><span class="line"><span class="cl">      <span class="n">ResAdd_compute</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">ResAdd_input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">ResAdd_input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">ResAdd_input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="n">GB</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">ops</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="o">+</span><span class="s2">&#34;_&#34;</span><span class="o">+</span><span class="s2">&#34;ResAdd&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="s2">&#34;ResAdd&#34;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                          <span class="s2">&#34;type&#34;</span><span class="p">:</span> <span class="s2">&#34;Vector&#34;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                          <span class="s2">&#34;ishape&#34;</span><span class="p">:</span> <span class="n">ResAdd_input_shape</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                          <span class="s2">&#34;wshape&#34;</span><span class="p">:</span> <span class="n">ResAdd_weight_shape</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                          <span class="s2">&#34;oshape&#34;</span><span class="p">:</span> <span class="n">ResAdd_output_shape</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                          <span class="s2">&#34;compute&#34;</span><span class="p">:</span> <span class="n">ResAdd_compute</span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>å°±åƒè¿™æ ·æ„å»ºæ•´ä¸ª Transformer block çš„æ‰€æœ‰æ“ä½œ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">STDIT2_block</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># {name:{type:&#34;&#34;, size:&#34;&#34;, ishape:[], wshape:[]/None, oshape:[]}}</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">ops</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">construct_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">construct_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">spatial_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;B&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;B_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;S_Q&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_Q_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;S_KV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_KV_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;D_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_QKV&#34;</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                      <span class="s2">&#34;H_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_QKV&#34;</span><span class="p">],</span> <span class="s2">&#34;N_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;N_A&#34;</span><span class="p">],</span> <span class="s2">&#34;H_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_A&#34;</span><span class="p">],</span> <span class="s2">&#34;D_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_O_spt&#34;</span><span class="p">],</span> <span class="s2">&#34;H_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_O_spt&#34;</span><span class="p">]</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="n">temporal_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;B&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;B_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;S_Q&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_Q_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;S_KV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_KV_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;D_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_QKV&#34;</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                      <span class="s2">&#34;H_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_QKV&#34;</span><span class="p">],</span> <span class="s2">&#34;N_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;N_A&#34;</span><span class="p">],</span> <span class="s2">&#34;H_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_A&#34;</span><span class="p">],</span> <span class="s2">&#34;D_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_O_tmp&#34;</span><span class="p">],</span> <span class="s2">&#34;H_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_O_tmp&#34;</span><span class="p">]</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="n">cross_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;B&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;B_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;S_Q&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_Q_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;S_KV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;S_KV_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;D_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_QKV&#34;</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                      <span class="s2">&#34;H_QKV&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_QKV&#34;</span><span class="p">],</span><span class="s2">&#34;N_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;N_A&#34;</span><span class="p">],</span> <span class="s2">&#34;H_A&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_A&#34;</span><span class="p">],</span> <span class="s2">&#34;D_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_O_cro&#34;</span><span class="p">],</span> <span class="s2">&#34;H_O&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_O_cro&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                      <span class="s2">&#34;D_FU&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_FU&#34;</span><span class="p">],</span> <span class="s2">&#34;H_FU&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_FU&#34;</span><span class="p">],</span> <span class="s2">&#34;D_FD&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;D_FD&#34;</span><span class="p">],</span> <span class="s2">&#34;H_FD&#34;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;H_FD&#34;</span><span class="p">]}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">spatial_modulate</span> <span class="o">=</span> <span class="n">Modulate</span><span class="p">(</span><span class="n">spatial_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;spatial&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">spatial_block</span> <span class="o">=</span> <span class="n">MHSA_block</span><span class="p">(</span><span class="n">spatial_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;spatial&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">spatial_gate_resadd</span> <span class="o">=</span> <span class="n">Gate_ResAdd</span><span class="p">(</span><span class="n">spatial_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;spatial&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">temporal_modulate</span> <span class="o">=</span> <span class="n">Modulate</span><span class="p">(</span><span class="n">temporal_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;temporal&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">temporal_block</span> <span class="o">=</span> <span class="n">MHSA_block</span><span class="p">(</span><span class="n">temporal_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;temporal&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">temporal_gate_resadd</span> <span class="o">=</span> <span class="n">Gate_ResAdd</span><span class="p">(</span><span class="n">temporal_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;temporal&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">cross_block</span> <span class="o">=</span> <span class="n">MHSA_block</span><span class="p">(</span><span class="n">cross_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;cross&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">cross_gate_resadd</span> <span class="o">=</span> <span class="n">Gate_ResAdd</span><span class="p">(</span><span class="n">cross_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;cross&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">mlp_modulate</span> <span class="o">=</span> <span class="n">Modulate</span><span class="p">(</span><span class="n">cross_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;mlp&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">ffn_block</span> <span class="o">=</span> <span class="n">FFN_block</span><span class="p">(</span><span class="n">cross_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">mlp_gate_resadd</span> <span class="o">=</span> <span class="n">Gate_ResAdd</span><span class="p">(</span><span class="n">cross_config</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;mlp&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="n">op_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_modulate</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_block</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_gate_resadd</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="bp">self</span><span class="o">.</span><span class="n">temporal_modulate</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">temporal_block</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">temporal_gate_resadd</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="bp">self</span><span class="o">.</span><span class="n">cross_block</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_gate_resadd</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_modulate</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_block</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_gate_resadd</span><span class="o">.</span><span class="n">ops</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">for</span> <span class="n">op_dict</span> <span class="ow">in</span> <span class="n">op_list</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="bp">self</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">op_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ç„¶åå°±å¯ä»¥å°†æ„å»ºå¥½çš„ ops æ”¾å…¥ mapper è¿›è¡Œåˆ†æã€‚åˆšæ‰é‚£äº›æ“ä½œä¼šè¢«åˆ†æˆ 3 ç±» <code>vector_mapper</code>, <code>gemm_auto_opt_mapper</code> å’Œ <code>flashatten_mapper</code>. æˆ‘ä»¬æ ¹æ®æ“ä½œçš„ç±»å‹é€å…¥å¯¹åº”çš„ mapper è¿›è¡Œåˆ†æï¼Œå…·ä½“å¦‚ä¸‹</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">STDIT2_mapper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">arch</span><span class="p">,</span> <span class="n">QKV_fusion</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">preset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">config</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</span></span><span class="line"><span class="cl">  <span class="n">Layers</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;L&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">spatial_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;B_spt&#39;</span><span class="p">],</span> <span class="s1">&#39;S_Q&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;S_Q_spt&#39;</span><span class="p">],</span> <span class="s1">&#39;S_KV&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;S_KV_spt&#39;</span><span class="p">],</span> <span class="s1">&#39;H_A&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;H_A&#39;</span><span class="p">],</span> <span class="s1">&#39;N_A&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;N_A&#39;</span><span class="p">],</span> <span class="s1">&#39;Q&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;Q&#39;</span><span class="p">]}</span>
</span></span><span class="line"><span class="cl">  <span class="n">temporal_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;B_tmp&#39;</span><span class="p">],</span> <span class="s1">&#39;S_Q&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;S_Q_tmp&#39;</span><span class="p">],</span> <span class="s1">&#39;S_KV&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;S_KV_tmp&#39;</span><span class="p">],</span> <span class="s1">&#39;H_A&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;H_A&#39;</span><span class="p">],</span> <span class="s1">&#39;N_A&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;N_A&#39;</span><span class="p">],</span> <span class="s1">&#39;Q&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;Q&#39;</span><span class="p">]}</span>
</span></span><span class="line"><span class="cl">  <span class="n">cross_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;B_cro&#39;</span><span class="p">],</span> <span class="s1">&#39;S_Q&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;S_Q_cro&#39;</span><span class="p">],</span> <span class="s1">&#39;S_KV&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;S_KV_cro&#39;</span><span class="p">],</span> <span class="s1">&#39;H_A&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;H_A&#39;</span><span class="p">],</span> <span class="s1">&#39;N_A&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;N_A&#39;</span><span class="p">],</span> <span class="s1">&#39;Q&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;Q&#39;</span><span class="p">]}</span>
</span></span><span class="line"><span class="cl">  <span class="n">ops</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">ops</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;&#39;&#39;=========================
</span></span></span><span class="line"><span class="cl"><span class="s1">  == Spatial Branch Mapping ==
</span></span></span><span class="line"><span class="cl"><span class="s1">  =========================&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">TmTn</span> <span class="o">=</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span> <span class="k">if</span> <span class="n">preset</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;spatial_Modulate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;spatial_Modulate&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;spatial_RMSNorm&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;spatial_RMSNorm&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;spatial_Q_proj&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;spatial_Q_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;spatial_K_proj&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;spatial_K_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;spatial_V_proj&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;spatial_V_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">Tx_Ty</span> <span class="o">=</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span> <span class="k">if</span> <span class="n">preset</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;spatial_Flashatten&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">flashatten_mapper</span><span class="p">(</span><span class="n">spatial_config</span><span class="p">,</span> <span class="n">arch</span><span class="p">,</span> <span class="n">Tx_Ty</span><span class="o">=</span><span class="n">Tx_Ty</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">,</span> <span class="n">Head_fused</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># FIXME</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;spatial_ResAdd&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;spatial_ResAdd&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;&#39;&#39;==========================
</span></span></span><span class="line"><span class="cl"><span class="s1">  == Temporal Branch Mapping ==
</span></span></span><span class="line"><span class="cl"><span class="s1">  ==========================&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;temporal_Modulate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;temporal_Modulate&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>  <span class="c1"># åˆ‡åˆ† 30 ä»½ä¹Ÿæ— æ³•æ»¡è¶³SRAMè¦æ±‚</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;temporal_RMSNorm&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;temporal_RMSNorm&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;temporal_Q_proj&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;temporal_Q_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;temporal_K_proj&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;temporal_K_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;temporal_V_proj&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;temporal_V_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">Tx_Ty</span> <span class="o">=</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span> <span class="k">if</span> <span class="n">preset</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;temporal_Flashatten&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">flashatten_mapper</span><span class="p">(</span><span class="n">temporal_config</span><span class="p">,</span> <span class="n">arch</span><span class="p">,</span> <span class="n">Tx_Ty</span><span class="o">=</span><span class="n">Tx_Ty</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">,</span> <span class="n">Head_fused</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># FIXME</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;temporal_ResAdd&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;temporal_ResAdd&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;&#39;&#39;====================================
</span></span></span><span class="line"><span class="cl"><span class="s1">  == Cross Branch Mapping 2x per block ==
</span></span></span><span class="line"><span class="cl"><span class="s1">  ====================================&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="c1">#mapping_result[&#39;spatial_RMSNorm&#39;]= vector_mapper(ops[&#39;spatial_RMSNorm&#39;],arch,splits=None,details=details)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_Q_proj&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;cross_Q_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_Q_proj_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_Q_proj&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_K_proj&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;cross_K_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_K_proj_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_K_proj&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_V_proj&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;cross_V_proj&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_V_proj_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_V_proj&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">Tx_Ty</span> <span class="o">=</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span> <span class="k">if</span> <span class="n">preset</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_Flashatten&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">flashatten_mapper</span><span class="p">(</span><span class="n">cross_config</span><span class="p">,</span> <span class="n">arch</span><span class="p">,</span> <span class="n">Tx_Ty</span><span class="o">=</span><span class="n">Tx_Ty</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">,</span> <span class="n">Head_fused</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># FIXME</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_Flashatten_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_Flashatten&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;cross_ResAdd&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;cross_ResAdd&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>  
</span></span><span class="line"><span class="cl">  <span class="c1"># HACK: Gate_ResAdd *2 äº†, cross æ— gate è¿™é‡Œæ—  _2</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;&#39;&#39;====================================
</span></span></span><span class="line"><span class="cl"><span class="s1">  == Feed Forward Network 2x per block ==
</span></span></span><span class="line"><span class="cl"><span class="s1">  ====================================&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;mlp_Modulate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;mlp_Modulate&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;mlp_Modulate_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;mlp_Modulate&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;FFNup&amp;SiLU&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;FFNup&#39;</span><span class="p">],</span><span class="n">arch</span><span class="p">,</span><span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span><span class="n">fusion_op2</span><span class="o">=</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;SiLU&#39;</span><span class="p">],</span><span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;FFNup&amp;SiLU_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;FFNup&amp;SiLU&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># mapping_result[&#39;FFNgate&#39;] = gemm_auto_opt_mapper(ops[&#39;FFNgate&#39;], arch, TmTn=TmTn, details=details)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># mapping_result[&#39;Hadamard&#39;] = vector_mapper(ops[&#39;Hadamard&#39;], arch, splits=None)</span>
</span></span><span class="line"><span class="cl">  <span class="n">TmTn</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span> <span class="k">if</span> <span class="n">preset</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;FFNdown&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gemm_auto_opt_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;FFNdown&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">TmTn</span><span class="o">=</span><span class="n">TmTn</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;FFNdown_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;FFNdown&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;mlp_ResAdd&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector_mapper</span><span class="p">(</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;mlp_ResAdd&#39;</span><span class="p">],</span> <span class="n">arch</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="n">details</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;mlp_ResAdd_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_result</span><span class="p">[</span><span class="s1">&#39;mlp_ResAdd&#39;</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>mapper ä¼šéå†æ‰€æœ‰å¯èƒ½çš„åˆ‡åˆ†ç­–ç•¥æ”¾å…¥ tx8 æ‰§è¡Œå¹¶é€‰æ‹©æœ€å¥½çš„é‚£ä¸€ä¸ªã€‚å¯¹äº vector ç±»å‹çš„ç®—å­åªä¼šæ²¿ç€ sequence ç»´åº¦åˆ‡åˆ†ï¼›å¯¹äº GEMM ç®—å­åˆ™ä¼šæ²¿ç€ m, k, n ç»´åº¦éƒ½è¿›è¡Œåˆ‡åˆ†ï¼›å¯¹äº flash-attention çš„åˆ‡åˆ†åˆ™ä¸åŸç®—æ³•ç›¸åŒï¼Œå¤–å¾ªç¯éå† K, V çš„æ¯ä¸€å—ï¼Œå†…å¾ªç¯éå† Q çš„æ¯ä¸€å—ã€‚è¿™æ ·å°±å¯ä»¥å¾—åˆ°æ¯ä¸ª tx8 ä¸Šæœ€ä¼˜çš„åˆ‡åˆ†æ–¹å¼å¯¹åº”çš„é€šä¿¡ç”¨æ—¶ï¼Œè®¡ç®—ç”¨æ—¶å’Œåˆ©ç”¨ç‡ã€‚å†ç”¨ä¹‹å‰ç»Ÿè®¡å‡ºçš„æ¯ä¸ª die ä¸Šé€šä¿¡é‡é™¤ä»¥ die2die å¸¦å®½å¾—åˆ°é€šä¿¡ç”¨æ—¶ï¼Œç”±æ­¤å¾—åˆ°æ€»çš„æ¨ç†ç”¨æ—¶ã€‚</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/distributed-training/">Distributed Training</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/blogs/courselearning/tvm/tvm-ch9/">
    <span class="title">Â« Prev</span>
    <br>
    <span>TVM Learning (11)-Add Model Architeture in MLC LLM</span>
  </a>
</nav>

  </footer><script src="https://giscus.app/client.js"
        data-repo="jamesnulliu/jamesnulliu.github.io"
        data-repo-id="R_kgDOMPCQIw"
        data-category="Announcements"
        data-category-id="DIC_kwDOMPCQI84Cgb2t"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>Â© 2024-2025 WITHER</span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
