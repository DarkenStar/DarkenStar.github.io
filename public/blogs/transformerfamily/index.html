<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=57770&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Transformer Family | WITHER</title>
<meta name="keywords" content="Transformer">
<meta name="description" content="Introduction of Transformer Family">
<meta name="author" content="WITHER">
<link rel="canonical" href="http://localhost:57770/blogs/transformerfamily/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5989807471fe399ba380d3b1501334cf52bf92768fffdd44127d22f5eeae9f42.css" integrity="sha256-WYmAdHH&#43;OZujgNOxUBM0z1K/knaP/91EEn0i9e6un0I=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:57770/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:57770/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:57770/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:57770/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:57770/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:57770/blogs/transformerfamily/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]  
    }
  };
</script>


<meta property="og:url" content="http://localhost:57770/blogs/transformerfamily/">
  <meta property="og:site_name" content="WITHER">
  <meta property="og:title" content="Transformer Family">
  <meta property="og:description" content="Introduction of Transformer Family">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2025-06-07T21:24:13+08:00">
    <meta property="article:modified_time" content="2025-06-07T23:40:58+08:00">
    <meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Transformer Family">
<meta name="twitter:description" content="Introduction of Transformer Family">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "http://localhost:57770/blogs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Transformer Family",
      "item": "http://localhost:57770/blogs/transformerfamily/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Transformer Family",
  "name": "Transformer Family",
  "description": "Introduction of Transformer Family",
  "keywords": [
    "Transformer"
  ],
  "articleBody": "Origin of Transformer Transformer ç”±è°·æ­Œç ”äº 2017 å¹´åœ¨ä¸€ç¯‡åä¸º Attention is All You Need çš„è®ºæ–‡ä¸­æå‡ºã€‚ä¸ RNN çš„è¾“å…¥ä»…ä¸ºä¸€ä¸ª token ä¸åŒï¼ŒTransformer ä¸€æ¬¡æ€§å¯ä»¥è¾“å…¥ä¸€æ•´ä¸ªå®Œæ•´çš„åºåˆ—ã€‚æ€»ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒåŒ…å«ä¸€ä¸ª Encoder å’Œä¸€ä¸ª Decoder.\nTransformers Architecture\nEmbedding Embedding æ˜¯ä¸€ç§å°†ç¦»æ•£çš„ã€ç¨€ç–çš„è¾“å…¥ (å¦‚è¯è¯­ã€å­—ç¬¦ã€ç±»åˆ«æ ‡ç­¾â€¦) è½¬æ¢ä¸ºè¿ç»­çš„ã€å¯†é›†çš„å‘é‡è¡¨ç¤ºçš„æŠ€æœ¯ï¼Œæ ¸å¿ƒæ˜¯é€šè¿‡ä¸€ä¸ªæ˜ å°„å‡½æ•°å°†ç¦»æ•£çš„è¾“å…¥ç¬¦å· (å¦‚å•è¯) æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´å‘é‡ç©ºé—´ä¸­ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å« V ä¸ªå•è¯çš„ Vocabularyï¼Œç»´åº¦ä¸º dï¼Œé‚£ä¹ˆ Embedding Matrix å°†æ˜¯ä¸€ä¸ªå¤§å°ä¸º VÃ—d çš„çŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªå•è¯çš„å‘é‡è¡¨ç¤ºã€‚é€šè¿‡åµŒå…¥å±‚ï¼Œè¾“å…¥çš„è¯ç´¢å¼• (é€šå¸¸æ˜¯æ•´æ•°) å°±ä¼šè¢«æ˜ å°„åˆ°è¯¥çŸ©é˜µçš„å¯¹åº”è¡Œï¼Œä»è€Œå¾—åˆ°è¯çš„å‘é‡è¡¨ç¤ºã€‚å¸¸è§çš„é¢„è®­ç»ƒè¯åµŒå…¥æ–¹æ³•åŒ…æ‹¬ï¼š\nWord2Vecï¼šé€šè¿‡ä¸Šä¸‹æ–‡é¢„æµ‹è¯è¯­çš„æ–¹å¼å­¦ä¹ è¯å‘é‡ã€‚ GloVeï¼šé€šè¿‡ç»Ÿè®¡è¯å…±ç°ä¿¡æ¯æ¥å­¦ä¹ è¯å‘é‡ã€‚ FastTextï¼šè€ƒè™‘äº†å­è¯ä¿¡æ¯çš„è¯åµŒå…¥æ–¹æ³•ï¼Œèƒ½æ›´å¥½åœ°å¤„ç†è¯å½¢å˜åŒ–ã€‚ åœ¨ PyTorch å’Œ TensorFlow ç­‰æ¡†æ¶ä¸­ï¼Œé€šå¸¸æœ‰ä¸“é—¨çš„ Embedding å±‚ï¼ŒHugging Face ä¹Ÿæœ‰ tokenizer å°†å¥å­åˆ’åˆ†æˆå•è¯å¹¶è½¬æ¢æˆå¯¹åº”çš„ç´¢å¼•ï¼š\nPositional Encoding Positional Encoding ä½œç”¨æ˜¯ä¸ºè¾“å…¥çš„åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ æä¾›ä½ç½®ä¿¡æ¯ã€‚ç”±äº Transformer æ¶æ„å¹¶æ²¡æœ‰ä½¿ç”¨é€’å½’æˆ–å·ç§¯ç»“æ„ï¼Œæœ¬èº«æ— æ³•æ•æ‰è¾“å…¥åºåˆ—ä¸­å…ƒç´ çš„ç›¸å¯¹ä½ç½®å…³ç³»ï¼Œå› æ­¤éœ€è¦é€šè¿‡ä½ç½®ç¼–ç æ¥æ˜¾å¼åœ°å¼•å…¥è¿™äº›ä½ç½®ä¿¡æ¯ã€‚\nNote\nTransformer çš„ä¸»è¦ä¼˜åŠ¿æ˜¯é€šè¿‡ Self-Attention å¹¶è¡Œå¤„ç†åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œä½†æ˜¯è¿™ä¹Ÿæ„å‘³ç€å®ƒæ²¡æœ‰è‡ªå¸¦é¡ºåºæ„ŸçŸ¥èƒ½åŠ›ï¼Œå®ƒå¹¶ä¸ä¼šè‡ªåŠ¨çŸ¥é“ä¸€ä¸ªå•è¯æ˜¯åœ¨å¥å­çš„å¼€å¤´è¿˜æ˜¯ç»“å°¾ï¼Œå› æ­¤éœ€è¦é¢å¤–çš„æœºåˆ¶æ¥ç¼–ç æ¯ä¸ªå…ƒç´ åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚\nä½ç½®ç¼–ç  é€šè¿‡å°†æ¯ä¸ªå•è¯çš„ä½ç½®ä¿¡æ¯ (å³å®ƒåœ¨åºåˆ—ä¸­çš„ä½ç½®) ç¼–ç ä¸ºä¸€ä¸ªå‘é‡ï¼Œå¹¶å°†è¯¥å‘é‡æ·»åŠ åˆ°å•è¯çš„åµŒå…¥è¡¨ç¤ºä¸­ï¼Œä»è€Œè®©æ¨¡å‹èƒ½å¤Ÿæ„ŸçŸ¥æ¯ä¸ªå…ƒç´ çš„ç›¸å¯¹æˆ–ç»å¯¹ä½ç½®ã€‚\nç»å…¸çš„ Transformer ä½ç½®ç¼–ç ä½¿ç”¨ æ­£å¼¦å’Œä½™å¼¦å‡½æ•°çš„ç»„åˆï¼Œä¸ºæ¯ä¸ªä½ç½®ç”Ÿæˆçš„å‘é‡åœ¨ä¸åŒç»´åº¦ä¸Šå…·æœ‰ä¸åŒçš„å‘¨æœŸæ€§ï¼Œè¿™èƒ½å¤Ÿæ•æ‰åˆ°ä¸åŒçº§åˆ«çš„ç›¸å¯¹ä½ç½®å…³ç³»ã€‚å‡è®¾è¾“å…¥çš„åºåˆ—ä¸­æœ‰ N ä¸ªå•è¯ï¼Œæ¯ä¸ªå•è¯çš„åµŒå…¥ç»´åº¦ä¸º dï¼Œé‚£ä¹ˆ Positional Encodin(PE) çš„è®¡ç®—å…¬å¼å¦‚ä¸‹:\n$$\r\\begin{aligned}\r\u0026PE_{(pos,2i)}=\\sin\\left(\\frac{pos}{10000^{\\frac{2i}d}}\\right)\\\\\r\u0026PE_{(pos,2i+1)}=\\cos\\left(\\frac{pos}{10000^{\\frac{2i}d}}\\right)\r\\end{aligned}\r$$å…¶ä¸­ï¼š\npos æ˜¯å•è¯åœ¨åºåˆ—ä¸­çš„ä½ç½®ç´¢å¼• (ä½ç½®ä» 0 å¼€å§‹). i æ˜¯ä½ç½®ç¼–ç çš„ç»´åº¦ç´¢å¼•ï¼Œè¡¨ç¤ºè¯¥ä½ç½®ç¼–ç å‘é‡ä¸­çš„ç¬¬ i ä¸ªå…ƒç´ ã€‚ d æ˜¯ Embedding çš„ç»´åº¦ è¿™äº›ä½ç½®ç¼–ç ä¸å•è¯çš„è¯åµŒå…¥ (Word Embedding) ç›¸åŠ ï¼Œæœ€ç»ˆå½¢æˆè¾“å…¥æ¨¡å‹çš„å‘é‡è¡¨ç¤ºã€‚\n(Masked) Multi-Head Attention Multi-Head Attention (MHA) çš„ç›®çš„æ˜¯é€šè¿‡å¹¶è¡Œåœ°è®¡ç®—å¤šä¸ªæ³¨æ„åŠ›å¤´ (Attention Head)ï¼Œä»å¤šä¸ªå­ç©ºé—´ä¸­å­¦ä¹ è¾“å…¥åºåˆ—çš„ä¸åŒè¡¨ç¤ºã€‚ç»è¿‡ Word Embedding åçš„è¾“å…¥ X å½¢çŠ¶ä¸º Nxd. è®¡ç®—æ­¥éª¤å¦‚ä¸‹\né€šè¿‡å­¦ä¹ çš„å˜æ¢çŸ©é˜µå°† X æ˜ å°„åˆ°æŸ¥è¯¢ (Q)ã€é”® (K) å’Œå€¼ (V) ç©ºé—´ã€‚ $$\r\\begin{aligned}\u0026Q=XW^{Q}\\\\\u0026K=XW^{K}\\\\\u0026V=XW^{V}\\end{aligned}\r$$ å…¶ä¸­ $W^{Q},W^{K}\\in\\mathbb{R}d_{model}\\times d_{k},W^{Q},W^{V}\\in\\mathbb{R}d_{model}\\times d_{v}$\næ ¹æ® QKV è®¡ç®— Attention æ¯ä¸ªæŸ¥è¯¢å‘é‡ä¼šä¸æ‰€æœ‰é”®å‘é‡è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®— (ä¸€èˆ¬é‡‡ç”¨ scaled inner product)ï¼Œä»è€Œè·å¾—æƒé‡ï¼Œç„¶ååˆ©ç”¨è¿™äº›æƒé‡å¯¹æ‰€æœ‰å€¼å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œã€‚\n$$\r\\mathrm{Attention}(Q,K,V)=\\mathrm{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\r$$\nåœ¨å¤šå¤´æ³¨æ„åŠ›ä¸­ï¼Œä¸ºäº†å¢åŠ æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œé€šå¸¸å°† Qã€K å’Œ V é€šè¿‡å¤šä¸ªä¸åŒçš„çº¿æ€§å˜æ¢çŸ©é˜µè¿›è¡Œå¤šæ¬¡è®¡ç®—ï¼Œå¾—åˆ°å¤šä¸ªæ³¨æ„åŠ›å¤´ (Attention Heads). æ¯ä¸ªå¤´çš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ï¼Œä½†å®ƒä»¬çš„ç»“æœä¼šåœ¨æœ€åè¿›è¡Œæ‹¼æ¥å¹¶ç»è¿‡çº¿æ€§å˜æ¢ã€‚æœ€ç»ˆçš„ Multi-Head Attention å…¬å¼ä¸ºï¼š\n$$\r\\text{MultiHead}(Q,K,V)=\\text{Concat}(head_1,head_2,\\ldots,head_h)W^O\r$$\næ¯ä¸ªå¤´ $head_i$ è®¡ç®—å…¬å¼ä¸º\n$$\r\\text{MultiHead}(Q,K,V)=\\text{Concat}(head_1,head_2,\\ldots,head_h)W^O\r$$\nè¿™é‡Œçš„ $W^{Q}_{i},W^{K}_{i},W^{V}_{i}$ æ˜¯ä¸ºæ¯ä¸ªå¤´å­¦ä¹ åˆ°çš„ä¸åŒæƒé‡çŸ©é˜µï¼Œ$W^O$ æ˜¯è¾“å‡ºçš„çº¿æ€§å˜æ¢çŸ©é˜µã€‚\nMulti-Head Attention\nDecoder ä¸­çš„ Masked MHA ç¡®ä¿æ¨¡å‹åªèƒ½åœ¨è§£ç åºåˆ—çš„å½“å‰ä½ç½®åŠå…¶ä¹‹å‰çš„ä½ç½®ä¸Šæ“ä½œï¼Œè€Œä¸èƒ½ â€œçœ‹åˆ°â€ å°†è¦ç”Ÿæˆçš„æœªæ¥ä¿¡æ¯ã€‚ä¸æ ‡å‡†çš„ MHA ç›¸åŒï¼Œæ³¨æ„åŠ›åˆ†æ•° $\\mathrm{Attention Scores}=\\frac{QK^T}{\\sqrt{d_k}}$ æ˜¯é€šè¿‡ Q å’Œ K çš„ç‚¹ç§¯è®¡ç®—å¾—åˆ°çš„ã€‚è®¡ç®—å®Œæˆåæˆ‘ä»¬ç»™å…¶åŠ ä¸Šä¸€ä¸ªä¸‹ä¸‰è§’å…ƒç´  (åŒ…å«ä¸»å¯¹è§’çº¿) ä¸º 0ï¼Œä¸Šä¸‰è§’å…ƒç´ ä¸º â€”âˆ çš„ maskï¼Œè¿™æ ·æœªæ¥çš„ä¿¡æ¯ç»è¿‡ Softmax åçš„æƒé‡ä¸º 0ï¼Œè¢«å®Œå…¨å±è”½ã€‚\nGrouped Query Attentionï¼ˆGQAï¼‰\u0026 Multi-query Attention (MQA) GQA å°†å¤šä¸ª Q åˆ†æˆè‹¥å¹²ç»„ï¼Œæ¯ä¸€ç»„å…±äº«ç›¸åŒçš„æƒé‡çŸ©é˜µã€‚è¿™ä½¿å¾—æ¯ç»„æŸ¥è¯¢å¯ä»¥å…±åŒå¤„ç†åŒä¸€ä¸ª K å’Œ Vï¼Œé™ä½äº†è®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚ã€‚åœ¨ MHA ä¸­ï¼Œæ‰€æœ‰çš„å¤´å…±äº«ç›¸åŒçš„è¾“å…¥ Xï¼Œä½†ä½¿ç”¨ä¸åŒçš„æŠ•å½±çŸ©é˜µæ¥ç”Ÿæˆ K å’Œ V. GQA ä¸­ K å’Œ V é€šå¸¸æ˜¯å¯¹è¾“å…¥ X è¿›è¡Œä¸€æ¬¡æ€§çº¿æ€§å˜æ¢ï¼Œå¹¶åœ¨æ‰€æœ‰åŒä¸€åˆ†ç»„ä¸­çš„ Q å…±äº«ã€‚MQA æ›´ä¸ºæç«¯ï¼Œæ‰€æœ‰çš„ Q å…±äº«ä¸€ä¸ª K å’Œ V.\nOverview of MHA, GQA \u0026 MQA\nMulti-Head Cross Attention Multi-Head Cross Attention æ˜¯ Transformer Decoder ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒç»„ä»¶ã€‚ä¸ Self-Attention ä¸åŒï¼ŒCross Attention è´Ÿè´£å°†è§£ç å™¨çš„éšè—çŠ¶æ€ä¸ç¼–ç å™¨çš„è¾“å‡ºä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œäº¤äº’ï¼Œå…è®¸è§£ç å™¨çš„æ¯ä¸€ä¸ªè§£ç æ—¶é—´æ­¥çš„çŠ¶æ€ æŸ¥çœ‹æ•´ä¸ªç¼–ç å™¨çš„è¾“å‡ºã€‚æ¯ä¸ªè§£ç çš„æ—¶é—´æ­¥ tï¼ŒDecoder çš„éšè—çŠ¶æ€ä½œä¸º Qï¼ŒEncoder çš„è¾“å‡ºä½œä¸º K å’Œ Vï¼Œè®¡ç®—è¿‡ç¨‹ä¸ æ ‡å‡†çš„ Self-Attention ç›¸åŒã€‚\nEvolution Tree of Transformer åç»­çš„ç ”ç©¶é€æ¸æŠŠ Encoder å’Œ Decoder åˆ†ç¦»å¼€æ¥ï¼Œå½¢æˆ Encoder-Only å’Œ Decoder-Only çš„æ¨¡å‹ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º\nTransformer Evolution Tree\nFeed Forward Network FFN æ˜¯ä¸€ä¸ªä¸¤å±‚çš„å‰é¦ˆå…¨è¿æ¥ç½‘ç»œï¼Œä¸­é—´æœ‰ä¸€ä¸ªéçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚ç¬¬ä¸€å±‚å…¨è¿æ¥å°† $d_model$ æ˜ å°„åˆ° $4d_model$ ï¼Œç»è¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°åï¼Œç¬¬äºŒå±‚å…¨è¿æ¥å†é‡æ–°æ˜ å°„å› $d_model$.\nDecoder-Only Transformer Decoder-Only åˆ é™¤äº†åŸå…ˆ Transformer Encoder çš„éƒ¨åˆ†ä»¥åŠ Encoder å’Œ Decoder è¿›è¡Œ Cross Attention çš„éƒ¨åˆ†ã€‚å®ƒå…·æœ‰ä¸‰ä¸ªå¿…è¦çš„ç‰¹å¾:\nåœ¨ç»™å®šç¼–ç å™¨è¾“å…¥ä½œä¸ºä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹åŸºäºè¿„ä»Šä¸ºæ­¢ç”Ÿæˆçš„ token è‡ªåŠ¨å›å½’é¢„æµ‹ä¸‹ä¸€ä¸ªã€‚ åœ¨è¯„ä¼°å¯¹è¾“å…¥åºåˆ—çš„ Q æ—¶çœ‹ä¸åˆ°æœªæ¥å€¼ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»…è§£ç å™¨çš„æ¨¡å‹é€šå¸¸è¢«ç§°ä¸º Casual Language Model (CLM). è®­ç»ƒæ¨¡å‹ä»¥åœ¨ç»™å®šå½“å‰è¾“å…¥åºåˆ—çš„æƒ…å†µä¸‹é¢„æµ‹ä¸‹ä¸€ä¸ª token. è¿™ç§è®­ç»ƒæ–¹æ³•ä¸å›å½’ç›¸ç»“åˆï¼Œå…è®¸æ¨¡å‹è‡ªå›å½’ç”Ÿæˆä»»æ„é•¿ (æœ€é«˜è¾¾è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦) çš„åºåˆ—ã€‚ Decoder-only (left) and Encoder-only (right) Transformer Architectures\nLLaMA Transformer Architecture LLaMA Transformer ç»“æ„å¦‚ä¸‹ï¼Œä¸»è¦æœ‰ä»¥ä¸‹å˜åŒ–\nä½¿ç”¨ RoPE (Rotary Position Embedding) æ›¿ä»£ä¼ ç»Ÿçš„ä½ç½®ç¼–ç ã€‚ RMSNorm æ›¿ä»£ LayerNorm å¼•å…¥ Gated Linear Unit (GLU) Rotary Position Embedding ä¼ ç»Ÿçš„ Transformer æ¨¡å‹ä½¿ç”¨å¯å­¦ä¹ çš„ç»å¯¹ä½ç½®ç¼–ç  (å¦‚ sinusoidal position embedding)ï¼Œä½† RoPE é‡‡ç”¨äº†æ—‹è½¬çŸ©é˜µçš„æ€æƒ³ï¼Œå°†ä½ç½®ç¼–ç ä¸è¾“å…¥çš„ token è¡¨ç¤ºç›´æ¥ç»“åˆï¼Œè€Œä¸ä¾èµ–äºé¢å¤–çš„å¯å­¦ä¹ å‚æ•°ã€‚\nè¾“å…¥å‘é‡çš„æ—‹è½¬è§’åº¦ä¸º $\\theta(p,i)=p\\cdot10000^{-2i/d}$. p è¡¨ç¤ºä½ç½®ç´¢å¼•ï¼Œi è¡¨ç¤ºç»´åº¦ç´¢å¼•ï¼Œd ä¸ºå‘é‡çš„æ€»ç»´åº¦ã€‚å¯¹äºè¾“å…¥çš„ token å‘é‡ x ä¸­çš„æ¯ä¸€å¯¹å¶æ•°å’Œå¥‡æ•°ç»´åº¦ $(x_{2i},x_{2i+1})$ï¼Œæ—‹è½¬æ“ä½œå¯ä»¥ç”¨ 2D æ—‹è½¬çŸ©é˜µè¡¨ç¤ºä¸º\n$$\\begin{bmatrix}x_{2i}^{\\prime}\\\\x_{2i+1}^{\\prime}\\end{bmatrix}=\\begin{bmatrix}\\cos(\\theta)\u0026-\\sin(\\theta)\\\\\\sin(\\theta)\u0026\\cos(\\theta)\\end{bmatrix}\\cdot\\begin{bmatrix}x_{2i}\\\\x_{2i+1}\\end{bmatrix}$$\nå¯¹äºè¾“å…¥çš„ token å‘é‡ $\\mathbf{x}\\left[x_{0},x_{1},x_{2},x_{3},\\cdots,x_{d-1}\\right]$, RoPE å°†å…¶ä¸¤ä¸¤ä¸€ç»„é…å¯¹ï¼Œæ¯ä¸€ç»„éƒ½ä¼šä¸ä½ç½®ç›¸å…³çš„æ—‹è½¬è§’åº¦ Î¸ å¯¹åº”åœ°åº”ç”¨æ—‹è½¬æ“ä½œã€‚è¿™ä¸ªè¿‡ç¨‹çš„æœ¬è´¨æ˜¯å¯¹è¾“å…¥ token çš„è¡¨ç¤ºåšäº†æ—‹è½¬å˜æ¢ï¼Œä½¿å¾—è¿™äº›ç‰¹å¾ä¸ä»…ä¾èµ–äºè¾“å…¥çš„ç‰¹å¾ï¼Œè¿˜éšå«äº†è¯¥ token åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚\nRoPE\nRMSNorm RMSNorm ç›¸å¯¹äº LayerNorm å»æ‰äº†å‡å€¼è®¡ç®—ï¼Œä»…åŸºäºè¾“å…¥çš„å‡æ–¹æ ¹è¿›è¡Œå½’ä¸€åŒ– $\\mathrm{RMSNorm}(\\mathbf{x})=\\frac{\\mathbf{x}}{\\mathrm{RMS}(\\mathbf{x})+\\epsilon}\\cdot\\gamma$\nå…¶ä¸­\n$\\mathrm{RMS}(\\mathbf{x})=\\sqrt{\\frac1d\\sum_{i=1}^dx_i^2}$ ä¸ºè¾“å…¥çš„å‡æ–¹æ ¹ã€‚ $\\gamma{:}$ ä¸ºå¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•°ã€‚ $\\epsilon{:}$ ä¸ºé˜²æ­¢é™¤ä»¥ 0 çš„å°æ•°ã€‚ SiLU SiLU (Sigmoid Linear Unit) æ˜¯ä¸€ç§æ¿€æ´»å‡½æ•°ï¼Œä¹Ÿç§°ä¸º Swishï¼Œå…¶å®šä¹‰ä¸ºè¾“å…¥ x å’Œ Sigmoid å‡½æ•°è¾“å‡ºçš„ä¹˜ç§¯ã€‚å…¶å®šä¹‰ä¸º $$\\mathrm{SiLU}(x)=x\\cdot\\sigma(x)$$ å…¶ä¸­ $\\sigma(x)=\\frac1{1+e^{-x}}$\nSiLU\n",
  "wordCount" : "2392",
  "inLanguage": "en",
  "datePublished": "2025-06-07T21:24:13+08:00",
  "dateModified": "2025-06-07T23:40:58+08:00",
  "author":[{
    "@type": "Person",
    "name": "WITHER"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:57770/blogs/transformerfamily/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "WITHER",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:57770/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:57770/" accesskey="h" title="WITHER (Alt + H)">WITHER</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="http://localhost:57770/zh/" title="ç®€ä½“ä¸­æ–‡"
                            aria-label="ç®€ä½“ä¸­æ–‡">ç®€ä½“ä¸­æ–‡</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:57770/" title="ğŸ  Home">
                    <span>ğŸ  Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:57770/about_me/" title="ğŸ™‹ğŸ»â€â™‚ï¸ Me">
                    <span>ğŸ™‹ğŸ»â€â™‚ï¸ Me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:57770/blogs/" title="ğŸ“š Blogs">
                    <span>ğŸ“š Blogs</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:57770/categories/" title="ğŸ§© Categories">
                    <span>ğŸ§© Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:57770/tags/" title="ğŸ”– Tags">
                    <span>ğŸ”– Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:57770/archives/" title="â± Archive">
                    <span>â± Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:57770/search/" title="ğŸ” Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ” Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:57770/friends/" title="ğŸ¤ Friends">
                    <span>ğŸ¤ Friends</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:57770/">Home</a>&nbsp;Â»&nbsp;<a href="http://localhost:57770/blogs/">Blogs</a></div>
    <h1 class="post-title entry-hint-parent">
      Transformer Family
    </h1>
    <div class="post-description">
      Introduction of Transformer Family
    </div>
    <div class="post-meta"><span title='2025-06-07 21:24:13 +0800 CST'>Jun-07-2025</span>&nbsp;Â·&nbsp;5 min&nbsp;Â·&nbsp;2392 words&nbsp;Â·&nbsp;WITHER

</div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#origin-of-transformer" aria-label="Origin of Transformer">Origin of Transformer</a><ul>
                            
                    <li>
                        <a href="#embedding" aria-label="Embedding">Embedding</a></li>
                    <li>
                        <a href="#positional-encoding" aria-label="Positional Encoding">Positional Encoding</a></li>
                    <li>
                        <a href="#masked-multi-head-attention" aria-label="(Masked) Multi-Head Attention">(Masked) Multi-Head Attention</a></li>
                    <li>
                        <a href="#grouped-query-attentiongqa-multi-query-attention-mqa" aria-label="Grouped Query Attentionï¼ˆGQAï¼‰&amp; Multi-query Attention (MQA)">Grouped Query Attentionï¼ˆGQAï¼‰&amp; Multi-query Attention (MQA)</a></li>
                    <li>
                        <a href="#multi-head-cross-attention" aria-label="Multi-Head Cross Attention">Multi-Head Cross Attention</a></li></ul>
                    </li>
                    <li>
                        <a href="#evolution-tree-of-transformer" aria-label="Evolution Tree of Transformer">Evolution Tree of Transformer</a><ul>
                            
                    <li>
                        <a href="#feed-forward-network" aria-label="Feed Forward Network">Feed Forward Network</a></li></ul>
                    </li>
                    <li>
                        <a href="#decoder-only-transformer" aria-label="Decoder-Only Transformer">Decoder-Only Transformer</a></li>
                    <li>
                        <a href="#llama-transformer-architecture" aria-label="LLaMA Transformer Architecture">LLaMA Transformer Architecture</a><ul>
                            
                    <li>
                        <a href="#rotary-position-embedding" aria-label="Rotary Position Embedding">Rotary Position Embedding</a></li>
                    <li>
                        <a href="#rmsnorm" aria-label="RMSNorm">RMSNorm</a></li>
                    <li>
                        <a href="#silu" aria-label="SiLU">SiLU</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>
  <div class="post-content"><h1 id="origin-of-transformer">Origin of Transformer<a hidden class="anchor" aria-hidden="true" href="#origin-of-transformer">#</a></h1>
<p>Transformer ç”±è°·æ­Œç ”äº 2017 å¹´åœ¨ä¸€ç¯‡åä¸º <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> çš„è®ºæ–‡ä¸­æå‡ºã€‚ä¸ RNN çš„è¾“å…¥ä»…ä¸ºä¸€ä¸ª token ä¸åŒï¼ŒTransformer ä¸€æ¬¡æ€§å¯ä»¥è¾“å…¥ä¸€æ•´ä¸ªå®Œæ•´çš„åºåˆ—ã€‚æ€»ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒåŒ…å«ä¸€ä¸ª Encoder å’Œä¸€ä¸ª Decoder.</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBd293bc1a46904e1af31ce993b83c68f1?method=download&amp;shareKey=47cf357e488e7da5483a1b98f3257ab1" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBd293bc1a46904e1af31ce993b83c68f1?method=download&amp;shareKey=47cf357e488e7da5483a1b98f3257ab1" alt="Transformers Architecture">
    </a><figcaption>Transformers Architecture</figcaption></figure></p>
<h2 id="embedding">Embedding<a hidden class="anchor" aria-hidden="true" href="#embedding">#</a></h2>
<p>Embedding æ˜¯ä¸€ç§å°†ç¦»æ•£çš„ã€ç¨€ç–çš„è¾“å…¥ (å¦‚è¯è¯­ã€å­—ç¬¦ã€ç±»åˆ«æ ‡ç­¾&hellip;) è½¬æ¢ä¸ºè¿ç»­çš„ã€å¯†é›†çš„å‘é‡è¡¨ç¤ºçš„æŠ€æœ¯ï¼Œæ ¸å¿ƒæ˜¯é€šè¿‡ä¸€ä¸ªæ˜ å°„å‡½æ•°å°†ç¦»æ•£çš„è¾“å…¥ç¬¦å· (å¦‚å•è¯) æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´å‘é‡ç©ºé—´ä¸­ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å« V ä¸ªå•è¯çš„ Vocabularyï¼Œç»´åº¦ä¸º dï¼Œé‚£ä¹ˆ Embedding Matrix å°†æ˜¯ä¸€ä¸ªå¤§å°ä¸º VÃ—d çš„çŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªå•è¯çš„å‘é‡è¡¨ç¤ºã€‚é€šè¿‡åµŒå…¥å±‚ï¼Œè¾“å…¥çš„è¯ç´¢å¼• (é€šå¸¸æ˜¯æ•´æ•°) å°±ä¼šè¢«æ˜ å°„åˆ°è¯¥çŸ©é˜µçš„å¯¹åº”è¡Œï¼Œä»è€Œå¾—åˆ°è¯çš„å‘é‡è¡¨ç¤ºã€‚å¸¸è§çš„é¢„è®­ç»ƒè¯åµŒå…¥æ–¹æ³•åŒ…æ‹¬ï¼š</p>
<ul>
<li>Word2Vecï¼šé€šè¿‡ä¸Šä¸‹æ–‡é¢„æµ‹è¯è¯­çš„æ–¹å¼å­¦ä¹ è¯å‘é‡ã€‚</li>
<li>GloVeï¼šé€šè¿‡ç»Ÿè®¡è¯å…±ç°ä¿¡æ¯æ¥å­¦ä¹ è¯å‘é‡ã€‚</li>
<li>FastTextï¼šè€ƒè™‘äº†å­è¯ä¿¡æ¯çš„è¯åµŒå…¥æ–¹æ³•ï¼Œèƒ½æ›´å¥½åœ°å¤„ç†è¯å½¢å˜åŒ–ã€‚</li>
</ul>
<p>åœ¨ PyTorch å’Œ TensorFlow ç­‰æ¡†æ¶ä¸­ï¼Œé€šå¸¸æœ‰ä¸“é—¨çš„ Embedding å±‚ï¼ŒHugging Face ä¹Ÿæœ‰ tokenizer å°†å¥å­åˆ’åˆ†æˆå•è¯å¹¶è½¬æ¢æˆå¯¹åº”çš„ç´¢å¼•ï¼š</p>
<h2 id="positional-encoding">Positional Encoding<a hidden class="anchor" aria-hidden="true" href="#positional-encoding">#</a></h2>
<p>Positional Encoding ä½œç”¨æ˜¯ä¸ºè¾“å…¥çš„åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ æä¾›ä½ç½®ä¿¡æ¯ã€‚ç”±äº Transformer æ¶æ„å¹¶æ²¡æœ‰ä½¿ç”¨é€’å½’æˆ–å·ç§¯ç»“æ„ï¼Œæœ¬èº«æ— æ³•æ•æ‰è¾“å…¥åºåˆ—ä¸­å…ƒç´ çš„ç›¸å¯¹ä½ç½®å…³ç³»ï¼Œå› æ­¤éœ€è¦é€šè¿‡ä½ç½®ç¼–ç æ¥æ˜¾å¼åœ°å¼•å…¥è¿™äº›ä½ç½®ä¿¡æ¯ã€‚</p>
<style type="text/css">
     
    .notice {
        --title-color: #fff;
        --title-background-color: #6be;
        --content-color: #444;
        --content-background-color: #e7f2fa;
    }

    .notice.info {
        --title-background-color: #fb7;
        --content-background-color: #fec;
    }

    .notice.tip {
        --title-background-color: #5a5;
        --content-background-color: #efe;
    }

    .notice.warning {
        --title-background-color: #c33;
        --content-background-color: #fee;
    }

     
    @media (prefers-color-scheme:dark) {
        .notice {
            --title-color: #fff;
            --title-background-color: #069;
            --content-color: #ddd;
            --content-background-color: #023;
        }

        .notice.info {
            --title-background-color: #a50;
            --content-background-color: #420;
        }

        .notice.tip {
            --title-background-color: #363;
            --content-background-color: #121;
        }

        .notice.warning {
            --title-background-color: #800;
            --content-background-color: #400;
        }
    }

    body.dark .notice {
        --title-color: #fff;
        --title-background-color: #069;
        --content-color: #ddd;
        --content-background-color: #023;
    }

    body.dark .notice.info {
        --title-background-color: #a50;
        --content-background-color: #420;
    }

    body.dark .notice.tip {
        --title-background-color: #363;
        --content-background-color: #121;
    }

    body.dark .notice.warning {
        --title-background-color: #800;
        --content-background-color: #400;
    }

     
    .notice {
        padding: 18px;
        line-height: 24px;
        margin-bottom: 24px;
        border-radius: 4px;
        color: var(--content-color);
        background: var(--content-background-color);
    }

    .notice p:last-child {
        margin-bottom: 0
    }

     
    .notice-title {
        margin: -18px -18px 12px;
        padding: 4px 18px;
        border-radius: 4px 4px 0 0;
        font-weight: 700;
        color: var(--title-color);
        background: var(--title-background-color);
    }

     
    .icon-notice {
        display: inline-flex;
        align-self: center;
        margin-right: 8px;
    }

    .icon-notice img,
    .icon-notice svg {
        height: 1em;
        width: 1em;
        fill: currentColor;
    }

    .icon-notice img,
    .icon-notice.baseline svg {
        top: .125em;
        position: relative;
    }
</style><div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>Transformer çš„ä¸»è¦ä¼˜åŠ¿æ˜¯é€šè¿‡ Self-Attention å¹¶è¡Œå¤„ç†åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œä½†æ˜¯è¿™ä¹Ÿæ„å‘³ç€å®ƒæ²¡æœ‰è‡ªå¸¦é¡ºåºæ„ŸçŸ¥èƒ½åŠ›ï¼Œå®ƒå¹¶ä¸ä¼šè‡ªåŠ¨çŸ¥é“ä¸€ä¸ªå•è¯æ˜¯åœ¨å¥å­çš„å¼€å¤´è¿˜æ˜¯ç»“å°¾ï¼Œå› æ­¤éœ€è¦é¢å¤–çš„æœºåˆ¶æ¥ç¼–ç æ¯ä¸ªå…ƒç´ åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚</p>
<p>ä½ç½®ç¼–ç  é€šè¿‡å°†æ¯ä¸ªå•è¯çš„ä½ç½®ä¿¡æ¯ (å³å®ƒåœ¨åºåˆ—ä¸­çš„ä½ç½®) ç¼–ç ä¸ºä¸€ä¸ªå‘é‡ï¼Œå¹¶å°†è¯¥å‘é‡æ·»åŠ åˆ°å•è¯çš„åµŒå…¥è¡¨ç¤ºä¸­ï¼Œä»è€Œè®©æ¨¡å‹èƒ½å¤Ÿæ„ŸçŸ¥æ¯ä¸ªå…ƒç´ çš„ç›¸å¯¹æˆ–ç»å¯¹ä½ç½®ã€‚</p></div>

<p>ç»å…¸çš„ Transformer ä½ç½®ç¼–ç ä½¿ç”¨ æ­£å¼¦å’Œä½™å¼¦å‡½æ•°çš„ç»„åˆï¼Œä¸ºæ¯ä¸ªä½ç½®ç”Ÿæˆçš„å‘é‡åœ¨ä¸åŒç»´åº¦ä¸Šå…·æœ‰ä¸åŒçš„å‘¨æœŸæ€§ï¼Œè¿™èƒ½å¤Ÿæ•æ‰åˆ°ä¸åŒçº§åˆ«çš„ç›¸å¯¹ä½ç½®å…³ç³»ã€‚å‡è®¾è¾“å…¥çš„åºåˆ—ä¸­æœ‰ N ä¸ªå•è¯ï¼Œæ¯ä¸ªå•è¯çš„åµŒå…¥ç»´åº¦ä¸º dï¼Œé‚£ä¹ˆ Positional Encodin(PE) çš„è®¡ç®—å…¬å¼å¦‚ä¸‹:</p>
$$
\begin{aligned}
&PE_{(pos,2i)}=\sin\left(\frac{pos}{10000^{\frac{2i}d}}\right)\\
&PE_{(pos,2i+1)}=\cos\left(\frac{pos}{10000^{\frac{2i}d}}\right)
\end{aligned}
$$<p>å…¶ä¸­ï¼š</p>
<ul>
<li>pos æ˜¯å•è¯åœ¨åºåˆ—ä¸­çš„ä½ç½®ç´¢å¼• (ä½ç½®ä» 0 å¼€å§‹).</li>
<li>i æ˜¯ä½ç½®ç¼–ç çš„ç»´åº¦ç´¢å¼•ï¼Œè¡¨ç¤ºè¯¥ä½ç½®ç¼–ç å‘é‡ä¸­çš„ç¬¬ i ä¸ªå…ƒç´ ã€‚</li>
<li>d æ˜¯ Embedding çš„ç»´åº¦</li>
</ul>
<p>è¿™äº›ä½ç½®ç¼–ç ä¸å•è¯çš„è¯åµŒå…¥ (Word Embedding) ç›¸åŠ ï¼Œæœ€ç»ˆå½¢æˆè¾“å…¥æ¨¡å‹çš„å‘é‡è¡¨ç¤ºã€‚</p>
<h2 id="masked-multi-head-attention">(Masked) Multi-Head Attention<a hidden class="anchor" aria-hidden="true" href="#masked-multi-head-attention">#</a></h2>
<p>Multi-Head Attention (MHA) çš„ç›®çš„æ˜¯é€šè¿‡å¹¶è¡Œåœ°è®¡ç®—å¤šä¸ªæ³¨æ„åŠ›å¤´ (Attention Head)ï¼Œä»å¤šä¸ªå­ç©ºé—´ä¸­å­¦ä¹ è¾“å…¥åºåˆ—çš„ä¸åŒè¡¨ç¤ºã€‚ç»è¿‡ Word Embedding åçš„è¾“å…¥ X å½¢çŠ¶ä¸º Nxd. è®¡ç®—æ­¥éª¤å¦‚ä¸‹</p>
<ol>
<li>
<p>é€šè¿‡å­¦ä¹ çš„å˜æ¢çŸ©é˜µå°† X æ˜ å°„åˆ°æŸ¥è¯¢ (Q)ã€é”® (K) å’Œå€¼ (V) ç©ºé—´ã€‚
</p>
$$
\begin{aligned}&Q=XW^{Q}\\&K=XW^{K}\\&V=XW^{V}\end{aligned}
$$<p>
å…¶ä¸­ $W^{Q},W^{K}\in\mathbb{R}d_{model}\times d_{k},W^{Q},W^{V}\in\mathbb{R}d_{model}\times d_{v}$</p>
</li>
<li>
<p>æ ¹æ® QKV è®¡ç®— Attention
æ¯ä¸ªæŸ¥è¯¢å‘é‡ä¼šä¸æ‰€æœ‰é”®å‘é‡è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®— (ä¸€èˆ¬é‡‡ç”¨ scaled inner product)ï¼Œä»è€Œè·å¾—æƒé‡ï¼Œç„¶ååˆ©ç”¨è¿™äº›æƒé‡å¯¹æ‰€æœ‰å€¼å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œã€‚</p>
</li>
</ol>
$$
\mathrm{Attention}(Q,K,V)=\mathrm{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$<p><br>åœ¨å¤šå¤´æ³¨æ„åŠ›ä¸­ï¼Œä¸ºäº†å¢åŠ æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œé€šå¸¸å°† Qã€K å’Œ V é€šè¿‡å¤šä¸ªä¸åŒçš„çº¿æ€§å˜æ¢çŸ©é˜µè¿›è¡Œå¤šæ¬¡è®¡ç®—ï¼Œå¾—åˆ°å¤šä¸ªæ³¨æ„åŠ›å¤´ (Attention Heads). æ¯ä¸ªå¤´çš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ï¼Œä½†å®ƒä»¬çš„ç»“æœä¼šåœ¨æœ€åè¿›è¡Œæ‹¼æ¥å¹¶ç»è¿‡çº¿æ€§å˜æ¢ã€‚æœ€ç»ˆçš„ Multi-Head Attention å…¬å¼ä¸ºï¼š</p>
$$
\text{MultiHead}(Q,K,V)=\text{Concat}(head_1,head_2,\ldots,head_h)W^O
$$<p><br>æ¯ä¸ªå¤´ $head_i$ è®¡ç®—å…¬å¼ä¸º</p>
$$
\text{MultiHead}(Q,K,V)=\text{Concat}(head_1,head_2,\ldots,head_h)W^O
$$<p><br>è¿™é‡Œçš„ $W^{Q}_{i},W^{K}_{i},W^{V}_{i}$ æ˜¯ä¸ºæ¯ä¸ªå¤´å­¦ä¹ åˆ°çš„ä¸åŒæƒé‡çŸ©é˜µï¼Œ$W^O$ æ˜¯è¾“å‡ºçš„çº¿æ€§å˜æ¢çŸ©é˜µã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB85e0bf86b5d9f2c649bbc3f08c03d203?method=download&amp;shareKey=b5e662d324237709f786beb08c27b774" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB85e0bf86b5d9f2c649bbc3f08c03d203?method=download&amp;shareKey=b5e662d324237709f786beb08c27b774" alt="Multi-Head Attention">
    </a><figcaption>Multi-Head Attention</figcaption></figure></p>
<p>Decoder ä¸­çš„ Masked MHA ç¡®ä¿æ¨¡å‹åªèƒ½åœ¨è§£ç åºåˆ—çš„å½“å‰ä½ç½®åŠå…¶ä¹‹å‰çš„ä½ç½®ä¸Šæ“ä½œï¼Œè€Œä¸èƒ½ â€œçœ‹åˆ°â€ å°†è¦ç”Ÿæˆçš„æœªæ¥ä¿¡æ¯ã€‚ä¸æ ‡å‡†çš„ MHA ç›¸åŒï¼Œæ³¨æ„åŠ›åˆ†æ•° $\mathrm{Attention Scores}=\frac{QK^T}{\sqrt{d_k}}$ æ˜¯é€šè¿‡ Q å’Œ K çš„ç‚¹ç§¯è®¡ç®—å¾—åˆ°çš„ã€‚è®¡ç®—å®Œæˆåæˆ‘ä»¬ç»™å…¶åŠ ä¸Šä¸€ä¸ªä¸‹ä¸‰è§’å…ƒç´  (åŒ…å«ä¸»å¯¹è§’çº¿) ä¸º 0ï¼Œä¸Šä¸‰è§’å…ƒç´ ä¸º â€”âˆ çš„ maskï¼Œè¿™æ ·æœªæ¥çš„ä¿¡æ¯ç»è¿‡ Softmax åçš„æƒé‡ä¸º 0ï¼Œè¢«å®Œå…¨å±è”½ã€‚</p>
<h2 id="grouped-query-attentiongqa-multi-query-attention-mqa">Grouped Query Attentionï¼ˆGQAï¼‰&amp; Multi-query Attention (MQA)<a hidden class="anchor" aria-hidden="true" href="#grouped-query-attentiongqa-multi-query-attention-mqa">#</a></h2>
<p><a href="https://arxiv.org/pdf/2305.13245">GQA</a> å°†å¤šä¸ª Q åˆ†æˆè‹¥å¹²ç»„ï¼Œæ¯ä¸€ç»„å…±äº«ç›¸åŒçš„æƒé‡çŸ©é˜µã€‚è¿™ä½¿å¾—æ¯ç»„æŸ¥è¯¢å¯ä»¥å…±åŒå¤„ç†åŒä¸€ä¸ª K å’Œ Vï¼Œé™ä½äº†è®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚ã€‚åœ¨ MHA ä¸­ï¼Œæ‰€æœ‰çš„å¤´å…±äº«ç›¸åŒçš„è¾“å…¥ Xï¼Œä½†ä½¿ç”¨ä¸åŒçš„æŠ•å½±çŸ©é˜µæ¥ç”Ÿæˆ K å’Œ V. GQA ä¸­ K å’Œ V é€šå¸¸æ˜¯å¯¹è¾“å…¥ X è¿›è¡Œä¸€æ¬¡æ€§çº¿æ€§å˜æ¢ï¼Œå¹¶åœ¨æ‰€æœ‰åŒä¸€åˆ†ç»„ä¸­çš„ Q å…±äº«ã€‚MQA æ›´ä¸ºæç«¯ï¼Œæ‰€æœ‰çš„ Q å…±äº«ä¸€ä¸ª K å’Œ V.</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB3c7dc003db55abf4b8a1ebeb4aabd667?method=download&amp;shareKey=f1570d975432b38d6f74742e9bb4cf6e" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB3c7dc003db55abf4b8a1ebeb4aabd667?method=download&amp;shareKey=f1570d975432b38d6f74742e9bb4cf6e" alt="Overview of MHA, GQA &amp; MQA">
    </a><figcaption>Overview of MHA, GQA &amp; MQA</figcaption></figure></p>
<h2 id="multi-head-cross-attention">Multi-Head Cross Attention<a hidden class="anchor" aria-hidden="true" href="#multi-head-cross-attention">#</a></h2>
<p>Multi-Head Cross Attention æ˜¯ Transformer Decoder ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒç»„ä»¶ã€‚ä¸ Self-Attention ä¸åŒï¼ŒCross Attention è´Ÿè´£å°†è§£ç å™¨çš„éšè—çŠ¶æ€ä¸ç¼–ç å™¨çš„è¾“å‡ºä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œäº¤äº’ï¼Œå…è®¸è§£ç å™¨çš„æ¯ä¸€ä¸ªè§£ç æ—¶é—´æ­¥çš„çŠ¶æ€ <strong>æŸ¥çœ‹æ•´ä¸ªç¼–ç å™¨çš„è¾“å‡º</strong>ã€‚æ¯ä¸ªè§£ç çš„æ—¶é—´æ­¥ tï¼ŒDecoder çš„éšè—çŠ¶æ€ä½œä¸º Qï¼ŒEncoder çš„è¾“å‡ºä½œä¸º K å’Œ Vï¼Œè®¡ç®—è¿‡ç¨‹ä¸ æ ‡å‡†çš„ Self-Attention ç›¸åŒã€‚</p>
<h1 id="evolution-tree-of-transformer">Evolution Tree of Transformer<a hidden class="anchor" aria-hidden="true" href="#evolution-tree-of-transformer">#</a></h1>
<p>åç»­çš„ç ”ç©¶é€æ¸æŠŠ Encoder å’Œ Decoder åˆ†ç¦»å¼€æ¥ï¼Œå½¢æˆ Encoder-Only å’Œ Decoder-Only çš„æ¨¡å‹ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBa2db49ee75b563db2d846dab14947060?method=download&amp;shareKey=12514a3314f3bb4c5e30936c2d634650" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBa2db49ee75b563db2d846dab14947060?method=download&amp;shareKey=12514a3314f3bb4c5e30936c2d634650" alt="Transformer Evolution Tree">
    </a><figcaption>Transformer Evolution Tree</figcaption></figure></p>
<h2 id="feed-forward-network">Feed Forward Network<a hidden class="anchor" aria-hidden="true" href="#feed-forward-network">#</a></h2>
<p>FFN æ˜¯ä¸€ä¸ªä¸¤å±‚çš„å‰é¦ˆå…¨è¿æ¥ç½‘ç»œï¼Œä¸­é—´æœ‰ä¸€ä¸ªéçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚ç¬¬ä¸€å±‚å…¨è¿æ¥å°† $d_model$ æ˜ å°„åˆ° $4d_model$ ï¼Œç»è¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°åï¼Œç¬¬äºŒå±‚å…¨è¿æ¥å†é‡æ–°æ˜ å°„å› $d_model$.</p>
<h1 id="decoder-only-transformer">Decoder-Only Transformer<a hidden class="anchor" aria-hidden="true" href="#decoder-only-transformer">#</a></h1>
<p>Decoder-Only åˆ é™¤äº†åŸå…ˆ Transformer Encoder çš„éƒ¨åˆ†ä»¥åŠ Encoder å’Œ Decoder è¿›è¡Œ Cross Attention çš„éƒ¨åˆ†ã€‚å®ƒå…·æœ‰ä¸‰ä¸ªå¿…è¦çš„ç‰¹å¾:</p>
<ol>
<li>åœ¨ç»™å®šç¼–ç å™¨è¾“å…¥ä½œä¸ºä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹åŸºäºè¿„ä»Šä¸ºæ­¢ç”Ÿæˆçš„ token è‡ªåŠ¨å›å½’é¢„æµ‹ä¸‹ä¸€ä¸ªã€‚</li>
<li>åœ¨è¯„ä¼°å¯¹è¾“å…¥åºåˆ—çš„ Q æ—¶çœ‹ä¸åˆ°æœªæ¥å€¼ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»…è§£ç å™¨çš„æ¨¡å‹é€šå¸¸è¢«ç§°ä¸º Casual Language Model (CLM).</li>
<li>è®­ç»ƒæ¨¡å‹ä»¥åœ¨ç»™å®šå½“å‰è¾“å…¥åºåˆ—çš„æƒ…å†µä¸‹é¢„æµ‹ä¸‹ä¸€ä¸ª token. è¿™ç§è®­ç»ƒæ–¹æ³•ä¸å›å½’ç›¸ç»“åˆï¼Œå…è®¸æ¨¡å‹è‡ªå›å½’ç”Ÿæˆä»»æ„é•¿ (æœ€é«˜è¾¾è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦) çš„åºåˆ—ã€‚</li>
</ol>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBa6c37075488053053efa01808163d0ba?method=download&amp;shareKey=5542015805dbda24ff7ab5dbf44a368b" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBa6c37075488053053efa01808163d0ba?method=download&amp;shareKey=5542015805dbda24ff7ab5dbf44a368b" alt="Decoder-only (left) and Encoder-only (right) Transformer Architectures">
    </a><figcaption>Decoder-only (left) and Encoder-only (right) Transformer Architectures</figcaption></figure></p>
<h1 id="llama-transformer-architecture">LLaMA Transformer Architecture<a hidden class="anchor" aria-hidden="true" href="#llama-transformer-architecture">#</a></h1>
<p>LLaMA Transformer ç»“æ„å¦‚ä¸‹ï¼Œä¸»è¦æœ‰ä»¥ä¸‹å˜åŒ–</p>
<ol>
<li>ä½¿ç”¨ RoPE (Rotary Position Embedding) æ›¿ä»£ä¼ ç»Ÿçš„ä½ç½®ç¼–ç ã€‚</li>
<li>RMSNorm æ›¿ä»£ LayerNorm</li>
<li>å¼•å…¥ Gated Linear Unit (GLU)</li>
</ol>
<h2 id="rotary-position-embedding">Rotary Position Embedding<a hidden class="anchor" aria-hidden="true" href="#rotary-position-embedding">#</a></h2>
<p>ä¼ ç»Ÿçš„ Transformer æ¨¡å‹ä½¿ç”¨å¯å­¦ä¹ çš„ç»å¯¹ä½ç½®ç¼–ç  (å¦‚ sinusoidal position embedding)ï¼Œä½† RoPE é‡‡ç”¨äº†æ—‹è½¬çŸ©é˜µçš„æ€æƒ³ï¼Œå°†ä½ç½®ç¼–ç ä¸è¾“å…¥çš„ token è¡¨ç¤ºç›´æ¥ç»“åˆï¼Œè€Œä¸ä¾èµ–äºé¢å¤–çš„å¯å­¦ä¹ å‚æ•°ã€‚</p>
<p>è¾“å…¥å‘é‡çš„æ—‹è½¬è§’åº¦ä¸º $\theta(p,i)=p\cdot10000^{-2i/d}$. p è¡¨ç¤ºä½ç½®ç´¢å¼•ï¼Œi è¡¨ç¤ºç»´åº¦ç´¢å¼•ï¼Œd ä¸ºå‘é‡çš„æ€»ç»´åº¦ã€‚å¯¹äºè¾“å…¥çš„ token å‘é‡ x ä¸­çš„æ¯ä¸€å¯¹å¶æ•°å’Œå¥‡æ•°ç»´åº¦ $(x_{2i},x_{2i+1})$ï¼Œæ—‹è½¬æ“ä½œå¯ä»¥ç”¨ 2D æ—‹è½¬çŸ©é˜µè¡¨ç¤ºä¸º</p>
$$\begin{bmatrix}x_{2i}^{\prime}\\x_{2i+1}^{\prime}\end{bmatrix}=\begin{bmatrix}\cos(\theta)&-\sin(\theta)\\\sin(\theta)&\cos(\theta)\end{bmatrix}\cdot\begin{bmatrix}x_{2i}\\x_{2i+1}\end{bmatrix}$$<p><br>å¯¹äºè¾“å…¥çš„ token å‘é‡ $\mathbf{x}\left[x_{0},x_{1},x_{2},x_{3},\cdots,x_{d-1}\right]$, RoPE å°†å…¶ä¸¤ä¸¤ä¸€ç»„é…å¯¹ï¼Œæ¯ä¸€ç»„éƒ½ä¼šä¸ä½ç½®ç›¸å…³çš„æ—‹è½¬è§’åº¦ Î¸ å¯¹åº”åœ°åº”ç”¨æ—‹è½¬æ“ä½œã€‚è¿™ä¸ªè¿‡ç¨‹çš„æœ¬è´¨æ˜¯å¯¹è¾“å…¥ token çš„è¡¨ç¤ºåšäº†æ—‹è½¬å˜æ¢ï¼Œä½¿å¾—è¿™äº›ç‰¹å¾ä¸ä»…ä¾èµ–äºè¾“å…¥çš„ç‰¹å¾ï¼Œè¿˜éšå«äº†è¯¥ token åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBf24aca24d7ff8bc2901ca4983cbf6c47?method=download&amp;shareKey=9ac054d415fe2e172bb8a719935d4793" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBf24aca24d7ff8bc2901ca4983cbf6c47?method=download&amp;shareKey=9ac054d415fe2e172bb8a719935d4793" alt="RoPE">
    </a><figcaption>RoPE</figcaption></figure></p>
<h2 id="rmsnorm">RMSNorm<a hidden class="anchor" aria-hidden="true" href="#rmsnorm">#</a></h2>
<p>RMSNorm ç›¸å¯¹äº LayerNorm å»æ‰äº†å‡å€¼è®¡ç®—ï¼Œä»…åŸºäºè¾“å…¥çš„å‡æ–¹æ ¹è¿›è¡Œå½’ä¸€åŒ– $\mathrm{RMSNorm}(\mathbf{x})=\frac{\mathbf{x}}{\mathrm{RMS}(\mathbf{x})+\epsilon}\cdot\gamma$</p>
<p>å…¶ä¸­</p>
<ul>
<li>$\mathrm{RMS}(\mathbf{x})=\sqrt{\frac1d\sum_{i=1}^dx_i^2}$ ä¸ºè¾“å…¥çš„å‡æ–¹æ ¹ã€‚</li>
<li>$\gamma{:}$ ä¸ºå¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•°ã€‚</li>
<li>$\epsilon{:}$ ä¸ºé˜²æ­¢é™¤ä»¥ 0 çš„å°æ•°ã€‚</li>
</ul>
<h2 id="silu">SiLU<a hidden class="anchor" aria-hidden="true" href="#silu">#</a></h2>
<p>SiLU (Sigmoid Linear Unit) æ˜¯ä¸€ç§æ¿€æ´»å‡½æ•°ï¼Œä¹Ÿç§°ä¸º Swishï¼Œå…¶å®šä¹‰ä¸ºè¾“å…¥ x å’Œ Sigmoid å‡½æ•°è¾“å‡ºçš„ä¹˜ç§¯ã€‚å…¶å®šä¹‰ä¸º
</p>
$$\mathrm{SiLU}(x)=x\cdot\sigma(x)$$<p>
å…¶ä¸­ $\sigma(x)=\frac1{1+e^{-x}}$</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB552a846c520bf2b5194c621e7b8e224e?method=download&amp;shareKey=519f3a1e4cce59da1895fa7bc2bcc842" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB552a846c520bf2b5194c621e7b8e224e?method=download&amp;shareKey=519f3a1e4cce59da1895fa7bc2bcc842" alt="SiLU">
    </a><figcaption>SiLU</figcaption></figure></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:57770/tags/transformer/">Transformer</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:57770/blogs/astra-sim/">
    <span class="title">Â« Prev</span>
    <br>
    <span>astra-Sim</span>
  </a>
  <a class="next" href="http://localhost:57770/blogs/zero/">
    <span class="title">Next Â»</span>
    <br>
    <span>ZeRO, ZeRO-Offload, ZeRO-Infinity</span>
  </a>
</nav>

  </footer><script src="https://giscus.app/client.js"
        data-repo="jamesnulliu/jamesnulliu.github.io"
        data-repo-id="R_kgDOMPCQIw"
        data-category="Announcements"
        data-category-id="DIC_kwDOMPCQI84Cgb2t"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>Â© 2024-2025 WITHER</span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
