[{"content":"Problem Description è¯¦æƒ…è¯·è§é¢˜ç›®é“¾æ¥ï¼Œè¿™é‡Œç®€è¦è¯´æ˜ä¸‹:é¢˜ç›®è¦æ±‚æ˜¯ä¼˜åŒ– rotate_the_bit_vector_left() å‡½æ•°ï¼Œè¯¥å‡½æ•°å°† bit_vector çš„ä¸€æ®µä»å·¦å¾€å³æ•°ç¬¬ bit_offset ä½ä¸ºèµ·å§‹ç‚¹, é•¿åº¦ä¸º bit_length çš„å­æ•°ç»„çš„å‰ bit_amount ä½å¾ªç¯å·¦ç§»ã€‚\nbit_vector.h å’Œ bit_vector.c ä¸­æœ‰ä¸€äº›æœ‰ç”¨çš„å‡½æ•°å£°æ˜å®šä¹‰ã€‚\nmodulo(): è¿”å› r = n (mod m) çš„ç»“æœï¼Œå…¶ä¸­ 0 \u0026lt;= r \u0026lt; m. bitmask(): è¿”å›å’Œä¸€ä¸ª byte ç›¸ä¸æ—¶ä¿ç•™ä»å³å¾€å·¦æ•°çš„ç¬¬ bit_index ä½çš„æ©ç ã€‚ bit_vector_get_bit_sz(): è·å–ä¸€ä¸ª bit_vector å¯¹è±¡çš„ä½æ•°ã€‚ bit_vector_get(): è·å–ä¸€ä¸ª bit_vector ç¬¬ bit_index ä½çš„å€¼ã€‚ bit_vector_set(): å°†ä¸€ä¸ª bit_vector ç¬¬ bit_index ä½çš„å€¼è®¾ç½®ä¸º value. Vanilla Method Analysis perf æ˜¯ Linux å†…æ ¸å†…ç½®çš„æ€§èƒ½åˆ†æå·¥å…· (Performance Counters for Linux)ï¼Œå®ƒå¯ä»¥å¸®åŠ©é‡‡æ ·ç¨‹åºçš„ CPU ä½¿ç”¨æƒ…å†µã€å‡½æ•°è°ƒç”¨æ ˆã€çƒ­ç‚¹ä»£ç ç­‰ï¼Œä»è€Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆã€‚\nHow to install perf tools in WSL2 # windows wsl --update # wsl 2 sudo apt update sudo apt install flex bison sudo apt install pkg-config # operator \u0026#39;\u0026amp;\u0026amp;\u0026#39; has no right operand sudo apt install libdwarf-dev libelf-dev libnuma-dev libunwind-dev \\ libnewt-dev libdwarf++0 libelf++0 libdw-dev libbfb0-dev \\ systemtap-sdt-dev libssl-dev libperl-dev python-dev-is-python3 \\ binutils-dev libiberty-dev libzstd-dev libcap-dev libbabeltrace-dev libtraceevent-dev git clone https://github.com/microsoft/WSL2-Linux-Kernel --depth 1 cd WSL2-Linux-Kernel/tools/perf make -j8 # parallel build sudo cp perf /usr/local/bin æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹åŸå§‹ rotate_the_bit_vector_left() çš„æ‰§è¡Œæµç¨‹:\nå®ƒæœ‰ä¸€ä¸ªå¾ªç¯ï¼Œéœ€è¦æ—‹è½¬ bit_left_amount æ¬¡ã€‚ åœ¨å¾ªç¯å†…éƒ¨ï¼Œå®ƒè°ƒç”¨ rotate_the_bit_vector_left_one() å‡½æ•°ã€‚ è¯¥å‡½æ•°çš„ä½œç”¨æ˜¯å°†å­æ•°ç»„å·¦æ—‹ä¸€ä½ã€‚å®ƒå†…éƒ¨åˆæœ‰ä¸€ä¸ªå¾ªç¯ï¼Œéœ€è¦éå† bit_length - 1 æ¬¡ï¼Œæ¯æ¬¡éƒ½è°ƒç”¨ bit_vector_get å’Œ bit_vector_set æ¥ç§»åŠ¨ä¸€ä¸ªæ¯”ç‰¹ä½ã€‚ æ‰€ä»¥ï¼Œæ€»çš„æ“ä½œæ¬¡æ•°å¤§çº¦æ˜¯ bit_left_amount * bit_length æ¬¡æ¯”ç‰¹è¯»å†™ã€‚\nç¼–è¯‘å¥½åä½¿ç”¨ perf record ./everybit -s å‘½ä»¤ç”Ÿæˆ perf.data æ–‡ä»¶åä½¿ç”¨ perf report å‘½ä»¤æ˜¾ç¤ºé‡‡æ ·ç»“æœã€‚\nSamples: 105 of event \u0026#39;cpu-clock:ppp\u0026#39;, Event count (approx.): 26250000 Overhead Command Shared Object Symbol 52.38% everybit everybit [.] bit_vector_set 33.33% everybit everybit [.] bit_vector_get 10.48% everybit everybit [.] rotate_the_bit_vector 0.95% everybit [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore 0.95% everybit [kernel.kallsyms] [k] put_cpu_partial 0.95% everybit [kernel.kallsyms] [k] queue_work_on 0.95% everybit ld-linux-x86-64.so.2 [.] 0x00000000000131d2 æ ¹æ® perf çš„æ€§èƒ½åˆ†ææŠ¥å‘Šï¼Œè¶…è¿‡ 85% çš„æ—¶é—´éƒ½æ¶ˆè€—åœ¨äº† bit_vector_set (52.38%) å’Œ bit_vector_get (33.33%) è¿™ä¸¤ä¸ªå‡½æ•°ä¸Šï¼Œè¯´æ˜å½“å‰çš„ç®—æ³•å¯¹å•ä¸ªæ¯”ç‰¹ä½çš„è¯»å†™æ“ä½œè¿‡äºé¢‘ç¹ã€‚\nOptimization 1: 3-step Rotation æˆ‘ä»¬å¯ä»¥å€Ÿé‰´æ•°ç»„æ—‹è½¬çš„ç»å…¸â€œä¸‰æ­¥åè½¬æ³•â€æ€æƒ³ï¼Œä½†åœ¨è¿™é‡Œæ›´ç›´è§‚çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸€ä¸ªä¸´æ—¶ç¼“å†²åŒºã€‚æƒ³è±¡ä¸€ä¸‹æŠŠå­—ç¬¦ä¸² \u0026ldquo;ABCDEFG\u0026rdquo; å·¦æ—‹ 3 ä½:\nä¿å­˜: å…ˆæŠŠè¦è¢«ç§»åˆ°æœ«å°¾çš„å‰3ä¸ªå­—ç¬¦ \u0026ldquo;ABC\u0026rdquo; ä¿å­˜èµ·æ¥ã€‚ ç§»åŠ¨: æŠŠåé¢çš„ \u0026ldquo;DEFG\u0026rdquo; ç§»åŠ¨åˆ°å¼€å¤´ï¼Œå­—ç¬¦ä¸²å˜æˆ \u0026ldquo;DEFG___\u0026quot;ã€‚ æ”¾å›: æŠŠä¿å­˜çš„ \u0026ldquo;ABC\u0026rdquo; æ”¾åˆ°æœ«å°¾çš„ç©ºç™½å¤„ï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ \u0026ldquo;DEFGABC\u0026rdquo;ã€‚ è¿™ä¸ªè¿‡ç¨‹åªæ¶‰åŠä¸‰æ¬¡æ‰¹é‡æ“ä½œï¼Œè€Œä¸æ˜¯åƒåŸç®—æ³•é‚£æ ·æ‰§è¡Œ 3 æ¬¡ï¼ˆæ—‹è½¬ä½æ•°ï¼‰* 7 æ¬¡ï¼ˆé•¿åº¦ï¼‰çš„å•å­—ç¬¦ç§»åŠ¨ã€‚å…·ä½“æ­¥éª¤å’Œå¯¹åº”ä»£ç å¦‚ä¸‹\nåˆ†é…ç¼“å†²åŒº: æ ¹æ®è¦æ—‹è½¬çš„ä½æ•° bit_left_amountï¼Œç”³è¯·ä¸€å—è¶³å¤Ÿå¤§çš„å†…å­˜ä½œä¸ºä¸´æ—¶ç¼“å†²åŒºã€‚ ä¿å­˜å‰ç¼€: å°†å­æ•°ç»„æœ€å‰é¢çš„ bit_left_amount ä¸ªæ¯”ç‰¹ä½å¤åˆ¶åˆ°ç¼“å†²åŒºä¸­ã€‚ ç§»åŠ¨ä¸»ä½“: å°†å­æ•°ç»„ä¸­å‰©ä¸‹çš„ bit_length - bit_left_amount ä¸ªæ¯”ç‰¹ä½æ•´ä½“å‘å‰ç§»åŠ¨ bit_left_amount ä½ã€‚ å†™å›å‰ç¼€: å°†ç¼“å†²åŒºé‡Œä¿å­˜çš„æ¯”ç‰¹ä½å†™å›åˆ°å­æ•°ç»„çš„æœ«å°¾ã€‚ é‡Šæ”¾ç¼“å†²åŒº: é‡Šæ”¾ç¬¬ä¸€æ­¥ç”³è¯·çš„å†…å­˜ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 static void rotate_the_bit_vector_left(bit_vector_t* const bit_vector, const size_t bit_offset, // å¼€å§‹æ—‹è½¬çš„èµ·ç‚¹ const size_t bit_length, // æ—‹è½¬çš„é•¿åº¦ const size_t bit_left_amount) { // æ—‹è½¬çš„ä½æ•° if (bit_length == 0 || bit_left_amount == 0) { return; } const size_t effective_amount = bit_left_amount % bit_length; if (effective_amount == 0) { return; } // 1. åˆ†é…ä¸´æ—¶ç¼“å†²åŒºæ¥å­˜å‚¨è¢«æ—‹è½¬åˆ°æœ«å°¾çš„ bits const size_t prefix_bytes = (effective_amount + 7) / 8; char* prefix_buffer = (char*) calloc(prefix_bytes, sizeof(char)); if (prefix_buffer == NULL) { return; } // 2. å°†å­æ•°ç»„å‰ effective_amount ä¸ª bits å¤åˆ¶åˆ°ä¸´æ—¶ç¼“å†²åŒº for (size_t i = 0; i \u0026lt; effective_amount; i++) { if (bit_vector_get(bit_vector, bit_offset + i)) { // å­æ•°ç»„ç¬¬ i ä½æ˜¯å¦ä¸º 1 prefix_buffer[i / 8] |= bitmask(i); } } // 3. å°†å­æ•°ç»„å‰©ä¸‹çš„éƒ¨åˆ†å‘å‰ç§»åŠ¨ const size_t bits_to_move = bit_length - effective_amount; for (size_t i = 0; i \u0026lt; bits_to_move; i++) { bool bit = bit_vector_get(bit_vector, bit_offset + effective_amount + i); // è¦ç§»åŠ¨çš„ bit bit_vector_set(bit_vector, bit_offset + i, bit); } // 4. å°†ç¼“å†²åŒºä¿å­˜çš„ bits å†™å›å­æ•°ç»„æœ«å°¾ const size_t paste_offset = bit_offset + bits_to_move; for (size_t i = 0; i \u0026lt; effective_amount; i++) { bool bit = (prefix_buffer[i / 8] \u0026amp; bitmask(i)) != 0; // ä»ç¼“å†²åŒºè¯»å…¥ bit bit_vector_set(bit_vector, paste_offset + i, bit); } free(prefix_buffer); } è¯¥æ–¹æ³•ç»™å‡ºçš„è¯„åˆ†å¦‚ä¸‹\ncheck result: PASSED performance of -s: 28 performance of -m: 33 performance of -l: 38 ------score-------- -s : 70.00 /100 -m : 77.27 /100 -l : 80.00 /100 total score: 77.18 /100 Optimization 2: From bit-by-bit To byte-level è¿›ä¸€æ­¥ä¼˜åŒ–çš„ç‚¹æ˜¯å°†æŒ‰ä½æ‹·è´æ“ä½œæ”¹æˆä¸€æ¬¡æ“ä½œ 8 ä¸ªå­—èŠ‚ (éœ€è¦è€ƒè™‘å¯¹é½é—®é¢˜). æ‹·è´ä»»åŠ¡åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µå¤„ç†ï¼Œä»¥ä¼˜åŒ–æ€§èƒ½å¹¶å¤„ç†éå¯¹é½çš„ä½åç§»:\nå¤´éƒ¨å¤„ç†: å¤„ç†ç›®æ ‡åœ°å€éå­—èŠ‚å¯¹é½çš„ä½ã€‚ è®¡ç®—ç›®æ ‡åç§»çš„éå¯¹é½éƒ¨åˆ†ã€‚å¦‚æœç›®æ ‡åç§»ä¸æ˜¯å­—èŠ‚çš„å¼€å§‹ç‚¹ï¼Œéœ€è¦å…ˆæ‹·è´å°‘é‡ä½ï¼Œç›´åˆ°ç›®æ ‡åœ°å€å¯¹é½åˆ°å­—èŠ‚è¾¹ç•Œã€‚æ‹·è´çš„ä½æ•°æ˜¯å‰©ä½™åˆ°ä¸‹ä¸€ä¸ªå­—èŠ‚è¾¹ç•Œçš„ä½æ•°ï¼Œä½†ä¸èƒ½è¶…è¿‡ num_bits. ä¸­é—´å—å¤„ç†: ä»¥ 64 ä½ä¸ºå•ä½é«˜æ•ˆæ‹·è´å¯¹é½çš„å—ã€‚æ ¹æ®æºæ˜¯å¦å­—èŠ‚å¯¹é½ï¼Œåˆ†ä¸¤ç§æƒ…å†µ: æºå’Œç›®æ ‡éƒ½æŒ‰å­—èŠ‚å¯¹é½ï¼Œç›´æ¥ä½¿ç”¨ memmove æ‹·è´æ‰€æœ‰å­—èŠ‚ã€‚ æºéå­—èŠ‚å¯¹é½: ä½¿ç”¨ memcpy è¯»å– 8 å­—èŠ‚åˆ° uint64_t wordï¼Œé¿å…æœªå¯¹é½è®¿é—®é—®é¢˜ã€‚ è¯»å–ä¸‹ä¸€ä¸ªå­—èŠ‚ (next_byte = src_ptr[8])ï¼Œç”¨äºä½ç§»æ‹¼æ¥ã€‚å°†å½“å‰ 64 ä½å³ç§»å¹¶æ‹¼æ¥ä¸‹ä¸€å­—èŠ‚çš„ä½ (word \u0026gt;\u0026gt; src_bit_shift) | (next_byte \u0026lt;\u0026lt; (64 - src_bit_shift)) åå°†ç»“æœå†™å…¥ç›®æ ‡åœ°å€ã€‚ å°¾éƒ¨å¤„ç†: å¤„ç†å‰©ä½™ä¸è¶³ 64 ä½çš„éƒ¨åˆ†ã€‚é€ bit æ‹·è´ (|= è®¾ç½®ä¸º 1ï¼Œ\u0026amp;= ~ æ¸…é›¶). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 static void bit_block_move_ultimate(char* dest_data, size_t dest_bit_offset, const char* src_data, size_t src_bit_offset, size_t num_bits) { if (num_bits == 0) { return; } // åŒæ ·ï¼Œé‡å æ‹·è´çš„å¤„ç†å¯¹äºä¸€ä¸ªå¥å£®çš„å‡½æ•°æ˜¯å¿…éœ€çš„ã€‚ // è¿™é‡Œçš„ assert ä»…ç”¨äºæŒ‡å‡ºè¿™ä¸ªç®€åŒ–ã€‚ if (dest_data == src_data \u0026amp;\u0026amp; dest_bit_offset \u0026gt; src_bit_offset) { assert(dest_bit_offset \u0026gt;= src_bit_offset + num_bits); // å®é™…ä»£ç ä¸­éœ€è¦å®ç°åå‘æ‹·è´ } // 1. å¤„ç†å¤´éƒ¨çš„éå¯¹é½ bitï¼Œä½¿å¾—ç›®æ ‡åœ°å€æŒ‰å­—èŠ‚å¯¹é½ size_t dest_align_offset = dest_bit_offset % 8; if (dest_align_offset != 0) { size_t bits_in_head = 8 - dest_align_offset; if (bits_in_head \u0026gt; num_bits) { bits_in_head = num_bits; } // é€ bit æ‹·è´å¤´éƒ¨ for (size_t i = 0; i \u0026lt; bits_in_head; ++i) { if ((src_data[(src_bit_offset + i) / 8] \u0026gt;\u0026gt; ((src_bit_offset + i) % 8)) \u0026amp; 1) { dest_data[(dest_bit_offset + i) / 8] |= (1 \u0026lt;\u0026lt; ((dest_bit_offset + i) % 8)); } else { dest_data[(dest_bit_offset + i) / 8] \u0026amp;= ~(1 \u0026lt;\u0026lt; ((dest_bit_offset + i) % 8)); } } num_bits -= bits_in_head; src_bit_offset += bits_in_head; dest_bit_offset += bits_in_head; } // 2. å¤„ç†ä¸­é—´çš„ 64 ä½å¯¹é½å— size_t num_blocks = num_bits / 64; if (num_blocks \u0026gt; 0) { char* dest_ptr = dest_data + dest_bit_offset / 8; const char* src_ptr = src_data + src_bit_offset / 8; size_t src_bit_shift = src_bit_offset % 8; if (src_bit_shift == 0) { // æºå’Œç›®æ ‡éƒ½å·²å¯¹é½ï¼Œå¯ä»¥ç›´æ¥ memmove memmove(dest_ptr, src_ptr, num_blocks * 8); } else { for (size_t i = 0; i \u0026lt; num_blocks; ++i) { uint64_t word; // ã€ä¿®æ­£ #3 \u0026amp; #4ã€‘å®‰å…¨åœ°è¯»å–æºæ•°æ® // ä½¿ç”¨ memcpy æ¥é¿å…ä¸å¯¹é½è¯»å–ï¼ŒåŒæ—¶å®ƒä¹Ÿæ¯”é€å­—èŠ‚æ‹¼æ¥é«˜æ•ˆ memcpy(\u0026amp;word, src_ptr, sizeof(uint64_t)); // ä¸ºäº†æ‹¼æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸‹ä¸€ä¸ªå­—èŠ‚çš„æ•°æ® uint64_t next_byte = 0; // è®¡ç®—éœ€è¦æ‹·è´çš„æ€»å­—èŠ‚æ•° size_t total_bits_processed = (i + 1) * 64; size_t required_src_bytes = (src_bit_offset + total_bits_processed - dest_bit_offset + 7) / 8; next_byte = (uint64_t)src_ptr[8]; uint64_t result = (word \u0026gt;\u0026gt; src_bit_shift) | (next_byte \u0026lt;\u0026lt; (64 - src_bit_shift)); memcpy(dest_ptr, \u0026amp;result, sizeof(uint64_t)); dest_ptr += 8; src_ptr += 8; } } size_t bits_in_middle = num_blocks * 64; num_bits -= bits_in_middle; src_bit_offset += bits_in_middle; dest_bit_offset += bits_in_middle; } // 3. å¤„ç†å°¾éƒ¨å‰©ä½™çš„ä¸è¶³ 64 ä½çš„ bit if (num_bits \u0026gt; 0) { for (size_t i = 0; i \u0026lt; num_bits; ++i) { if ((src_data[(src_bit_offset + i) / 8] \u0026gt;\u0026gt; ((src_bit_offset + i) % 8)) \u0026amp; 1) { dest_data[(dest_bit_offset + i) / 8] |= (1 \u0026lt;\u0026lt; ((dest_bit_offset + i) % 8)); } else { dest_data[(dest_bit_offset + i) / 8] \u0026amp;= ~(1 \u0026lt;\u0026lt; ((dest_bit_offset + i) % 8)); } } } } å®Œæ•´çš„å‡½æ•°å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 void rotate_the_bit_vector(bit_vector_t* const bit_vector, const size_t bit_offset, const size_t bit_length, const ssize_t bit_right_amount) { assert(bit_offset + bit_length \u0026lt;= bit_vector-\u0026gt;bit_sz); if (bit_length == 0) { return; } const size_t left_shift = modulo(-bit_right_amount, bit_length); if (left_shift == 0) { return; } // 1. åˆ†é…ä¸€ä¸ªè¶³ä»¥å®¹çº³æ•´ä¸ªæ—‹è½¬åŒºåŸŸçš„å¤§ä¸´æ—¶ç¼“å†²åŒºã€‚ // è¿™æ˜¯è§£å†³å†…å­˜å´©æºƒé—®é¢˜çš„å…³é”®ï¼Œç¡®ä¿äº†åç»­ bithack_memcpy çš„æ‰€æœ‰è¯»å–éƒ½æ˜¯å®‰å…¨çš„ã€‚ const size_t temp_buf_bytes = (bit_length + 7) / 8; char* temp_buffer = (char*)malloc(temp_buf_bytes); if (temp_buffer == NULL) { // åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œåº”æœ‰æ›´å®Œå–„çš„é”™è¯¯å¤„ç† exit(1); } // å°†æ—‹è½¬åŒºåŸŸåˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š // part_A (å‰éƒ¨): åŸæœ¬åœ¨å‰é¢ï¼Œéœ€è¦è¢«æ—‹è½¬åˆ°æœ«å°¾çš„éƒ¨åˆ†ã€‚ // part_B (åéƒ¨): åŸæœ¬åœ¨åé¢ï¼Œéœ€è¦è¢«æ—‹è½¬åˆ°å‰é¢çš„éƒ¨åˆ†ã€‚ const size_t part_A_len = left_shift; const size_t part_B_len = bit_length - left_shift; // 2. å°† part_B æ‹·è´åˆ°ä¸´æ—¶ç¼“å†²åŒºçš„å¼€å¤´ bit_block_move_ultimate(temp_buffer, 0, bit_vector-\u0026gt;buf, bit_offset + part_A_len, part_B_len); // 3. å°† part_A æ‹·è´åˆ°ä¸´æ—¶ç¼“å†²åŒºçš„æœ«å°¾ï¼Œç´§éš part_B ä¹‹å bit_block_move_ultimate(temp_buffer, part_B_len, bit_vector-\u0026gt;buf, bit_offset, part_A_len); // 4. è‡³æ­¤ï¼Œtemp_buffer ä¸­å·²æ˜¯æ—‹è½¬åçš„æ­£ç¡®åºåˆ— [B|A]. // å°†æ•´ä¸ªä¸´æ—¶ç¼“å†²åŒºä¸€æ¬¡æ€§æ‹·è´å›åŸä½ã€‚ bit_block_move_ultimate(bit_vector-\u0026gt;buf, bit_offset, temp_buffer, 0, bit_length); // 5. é‡Šæ”¾ä¸´æ—¶ç¼“å†²åŒº free(temp_buffer); } æœ€åä¹Ÿæ˜¯è¾¾åˆ°äº†æ»¡åˆ†\ncheck result: PASSED performance of -s: 36 performance of -m: 40 performance of -l: 45 ------score-------- -s : 100.00 /100 -m : 100.00 /100 -l : 100.00 /100 total score: 100.00 /100 ","permalink":"http://localhost:1313/blogs/sjtu-xflops2024/bithack/","summary":"Solution of SJTU-xflops2024 Bithack.","title":"Bithack"},{"content":"Hash 1 ç”±äºé¢˜ç›®è§„å®šä¸èƒ½ç”¨é‡å¤å…ƒç´ ï¼Œå› æ­¤è¦å…ˆåˆ¤æ–­å“ˆå¸Œè¡¨ä¸­æ˜¯å¦å·²ç»æœ‰ target - nums[i] å†å°† nums[i] åŠ å…¥åˆ°å“ˆå¸Œè¡¨ (å¦åˆ™ 2*nums[i] = target æƒ…å†µå°±ä¼šåŠ å…¥é‡å¤å…ƒç´ )\nclass Solution { public: vector\u0026lt;int\u0026gt; twoSum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { vector\u0026lt;int\u0026gt; ans; unordered_map\u0026lt;int, int\u0026gt; map; for (int i = 0; i \u0026lt; nums.size(); i++) { if (map.find(target - nums[i]) != map.end()) { ans = {i, map[target - nums[i]]}; break; } map[nums[i]] = i; } return ans; } }; 49 å­—æ¯å¼‚ä½è¯æ˜¯é€šè¿‡é‡æ–°æ’åˆ—ä¸åŒå•è¯æˆ–çŸ­è¯­çš„å­—æ¯è€Œå½¢æˆçš„å•è¯æˆ–çŸ­è¯­ï¼Œå¹¶ä½¿ç”¨æ‰€æœ‰åŸå­—æ¯ä¸€æ¬¡ã€‚\nè¿™æç¤ºæˆ‘ä»¬å¦‚æœä¸¤ä¸ªå•è¯æŒ‰å­—æ¯è¡¨é¡ºåºæ’åºåç›¸ç­‰ï¼Œé‚£ä¹ˆå°±æ˜¯å­—æ¯å¼‚ä½è¯ã€‚å¯ä»¥ç”¨ä¸€ä¸ªå“ˆå¸Œè¡¨æ¥å­˜å‚¨æ’åºåç›¸ç­‰çš„å­—ç¬¦ä¸²ã€‚\nclass Solution { public: vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; groupAnagrams(vector\u0026lt;string\u0026gt;\u0026amp; strs) { vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; ans; unordered_map\u0026lt;string, vector\u0026lt;string\u0026gt;\u0026gt; map; for (int i = 0; i \u0026lt; strs.size(); i++) { string s = strs[i]; ranges::sort(s); map[s].push_back(strs[i]); } for (auto [key, value] : map) { ans.push_back(value); } return ans; } }; 128 ç”¨ä¸€ä¸ªå“ˆå¸Œé›†åˆæ¥å­˜å‚¨ nums ä¸­çš„ä¸åŒå…ƒç´ ï¼Œè¿™æ ·å¯ä»¥å®ç°å¹³å‡ $O(1)$ æ—¶é—´å¤æ‚åº¦çš„æŸ¥æ‰¾ã€‚éå†é›†åˆä¸­çš„æ•°å­— xï¼Œå¦‚æœå‘ç° x-1 ä¹Ÿåœ¨é›†åˆä¸­ï¼Œåˆ™è·³è¿‡è¯¥æ•°å­—ã€‚å› ä¸ºä» x-1 å¼€å§‹æŸ¥æ‰¾çš„è¿ç»­é•¿åº¦è‚¯å®šæ¯”ä» x å¼€å§‹çš„é•¿ã€‚ä»æ¯ä¸€ä¸ªå¯èƒ½çš„èµ·ç‚¹ (ä¸å­˜åœ¨æ¯”ä»–å° 1 çš„æ•°å­—) æŸ¥æ‰¾è¿ç»­é•¿åº¦å¹¶ä¸æ–­æ›´æ–°ã€‚\nclass Solution { public: int longestConsecutive(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int ans = 0; unordered_set\u0026lt;int\u0026gt; s(nums.begin(), nums.end()); for (int num : s) { if (s.contains(num - 1)) { continue; } int x = 1; while (s.contains(num + 1)) { x++; num++; } ans = max(ans, x); if (ans * 2 \u0026gt;= nums.size()) { break; } } return ans; } }; Double-Pointer 283 æŠŠ 0 è§†ä½œç©ºä½\næ…¢æŒ‡é’ˆ slow æŒ‡å‘ä¸‹ä¸€ä¸ªéé›¶å…ƒç´ åº”è¯¥è¢«æ”¾ç½®çš„ä½ç½®ã€‚æ¢å¥è¯è¯´ï¼Œslow å·¦è¾¹çš„æ‰€æœ‰å…ƒç´ ï¼ˆä¸åŒ…æ‹¬slowæŒ‡å‘çš„ä½ç½®ï¼‰éƒ½æ˜¯å¤„ç†å¥½çš„ã€ä¸ä¸ºé›¶çš„å…ƒç´ ã€‚ å¿«æŒ‡é’ˆ fast å¼€å§‹å‘å³éå†æ•°ç»„ï¼Œè‹¥é‡åˆ°éé›¶å…ƒç´ åˆ™å°†å…¶å’Œ slow ä½ç½®çš„å…ƒç´ äº¤æ¢ï¼Œç„¶åï¼Œå°†æ…¢æŒ‡é’ˆ slow å‘å³ç§»åŠ¨ä¸€ä½ã€‚é‡åˆ°é›¶åˆ™ä»€ä¹ˆéƒ½ä¸åšç»§ç»­å‘å‰éå†ã€‚ è¿™æ · [slow, fast - 1] æ‰€å½¢æˆçš„åŒºé—´å†…å‡ä¸º 0.\nclass Solution { public: void moveZeroes(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int slow = 0; for (int\u0026amp; num : nums) { if (num) { swap(num, nums[slow]); slow++; } } } }; 12 ç»™å®šå·¦å³æ¨¡æ¿çš„ä½ç½® left å’Œ rightã€‚å®¹å™¨èƒ½æ¥æ°´çš„é«˜åº¦å–å†³äºè¾ƒçŸ®çš„é‚£ä¸ªã€‚å½“ç›¸å‘ç§»åŠ¨æŒ‡é’ˆçš„æ—¶å€™ï¼Œå®½åº¦å˜çŸ­ï¼Œæƒ³è¦ç››æ°´æ›´å¤šåªèƒ½å¯„å¸Œæœ›äºæ¥æ°´é«˜åº¦å¢åŠ ã€‚å› æ­¤ left \u0026lt; right çš„æ—¶å€™æˆ‘ä»¬ç§»åŠ¨æŒ‡å‘è¾ƒçŸ®æœ¨æ¿çš„æŒ‡é’ˆã€‚\nclass Solution { public: int maxArea(vector\u0026lt;int\u0026gt;\u0026amp; height) { int ans = 0; int left = 0, right = height.size() - 1; while (left \u0026lt; right) { int area = min(height[left],height[right]) * (right - left); ans = max(area, ans); height[left] \u0026lt; height[right] ? left++ : right--; } return ans; } }; 15 æƒ³æ‰¾åˆ° a + b + c = 0ï¼Œå¦‚æœèƒ½ç¡®å®šä¸€ä¸ªæ•° aï¼Œé—®é¢˜å°±å˜æˆäº†åœ¨æ•°ç»„å‰©ä¸‹çš„éƒ¨åˆ†å¯»æ‰¾ä¸¤ä¸ªæ•° b å’Œ cï¼Œä½¿å¾— b + c = -a. è¿™å°±ä»ä¸‰æ•°ä¹‹å’Œé—®é¢˜é™ç»´æˆäº†æˆ‘ä»¬ç†Ÿæ‚‰çš„ä¸¤æ•°ä¹‹å’Œé—®é¢˜ã€‚å¯¹æ•´ä¸ªæ•°ç»„è¿›è¡Œæ’åºï¼Œç„¶åéå†æ’åºåçš„æ•°ç»„ï¼Œå¯¹äºæ¯ä¸ªå…ƒç´  nums[i]ï¼Œæˆ‘ä»¬å°†å…¶è§†ä¸º aï¼Œç„¶ååœ¨å®ƒåé¢çš„åŒºé—´ [i+1, n-1] å†…ä½¿ç”¨åŒæŒ‡é’ˆæ³•å¯»æ‰¾ b å’Œ c.\nå»é‡æ³¨æ„ç‚¹\næšä¸¾çš„ç«¯ç‚¹ nums[i] å’Œä¸Šä¸€ä¸ª nums[i-1] ç›¸ç­‰æ—¶éœ€è¦è°ƒè¿‡ã€‚ åŒæŒ‡é’ˆéå†æ‰¾åˆ°ä¸€ä¸ªå¯è¡Œè§£æ—¶ï¼Œç§»åŠ¨ j å’Œ k ç›´åˆ°ä»–ä»¬æŒ‡å‘ä½ç½®çš„å…ƒç´ å’ŒåŠ å…¥ç­”æ¡ˆä¸­çš„å€¼ä¸ç›¸ç­‰ã€‚ å‰ªæä¼˜åŒ–\nnums[i] + nums[i+1] + nums[i + 2] \u0026gt; 0: è¯´æ˜ä»¥ i åŠä¹‹åä¸ºç«¯ç‚¹çš„æ‰€æœ‰ä¸‰å…ƒç»„ä¹‹å’Œå…¨éƒ½ \u0026gt; 0. ç›´æ¥é€€å‡ºå¾ªç¯ã€‚ nums[i] + nums[n - 2] + nums[n - 1] \u0026lt; 0: è¯´æ˜ ä»¥ i ä¸ºç«¯ç‚¹çš„æ‰€æœ‰ä¸‰å…ƒç»„ä¹‹å’Œå’Œå…¨éƒ½ \u0026lt; 0. æšä¸¾ä¸‹ä¸€ä¸ªç«¯ç‚¹ã€‚ class Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; threeSum(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; int n = nums.size(); ranges::sort(nums); for (int i = 0; i \u0026lt; n - 2; i++) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) continue; if (nums[i] + nums[i+1] + nums[i + 2] \u0026gt; 0) break; if (nums[i] + nums[n - 2] + nums[n - 1] \u0026lt; 0) continue; int j = i + 1, k = n - 1; while (j \u0026lt; k) { int sum = nums[i] + nums[j] + nums[k]; if (sum \u0026lt; 0) { j++; } else if (sum \u0026gt; 0) { k--; } else { ans.push_back({nums[i], nums[j], nums[k]}); j++; k--; while(j \u0026lt; k \u0026amp;\u0026amp; nums[j] == nums [j - 1]) j++; while(j \u0026lt; k \u0026amp;\u0026amp; nums[k] == nums [k + 1]) k--; } } } return ans; } }; 42 åŒæ ·æ˜¯æ¥é›¨æ°´é—®é¢˜ï¼Œæ¯ä¸ªæŸ±å­èƒ½æ¥æ°´çš„é‡ä¸ºå·¦å³ä¸¤ä¾§æŸ±å­è¾ƒçŸ®è€…å‡å»è‡ªå·±çš„é«˜åº¦ã€‚å› æ­¤åˆå§‹åŒ–ä¸¤ä¸ªæŒ‡é’ˆæŒ‡å‘å·¦å³ç«¯ç‚¹ï¼Œä»å·¦å¾€å³éå†è¿‡ç¨‹ä¸­çœ‹å“ªè¾¹æŸ±å­çŸ®å°±ç§»åŠ¨å“ªè¾¹ï¼Œä¸æ–­æ›´æ–°å·¦å³ä¾§æŸ±å­çš„æœ€å¤§é«˜åº¦ã€‚æœ€åå·¦å³æŒ‡é’ˆä¸€å®šä¼šåœ¨é«˜åº¦æœ€é«˜çš„æŸ±å­ç›¸é‡ï¼Œè€Œè¿™ä¸ªä½ç½®æ˜¯æ— æ³•æ¥æ°´çš„ã€‚\nclass Solution { public: int trap(vector\u0026lt;int\u0026gt;\u0026amp; height) { int ans = 0; int left = 0, right = height.size() - 1; int lMax = 0, rMax = 0; for (int i = 0; i \u0026lt; height.size(); i++) { lMax = max(lMax, height[left]); rMax = max(rMax, height[right]); ans += min(lMax, rMax) - height[i]; lMax \u0026lt; rMax ? left++ : right--; } return ans; } }; Sliding Window 3 æˆ‘ä»¬æ»‘åŠ¨çª—å£ç»´æŠ¤çš„æ˜¯ä¸€æ®µæ²¡æœ‰é‡å¤å­—ç¬¦çš„å­ä¸²ï¼Œéœ€è¦ç”¨ä¸€ä¸ªå“ˆå¸Œè¡¨æ¥è®°å½•å­ä¸²ä¸­å­—ç¬¦å¯¹åº”çš„ä¸‹æ ‡ã€‚\né€šè¿‡ä»å·¦å‘å³éå†æ¥å°è¯•æ‰©å¤§çª—å£\nè‹¥å‘ç°å­—ç¬¦å·²å­˜åœ¨ï¼Œåˆ™ left åˆ° map[s[right]] çš„æ‰€æœ‰å­—ç¬¦éƒ½éœ€è¦è¢«åˆ é™¤ã€‚çª—å£å·¦ç«¯ç‚¹å˜ä¸º map[s[right]] + 1ï¼Œæ›´æ–°å½“å‰çš„æ— é‡å¤å­ä¸²é•¿åº¦ï¼Œä»¥åŠè¿™ä¸ªé‡å¤å­—ç¬¦å¯¹åº”çš„ä¸‹æ ‡ã€‚ å¦åˆ™å½“å‰æ— é‡å¤å­ä¸²é•¿åº¦ + 1ï¼Œæ›´æ–°ç­”æ¡ˆï¼Œå°†å­—ç¬¦åŠå¯¹åº”ä¸‹æ ‡è®°å½•åœ¨å“ˆå¸Œè¡¨ä¸­ã€‚ class Solution { public: int lengthOfLongestSubstring(string s) { unordered_map\u0026lt;char, int\u0026gt; map; int ans = 0; int left = 0; int len = 0; for (int right = 0; right \u0026lt; s.size(); right++) { if (map.find(s[right]) != map.end()) { while (left \u0026lt;= map[s[right]]) { map.erase(s[left]); left++; } len = right - left + 1; } else { len++; ans = max(ans, len); } map[s[right]] = right; } return ans; } }; 438 ç»´æŒä¸€ä¸ªå’Œ p å­—ç¬¦ä¸²é•¿åº¦ç›¸ç­‰çš„çª—å£ï¼Œåœ¨ s å­—ç¬¦ä¸²ä¸Šæ»‘åŠ¨ã€‚æˆ‘ä»¬åªéœ€è¦åˆ¤æ–­çª—å£å†…çš„å­—ç¬¦ä¸²æ˜¯ä¸æ˜¯ p çš„ä¸€ä¸ªå¼‚ä½è¯ã€‚ä¸éœ€è¦æ¯æ¬¡éƒ½å¯¹çª—å£å†…çš„å­ä¸²è¿›è¡Œæ’åºï¼Œè€Œæ˜¯é€šè¿‡å­—ç¬¦é¢‘ç‡æ¥åˆ¤æ–­ã€‚ç”±äºé¢˜ç›®è¯´äº†å­—ç¬¦ä¸²åªåŒ…å«å°å†™å­—æ¯ï¼Œå› æ­¤å¯ä»¥ç”¨é•¿åº¦ä¸º 26 çš„æ•°ç»„æ¥å­˜å‚¨é¢‘ç‡ã€‚\né¦–å…ˆæ„é€ ç¬¬ä¸€ä¸ªçª—å£ï¼Œåˆ¤æ–­æ˜¯å¦ç›¸åŒåå‘åæ»‘åŠ¨ï¼Œåœ¨æ¯ä¸€æ­¥å¾ªç¯ä¸­æ›´æ–°çª—å£å†…å­—ç¬¦çš„é¢‘ç‡ï¼Œç„¶åå†æ¬¡è¿›è¡Œæ¯”è¾ƒåˆ¤æ–­ã€‚\nclass Solution { public: vector\u0026lt;int\u0026gt; findAnagrams(string s, string p) { vector\u0026lt;int\u0026gt; ans; int sLen = s.length(), pLen = p.length(); if (sLen \u0026lt; pLen) { return ans; } vector\u0026lt;int\u0026gt; pFreq(26, 0), wFreq(26, 0); // init first window for (int i = 0; i \u0026lt; pLen; i++) { pFreq[p[i] - \u0026#39;a\u0026#39;]++; wFreq[s[i] - \u0026#39;a\u0026#39;]++; } if (pFreq == wFreq) { ans.push_back(0); } for (int right = pLen; right \u0026lt; sLen; right++) { int left = right - pLen + 1; // insert and remove wFreq[s[right] - \u0026#39;a\u0026#39;]++; wFreq[s[left - 1] - \u0026#39;a\u0026#39;]--; if (pFreq == wFreq) { ans.push_back(left); } } return ans; } }; Substr 560 å®šä¹‰ pre[i] ä¸ºä» nums[0] åˆ° nums[i] çš„å‰ç¼€å’Œã€‚é‚£ä¹ˆï¼Œä»ç´¢å¼• j åˆ° i (j \u0026lt;= i) çš„å­æ•°ç»„çš„å’Œå°±å¯ä»¥è¡¨ç¤ºä¸º pre[i] - pre[j-1]. é¢˜ç›®è¦æ±‚æˆ‘ä»¬æ‰¾åˆ°å’Œä¸º k çš„å­æ•°ç»„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°æ»¡è¶³ pre[i] - pre[j-1] == k çš„ (i, j) ç»„åˆçš„æ•°é‡ã€‚\nå°†ä¸Šé¢çš„ç­‰å¼å˜æ¢ä¸€ä¸‹ï¼Œå°±å¾—åˆ° pre[j-1] == pre[i] - k. å¯¹äºå½“å‰çš„ç´¢å¼• iï¼Œæˆ‘ä»¬ä¸å†éœ€è¦å‘å‰éå† j æ¥æ£€æŸ¥æ¯ä¸€ä¸ªå­æ•°ç»„çš„å’Œã€‚æˆ‘ä»¬åªéœ€è¦çŸ¥é“ï¼Œåœ¨ 0 åˆ° i-1 çš„èŒƒå›´å†…ï¼Œæœ‰å¤šå°‘ä¸ª j-1 ä½¿å¾— pre[j-1] çš„å€¼æ°å¥½ç­‰äº pre[i] - k.\næˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªå“ˆå¸Œè¡¨æ¥å­˜å‚¨å‡ºç°è¿‡çš„å‰ç¼€å’ŒåŠå‡ºç°çš„æ¬¡æ•°ã€‚åˆå§‹åŒ–çš„æ—¶å€™ä¸º {0, 1} è¡¨ç¤ºå‰ç¼€å’Œä¸º 0 çš„æƒ…å†µå‡ºç°è¿‡ 1 æ¬¡ã€‚åˆå§‹åŒ–å‰ç¼€å’Œ preSum = 0. éå†æ•°ç»„çš„æ—¶å€™ä¸€è¾¹ç´¯åŠ å‰ç¼€å’Œä¸€è¾¹æŸ¥æ‰¾ preSum - k å‡ºç°è¿‡çš„æ¬¡æ•°ã€‚æ³¨æ„è¦å…ˆæŸ¥æ‰¾åæ·»åŠ  (2 * preSum = k æƒ…å†µä¸‹å°±å¤šæ‰¾äº†).\nclass Solution { public: int subarraySum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { unordered_map\u0026lt;int, int\u0026gt; map; map[0] = 1; int ans = 0, preSum = 0; for (int i = 0; i \u0026lt; nums.size(); i++) { preSum += nums[i]; if (map.count(preSum - k)) { ans += map[preSum - k]; } map[preSum]++; } return ans; }Â· }; 239 ç»´æŠ¤ä¸€ä¸ªä»å¤´åˆ°å°¾å•è°ƒé€’å‡çš„åŒç«¯é˜Ÿåˆ—ã€‚ç§»åŠ¨çª—å£ (éå†æ•°ç»„) çš„è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæ•°ç»„å…ƒç´  \u0026gt;= é˜Ÿå°¾å…ƒç´ å°±ä¸€ç›´å°†é˜Ÿå°¾å…ƒç´ å¼¹å‡ºï¼Œç›´åˆ°æ¡ä»¶ä¸æ»¡è¶³æˆ–è€…é˜Ÿåˆ—ä¸ºç©ºï¼Œç„¶åå°†å…ƒç´ æ’å…¥é˜Ÿå°¾ã€‚\nåŒæ—¶ä¸ºäº†ä¸è¶…å‡ºçª—å£å¤§å°ï¼Œé˜Ÿåˆ—ä¸­éœ€è¦è®°å½•çš„æ˜¯å…ƒç´ çš„ä¸‹æ ‡ï¼Œå¹¶åœ¨æ¯æ¬¡å¾ªç¯çš„è¿‡ç¨‹ä¸­åˆ¤æ–­å½“å‰å…ƒç´ ä¸‹æ ‡å‡å»é˜Ÿå¤´å…ƒç´ ä¸‹æ ‡æ˜¯å¦è¶…å‡ºçª—å£å¤§å°ã€‚å½“éå†åˆ°çš„ä¸‹æ ‡ i \u0026gt;= k - 1 æ—¶è¯´æ˜çª—å£å½¢æˆï¼Œå°†é˜Ÿå¤´å…ƒç´ å¯¹åº”æ•°ç»„ä¸­çš„å€¼åŠ å…¥ç­”æ¡ˆã€‚\nclass Solution { public: vector\u0026lt;int\u0026gt; maxSlidingWindow(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { vector\u0026lt;int\u0026gt; ans; deque\u0026lt;int\u0026gt; dq; for (int i = 0; i \u0026lt; nums.size(); i++) { while (!dq.empty() \u0026amp;\u0026amp; nums[i] \u0026gt;= nums[dq.back()]) { dq.pop_back(); } dq.push_back(i); if (i - dq.front() + 1 \u0026gt; k) { dq.pop_front(); } if (i \u0026gt;= k - 1) { ans.push_back(nums[dq.front()]); } } return ans; } }; 76 è¿˜æ˜¯æ»‘åŠ¨çª—å£çš„æ€æƒ³ï¼Œä¸æ–­æšä¸¾å­ä¸²çš„å³ç«¯ç‚¹ï¼Œå¦‚æœå½“å‰çª—å£åŒ…å« tï¼Œæˆ‘ä»¬å°±ä¸æ–­ç§»åŠ¨å·¦ç«¯ç‚¹æ¥ç¼©å°çª—å£ï¼Œä¸æ–­æ›´æ–°é•¿åº¦æœ€å°çš„å­ä¸²ç›´è‡³å½“å‰çª—å£ä¸å†åŒ…å« t.\nå¯¹äºå¦‚ä½•åˆ¤æ–­çª—å£æ˜¯å¦åŒ…å« tï¼Œç”±äº s å’Œ t éƒ½åªç”±å¤§å°å†™å­—æ¯ç»„æˆï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªæ•°ç»„ cnt æ¥è®°å½•çª—å£ä¸­å­—æ¯å°äº t ä¸­å‡ºç°çš„æ¬¡æ•°ï¼Œå¹¶ç”¨ä¸€ä¸ªå˜é‡ less æ¥è®°å½•å½“å‰çª—å£ä¸­æœ‰å¤šå°‘å­—æ¯çš„æ¬¡æ•°ä½äº t ä¸­å¯¹åº”å­—æ¯çš„æ¬¡æ•°ã€‚\néå†è¿‡ç¨‹ä¸­å°† cnt å¯¹åº”å­—æ¯é¢‘ç‡ -1 (å‡ºç°è´Ÿæ•°ä¹Ÿä¸å½±å“åˆ¤æ–­)ï¼Œcnt[s[right]] == 0 æ—¶è¯´æ˜ t ä¸­å¯¹åº”å­—æ¯å·²ç»è¢«å®Œå…¨è¦†ç›–ï¼Œless--. å½“ less == 0 è¯´æ˜çª—å£åŒ…å« t. åœ¨ç¼©å°çª—å£çš„è¿‡ç¨‹ä¸­è¿˜åŸ cnt æ•°ç»„ï¼Œå¦‚æœ cnt[s[left]] == 0ï¼Œé‚£ä¹ˆè¿˜åŸåçª—å£è¯¥å­—æ¯å‡ºç°çš„æ¬¡æ•°åˆä¼šå°äº t çš„ï¼Œless++.\nclass Solution { public: string minWindow(string s, string t) { if (s.length() \u0026lt; t.length()) { return \u0026#34;\u0026#34;; } int cnt[128]{}, less = 0; for (char c : t) { if (cnt[c] == 0) { less++; } cnt[c]++; } int left = 0; int ans_left = -1, ans_right = s.length(); for (int right = 0; right \u0026lt; s.length(); right++) { char c = s[right]; cnt[c]--; if (cnt[c] == 0) { less--; } while (less == 0) { if (right - left \u0026lt; ans_right - ans_left) { ans_right = right; ans_left = left; } if (cnt[s[left]] == 0) { less++; } cnt[s[left]]++; left++; } } return ans_left \u0026lt; 0 ? \u0026#34;\u0026#34; : s.substr(ans_left, ans_right - ans_left + 1); } }; Array 53 å®šä¹‰ f[i] ä¸ºä»¥ nums[i] ä¸ºç»“å°¾çš„æœ€å¤§å­æ•°ç»„å’Œã€‚f[i] å¯ä»¥é€‰æ‹©å’Œä¹‹å‰çš„æ‹¼åœ¨ä¸€èµ· f[i-1] + nums[i] æˆ–è€…è‡ªæˆä¸€ä¸ªå­æ•°ç»„ nums[i]. å¦‚æœä¹‹å‰çš„æœ€å¤§å­æ•°ç»„å’Œ \u0026lt; 0 åˆ™æ‹¼åœ¨ä¸€èµ·åªä¼šæ›´å°ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ‰\n$$ f[i]=\\begin{cases}nums[i],\u0026i=0\\\\\\max(f[i-1],0)+nums[i],\u0026i\\geq1\\end{cases} $$ç­”æ¡ˆä¸º f æ•°ç»„ä¸­æœ€å¤§çš„é‚£ä¸€ä¸ªã€‚\nclass Solution { public: int maxSubArray(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;int\u0026gt; f(nums.size()); f[0] = nums[0]; for (int i = 1; i \u0026lt; nums.size(); i++) { f[i] = max(f[i - 1], 0) + nums[i]; } return ranges::max(f); } }; è§‚å¯Ÿåˆ°æˆ‘ä»¬æ›´æ–°çš„ç­‰å¼åªç”¨åˆ°äº†ä¸¤ä¸ªçŠ¶æ€ï¼Œå› æ­¤å¯ä»¥é™ä½ç©ºé—´å¤æ‚åº¦\nclass Solution { public: int maxSubArray(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int ans = nums[0]; int f = nums[0]; for (int i = 1; i \u0026lt; nums.size(); i++) { f = max(f, 0) + nums[i]; ans = max(ans, f); } return ans; } }; 56 ä¸¤ä¸ªåŒºé—´ [a, b], [c, d] é‡åˆçš„å……è¦æ¡ä»¶ä¸º a \u0026lt;= d \u0026amp;\u0026amp; c \u0026lt;= b. å…ˆæŒ‰ç…§åŒºé—´å¼€å§‹æ—¶é—´æ’åºå°±ä¿è¯äº† a \u0026lt;= c \u0026lt;= d. éå†æ•°ç»„çš„æ—¶å€™è‹¥ c \u0026lt;= b å°±è¯´æ˜ä¸¤ä¸ªåŒºé—´å¯ä»¥é‡åˆï¼Œç„¶åæ›´æ–°ç»“æŸæ—¶é—´ä¸ºä¸¤ä¸ªåŒºé—´çš„è¾ƒå¤§è€…ã€‚\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; merge(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; intervals) { ranges::sort(intervals); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; int begin = intervals[0][0], end = intervals[0][1]; for (auto interval : intervals) { if (interval[0] \u0026lt;= end) { end = max(end, interval[1]); } else{ ans.push_back({begin, end}); begin = interval[0]; end = interval[1]; } } ans.push_back({begin, end}); return ans; } }; 189 è®¾æ•°ç»„å¤§å°ä¸º n.\nåè½¬å‰ n - k ä¸ªå…ƒç´ ã€‚ åè½¬å k ä¸ªå…ƒç´ ã€‚ åè½¬æ•´ä¸ªæ•°ç»„ã€‚ class Solution { public: void rotate(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { int n = nums.size(); k %= n; // 1. åè½¬å‰ n - k ä¸ªå…ƒç´  std::reverse(nums.begin(), nums.begin() + n - k); // 2. åè½¬å k ä¸ªå…ƒç´  std::reverse(nums.begin() + n - k, nums.end()); // 3. åè½¬æ•´ä¸ªæ•°ç»„ std::reverse(nums.begin(), nums.end()); } }; 238 å¯¹äºæ•°ç»„ä¸­çš„ä»»æ„ä¸€ä¸ªä½ç½® iï¼Œanswer[i] çš„å€¼æ˜¯å®ƒå·¦è¾¹æ‰€æœ‰å…ƒç´ çš„ä¹˜ç§¯ ä¹˜ä»¥ å³è¾¹æ‰€æœ‰å…ƒç´ çš„ä¹˜ç§¯ã€‚æˆ‘ä»¬å¯ä»¥åˆ†ä¸¤æ­¥æ¥è®¡ç®—ï¼š\nè®¡ç®—å‰ç¼€ä¹˜ç§¯ (Prefix Products): åˆ›å»ºä¸€ä¸ªæ•°ç»„ï¼ˆæˆ–è€…ç›´æ¥åˆ©ç”¨ç»“æœæ•°ç»„ answerï¼‰ï¼Œanswer[i] å­˜å‚¨ nums[0] åˆ° nums[i-1] çš„æ‰€æœ‰å…ƒç´ çš„ä¹˜ç§¯ã€‚\nè®¡ç®—åç¼€ä¹˜ç§¯ (Suffix Products) å¹¶å¾—å‡ºæœ€ç»ˆç»“æœ: ä»åå‘å‰éå†æ•°ç»„ã€‚å¼•å…¥ä¸€ä¸ªå˜é‡ suffix_product æ¥è®°å½•å³ä¾§æ‰€æœ‰å…ƒç´ çš„ç´¯ç§¯ä¹˜ç§¯ã€‚åœ¨éå†åˆ°ä½ç½® i æ—¶ï¼Œå…ˆå°† answer[i]ï¼ˆæ­¤æ—¶å­˜å‚¨çš„æ˜¯å‰ç¼€ä¹˜ç§¯ï¼‰ä¹˜ä»¥ suffix_productï¼Œç„¶åæ›´æ–° suffix_product ä¸º suffix_product * nums[i]ï¼Œä¸ºä¸‹ä¸€ä¸ªä½ç½®çš„è®¡ç®—åšå‡†å¤‡ã€‚\nclass Solution { public: vector\u0026lt;int\u0026gt; productExceptSelf(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); vector\u0026lt;int\u0026gt; suf(n, 1); for (int i = n - 2; i \u0026gt;= 0; i--) { suf[i] = suf[i + 1] * nums[i + 1]; } int pre = nums[0]; for (int i = 1; i \u0026lt; n; i++) { suf[i] *= pre; pre *= nums[i]; } return suf; } }; 41 $O(1)$ çš„ç©ºé—´å¤æ‚åº¦é™åˆ¶æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨å“ˆå¸Œè¡¨ç­‰é¢å¤–çš„æ•°æ®ç»“æ„æ¥è®°å½•æ•°å­—çš„å‡ºç°æƒ…å†µã€‚å¿…é¡»åœ¨è¾“å…¥æ•°ç»„ nums æœ¬èº«ä¸Šè¿›è¡Œä¿®æ”¹å’Œæ ‡è®°ï¼Œä»¥è¾¾åˆ°è®°å½•ä¿¡æ¯çš„ç›®çš„ã€‚\næˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ç¼ºå¤±çš„ç¬¬ä¸€ä¸ªæ­£æ•´æ•°ã€‚å‡è®¾æ•°ç»„çš„é•¿åº¦ä¸º nï¼Œé‚£ä¹ˆè¿™ä¸ªç¼ºå¤±çš„æ•°ä¸€å®šåœ¨ [1, n+1] è¿™ä¸ªèŒƒå›´å†…ã€‚\nå¦‚æœ 1 åˆ° n éƒ½åœ¨æ•°ç»„ nums ä¸­ï¼Œé‚£ä¹ˆç¼ºå¤±çš„ç¬¬ä¸€ä¸ªæ­£æ•´æ•°å°±æ˜¯ n+1. å¦‚æœ 1 åˆ° n ä¸­æœ‰ä»»ä½•ä¸€ä¸ªæ•°ä¸åœ¨ nums ä¸­ï¼Œé‚£ä¹ˆç¼ºå¤±çš„ç¬¬ä¸€ä¸ªæ­£æ•´æ•°å°±åœ¨ [1, n] è¿™ä¸ªåŒºé—´å†…ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬çš„é—®é¢˜è½¬åŒ–ä¸ºäº†ï¼šæ£€æŸ¥ 1 åˆ° n è¿™äº›æ•°å­—æ˜¯å¦åœ¨ nums æ•°ç»„ä¸­ã€‚\næˆ‘ä»¬å¯ä»¥åˆ©ç”¨æ•°ç»„çš„ç´¢å¼•æ¥å……å½“å“ˆå¸Œè¡¨çš„é”®ï¼Œæ•°ç»„ä¸­çš„å…ƒç´ æ¥å……å½“å€¼ï¼Œä»è€Œå»ºç«‹ä¸€ç§æ˜ å°„å…³ç³»ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›æ•°å­— k èƒ½å¤Ÿè¢«æ”¾åˆ°ç´¢å¼•ä¸º k-1 çš„ä½ç½®ä¸Šã€‚ä¾‹å¦‚ï¼Œæ•°å­— 1 åº”è¯¥è¢«æ”¾åˆ°ç´¢å¼• 0ï¼Œæ•°å­— 2 åº”è¯¥è¢«æ”¾åˆ°ç´¢å¼• 1ï¼Œä»¥æ­¤ç±»æ¨ã€‚\nç¬¬ä¸€æ¬¡éå†æ•°ç»„æ—¶ï¼Œåªè¦ nums[i] æ˜¯ä¸€ä¸ªåœ¨ [1, n] èŒƒå›´å†…çš„æ­£æ•°ï¼Œå¹¶ä¸”å®ƒæ²¡æœ‰è¢«æ”¾åˆ°æ­£ç¡®çš„ä½ç½®ä¸Š (å³ nums[i] != nums[nums[i] - 1])ï¼Œæˆ‘ä»¬å°±ç»§ç»­äº¤æ¢ã€‚\nnums[i] != nums[nums[i] - 1] æ˜¯ä¸ºäº†é˜²æ­¢å½“ä¸¤ä¸ªç›¸åŒæ•°å­—éœ€è¦äº¤æ¢æ—¶é™·å…¥æ­»å¾ªç¯ã€‚ä¾‹å¦‚ nums = [1, 1], i = 0, nums[0] = 1, éå†åˆ° nums[1] æ—¶ nums[nums[1]-1] = nums[0] = 1. è¯´æ˜è¦è¿›è¡Œäº¤æ¢çš„ä½ç½®ä¸Šçš„å€¼å·²ç»æ˜¯æ­£ç¡®çš„ã€‚\nç»è¿‡ä¸Šä¸€æ­¥çš„æ•´ç†ï¼Œæ•°ç»„ nums å·²ç»å°½å¯èƒ½åœ°æŠŠæ•°å­— k æ”¾åœ¨äº†ç´¢å¼• k-1 çš„ä½ç½® (åœ¨ç­”æ¡ˆèŒƒå›´å†…ä¸”æ²¡æœ‰é‡å¤çš„)ã€‚ç°åœ¨æˆ‘ä»¬å†éå†ä¸€æ¬¡æ•°ç»„ï¼šæ£€æŸ¥ nums[i] æ˜¯å¦ç­‰äº i+1ã€‚ç¬¬ä¸€ä¸ªä¸æ»¡è¶³æ¡ä»¶çš„ç´¢å¼• iï¼Œå°±æ„å‘³ç€ i+1 æ˜¯ç¼ºå¤±çš„ç¬¬ä¸€ä¸ªæ­£æ•´æ•°ã€‚éå†å®Œæˆéƒ½æ»¡è¶³è¯´æ˜ç¼ºå¤±çš„ç¬¬ä¸€ä¸ªæ­£æ•´æ•°ä¸º n+1.\nclass Solution { public: int firstMissingPositive(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); for (int i = 0; i \u0026lt; n; i++) { while (nums[i] \u0026gt;= 1 \u0026amp;\u0026amp; nums[i] \u0026lt;= n \u0026amp;\u0026amp; nums[i] != nums[nums[i] - 1]) { swap(nums[i], nums[nums[i] - 1]); } } for (int i = 0; i \u0026lt; n; i++) { if (nums[i] != i + 1) { return i + 1; } } return n + 1; } }; Matrix 73 å¯ä»¥åˆ©ç”¨çŸ©é˜µçš„ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—æ¥å­˜å‚¨å“ªäº›è¡Œå’Œåˆ—éœ€è¦è¢«ç½®é›¶ã€‚\né¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸¤ä¸ªå¸ƒå°”å˜é‡ isFirstRowZero å’Œ isFirstColZero æ¥å•ç‹¬è®°å½•ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—æ˜¯å¦æœ¬èº«å°±åŒ…å« 0. å› ä¸ºç¬¬ä¸€è¡Œç¬¬ä¸€åˆ— matrix[0][0] çš„çŠ¶æ€æ˜¯å…±äº«çš„ï¼Œæ‰€ä»¥éœ€è¦åˆ†å¼€è®°å½•ã€‚\nç”¨ç¬¬ä¸€è¡Œ/åˆ—åšæ ‡è®°ï¼šéå†é™¤ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—ä¹‹å¤–çš„çŸ©é˜µéƒ¨åˆ†ï¼Œå¦‚æœ matrix[i][j] == 0ï¼Œåˆ™å°†å¯¹åº”çš„ç¬¬ä¸€è¡Œ matrix[i][0] å’Œç¬¬ä¸€åˆ— matrix[0][j] çš„å…ƒç´ ç½®é›¶ã€‚\nå†æ¬¡éå†é™¤ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—ä¹‹å¤–çš„çŸ©é˜µéƒ¨åˆ†ã€‚å¦‚æœ matrix[i][0] == 0 æˆ– matrix[0][j] == 0ï¼Œè¯´æ˜ç¬¬ i è¡Œæˆ–ç¬¬ j åˆ—éœ€è¦è¢«æ¸…é›¶ï¼Œå› æ­¤å°† matrix[i][j] ç½®ä¸º 0.\næœ€åï¼Œæ ¹æ®æ­¥éª¤ 1 ä¸­è®°å½•çš„ isFirstRowZero å’Œ isFirstColZero çš„å€¼æ¥å†³å®šæ˜¯å¦å°†ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—æ•´ä½“ç½®é›¶ã€‚\nclass Solution { public: void setZeroes(std::vector\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix) { int m = matrix.size(); if (m == 0) return; int n = matrix[0].size(); bool isFirstColZero = false; bool isFirstRowZero = false; // 1. æ£€æŸ¥ç¬¬ä¸€åˆ—æ˜¯å¦éœ€è¦ç½®é›¶ for (int i = 0; i \u0026lt; m; ++i) { if (matrix[i][0] == 0) { isFirstColZero = true; break; } } // 2. æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦éœ€è¦ç½®é›¶ for (int j = 0; j \u0026lt; n; ++j) { if (matrix[0][j] == 0) { isFirstRowZero = true; break; } } // 3. ç”¨ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—è®°å½•å…¶ä»–è¡Œåˆ—çš„é›¶çŠ¶æ€ // ä» (1, 1) å¼€å§‹éå† for (int i = 1; i \u0026lt; m; ++i) { for (int j = 1; j \u0026lt; n; ++j) { if (matrix[i][j] == 0) { matrix[i][0] = 0; matrix[0][j] = 0; } } } // 4. æ ¹æ®ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—çš„æ ‡è®°ï¼Œæ›´æ–°çŸ©é˜µï¼ˆä¸åŒ…æ‹¬ç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—ï¼‰ for (int i = 1; i \u0026lt; m; ++i) { for (int j = 1; j \u0026lt; n; ++j) { if (matrix[i][0] == 0 || matrix[0][j] == 0) { matrix[i][j] = 0; } } } // 5. æœ€åå¤„ç†ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ— if (isFirstRowZero) { for (int j = 0; j \u0026lt; n; ++j) { matrix[0][j] = 0; } } if (isFirstColZero) { for (int i = 0; i \u0026lt; m; ++i) { matrix[i][0] = 0; } } } }; 54 ç»´æŠ¤å››ä¸ªå˜é‡ï¼Œåˆ†åˆ«ä»£è¡¨å½“å‰å¾…éå†çŸ©é˜µçš„ä¸Šã€ä¸‹ã€å·¦ã€å³å››ä¸ªè¾¹ç•Œã€‚åœ¨æ¯ä¸€è½®å¾ªç¯ä¸­ï¼Œæˆ‘ä»¬æ²¿ç€è¿™å››ä¸ªè¾¹ç•Œèµ°ä¸€åœˆ (ğŸ‘‰ğŸ‘‡ğŸ‘ˆğŸ‘†)ï¼Œç„¶åå‘å†…æ”¶ç¼©è¾¹ç•Œï¼Œç›´åˆ°è¾¹ç•Œç›¸é‡æˆ–äº¤é”™ã€‚\nå½“èºæ—‹æ”¶ç¼©åˆ°åªå‰©ä¸€è¡Œæˆ–ä¸€åˆ—æ—¶ï¼Œä¸Šé¢ç¬¬ 1ã€2 æ­¥æ‰§è¡Œå®Œåï¼Œè¾¹ç•Œæ¡ä»¶å¯èƒ½å°±ä¸æ»¡è¶³äº†ï¼ˆä¾‹å¦‚ï¼Œtop \u0026gt; bottomï¼‰ã€‚å› æ­¤ï¼Œåœ¨æ‰§è¡Œç¬¬ 3ã€4 æ­¥ä¹‹å‰ï¼Œéœ€è¦å†æ¬¡æ£€æŸ¥è¾¹ç•Œæ¡ä»¶ï¼Œé˜²æ­¢é‡å¤æ·»åŠ å…ƒç´ ã€‚\nclass Solution { public: std::vector\u0026lt;int\u0026gt; spiralOrder(std::vector\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix) { int m = matrix.size(); int n = matrix[0].size(); std::vector\u0026lt;int\u0026gt; ans; ans.reserve(m * n); int top = 0, bottom = m - 1, left = 0, right = n - 1; while (left \u0026lt;= right \u0026amp;\u0026amp; top \u0026lt;= bottom) { // 1. ä»å·¦åˆ°å³éå†ä¸Šè¾¹ç•Œ for (int j = left; j \u0026lt;= right; ++j) { ans.push_back(matrix[top][j]); } top++; // ä¸Šè¾¹ç•Œä¸‹ç§» // 2. ä»ä¸Šåˆ°ä¸‹éå†å³è¾¹ç•Œ for (int i = top; i \u0026lt;= bottom; ++i) { ans.push_back(matrix[i][right]); } right--; // å³è¾¹ç•Œå·¦ç§» // æ£€æŸ¥è¾¹ç•Œï¼Œé˜²æ­¢åœ¨åªå‰©ä¸€è¡Œæˆ–ä¸€åˆ—æ—¶é‡å¤éå† if (top \u0026lt;= bottom) { // 3. ä»å³åˆ°å·¦éå†ä¸‹è¾¹ç•Œ for (int j = right; j \u0026gt;= left; --j) { ans.push_back(matrix[bottom][j]); } bottom--; // ä¸‹è¾¹ç•Œä¸Šç§» } if (left \u0026lt;= right) { // 4. ä»ä¸‹åˆ°ä¸Šéå†å·¦è¾¹ç•Œ for (int i = bottom; i \u0026gt;= top; --i) { ans.push_back(matrix[i][left]); } left++; // å·¦è¾¹ç•Œå³ç§» } } return ans; } }; 48 ä½äº i è¡Œ j åˆ—çš„å…ƒç´ ï¼Œå»åˆ° j è¡Œ nâˆ’1âˆ’i åˆ—ï¼Œå³ (i,j) -\u0026gt; (j,nâˆ’1âˆ’i). å› æ­¤å¯ä»¥é€šè¿‡å…ˆè½¬ç½®å†çºµå‘å¯¹ç§°ç¿»è½¬å®ç°ã€‚\nclass Solution { public: void rotate(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix) { int m = matrix.size(); int n = matrix[0].size(); for (int i = 0; i \u0026lt; m; i++) { for (int j = i + 1; j \u0026lt; n; j++) { swap(matrix[i][j], matrix[j][i]); } } for (int i = 0; i \u0026lt; m; i++) { for (int j = 0; j \u0026lt; n / 2; j++) { swap(matrix[i][j], matrix[i][n - 1 - j]); } } } }; 240 å³ä¸Šè§’çš„å…ƒç´ ï¼Œå®ƒæ˜¯å½“å‰è¡Œçš„æœ€å¤§å€¼ï¼ŒåŒæ—¶ä¹Ÿæ˜¯å½“å‰åˆ—çš„æœ€å°å€¼ã€‚æ¯ä¸€æ­¥éƒ½å¯ä»¥æ’é™¤æ‰ä¸€è¡Œæˆ–è€…ä¸€åˆ—ï¼Œä»è€Œä¸æ–­ç¼©å°æœç´¢èŒƒå›´ã€‚ä»å³ä¸Šè§’å¼€å§‹æœç´¢:\nmatrix[row][col] \u0026gt; target: å½“å‰å…ƒç´ æ˜¯å…¶æ‰€åœ¨åˆ—çš„æœ€å°å€¼ï¼Œå¦‚æœå®ƒéƒ½æ¯” target å¤§ï¼Œé‚£ä¹ˆè¿™ä¸€æ•´åˆ—ä¸‹æ–¹çš„æ‰€æœ‰å…ƒç´ å¿…å®šä¹Ÿæ¯” target å¤§ã€‚å› æ­¤ï¼Œå¯ä»¥å®Œå…¨æ’é™¤å½“å‰åˆ—ã€‚å‘å·¦ç§»åŠ¨ï¼Œcol--.\nmatrix[row][col] \u0026lt; target: å› ä¸ºå½“å‰å…ƒç´ æ˜¯å…¶æ‰€åœ¨è¡Œçš„æœ€å¤§å€¼ï¼Œå¦‚æœå®ƒéƒ½æ¯” target å°ï¼Œé‚£ä¹ˆè¿™ä¸€æ•´è¡Œå·¦è¾¹çš„æ‰€æœ‰å…ƒç´ å¿…å®šä¹Ÿæ¯” target å°ã€‚å› æ­¤ï¼Œå¯ä»¥å®Œå…¨æ’é™¤å½“å‰è¡Œã€‚å‘ä¸‹ç§»åŠ¨ï¼Œrow++.\nå½“è¶…å‡ºä¸‹è¾¹ç•Œæˆ–è¶…å‡ºå·¦è¾¹ç•Œæ—¶è¯´æ˜æ‰¾ä¸åˆ°ç›®æ ‡å€¼ã€‚\nclass Solution { public: bool searchMatrix(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix, int target) { int m = matrix.size(); int n = matrix[0].size(); int row = 0, col = n - 1; while (row \u0026lt; m \u0026amp;\u0026amp; col \u0026gt;= 0) { if (matrix[row][col] \u0026gt; target) { col--; } else if (matrix[row][col] \u0026lt; target) { row++; } else { return true; } } return false; } }; Linked List 160 ä½¿ç”¨ä¸¤ä¸ªæŒ‡é’ˆ pa å’Œ pb åˆ†åˆ«æŒ‡å‘ headA å’Œ headB. åŒæ—¶éå†ä¸¤ä¸ªé“¾è¡¨:\nå¦‚æœ pa æˆ– pb åˆ°è¾¾é“¾è¡¨æœ«å°¾ï¼ˆnullptrï¼‰ï¼Œå°†å…¶åˆ‡æ¢åˆ°å¦ä¸€ä¸ªé“¾è¡¨çš„å¤´éƒ¨ç»§ç»­éå†ã€‚è¿™æ ·ï¼Œä¸¤ä¸ªæŒ‡é’ˆæœ€ç»ˆä¼šâ€œèµ°è¿‡ç›¸åŒçš„è·ç¦»â€ï¼Œè¦ä¹ˆåœ¨ç›¸äº¤èŠ‚ç‚¹ç›¸é‡ï¼Œè¦ä¹ˆéƒ½åˆ°è¾¾ nullptr.\nè®¾é“¾è¡¨ A çš„é•¿åº¦ä¸º a + cï¼Œé“¾è¡¨ B çš„é•¿åº¦ä¸º b + cï¼Œå…¶ä¸­ c æ˜¯ç›¸äº¤éƒ¨åˆ†çš„é•¿åº¦ã€‚æŒ‡é’ˆ pa éå† a + c + b åï¼ŒæŒ‡é’ˆ pb éå† b + c + a åï¼Œå®ƒä»¬ä¼šåœ¨ç›¸äº¤èŠ‚ç‚¹ç›¸é‡ (æ— äº¤ç‚¹åˆ™éƒ½åˆ°è¾¾ nulll ptr).\nclass Solution { public: ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) { ListNode*pa = headA, *pb = headB; while (pa != pb) { pa = pa ? pa-\u0026gt;next : headB; pb = pb ? pb-\u0026gt;next : headA; } return pa; } }; 206 ä» pre = nullptr å¼€å§‹ï¼Œè¿™æ ·å¯ä»¥è‡ªç„¶åœ°å°†åŸå¤´èŠ‚ç‚¹çš„ next è®¾ç½®ä¸º nullptr.\nclass Solution { public: ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr, *cur = head; while (cur) { ListNode* n = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = n; } return pre; } }; 141 æ…¢æŒ‡é’ˆ slow ä¸€æ¬¡ç§»åŠ¨ä¸€æ­¥ï¼Œå¿«æŒ‡é’ˆ fast ä¸€æ¬¡ç§»åŠ¨ä¸¤æ­¥ã€‚å¦‚æœèƒ½ç›¸é‡è¯´æ˜æœ‰ç¯ï¼Œå¦åˆ™å¿«æŒ‡é’ˆä¼šå…ˆèµ°åˆ°é“¾è¡¨æœ«å°¾ nullptr.\nclass Solution { public: bool hasCycle(ListNode *head) { ListNode* slow = head, *fast = head; while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; if (slow == fast) { return true; } } return false; } }; 142 å‡è®¾è¿›ç¯å‰çš„è·¯ç¨‹ä¸º aï¼Œç¯é•¿ä¸º bã€‚è®¾æ…¢æŒ‡é’ˆèµ°äº† x æ­¥æ—¶ï¼Œå¿«æ…¢æŒ‡é’ˆç›¸é‡ï¼Œæ­¤æ—¶å¿«æŒ‡é’ˆèµ°äº† 2x æ­¥ã€‚æ˜¾ç„¶ 2x-x=nbï¼ˆå¿«æŒ‡é’ˆæ¯”æ…¢æŒ‡é’ˆå¤šèµ°äº† n åœˆï¼‰ï¼Œå³ x=nb. ä¹Ÿå°±æ˜¯è¯´æ…¢æŒ‡é’ˆæ€»å…±èµ°è¿‡çš„è·¯ç¨‹æ˜¯ nbï¼Œä½†è¿™ nb å½“ä¸­ï¼Œå®é™…ä¸ŠåŒ…å«äº†è¿›ç¯å‰çš„ä¸€ä¸ªå° aï¼Œå› æ­¤æ…¢æŒ‡é’ˆåœ¨ç¯ä¸­åªèµ°äº† nb-a æ­¥ï¼Œå®ƒè¿˜å¾—å†å¾€å‰èµ° a æ­¥ï¼Œæ‰æ˜¯å®Œæ•´çš„ n åœˆã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬è®©å¤´èŠ‚ç‚¹å’Œæ…¢æŒ‡é’ˆåŒæ—¶å¾€å‰èµ°ï¼Œå½“ä»–ä¿©ç›¸é‡æ—¶ï¼Œå°±èµ°è¿‡äº†æœ€åè¿™ a æ­¥ã€‚\nclass Solution { public: ListNode *detectCycle(ListNode *head) { ListNode* slow = head, *fast = head; while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; if (slow == fast) { while (head != slow) { slow = slow-\u0026gt;next; head = head-\u0026gt;next; } return slow; } } return nullptr; } }; 21 åˆ›å»ºä¸€ä¸ª dummy èŠ‚ç‚¹ï¼Œä½œä¸ºåˆå¹¶åçš„æ–°é“¾è¡¨å¤´èŠ‚ç‚¹çš„å‰ä¸€ä¸ªèŠ‚ç‚¹ã€‚\næ¯”è¾ƒ list 1 å’Œ list2çš„èŠ‚ç‚¹å€¼ï¼Œå¦‚æœ list1 çš„èŠ‚ç‚¹å€¼å°ï¼Œåˆ™æŠŠ list1 åŠ åˆ°æ–°é“¾è¡¨çš„æœ«å°¾ï¼Œç„¶åæŠŠ list1 æ›¿æ¢æˆå®ƒçš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚åä¹‹åŒæ ·ã€‚\nç›´åˆ°ä¸€ä¸ªé“¾è¡¨ä¸ºç©ºå°±æŠŠå¦ä¸€ä¸ªé“¾è¡¨ç›´æ¥åŠ åˆ°æ–°é“¾è¡¨æœ«å°¾ï¼Œè¿”å› dummy.next.\nclass Solution { public: ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) { ListNode dummy(0); ListNode* tail = \u0026amp;dummy; while (list1 \u0026amp;\u0026amp; list2) { if (list1-\u0026gt;val \u0026lt; list2-\u0026gt;val) { tail-\u0026gt;next = list1; list1 = list1-\u0026gt;next; } else { tail-\u0026gt;next = list2; list2 = list2-\u0026gt;next; } tail = tail-\u0026gt;next; } tail-\u0026gt;next = list1 ? list1 : list2; return dummy.next; } }; 2 æ³¨æ„ä¸¤ä¸ªé“¾è¡¨éå†å®Œåå¯èƒ½è¿˜æœ‰è¿›ä½ã€‚\nclass Solution { public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) { ListNode dummy; ListNode* p = \u0026amp;dummy; int carry = 0; while (l1 \u0026amp;\u0026amp; l2) { int num = l1-\u0026gt;val + l2-\u0026gt;val + carry; carry = num \u0026gt;= 10 ? 1 : 0; num %= 10; p-\u0026gt;next = new ListNode(num); p = p-\u0026gt;next; l1 = l1-\u0026gt;next; l2 = l2-\u0026gt;next; } while (l1) { int num = l1-\u0026gt;val + carry; carry = num \u0026gt;= 10 ? 1 : 0; num %= 10; p-\u0026gt;next = new ListNode(num); p = p-\u0026gt;next; l1 = l1-\u0026gt;next; } while (l2) { int num = l2-\u0026gt;val + carry; carry = num \u0026gt;= 10 ? 1 : 0; num %= 10; p-\u0026gt;next = new ListNode(num); p = p-\u0026gt;next; l2 = l2-\u0026gt;next; } if (carry) { p-\u0026gt;next = new ListNode(carry); } return dummy.next; } }; 19 ä¸ºäº†ç®€åŒ–éœ€è¦åˆ é™¤å¤´èŠ‚ç‚¹çš„é€»è¾‘ï¼Œæˆ‘ä»¬éœ€è¦æ·»åŠ ä¸€ä¸ªå“¨å…µèŠ‚ç‚¹ dummy. æ…¢æŒ‡é’ˆ slow åœ¨é“¾è¡¨ dummyï¼Œå…ˆç§»åŠ¨å¿«æŒ‡é’ˆ slow åˆ°æ­£æ•°ç¬¬ n ä¸ªèŠ‚ç‚¹ã€‚ç„¶ååŒæ—¶ç§»åŠ¨å¿«æ…¢æŒ‡é’ˆï¼Œfast åˆ°è¾¾ nullptr æ—¶ï¼Œå·¦ç«¯ç‚¹å°±åœ¨å€’æ•°ç¬¬ n ä¸ªèŠ‚ç‚¹ã€‚\nclass Solution { public: ListNode* removeNthFromEnd(ListNode* head, int n) { ListNode dummy(0, head); ListNode* slow = \u0026amp;dummy, *fast = head; for (int i = 0; i \u0026lt; n; i++) { fast = fast-\u0026gt;next; } while (fast) { slow = slow-\u0026gt;next; fast= fast-\u0026gt;next; } slow-\u0026gt;next = slow-\u0026gt;next-\u0026gt;next; return dummy.next; } }; 24 ç”¨ä¸€ä¸ªæŒ‡é’ˆ pre æŒ‡å‘å·²ç»ç¿»è½¬éƒ¨åˆ†çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼Œcur æŒ‡å‘ä¸‹ä¸€ä¸ªè¦ç¿»è½¬çš„èŠ‚ç‚¹ã€‚å½“è¦ç¿»è½¬çš„ä¸€å¯¹èŠ‚ç‚¹ cur \u0026amp;\u0026amp; cur-\u0026gt;next éƒ½å­˜åœ¨æ—¶:\npre-\u0026gt;next = cur-\u0026gt;next cur-\u0026gt;next = cur-\u0026gt;next-\u0026gt;next cur-\u0026gt;next-\u0026gt;next = cur æ­¤æ—¶ cur æˆä¸ºå·²ç»ç¿»è½¬éƒ¨åˆ†çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼Œè®© pre æŒ‡å‘å®ƒï¼Œcur å†æŒ‡å‘ cur-\u0026gt;next. ç”±äºéœ€è¦å¯¹å¤´èŠ‚ç‚¹è¿›è¡Œç¿»è½¬ï¼Œæ‰€ä»¥æˆ‘ä»¬åˆå§‹åŒ–å“¨å…µèŠ‚ç‚¹æ¥ä½œä¸ºä¸€å¼€å§‹å·²ç»ç¿»è½¬éƒ¨åˆ†çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ã€‚\nclass Solution { public: ListNode* swapPairs(ListNode* head) { if (!head || !head-\u0026gt;next) { return head; } ListNode dummy(0, head); ListNode* pre = \u0026amp;dummy, *cur = head; while (cur \u0026amp;\u0026amp; cur-\u0026gt;next) { ListNode* next = cur-\u0026gt;next; pre-\u0026gt;next = next; cur-\u0026gt;next = next-\u0026gt;next; next-\u0026gt;next = cur; pre = cur; cur = cur-\u0026gt;next; } return dummy.next; } }; 25 é€šè¿‡ä¸€æ¬¡éå†è®¡ç®—å‡ºé“¾è¡¨æ€»é•¿åº¦ï¼Œä»è€Œç¡®å®šæ€»å…±éœ€è¦åè½¬å¤šå°‘ä¸ªåˆ†ç»„ã€‚ pre æŒ‡å‘å·²ç»ç¿»è½¬çš„éƒ¨åˆ†çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼Œ å†…å¾ªç¯è¿›è¡Œæ¯ä¸€ç»„çš„é“¾è¡¨åè½¬ã€‚åè½¬ç»“æŸå cur æŒ‡å‘çš„æ˜¯ä¸‹ä¸€ç»„çš„å¼€å§‹èŠ‚ç‚¹ã€‚é‡æ–°é“¾æ¥åè½¬åçš„å­é“¾è¡¨ã€‚ class Solution { public: ListNode* reverseKGroup(ListNode* head, int k) { int len = 0; ListNode* cur = head; while (cur) { len++; cur = cur-\u0026gt;next; } int ng = len / k; ListNode dummy(0, head); ListNode* pre = \u0026amp;dummy; cur = head; for (int i = 0; i \u0026lt; ng; i++) { ListNode* p = nullptr; for (int j = 0; j \u0026lt; k; j++) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = p; p = cur; cur = next; } pre-\u0026gt;next-\u0026gt;next = cur; ListNode* next_pre = pre-\u0026gt;next; pre-\u0026gt;next = p; pre = next_pre; } return dummy.next; } }; 234 ç”¨å¿«æ…¢æŒ‡é’ˆæ‰¾åˆ°é“¾è¡¨ä¸­é—´ä½ç½® (len / 2) çš„èŠ‚ç‚¹ã€‚ ç¿»è½¬åä¸€åŠé“¾è¡¨ã€‚ åŒæ—¶ä»å¤´å°¾å¼€å§‹éå†åˆ¤æ–­å€¼æ˜¯å¦ç›¸ç­‰ã€‚ class Solution { ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr, *cur = head; while (cur) { ListNode* n = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = n; } return pre; } ListNode* middleList(ListNode* head) { ListNode* slow = head, *fast = head; while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; } return slow; } public: bool isPalindrome(ListNode* head) { ListNode* mid = middleList(head); ListNode* tail = reverseList(mid); while (head \u0026amp;\u0026amp; tail) { if (head-\u0026gt;val != tail-\u0026gt;val) { return false; } head = head-\u0026gt;next; tail = tail-\u0026gt;next; } return true; } }; 138 åˆ›å»ºäº¤ç»‡é“¾è¡¨: éå†åŸé“¾è¡¨ï¼Œå¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªæ–°èŠ‚ç‚¹ï¼ˆå‰¯æœ¬ï¼‰ï¼Œå¹¶å°†å…¶æ’å…¥åˆ°åŸèŠ‚ç‚¹å’ŒåŸèŠ‚ç‚¹çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ä¹‹é—´ã€‚ä¾‹å¦‚ï¼ŒåŸé“¾è¡¨ A -\u0026gt; B -\u0026gt; C å˜æˆ A -\u0026gt; A' -\u0026gt; B -\u0026gt; B' -\u0026gt; C -\u0026gt; C'.\nè®¾ç½® random æŒ‡é’ˆ: å¯¹äºåŸé“¾è¡¨çš„æ¯ä¸ªèŠ‚ç‚¹ Nï¼Œå…¶å‰¯æœ¬èŠ‚ç‚¹ N\u0026rsquo; ç´§éšå…¶åã€‚ å¦‚æœ N-\u0026gt;random æŒ‡å‘æŸä¸ªèŠ‚ç‚¹ Mï¼Œåˆ™ N'-\u0026gt;random åº”æŒ‡å‘ M\u0026rsquo; (M çš„å‰¯æœ¬). ç”±äº M\u0026rsquo; æ˜¯ M-\u0026gt;nextï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è®¾ç½® N-\u0026gt;next-\u0026gt;random = N-\u0026gt;random-\u0026gt;next.\nåˆ†ç¦»æ–°æ—§é“¾è¡¨: éå†äº¤ç»‡é“¾è¡¨ï¼Œå°†æ–°èŠ‚ç‚¹å’Œæ—§èŠ‚ç‚¹åˆ†å¼€ï¼Œæ¢å¤åŸé“¾è¡¨å¹¶æå–æ–°é“¾è¡¨ã€‚ç¡®ä¿æ­£ç¡®è®¾ç½® next æŒ‡é’ˆï¼Œæ–­å¼€æ–°æ—§èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥ã€‚\nclass Solution { public: Node* copyRandomList(Node* head) { if (!head) return nullptr; Node * cur = head; while (cur) { cur-\u0026gt;next = new Node(cur-\u0026gt;val, cur-\u0026gt;next, nullptr); cur = cur-\u0026gt;next-\u0026gt;next; } cur = head; while (cur) { if (cur-\u0026gt;random) { cur-\u0026gt;next-\u0026gt;random = cur-\u0026gt;random-\u0026gt;next; } cur = cur-\u0026gt;next-\u0026gt;next; } Node *newHead = head-\u0026gt;next; cur = head; while (cur-\u0026gt;next-\u0026gt;next) { Node* copy = cur-\u0026gt;next; cur-\u0026gt;next = copy-\u0026gt;next; copy-\u0026gt;next = cur-\u0026gt;next-\u0026gt;next; cur = cur-\u0026gt;next; } cur-\u0026gt;next = nullptr; return newHead; } }; 148 éå†é“¾è¡¨ï¼Œè·å–é“¾è¡¨é•¿åº¦ã€‚ è‡ªåº•å‘ä¸Šå½’å¹¶æ’åº: å°†é“¾è¡¨ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½çœ‹ä½œæ˜¯ä¸€ä¸ªé•¿åº¦ä¸º 1 çš„ã€å·²ç»æ’å¥½åºçš„å­é“¾è¡¨ã€‚åœ¨å†…éƒ¨å¾ªç¯æ¯ä¸€è½®ä¸­æ‰¾åˆ°æ¯ä¸€å¯¹è¦åˆå¹¶çš„å­é“¾è¡¨ head1 å’Œ head2ï¼Œç„¶åå°†å®ƒä»¬åˆå¹¶ï¼Œå¹¶é“¾æ¥åˆ°ä¸Šä¸€æ®µåˆå¹¶å¥½çš„é“¾è¡¨çš„æœ«å°¾ã€‚ ç¬¬ä¸€è½®ï¼šå°†ç›¸é‚»çš„ã€é•¿åº¦ä¸º 1 çš„å­é“¾è¡¨ä¸¤ä¸¤åˆå¹¶ï¼Œå½¢æˆå¤šä¸ªé•¿åº¦ä¸º 2 çš„æœ‰åºå­é“¾è¡¨ã€‚ ç¬¬äºŒè½®ï¼šå°†ç›¸é‚»çš„ã€é•¿åº¦ä¸º 2 çš„å­é“¾è¡¨ä¸¤ä¸¤åˆå¹¶ï¼Œå½¢æˆå¤šä¸ªé•¿åº¦ä¸º 4 çš„æœ‰åºå­é“¾è¡¨ã€‚ ç¬¬ä¸‰è½®ï¼šå°†ç›¸é‚»çš„ã€é•¿åº¦ä¸º 4 çš„å­é“¾è¡¨ä¸¤ä¸¤åˆå¹¶ï¼Œå½¢æˆå¤šä¸ªé•¿åº¦ä¸º 8 çš„æœ‰åºå­é“¾è¡¨ã€‚ æ¯æ¬¡ä» dummy èŠ‚ç‚¹å¼€å§‹é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œå½’å¹¶åå°†å­é“¾è¡¨çš„é•¿åº¦ subLen ç¿»å€ (1, 2, 4, 8, \u0026hellip;)ï¼Œç›´åˆ° subLen \u0026gt;= æ•´ä¸ªé“¾è¡¨çš„é•¿åº¦ã€‚ class Solution { ListNode* merge(ListNode* head1, ListNode* head2) { ListNode dummy(0); ListNode* tail = \u0026amp;dummy; while (head1 \u0026amp;\u0026amp; head2) { if (head1-\u0026gt;val \u0026lt; head2-\u0026gt;val) { tail-\u0026gt;next = head1; head1 = head1-\u0026gt;next; } else { tail-\u0026gt;next = head2; head2 = head2-\u0026gt;next; } tail = tail-\u0026gt;next; } tail-\u0026gt;next = head1 ? head1 : head2; return dummy.next; } public: ListNode* sortList(ListNode* head) { int len = 0; ListNode* p = head; while (p) { len++; p = p-\u0026gt;next; } ListNode dummy(0, head); for (int subLen = 1; subLen \u0026lt; len; subLen*= 2) { ListNode* pre = \u0026amp;dummy; // pre records the tail of last merged 2 segments ListNode* cur = dummy.next; // cur records the start node to merge while (cur) { // find first segment chainList with subLen ListNode* head1 = cur; for (int i = 1; i \u0026lt; subLen \u0026amp;\u0026amp; cur \u0026amp;\u0026amp; cur-\u0026gt;next; i++) { cur = cur-\u0026gt;next; } // find second segment chianList and cut the connection with first segement ListNode* head2 = nullptr; if (cur) { head2 = cur-\u0026gt;next; cur-\u0026gt;next = nullptr; } // find the tail of second segment cur = head2; for (int i = 1; i \u0026lt; subLen \u0026amp;\u0026amp; cur \u0026amp;\u0026amp; cur-\u0026gt;next; i++) { cur = cur-\u0026gt;next; } // record the next round start node to merge and cut the connection with second segement ListNode* nextSub = nullptr; if (cur) { nextSub = cur-\u0026gt;next; cur-\u0026gt;next = nullptr; } ListNode* merged = merge(head1, head2); pre-\u0026gt;next = merged; // move pre to the end of merged segment while (pre-\u0026gt;next) { pre = pre-\u0026gt;next; } cur = nextSub; } } return dummy.next; } }; 23 ç›´æ¥è‡ªåº•å‘ä¸Šåˆå¹¶é“¾è¡¨ï¼š\nä¸¤ä¸¤åˆå¹¶ï¼šæŠŠ lists[0] å’Œ lists[1] åˆå¹¶ï¼Œåˆå¹¶åçš„é“¾è¡¨ä¿å­˜åœ¨ lists[0] ä¸­ï¼›æŠŠ lists[2] å’Œ lists[3] åˆå¹¶ï¼Œåˆå¹¶åçš„é“¾è¡¨ä¿å­˜åœ¨ lists[2] ä¸­ï¼›ä¾æ­¤ç±»æ¨ã€‚ å››å››åˆå¹¶ï¼šæŠŠ lists[0] å’Œ lists[2] åˆå¹¶ï¼ˆç›¸å½“äºåˆå¹¶å‰å››æ¡é“¾è¡¨ï¼‰ï¼Œåˆå¹¶åçš„é“¾è¡¨ä¿å­˜åœ¨ lists[0] ä¸­ï¼›æŠŠ lists[4] å’Œ lists[6] åˆå¹¶ï¼Œåˆå¹¶åçš„é“¾è¡¨ä¿å­˜åœ¨ lists[4] ä¸­ï¼›ä¾æ­¤ç±»æ¨ã€‚ å…«å…«åˆå¹¶ï¼šæŠŠ lists[0] å’Œ lists[4] åˆå¹¶ï¼ˆç›¸å½“äºåˆå¹¶å‰å…«æ¡é“¾è¡¨ï¼‰ï¼Œåˆå¹¶åçš„é“¾è¡¨ä¿å­˜åœ¨ lists[0] ä¸­ï¼›æŠŠ lists[8] å’Œ lists[12] åˆå¹¶ï¼Œåˆå¹¶åçš„é“¾è¡¨ä¿å­˜åœ¨ lists[8] ä¸­ï¼›ä¾æ­¤ç±»æ¨ã€‚ ä¾æ­¤ç±»æ¨ï¼Œç›´åˆ°æ‰€æœ‰é“¾è¡¨éƒ½åˆå¹¶åˆ° lists[0] ä¸­ã€‚æœ€åè¿”å› lists[0]. class Solution { ListNode* merge(ListNode* head1, ListNode* head2) { ListNode dummy(0); ListNode* tail = \u0026amp;dummy; while (head1 \u0026amp;\u0026amp; head2) { if (head1-\u0026gt;val \u0026lt; head2-\u0026gt;val) { tail-\u0026gt;next = head1; head1 = head1-\u0026gt;next; } else { tail-\u0026gt;next = head2; head2 = head2-\u0026gt;next; } tail = tail-\u0026gt;next; } tail-\u0026gt;next = head1 ? head1 : head2; return dummy.next; } public: ListNode* mergeKLists(vector\u0026lt;ListNode*\u0026gt;\u0026amp; lists) { if (lists.empty()) return nullptr; if (lists.size() == 1) return lists[0]; for (int step = 1; step \u0026lt; lists.size(); step *= 2) { for (int i = 0; i \u0026lt; lists.size() - step; i += step * 2) { lists[i] = merge(lists[i], lists[i + step]); } } return lists[0]; } }; 146 åŒå‘é“¾è¡¨ (std::list): ç»´æŠ¤æ•°æ®çš„ä½¿ç”¨é¡ºåºã€‚\né“¾è¡¨ä¸­å­˜å‚¨ (key, value) å¯¹ã€‚ é“¾è¡¨å¤´éƒ¨ (front)ï¼šå­˜æ”¾æœ€è¿‘è®¿é—®è¿‡çš„æ•°æ®ã€‚ é“¾è¡¨å°¾éƒ¨ (back)ï¼šå­˜æ”¾æœ€ä¹…æœªè¢«è®¿é—®çš„æ•°æ®ã€‚ å“ˆå¸Œè¡¨ (std::unordered_map): å®ç° O(1) çš„å¿«é€ŸæŸ¥æ‰¾ã€‚é€šè¿‡ keyï¼Œæˆ‘ä»¬èƒ½ç«‹åˆ»å®šä½åˆ°å®ƒåœ¨é“¾è¡¨ä¸­çš„ä½ç½®ã€‚\nkeyï¼šå­˜å‚¨ç¼“å­˜é¡¹çš„é”®ã€‚ valueï¼šå­˜å‚¨ä¸€ä¸ªæŒ‡å‘åŒå‘é“¾è¡¨ä¸­å¯¹åº”èŠ‚ç‚¹çš„æŒ‡é’ˆæˆ–è¿­ä»£å™¨ã€‚ get(key):\né€šè¿‡å“ˆå¸Œè¡¨æŸ¥æ‰¾ key. å¦‚æœæœªæ‰¾åˆ°ç›´æ¥è¿”å› -1.å¦‚æœæ‰¾åˆ°äº†:\nä»å“ˆå¸Œè¡¨ä¸­è·å–åˆ°é“¾è¡¨èŠ‚ç‚¹çš„æŒ‡é’ˆ/è¿­ä»£å™¨ã€‚ é€šè¿‡æŒ‡é’ˆ/è¿­ä»£å™¨è·å–èŠ‚ç‚¹ä¸­çš„ value. å°†è¿™ä¸ªèŠ‚ç‚¹ä»å®ƒå½“å‰çš„ä½ç½®ç§»åŠ¨åˆ°é“¾è¡¨çš„å¤´éƒ¨ï¼ˆè¡¨ç¤ºå®ƒåˆšåˆšè¢«è®¿é—®è¿‡ï¼‰ã€‚ è¿”å› value. put(key, value) æ“ä½œ: é€šè¿‡å“ˆå¸Œè¡¨æŸ¥æ‰¾ key.\nå¦‚æœæ‰¾åˆ°äº† (key å·²å­˜åœ¨)ï¼š\nä»å“ˆå¸Œè¡¨ä¸­è·å–åˆ°é“¾è¡¨èŠ‚ç‚¹çš„æŒ‡é’ˆ/è¿­ä»£å™¨ã€‚ æ›´æ–°è¯¥èŠ‚ç‚¹ä¸­çš„ value. å°†è¿™ä¸ªèŠ‚ç‚¹ç§»åŠ¨åˆ°é“¾è¡¨çš„å¤´éƒ¨ã€‚ å¦‚æœæœªæ‰¾åˆ° (key æ˜¯æ–°çš„)ï¼š\næ£€æŸ¥ç¼“å­˜æ˜¯å¦å·²æ»¡ï¼Œå¦‚æœå·²æ»¡: è·å–é“¾è¡¨å°¾éƒ¨çš„èŠ‚ç‚¹ã€‚ ä»å“ˆå¸Œè¡¨ä¸­åˆ é™¤å°¾éƒ¨èŠ‚ç‚¹çš„ keyã€‚ ä»é“¾è¡¨ä¸­åˆ é™¤è¯¥å°¾éƒ¨èŠ‚ç‚¹ã€‚ åœ¨é“¾è¡¨å¤´éƒ¨åˆ›å»ºä¸€ä¸ªæ–°èŠ‚ç‚¹ï¼Œå­˜å‚¨ (key, value). åœ¨å“ˆå¸Œè¡¨ä¸­æ’å…¥æ–°çš„ keyï¼Œå¹¶è®©å…¶ value æŒ‡å‘åˆšåˆ›å»ºçš„é“¾è¡¨å¤´èŠ‚ç‚¹ã€‚ ","permalink":"http://localhost:1313/blogs/leetcode/hot100/","summary":"\u003ch1 id=\"hash\"\u003eHash\u003c/h1\u003e\n\u003ch2 id=\"1\"\u003e1\u003c/h2\u003e\n\u003cp\u003eç”±äºé¢˜ç›®è§„å®šä¸èƒ½ç”¨é‡å¤å…ƒç´ ï¼Œå› æ­¤è¦å…ˆåˆ¤æ–­å“ˆå¸Œè¡¨ä¸­æ˜¯å¦å·²ç»æœ‰ \u003ccode\u003etarget - nums[i]\u003c/code\u003e å†å°† \u003ccode\u003enums[i]\u003c/code\u003e åŠ å…¥åˆ°å“ˆå¸Œè¡¨ (å¦åˆ™ \u003ccode\u003e2*nums[i] = target\u003c/code\u003e æƒ…å†µå°±ä¼šåŠ å…¥é‡å¤å…ƒç´ )\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eSolution\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003epublic\u003c/span\u003e\u003cspan class=\"o\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003evector\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003etwoSum\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003evector\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u0026amp;\u003c/span\u003e \u003cspan class=\"n\"\u003enums\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003evector\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eans\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eunordered_map\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003enums\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efind\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003enums\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e \u003cspan class=\"o\"\u003e!=\u003c/span\u003e \u003cspan class=\"n\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eend\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"n\"\u003eans\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003enums\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e]]};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"k\"\u003ebreak\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003enums\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003eans\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"49\"\u003e49\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eå­—æ¯å¼‚ä½è¯æ˜¯é€šè¿‡é‡æ–°æ’åˆ—ä¸åŒå•è¯æˆ–çŸ­è¯­çš„å­—æ¯è€Œå½¢æˆçš„å•è¯æˆ–çŸ­è¯­ï¼Œå¹¶ä½¿ç”¨æ‰€æœ‰åŸå­—æ¯ä¸€æ¬¡ã€‚\u003c/p\u003e","title":"Hot100"},{"content":"239. é€šè¿‡æ¨¡æ‹Ÿæ»‘åŠ¨çª—å£å¯ä»¥å‘ç°å¦‚æœ nums[i] \u0026lt;= nums[j], i \u0026lt; jï¼Œé‚£ä¹ˆåªè¦ nums[j] è¿˜åœ¨çª—å£å†…ï¼Œnums[i] å°±æ°¸è¿œä¸å¯èƒ½æˆä¸ºè¿™ä¸ªçª—å£çš„æœ€å¤§å€¼ã€‚å› ä¸º nums[j] ä¸ä»…æ¯” nums[i] å¤§ï¼ˆæˆ–ç›¸ç­‰ï¼‰ï¼Œè€Œä¸”æ¯”å®ƒæ›´æ™šç¦»å¼€çª—å£ã€‚å› æ­¤ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œnums[i] å¯ä»¥è¢«å®‰å…¨åœ°ä¸¢å¼ƒã€‚\nå› æ­¤ä½¿ç”¨ä¸€ä¸ªåŒç«¯é˜Ÿåˆ—æ¥å­˜å‚¨æ•°ç»„å…ƒç´ çš„ç´¢å¼•ï¼Œå¹¶å§‹ç»ˆä¿æŒé˜Ÿåˆ—ä¸­ç´¢å¼•å¯¹åº”çš„å…ƒç´ å€¼æ˜¯ä¸¥æ ¼å•è°ƒé€’å‡çš„ã€‚è¿™æ ·ä¸€æ¥ï¼Œé˜Ÿåˆ—çš„é˜Ÿé¦–å…ƒç´ æ‰€å¯¹åº”çš„æ•°ç»„å€¼ï¼Œå°±æ°¸è¿œæ˜¯å½“å‰çª—å£çš„æœ€å¤§å€¼ã€‚\nä¸ºäº†ç»´æŠ¤è¿™ä¸ªå•è°ƒé€’å‡çš„é˜Ÿåˆ—ï¼Œæˆ‘ä»¬éœ€è¦éµå¾ªä»¥ä¸‹ä¸¤ä¸ªè§„åˆ™ï¼š\nç§»é™¤å‡ºç•Œå…ƒç´ ï¼šåœ¨çª—å£å‘å³æ»‘åŠ¨æ—¶ï¼Œé¦–å…ˆè¦æ£€æŸ¥é˜Ÿé¦–çš„ç´¢å¼•æ˜¯å¦å·²ç»è¶…å‡ºäº†å½“å‰çª—å£çš„å·¦è¾¹ç•Œã€‚å¦‚æœæ˜¯ï¼Œåˆ™è¯´æ˜é˜Ÿé¦–å…ƒç´ å·²ç»è¿‡æœŸï¼Œéœ€è¦ä»é˜Ÿåˆ—ä¸­ç§»é™¤ï¼ˆpop_frontï¼‰ã€‚å› æ­¤é˜Ÿåˆ—ä¸­è¦è®°å½•çš„æ˜¯å…ƒç´ åœ¨æ•°ç»„ä¸­çš„ä¸‹æ ‡ã€‚ ç»´æŒé˜Ÿåˆ—å•è°ƒé€’å‡ï¼šå½“ä¸€ä¸ªæ–°çš„å…ƒç´ å‡†å¤‡å…¥é˜Ÿæ—¶ï¼Œä¸ºäº†ç»´æŒé˜Ÿåˆ—çš„å•è°ƒæ€§ï¼Œæˆ‘ä»¬éœ€è¦ä»é˜Ÿå°¾ï¼ˆbackï¼‰ å¼€å§‹ï¼Œå‘å‰æ¯”è¾ƒã€‚å¦‚æœé˜Ÿå°¾çš„å…ƒç´ å°äºæˆ–ç­‰äºå½“å‰è¦å…¥é˜Ÿçš„å…ƒç´ ï¼Œé‚£ä¹ˆé˜Ÿå°¾çš„å…ƒç´ å°±ä¸å¯èƒ½æˆä¸ºæœªæ¥ä»»ä½•çª—å£çš„æœ€å¤§å€¼ï¼ˆå› ä¸ºå½“å‰å…ƒç´ æ›´â€œæ–°â€ä¹Ÿæ›´â€œå¤§â€ï¼‰ï¼Œæ‰€ä»¥åº”è¯¥å°†é˜Ÿå°¾å…ƒç´ å‡ºé˜Ÿï¼ˆpop_backï¼‰.é‡å¤æ­¤è¿‡ç¨‹ï¼Œç›´åˆ°é˜Ÿåˆ—ä¸ºç©ºæˆ–è€…é˜Ÿå°¾å…ƒç´ å¤§äºå½“å‰å…ƒç´ ï¼Œç„¶åæ‰å°†å½“å‰å…ƒç´ çš„ç´¢å¼•å…¥é˜Ÿï¼ˆpush_backï¼‰. åŒæ—¶å½“çª—å£å½¢æˆå (å³éå†åˆ°çš„å…ƒç´ æ•°é‡è¾¾åˆ° k) æ‰å¼€å§‹è®°å½•ç»“æœã€‚\nclass Solution { public: vector\u0026lt;int\u0026gt; maxSlidingWindow(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { vector\u0026lt;int\u0026gt; ans; deque\u0026lt;int\u0026gt; dq; int n = nums.size(); for (int i = 0; i \u0026lt; n; i++) { while (!dq.empty() \u0026amp;\u0026amp; nums[dq.back()] \u0026lt;= nums[i]) { dq.pop_back(); } dq.push_back(i); // can use if because we judge with each i if (i - dq.front() + 1 \u0026gt; k) { // excess the window dq.pop_front(); } if (i \u0026gt;= k - 1) { ans.push_back(nums[dq.front()]); } } return ans; } }; ","permalink":"http://localhost:1313/blogs/leetcode/09_monotonedeque/","summary":"Algorithm questions about monotone deque.","title":"09 Monotone Deque"},{"content":"739. è¿™é“é¢˜çš„æœ¬è´¨æ˜¯å¯»æ‰¾æ¯ä¸ªå…ƒç´ å³ä¾§ç¬¬ä¸€ä¸ªæ¯”å®ƒå¤§çš„å…ƒç´ ã€‚è¿™ç±» \u0026ldquo;ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´ \u0026rdquo; (Next Greater Element) çš„é—®é¢˜ï¼Œæ­£æ˜¯å•è°ƒæ ˆçš„ç»å…¸åº”ç”¨åœºæ™¯ã€‚å•è°ƒæ ˆæ˜¯ä¸€ç§ç‰¹æ®Šçš„æ ˆï¼Œå®ƒåœ¨ä»»ä½•æ—¶å€™ï¼Œæ ˆå†…çš„å…ƒç´ éƒ½ä¿æŒç€å•è°ƒé€’å¢æˆ–å•è°ƒé€’å‡çš„é¡ºåºã€‚å½“ä¸€ä¸ªæ–°å…ƒç´ éœ€è¦å…¥æ ˆæ—¶ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡å¼¹å‡ºæ ˆé¡¶å…ƒç´ çš„æ–¹å¼æ¥ç»´æŠ¤è¿™ä¸ªå•è°ƒæ€§ã€‚\nå¯¹äºè¿™é“é¢˜ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°çš„æ˜¯æ¯ä¸ªæ¸©åº¦å€¼å³è¾¹çš„ç¬¬ä¸€ä¸ªæ›´é«˜æ¸©åº¦ã€‚æˆ‘ä»¬å¯ä»¥ç»´æŠ¤ä¸€ä¸ªå•è°ƒé€’å‡çš„æ ˆï¼Œæ ˆä¸­å­˜å‚¨çš„æ˜¯æ•°ç»„çš„ä¸‹æ ‡ã€‚\nä»å³å‘å·¦éå†:\nå¦‚æœæ ˆä¸ä¸ºç©ºï¼Œä¸”æ ˆé¡¶å…ƒç´ å¤©æ•°å¯¹åº”çš„æ¸©åº¦ \u0026lt;= å½“å‰å¤©æ•°æ¸©åº¦ï¼Œå¹¶ä¸”ç”±äºæˆ‘ä»¬æ˜¯å€’åºéå†ï¼Œå®ƒä¹Ÿä¸å¯èƒ½æ˜¯å½“å‰å¤©æ•°å³è¾¹çš„ç¬¬ä¸€ä¸ªæ›´é«˜æ¸©ã€‚æ‰€ä»¥ï¼Œè¿™ä¸ªæ ˆé¡¶å…ƒç´ å¯¹äºå½“å‰æ¥è¯´æ²¡æœ‰ç”¨äº†ï¼Œç›´æ¥å¼¹å‡ºã€‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°æ ˆä¸ºç©ºï¼Œæˆ–è€…æ ˆé¡¶å…ƒç´ å¯¹åº”çš„æ¸©åº¦å¤§äºå½“å‰æ¸©åº¦ã€‚\nç»è¿‡ä¸Šä¸€æ­¥çš„ç»´æŠ¤ï¼Œå¦‚æœæ­¤æ—¶æ ˆä¸ä¸ºç©ºï¼Œé‚£ä¹ˆæ ˆé¡¶å…ƒç´ å°±æ˜¯å³ä¾§ç¬¬ä¸€ä¸ªæ¯”å½“å‰æ›´é«˜çš„æ¸©åº¦çš„ä¸‹æ ‡ã€‚æˆ‘ä»¬å°±å¯ä»¥è®¡ç®—å®ƒä»¬ä¹‹é—´çš„å¤©æ•°å·®ã€‚å¦‚æœæ ˆä¸ºç©ºï¼Œè¯´æ˜ å³ä¾§æ²¡æœ‰æ¯”å®ƒæ›´çƒ­çš„å¤©äº†ï¼Œç­”æ¡ˆä¸º 0.\nå¤„ç†å®Œä¹‹åï¼Œå°†å½“å‰ä¸‹æ ‡å‹å…¥æ ˆä¸­ã€‚å› ä¸ºæˆ‘ä»¬å·²ç»æŠŠæ‰€æœ‰æ¯”å®ƒçŸ®ï¼ˆæ¸©åº¦ä½ï¼‰çš„å…ƒç´ éƒ½å¼¹å‡ºäº†ï¼Œæ‰€ä»¥ iå…¥æ ˆåï¼Œæ ˆä»ç„¶ä¿æŒå•è°ƒé€’å‡ã€‚\nclass Solution { public: std::vector\u0026lt;int\u0026gt; dailyTemperatures(std::vector\u0026lt;int\u0026gt;\u0026amp; temperatures) { int n = temperatures.size(); std::vector\u0026lt;int\u0026gt; answer(n, 0); std::stack\u0026lt;int\u0026gt; st; for (int i = n - 1; i \u0026gt;= 0; --i) { while (!st.empty() \u0026amp;\u0026amp; temperatures[i] \u0026gt;= temperatures[st.top()]) { st.pop(); } if (!st.empty()) { answer[i] = st.top() - i; } st.push(i); } return answer; } }; ä»å·¦å‘å³éå†:\nå¦‚æœæ ˆä¸ä¸ºç©ºï¼Œä¸”å½“å‰æ¸©åº¦å¤§äºæ ˆé¡¶å…ƒç´ å¯¹åº”å¤©æ•°çš„æ¸©åº¦ï¼Œè¿™è¯´æ˜æˆ‘ä»¬æ‰¾åˆ°äº†æ ˆé¡¶ä¸‹æ ‡å¯¹åº”çš„ç­”æ¡ˆã€‚ç›¸å‡è®¡ç®—å¤©æ•°å·®åå°†æ ˆé¡¶å…ƒç´ å¼¹å‡ºã€‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°æ ˆä¸ºç©ºï¼Œæˆ–è€…å½“å‰æ¸©åº¦ä¸å†å¤§äºæ ˆé¡¶å…ƒç´ å¯¹åº”çš„æ¸©åº¦ã€‚ ç»è¿‡ä¸Šä¸€æ­¥å¤„ç†åï¼Œæˆ‘ä»¬å°†å½“å‰ä¸‹æ ‡å‹å…¥æ ˆä¸­ã€‚å› ä¸ºåªæœ‰å½“å½“å‰å¤©æ•°æ¸© \u0026lt;= æ ˆé¡¶æ¸©åº¦æ—¶ï¼Œå¾ªç¯æ‰ä¼šåœæ­¢ï¼Œæ‰€ä»¥å…¥æ ˆåï¼Œæ ˆä»ç„¶èƒ½ä¿æŒä»æ ˆåº•åˆ°æ ˆé¡¶çš„å•è°ƒé€’å‡æ€§ã€‚å½“å‰å…ƒç´ å°†ä¼šç­‰å¾…å®ƒå³ä¾§çš„æ›´é«˜æ¸©åº¦å‡ºç°ã€‚ éå†ç»“æŸåï¼Œé‚£äº›ä»ç„¶ç•™åœ¨æ ˆä¸­çš„ä¸‹æ ‡ï¼Œæ„å‘³ç€å®ƒä»¬å³ä¾§æ²¡æœ‰æ›´é«˜çš„æ¸©åº¦ï¼Œè€Œç»“æœæ•°ç»„åˆå§‹åŒ–æ—¶å°±æ˜¯ 0ï¼Œæ‰€ä»¥æ— éœ€é¢å¤–å¤„ç†ã€‚ class Solution { public: std::vector\u0026lt;int\u0026gt; dailyTemperatures(std::vector\u0026lt;int\u0026gt;\u0026amp; temperatures) { int n = temperatures.size(); std::vector\u0026lt;int\u0026gt; answer(n, 0); std::stack\u0026lt;int\u0026gt; st; for (int i = 0; i \u0026lt; n; ++i) { while (!st.empty() \u0026amp;\u0026amp; temperatures[i] \u0026gt; temperatures[st.top()]) { int prev_index = st.top(); answer[prev_index] = i - prev_index; st.pop(); } st.push(i); } return answer; } }; æ—¶é—´å¤æ‚åº¦: $O(n)$. è™½ç„¶æœ‰åµŒå¥—çš„ while å¾ªç¯ï¼Œä½†æ¯ä¸ªä¸‹æ ‡æœ€å¤šè¢«å‹å…¥æ ˆä¸€æ¬¡ï¼Œå¼¹å‡ºæ ˆä¸€æ¬¡ã€‚ ç©ºé—´å¤æ‚åº¦: $O(n)$. åœ¨æœ€åçš„æƒ…å†µä¸‹ (æ¸©åº¦å•è°ƒé€’å‡)ï¼Œæ‰€æœ‰æŸ±å­çš„ä¸‹æ ‡éƒ½ä¼šè¢«å‹å…¥æ ˆä¸­ã€‚ 42. è¿™é“é¢˜çš„æœ¬è´¨æ˜¯å¯¹äºæ¯ä¸ªä½ç½®ï¼Œæ‰¾åˆ°å…¶å·¦å³ä¸¤è¾¹æ¯”å®ƒé«˜çš„æŸ±å­ï¼Œç„¶åè®¡ç®—è¿™ä¸ªä½ç½®èƒ½æ¥çš„é›¨æ°´ã€‚ç»´æŠ¤ä¸€ä¸ªå•è°ƒé€’å‡çš„æ ˆï¼Œæ ˆä¸­å­˜å‚¨çš„æ˜¯æŸ±å­çš„ä¸‹æ ‡ï¼Œå…¶å¯¹åº”çš„é«˜åº¦æ˜¯ä¸¥æ ¼é€’å‡çš„ã€‚\nä»å·¦åˆ°å³éå†æ¯ä¸ªæŸ±å­ã€‚å½“æ ˆä¸ä¸ºç©ºï¼Œä¸”å½“å‰æŸ±å­çš„é«˜åº¦å¤§äºæ ˆé¡¶ä¸‹æ ‡å¯¹åº”çš„æŸ±å­çš„é«˜åº¦æ—¶ï¼Œè¯´æ˜ä¸€ä¸ªå‡¹æ§½çš„å³è¾¹ç•Œå·²ç»æ‰¾åˆ°ã€‚ å°†æ ˆé¡¶å…ƒç´  å¼¹å‡ºï¼Œå…¶ä¸‹æ ‡è®°ä¸º midï¼Œheight[mid] å°±æ˜¯å‡¹æ§½çš„åº•éƒ¨é«˜åº¦ã€‚æ­¤æ—¶ï¼Œå¦‚æœæ ˆä»ç„¶ä¸ä¸ºç©ºï¼Œæ–°çš„æ ˆé¡¶å…ƒç´ å°±æ˜¯å‡¹æ§½çš„å·¦è¾¹ç•Œï¼Œå…¶ä¸‹æ ‡è®°ä¸º left. å‡¹æ§½çš„å®½åº¦ w = i - left - 1. å‡¹æ§½çš„é«˜åº¦å–å†³äºå·¦å³ä¸¤ä¸ªè¾¹ç•Œä¸­è¾ƒçŸ®çš„é‚£ä¸ªã€‚æ¥æ°´çš„é«˜åº¦æ˜¯è¿™ä¸ªè¾ƒçŸ®è¾¹ç•Œçš„é«˜åº¦å‡å»åº•éƒ¨çš„é«˜åº¦ï¼Œå³ h = min(height[i], height[left]) - height[mid]. å°†è¿™éƒ¨åˆ†é›¨æ°´é‡ w * h ç´¯åŠ ã€‚ åªè¦å½“å‰æŸ±å­ä»ç„¶æ¯”æ–°çš„æ ˆé¡¶å…ƒç´ é«˜ï¼Œå°±è¯´æ˜å½“å‰æŸ±å­å¯ä»¥ä½œä¸ºæ›´å¤šå‡¹æ§½çš„å³è¾¹ç•Œï¼Œå› æ­¤é‡å¤ä¸Šè¿°è®¡ç®—è¿‡ç¨‹ã€‚ å½“ while å¾ªç¯ç»“æŸå (å³æ ˆä¸ºç©ºï¼Œæˆ–å½“å‰æŸ±å­ä¸å†é«˜äºæ ˆé¡¶æŸ±å­)ï¼Œæˆ‘ä»¬å°†å½“å‰æŸ±å­çš„ä¸‹æ ‡å‹å…¥æ ˆä¸­ã€‚ class Solution { public: int trap(std::vector\u0026lt;int\u0026gt;\u0026amp; height) { if (height.empty()) { return 0; } std::stack\u0026lt;int\u0026gt; st; int total_water = 0; for (int i = 0; i \u0026lt; height.size(); ++i) { while (!st.empty() \u0026amp;\u0026amp; height[i] \u0026gt; height[st.top()]) { int mid_index = st.top(); st.pop(); if (st.empty()) { break; } int left_index = st.top(); // å‡¹æ§½çš„å·¦è¾¹ç•Œ int width = i - left_index - 1; int bound_height = std::min(height[i], height[left_index]); int effective_height = bound_height - height[mid_index]; total_water += width * effective_height; } st.push(i); } return total_water; } }; 496. ä»å·¦å¾€å³éå†ï¼Œåªè¦éå†åˆ°æ¯”æ ˆé¡¶å…ƒç´ æ›´å¤§çš„æ•°ï¼Œå°±æ„å‘³ç€æ ˆé¡¶å…ƒç´ æ‰¾åˆ°äº†ç­”æ¡ˆï¼Œè®°å½•ç­”æ¡ˆï¼Œå¹¶å¼¹å‡ºæ ˆé¡¶ã€‚æˆ‘ä»¬åªéœ€æŠŠåœ¨ nums1 ä¸­çš„å…ƒç´ å…¥æ ˆè¿™æ ·ç©ºé—´å¤æ‚åº¦å°±ä¸º $O(m)$.\nclass Solution { public: vector\u0026lt;int\u0026gt; nextGreaterElement(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2) { int m = nums1.size(); int n = nums2.size(); vector\u0026lt;int\u0026gt; ans(m, -1); stack\u0026lt;int\u0026gt; st; unordered_map\u0026lt;int, int\u0026gt; map; for (int i = 0; i \u0026lt; nums1.size(); i++) { map[nums1[i]] = i; } for (int i = 0; i \u0026lt; n; i ++) { while(!st.empty() \u0026amp;\u0026amp; nums2[i] \u0026gt; st.top()) { ans[map[st.top()]] = nums2[i]; st.pop(); } if (map.contains(nums2[i])) { st.push(nums2[i]); } } return ans; } }; 503 å¾ªç¯ä¸¤éæ•°ç»„ï¼Œå–æ¨¡éå†ï¼Œæ³¨æ„æ•°ç»„ä¸­å…ƒç´ åªç”¨å‹æ ˆä¸€æ¬¡ã€‚\nclass Solution { public: vector\u0026lt;int\u0026gt; nextGreaterElements(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); vector\u0026lt;int\u0026gt; ans(n, -1); stack\u0026lt;int\u0026gt; st; for (int i = 0; i \u0026lt; 2*n; i++) { while (!st.empty() \u0026amp;\u0026amp; nums[i%n] \u0026gt; nums[st.top()]) { ans[st.top()] = nums[i%n]; st.pop(); } if (i \u0026lt; n) st.push(i); } return ans; } }; 901. ç»´æŠ¤ä¸€ä¸ªä»·æ ¼å•è°ƒé€’å‡çš„æ ˆã€‚æ ˆä¸­ä¸ä»…è¦å­˜ä»·æ ¼ï¼Œè¿˜è¦å­˜è¯¥ä»·æ ¼å¯¹åº”çš„è·¨åº¦ã€‚æŸ¥çœ‹æ ˆé¡¶çš„å…ƒç´  {top_price, top_span}ã€‚\nå½“å‰ä»·æ ¼åˆ›å»ºä¸€ä¸ªåˆå§‹è·¨åº¦ curSpan = 1. å¦‚æœæ ˆé¡¶ä»·æ ¼ \u0026lt;= å½“å‰ä»·æ ¼ï¼Œå®ƒçš„è·¨åº¦å¯ä»¥è¢«å¸æ”¶åˆå¹¶åˆ°å½“å‰ä»·æ ¼çš„è·¨åº¦ä¸­ã€‚åˆå§‹è·¨åº¦åŠ ä¸ŠåŠ æ ˆé¡¶å…ƒç´ è·¨åº¦åå¼¹å‡ºæ ˆé¡¶å…ƒç´ ã€‚æŒç»­è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°æ ˆä¸ºç©ºï¼Œæˆ–è€…æ ˆé¡¶çš„ä»·æ ¼æ¯”å½“å‰ä»·æ ¼æ›´é«˜ã€‚\nç»è¿‡ä¸Šä¸€æ­¥çš„åˆå¹¶ï¼ŒcurSpan å·²ç»è®¡ç®—å‡ºäº†æœ€ç»ˆçš„ç»“æœã€‚æˆ‘ä»¬å°†å½“å‰çš„ä»·æ ¼å’Œå®ƒè®¡ç®—å‡ºçš„æ€»è·¨åº¦ {price, curSpan} ä½œä¸ºä¸€ä¸ªæ–°çš„å…ƒç´ å‹å…¥æ ˆä¸­ï¼Œä»¥ä¾›åç»­çš„ä»·æ ¼ä½¿ç”¨ã€‚ç„¶åè¿”å› curSpan.\nclass StockSpanner { public: stack\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; st; StockSpanner() { } int next(int price) { int curSpan = 1; while (!st.empty() \u0026amp;\u0026amp; price \u0026gt;= st.top().first) { curSpan += st.top().second; st.pop(); } st.push({price, curSpan}); return curSpan; } }; ","permalink":"http://localhost:1313/blogs/leetcode/08_monotonestack/","summary":"Algorithm questions about monotone stack.","title":"08 Monotone Stack"},{"content":"C++ Lambda è¡¨è¾¾å¼ï¼ˆä¹Ÿç§°ä¸º Lambda å‡½æ•°ï¼‰æ˜¯ä¸€ç§åœ¨ä»£ç ä¸­å®šä¹‰åŒ¿åå‡½æ•°çš„ä¾¿æ·æ–¹å¼ã€‚å®ƒç‰¹åˆ«é€‚ç”¨äºéœ€è¦ä¸€ä¸ªç®€çŸ­ã€ä¸´æ—¶çš„å‡½æ•°å¯¹è±¡çš„åœºæ™¯ï¼Œä¾‹å¦‚ä½œä¸ºæ ‡å‡†åº“ç®—æ³•çš„å‚æ•°ã€‚\nä¸€ä¸ªå®Œæ•´çš„ Lambda è¡¨è¾¾å¼çš„é€šç”¨è¯­æ³•å¦‚ä¸‹ï¼š\n[capture-list](parameters) mutable exception -\u0026gt; return_type { // å‡½æ•°ä½“ statement; } æ•è·åˆ—è¡¨ [capture_list] ç”¨äºæ§åˆ¶ Lambda å‡½æ•°å¦‚ä½•ä»å…¶æ‰€åœ¨çš„çˆ¶ä½œç”¨åŸŸâ€œæ•è·â€å˜é‡ã€‚\n[]ï¼šç©ºæ•è·åˆ—è¡¨ã€‚è¡¨ç¤ºä¸æ•è·ä»»ä½•å¤–éƒ¨å˜é‡ã€‚Lambda å‡½æ•°ä½“å†…ä¸èƒ½è®¿é—®çˆ¶ä½œç”¨åŸŸä¸­çš„ä»»ä½•å˜é‡ã€‚ [=]ï¼šä»¥å€¼ï¼ˆby valueï¼‰çš„æ–¹å¼æ•è·æ‰€æœ‰å¤–éƒ¨å˜é‡ã€‚åœ¨ Lambda å‡½æ•°ä½“å†…ï¼Œä½ åªèƒ½è¯»å–è¿™äº›å˜é‡çš„å€¼ï¼Œä¸èƒ½ä¿®æ”¹å®ƒä»¬ï¼ˆé™¤éä½¿ç”¨ mutable å…³é”®å­—ï¼‰ã€‚è¿™ç›¸å½“äºåˆ›å»ºäº†å¤–éƒ¨å˜é‡çš„ä¸€ä»½æ‹·è´ã€‚ [\u0026amp;]ï¼šä»¥å¼•ç”¨ï¼ˆby referenceï¼‰çš„æ–¹å¼æ•è·æ‰€æœ‰å¤–éƒ¨å˜é‡ã€‚åœ¨ Lambda å‡½æ•°ä½“å†…ï¼Œä½ å¯ä»¥ä¿®æ”¹è¿™äº›å¤–éƒ¨å˜é‡ï¼Œå¹¶ä¸”ä¿®æ”¹ä¼šå½±å“åˆ°åŸå§‹å˜é‡ã€‚ [this]ï¼šä»¥å€¼çš„æ–¹å¼æ•è·å½“å‰å¯¹è±¡çš„ this æŒ‡é’ˆã€‚è¿™ä½¿å¾—ä½ å¯ä»¥åœ¨ Lambda å‡½æ•°ä½“å†…è®¿é—®å½“å‰å¯¹è±¡çš„æˆå‘˜å˜é‡å’Œæˆå‘˜å‡½æ•°ã€‚ [a, \u0026amp;b]ï¼šæŒ‡å®šæ•è·åˆ—è¡¨ã€‚è¿™é‡Œ a ä»¥å€¼çš„æ–¹å¼æ•è·ï¼Œè€Œ b ä»¥å¼•ç”¨çš„æ–¹å¼æ•è·ã€‚ä½ å¯ä»¥æ··åˆä½¿ç”¨å€¼æ•è·å’Œå¼•ç”¨æ•è·ã€‚ [=, \u0026amp;b]ï¼šä»¥å€¼çš„æ–¹å¼æ•è·æ‰€æœ‰å˜é‡ï¼Œä½†å˜é‡ b é™¤å¤–ï¼Œå®ƒä»¥å¼•ç”¨çš„æ–¹å¼æ•è·ã€‚ [\u0026amp;, a]ï¼šä»¥å¼•ç”¨çš„æ–¹å¼æ•è·æ‰€æœ‰å˜é‡ï¼Œä½†å˜é‡ a é™¤å¤–ï¼Œå®ƒä»¥å€¼çš„æ–¹å¼æ•è·ã€‚ int x = 10; int y = 20; // ä¸æ•è·ä»»ä½•å˜é‡ auto f1 = []() { return 5; }; // ä»¥å€¼çš„æ–¹å¼æ•è· x å’Œ y auto f2 = [=]() { return x + y; }; // ä»¥å¼•ç”¨çš„æ–¹å¼æ•è· x å’Œ y auto f3 = [\u0026amp;]() { x = 15; y = 25; }; // æ··åˆæ•è· auto f4 = [x, \u0026amp;y]() { y = 30; return x + y; }; å‚æ•°åˆ—è¡¨ (parameters): å’Œæ™®é€šå‡½æ•°çš„å‚æ•°åˆ—è¡¨ä¸€æ ·ï¼Œè¿™éƒ¨åˆ†æ˜¯å¯é€‰çš„ã€‚\n// æ²¡æœ‰å‚æ•° auto greet = []() { std::cout \u0026lt;\u0026lt; \u0026#34;Hello, World!\u0026#34; \u0026lt;\u0026lt; std::endl; }; // æ¥æ”¶ä¸¤ä¸ª int å‚æ•° auto add = [](int a, int b) { return a + b; }; // C++14 ä»¥åï¼Œå¯ä»¥ä½¿ç”¨ auto è¿›è¡Œæ³›å‹å‚æ•°å£°æ˜ auto generic_add = [](auto a, auto b) { return a + b; }; mutable å…³é”®å­— (å¯é€‰): é»˜è®¤æƒ…å†µä¸‹ï¼Œé€šè¿‡å€¼æ•è·çš„å˜é‡åœ¨ Lambda å‡½æ•°ä½“å†…æ˜¯ const çš„ï¼Œä¸èƒ½ä¿®æ”¹å®ƒä»¬ã€‚å¦‚æœå¸Œæœ›èƒ½å¤Ÿä¿®æ”¹è¿™äº›æŒ‰å€¼æ•è·çš„å˜é‡çš„æ‹·è´ï¼ˆæ³¨æ„ï¼Œè¿™ä¸ä¼šå½±å“åŸå§‹å˜é‡ï¼‰ï¼Œéœ€è¦ä½¿ç”¨ mutable å…³é”®å­—ã€‚\nint value = 100; auto counter = [value]() mutable { value++; // å¦‚æœæ²¡æœ‰ mutableï¼Œè¿™é‡Œä¼šç¼–è¯‘é”™è¯¯ return value; }; std::cout \u0026lt;\u0026lt; counter() \u0026lt;\u0026lt; std::endl; // è¾“å‡º 101 std::cout \u0026lt;\u0026lt; counter() \u0026lt;\u0026lt; std::endl; // è¾“å‡º 102 std::cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; // åŸå§‹ value ä»ç„¶æ˜¯ 100 å¼‚å¸¸è§„èŒƒ exception (å¯é€‰):å¯ä»¥ä½¿ç”¨ noexcept æ¥æŒ‡æ˜è¯¥ Lambda å‡½æ•°ä¸ä¼šæŠ›å‡ºä»»ä½•å¼‚å¸¸ã€‚\nauto safe_divide = [](int a, int b) noexcept { return (b == 0) ? 0 : a / b; }; è¿”å›ç±»å‹ -\u0026gt; return_type (å¯é€‰): åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œç¼–è¯‘å™¨å¯ä»¥è‡ªåŠ¨æ¨æ–­å‡º Lambda è¡¨è¾¾å¼çš„è¿”å›ç±»å‹ã€‚ä½†å¦‚æœå‡½æ•°ä½“åŒ…å«å¤šä¸ª return è¯­å¥ï¼Œæˆ–è€…å¸Œæœ›æ˜ç¡®æŒ‡å®šè¿”å›ç±»å‹ï¼Œå°±å¯ä»¥ä½¿ç”¨è¿™ä¸ªè¯­æ³•ã€‚\n// ç¼–è¯‘å™¨å¯ä»¥è‡ªåŠ¨æ¨æ–­è¿”å›ç±»å‹ä¸º int auto add = [](int a, int b) { return a + b; }; // æ˜ç¡®æŒ‡å®šè¿”å›ç±»å‹ä¸º double auto divide = [](int a, int b) -\u0026gt; double { if (b == 0) { return 0; } return static_cast\u0026lt;double\u0026gt;(a) / b; }; ","permalink":"http://localhost:1313/blogs/productivity/cpplambdaexpression/","summary":"Lambda Expression in CPP.","title":"Cpp Lambda Expression"},{"content":"Overview vLLM è°ƒç”¨ txda åˆå§‹åŒ– context. ç¨‹åºç»“æŸåé‡Šæ”¾ context. vLLM æ ¹æ® hf_dir ä¸­çš„é…ç½®æ–‡ä»¶åˆ›å»ºæ¨¡å‹, å…¶ä¸­ config.json å†³å®šä½¿ç”¨ TxNN ä¸­å®šä¹‰çš„å“ªä¸ª model class; ä¹Ÿå†³å®šäº†è¿™ä¸ª class init æ—¶çš„å‚æ•°æ˜¯ä»€ä¹ˆ. è°ƒç”¨ TxNN çš„ model class çš„ load weight å‡½æ•°å’Œ forward å‡½æ•°, å…·ä½“å®ç°éƒ½ä¾èµ–äº TxDA. Argument def parse_args(): parser = argparse.ArgumentParser() parser.add_argument(\u0026#39;--hf_dir\u0026#39;, type=str, help=\u0026#39;Huggingface model path\u0026#39;) parser.add_argument(\u0026#39;--max_tokens\u0026#39;, type=int, default=32, help=\u0026#39;Max generated tokens\u0026#39;) parser.add_argument(\u0026#39;--tp_size\u0026#39;, type=int, default=1, help=\u0026#39;Model TP size\u0026#39;) # tensor parallel degree, must Keep consistent with model.json parser.add_argument( \u0026#39;--device\u0026#39;, type=lambda e: [int(e) for e in str(e).split(\u0026#39;,\u0026#39;)], default=[0, 1, 2, 3], help=\u0026#34;Tx device idxs; E.g., --device 0,1,2,3\u0026#34; ) parser.add_argument(\u0026#34;--log_file\u0026#34;, type=str, default=\u0026#34;\u0026#34;, help=\u0026#34;Log file path\u0026#34;) args = parser.parse_args() # Get case_dir from huggingface model config with open(f\u0026#34;{args.hf_dir}/config.json\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as file: hf_config = json.load(file) args.case_dir = hf_config[\u0026#34;param_dir\u0026#34;] # kcorebin path, with model_info.json and chip0/, chip1/ ... in the directory print( \u0026#34;Inference info:\\n\u0026#34; f\u0026#34;| - hf_dir: {args.hf_dir}\\n\u0026#34; f\u0026#34;| - case_dir: {args.case_dir}\\n\u0026#34; f\u0026#34;| - max_tokens: {args.max_tokens}\\n\u0026#34; f\u0026#34;| - tp_size: {args.tp_size}\\n\u0026#34; f\u0026#34;| - ENV:TXDA_VISIBLE_DEVICES: \u0026#34; f\u0026#34;{os.environ.get(\u0026#39;TXDA_VISIBLE_DEVICES\u0026#39;, default=\u0026#39;Not specified\u0026#39;)}\\n\u0026#34; f\u0026#34;| - device: {args.device}\\n\u0026#34; f\u0026#34;| - log_file: {args.log_file}\u0026#34; ) return args hf_dir: æŒ‡çš„æ˜¯æ¨¡å‹çš„ hugging_face è·¯å¾„ã€‚ case_dir: æ˜¯è§£æ hf_dir ä¸‹çš„ config.json æ–‡ä»¶çš„å­—æ®µï¼ŒæŒ‡çš„æ˜¯åç«¯ç”Ÿæˆçš„ kcore æ–‡ä»¶å¤¹è·¯å¾„ã€‚é™¤æ­¤ä¹‹å¤–è¿˜éœ€è¦åœ¨ json æ–‡ä»¶ä¸­é¢å¤–é…ç½®å¹¶è¡Œåº¦ç›¸å…³ä¿¡æ¯ã€‚ { // ... \u0026#34;param_dir\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;tensor_parallel\u0026#34;: { \u0026#34;use_tp\u0026#34;: false, \u0026#34;parallel_size\u0026#34;: 1 } } ä¼šæ ¹æ®æˆ‘ä»¬ä¼ å…¥çš„ --device å’Œ tp_size å‚æ•°åˆ›å»ºé€»è¾‘åˆ°å®é™…ç‰©ç†èŠ¯ç‰‡çš„æ˜ å°„ã€‚è¿™é‡Œ InternLM3 ä½¿ç”¨çš„æ˜¯ 4 å¡æœºå™¨ï¼Œå¼ é‡å¹¶è¡Œåº¦ä¸º 2. è®¡ç®—å›¾ä¸­ batchsize=1.\n// setDeviceIdx std::unordered_map\u0026lt;uint32_t, std::vector\u0026lt;uint32_t\u0026gt;\u0026gt; c4_TP2x2 = { {0, {0, 1}}, {1, {2, 3}} }; std::unordered_map\u0026lt;uint32_t, std::vector\u0026lt;uint32_t\u0026gt;\u0026gt; c4_TP2x2_hw = { {0, {0, 1}}, {1, {2, 3}} }; auto set_TP2_C4_Map = [\u0026amp;](std::unordered_map\u0026lt;uint32_t, std::vector\u0026lt;uint32_t\u0026gt;\u0026gt;\u0026amp; user_map, std::unordered_map\u0026lt;uint32_t, std::vector\u0026lt;uint32_t\u0026gt;\u0026gt;\u0026amp; hw_map, std::vector\u0026lt;uint32_t\u0026gt;\u0026amp; user_settings) { for (auto it_TP2x2 : user_map) { if (user_settings == it_TP2x2.second) { device_setting_ = hw_map[it_TP2x2.first]; } } }; if (TxdATPMode::C4TP2B1 == tp_mode_) { set_TP2_C4_Map(c4_TP2x2, c4_TP2x2_hw, user_settings); } TxdaContext::initDevice çš„ä¸»è¦åŠŸèƒ½æ˜¯åˆå§‹åŒ–è®¾å¤‡ (TsmDevice)ï¼Œå¹¶å°†å…¶å°è£…ä¸º TxdaDevice å¯¹è±¡ï¼Œæœ€ç»ˆå­˜å‚¨åˆ°è®¾å¤‡ç»„ (device_group_) ä¸­ã€‚\nTxdaContext::initChipProperty çš„ä¸»è¦åŠŸèƒ½æ˜¯åˆå§‹åŒ–èŠ¯ç‰‡ç›¸å…³çš„å±æ€§å’Œé…ç½®ï¼ŒåŒ…æ‹¬è®¾å¤‡ç»„ã€æ¨¡å‹æ•°é‡ã€ç¯å¢ƒå˜é‡è§£æã€å†…å­˜åœ°å€åˆå§‹åŒ–ä»¥åŠè®¾å¤‡å¯åŠ¨å‚æ•°çš„è®¾ç½®ã€‚\nTxdaContext::initModelï¼šè´Ÿè´£åˆå§‹åŒ–æ¨¡å‹ï¼Œè§£ææ¡ˆä¾‹ç›®å½•ï¼Œè®¾ç½® TP å¤§å°å’Œ TP æ¨¡å¼ï¼Œå¹¶è°ƒç”¨ TxdaModel::init åˆå§‹åŒ–æ¯ä¸ªæ¨¡å‹ çš„åŸºæœ¬å±æ€§ï¼ŒåŒ…æ‹¬æ¡ˆä¾‹ç›®å½•ã€JSON é…ç½®å’Œç¼–è¯‘é€‰é¡¹ã€‚\nTxNN configuration_internlm3.py ä¸­ä¸»è¦è´Ÿè´£æ¨¡å‹ç»“æ„å‚æ•°çš„åˆå§‹åŒ– (æ ¹ hugging face ä¸­çš„ config.json ä¿æŒä¸€è‡´) ä»¥åŠå¼ é‡å¹¶è¡Œçš„è®¾ç½®ã€‚\ninput_output_internlm3.py è´Ÿè´£åœ¨ python ç«¯ä¸ºè¦ä»åç«¯åŠ è½½è¿›æ¥çš„è¾“å…¥å’Œè¾“å‡ºæ³¨å†Œå¼ é‡å’Œå¼€è¾Ÿç©ºé—´ã€‚-\nInputBuffer ä¼šåˆ›å»ºä¸€ä¸ª IntermediateKVCache å®ä¾‹ã€‚è¿™æ˜¯ KV Cache çš„å®é™…å­˜å‚¨ç©ºé—´ï¼Œå¤§å°æ ¹æ®åºåˆ—é•¿åº¦ã€å¤´çš„æ•°é‡é¢„å…ˆåˆ†é…å¥½ã€‚è¿˜ä¼šæ³¨å†Œå„ç§è¾“å…¥ç›¸å…³çš„ç¼“å†²åŒº input_ids: å½“å‰éœ€è¦å¤„ç†çš„è¾“å…¥ token IDã€‚ start_index, seq_len: ç”¨äºç®¡ç†å½“å‰ç”Ÿæˆåºåˆ—çš„ä½ç½®ä¿¡æ¯ã€‚ k_gather_end_indices: ä¸ºæ¯ä¸€å±‚é…ç½® å¯¹åº”çš„ KV cache çš„èµ·å§‹ç´¢å¼•ã€‚ OutputBuffer å’Œ InputBuffer ç±»ä¼¼ï¼Œå®ƒä¹Ÿåˆ›å»ºäº†ä¸€ä¸ª IntermediateKVCache å®ä¾‹ã€‚è¿™ä¸ª Cache ç”¨äºå­˜æ”¾è®¡ç®—å®Œæˆåæ›´æ–°çš„ Key å’Œ Valueï¼Œè¿™äº›æ›´æ–°åçš„å€¼å°†åœ¨ä¸‹ä¸€æ­¥ç”Ÿæˆtokenæ—¶ä½œä¸ºè¾“å…¥ä½¿ç”¨ã€‚\næ³¨å†Œæ‰€æœ‰KV Cacheå±‚: å®ƒç«‹å³å°†æ‰€æœ‰å±‚çš„ KV Cache ç¼“å†²åŒºæ³¨å†Œåˆ°è‡ªå·±çš„ _buffer ä¸­ã€‚ æ³¨å†Œè¾“å‡ºç¼“å†²åŒº: é¢„å…ˆåˆ†é…å¹¶æ³¨å†Œäº†ç”¨äºå­˜æ”¾æœ€ç»ˆç»“æœçš„å†…å­˜ç©ºé—´ï¼š lm_head_reshape_out: ç”¨äºå­˜æ”¾è¯­è¨€æ¨¡å‹æœ€åçš„è¾“å‡ºï¼ˆé€šå¸¸æ˜¯ logitsï¼‰ï¼Œå…¶ç»´åº¦ä¸º (åºåˆ—é•¿åº¦, è¯æ±‡è¡¨å¤§å°)ã€‚ lm_head_argmax_out: ç”¨äºå­˜æ”¾æœ€ç»ˆé¢„æµ‹å‡ºçš„ token IDï¼ˆå¯¹ logits å– argmax åçš„ç»“æœï¼‰ã€‚ é‡Œé¢è´Ÿè´£å®šä¹‰æ¨¡å‹ï¼Œåœ¨ python ç«¯ä¸ºæ•°æ®å¼€è¾Ÿå¥½å†…å­˜ï¼ŒGraphBasedInternlm3ForCausalLM åœ¨åˆå§‹åŒ–æ—¶ï¼Œä¼šåˆ›å»º InputBuffer å’Œ OutputBuffer çš„å®ä¾‹ã€‚å®ƒä¸º tensor_parallel çš„æ¯ä¸€è·¯éƒ½åˆ›å»ºäº†ç¼“å†²åŒºã€‚\nå½“ forward æ–¹æ³•æ¥æ”¶ input_ids. ä¸åœ¨ Python ä¸­æ‰§è¡Œå¤æ‚çš„æ•°å­¦è¿ç®—ã€‚è€Œæ˜¯é€šè¿‡ load_input æŠŠåç«¯ç¼–è¯‘ç”Ÿæˆçš„ bin æ–‡ä»¶æ•°æ®å¡«å……åˆ° InputBuffer ä¸­.\né€šè¿‡ TxDA context æŠŠåŠ è½½å¥½çš„æ•°æ®æ”¾åˆ°ç¡¬ä»¶ä¸Šç„¶å launch kernelå°† InputBuffer å’Œ OutputBuffer çš„å†…å­˜åœ°å€ä¼ é€’ç»™åº•å±‚å¼•æ“ã€‚åº•å±‚å¼•æ“ç›´æ¥ä» InputBuffer æŒ‡å‘çš„å†…å­˜ä¸­è¯»å–è¾“å…¥ï¼Œæ‰§è¡Œé«˜æ•ˆçš„æ¨¡å‹è®¡ç®—ï¼Œç„¶åå°†ç»“æœç›´æ¥å†™å…¥ OutputBuffer æŒ‡å‘çš„å†…å­˜ä¸­ã€‚\nvllm ä¸»è¦åˆ©ç”¨çš„æ˜¯å…¶æ¨ç†æ¡†æ¶ï¼Œåœ¨ LLMEngine é‡Œæ·»åŠ äº†è‡ªå·±çš„ TxNPUExecutor é‡Œé¢åŒ…å«è‡ªå·±çš„ TxNPUWorkerï¼Œå…¶ä¸­åŒ…å« TxNPUCacheEngine å’Œ TxNPUModelRunner.\nTxNPUMModelRunner å®šä¹‰äº†ä¸“é—¨ä»åç«¯ç¼–è¯‘å‡ºçš„ chip_out æ–‡ä»¶å¤¹ä¸­çš„ param.bin æ–‡ä»¶é‡ŒåŠ è½½æ¨¡å‹å‚æ•°åˆ° TxNN çš„å®šä¹‰æ¨¡å‹çš„ ModelLoader. ç„¶åæ¨ç†çš„æ—¶å€™è°ƒç”¨çš„ forward æµç¨‹å¦‚ä¸Šã€‚\n","permalink":"http://localhost:1313/blogs/tx8_inferenceengine/","summary":"TX8 inference engine description.","title":"TX8 Inference Engine"},{"content":"Preliminary 198. House Robber é¢˜ç›®ç½‘å€. åŠ¨æ€è§„åˆ’çš„æ ¸å¿ƒæ˜¯çŠ¶æ€å®šä¹‰å’ŒçŠ¶æ€è½¬ç§»æ–¹ç¨‹ï¼Œå¯¹äºå­é›†å‹å›æº¯æœ‰é€‰/ä¸é€‰ä»¥åŠé€‰å“ªä¸ªè¿™ä¸¤ç§æ€è·¯ï¼Œå¯¹äº DP ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚å¯¹äºæœ¬é¢˜ä»ç¬¬ä¸€ä¸ªæˆ–è€…æœ€åä¸€ä¸ªæˆ¿å­è¿›è¡Œæ€è€ƒæ˜¯æœ€å®¹æ˜“çš„ã€‚å¦‚æœé€‰ï¼Œé‚£ä¹ˆå‰©ä¸‹ n-2 ä¸ªæˆ¿å­ï¼›å¦‚æœä¸é€‰ï¼Œé‚£ä¹ˆå‰©ä¸‹ n-1 ä¸ªæˆ¿å­ã€‚\nè¿™é‡Œä»æœ€åä¸€ä¸ªæˆ¿å­å¼€å§‹ï¼Œå› æ­¤æˆ‘ä»¬çš„å›æº¯ä¸‰é—®å°±æ˜¯\nå½“å‰æ“ä½œ: æšä¸¾ç¬¬ i ä¸ªæˆ¿å­é€‰ä¸é€‰ã€‚ å­é—®é¢˜: ä»å‰ i ä¸ªæˆ¿å­ä¸­å¾—åˆ°çš„æœ€å¤§é‡‘é¢å’Œã€‚ ä¸‹ä¸€ä¸ªå­é—®é¢˜: åˆ†ç±»è®¨è®º: é€‰: ä»å‰ i-1 ä¸ªæˆ¿å­ä¸­å¾—åˆ°çš„æœ€å¤§é‡‘é¢å’Œã€‚ ä¸é€‰: ä»å‰ i-2 ä¸ªæˆ¿å­ä¸­å¾—åˆ°çš„æœ€å¤§é‡‘é¢å’Œã€‚ æˆ‘ä»¬çš„å›æº¯æ¨¡æ¿å¯ä»¥å†™ä½œ dfs(i) = max(dfs(i-1), dfs(i-2) + nums[i]).\nåœ¨å®šä¹‰ DFS æˆ–è€… DP æ•°ç»„çš„å«ä¹‰æ—¶ï¼Œåªèƒ½è¡¨ç¤ºä»ä¸€äº›å…ƒç´ ä¸­ç®—å‡ºçš„ç»“æœï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç»“æœä¸­ç®—å‡ºçš„ç»“æœã€‚æ³¨æ„è¿™é‡Œæ²¡æœ‰æŠŠå¾—åˆ°çš„é‡‘é¢ä½œä¸ºé€’å½’çš„è¾“å…¥å‚æ•°ï¼Œè€Œæ˜¯ä½œä¸ºè¿”å›å€¼ã€‚\nclass Solution { public: int dfs(int i, vector\u0026lt;int\u0026gt;\u0026amp; nums) { if (i \u0026lt; 0) return 0; return max(dfs(i-1, nums), dfs(i-2, nums) + nums[i]); } int rob(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); return dfs(n - 1, nums); } }; ç”±äºå›æº¯çš„æ—¶é—´å¤æ‚åº¦æ˜¯æŒ‡æ•°çº§åˆ«çš„ï¼Œä¸Šè¿°ç®—æ³•ä¼šè¶…æ—¶ã€‚ä»”ç»†è§‚å¯Ÿæœç´¢æ ‘ä¼šå‘ç°ï¼Œç¬¬ä¸€æ¬¡é€‰äº†åä¼šè¿›è¡Œ dfs(2)ï¼Œç¬¬ä¸€æ¬¡ä¸é€‰ç¬¬äºŒæ¬¡ä¹Ÿä¸é€‰åˆä¼šè¿›è¡Œ dfs(2)ï¼Œå¯¼è‡´äº†é‡å¤è®¡ç®—ã€‚ä¼˜åŒ–æ–¹æ³•æ˜¯ç¬¬ä¸€æ¬¡è®¡ç®—çš„æ—¶å€™å¯ä»¥é€šè¿‡ä¸€ä¸ªæ•°ç»„æ¥è®°å½•ç»“æœï¼Œå°†é€’å½’è®¡ç®—çš„ç»“æœä¿ç•™ä¸‹æ¥ï¼Œé‚£ä¹ˆä¸‹æ¬¡é€’å½’åˆ°åŒæ ·å…¥å‚çš„æ—¶å€™ï¼Œå°±ç›´æ¥è¿”å›å…ˆå‰ä¿å­˜çš„ç»“æœã€‚è¿™æ ·æ ‘ä¸­åªæœ‰ n ä¸ªèŠ‚ç‚¹ï¼Œæ—¶é—´å¤æ‚åº¦å¾—åˆ°ä¼˜åŒ–ã€‚\nclass Solution { public: int dfs(int i, vector\u0026lt;int\u0026gt;\u0026amp; nums, vector\u0026lt;int\u0026gt;\u0026amp; cache) { if (i \u0026lt; 0) return 0; if (cache[i] != -1) // find in cache return cache[i]; int res = max(dfs(i-1, nums, cache), dfs(i-2, nums, cache) + nums[i]); cache[i] = res; // reserve result return res; } int rob(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); vector\u0026lt;int\u0026gt; cache(n, -1); return dfs(n - 1, nums, cache); } }; å…³äºæ—¶é—´å¤æ‚åº¦çš„è®¡ç®—æœ‰ä¸€ä¸ªå…¬å¼: çŠ¶æ€ä¸ªæ•° x å•æ¬¡çŠ¶æ€è®¡ç®—æ—¶é—´ã€‚è¿™é‡ŒçŠ¶æ€ä¸ªæ•°æ˜¯ $O(n)$ï¼Œå•è¯çŠ¶æ€è®¡ç®—æ—¶é—´æ˜¯ $O(1)$ï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º $O(n)$. ä½¿ç”¨äº†ä¸€ä¸ª cache æ•°ç»„ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(n)$.\nè§‚å¯Ÿå¯å‘ç°è¿™é‡Œçš„ max è®¡ç®—å‘ç”Ÿåœ¨ dfs è°ƒç”¨ç»“æŸä¹‹åï¼Œä¹Ÿå°±æ˜¯é€’å½’ä¸­å½’çš„è¿‡ç¨‹ã€‚å†æ¬¡è§‚å¯Ÿæœç´¢æ ‘ä¼šå‘ç° dfs(0) å’Œ dfs(1) å½’åˆ° dfs(2)ï¼Œdfs(1) å’Œ dfs(2) å½’åˆ° dfs(3). æ—¢ç„¶çŸ¥é“å“ªäº›ç‚¹ä¼šå½’åˆ°å“ªä¸ªç‚¹ï¼Œå¹²è„†ç›´æ¥å»æ‰é€’å½’ä¸­çš„é€’ï¼Œåªä¿ç•™å½’çš„è¿‡ç¨‹ï¼Œä¹Ÿå°±æ˜¯ç›´æ¥ä»æœ€ä¸‹é¢å‘ä¸Šè®¡ç®—ï¼Œè¿™å°±æ˜¯é€’æ¨ã€‚å…·ä½“æ¥è¯´å°±æ˜¯å°† dfs æ”¹æˆæ•°ç»„ï¼Œé€’å½’æ”¹æˆå¾ªç¯çš„å½¢å¼ï¼Œä½†è¿™æ ·éœ€è¦å¯¹é€’å½’è¾¹ç•Œä¹Ÿå°±æ˜¯ i=0 å’Œ i=1 ç‰¹æ®Šå¤„ç†ï¼Œå¦åˆ™ä¼šå‡ºç°è´Ÿæ•°ä¸‹æ ‡ã€‚\n$$ \\begin{aligned} dfs(i)\u0026=\\max\\left(dfs(i-1),dfs(i-2)+nums[i]\\right)\\\\ f[i]\u0026=\\max\\left(f[i-1],f[i-2]+nums[i]\\right)\\\\ f[i+2]\u0026=\\max\\left(f[i+1],f[i]+nums[i]\\right)\\end{aligned} $$class Solution { public: int rob(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); vector\u0026lt;int\u0026gt; f(n + 2, 0); for (int i = 0; i \u0026lt; nums.size(); i++) { f[i + 2] = max(f[i + 1], f[i] + nums[i]); } return f[n + 1]; } }; ä¸Šè¿°åšæ³•çš„ç©ºé—´å¤æ‚åº¦ä»ä¸º $O(n)$ï¼Œå†è§‚å¯Ÿé€’æ¨å…¬å¼å¯å‘ç°å½“å‰çŠ¶æ€çš„å€¼åªä¾èµ–äºä¸Šä¸€ä¸ªçŠ¶æ€å’Œä¸Šä¸Šä¸ªçŠ¶æ€ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åªä¿ç•™ä¸¤ä¸ªçŠ¶æ€å€¼ï¼Œåœ¨åœ°æ¨è¿‡ç¨‹ä¸­ä¸æ–­æ›´æ–°ã€‚æœ€åè¿”å› f1ï¼Œå› ä¸ºå®ƒæ˜¯æœ€åä¸€æ¬¡ç®—å‡ºçš„ newF.\n$$ \\begin{aligned}\u0026\\text{å½“å‰}=\\max (\\text{ä¸Šä¸€ä¸ª,ä¸Šä¸Šä¸€ä¸ª}+nums[i])\\\\\u0026f_0\\text{ è¡¨ç¤ºä¸Šä¸Šä¸€ä¸ª,}f_1\\text{ è¡¨ç¤ºä¸Šä¸€ä¸ª}\\\\\u0026newF=\\max\\left(f_1,f_0+nums[i]\\right)\\\\\u0026f_0=f_1\\\\\u0026f_1=newF\\end{aligned} $$class Solution { public: int rob(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); int f0 = 0, f1 = 0; for (int i = 0; i \u0026lt; nums.size(); i++) { int newF = max(f1, f0 + nums[i]); f0 = f1; f1 = newF; } return f1; } }; 70. Climbing Stairs é¢˜ç›®ç½‘å€. çˆ¬ n é˜¶æ¥¼æ¢¯çš„æ–¹æ³•æ•°é‡ï¼Œç­‰äº 2 éƒ¨åˆ†ä¹‹å’Œï¼š\nå…ˆçˆ¬ä¸€æ­¥ï¼ŒåŠ ä¸Šåé¢çš„ n-1 é˜¶æ¥¼æ¢¯çˆ¬æ³•ã€‚ å…ˆçˆ¬ä¸¤æ­¥ï¼ŒåŠ ä¸Šåé¢çš„ n-2 é˜¶æ¥¼æ¢¯çˆ¬æ³•ã€‚ å› æ­¤é€’æ¨å…¬å¼æœ‰ f(n) = f(n-1) + f(n-2). åˆå§‹åŒ– f0=0 å¯ä»¥ç†è§£ä¸ºå¼€å§‹ä¸ç”¨çˆ¬å°± 1 ç§æ–¹æ³•ã€‚\nclass Solution { public: int climbStairs(int n) { // çˆ¬åˆ° n-1 é˜¶çš„æ–¹å¼ + çˆ¬åˆ° n-2 é˜¶çš„æ–¹å¼ // f(n) = f(n-1) + f(n-2) int f0 = 0, f1 = 1; for (int i = 1; i \u0026lt;= n; i++) { int newF = f0 + f1; f0 = f1; f1 = newF; } return f1; } }; 746. Min Cost Climbing Stairs é¢˜ç›®ç½‘å€. çˆ¬ n é˜¶æ¥¼æ¢¯çš„æœ€å°èŠ±è´¹ï¼Œç­‰äºä¸‹é¢ 2 ç§æƒ…å†µçš„è¾ƒå°è€…ï¼š\nçˆ¬åˆ° n-1 é˜¶çš„æœ€å°èŠ±è´¹ + cost[n-1]. çˆ¬åˆ° n-2 é˜¶çš„æœ€å°èŠ±è´¹ + cost[n-2]. å› æ­¤é€’æ¨å…¬å¼æœ‰ f(n) = min(f(n-1) + cost[n-1], f(n-2) + cost[n-2]). å› ä¸ºå¯ä»¥ä»ç¬¬ 0 é˜¶æˆ–è€… ç¬¬ 1 é˜¶å¼€å§‹çˆ¬ï¼Œå› æ­¤ åˆå§‹åŒ– f0=f1=0.\nclass Solution { public: int minCostClimbingStairs(vector\u0026lt;int\u0026gt;\u0026amp; cost) { // f(n) = min(f(n-1) + cost[n-1], f(n-2) + cost[n-2]) int f0 = 0, f1 = 0; for (int i = 2; i \u0026lt;= cost.size(); i++) { // nums[n-1] needs climb int newF = min(f1 + cost[i-1], f0 + cost[i-2]); f0 = f1; f1 = newF; } return f1; } }; 213. House Robber II é¢˜ç›®ç½‘å€. æ€è·¯è·Ÿ 198 ä¸€æ ·ï¼Œåªä¸è¿‡è¿™é‡Œæ˜¯å›´æˆä¸€åœˆï¼Œåˆ†æˆå·ç¬¬ä¸€å®¶å’Œå·æœ€åä¸€å®¶è¿›è¡Œé€’æ¨ã€‚\nclass Solution { public: int rob(vector\u0026lt;int\u0026gt;\u0026amp; nums) { if (nums.size() == 1) return nums[0]; int n = nums.size(); int f0 = 0, f1 = 0; int robFirst = 0, robLast = 0; for (int i = 0; i \u0026lt; n - 1; i ++) { robFirst = max(f0 + nums[i], f1); f0 = f1; f1 = robFirst; } f0 = 0; f1 = 0; for (int i = 1; i \u0026lt; n; i ++) { robLast = max(f0 + nums[i], f1); f0 = f1; f1 = robLast; } return max(robFirst, robLast); } }; 740. Delete and Earn é¢˜ç›®ç½‘å€. æ•°ç»„ä¸­çš„æ¯ä¸ªæ•°å­— num éƒ½ä¼šè´¡çŒ®ä¸€å®šçš„ç‚¹æ•°ï¼Œä½†é€‰æ‹© num åï¼Œä¼šå¯¼è‡´ num-1 å’Œ num+1 çš„æ•°å­—æ— æ³•é€‰æ‹©ã€‚è¿™ç§é™åˆ¶ç±»ä¼¼äºâ€œæ‰“å®¶åŠ«èˆâ€é—®é¢˜ä¸­ä¸èƒ½é€‰æ‹©ç›¸é‚»çš„æˆ¿å­ã€‚éœ€è¦å°†é—®é¢˜è½¬åŒ–ä¸ºé€‰æ‹©ä¸€ç»„ä¸ç›¸é‚»çš„æ•°å­— (åœ¨å€¼åŸŸä¸Šä¸ç›¸é‚»)ï¼Œå¹¶æœ€å¤§åŒ–ç‚¹æ•°å’Œã€‚\né¦–å…ˆç»Ÿè®¡æ¯ä¸ªæ•°å­—å‡ºç°çš„é¢‘ç‡ã€‚ä¾‹å¦‚ï¼Œå¯¹äº nums = [3,4,2]ï¼Œå¯ä»¥è®¡ç®—å‡º 2 å‡ºç° 1 æ¬¡ï¼Œ3 å‡ºç° 1 æ¬¡ï¼Œ4 å‡ºç° 1 æ¬¡ã€‚\nå°†æ¯ä¸ªæ•°å­— i çš„ç‚¹æ•°å®šä¹‰ä¸º i * freq[i]ï¼Œå…¶ä¸­ freq[i] æ˜¯æ•°å­— i å‡ºç°çš„æ¬¡æ•°ã€‚è¿™æ ·ï¼Œé—®é¢˜è½¬åŒ–ä¸ºé€‰æ‹©ä¸€ç»„å€¼åŸŸä¸Šä¸ç›¸é‚»çš„æ•°å­—ï¼Œä½¿å¾—æ€»ç‚¹æ•°æœ€å¤§ã€‚\nå‡è®¾æ•°ç»„ä¸­çš„æœ€å¤§å€¼ä¸º maxValï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ä» 0 åˆ° maxVal çš„æ‰€æœ‰æ•°å­— (å³ä½¿æŸäº›æ•°å­—çš„é¢‘ç‡ä¸º 0)ã€‚\nå®šä¹‰çŠ¶æ€ f[i] è¡¨ç¤ºåœ¨å€¼åŸŸ [0, i] ä¸Šé€‰æ‹©æ•°å­—æ‰€èƒ½è·å¾—çš„æœ€å¤§ç‚¹æ•°ï¼Œä¸”æœ€åä¸€ä¸ªé€‰æ‹©çš„æ•°å­—å¯ä»¥æ˜¯ i æˆ–ä¸é€‰ i. å¯¹äºæ¯ä¸ªæ•°å­— iï¼Œæœ‰ä¸¤ç§é€‰æ‹©ï¼š\nä¸é€‰: æœ€å¤§ç‚¹æ•°ä¸º dp[i-1] (å‰ i-1 ä¸ªæ•°å­—çš„æœ€å¤§ç‚¹æ•°)ã€‚ é€‰: è·å¾— i * freq[i] çš„ç‚¹æ•°ï¼Œä½†ä¸èƒ½é€‰ i-1ï¼Œå› æ­¤æœ€å¤§ç‚¹æ•°ä¸º dp[i-2] + i * freq[i]. å› æ­¤æœ‰ f[i] = max(f[i-1], f[i-2] + i * f[i])\nclass Solution { public: int deleteAndEarn(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); int maxVal = ranges::max(nums); vector\u0026lt;int\u0026gt; freq(maxVal + 1, 0); for(int num: nums) freq[num]++; int f0 = 0, f1 = 1 * freq[1]; for(int i = 2; i \u0026lt;= maxVal; i++) { int newF = max(f0 + i * freq[i], f1); f0 = f1; f1 = newF; } return f1; } }; 2466. Count Ways to Build Good Strings é¢˜ç›®ç½‘å€. ç›¸å½“äºä¸€æ¬¡å¯ä»¥çˆ¬ zero ä¸ªå°é˜¶æˆ–è€…ä¸€æ¬¡å¯ä»¥çˆ¬ one ä¸ªå°é˜¶ï¼Œç»Ÿè®¡çˆ¬ [low, high] å†…çš„å°é˜¶ä¸€å…±æœ‰å‡ ç§æ–¹æ³•ã€‚æ³¨æ„æ›´æ–°çš„æ—¶å€™é¿å…æ•°ç»„ä¸‹æ ‡æœªè´Ÿæ•°ã€‚\nclass Solution { public: int countGoodStrings(int low, int high, int zero, int one) { // f[high - one] + f[high - zero] const int MOD = 1000000007; vector\u0026lt;int\u0026gt; f(high + 1, 0); f[0] = 1; int minLen = zero \u0026lt; one ? zero : one; for (int i = minLen; i \u0026lt;= high; i++) { if (i \u0026gt;= zero) { f[i] = (f[i] + f[i - zero]) % MOD; } if (i \u0026gt;= one) { f[i] = (f[i] + f[i - one]) % MOD; } } int ans = 0; for (int i = low; i \u0026lt;= high; i++) ans = (ans + f[i]) % MOD; return ans; } }; 0/1 knapsack Problem 0-1 èƒŒåŒ…:æœ‰ n ä¸ªç‰©å“,ç¬¬ i ä¸ªç‰©å“çš„ä½“ç§¯ä¸º w[i],ä»·å€¼ä¸º v[i]. æ¯ä¸ªç‰©å“è‡³å¤šé€‰ä¸€ä¸ª,æ±‚ä½“ç§¯å’Œä¸è¶…è¿‡ capacity æ—¶çš„æœ€å¤§ä»·å€¼å’Œã€‚\nå½“å‰æ“ä½œ: æšä¸¾ç¬¬ i ä¸ªç‰©å“é€‰æˆ–ä¸é€‰ã€‚é€‰ï¼Œå‰©ä½™å®¹é‡å‡å°‘ w[i]ï¼›ä¸é€‰ï¼Œå‰©ä½™å®¹é‡ä¸å˜ã€‚ å­é—®é¢˜: å‰©ä½™å®¹é‡ä¸º c æ—¶ï¼Œä»å‰ i ä¸ªç‰©å“ä¸­å¾—åˆ°çš„æœ€å¤§ä»·å€¼å’Œã€‚ ä¸‹ä¸€ä¸ªå­é—®é¢˜: åˆ†ç±»è®¨è®º ä¸é€‰: å‰©ä½™å®¹é‡ä¸º c æ—¶ï¼Œä»å‰ i-1 ä¸ªç‰©å“ä¸­å¾—åˆ°çš„æœ€å¤§ä»·å€¼å’Œã€‚ é€‰: å‰©ä½™å®¹é‡ä¸º c - w[i] æ—¶ï¼Œä»å‰ i-1 ä¸ªç‰©å“ä¸­å¾—åˆ°çš„æœ€å¤§ä»·å€¼å’Œã€‚ å› æ­¤é€’å½’æ¨¡å‹ä¸º $dfs(i,c)=\\max\\left(dfs(i-1,c),dfs(i-1,c-w[i])+v[i]\\right)$.\nint dfs(int i, int capacity, vector\u0026lt;int\u0026gt;\u0026amp; weights, vector\u0026lt;int\u0026gt;\u0026amp; values) { if (i \u0026lt; 0) return 0; if (weights[i] \u0026gt; capacity) return dfs(i - 1, capacity); return max(dfs(i - 1, capacity), dfs(i - 1, capacity - weights[i]) + values[i]); } int zeroOneKnapsack(int capacity, vector\u0026lt;int\u0026gt;\u0026amp; weights, vector\u0026lt;int\u0026gt;\u0026amp; values) { int n = weights.size(); return dfs(n - 1, capacity, weights, values); } å’Œä¸Šä¸€èŠ‚ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªæ•°ç»„æ¥è®°å½•é€’å½’è¿‡ç¨‹ä¸­æ¯ä¸ªå­é—®é¢˜çš„è§£ã€‚ç”±äºè¿™é‡Œé€’å½’éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼Œåˆå§‹åŒ–ä¸€ä¸ªäºŒç»´æ•°ç»„ memo[n][capacity + 1] è¡¨ç¤ºåœ¨å‰©ä½™å®¹é‡ capacity ä¸‹é€‰æ‹© i ä¸ªç‰©å“çš„æœ€å¤§ä»·å€¼ã€‚\nint dfs(int i, int capacity, vector\u0026lt;int\u0026gt;\u0026amp; weights, vector\u0026lt;int\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; memo) { if (i \u0026lt; 0) return 0; if (memo[i][capacity] != -1) return memo[i][capacity]; if (weights[i] \u0026gt; capacity) return memo[i][capacity] = dfs(i - 1, capacity, weights, values, memo); return memo[i][capacity] = max(dfs(i - 1, capacity, weights, values, memo), dfs(i - 1, capacity - weights[i], weights, values, memo) + values[i]); } 494. Target Sum é¢˜ç›®ç½‘å€. å‡è®¾æ•°ç»„æ€»å’Œä¸º sï¼Œæ­£æ•°å’Œä¸º pï¼Œè´Ÿæ•°å’Œçš„ç»å¯¹å€¼ä¸º nï¼Œåˆ™ï¼š\np - n = target p + n = s æ¨å¯¼å¾— p = (target + s) / 2. å› æ­¤ï¼Œé—®é¢˜ç­‰ä»·äºåœ¨ nums ä¸­é€‰æ‹©ä¸€äº›æ•°ï¼Œä½¿å…¶å’Œæ°å¥½ä¸º (target + s) / 2. è¿™ç§é€‰æˆ–ä¸é€‰é—®é¢˜æ­£å¥½å¯ä»¥ç”¨ 01 èƒŒåŒ…çš„æ€è·¯è§£å†³ã€‚\nç”±äº p æ˜¯æ­£æ•´æ•° æ‰€ä»¥å¦‚æœ (target + s) / 2 \u0026lt; 0 æˆ–è€… target + s æ˜¯å¥‡æ•°é‚£ä¹ˆè‚¯å®šæ‰¾ä¸åˆ°æ–¹æ¡ˆã€‚æ ¹æ®äº’æ–¥åŸç†ï¼Œæ€»çš„æ–¹æ¡ˆæ•°å¯ä»¥åˆ†æˆé€‰ç¬¬ i ä¸ªæ•°å’Œä¸é€‰ä¸¤ç§æƒ…å†µçš„æ–¹æ¡ˆæ•°ç›®ä¹‹å’Œã€‚\nclass Solution { int dfs(int i, vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { // choose nums[i] as pos or not if (i \u0026lt; 0) return target == 0 ? 1 : 0; if (nums[i] \u0026gt; target) return dfs(i - 1, nums, target); return dfs(i - 1, nums, target) + dfs(i - 1, nums, target - nums[i]); } public: int findTargetSumWays(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { // p: sum of positive nums // n: abs of sum of negative nums // then we have p - n = t p + n = sum(nums) // p = (t + sum(nums)) / 2 int n = nums.size(); int s = accumulate(nums.begin(), nums.end(), 0); target += s; if (target \u0026lt; 0 || target % 2 == 1) return 0; target /= 2; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(n, vector\u0026lt;int\u0026gt;(target + 1, 0)); return dfs(n- 1, nums, target); } }; è®° c = (target + s) / 2ï¼Œç”¨ä¸Šè®°å¿†åŒ–æœç´¢å¹¶ä¸”é¿å…ç´¢å¼•ä¸ºè´Ÿæ•°æˆ‘ä»¬æœ‰. f æ•°ç»„è¡¨ç¤ºå‰ i ä¸ªæ•°ä¸­è¿›è¡Œé€‰æ‹©ä½¿å’Œä¸º c çš„æ–¹æ¡ˆæ•°ç›®ã€‚\n$$ \\begin{aligned} dfs(i,c)\u0026=dfs(i-1,c)+dfs(i-1,c-nums[i])\\\\ f[i][c]\u0026=f[i-1][c]+f[i-1][c-nums[i]]\\\\ f[i+1][c]\u0026=f[i][c]+f[i][c-nums[i]] \\end{aligned} $$int findTargetSumWays(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int n = nums.size(); int s = accumulate(nums.begin(), nums.end(), 0); target += s; if (target \u0026lt; 0 || target % 2 == 1) return 0; target /= 2; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;int\u0026gt;(target + 1, 0)); f[0][0] = 1; for (int i = 0; i \u0026lt; n; i++) { for (int c = 0; c \u0026lt;= target; c++) { if (nums[i] \u0026gt; c) { f[i + 1][c] = f[i][c]; } else { f[i + 1][c] = f[i][c] + f[i][c-nums[i]]; } } } return f[n][target]; } ä»é€’æ¨å…¬å¼å¯ä»¥çœ‹å‡ºæ¯æ¬¡è®¡ç®—å®Œ f[i+1] åå°±ä¸éœ€è¦ç”¨åˆ° f[i] äº†ã€‚ä¹Ÿå°±æ˜¯è¯´æ¯æ—¶æ¯åˆ»åªæœ‰ä¸¤ä¸ªæ•°ç»„çš„å…ƒç´ åœ¨å‚ä¸çŠ¶æ€è½¬ç§»ï¼Œå› æ­¤å¯ä»¥ç”¨ä¸¤ä¸ªæ•°ç»„æ¥å­˜å‚¨çŠ¶æ€ã€‚$f[(i+1)\\%2][c]=f[i\\%2][c]+f[i\\%2][c-nums[i]]$\nint findTargetSumWays(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int n = nums.size(); int s = accumulate(nums.begin(), nums.end(), 0); target += s; if (target \u0026lt; 0 || target % 2 == 1) return 0; target /= 2; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(2, vector\u0026lt;int\u0026gt;(target + 1, 0)); f[0][0] = 1; for (int i = 0; i \u0026lt; n; i++) { for (int c = 0; c \u0026lt;= target; c++) { if (nums[i] \u0026gt; c) { f[(i + 1)%2][c] = f[i%2][c]; } else { f[(i + 1)%2][c] = f[i%2][c] + f[i%2][c-nums[i]]; } } } return f[n%2][target]; } æ›´è¿›ä¸€æ­¥ï¼Œå¯ä»¥åªç”¨ä¸€ä¸ªæ•°ç»„æ¥å­˜å‚¨çŠ¶æ€ã€‚ä½†ç”±äºåé¢çš„çŠ¶æ€å€¼ä¾èµ–äºå‰é¢çš„ï¼Œå› æ­¤æˆ‘ä»¬è¦ä»åå¾€å‰æ›´æ–°çŠ¶æ€ï¼Œé¿å…è¦†ç›–ã€‚ç”±äº nums[i] \u0026gt; c çš„æ—¶å€™æ•°ç»„çš„çŠ¶æ€æ˜¯ä¸å˜çš„ï¼Œå› æ­¤åªç”¨æ›´æ–°ä» target åˆ° nums[i] çš„æƒ…å†µã€‚\nint findTargetSumWays(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int n = nums.size(); int s = accumulate(nums.begin(), nums.end(), 0); target += s; if (target \u0026lt; 0 || target % 2 == 1) return 0; target /= 2; vector\u0026lt;int\u0026gt; f(target + 1, 0); f[0] = 1; for (int i = 0; i \u0026lt; n; i++) for (int c = target; c \u0026gt;= nums[i]; c--) { f[c] = f[c] + f[c-nums[i]]; } return f[target]; } 2915. Length of the Longest Subsequence that Sums to Target é¢˜ç›®ç½‘å€. f è¡¨ç¤ºä»å‰ i ä¸ªæ•°ä¸­è¿›è¡Œé€‰æ‹©ä½¿å¾—å’Œä¸º c çš„å­æ•°ç»„ä¸­æœ€é•¿çš„é•¿åº¦ã€‚é€’å½’çš„è¾¹ç•Œæ¡ä»¶ä¸º i = 0 æ—¶ è‹¥ target = 0 è¡¨ç¤ºèƒ½æ‰¾åˆ°ï¼Œè¿”å› 0 (ç©ºæ•°ç»„é•¿åº¦)ï¼›å¦åˆ™è¿”å› INT_MIN è¡¨ç¤ºæ‰¾ä¸åˆ°ã€‚\nclass Solution { public: int lengthOfLongestSubsequence(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { // f[i][c] = max(f[i-1][c] , f[i-1][c - nums[i]] + 1) // f is max sub seq len in first i nums which sum is c int n = nums.size(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;int\u0026gt;(target + 1, INT_MIN)); f[0][0] = 0; for (int i = 0; i \u0026lt; n; i++) { for (int c = 0; c \u0026lt;= target; c++) { if (nums[i] \u0026gt; c) { f[i+1][c] = f[i][c]; } else { f[i+1][c] = max(f[i][c] , f[i][c - nums[i]] + 1); } } } return f[n][target] \u0026gt; 0 ? f[n][target] : -1; } }; ä»¿ç…§ 0/1 èƒŒåŒ…å¯ä»¥è¿›è¡Œç©ºé—´ä¼˜åŒ–ã€‚\nint lengthOfLongestSubsequence(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int n = nums.size(); vector\u0026lt;int\u0026gt; f(target + 1, INT_MIN); f[0] = 0; for (int i = 0; i \u0026lt; n; i++) { for (int c = target; c \u0026gt;= nums[i]; c--) { f[c] = max(f[c] , f[c - nums[i]] + 1); } } return f[target] \u0026gt; 0 ? f[target] : -1; } 416. Partition Equal Subset Sum é¢˜ç›®ç½‘å€. ç›¸å½“äºåˆ¤æ–­èƒ½å¦é€‰æ‹©å…ƒç´ ä½¿å¾—å’Œç­‰äºæ•´ä¸ªæ•°ç»„ä¹‹å’Œçš„ä¸€åŠã€‚f è¡¨ç¤ºèƒ½å¦ä»å‰ i ä¸ªæ•°ä¸­è¿›è¡Œé€‰æ‹©ä½¿å¾—å’Œä¸º c.\nclass Solution { public: bool canPartition(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); int s = accumulate(nums.begin(), nums.end(), 0); if (s % 2) return false; int target = s / 2; // f[i][c] = f[i-1][c] || f[i-1][c-nums[i]] // f is can select in first i ele which sum is c vector\u0026lt;vector\u0026lt;bool\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;bool\u0026gt;(target + 1, false)); f[0][0] = true; for (int i = 0; i \u0026lt; n; i++) { for (int c = 0; c \u0026lt;= target; c++) { if (nums[i] \u0026gt; c) { f[i+1][c] = f[i][c]; } else { f[i+1][c] = f[i][c] || f[i][c-nums[i]]; } } } return f[n][target]; } }; 2787. Ways to Express an Integer as Sum of Powers é¢˜ç›®ç½‘å€. æœ¬é¢˜ä¹Ÿæ˜¯æ°å¥½è£…æ»¡å‹ 0/1 èƒŒåŒ…çš„æ–¹æ¡ˆæ•°ã€‚éœ€è¦æ³¨æ„çš„æ˜¯è®¡ç®— pow çš„æ—¶å€™ç”±äºä¿®æ”¹äº†æ•°ç»„ç´¢å¼•é¿å…è´Ÿæ•°ï¼Œåº”è¯¥ä¸º pow(i + 1, x).\nclass Solution { public: int numberOfWays(int n, int x) { int MOD = 1\u0026#39;000\u0026#39;000\u0026#39;007; int m = 0; while (pow(m + 1, x) \u0026lt;= n) { m++; } // f[i][c] = f[i-1][c] + f[i-1][c-i^x]; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(m + 2, vector\u0026lt;int\u0026gt;(n + 1, 0)); f[0][0] = 1; for (int i = 0; i \u0026lt;= m; i++) { int val = pow(i + 1, x); // nums[i] is i+1 for (int c = 0; c \u0026lt;= n; c++) { if (val \u0026gt; c) { f[i+1][c] = f[i][c]; } else { f[i+1][c] = f[i][c] + f[i][c-val]; } } } return f[m+1][n] % MOD; } }; ä¸€ç»´ç©ºé—´ä¼˜åŒ–åä»£ç å¦‚ä¸‹ï¼Œä¸€ç»´æ•°ç»„æ±‚æ–¹æ¡ˆæ•°æ˜¯åœ¨ä¸€ç›´ç´¯åŠ çš„ï¼Œæ‰€ä»¥å¾ªç¯å†…è¦å–æ¨¡ã€‚\nint numberOfWays(int n, int x) { int MOD = 1\u0026#39;000\u0026#39;000\u0026#39;007; int m = 0; while (pow(m + 1, x) \u0026lt;= n) { m++; } // f[i][c] = f[i-1][c] + f[i-1][c-i^x]; vector\u0026lt;int\u0026gt; f(n + 1, 0); f[0] = 1; for (int i = 0; i \u0026lt;= m; i++) { int val = pow(i + 1, x); // nums[i] is i+1 for (int c = n; c \u0026gt;= val; c--) { f[i+1][c] = (f[i][c] + f[i][c-val]) % MOD; } } return f[n] % MOD; } Unbounded Knapsack Problem å®Œå…¨èƒŒåŒ…:æœ‰ n ç§ç‰©å“,ç¬¬ i ç§ç‰©å“çš„ä½“ç§¯ä¸º w[i],ä»·å€¼ä¸º v[i]. æ¯ç§ç‰©å“å¯ä»¥é€‰æ— é™æ¬¡,æ±‚ä½“ç§¯å’Œä¸è¶…è¿‡ capacity æ—¶çš„æœ€å¤§ä»·å€¼å’Œã€‚\nå½“å‰æ“ä½œ: æšä¸¾ç¬¬ i ç§ç‰©å“é€‰ä¸€ä¸ªæˆ–ä¸é€‰ã€‚é€‰ï¼Œå‰©ä½™å®¹é‡å‡å°‘ w[i]ï¼›ä¸é€‰ï¼Œå‰©ä½™å®¹é‡ä¸å˜ã€‚ å­é—®é¢˜: å‰©ä½™å®¹é‡ä¸º c æ—¶ï¼Œä»å‰ i ç§ç‰©å“ä¸­å¾—åˆ°çš„æœ€å¤§ä»·å€¼å’Œã€‚ ä¸‹ä¸€ä¸ªå­é—®é¢˜: åˆ†ç±»è®¨è®º ä¸é€‰: å‰©ä½™å®¹é‡ä¸º c æ—¶ï¼Œä»å‰ i-1 ç§ç‰©å“ä¸­å¾—åˆ°çš„æœ€å¤§ä»·å€¼å’Œã€‚ é€‰: å‰©ä½™å®¹é‡ä¸º c - w[i] æ—¶ï¼Œä»å‰ i ç§ç‰©å“ä¸­å¾—åˆ°çš„æœ€å¤§ä»·å€¼å’Œã€‚ ä»£ç å’Œä¹‹å‰å”¯ä¸€çš„åŒºåˆ«å°±æ˜¯é€‰ç¬¬ i ç§ç‰©å“çš„æ—¶å€™é€’å½’åˆ°çš„è¿˜æ˜¯ i.\n322. è¿™å…¶å®æ˜¯å®Œå…¨èƒŒåŒ…çš„ä¸€ç§å˜å½¢ï¼ŒæŠŠç¡¬å¸çš„ä»·å€¼çœ‹æˆ 1ï¼ŒæŠŠæœ€å¤§æ”¹æˆæ±‚æœ€å°å°±å¯ä»¥å¾—åˆ°\n$dfs(i,c)=\\min\\left(dfs(i-1,c),dfs(i-1,c-coins[i])+1\\right)$.\nclass Solution { public: long long dfs(int i, vector\u0026lt;int\u0026gt;\u0026amp; coins, long long amount) { if (i \u0026lt; 0) return amount ? INT_MAX : 0; if (coins[i] \u0026gt; amount) return dfs(i - 1, coins, amount); return min(dfs(i - 1, coins, amount), dfs(i, coins, amount - coins[i]) + 1); } int coinChange(vector\u0026lt;int\u0026gt;\u0026amp; coins, int amount) { int n = coins.size(); long long res = dfs(n - 1, coins, (long long) amount); return res \u0026lt; INT_MAX ? res : -1; } }; ç¿»è¯‘æˆé€’æ¨æƒ…å†µï¼Œä»å›æº¯å¯çŸ¥ï¼Œi = 0 (ç´¢å¼• +1 é˜²æ­¢è´Ÿæ•°) ä¸” amount = 0 æ—¶è¿”å› 0ï¼Œå…¶ä»–æƒ…å†µéƒ½æ˜¯ INT_MAX / 2 (é˜²æ­¢æº¢å‡º).\nint coinChange(vector\u0026lt;int\u0026gt;\u0026amp; coins, int amount) { int n = coins.size(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;int\u0026gt;(amount + 1, INT_MAX / 2)); f[0][0] = 0; for (int i = 0; i \u0026lt; n; i++) { for (int c = 0; c \u0026lt;= amount; c++) { if (coins[i] \u0026gt; c) { f[i + 1][c] = f[i][c]; } else { f[i + 1][c] = min(f[i][c], f[i + 1][c - coins[i]] + 1); } } } return f[n][amount] \u0026lt; INT_MAX / 2 ? f[n][amount] : -1; } å¯¹äºå®Œå…¨èƒŒåŒ…é—®é¢˜ä½¿ç”¨ä¸€ç»´æ•°ç»„æ—¶ï¼Œå¯ä»¥ä»å‰å¾€åè®¡ç®—ï¼Œå› ä¸ºå½“å‰æ›´æ–°çš„çŠ¶æ€æ¥äºä¸Šä¸€æ­¥åŒæ—¶çš„çŠ¶æ€å’Œè¿™ä¸€æ­¥å·²ç»è®¡ç®—å‡ºæ¥çš„çŠ¶æ€ã€‚åŒæ—¶ç”±äº coins[i] \u0026gt; c æ—¶çŠ¶æ€ä¸å˜ï¼Œæˆ‘ä»¬å¯ä»¥ä» c = coins[i] æ—¶å¼€å§‹æ›´æ–°ã€‚\nint coinChange(vector\u0026lt;int\u0026gt;\u0026amp; coins, int amount) { int n = coins.size(); vector\u0026lt;int\u0026gt; f(amount + 1, INT_MAX / 2); f[0] = 0; for (int i = 0; i \u0026lt; n; i++) { for (int c = coins[i]; c \u0026lt;= amount; c++) { f[c] = min(f[c], f[c - coins[i]] + 1); } } return f[amount] \u0026lt; INT_MAX / 2 ? f[amount] : -1; } å¸¸è§å˜å½¢\nè‡³å¤šè£… capacityï¼Œæ±‚æ–¹æ¡ˆæ•°/æœ€å¤§ä»·å€¼å’Œ æ°å¥½è£… capacityï¼Œæ±‚æ–¹æ¡ˆæ•°/æœ€å¤§/æœ€å°ä»·å€¼å’Œ è‡³å°‘è£… capacityï¼Œæ±‚æ–¹æ¡ˆæ•°/æœ€å°ä»·å€¼å’Œ 494 å¯¹äºè‡³å¤šçš„æƒ…å†µï¼Œdfs åœ¨è¾¹ç•Œåˆ¤å®šçš„æ—¶å€™å°±ä¸éœ€è¦åˆ¤æ–­ c æ˜¯å¦ç­‰äº 0 äº† (å› ä¸ºä¸è¦æ±‚è£…æ»¡)ï¼ŒåŒæ—¶åˆå§‹åŒ– f æ•°ç»„éƒ½ä¸º 1 (è‡³å°‘æœ‰ä¸€ç§æ–¹æ¡ˆä¹Ÿå°±æ˜¯ä¸è£…).\nå¯¹äºè‡³å°‘çš„æƒ…å†µ dfs åœ¨è¾¹ç•Œåˆ¤å®šçš„æ—¶å€™æ¡ä»¶åˆ¤æ–­å˜ä¸º c \u0026lt;= 0 (å› ä¸ºå¯ä»¥è¶…å‡º). ä½¿ç”¨é€’æ¨æ›´æ–°çŠ¶æ€çš„æ—¶å€™è¦å¾ªç¯åˆ° c = 0 çš„æƒ…å†µ (å› ä¸ºæ¯ä¸ªç‰©å“éƒ½å¯ä»¥é€‰æˆ–ä¸é€‰ï¼Œæœ‰ 2^n ç§æƒ…å†µï¼Œå› æ­¤è¿™æ ·å¾ªç¯æ¯ä¸ªç‰©å“éƒ½èƒ½è€ƒè™‘åˆ°ä¸¤ç§æƒ…å†µ)ï¼ŒåŒæ—¶æ”¹æˆ f[max(c-nums[i], 0)] è¡¨ç¤ºæŠŠ c \u0026lt;= 0 çš„çŠ¶æ€éƒ½è®°å½•åˆ° f[0] é‡Œã€‚\n518. Coin Change II é¢˜ç›®ç½‘å€. å®Œå…¨èƒŒåŒ…é—®é¢˜ï¼Œå®šä¹‰ dfs(i,c) è¡¨ç¤ºç”¨å‰ i ç§ç¡¬å¸ç»„æˆé‡‘é¢ c çš„æ–¹æ¡ˆæ•°ï¼Œè€ƒè™‘ã€Œé€‰æˆ–ä¸é€‰ã€ï¼Œæœ‰ï¼š\nä¸å†ç»§ç»­é€‰ç¬¬ i ç§ç¡¬å¸: dfs(iâˆ’1,c) ç»§ç»­é€‰ä¸€æšç¬¬ i ç§ç¡¬å¸: dfs(i,câˆ’coins[i]) æ ¹æ®åŠ æ³•åŸç†ï¼ŒäºŒè€…ç›¸åŠ å¾— dfs(i,c) = dfs(iâˆ’1,c) + dfs(i,câˆ’coins[i])\né€’å½’è¾¹ç•Œ: dfs(âˆ’1,0) = 1, dfs(âˆ’1, \u0026gt;0) = 0 (éå†å®Œæ‰€æœ‰ç¡¬å¸ä»ç„¶æ‰¾ä¸åˆ°å’Œä¸º c) é€’å½’å…¥å£: dfs(nâˆ’1,amount) class Solution { public: int change(int amount, vector\u0026lt;int\u0026gt;\u0026amp; coins) { // f[i][c] = f[i-1][c] + f[i][c-coins[i]] int n = coins.size(); vector\u0026lt;vector\u0026lt;unsigned long long\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;unsigned long long\u0026gt;(amount + 1, 0)); f[0][0] = 1; for (int i = 0; i \u0026lt; n; i++) { for (int c = 0; c \u0026lt;= amount; c++) { if (coins[i] \u0026gt; c) { f[i + 1][c] = f[i][c]; } else { f[i + 1][c] = f[i][c] + f[i + 1][c - coins[i]]; } } } return f[n][amount]; } }; ä¸€ç»´æ•°ç»„ç©ºé—´ä¼˜åŒ–ï¼Œå®Œå…¨èƒŒåŒ…é—®é¢˜æ­£å‘æ›´æ–°çŠ¶æ€ã€‚\nint change(int amount, vector\u0026lt;int\u0026gt;\u0026amp; coins) { // f[i][c] = f[i-1][c] + f[i][c-coins[i]] int n = coins.size(); vector\u0026lt;unsigned long long\u0026gt; f(amount + 1, 0); f[0] = 1; for (int i = 0; i \u0026lt; n; i++) { for (int c = coins[i]; c \u0026lt;= amount; c++) { f[c] = f[c] + f[c - coins[i]]; } } return f[amount]; } 279. Perfect Squares é¢˜ç›®ç½‘å€. å®šä¹‰ dfs(i,c) ä¸ºä»å‰ i ä¸ªå®Œå…¨å¹³æ–¹æ•°ä¸­é€‰ä¸€äº›æ•° (å¯ä»¥é‡å¤é€‰)ï¼Œæ»¡è¶³å…ƒç´ å’Œæ°å¥½ç­‰äº cï¼Œæœ€å°‘è¦é€‰çš„æ•°å­—ä¸ªæ•°ã€‚\né€’å½’è¾¹ç•Œ: dfs(0,0) = 0, dfs(0,\u0026gt;0) = INF (è¦å– minï¼Œåˆå§‹åŒ–ä¸ºæœ€å¤§) é€’å½’å…¥å£: dfs(sqrt(n),n) class Solution { public: int numSquares(int n) { // f[i][c] = min(f[i-1][c], f[i][c - i^2] + 1) int m = sqrt(n); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(m + 2, vector\u0026lt;int\u0026gt;(n + 1, INT_MAX / 2)); f[0][0] = 0; for (int i = 0; i \u0026lt;= m; i++) { int val = (i + 1) * (i + 1); for (int c = 0; c \u0026lt;= n; c++) { if (val \u0026gt; c) { f[i + 1][c] = f[i][c]; } else { f[i + 1][c] = min(f[i][c], f[i + 1][c - val] + 1); } } } return f[m+1][n]; } }; ä¸€ç»´æ•°ç»„ç©ºé—´ä¼˜åŒ–\nint numSquares(int n) { // f[i][c] = min(f[i-1][c], f[i][c - i^2] + 1) int m = sqrt(n); vector\u0026lt;int\u0026gt; f(n + 1, INT_MAX / 2); f[0] = 0; for (int i = 0; i \u0026lt;= m; i++) { int val = (i + 1) * (i + 1); for (int c = val; c \u0026lt;= n; c++) { f[c] = min(f[c], f[c - val] + 1); } } return f[n]; } Linear DP 1143. Longest Common Subsequence é¢˜ç›®ç½‘å€. åœ¨é»˜è®¤æƒ…å†µä¸‹å­ä¸²å’Œå­æ•°ç»„è¦æ±‚è¿ç»­ï¼Œå­åºåˆ—ä¸ä¸€å®šè¿ç»­ã€‚å…¬å…±å­åºåˆ—åˆ™ä¸ºä¸¤ä¸ªå­—ç¬¦ä¸²ä¸­éƒ½æœ‰çš„å­åºåˆ—ã€‚\nè®¾ä¸¤ä¸ªå­—ç¬¦ä¸²åˆ†åˆ«ä¸º s å’Œ tï¼Œé•¿åº¦åˆ†åˆ«ä¸º m å’Œ n. å­åºåˆ—çš„æœ¬è´¨å°±æ˜¯é€‰æˆ–ä¸é€‰ï¼Œè€ƒè™‘æœ€åä¸€å¯¹å­—æ¯ï¼Œä¸¤ä¸¤ç»„åˆå°±æœ‰å››ç§æƒ…å†µã€‚\né€‰x ä¸” é€‰y xå¾…å®š ä¸” ä¸é€‰y ä¸é€‰x ä¸” yå¾…å®š ä¸é€‰x ä¸” ä¸é€‰y ç”±æ­¤å¯ä»¥å¾—åˆ°æˆ‘ä»¬çš„å›æº¯ä¸‰é—®\nå½“å‰æ“ä½œ: è€ƒè™‘ s[i] å’Œ t[j] é€‰æˆ–ä¸é€‰ã€‚ å­é—®é¢˜: s å‰ i ä¸ªå­—æ¯å’Œ t å‰ j ä¸ªå­—æ¯çš„ LCS é•¿åº¦ã€‚ ä¸‹ä¸€ä¸ªå­é—®é¢˜: æ ¹æ®é€‰æ‹©æƒ…å†µè¿›è¡Œåˆ†ç±»è®¨è®º: s å‰ i-1 ä¸ªå­—æ¯å’Œ t å‰ j-1 ä¸ªå­—æ¯çš„ LCS é•¿åº¦ã€‚ s å‰ i-1 ä¸ªå­—æ¯å’Œ t å‰ j ä¸ªå­—æ¯çš„ LCS é•¿åº¦ã€‚ s å‰ i ä¸ªå­—æ¯å’Œ t å‰ j-1 ä¸ªå­—æ¯çš„ LCS é•¿åº¦ã€‚ æ³¨æ„è¿™é‡Œéƒ½é€‰ (å½“ç„¶åªæœ‰ s[i]==t[j] æ—¶æ‰èƒ½éƒ½é€‰) æˆ–è€…éƒ½ä¸é€‰çš„ä¸‹ä¸€ä¸ªå­é—®é¢˜æ˜¯ä¸€æ ·çš„ (å¹¶ä¸”é€‰è‚¯å®šæ¯”ä¸é€‰å¥½)ï¼Œéƒ½å¯¹åº”ç¬¬ä¸€ç§æƒ…å†µã€‚å› æ­¤å¾—åˆ°å›æº¯å…¬å¼å¦‚ä¸‹\n$$ \\begin{aligned} \u0026dfs(i,j)=\\begin{cases} \\max (dfs(i-1,j), dfs(i,j-1), dfs(i-1,j-1)+1)\u0026s[i]=t[j] \\\\ \\max dfs(i-1,j),dfs(i,j-1),dfs(i-1,j-1)\u0026s[i]\\neq t[j] \\end{cases} \\\\ \\implies \u0026dfs(i,j)=\\max\\left(dfs(i-1,j),dfs(i,j-1),dfs(i-1,j-1)+(s[i]= t[j])\\right) \\end{aligned} $$è¿™é‡Œæœ‰ä¸¤ä¸ªä¸èƒ½å¿½ç•¥çš„é—®é¢˜\ns[i] == t[j] æ—¶å€™éœ€è¦è€ƒè™‘ dfs(i-1, j) å’Œ dfs(i, j-1) ä¹Ÿå°±æ˜¯åªé€‰ä¸€ä¸ªçš„æƒ…å†µå—ï¼Ÿ dfs(i-1, j) å’Œ dfs(i, j-1) æ˜¯ä¸è€ƒè™‘å½“å‰å­—ç¬¦ç›¸ç­‰æ—¶å€™å¾—åˆ°çš„ LCS é•¿åº¦ï¼Œ\ns[i] != t[j] æ—¶å€™éœ€è¦è€ƒè™‘ dfs(i-1, j-1) å°±æ˜¯ä¸¤ä¸ªéƒ½ä¸é€‰çš„æƒ…å†µå—ï¼Ÿ æ ¹æ®ä¸‹é¢å¼å­å¯ä»¥å‘ç°ï¼Œå¦‚æœè¿™æ¬¡é€‰æ‹© s[i] é‚£ä¹ˆä¸‹ä¸€æ¬¡é€‰æ‹© t[j] å°±é€’å½’åˆ° dfs(i-1, j-1)ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸¤ä¸ªéƒ½ä¸é€‰çš„æƒ…å†µå·²ç»åŒ…å«åœ¨ä¹‹é€‰ä¸€ä¸ªçš„æƒ…å†µé‡Œé¢äº†ã€‚ $$ dfs(i,j){\\operatorname*{\\longrightarrow}}dfs(i-1,j){\\operatorname*{\\longrightarrow}}dfs(i-1,j-1) $$æ‰€ä»¥æœ€ç»ˆå…¬å¼å¯ä»¥ç®€åŒ–ä¸º\n$$ dfs(i,j)=\\begin{cases}dfs(i-1,j-1)+1\u0026s[i]=t[j]\\\\\\max\\left(dfs(i-1,j),dfs(i,j-1)\\right)\u0026s[i]\\neq t[j]\u0026\\end{cases} $$class Solution { public: int dfs(int i, int j, string text1, string text2) { if (i \u0026lt; 0 || j \u0026lt; 0) return 0; if (text1[i] == text2[j]) return dfs(i - 1, j - 1, text1, text2) + 1; return max(dfs(i - 1, j, text1, text2), dfs(i, j - 1, text1, text2)); } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); return dfs(n - 1, m - 1, text1, text2); } }; ä¹Ÿå¯ä»¥ç”¨ä¸€ä¸ªäºŒç»´æ•°ç»„ç¿»è¯‘æˆé€’æ¨å½¢å¼ã€‚\nint longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;int\u0026gt;(m + 1, 0)); for (int i = 0; i \u0026lt; n; i++) { for (int j = 0; j \u0026lt; m; j++) { if (text1[i] == text2[j]){ f[i + 1][j + 1] = f[i][j] + 1; } else { f[i + 1][j + 1] = max(f[i][j + 1], f[i + 1][j]); } } } return f[n][m]; } è¿›ä¸€æ­¥å¯ä»¥ç”¨ä¸€ç»´æ•°ç»„è¿›è¡Œè½¬æ¢ã€‚æœ¬é¢˜ f[i+1][j+1] éœ€è¦ä» f[i+1][j] è½¬ç§»è¿‡æ¥ï¼Œè¿™åªèƒ½æ­£åºæšä¸¾ j. å€’åºæšä¸¾çš„è¯ï¼Œf[i+1][j] è¿˜æ²¡æœ‰è®¡ç®—å‡ºæ¥ã€‚åŒæ—¶è¦ä¿ç•™ä¸Šä¸€æ¬¡ f[i][j+1] ä¹Ÿå°±æ˜¯æœ¬è½® f[i][j] çš„çŠ¶æ€ï¼Œå› ä¸ºæ­£åºæ›´æ–°çš„æ—¶å€™å·²ç»è¢«è¦†ç›–ã€‚\nint longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); vector\u0026lt;int\u0026gt; f(m + 1, 0); for (int i = 0; i \u0026lt; n; i++) { int pre = f[0]; // last j + 1 for (int j = 0; j \u0026lt; m; j++) { int cur = f[j+1]; if (text1[i] == text2[j]){ f[j + 1] = pre + 1; } else { f[j + 1] = max(f[j + 1], f[j]); } pre = cur; } } return f[m]; } 72. Edit Distance é¢˜ç›®ç½‘å€. è¿™é¢˜éœ€è¦æ€è·¯è½¬æ¢ä¸€ä¸‹ï¼Œdfs(i, j) è¡¨ç¤º s å‰ i ä¸ªå­—æ¯å’Œ t å‰ j ä¸ªå­—æ¯å®ŒæˆåŒ¹é…æ‰€éœ€è¦çš„æœ€å°æ“ä½œæ•°ã€‚å¦‚æœ s[i] != t[j] ä¸‹é¢ä¸‰ç§æ“ä½œåˆ†åˆ«ç›¸å½“äº\næ’å…¥: è¦è¿›è¡ŒåŒ¹é…é‚£æ’å…¥çš„è‚¯å®šæ—¶å’Œ t[j] ä¸€æ ·çš„å­—æ¯ï¼Œä¹Ÿå°±ç›¸å½“äºæŠŠ t[j] ç»™æŠ¹å»ï¼Œå› æ­¤é€’å½’åˆ° dfs(i, j-1). åˆ é™¤: é€’å½’åˆ° dfs(j-1, j). æ›¿æ¢: ç›¸å½“äºä¸¤è¾¹éƒ½è¿›è¡ŒæŠ¹å»ï¼Œé€’å½’åˆ° dfs(i-1, j-1). å› æ­¤æˆ‘ä»¬çš„å›æº¯å…¬å¼ä¸º\n$$ dfs(i,j)=\\begin{cases}dfs(i-1,j-1)\u0026s[i]=t[j]\\\\\\min{\\left(dfs(i,j-1),dfs(i-1,j),dfs(i-1,j-1)\\right)+1}\u0026s[i]\\neq t[j]\\end{cases} $$class Solution { public: int dfs(int i, int j, string word1, string word2) { // surplus chars need to be deleted if (i \u0026lt; 0) return j + 1; // 0 - j have j+1 chars if (j \u0026lt; 0) return i + 1; if (word1[i] == word2[j]) // no need operation return dfs(i - 1, j - 1, word1, word2); return min({dfs(i, j-1, word1, word2), // insert dfs(i-1, j, word1, word2), // erase dfs(i-1, j-1, word1, word2)}) // substitute + 1; } int minDistance(string word1, string word2) { int n = word1.size(); int m = word2.size(); return dfs(n-1, m-1, word1, word2); } }; åŒæ ·å¯ä»¥ç¿»è¯‘æˆé€’æ¨ï¼Œæ³¨æ„è¾¹ç•Œæ¡ä»¶çš„ç¿»è¯‘ã€‚\nint minDistance(string word1, string word2) { int n = word1.size(); int m = word2.size(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;int\u0026gt;(m + 1, 0)); for (int j = 0; j \u0026lt; m; j++) f[0][j + 1] = j + 1; for (int i = 0; i \u0026lt; n; i++) f[i + 1][0] = i + 1; for (int i = 0; i \u0026lt; n; i++) { for (int j = 0; j \u0026lt; m; j++) { if (word1[i] == word2[j]) { f[i + 1][j + 1] = f[i][j]; } else { f[i + 1][j + 1] = min({f[i + 1][j], f[i][j + 1], f[i][j]}) + 1; } } } return f[n][m]; } ç”¨ä¸€ç»´æ•°ç»„è¿›è¡Œç©ºé—´ä¼˜åŒ–çš„æ—¶å€™ï¼Œæ³¨æ„ä¿ç•™ä¸Šä¸€çŠ¶æ€ i çš„å‰ä¸€ä¸ªå€¼å¹¶ä¸”æ›´æ–°å½“å‰ i+1 çŠ¶æ€çš„è¾¹ç•Œæ¡ä»¶ã€‚\nint minDistance(string word1, string word2) { int n = word1.size(); int m = word2.size(); vector\u0026lt;int\u0026gt; f(m + 1, 0); for (int j = 0; j \u0026lt; m; j++) f[j + 1] = j + 1; for (int i = 0; i \u0026lt; n; i++) { int pre = f[0]; // last f[j+1] f[0] = i + 1; // cur f[i+1] = i + 1 for (int j = 0; j \u0026lt; m; j++) { int cur = f[j + 1]; if (word1[i] == word2[j]) { f[j + 1] = pre; } else { f[j + 1] = min({f[j], f[j + 1], pre}) + 1; } pre = cur; } } return f[m]; } 583. Delete Operation for Two Strings é¢˜ç›®ç½‘å€. è¾¹ç•Œæ¡ä»¶: å’Œä¸Šä¸€é¢˜ä¸€æ ·ï¼Œå½“æœ‰ä¸€ä¸ªå­—ç¬¦ä¸²éå†å®Œçš„æ—¶å€™ï¼Œå¦ä¸€ä¸ªå­—ç¬¦ä¸²åº”è¯¥å…¨éƒ¨åˆ é™¤ã€‚ é€’å½’æ¡ä»¶: s[i] != t[j] ç”±äºä¸€æ¬¡åªèƒ½åˆ é™¤ä¸€ä¸ªå­—ç¬¦ï¼Œæ‰€ä»¥å‰©ä½™æ­¥æ•°ä¸ºåˆ†åˆ«åˆ é™¤ä¸¤è€…çš„æœ€å°å€¼å†åŠ ä¸Šå½“å‰åˆ é™¤æ“ä½œçš„ä¸€æ¬¡ min(dfs(i-1, j), dfs(i, j-1)) + 1. ç›¸ç­‰æ—¶åˆ™ä¸ç”¨åˆ é™¤ï¼Œå¾€ä¸‹é€’å½’ä¸€æ¬¡ã€‚\nclass Solution { public: int minDistance(string word1, string word2) { // s[i] != t[j] min(dfs(i-1, j), dfs(i, j-1)) + 1 // = dfs(i-1, j-1) // i = 0 return j+1; j = 0 return i + 1 int n = word1.size(); int m = word2.size(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;int\u0026gt;(m + 1, 0)); for (int j = 0; j \u0026lt; m; j++) f[0][j + 1] = j + 1; for (int i = 0; i \u0026lt; n; i++) { f[i + 1][0] = i + 1; for (int j = 0; j \u0026lt; m; j++) { if (word1[i] == word2[j]) { f[i + 1][j + 1] = f[i][j]; } else { f[i + 1][j + 1] = min(f[i + 1][j], f[i][j + 1]) + 1; } } } return f[n][m]; } }; è½¬å˜æˆä¸€ç»´æ•°ç»„çš„æ€è·¯ä¸ä¸Šé¢˜ä¸€æ ·ï¼Œæ—¶åˆ»è®°ä½è¦å­˜å‚¨ f[i][j] ä¹Ÿå°±æ˜¯å·¦ä¸Šè§’çš„å€¼ï¼Œå› ä¸ºåœ¨æœ¬æ¬¡æ­£åºæ›´æ–°ä¸­å·²ç»è¢«è¦†ç›–ã€‚\nint minDistance(string word1, string word2) { int n = word1.size(); int m = word2.size(); vector\u0026lt;int\u0026gt; f(m + 1, 0); for (int j = 0; j \u0026lt; m; j++) f[j + 1] = j + 1; for (int i = 0; i \u0026lt; n; i++) { int pre = f[0]; // last f[j+1] f[0] = i + 1; for (int j = 0; j \u0026lt; m; j++) { int cur = f[j + 1]; if (word1[i] == word2[j]) { f[j + 1] = pre; } else { f[j + 1] = min(f[j], f[j + 1]) + 1; } pre = cur; } } return f[m]; } 712. Minimum ASCII Delete Sum for Two Strings é¢˜ç›®ç½‘å€. ç›´æ¥å¥—ç”¨ä¸Šä¸€é¢˜æ¨¡æ¿ï¼Œåªä¸è¿‡è¿™é¢˜åˆ é™¤çš„ä»£ä»·å˜æˆäº†å­—æ¯å¯¹åº”çš„äºŒ ASCII å€¼è€Œä¸æ˜¯æ¬¡æ•° 1.\nclass Solution { public: int minimumDeleteSum(string s1, string s2) { // f[i][j] = min(f[i][j-1] + s2[j], f[i-1][j] + s1[i]) int n = s1.size(); int m = s2.size(); vector\u0026lt;int\u0026gt; f(m + 1, 0); for (int j = 0; j \u0026lt; m; j++) f[j + 1] = f[j] + static_cast\u0026lt;int\u0026gt;(s2[j]); for (int i = 0; i \u0026lt; n; i++) { int pre = f[0]; // last f[j+1] f[0] += static_cast\u0026lt;int\u0026gt;(s1[i]); for (int j = 0; j \u0026lt; m; j++) { int cur = f[j + 1]; if (s1[i] == s2[j]) { f[j + 1] = pre; } else { f[j + 1] = min(f[j] + static_cast\u0026lt;int\u0026gt;(s2[j]), f[j + 1] + static_cast\u0026lt;int\u0026gt;(s1[i])); } pre = cur; } } return f[m]; } }; 97. Interleaving String é¢˜ç›®ç½‘å€. é¦–å…ˆè¦æ˜ç¡®å¦‚æœ s1 é•¿åº¦å’Œ s2 é•¿åº¦ä¹‹å’Œä¸ç­‰äº s3 é•¿åº¦ï¼Œé‚£ä¹ˆè‚¯å®šä¸å¯èƒ½æ‹¼æˆåŠŸã€‚ dfs(i, j) è¡¨ç¤º s1 å‰ i ä¸ªå­—æ¯å’Œ s2 å‰ j ä¸ªå­—æ¯èƒ½å¦å’Œ s3 å‰ i+j ä¸ªå­—æ¯åŒ¹é…ä¸Šã€‚å› æ­¤è¦åŒ¹é…çš„ s3 ç´¢å¼•ä¸º k = i+j-1.\né€’å½’è¾¹ç•Œ: i \u0026lt; 0 å¹¶ä¸” j \u0026lt; 0 è¯´æ˜åˆšèƒ½æ‹¼æˆåŠŸã€‚ i \u0026lt; 0 å¹¶ä¸” s2[0]-s2[j] å’Œ s3[0]-s3[j] å…¨éƒ¨ç›¸ç­‰è¯´æ˜èƒ½æˆåŠŸã€‚ j \u0026lt; 0 å¹¶ä¸” s1[0]-s1[i] å’Œ s3[0]-s3[i] å…¨éƒ¨ç›¸ç­‰è¯´æ˜èƒ½æˆåŠŸã€‚ å›æº¯æ¡ä»¶: å½“å‰éƒ½èƒ½åŒ¹é…ä¸Š s1[i] == s3[k] \u0026amp;\u0026amp; s2[j] == s3[k]ï¼Œéšä¾¿é€‰ä¸€ä¸ªè¿›è¡ŒåŒ¹é…ï¼Œå‰©ä¸‹çš„æœ‰èƒ½åŒ¹é…ä¸Šå°±æˆåŠŸ dfs(i-1, j, k-1) || dfs(i, j-1, k-1). å½“å‰åªæœ‰ä¸€ä¸ªåŒ¹é…ä¸Šå°±é€‰å®ƒ. å½“å‰ä¸¤è€…éƒ½åŒ¹é…ä¸ä¸Šï¼Œç”±äºé•¿åº¦åŠ èµ·æ¥ç›¸ç­‰ï¼Œé‚£ä¹ˆè‚¯å®šåŒ¹é…ä¸ä¸Šï¼Œä¸ç”¨å›æº¯äº†ï¼Œç›´æ¥è¿”å› false. æ‰€ä»¥é€»è¾‘å¯ä»¥ç®€åŒ–ä¸º s1 åŒ¹é…ä¸Šæ—¶é€’å½’æˆåŠŸ æˆ–è€… s2 åŒ¹é…ä¸Šæ—¶é€’å½’æˆåŠŸã€‚\nå› æ­¤è½¬æ¢æˆé€’æ¨ï¼Œåˆå§‹åŒ–çŠ¶æ€æ•°ç»„çš„æ—¶å€™ã€‚æ£€æŸ¥ i=0 è¾¹ç•Œæ¡ä»¶ä¸º å‰é¢çš„éƒ½åŒ¹é…ä¸Šä¸”å½“å‰å­—ç¬¦èƒ½åŒ¹é…ä¸Šã€‚j=0 æ—¶çš„è¾¹ç•Œæ¡ä»¶ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚å‰©ä¸‹çš„å°±æ˜¯ç›´æ¥æŠ„ dfs.\nclass Solution { public: bool isInterleave(string s1, string s2, string s3) { int n = s1.size(), m = s2.size(), l = s3.size(); if (n + m != l) return false; // i \u0026lt; 0 \u0026amp;\u0026amp; j \u0026lt; 0: if k \u0026lt; 0 true, else false // i \u0026lt; 0: while(s2[j--]==s3[j--]) return j==0; // j \u0026lt; 0: while(s1[i--]==s3[i--]) return i==0; // s1[i] == s3[k] \u0026amp;\u0026amp; s2[j] == s3[k] return dfs(i-1, j, k-1) || dfs(i, j-1, k-1) // == != return dfs(i-1, j, k-1) // != == return dfs(i, j-1, k-1) // != != return false vector\u0026lt;vector\u0026lt;bool\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;bool\u0026gt;(m + 1, false)); f[0][0] = true; for (int j = 0; j \u0026lt; m; j++) { // previous are all equal and current is equal f[0][j+1] = f[0][j] \u0026amp;\u0026amp; (s2[j] == s3[j]); } for (int i = 0; i \u0026lt; n; i++) { f[i+1][0] = f[i][0] \u0026amp;\u0026amp; (s1[i] == s3[i]); for (int j = 0; j \u0026lt; m; j++) { int k = i + j + 1; f[i+1][j+1] = (s1[i] == s3[k] \u0026amp;\u0026amp; f[i][j+1]) || (s2[j] == s3[k] \u0026amp;\u0026amp; f[i+1][j]); } } return f[n][m]; } }; ä¼˜åŒ–æˆä¸€ç»´æ•°ç»„ï¼Œè¿™é‡Œè§‚å¯Ÿåˆ°æ›´æ–°çŠ¶æ€çš„æ—¶å€™æ²¡æœ‰ç”¨åˆ° dfs(i-1, j-1) ä¹Ÿå°±ä¸éœ€è¦è¿›è¡Œä¿å­˜ã€‚\nclass Solution { public: bool isInterleave(string s1, string s2, string s3) { int n = s1.size(), m = s2.size(), l = s3.size(); if (n + m != l) return false; vector\u0026lt;bool\u0026gt; f(m + 1, false); f[0] = true; for (int j = 0; j \u0026lt; m; j++) { // previous are all equal and current is equal f[j+1] = f[j] \u0026amp;\u0026amp; (s2[j] == s3[j]); } for (int i = 0; i \u0026lt; n; i++) { f[0] = f[0] \u0026amp;\u0026amp; (s1[i] == s3[i]); for (int j = 0; j \u0026lt; m; j++) { int k = i + j + 1; f[j+1] = (f[j+1] \u0026amp;\u0026amp; s1[i] == s3[k]) || (f[j] \u0026amp;\u0026amp; s2[j] == s3[k]); } } return f[m]; } }; 1458. Max Dot Product of Two Subsequences é¢˜ç›®ç½‘å€. dfs(i,j) è¡¨ç¤ºï¼šnums1 çš„å‰ i ä¸ªå…ƒç´ å’Œ nums2 çš„å‰ j ä¸ªå…ƒç´ æ‰€èƒ½æ„æˆçš„æœ€å¤§ç‚¹ç§¯ã€‚\nè¾¹ç•Œæ¡ä»¶: æˆ‘ä»¬éœ€è¦è®©é€’å½’å‡½æ•°çŸ¥é“ä¸€ä¸ªè‡³å…³é‡è¦çš„ä¿¡æ¯ï¼šâ€œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬æ˜¯å¦å·²ç»é€‰æ‹©è¿‡è‡³å°‘ä¸€å¯¹å…ƒç´ ï¼Ÿâ€ ä¸ºæ­¤ï¼Œæˆ‘ä»¬è¦ç»™å‡½æ•°å¢åŠ ä¸€ä¸ªçŠ¶æ€ dfs(i, j, has_taken):\nhas_taken == trueï¼šè¯´æ˜æˆ‘ä»¬å·²ç»æˆåŠŸæ„æˆäº†ä¸€ä¸ªéç©ºçš„å­åºåˆ—ï¼Œé€’å½’èµ°åˆ°äº†å°½å¤´ã€‚åç»­ä¸å¯èƒ½å†äº§ç”Ÿä»»ä½•ç‚¹ç§¯äº†ã€‚ æ­¤æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥è¿”å› 0ï¼Œå› ä¸ºå®ƒå¯¹ä¹‹å‰çš„ç‚¹ç§¯æ€»å’Œæ²¡æœ‰è´¡çŒ®ï¼Œä¹Ÿä¸ä¼šäº§ç”Ÿå½±å“ã€‚ has_taken == falseï¼šè¯´æ˜é€’å½’èµ°åˆ°äº†å°½å¤´ï¼Œä½†ä¸€æ¬¡å…ƒç´ é…å¯¹éƒ½æ²¡æœ‰é€‰æ‹©è¿‡ã€‚æ ¹æ®é¢˜æ„ï¼Œå­åºåˆ—å¿…é¡»æ˜¯éç©ºçš„ï¼Œæ‰€ä»¥è¿™æ¡â€œå…¨ç¨‹è·³è¿‡â€çš„è·¯å¾„æ˜¯æ— æ•ˆè·¯å¾„ã€‚ä¸ºäº†åœ¨ max æ¯”è¾ƒä¸­æ·˜æ±°æ‰è¿™æ¡æ— æ•ˆè·¯å¾„ï¼Œæˆ‘ä»¬å¿…é¡»è¿”å›ä¸€ä¸ªæå°å€¼ (æ¯”å¦‚ -Infinity æˆ– C++ é‡Œçš„ INT_MIN)ã€‚è¿™æ ·ä»»ä½•ä¸€ä¸ªæœ‰æ•ˆçš„ç‚¹ç§¯ (å“ªæ€•æ˜¯è´Ÿæ•°)éƒ½ä¼šæ¯”å®ƒå¤§ã€‚ å›æº¯è¿‡ç¨‹: é€’å½’åˆ° dfs(i, j) æ—¶æˆ‘ä»¬è€ƒè™‘ nums1[i-1] å’Œ nums2[j-1] è¿™ä¸¤ä¸ªå…ƒç´ ã€‚æˆ‘ä»¬æœ‰ä»¥ä¸‹å‡ ç§é€‰æ‹©ï¼š\nä¸ä½¿ç”¨ nums1[i-1]ï¼šé‚£ä¹ˆæœ€å¤§ç‚¹ç§¯å°±ç­‰äºåªè€ƒè™‘ nums1 å‰ i-1 ä¸ªå…ƒç´ å’Œ nums2 å‰ j ä¸ªå…ƒç´ çš„ç»“æœï¼Œå³ dfs(i-1, j). ä¸ä½¿ç”¨ nums2[j-1]ï¼šåŒç†ï¼Œç»“æœä¸º dfs(i, j-1). åŒæ—¶ä½¿ç”¨ nums1[i-1] å’Œ nums2[j-1]ï¼Œå®ƒä»¬çš„ç‚¹ç§¯æ˜¯ product = nums1[i-1] * nums2[j-1]. ç»§ç»­é€’å½’å¦‚æœ dfs(i-1, j-1) å¾—åˆ°çš„å‰©ä¸‹å­åºåˆ—çš„æœ€å¤§ç‚¹ç§¯æ˜¯ä¸€ä¸ªè´Ÿæ•° (æ¯”å¦‚ï¼Œæˆ‘ä»¬å®æ„¿ä¸è¦å®ƒï¼Œè€Œæ˜¯åªç”¨ product è‡ªå·±ã€‚è¿™ä¸ªå†³ç­–å¯ä»¥ç”¨ product + max(dfs(i-1, j-1), 0) æ¥å·§å¦™åœ°å®ç°ã€‚ class Solution { public: int maxDotProduct(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2) { // i \u0026lt; 0 || j \u0026lt; 0 return -inf // i not j: dfs(i-1, j) // j not i: dfs(i, j-1) // not i not j: dfs(i-1, j-1) // in the situation of i not j --\u0026gt; j not j // i and j : nums1[i]*nums2[j] + max(dfs(i-1, j-1), 0); // max in all int n = nums1.size(); int m = nums2.size(); vector\u0026lt;vector\u0026lt;long long\u0026gt;\u0026gt; f(n + 1, vector\u0026lt;long long\u0026gt;(m + 1, -1e18)); for (int i = 0; i \u0026lt; n; i++) { for (int j = 0; j \u0026lt; m; j++) { long long product = nums1[i] * nums2[j]; f[i + 1][j + 1] = max({f[i][j+1], f[i+1][j], product + max(f[i][j], 0LL)}); } } return f[n][m]; } }; ä¸€ç»´æ•°ç»„ç©ºé—´ä¼˜åŒ–å\nint maxDotProduct(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2) { int n = nums1.size(); int m = nums2.size(); vector\u0026lt;long long\u0026gt; f(m + 1, -1e18); for (int i = 0; i \u0026lt; n; i++) { long long pre = f[0]; for (int j = 0; j \u0026lt; m; j++) { long long cur = f[j + 1]; long long product = nums1[i] * nums2[j]; f[j + 1] = max({f[j+1], f[j], product + max(pre, 0LL)}); pre = cur; } } return f[m]; } 300. Longest Increasing Subsequence é¢˜ç›®ç½‘å€. æœ€é•¿é€’å¢å­åºåˆ— (Longest Increasing Subsequence, LIS) å±äºå­é›†å‹å›æº¯ï¼Œæœ‰ä¸¤ä¸ªæ€è·¯ã€‚\né€‰æˆ–ä¸é€‰: ä¸ºäº†æ¯”è¾ƒå¤§å°ï¼Œéœ€è¦çŸ¥é“ä¸Šä¸€ä¸ªé€‰çš„æ•°å­—ã€‚ æšä¸¾é€‰å“ªä¸ª: æ¯”è¾ƒå½“å‰é€‰çš„æ•°å­—å’Œä¸‹ä¸€ä¸ªé€‰çš„æ•°å­—ï¼Œåªç”¨å½“å‰ä¸‹æ ‡è¿™ä¸€ä¸ªå‚æ•°ã€‚ é—®ï¼šä»€ä¹ˆæ ·çš„é¢˜ç›®é€‚åˆã€Œé€‰æˆ–ä¸é€‰ã€ï¼Œä»€ä¹ˆæ ·çš„é¢˜ç›®é€‚åˆã€Œæšä¸¾é€‰å“ªä¸ªã€ï¼Ÿ\nç­”ï¼šæˆ‘åˆ†æˆä¸¤ç±»é—®é¢˜ï¼š\nç›¸é‚»æ— å…³å­åºåˆ—é—®é¢˜ (æ¯”å¦‚ 0-1 èƒŒåŒ…)ï¼Œé€‚åˆã€Œé€‰æˆ–ä¸é€‰ã€ã€‚æ¯ä¸ªå…ƒç´ äº’ç›¸ç‹¬ç«‹ï¼Œåªéœ€ä¾æ¬¡è€ƒè™‘æ¯ä¸ªç‰©å“é€‰æˆ–ä¸é€‰ã€‚ ç›¸é‚»ç›¸å…³å­åºåˆ—é—®é¢˜ (æ¯”å¦‚æœ¬é¢˜)ï¼Œé€‚åˆã€Œæšä¸¾é€‰å“ªä¸ªã€ã€‚æˆ‘ä»¬éœ€è¦çŸ¥é“å­åºåˆ—ä¸­çš„ç›¸é‚»ä¸¤ä¸ªæ•°çš„å…³ç³»ã€‚å¯¹äºæœ¬é¢˜æ¥è¯´ï¼Œæšä¸¾ nums[i] å¿…é€‰ï¼Œç„¶åæšä¸¾å‰ä¸€ä¸ªå¿…é€‰çš„æ•°ï¼Œæ–¹ä¾¿æ¯”å¤§å°ã€‚å¦‚æœç¡¬è¦ç”¨ã€Œé€‰æˆ–ä¸é€‰ã€ï¼Œéœ€è¦é¢å¤–è®°å½•ä¸Šä¸€ä¸ªé€‰çš„æ•°çš„ä¸‹æ ‡ï¼Œç®—æ³•æ€»ä½“çš„ç©ºé—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œè€Œæšä¸¾é€‰å“ªä¸ªåªéœ€è¦ $O(n)$ çš„ç©ºé—´ã€‚ å®šä¹‰ dfs(i) ä¸ºä»¥ nums[i] ä¸ºç»“å°¾çš„ LIS é•¿åº¦ï¼Œé‚£ä¹ˆéœ€è¦æšä¸¾ nums[j] ä½œä¸ºå€’æ•°ç¬¬äºŒä¸ªå…ƒç´ ï¼Œè¿™é‡Œè¦æ±‚ j \u0026lt; i å¹¶ä¸” nums[j] \u0026lt; nums[i]. ç”±æ­¤å¾—åˆ°å›æº¯ä¸‰é—®:\nå½“å‰æ“ä½œ: æšä¸¾ nums[j]. å­é—®é¢˜: ä»¥ nums[i] ä¸ºç»“å°¾çš„ LIS é•¿åº¦ã€‚ ä¸‹ä¸€ä¸ªå­é—®é¢˜: ä»¥ nums[j] ä¸ºç»“å°¾çš„ LIS é•¿åº¦ã€‚ ç”±æ­¤å¾—åˆ°æˆ‘ä»¬çš„é€’å½’æ¨¡å‹ $dfs(i)=\\max\\left\\{dfs(j)\\right\\}+1,\\quad j","permalink":"http://localhost:1313/blogs/leetcode/07_dynamicprogramming/","summary":"Algorithm questions about dynamic programming.","title":"07 DynamicProgramming"},{"content":"Preliminary åŸé—®é¢˜: æ„é€ é•¿åº¦ä¸º n çš„å­—ç¬¦ä¸²ã€‚ -æšä¸¾ä¸€ä¸ªå­—æ¯å å­é—®é¢˜: æ„é€ é•¿åº¦ä¸º n-1 çš„å­—ç¬¦ä¸²ã€‚ å›æº¯æœ‰ä¸€ä¸ªå¢é‡æ„é€ ç­”æ¡ˆçš„è¿‡ç¨‹ï¼Œè¿™ä¸ªè¿‡ç¨‹é€šå¸¸ç”¨é€’å½’æ¥å®ç°ã€‚è·Ÿä¹‹å‰é€’å½’ä¸€æ ·ï¼Œåªéœ€è¦è€ƒè™‘è¾¹ç•Œæ¡ä»¶å’Œéè¾¹ç•Œæ¡ä»¶çš„é€»è¾‘ã€‚æ€»ç»“æˆå›æº¯ä¸‰é—®:\nå½“å‰æ“ä½œ? ç”¨ä¸€ä¸ª path æ•°ç»„è®°å½•è·¯å¾„ä¸Šçš„å­—æ¯ã€‚å½“å‰æ“ä½œä¸ºæšä¸¾ path[i] è¦å¡«å…¥çš„å­—æ¯ã€‚ è¿™é‡Œéœ€è¦æ³¨æ„é€’å½’å‚æ•°ä¸­çš„ i ä¸æ˜¯æŒ‡çš„ç¬¬ i ä¸ªï¼Œè€Œæ˜¯ä¸‹æ ‡ \u0026gt;= i çš„è¿™éƒ¨åˆ†ã€‚\nå­é—®é¢˜? æ„é€ å­—ç¬¦ä¸² \u0026gt;= i çš„è¿™éƒ¨åˆ†ã€‚ ä¸‹ä¸€ä¸ªå­é—®é¢˜? æ„é€ å­—ç¬¦ä¸² \u0026gt;= i çš„è¿™éƒ¨åˆ†ã€‚ æ•´ä¸ªè¿‡ç¨‹å’Œåœ¨ä¸€æ£µæ ‘ä¸Šè¿›è¡Œ dfs æ˜¯ç±»ä¼¼çš„ (dfs(i) \u0026ndash;\u0026gt; dfs(i+1)). 17. Letter Combinations of a Phone Number é¢˜ç›®ç½‘å€.\nè¾¹ç•Œæ¡ä»¶: æšä¸¾å®Œå½“å‰è·¯å¾„åæŠŠ path æ·»åŠ è¿› ans. é€’å½’æ¡ä»¶: éå†å½“å‰è¦æšä¸¾çš„æ•°å­—æ‰€å¯¹åº”çš„å­—æ¯ï¼Œæ·»åŠ è¿› path ä¹‹åè¿›è¡Œä¸‹ä¸€å±‚æ¬¡é€’å½’ã€‚ç»“æŸåæ¢å¤ç°åœºã€‚ class Solution { public: unordered_map\u0026lt;char, string\u0026gt; phoneMap{ {\u0026#39;2\u0026#39;, \u0026#34;abc\u0026#34;}, {\u0026#39;3\u0026#39;, \u0026#34;def\u0026#34;}, {\u0026#39;4\u0026#39;, \u0026#34;ghi\u0026#34;}, {\u0026#39;5\u0026#39;, \u0026#34;jkl\u0026#34;}, {\u0026#39;6\u0026#39;, \u0026#34;mno\u0026#34;}, {\u0026#39;7\u0026#39;, \u0026#34;pqrs\u0026#34;}, {\u0026#39;8\u0026#39;, \u0026#34;tuv\u0026#34;}, {\u0026#39;9\u0026#39;, \u0026#34;wxyz\u0026#34;} }; string path; vector\u0026lt;string\u0026gt; ans; void dfs(int i, string digits) { if (i == digits.size()) { ans.push_back(path); return; } for (auto\u0026amp; c : phoneMap[digits[i]]) { path += c; dfs(i + 1, digits); path.pop_back(); } } vector\u0026lt;string\u0026gt; letterCombinations(string digits) { if (0 == digits.size()) return vector\u0026lt;string\u0026gt;{}; dfs(0, digits); return ans; } }; æ—¶é—´å¤æ‚åº¦ï¼š$O(n4^n)$ï¼Œå…¶ä¸­ n ä¸º digits çš„é•¿åº¦ã€‚æœ€åæƒ…å†µä¸‹æ¯æ¬¡éœ€è¦æšä¸¾ 4 ä¸ªå­—æ¯ï¼Œé€’å½’æ¬¡æ•°ä¸ºä¸€ä¸ªæ»¡å››å‰æ ‘çš„èŠ‚ç‚¹ä¸ªæ•°ï¼Œé‚£ä¹ˆä¸€å…±ä¼šé€’å½’ $O(4^n)$ (ç­‰æ¯”æ•°åˆ—å’Œ) ï¼Œå†ç®—ä¸ŠåŠ å…¥ç­”æ¡ˆæ—¶å¤åˆ¶ path éœ€è¦ $O(n)$ çš„æ—¶é—´ï¼Œæ‰€ä»¥æ—¶é—´å¤æ‚åº¦ä¸º $O(n4^n)$. ç©ºé—´å¤æ‚åº¦ï¼š$O(n)$. è¿”å›å€¼çš„ç©ºé—´ä¸è®¡ã€‚ Subset Backtracking å­é›†å‹å›æº¯æœ¬è´¨ä¸Šæ˜¯çœ‹å¯¹äºæ¯ä¸ªå…ƒç´ æ˜¯é€‰/ä¸é€‰ã€‚\n78. Subsets é¢˜ç›®ç½‘å€. å¯¹äºç”Ÿæˆå­é›†æœ‰ä¸¤ç§æ€è·¯ï¼Œå…³é”®æ˜¯åœ¨äºå½“å‰æ“ä½œå®šä¹‰çš„åŒºåˆ«.\nè¾“å…¥è§’åº¦: å¯¹æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´  nums[i]ï¼Œè¿›è¡ŒäºŒå…ƒå†³ç­–ï¼šè¦ä¹ˆé€‰æ‹©è¯¥å…ƒç´ åŠ å…¥å½“å‰å­é›† (path) ï¼Œè¦ä¹ˆä¸é€‰æ‹©ã€‚æ¯æ¬¡é€’å½’å¤„ç†ä¸€ä¸ªå…ƒç´ ï¼Œé€æ­¥æ„å»ºæ‰€æœ‰å¯èƒ½çš„å­é›†ã€‚è¿™æ ·å­é—®é¢˜å’Œä¸‹ä¸€ä¸ªå­é—®é¢˜ä¸ä¸Šä¸€é¢˜çš„å®šä¹‰ä¸€æ ·ã€‚ void dfs(int i, vector\u0026lt;int\u0026gt;\u0026amp; nums) { if (i == nums.size()) { ans.push_back(path); return; } // don\u0026#39;t choose nums[i], continue dfs dfs(i + 1, nums); // choose nuns[i], add to path then dfs, pop when return path.push_back(nums[i]); dfs(i + 1, nums); path.pop_back(); } === Testing dfs (Decision-Based) === Not choosing nums[0] = 1, before dfs: path: [] Not choosing nums[1] = 2, before dfs: path: [] Not choosing nums[2] = 3, before dfs: path: [] Reached end, adding path: [] Choosing nums[2] = 3, before dfs: path: [3] Reached end, adding path: [3] Choosing nums[1] = 2, before dfs: path: [2] Not choosing nums[2] = 3, before dfs: path: [2] Reached end, adding path: [2] Choosing nums[2] = 3, before dfs: path: [2, 3] Reached end, adding path: [2, 3] Choosing nums[0] = 1, before dfs: path: [1] Not choosing nums[1] = 2, before dfs: path: [1] Not choosing nums[2] = 3, before dfs: path: [1] Reached end, adding path: [1] Choosing nums[2] = 3, before dfs: path: [1, 3] Reached end, adding path: [1, 3] Choosing nums[1] = 2, before dfs: path: [1, 2] Not choosing nums[2] = 3, before dfs: path: [1, 2] Reached end, adding path: [1, 2] Choosing nums[2] = 3, before dfs: path: [1, 2, 3] Reached end, adding path: [1, 2, 3] Result: [[], [3], [2], [2, 3], [1], [1, 3], [1, 2], [1, 2, 3]] ç­”æ¡ˆè§†è§’: ä»ç´¢å¼• i å¼€å§‹ï¼Œæšä¸¾åç»­æ‰€æœ‰å¯èƒ½çš„å…ƒç´ åŠ å…¥å­é›†ã€‚æ¯æ¬¡é€’å½’æ—¶ï¼Œå°†å½“å‰è·¯å¾„ path ä½œä¸ºå­é›†åŠ å…¥ç»“æœé›†ï¼Œç„¶åå°è¯•æ·»åŠ åç»­å…ƒç´ ã€‚ä¸ºäº†é¿å…é‡å¤å­é›†çš„å‡ºç°ï¼Œéœ€è¦æšä¸¾çš„ä¸‹æ ‡ j \u0026gt;= i çš„æ•°ã€‚å­é—®é¢˜å˜ä¸ºä¸‹æ ‡ \u0026gt;= i çš„æ•°ä¸­æ„é€ å­é›†ã€‚ä¸‹ä¸€ä¸ªå­é—®é¢˜ä¸ºä»ä¸‹æ ‡ \u0026gt;= j+1 çš„æ•°ä¸­æ„é€ å­é›†ã€‚ç”±äºå­é›†çš„é•¿åº¦æ²¡æœ‰é™åˆ¶ï¼Œå› æ­¤é€’å½’åˆ°çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ç­”æ¡ˆã€‚ä» dsf(i) æšä¸¾ dfs(i+1), dfs(i+2), \u0026hellip; , dfs(n). void dfs2(int i, vector\u0026lt;int\u0026gt;\u0026amp; nums) { ans.push_back(path); for (int j = i; j \u0026lt; nums.size(); j++) { path.push_back(nums[j]); dfs2(j + 1, nums); path.pop_back(); } return; } === Testing dfs2 (Enumeration-Based) === Adding path: [] Choosing nums[0] = 1, before dfs2: path: [1] Adding path: [1] Choosing nums[1] = 2, before dfs2: path: [1, 2] Adding path: [1, 2] Choosing nums[2] = 3, before dfs2: path: [1, 2, 3] Adding path: [1, 2, 3] Choosing nums[2] = 3, before dfs2: path: [1, 3] Adding path: [1, 3] Choosing nums[1] = 2, before dfs2: path: [2] Adding path: [2] Choosing nums[2] = 3, before dfs2: path: [2, 3] Adding path: [2, 3] Choosing nums[2] = 3, before dfs2: path: [3] Adding path: [3] Result: [[], [1], [1, 2], [1, 2, 3], [1, 3], [2], [2, 3], [3]] 131. Palindrome Partitioning é¢˜ç›®ç½‘å€.\nè¾“å…¥è§†è§’: å¯¹äºæ¯ä¸ªç´¢å¼• iï¼Œå†³å®šæ˜¯å¦åœ¨ i å’Œ i+1 ä¹‹é—´æ’å…¥åˆ†å‰²ç‚¹ (å³æ˜¯å¦å°† s[last:i+1) ä½œä¸ºä¸€ä¸ªå›æ–‡å­ä¸²). void dfs(int i, int last, string s) { // whether choose \u0026#39;,\u0026#39; between i and i+1 if (i == s.size()) { ans.push_back(path); return; } if (i \u0026lt; s.size() - 1) // must choose \u0026#39;,\u0026#39; when i==n-1 dfs(i + 1, last, s); // not , if (isPalindrome(s.substr(last, i - last + 1))) { path.push_back(s.substr(last, i - last + 1)); dfs(i+1, i+1, s); path.pop_back(); } return; } è‹¥æ²¡æœ‰ if (i \u0026lt; s.size() - 1) ä»£ç ä»ä¼šæ‰§è¡Œâ€œä¸åˆ†å‰²â€åˆ†æ”¯ dfs(i + 1, last, s)ï¼Œå¯¼è‡´è§¦å‘ç»ˆæ­¢æ¡ä»¶ï¼Œè®°å½•å½“å‰ pathã€‚ ä½†æ­¤æ—¶ï¼Œpath ä¸åŒ…å«æœ€åä¸€ä¸ªå­—ç¬¦ã€‚\nç­”æ¡ˆè§†è§’: æšä¸¾ä» i åˆ°å­—ç¬¦ä¸²æœ«å°¾çš„æ‰€æœ‰å¯èƒ½å­ä¸²ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºå›æ–‡ã€‚å¦‚æœ s[i:j+1) æ˜¯å›æ–‡ä¸²ï¼ŒåŠ å…¥ pathï¼Œé€’å½’å¤„ç†å‰©ä½™éƒ¨åˆ† (dfs2(j + 1, s)) ã€‚ å›æº¯æ—¶ç§»é™¤å½“å‰å­ä¸²ï¼Œç»§ç»­å°è¯•å…¶ä»–åˆ†å‰²ç‚¹ã€‚ void dfs2(int i, string s) { if (i == s.size()) { ans.push_back(path); return; } for (int j = i; j \u0026lt; s.size(); j++) { // enumerate all possible \u0026#39;,\u0026#39; if (isPalindrome(s.substr(i, j - i + 1))) { path.push_back(s.substr(i, j - i + 1)); dfs2(j + 1, s); path.pop_back(); } } return; } Q: ä¸ºä»€ä¹ˆè§¦å‘ç»ˆæ­¢æ¡ä»¶æ—¶ path ä¸­çš„å­ä¸²éƒ½æ˜¯å›æ–‡ï¼Ÿ\nA: å½“ i == s.size() æ—¶ï¼Œè¯´æ˜å·²ç»éå†äº†å­—ç¬¦ä¸² s çš„æ‰€æœ‰å­—ç¬¦ã€‚ç”±äºé€’å½’è¿‡ç¨‹ä¸­åªæœ‰å›æ–‡å­ä¸²æ‰ä¼šè¢«åŠ å…¥ pathï¼Œå¹¶ä¸”æ¯æ¬¡åˆ†å‰²å last ä¼šè¢«æ›´æ–°ä¸ºæ–°çš„èµ·ç‚¹ï¼Œpath ä¸­çš„å­ä¸²åºåˆ—è¦†ç›–äº†ä»å­—ç¬¦ä¸²å¼€å¤´åˆ°ç»“å°¾çš„æ‰€æœ‰å­—ç¬¦ã€‚\n784. Letter Case Permutation é¢˜ç›®ç½‘å€. ç›´æ¥å°†å½“å‰å­—ç¬¦åŠ å…¥ pathï¼Œé€’å½’åˆ°ä¸‹ä¸€ä½ã€‚åªå¯¹å¤„ç†å­—æ¯çš„æƒ…å†µä¸‹è¿›è¡Œæ¢å¤ã€‚å°† path ä¸­å¯¹åº”ä½ç½®çš„å­—ç¬¦åˆ‡æ¢å¤§å°å†™ (å¤§å†™å˜å°å†™æˆ–å°å†™å˜å¤§å†™) ï¼Œé€’å½’åˆ°ä¸‹ä¸€ä½ã€‚ ç§»é™¤å½“å‰å­—ç¬¦æ¢å¤ path è¿›è¡Œå›æº¯ï¼Œä»¥å°è¯•å…¶ä»–ç»„åˆã€‚\nclass Solution { public: string path; vector\u0026lt;string\u0026gt; ans; void dfs(int i, string s) { if (i == s.size()) { ans.push_back(path); return; } path += s[i]; dfs(i + 1, s); if (isalpha(s[i])) { path[i] = islower(s[i]) ? toupper(s[i]) : tolower(s[i]); dfs(i + 1, s); } path.pop_back(); return; } vector\u0026lt;string\u0026gt; letterCasePermutation(string s) { dfs(0, s); return ans; } }; 2397. Maximum Rows Covered by Columns é¢˜ç›®ç½‘å€. æ€è·¯å¾ˆç®€å•ï¼Œé€‰/ä¸é€‰æ¯ä¸€åˆ—ï¼Œåˆ¤æ–­èƒ½è¦†ç›–å¤šå°‘è¡Œï¼Œè¿™é‡Œç”¨ä½è¿ç®—è¿›è¡Œä¼˜åŒ–ã€‚\nrowMasks[i]: ç¬¬ i è¡Œçš„ 1 ä½ç½®è¡¨ç¤ºä¸ºä½æ©ç ï¼Œç¬¬ j ä½ä¸º 1 è¡¨ç¤º matrix[i][j] == 1. æšä¸¾åˆ—ç»„åˆï¼šä½¿ç”¨ mask (0 åˆ° $2^n - 1$) è¡¨ç¤ºæ‰€æœ‰å¯èƒ½çš„åˆ—é€‰æ‹©ç»„åˆã€‚__builtin_popcount(mask) æ£€æŸ¥ mask ä¸­ 1 çš„ä¸ªæ•°ä»è€Œåˆ¤æ–­æ˜¯å¦é€‰ä¸­äº† numSelect åˆ—ã€‚ æ£€æŸ¥è¦†ç›–: å¯¹äºæ¯è¡Œï¼Œè‹¥ rowMasks[i] \u0026amp; mask == rowMasks[i]ï¼Œè¯´æ˜è¯¥è¡Œçš„æ‰€æœ‰ 1 éƒ½åœ¨é€‰ä¸­çš„åˆ—ä¸­ (æˆ–è¯¥è¡Œæ—  1) . class Solution { public: int maximumRows(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix, int numSelect) { int m = matrix.size(), n = matrix[0].size(); vector\u0026lt;int\u0026gt; rowMask(m, 0); // which col is 1 in row[i] for (int i = 0; i \u0026lt; m; ++i) { for (int j = 0; j \u0026lt; n; ++j) { if (matrix[i][j]) { rowMask[i] |= (1 \u0026lt;\u0026lt; j); } } } int maxRows = 0; for (int mask = 0; mask \u0026lt; (1 \u0026lt;\u0026lt; n); mask++) { // col th bit 1/0 indicates select col or not if(__builtin_popcount(mask) != numSelect) continue; int covered = 0; for (int i = 0; i \u0026lt; m; i++) { if ((rowMask[i] \u0026amp; mask) == rowMask[i]) covered++; } maxRows = max(maxRows, covered); } return maxRows; } }; 2212. Maximum Points in an Archery Competition é¢˜ç›®ç½‘å€. é€’å½’æšä¸¾æ¯ä¸ªåŒºåŸŸæ˜¯å¦å¾—åˆ†ï¼š\né€‰æ‹©ä¸å¾—åˆ†: ä¸€ç®­ä¸å°„ï¼Œè·³åˆ°ä¸‹ä¸€åŒºåŸŸã€‚ é€‰æ‹©å¾—åˆ†ï¼šå°„å‡º aliceArrows[i] + 1 ç®­ï¼Œå¾— i åˆ†ï¼Œå‰©ä½™ç®­æ•°å‡å°‘ã€‚ æ³¨æ„é€’å½’åˆ°æœ€åä¸€ä¸ªåŒºåŸŸçš„æ—¶å€™éœ€è¦å°†æ‰€æœ‰ç®­å°„å‡ºã€‚ Member Variable Initilization in C++ ä¸èƒ½ç›´æ¥åœ¨ç±»å®šä¹‰ä¸­ä½¿ç”¨æ„é€ å‡½æ•°åˆå§‹åŒ–è¯­æ³•ï¼Œå¦‚ vector\u0026lt;int\u0026gt; ans(12,0). å®ƒè¢«è§†ä¸ºå‡½æ•°å£°æ˜ (ç”±äºc++ä¸­æœ€ä»¤äººçƒ¦æ¼çš„è§£æ) ï¼Œè€Œä¸æ˜¯å˜é‡åˆå§‹åŒ–ã€‚ç¼–è¯‘å™¨æœŸæœ›å‚æ•°å£°æ˜å™¨ (ä¾‹å¦‚ï¼Œå‡½æ•°å‚æ•°åˆ—è¡¨) ï¼Œå¯¼è‡´æœŸæœ›å‚æ•°å£°æ˜å™¨å‡ºé”™ã€‚\nåœ¨ c++11 ä¹‹å‰ï¼Œæˆå‘˜å˜é‡åªèƒ½åœ¨æ„é€ å‡½æ•°çš„åˆå§‹åŒ–åˆ—è¡¨ä¸­æˆ–åœ¨æ„é€ å‡½æ•°ä½“ä¸­åˆå§‹åŒ–ã€‚ åœ¨ c++11 åŠæ›´é«˜ç‰ˆæœ¬ä¸­ï¼Œå¯ä»¥ä½¿ç”¨å¤§æ‹¬å·åˆå§‹åŒ– ({}) æˆ–é»˜è®¤æˆå‘˜åˆå§‹åŒ–æ¥ä½¿ç”¨ç±»å†…åˆå§‹åŒ–ï¼Œä½†ä¸èƒ½ä½¿ç”¨åœ†æ‹¬å· () ã€‚ä¾‹å¦‚:\nvector\u0026lt;int\u0026gt; ans = vector\u0026lt;int\u0026gt;(12, 0); // Valid, but verbose vector\u0026lt;int\u0026gt; ans{vector\u0026lt;int\u0026gt;(12, 0)}; // Valid vector\u0026lt;int\u0026gt; ans = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}; // Valid class Solution { public: int maxScores = 0; vector\u0026lt;int\u0026gt; ans; void dfs(int i, int numArrows, vector\u0026lt;int\u0026gt;\u0026amp; aliceArrows, int score, vector\u0026lt;int\u0026gt;\u0026amp; bobArrows) { if (i == aliceArrows.size()) { if (score \u0026gt;= maxScores) { maxScores = score; ans = bobArrows; // Update ans with current bobArrows if (numArrows \u0026gt; 0) { ans[11] += numArrows; // Allocate remaining arrows to region 11 } } return; } // Pruning: Check if remaining score potential can beat maxScores int maxPossibleScore = score; for (int j = i; j \u0026lt; aliceArrows.size(); ++j) { maxPossibleScore += j; // Assume all remaining regions are scored } if (maxPossibleScore \u0026lt; maxScores || numArrows \u0026lt; 0) return; // Option 1: Don\u0026#39;t score in region i (use 0 arrows) bobArrows[i] = 0; dfs(i + 1, numArrows, aliceArrows, score, bobArrows); // Option 2: Score in region i (use aliceArrows[i] + 1 arrows) if (numArrows \u0026gt;= aliceArrows[i] + 1) { bobArrows[i] = aliceArrows[i] + 1; dfs(i + 1, numArrows - aliceArrows[i] - 1, aliceArrows, score + i, bobArrows); bobArrows[i] = 0; // Backtrack } } vector\u0026lt;int\u0026gt; maximumBobPoints(int numArrows, vector\u0026lt;int\u0026gt;\u0026amp; aliceArrows) { vector\u0026lt;int\u0026gt; bobArrows(12, 0); // Initialize bobArrows with size 12 ans.resize(12, 0); // Initialize ans with size 12 dfs(0, numArrows, aliceArrows, 0, bobArrows); return ans; } }; 2698. Find the Punishment Number of an Integer é¢˜ç›®ç½‘å€.\nç»ˆæ­¢æ¡ä»¶: index åˆ°è¾¾äº†å­—ç¬¦ä¸² s çš„æœ«å°¾ï¼Œè¯´æ˜æ•´ä¸ªå­—ç¬¦ä¸²å·²ç»è¢«æˆåŠŸåˆ†å‰²ã€‚æ­¤æ—¶ï¼Œæ£€æŸ¥ sum æ˜¯å¦ç­‰äºç›®æ ‡ i. é€‰/ä¸é€‰å›æº¯: å¯¹äºæ¯ä¸ªä½ç½®æˆ‘ä»¬å¯ä»¥é€‰æ‹©åˆ†å‰²æˆ–è€…ä¸åˆ†å‰²ã€‚è¦æ³¨æ„é€’å½’åˆ°æœ€åä¸€ä¸ªæ•°å­—çš„æ—¶å€™å¿…é¡»è¿›è¡Œåˆ†å‰²ã€‚ class Solution { public: int ans = 0; bool dfs(int i, string s, int start, int sum, int target) { if (i == s.size()) { return sum == target; } if (i \u0026lt; s.size() - 1) // must select last if (dfs(i + 1, s, start, sum, target)) return true; string subs = s.substr(start, i - start + 1); if (dfs(i + 1, s, i + 1, sum + stoll(subs), target)) return true; return false; } int punishmentNumber(int n) { for (int i = 0; i \u0026lt;= n; i++) if (dfs(0, to_string(i*i), 0, 0, i)) ans += i * i; return ans; } }; Combination Backtracking å›é¡¾å­é›†é—®é¢˜çš„æœç´¢æ ‘ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æ¯ä¸€å±‚èŠ‚ç‚¹çš„æ•°å­—ä¸ªæ•°æ˜¯ç›¸åŒçš„ï¼Œå®ƒä»¬æ°å¥½å¯ä»¥è¡¨ç¤ºä» n ä¸ªæ•°ä¸­é€‰æ‹© 1, 2, \u0026hellip;, n ä¸ªæ•°çš„æƒ…å†µã€‚ä» n ä¸ªæ•°ä¸­é€‰ k ä¸ªæ•°çš„ç»„åˆå¯ä»¥çœ‹ä½œæ˜¯é•¿åº¦å›ºå®šçš„å­é›†ã€‚å› æ­¤å¦‚æœæ˜¯æ‰¾ k ä¸ªæ•°çš„ç»„åˆï¼Œæˆ‘ä»¬å¯ä»¥æå‰è¿”å›è€Œä¸ç”¨ç»§ç»­é€’å½’ã€‚\n77. Combinations é¢˜ç›®ç½‘å€. ä»å¤§åˆ°å°è¿›è¡Œæšä¸¾ï¼Œå‡è®¾å½“å‰è·¯å¾„é•¿åº¦ä¸º mï¼Œé‚£ä¹ˆè¿˜éœ€è¦é€‰ d = k - m ä¸ªæ•°ã€‚å¦‚æœå½“å‰ä» i å¼€å§‹æšä¸¾ï¼Œå¦‚æœ i \u0026lt; dï¼Œæœ€åå¿…ç„¶æ— æ³•é€‰å‡º k ä¸ªæ•°ï¼Œä¸éœ€è¦ç»§ç»­é€’å½’ï¼Œè¿™æ˜¯ä¸€ç§å‰ªææŠ€å·§ã€‚\nè¿™é‡Œå¦‚æœä»å°åˆ°å¤§æšä¸¾ï¼Œåˆ¤æ–­æ¡ä»¶çš„ä¸ç­‰å¼ä¼šç¨å¾®å¤æ‚ä¸€äº›ã€‚\nè¿™é‡Œä»ç„¶å¯ä»¥é‡‡ç”¨é€‰æˆ–ä¸é€‰ ä»¥åŠ æšä¸¾ä¸¤ç§æ€è·¯ã€‚\nclass Solution { vector\u0026lt;int\u0026gt; path; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; void dfs(int i, int k) { int m = path.size(); if (m == k) { ans.push_back(path); return; } if (i \u0026lt; k - m) // not enough num to add return; dfs(i - 1, k); // don\u0026#39;t choose i path.push_back(i); dfs(i - 1, k); path.pop_back(); return; } void dfs2(int i, int k) { int m = path.size(); if (m == k) { ans.push_back(path); return; } if (i \u0026lt; k - m) // not enough num to add return; for (int j = i; j \u0026gt; 0; j--) { path.push_back(j); dfs2(j - 1, k); path.pop_back(); } return; } public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combine(int n, int k) { dfs(n, k); // dfs2(n, k); return ans; } }; å›æº¯çš„æ—¶é—´å¤æ‚åº¦æœ‰ä¸€ä¸ªå…¬å¼: å¶å­çš„ä¸ªæ•° x ä»æ ¹åˆ°å¶å­çš„è·¯å¾„é•¿åº¦ã€‚å› æ­¤æœ¬é¢˜çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(C_{n}^{k}k)$ ç©ºé—´å¤æ‚åº¦ä¸º $O(k)$ éœ€è¦ä¸€ä¸ªæ•°ç»„æ¥å­˜å‚¨ç»„åˆæ•°è·¯å¾„ã€‚\n216. Combination Sum III é¢˜ç›®ç½‘å€. è¿™é¢˜å¤šäº†ä¸€ä¸ªé€‰å‡ºçš„æ•°ç›®å’Œä¸º n çš„é™åˆ¶ï¼Œå’Œä¸Šé¢˜ä¸€æ ·è®¾è¿˜éœ€è¦é€‰ d = k - m ä¸ªæ•°ï¼Œä½¿å¾—å®ƒä»¬çš„å’Œä¸º t (åˆå§‹ä¸º nï¼Œæ¯é€‰ä¸€ä¸ªæ•°å°±å‡å°‘). è¿™é‡Œå¯ä»¥å‰ªæçš„æƒ…å†µæœ‰\nå‰©ä½™æ•°å­—ä¸å¤Ÿï¼Œå³ i \u0026lt; d. å½“å‰æ‰€é€‰æ•°å­—ä¹‹å’Œå·²ç»å¤§äº nï¼Œå³ t \u0026lt; 0. å³ä½¿å‰©ä½™æ•°å­—å…¨éƒ¨é€‰æœ€å¤§å‰å‡ ä¸ªï¼Œå®ƒä»¬çš„å’Œä¹Ÿå°äº tï¼Œå³ $i+\\cdots+(i-d+1)=\\frac{(i+i-d+1)\\cdot d}2 \u003c t$. class Solution { vector\u0026lt;int\u0026gt; path; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; void dfs(int i, int k, int t) { int m = path.size(); if (m == k \u0026amp;\u0026amp; t == 0) { ans.push_back(path); return; } int d = k - m; // need to choose d nums if (i \u0026lt; d || t \u0026lt; 0 || (i + i - d + 1) * d / 2 \u0026lt; t) // cur sum \u0026gt; n or sum of first d th big nums \u0026lt; t return; dfs(i - 1, k, t); // don\u0026#39;t choose i path.push_back(i); dfs(i - 1, k, t - i); path.pop_back(); return; } void dfs2(int i, int k, int t) { int m = path.size(); if (m == k \u0026amp;\u0026amp; t == 0) { ans.push_back(path); return; } int d = k - m; // need to choose d nums if (i \u0026lt; d || t \u0026lt; 0 || (i + i - d + 1) * d / 2 \u0026lt; t) // cur sum \u0026gt; n or sum of first d th big nums \u0026lt; t return; for (int j = i; j \u0026gt; 0; j--) { path.push_back(j); dfs2(j - 1, k, t - j); path.pop_back(); } return; } public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum3(int k, int n) { dfs(9, k, n); // dfs2(9, k, n); return ans; } }; 22. Generate Parentheses é¢˜ç›®ç½‘å€. å¯¹äºå­—ç¬¦ä¸²çš„æ¯ä¸ªå‰ç¼€ï¼Œå·¦æ‹¬å·çš„ä¸ªæ•°éƒ½éœ€è¦å¤§äºå³æ‹¬å·çš„ä¸ªæ•°ã€‚è¿™é¢˜å¯ä»¥çœ‹å‡ºä» 2n ä¸ªä½ç½®ä¸­é€‰ n ä¸ªä½ç½®æ”¾å·¦æ‹¬å·ã€‚å¯¹äºä¸€ä¸ªä½ç½®è¦ä¹ˆé€‰æ‹©æ”¾å·¦æ‹¬å·æˆ–è€…é€‰æ‹©æ”¾å³æ‹¬å·ã€‚\nclass Solution { public: string path; vector\u0026lt;string\u0026gt; ans; void dfs(int left, int diff, int n) { // choose n pos \u0026#39;(\u0026#39; in 2n if (path.size() == 2 * n) { ans.push_back(path); return; } if (diff \u0026gt; 0) { // if num of prefix \u0026#39;(\u0026#39; \u0026gt; num of \u0026#39;)\u0026#39; path += \u0026#39;)\u0026#39;; dfs(left, diff - 1, n); // then can choose \u0026#39;)\u0026#39; path.pop_back(); } if (left \u0026lt; n) { path += \u0026#39;(\u0026#39;; dfs(left + 1, diff + 1, n); path.pop_back(); } return; } vector\u0026lt;string\u0026gt; generateParenthesis(int n) { dfs(0, 0, n); return ans; } }; 39. Combination Sum é¢˜ç›®ç½‘å€. è¿™é¢˜å› ä¸ºæ•°å­—å¯ä»¥é‡å¤é€‰æ‹©ï¼Œå› æ­¤è¿›è¡Œé€’å½’çš„æ—¶å€™ä¸‹æ ‡è¦æ³¨æ„ã€‚æˆ‘ä»¬å…ˆå¯¹ candidates æ•°ç»„è¿›è¡Œæ’åºä»¥æ–¹ä¾¿å‰ªæã€‚\nç»ˆæ­¢æ¡ä»¶: å¦‚æœ target == 0ï¼Œè¯´æ˜å½“å‰è·¯å¾„çš„æ•°å­—å’Œè¾¾åˆ°ç›®æ ‡å€¼ï¼Œå°† path åŠ å…¥ç­”æ¡ˆ ansã€‚ å‰ªæ: å¦‚æœ i == candidates.size() æˆ–å½“å‰é€’å½’çš„æœ€å°æ•°å­— candidates[i] \u0026gt; targetï¼Œè¯´æ˜æ— æ³•ç»§ç»­é€‰æ‹©ï¼Œç›´æ¥è¿”å›ã€‚ é€‰/ä¸é€‰æ–¹æ³•\nä¸é€‰å½“å‰æ•°å­—:ç›´æ¥é€’å½’è°ƒç”¨ dfs(i + 1, candidates, target)ï¼Œè·³åˆ°ä¸‹ä¸€ä¸ªæ•°å­—ã€‚ é€‰æ‹©å½“å‰æ•°å­—: å°† candidates[i] åŠ å…¥ path åé€’å½’è°ƒç”¨ dfs(i, candidates, target - candidates[i])ï¼Œæ³¨æ„è¿™é‡Œæ˜¯ i (è€Œé i + 1)ï¼Œå› ä¸ºå…è®¸é‡å¤é€‰æ‹©å½“å‰æ•°å­—ã€‚å›æº¯æ—¶å¼¹å‡º path ä¸­æœ€åä¸€ä¸ªæ•°å­—ï¼Œæ¢å¤çŠ¶æ€ã€‚ void dfs(int i, vector\u0026lt;int\u0026gt;\u0026amp; candidates, int target) { if (target == 0) { ans.push_back(path); return; } if (i == candidates.size() || candidates[i] \u0026gt; target) return; dfs(i + 1, candidates, target); path.push_back(candidates[i]); dfs(i, candidates, target - candidates[i]); // can choose many times path.pop_back(); return; } æšä¸¾ä¸‹ä¸€ä¸ªæ–¹æ³•: å¾ªç¯ä»ä¸‹æ ‡ j = i åˆ° candidates.size() - 1 æšä¸¾ä»å½“å‰ä¸‹æ ‡ i å¼€å§‹çš„æ‰€æœ‰å¯èƒ½æ•°å­—ï¼Œé€æ­¥æ„å»ºæ»¡è¶³ target çš„ç»„åˆã€‚æ¯æ¬¡å¾ªç¯å°è¯•é€‰æ‹© candidates[j]ï¼Œå¹¶é€’å½’åˆ°å…è®¸é‡å¤é€‰æ‹©çš„çŠ¶æ€ dfs2(j, ...).\nvoid dfs2(int i, vector\u0026lt;int\u0026gt;\u0026amp; candidates, int target) { if (target == 0) { ans.push_back(path); return; } if (i == candidates.size() || candidates[i] \u0026gt; target) return; for (int j = i; j \u0026lt; candidates.size(); j++) { path.push_back(candidates[j]); dfs2(j, candidates, target - candidates[j]); path.pop_back(); } return; } 93. Restore IP Addresses é¢˜ç›®ç½‘å€. ç”¨ä¸€ä¸ª vector\u0026lt;string\u0026gt; æ¥å­˜å‚¨å½“å‰è·¯å¾„ä¸Šå·²ç»åˆ†å‰²å¥½çš„æ®µã€‚å¦‚æœ s æœ¬èº«é•¿åº¦ \u0026lt; 4 æˆ– \u0026gt;12 åˆ™è¯´æ˜æ— æ³•åˆ†å‰²ç›´æ¥è¿”å›ã€‚\né¦–å…ˆæ˜ç¡®åˆ†å‰²çš„å­ä¸²æ˜¯å¦æ˜¯ä¸€æ®µéæ³•çš„åœ°å€çš„æ¡ä»¶:\nå­ä¸²é•¿åº¦å¤§äº 1 ä¸”ä»¥ \u0026lsquo;0\u0026rsquo; å¼€å¤´ã€‚ å°†å­ä¸²è½¬ä¸ºæ•´æ•°çš„ç»“æœå¤§äº 255ã€‚ å­ä¸²é•¿åº¦å¤§äº 3. å¹¶ä¸”å¯ä»¥å‘ç°å°±ç®—å»¶é•¿å­ä¸²çš„é•¿åº¦ä¹Ÿä¸èƒ½ä½¿å…¶åˆæ³•ã€‚\nç»ˆæ­¢æ¡ä»¶: å½“ path ä¸­å·²ç»æœ‰ 4 æ®µæ—¶ï¼Œåˆ†å‰²å°±ç»“æŸäº†ã€‚æ­¤æ—¶ï¼Œè¿˜éœ€è¦æ£€æŸ¥æ˜¯å¦å·²ç»ç”¨å®Œäº†æ•´ä¸ªå­—ç¬¦ä¸² ( startIndex == s.length()). å¦‚æœåŒæ—¶æ»¡è¶³è¿™ä¸¤ä¸ªæ¡ä»¶ï¼Œè¯´æ˜æ‰¾åˆ°äº†ä¸€ä¸ªåˆæ³•çš„ IP åœ°å€ã€‚æˆ‘ä»¬å°† path ä¸­çš„ 4 æ®µç”¨ . è¿æ¥èµ·æ¥ï¼Œå­˜å…¥æœ€ç»ˆçš„ç»“æœæ•°ç»„ ans ä¸­ã€‚æ— è®ºæ˜¯å¦åˆæ³•éƒ½éœ€è¦è¿”å›ã€‚ é€‰/ä¸é€‰æ€è·¯:\nå‰ªæ: å¦‚æœå½“å‰æ²¡åˆ†å‰²æˆå››æ®µä½†æ˜¯å·²ç»ç”¨å®Œäº†æ•°ç»„ï¼Œæˆ–è€…å½“å‰å¯¹åº”åˆ†å‰²çš„å­ä¸²å·²ç»éæ³•å°±ç›´æ¥è¿”å›ã€‚ ä¸åˆ†å‰²: dfs(i + 1, \u0026hellip;). åˆ†å‰²: å½“å‰å­ä¸²åŠ å…¥ path åç»§ç»­é€’å½’ dfs(i + 1, i + 1, s) ç„¶åå›æº¯ã€‚ bool valid(string s) { if (s.size() \u0026gt; 3) return false; if (s[0] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s.size() \u0026gt; 1) return false; if(stoi(s) \u0026gt; 255) return false; return true; } void dfs(int i, int start, string s) { if (path.size() == 4) { if (start == s.size()) { string ip = path[0] + \u0026#39;.\u0026#39; + path[1] + \u0026#39;.\u0026#39; + path[2] + \u0026#39;.\u0026#39; + path[3]; ans.push_back(ip); } return; } if (i \u0026gt; s.size() - 1) return; string segment = s.substr(start, i - start + 1); if (!valid(segment)) return; dfs(i + 1, start, s); path.push_back(segment); dfs(i + 1, i + 1, s); path.pop_back(); return; } æšä¸¾æ‰€æœ‰åˆ†å‰²ç‚¹æ€è·¯:\nä» start å¼€å§‹ï¼Œå‘åéå†ï¼Œå°è¯•æˆªå–é•¿åº¦ä¸º 1/2/3 çš„å­ä¸²ä½œä¸ºä¸‹ä¸€ä¸ª IP æ®µã€‚ åœ¨å¾ªç¯ä¸­ï¼Œéœ€è¦ä¸æ–­æ£€æŸ¥å½“å‰æˆªå–çš„å­ä¸²æ˜¯å¦åˆæ³•ï¼Œä¸åˆæ³•å°±æ²¡å¿…è¦ç»§ç»­æ·±å…¥äº†ã€‚ å¦‚æœå½“å‰å­ä¸² segment åˆæ³•ï¼Œå°±æŠŠå®ƒåŠ å…¥åˆ° path ä¸­ç»§ç»­é€’å½’ dfs2(i + 1, s) åå›æº¯ã€‚ void dfs2(int start, string s) { if (path.size() == 4) { if (start == s.size()) { string ip = path[0] + \u0026#39;.\u0026#39; + path[1] + \u0026#39;.\u0026#39; + path[2] + \u0026#39;.\u0026#39; + path[3]; ans.push_back(ip); } return; } for (int i = start; i \u0026lt; s.size(); i++) { string segment = s.substr(start, i - start + 1); if (!valid(segment)) // no need to insert . break; path.push_back(segment); dfs2(i + 1, s); path.pop_back(); } return; } Permutation Backtracking 46. Permutations é¢˜ç›®ç½‘å€. ç›¸æ¯”äºç»„åˆæ¥è¯´ï¼Œæ’åˆ—å¯¹é¡ºåºæ˜¯æœ‰è¦æ±‚çš„ã€‚å½“é€‰äº†ä¸€ä¸ªæ•°ä¹‹åï¼Œç”¨ä¸€ä¸ªé›†åˆ s è®°å½•å‰©ä½™æœªé€‰æ•°å­—æ¥å‘Šè¯‰ä¸‹é¢èŠ‚ç‚¹è¿˜å¯ä»¥é€‰å“ªäº›æ•°å­—ã€‚\nå½“å‰æ“ä½œ: ä» s ä¸­æšä¸¾ path[i] ä¸­è¦å¡«å…¥çš„æ•°å­— x. è¿™æ ·å°±æ˜ç¡®äº†é€’å½’çš„å‚æ•°ä¸º i å’Œ s. å­é—®é¢˜: æ„é€ æ’åˆ— \u0026gt;= i çš„éƒ¨åˆ†ï¼Œå‰©ä½™æœªé€‰æ•°å­—é›†åˆ s. ä¸‹ä¸€ä¸ªå­é—®é¢˜: æ„é€ æ’åˆ— \u0026gt;= i + 1 çš„éƒ¨åˆ†ï¼Œå‰©ä½™æœªé€‰æ•°å­—é›†åˆ s - {x}. ç”±äº c++ set åˆ é™¤å…ƒç´ çš„å¼€é”€ä¸º $O(\\log n)$ï¼Œè¿™é‡Œæ›´é«˜æ•ˆçš„æ“ä½œæ–¹æ³•æ˜¯ç”¨ä¸€ä¸ªæ•°ç»„æ¥æ ‡æ•°å­—æ˜¯å¦è¢«é€‰ä¸­ã€‚\nclass Solution { vector\u0026lt;int\u0026gt; path; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; void dfs(vector\u0026lt;int\u0026gt;\u0026amp; nums, vector\u0026lt;bool\u0026gt;\u0026amp; used) { if (path.size() == nums.size()) { ans.push_back(path); return; } for (int i = 0; i \u0026lt; nums.size(); ++i) { if (!used[i]) { // select unused used[i] = true; // mark as used path.push_back(nums[i]); dfs(nums, used); path.pop_back(); used[i] = false; // recovery } } } public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; permute(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;bool\u0026gt; used(nums.size(), false); dfs(nums, used); return ans; } }; è¿™é‡Œçš„é‡ç‚¹æ˜¯æ—¶é—´å¤æ‚åº¦åˆ†æã€‚ä¹‹å‰è¯´è¿‡å¯ä»¥ç”¨å¶å­èŠ‚ç‚¹ä¸ªæ•° x æ ¹åˆ°å¶å­èŠ‚ç‚¹è·¯å¾„é•¿åº¦æ¥è¿›è¡Œä¼°ç®—ï¼ŒæŒ‰ç…§è¿™ç§æ–¹å¼å¾—å‡ºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n*n!)$. æ›´ç²¾ç¡®çš„æ–¹å¼æ˜¯è®¡ç®—èŠ‚ç‚¹çš„ä¸ªæ•°ï¼Œè¿™æ ·ä¹Ÿå°±çŸ¥é“äº†é€’å½’çš„æ¬¡æ•°ã€‚\næœ€åä¸€å±‚èŠ‚ç‚¹ä¸ªæ•°ä¸º $A_n^n$, å€’æ•°ç¬¬äºŒå±‚èŠ‚ç‚¹ä¸ªæ•°ä¸º $A_n^{n-1}$\u0026hellip;ä»¥æ­¤ç±»æ¨ã€‚æ ¹æ®å…¬å¼ $A_{n}^{m}=\\frac{n!}{(n-m)!}$ï¼Œæˆ‘ä»¬æœ‰\n$$ \\sum_{k=0}^nA_n^k=\\sum_{k=0}^n\\frac{n!}{(n-k)!}=n!\\sum_{k=0}^n\\frac1{(n-k)!}=n!\\sum_{m=0}^n\\frac1{m!} $$å…¶ä¸­ $m = n - k$. è¿™ä¸ªå’Œå¯ä»¥è¡¨ç¤ºä¸º\n$$ \\sum_{k=0}^nA_n^k=n!\\left(\\frac1{0!}+\\frac1{1!}+\\frac1{2!}+\\cdots+\\frac1{n!}\\right) $$æ±‚å’Œé¡¹ä¸º $e^x$ åœ¨ $x=1$ å¤„çš„æ³°å‹’å±•å¼€ï¼Œå› æ­¤è¿™ä¸ªå’Œæ¥è¿‘äº $n!\\cdot e$ï¼Œç”±äºèŠ‚ç‚¹ä¸ªæ•°ä¸ºæ•´æ•°ï¼Œå› æ­¤è¿™æ£µæ ‘çš„èŠ‚ç‚¹ä¸ªæ•°ä¸º $\\lfloor n!\\cdot e \\rfloor$. å†ç®—ä¸ŠæŠŠ path æ·»åŠ è¿› ans çš„æ—¶é—´ï¼Œæ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n*n!)$. ç©ºé—´å¤æ‚åº¦ä¸º $O(n)$ï¼Œä½¿ç”¨äº†é¢å¤–çš„æ•°ç»„æ¥è®°å½•è·¯å¾„å’Œæ ‡è®°ã€‚\n51. N Queens é¢˜ç›®ç½‘å€. ä¸€ä¸ª nxn çš„æ£‹ç›˜ä¸Šè¦æ”¾ n ä¸ªçš‡åå¹¶ä¸”è¦æ±‚ä¸åŒè¡Œï¼Œä¸åŒåˆ—ï¼Œä¸åœ¨åŒä¸€æ–œçº¿å…¶å®å°±æ˜¯è¦æ±‚æ¯è¡Œæ¯åˆ—æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªçš‡åã€‚å› ä¸ºå¦‚æœæœ‰ä¸€è¡Œ/åˆ—ä¸æ”¾çš‡åï¼Œå‰©ä¸‹ n-1 è¡Œ/åˆ—å°±è¦æ”¾ n ä¸ªçš‡åï¼Œå¿…ç„¶ä¸æ»¡è¶³è¦æ±‚ã€‚\nç”¨ä¸€ä¸ª col æ•°ç»„æ¥è®°å½•çš‡åçš„ä½ç½®ï¼Œcol[i] è¡¨ç¤ºç¬¬ i è¡Œçš„çš‡åè¢«æ”¾ç½®åœ¨ç¬¬å‡ åˆ—ã€‚é‚£ä¹ˆ col æœ¬èº«å°±æ˜¯ä¸€ä¸ª 0~n-1 çš„æ’åˆ—ã€‚å¯¹äºå³ä¸Šæ–¹çš„æ–œçº¿ï¼Œè¡Œå· r + åˆ—å· c æ˜¯ä¸€ä¸ªå®šå€¼ï¼›å¯¹äºå·¦ä¸Šæ–¹çš„æ–œçº¿ï¼Œè¡Œå· r - åˆ—å· c æ˜¯ä¸€ä¸ªå®šå€¼ã€‚æˆ‘ä»¬å¯ä»¥ä»ç¬¬ 0 è¡Œå¼€å§‹å‘ä¸‹æšä¸¾ï¼Œç”¨ä¸¤ä¸ªæ•°ç»„åˆ†åˆ«æ ‡è®° r+c å’Œ r-c æ˜¯å¦æœ‰å‡ºç°è¿‡ã€‚\nclass Solution { public: vector\u0026lt;int\u0026gt; col; vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; ans; vector\u0026lt;string\u0026gt; buildBoard(const vector\u0026lt;int\u0026gt;\u0026amp; queens, int n) { vector\u0026lt;string\u0026gt; board(n, string(n, \u0026#39;.\u0026#39;)); for (int r = 0; r \u0026lt; n; r++) { board[r][queens[r]] = \u0026#39;Q\u0026#39;; // Place queen in row r, column queens[r] } return board; } void dfs(int r, vector\u0026lt;bool\u0026gt;\u0026amp; used, vector\u0026lt;bool\u0026gt; diag1, vector\u0026lt;bool\u0026gt; diag2) { int n = used.size(); if (r == n) { ans.push_back(buildBoard(col, n)); return; } for (int c = 0; c \u0026lt; n; c++) { if (!used[c] \u0026amp;\u0026amp; !diag1[r + c] \u0026amp;\u0026amp; !diag2[r - c + n - 1]) { used[c] = true; diag1[r + c] = true; diag2[r - c + n - 1] = true; // avoid negative col.push_back(c); dfs(r + 1, used, diag1, diag2); col.pop_back(); diag2[r - c + n - 1] = false; diag1[r + c] = false; used[c] = false; } } } vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; solveNQueens(int n) { vector\u0026lt;bool\u0026gt; used(n, false); vector\u0026lt;bool\u0026gt; diag1(2*n - 1, false); // right_up vector\u0026lt;bool\u0026gt; diag2(2*n - 1, false); // left_up dfs(0, used, diag1, diag2); return ans; } }; 357. Count Numbers With Unique Digits é¢˜ç›®ç½‘å€. ä½¿ç”¨æ•°å­¦ç»„åˆå’ŒåŠ¨æ€è§„åˆ’çš„æ€è·¯è§£å†³ã€‚\nå®šä¹‰ f(k) ä¸º k ä½æ•°å­—ä¸­ï¼Œå„ä½æ•°éƒ½ä¸åŒçš„æ•°çš„ä¸ªæ•°ã€‚\nf(1) = 9 (1-9) f(2) = 9 * 9 (ç¬¬ä¸€ä½ä¸èƒ½æ˜¯0ï¼Œç¬¬äºŒä½ä¸èƒ½å’Œç¬¬ä¸€ä½ç›¸åŒ) f(3) = 9 * 9 * 8 \u0026hellip; f(k) = 9 * 9 * 8 * \u0026hellip; * (10 - k + 1) å¯ä»¥çœ‹å‡º k \u0026gt;= 2 æ—¶ f(k) $ = 9A_9^{k-1}$. ç”±äºé¢˜ç›®è¦æ±‚çš„æ˜¯å°äº $10^n$ çš„æ‰€æœ‰ä¸ªæ•°ï¼Œå› æ­¤ç­”æ¡ˆä¸ºæ˜¯ 1 (æ•°å­—0) + f(1) + f(2) + \u0026hellip; + f(n).\nclass Solution { public: int countNumbersWithUniqueDigits(int n) { if (n == 0) return 1; int ans = 9, cur = 9; for (int i = 0; i \u0026lt; n - 1; i ++) { cur *= 9 - i; ans += cur; } return ans + 1; // add 0 } }; 2850. Minimum Moves to Spread Stones over Grid é¢˜ç›®ç½‘å€. è¿™ä¸ªé—®é¢˜çš„æœ¬è´¨ä¸æ˜¯æ¨¡æ‹Ÿæ¯ä¸€æ­¥ç§»åŠ¨ï¼Œè€Œæ˜¯æ‰¾åˆ°ä¸€ä¸ªæœ€ä½³çš„åˆ†é…æ–¹æ¡ˆã€‚\næºå¤´ (Surplus): æŸäº›å•å…ƒæ ¼çš„çŸ³å¤´æ•°é‡å¤§äº 1ã€‚è¿™äº›æ˜¯â€œå¤šä½™â€çš„çŸ³å¤´ï¼Œå¯ä»¥è¢«ç§»èµ°ã€‚ä¸€ä¸ªæœ‰ k ä¸ªçŸ³å¤´çš„å•å…ƒæ ¼å¯ä»¥æä¾› k - 1 ä¸ªçŸ³å¤´ã€‚ ç›®çš„åœ° (Deficit): æŸäº›å•å…ƒæ ¼çš„çŸ³å¤´æ•°é‡ä¸º 0ã€‚è¿™äº›æ˜¯â€œç©ºç¼ºâ€çš„å•å…ƒæ ¼ï¼Œéœ€è¦çŸ³å¤´ã€‚æ¯ä¸ªè¿™æ ·çš„å•å…ƒæ ¼éœ€è¦ 1 ä¸ªçŸ³å¤´ã€‚ çŸ³å¤´æ•°ä¸º 1 çš„å•å…ƒæ ¼æ˜¯å¹³è¡¡çš„ï¼Œæˆ‘ä»¬ä¸éœ€è¦å¯¹å®ƒä»¬è¿›è¡Œä»»ä½•æ“ä½œã€‚ ç”±äºçŸ³å¤´æ€»æ•°æ˜¯ 9ï¼Œå¹¶ä¸”ç›®æ ‡æ˜¯æ¯ä¸ªæ ¼å­éƒ½æœ‰ 1 ä¸ªçŸ³å¤´ï¼Œé‚£ä¹ˆå¤šä½™çŸ³å¤´çš„æ€»æ•°å¿…ç„¶ç­‰äºç©ºç¼ºæ ¼å­çš„æ€»æ•°ã€‚ æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸¤ä¸ªåˆ—è¡¨ï¼š\nfrom_list: å­˜å‚¨æ‰€æœ‰â€œå¤šä½™â€çŸ³å¤´çš„èµ·å§‹åæ ‡ã€‚å¦‚æœä¸€ä¸ªå•å…ƒæ ¼ (r, c) æœ‰ k \u0026gt; 1 ä¸ªçŸ³å¤´ï¼Œæˆ‘ä»¬å°±æŠŠè¿™ä¸ªåæ ‡é‡å¤ k - 1 æ¬¡åŠ å…¥åˆ—è¡¨ã€‚ to_list: å­˜å‚¨æ‰€æœ‰â€œç©ºç¼ºâ€å•å…ƒæ ¼çš„åæ ‡ã€‚å¦‚æœ grid[i][j] == 0ï¼Œæˆ‘ä»¬å°±æŠŠ (i, j) åŠ å…¥åˆ—è¡¨ã€‚ ç»è¿‡è¿™ä¸ªæ“ä½œåï¼Œfrom_list å’Œ to_list çš„å¤§å°ä¸€å®šæ˜¯ç›¸ç­‰çš„ã€‚å°†ä¸€ä¸ªçŸ³å¤´ä» (r1, c1) ç§»åŠ¨åˆ° (r2, c2)ï¼Œæœ€å°‘çš„ç§»åŠ¨æ¬¡æ•°ç­‰äºå®ƒä»¬ä¹‹é—´çš„æ›¼å“ˆé¡¿è·ç¦» |r1 - r2| + |c1 - c2|. ç°åœ¨é—®é¢˜å°±å˜æˆäº†ï¼š å¦‚ä½•å°† from_list ä¸­çš„æ¯ä¸€ä¸ªçŸ³å¤´ä¸ to_list ä¸­çš„æ¯ä¸€ä¸ªç©ºæ ¼è¿›è¡Œä¸€ä¸€é…å¯¹ï¼Œä½¿å¾—æ‰€æœ‰é…å¯¹çš„æ›¼å“ˆé¡¿è·ç¦»ä¹‹å’Œæœ€å°ï¼Ÿ\nå¯¹äº k ä¸ªæºå¤´å’Œ k ä¸ªç›®çš„åœ°ï¼Œå¯»æ‰¾æœ€ä¼˜åŒ¹é…çš„ç»„åˆæ€»æ•°æ˜¯ k! æç«¯æƒ…å†µä¸‹ä¸€ä¸ªæ ¼å­æœ‰ 9 ä¸ªçŸ³å¤´ï¼Œå…¶ä»– 8 ä¸ªæ ¼å­éƒ½æ˜¯ 0. è¿™æ—¶ k = 8ï¼Œæ€»å…±ç»„åˆæ•°æœ‰ 40320 ç§æƒ…å†µã€‚\nstd::next_permutation æ˜¯ä¸€ä¸ªå®šä¹‰åœ¨ \u0026lt;algorithm\u0026gt; å¤´æ–‡ä»¶ä¸­çš„å‡½æ•°ã€‚å®ƒçš„æ ¸å¿ƒåŠŸèƒ½æ˜¯å°†ä¸€ä¸ªåºåˆ— (å¦‚ vectorã€string æˆ–æ•°ç»„) å°±åœ°è½¬æ¢ä¸ºå®ƒçš„ä¸‹ä¸€ä¸ªå­—å…¸åºæ’åˆ—ã€‚\nclass Solution { public: int minimumMoves(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; grid) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; from_coords; vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; to_coords; for (int i = 0; i \u0026lt; 3; i++) { for (int j = 0; j \u0026lt; 3; j++) { if (grid[i][j] \u0026gt; 1) { for (int k = 0; k \u0026lt; grid[i][j] - 1; k++) { // can supply num - 1 stones. from_coords.push_back({i, j}); } } else if (grid[i][j] == 0) { to_coords.push_back({i, j}); } } } if (to_coords.empty()) return 0; sort(from_coords.begin(), from_coords.end()); int minMove = INT_MAX; do { int curMove = 0; for (int i = 0; i \u0026lt; from_coords.size(); i++) { curMove += abs(from_coords[i].first - to_coords[i].first) + abs(from_coords[i].second - to_coords[i].second); } minMove = min(curMove, minMove); } while(next_permutation(from_coords.begin(), from_coords.end())); return minMove; } }; ","permalink":"http://localhost:1313/blogs/leetcode/06_backtracking/","summary":"Algorithm questions about backtracking.","title":"06 Backtracking"},{"content":"Preliminary: How to Think about the Recursion of Binary Tree å¦‚ä½•æ€è€ƒäºŒå‰æ ‘ç›¸å…³é—®é¢˜ï¼Ÿ ä¸è¦ä¸€å¼€å§‹å°±é™·å…¥ç»†èŠ‚ï¼Œè€Œæ˜¯æ€è€ƒæ•´æ£µæ ‘ä¸å…¶å·¦å³å­æ ‘çš„å…³ç³»ã€‚ ä¸ºä»€ä¹ˆéœ€è¦ä½¿ç”¨é€’å½’ï¼Ÿ å­é—®é¢˜å’ŒåŸé—®é¢˜æ˜¯ç›¸ä¼¼çš„ï¼Œä»–ä»¬æ‰§è¡Œçš„ä»£ç ä¹Ÿæ˜¯ç›¸åŒçš„ (ç±»æ¯”å¾ªç¯) ï¼Œä½†æ˜¯å­é—®é¢˜éœ€è¦æŠŠè®¡ç®—ç»“æœè¿”å›ç»™ä¸Šä¸€çº§ï¼Œè¿™æ›´é€‚åˆç”¨é€’å½’å®ç°ã€‚ ä¸ºä»€ä¹ˆè¿™æ ·å†™å°±ä¸€å®šèƒ½ç®—å‡ºæ­£ç¡®ç­”æ¡ˆï¼Ÿ ç”±äºå­é—®é¢˜çš„è§„æ¨¡æ¯”åŸé—®é¢˜å°ï¼Œä¸æ–­â€œé€’â€ä¸‹å»ï¼Œæ€»ä¼šæœ‰ä¸ªå°½å¤´ï¼Œå³é€’å½’çš„è¾¹ç•Œæ¡ä»¶ (base case)ï¼Œç›´æ¥è¿”å›å®ƒçš„ç­”æ¡ˆâ€œå½’â€ã€‚ ç±»ä¼¼äºæ•°å­¦å½’çº³æ³• (å¤šç±³è¯ºéª¨ç‰Œ) ï¼Œn=1æ—¶ ç±»ä¼¼è¾¹ç•Œæ¡ä»¶ï¼›n=m æ—¶ç±»ä¼¼å¾€åä»»æ„ä¸€ä¸ªèŠ‚ç‚¹ è®¡ç®—æœºæ˜¯æ€ä¹ˆæ‰§è¡Œé€’å½’çš„ï¼Ÿ å½“ç¨‹åºæ‰§è¡Œâ€œé€’â€åŠ¨ä½œæ—¶ï¼Œè®¡ç®—æœºä½¿ç”¨æ ˆä¿å­˜è¿™ä¸ªå‘å‡ºâ€œé€’â€åŠ¨ä½œçš„å¯¹è±¡ï¼Œç¨‹åºä¸æ–­â€œé€’â€ï¼Œè®¡ç®—æœºä¸æ–­å‹æ ˆï¼Œç›´åˆ°è¾¹ç•Œæ—¶ï¼Œç¨‹åºå‘ç”Ÿâ€œå½’â€åŠ¨ä½œï¼Œæ­£å¥½å°†æ‰§è¡Œçš„ç­”æ¡ˆâ€œå½’â€ç»™æ ˆé¡¶å…ƒç´ ï¼Œéšåç¨‹åºä¸æ–­â€œå½’â€ï¼Œè®¡ç®—æœºä¸æ–­å‡ºæ ˆï¼Œç›´åˆ°è¿”å›åŸé—®é¢˜çš„ç­”æ¡ˆï¼Œæ ˆç©ºã€‚ å¦ä¸€ç§é€’å½’æ€è·¯ ç»´æŠ¤å…¨å±€å˜é‡ï¼Œä½¿ç”¨äºŒå‰æ ‘éå†å‡½æ•°ï¼Œä¸æ–­æ›´æ–°å…¨å±€å˜é‡æœ€å¤§å€¼ 104. Maximum Depth of Binary Tree é¢˜ç›®ç½‘å€.\né€’å½’æ¨¡å‹ï¼šèŠ‚ç‚¹çš„æ·±åº¦ç­‰äºå…¶å·¦å­æ ‘å’Œå³å­æ ‘æ·±åº¦çš„æœ€å¤§å€¼åŠ ä¸Š 1 (å½“å‰èŠ‚ç‚¹æœ¬èº«). é€’å½’ç»ˆæ­¢æ¡ä»¶ï¼šå¦‚æœèŠ‚ç‚¹ä¸ºç©ºï¼Œè¿”å› 0. å¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œé€’å½’è®¡ç®—å·¦å­æ ‘å’Œå³å­æ ‘çš„æ·±åº¦ï¼Œç„¶åè¿”å›å…¶ä¸­æœ€å¤§å€¼ + 1. class Solution { public: int maxDepth(TreeNode* root) { if (root == nullptr) // base case return 0; // treeHight = max(leftTreeHeight, rightTreeHeight) + 1 int leftTreeHeight = maxDepth(root-\u0026gt;left); int rightTreeHeight = maxDepth(root-\u0026gt;right); return max(leftTreeHeight, rightTreeHeight) + 1; } }; äºŒå‰æ ‘çš„èŠ‚ç‚¹æ•°ä¸º Nï¼Œé€’å½’è¿‡ç¨‹ä¸­æ¯ä¸ªèŠ‚ç‚¹æ°å¥½è¢«è®¿é—®ä¸€æ¬¡ï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º $O(N)$. ç©ºé—´å¤æ‚åº¦å–å†³äºé€’å½’è°ƒç”¨æ ˆçš„æ·±åº¦ã€‚ä¸‹æœ€åæƒ…å†µäºŒå‰æ ‘ä¸ºä¸€ä¸ªå•é“¾è¡¨å½¢å¼çš„æ ‘æ ˆçš„æ·±åº¦ä¸º Nï¼Œå› æ­¤ç©ºé—´å¤æ‚åº¦ä¸º $O(N)$.\n111. Minimum Depth of Binary Tree é¢˜ç›®ç½‘å€. éœ€è¦ç‰¹åˆ«æ³¨æ„ï¼š\nå¶å­èŠ‚ç‚¹æ˜¯æ²¡æœ‰å­èŠ‚ç‚¹çš„èŠ‚ç‚¹ (å³ !node-\u0026gt;left \u0026amp;\u0026amp; !node-\u0026gt;right). å¦‚æœä¸€ä¸ªèŠ‚ç‚¹åªæœ‰ä¸€æ£µå­æ ‘ (å·¦å­æ ‘æˆ–å³å­æ ‘ä¸ºç©º) ï¼Œä¸èƒ½ç›´æ¥å–å¦ä¸€æ£µå­æ ‘çš„æ·±åº¦ï¼Œå› ä¸ºéå¶å­èŠ‚ç‚¹çš„æ·±åº¦ä¸å–å†³äºéå¶å­ å­èŠ‚ç‚¹ã€‚ class Solution { public: int minDepth(TreeNode* root) { if (!root) return 0; if (!root-\u0026gt;left) return minDepth(root-\u0026gt;right) + 1; // only has right if (!root-\u0026gt;right) return minDepth(root-\u0026gt;left) + 1; // only has left // left and right both exist return min(minDepth(root-\u0026gt;left), minDepth(root-\u0026gt;right)) + 1; } }; 112. Path Sum é¢˜ç›®ç½‘å€.\né€’å½’æ¨¡å‹ï¼šå·¦å­æ ‘æˆ–è€…æœ‰ä¸€æ¡å’Œä¸º targetSum - node-\u0026gt;val çš„è·¯å¾„ é€’å½’ç»ˆæ­¢æ¡ä»¶ï¼šå¦‚æœæ˜¯å¶å­èŠ‚ç‚¹ï¼Œåˆ™åˆ¤æ–­å…¶å€¼æ˜¯å¦ç­‰äº targetSum. å¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œé€’å½’è®¡ç®—å·¦å­æ ‘å’Œå³å­æ ‘çš„æ·±åº¦ï¼Œç„¶åè¿”å›å…¶ä¸­æœ€å¤§å€¼ + 1.\nclass Solution { public: bool hasPathSum(TreeNode* root, int targetSum) { if (!root) return false; if (!root-\u0026gt;left \u0026amp;\u0026amp; !root-\u0026gt;right) return root-\u0026gt;val == targetSum; return hasPathSum(root-\u0026gt;left, targetSum - root-\u0026gt;val) || hasPathSum(root-\u0026gt;right, targetSum - root-\u0026gt;val); } }; 129. Sum Root to leaf Numbers é¢˜ç›®ç½‘å€. è¿™é¢˜çš„æ€è·¯æœ‰ç‚¹åƒç§¦ä¹éŸ¶ç®—æ³•ï¼Œé€’å½’å‡½æ•° dfs åŠŸèƒ½æ˜¯è®¡ç®—ä»¥å½“å‰èŠ‚ç‚¹ä¸ºæ ¹çš„æ‰€æœ‰ä»æ ¹åˆ°å¶èŠ‚ç‚¹çš„è·¯å¾„æ•°å­—ä¹‹å’Œã€‚å¯¹äºå½“å‰èŠ‚ç‚¹ rootï¼Œæ–°çš„è·¯å¾„æ•°å­—ä¸º curr * 10 + root-\u0026gt;val.\nclass Solution { int dfs(TreeNode* root, int curr) { if (!root) return 0; curr = curr * 10 + root-\u0026gt;val; if (!root-\u0026gt;left \u0026amp;\u0026amp; !root-\u0026gt;right) return curr; return dfs(root-\u0026gt;left, curr) + dfs(root-\u0026gt;right, curr); } public: int sumNumbers(TreeNode* root) { return dfs(root, 0); } }; 1448. Count Good Nodes in Binary Tree é¢˜ç›®ç½‘å€.\né€’å½’æ¨¡å‹ï¼šæ ¹èŠ‚ç‚¹çš„å·¦å­æ ‘å¥½èŠ‚ç‚¹æ•°ç›®åŠ ä¸Šå³å­æ ‘å¥½èŠ‚ç‚¹æ•°ç›®åŠ ä¸Šå½“å‰èŠ‚ç‚¹æœ¬èº«æ˜¯ä¸æ˜¯ã€‚å‡½æ•°ä¼ å…¥ä¸€ä¸ªå˜é‡ä¸æ–­æ›´æ–°å½“å‰ç»è¿‡è·¯å¾„ä¸­çš„æœ€å¤§å€¼ã€‚ é€’å½’ç»ˆæ­¢æ¡ä»¶ï¼šå¦‚æœèŠ‚ç‚¹ä¸ºç©ºï¼Œè¿”å› 0. class Solution { int dfs(TreeNode* node, int curMax) { // left num + right num + if self if (!node) { return 0; } int isSelf = 0; if (curMax \u0026lt;= node-\u0026gt;val) { isSelf = 1; curMax = node-\u0026gt;val; } return dfs(node-\u0026gt;left, curMax) + dfs(node-\u0026gt;right, curMax) + isSelf; } public: int goodNodes(TreeNode* root) { return dfs(root, root-\u0026gt;val); } }; 987. Vertical Order Traversal of a Binary Tree é¢˜ç›®ç½‘å€. é¢˜ç›®å¯¹äºè¿”å›å€¼çš„è¦æ±‚ä¸ºæŒ‰åˆ—ç´¢å¼• col ä»å°åˆ°å¤§ã€‚åŒä¸€åˆ—å†…ï¼ŒèŠ‚ç‚¹æŒ‰è¡Œå· row å‡åºæ’åºï¼›è‹¥è¡Œå·ç›¸åŒï¼Œåˆ™æŒ‰èŠ‚ç‚¹å€¼ val å‡åºæ’åºã€‚æˆ‘ä»¬å¯ä»¥ç”¨é€’å½’æ–¹å¼éå†æ¯ä¸ªèŠ‚ç‚¹ï¼Œæ„å»ºä¸‰å…ƒç»„ (col, row, val). ç„¶åå¯¹è¿™ä¸ªä¸‰å…ƒç»„è¿›è¡Œæ’åºååˆ†ç»„æ„å»ºç­”æ¡ˆã€‚\nclass Solution { void dfs(TreeNode* root, vector\u0026lt;tuple\u0026lt;int, int, int\u0026gt;\u0026gt;\u0026amp; nodes, int row, int col) { if (!root) return; nodes.emplace_back(col, row, root-\u0026gt;val); // record (col, row, val) dfs(root-\u0026gt;left, nodes, row + 1, col - 1); dfs(root-\u0026gt;right, nodes, row + 1, col + 1); } public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; verticalTraversal(TreeNode* root) { vector\u0026lt;tuple\u0026lt;int, int, int\u0026gt;\u0026gt; nodes; // (col, row, val) dfs(root, nodes, 0, 0); sort(nodes.begin(), nodes.end()); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; if (nodes.empty()) return ans; ans.push_back({}); // first col int lastCol = get\u0026lt;0\u0026gt;(nodes[0]); // determin whether node is in another col ans.back().push_back(get\u0026lt;2\u0026gt;(nodes[0])); for (int i = 1; i \u0026lt; nodes.size(); ++i) { int col = get\u0026lt;0\u0026gt;(nodes[i]); int val = get\u0026lt;2\u0026gt;(nodes[i]); if (col != lastCol) { // another col ans.push_back({}); lastCol = col; } ans.back().push_back(val); } return ans; } }; 100. Same Tree é¢˜ç›®ç½‘å€.\né€’å½’æ¨¡å‹: ä¸¤æ£µæ ‘ç›¸åŒçš„æ¡ä»¶ä¸ºï¼Œå®ƒä»¬çš„å€¼ç›¸åŒå¹¶ä¸”å·¦å³å­æ ‘ä¹Ÿéƒ½ç›¸åŒã€‚ è¾¹ç•Œæ¡ä»¶: å¦‚æœå½“å‰ä¸¤ä¸ªæ ¹èŠ‚ç‚¹æœ‰ä¸€ä¸ªä¸ºç©ºï¼Œè‹¥ç›¸åŒåˆ™è¦æ±‚å¦ä¸€ä¸ªä¹Ÿä¸ºç©ºã€‚ class Solution { public: bool isSameTree(TreeNode* p, TreeNode* q) { if (!p || !q) { return p == q; } // 2 trees are same if their // val are same and left trees and right trees are all same return p-\u0026gt;val == q-\u0026gt;val \u0026amp;\u0026amp; isSameTree(p-\u0026gt;left, q-\u0026gt;left) \u0026amp;\u0026amp; isSameTree(p-\u0026gt;right, q-\u0026gt;right); } }; 101. Symmetric Tree é¢˜ç›®ç½‘å€.\né€’å½’æ¨¡å‹: ä¸€æ£µæ ‘å¯¹ç§°çš„æ¡ä»¶ä¸ºï¼Œå…¶å·¦å­æ ‘çš„å·¦å­æ ‘å’Œå³å­æ ‘çš„å³å­æ ‘ç›¸åŒå¹¶ä¸”å·¦å­æ ‘çš„å³å­æ ‘å’Œå³å­æ ‘çš„å·¦å­æ ‘ç›¸åŒã€‚æˆ‘ä»¬å¯¹ä¸Šä¸€é¢˜ä¼ å…¥çš„å‚æ•°ç¨åŠ ä¿®æ”¹ï¼Œå˜æˆæ¯”è¾ƒä¸€æ£µæ ‘çš„å·¦å­æ ‘å’Œå¦ä¸€æ£µæ ‘çš„å³å­æ ‘æ˜¯å¦ç›¸ç­‰ï¼Œå¹¶ä¸”å…¶å³å­æ ‘å’Œå¦ä¸€æ£µæ ‘çš„å·¦å­æ ‘ç›¸ç­‰ã€‚ è¾¹ç•Œæ¡ä»¶: å¦‚æœå½“å‰æœ‰ä¸€é¢—å­æ ‘ä¸ºç©ºï¼Œè‹¥å¯¹ç§°åˆ™è¦æ±‚å¦ä¸€ä¸ªä¹Ÿä¸ºç©ºã€‚ class Solution { bool isSameTree(TreeNode* p, TreeNode* q) { if (!p || !q) return p == q; return p-\u0026gt;val == q-\u0026gt;val \u0026amp;\u0026amp; isSameTree(p-\u0026gt;left, q-\u0026gt;right) \u0026amp;\u0026amp; isSameTree(p-\u0026gt;right, q-\u0026gt;left); } public: bool isSymmetric(TreeNode* root) { return isSameTree(root-\u0026gt;left, root-\u0026gt;right); } }; 110. Balanced Binary Tree [é¢˜ç›®ç½‘å€]é¢˜ç›®ç½‘å€.\né€’å½’æ¨¡å‹: å¹³è¡¡äºŒå‰æ ‘çš„å®šä¹‰å¤©ç„¶ç¬¦åˆé€’å½’ä½¿ç”¨æ¡ä»¶ï¼Œå¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œå·¦å³å­æ ‘çš„é«˜åº¦å·®ç»å¯¹å€¼ â‰¤ 1 å¹¶ä¸”å·¦å³å­æ ‘ä¹Ÿå¿…é¡»æ˜¯å¹³è¡¡äºŒå‰æ ‘ã€‚ å¯ä»¥é€šè¿‡é€’å½’è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„é«˜åº¦ï¼ŒåŒæ—¶æ£€æŸ¥æ˜¯å¦å¹³è¡¡ã€‚å¦‚æœå­æ ‘ä¸å¹³è¡¡ï¼Œè¿”å› -1 è¡¨ç¤ºä¸å¹³è¡¡ã€‚ ä¸å¹³è¡¡çš„æ¡ä»¶ä¸ºå·¦å³å­æ ‘æœ‰ä¸€é¢—ä¸å¹³è¡¡æˆ–è€…å½“å‰æ ¹èŠ‚ç‚¹çš„å·¦å³å­æ ‘é«˜åº¦ç›¸å·® \u0026gt; 1. è¾¹ç•Œæ¡ä»¶: å¦‚æœå½“å‰èŠ‚ç‚¹ä¸ºç©ºï¼Œè¿”å›å…¶é«˜åº¦ 0. class Solution { int getHeight(TreeNode* root) { // if not balanced return -1 if (!root) return 0; int leftHeight = getHeight(root-\u0026gt;left); int rightHeight = getHeight(root-\u0026gt;right); if (leftHeight == -1 || rightHeight == -1 || abs(leftHeight - rightHeight) \u0026gt; 1) return -1; return max(leftHeight, rightHeight) + 1; } public: bool isBalanced(TreeNode* root) { return getHeight(root) != -1; } }; 199. Binary Tree Right Side View é¢˜ç›®ç½‘å€. ä½¿ç”¨å‰åºéå†ï¼Œé€šè¿‡é€’å½’æ·±åº¦è·Ÿè¸ªå½“å‰èŠ‚ç‚¹çš„å±‚çº§ã€‚ å¦‚æœå½“å‰å±‚çº§æ·±åº¦ç­‰äºç»“æœæ•°ç»„çš„å¤§å°ï¼Œè¯´æ˜è¿™æ˜¯è¯¥å±‚ç¬¬ä¸€æ¬¡è®¿é—®çš„èŠ‚ç‚¹ï¼Œå°†å…¶å€¼åŠ å…¥ã€‚ ä¼˜å…ˆé€’å½’å³å­æ ‘ï¼Œç„¶åå·¦å­æ ‘ï¼Œç¡®ä¿æ¯å±‚æœ€å³èŠ‚ç‚¹ä¼˜å…ˆè¢«è®°å½•ã€‚\nclass Solution { void dfs(TreeNode* root, int d) { if (!root) return; if (d == ans.size()) ans.push_back(root-\u0026gt;val); dfs(root-\u0026gt;right, d + 1); dfs(root-\u0026gt;left, d + 1); } public: vector\u0026lt;int\u0026gt; ans; vector\u0026lt;int\u0026gt; rightSideView(TreeNode* root) { dfs(root, 0); return ans; } }; 965. é€’å½’æ¨¡å‹: å•å€¼äºŒå‰æ ‘çš„å·¦å³å­æ ‘ä¸€å®šä¹Ÿæ˜¯å•å€¼äºŒå‰æ ‘ã€‚å°†æ ¹èŠ‚ç‚¹çš„å€¼å±‚å±‚ä¸‹ä¼ è¿›è¡Œæ¯”å¯¹ã€‚ è¾¹ç•Œæ¡ä»¶: å¦‚æœå½“å‰èŠ‚ç‚¹ä¸ºç©ºï¼Œè¿”å› true. å¦åˆ™åˆ¤æ–­å½“å‰èŠ‚ç‚¹å€¼æ˜¯å¦ç­‰äº target. è‹¥ç›¸ç­‰å†é€’å½’åˆ¤æ–­å·¦å³å­æ ‘ã€‚ class Solution { bool dfs(TreeNode* root, int target) { if (!root) return true; if (root-\u0026gt;val != target) return false; return dfs(root-\u0026gt;left, target) \u0026amp;\u0026amp; dfs(root-\u0026gt;right, target); } public: bool isUnivalTree(TreeNode* root) { return dfs(root, root-\u0026gt;val); } }; 226. é€’å½’æ¨¡å‹: å¯¹äºä¸€æ£µå·²ç»ç¿»è½¬çš„äºŒå‰æ ‘ï¼Œå®ƒçš„å·¦å³å­æ ‘å’ŒåŸå…ˆç›¸æ¯”éƒ½æ˜¯ç¿»è½¬çš„ã€‚æˆ‘ä»¬ç¿»è½¬å½“å‰æ ¹èŠ‚ç‚¹çš„å·¦å³å­æ ‘åå°±è¿›è¡Œé€’å½’çš„ç¿»è½¬ã€‚ è¾¹ç•Œæ¡ä»¶: å¦‚æœå½“å‰èŠ‚ç‚¹ä¸ºç©ºï¼Œä¸ç”¨è¿›è¡Œç¿»è½¬ï¼Œè¿”å› nullptr. class Solution { public: TreeNode* invertTree(TreeNode* root) { if (!root) return nullptr; // reverse current root TreeNode * tmp = root-\u0026gt;left; root-\u0026gt;left = root-\u0026gt;right; root-\u0026gt;right = tmp; // recursive invertTree(root-\u0026gt;right); invertTree(root-\u0026gt;left); return root; } }; 617. é€’å½’æ¨¡å‹: åˆå¹¶åçš„äºŒå‰æ ‘çš„æ˜¯å¯¹å…¶å·¦å³å­æ ‘è¿›è¡Œåˆå¹¶åçš„ç»“æœã€‚ä¸¤èŠ‚ç‚¹å‡éç©ºæ—¶ï¼Œå°†ä¸¤ä¸ªèŠ‚ç‚¹çš„å€¼ç›¸åŠ ã€‚ ç„¶åé€’å½’åˆå¹¶å·¦å³å­æ ‘ï¼Œè¿™é‡Œé€‰æ‹©ç›´æ¥åˆå¹¶åˆ° root1 ä¸Šï¼Œå°†è¿”å›å€¼èµ‹å€¼ç»™ root1-\u0026gt;left å’Œ root1-\u0026gt;right. è¾¹ç•Œæ¡ä»¶: å½“ä¸€æ£µæ ‘ä¸ºç©ºæ—¶ï¼Œæ— éœ€ç»§ç»­åˆå¹¶ç›´æ¥è¿”å›å¦ä¸€æ£µæ ‘ã€‚ class Solution { public: TreeNode* mergeTrees(TreeNode* root1, TreeNode* root2) { if (!root1) return root2; if (!root2) return root1; // merge current node root1-\u0026gt;val += root2-\u0026gt;val; // merge to root1 root1-\u0026gt;left = mergeTrees(root1-\u0026gt;left, root2-\u0026gt;left); root1-\u0026gt;right = mergeTrees(root1-\u0026gt;right, root2-\u0026gt;right); return root1; } }; 1080. é€’å½’æ¨¡å‹: é€’å½’å‡½æ•°é‡‡ç”¨ååºéå†ï¼Œä¼ å…¥ä»æ ¹èŠ‚ç‚¹åˆ°å½“å‰èŠ‚ç‚¹ä¸ºæ­¢çš„å’Œã€‚é€’å½’å¤„ç†å·¦å³å­æ ‘ï¼Œè·å–å­æ ‘æ˜¯å¦æœ‰æ•ˆã€‚å¦‚æœå·¦å³å­æ ‘éƒ½è¢«åˆ é™¤è¯´æ˜å½“å‰èŠ‚ç‚¹æ— æœ‰æ•ˆè·¯å¾„ï¼Œåˆ é™¤å½“å‰èŠ‚ç‚¹ã€‚å¦åˆ™ï¼Œä¿ç•™èŠ‚ç‚¹ã€‚ è¾¹ç•Œæ¡ä»¶: å¦‚æœæ˜¯ç©ºèŠ‚ç‚¹ï¼Œè¿”å› nullptr. å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹ï¼Œæ£€æŸ¥è·¯å¾„å’Œ sum + node-\u0026gt;val \u0026lt; limit. å¦‚æœæ˜¯ï¼Œè¿”å› nullptr.å¦åˆ™è¿”å›è¯¥èŠ‚ç‚¹ã€‚ class Solution { TreeNode* dfs(TreeNode* root, int sum, int limit) { if (!root) return 0; if (!root-\u0026gt;left \u0026amp;\u0026amp; !root-\u0026gt;right) { if (root-\u0026gt;val + sum \u0026lt; limit) return nullptr; else return root; } root-\u0026gt;left = dfs(root-\u0026gt;left, sum + root-\u0026gt;val, limit); root-\u0026gt;right = dfs(root-\u0026gt;right, sum + root-\u0026gt;val, limit); if (!root-\u0026gt;left \u0026amp;\u0026amp; !root-\u0026gt;right) return nullptr; return root; } public: TreeNode* sufficientSubset(TreeNode* root, int limit) { return dfs(root, 0 , limit); } }; Binary Search Tree äºŒå‰æœç´¢æ ‘å®šä¹‰å¦‚ä¸‹ï¼š\nèŠ‚ç‚¹çš„å·¦å­æ ‘åªåŒ…å« ä¸¥æ ¼å°äº å½“å‰èŠ‚ç‚¹çš„æ•°ã€‚ èŠ‚ç‚¹çš„å³å­æ ‘åªåŒ…å« ä¸¥æ ¼å¤§äº å½“å‰èŠ‚ç‚¹çš„æ•°ã€‚ æ‰€æœ‰å·¦å­æ ‘å’Œå³å­æ ‘è‡ªèº«å¿…é¡»ä¹Ÿæ˜¯äºŒå‰æœç´¢æ ‘ 98. å‰åºéå†ï¼šå…ˆåˆ¤æ–­å†é€’å½’ï¼Œé€’å½’å‡½æ•°é™¤äº†è¦ä¼ å…¥æ ¹èŠ‚ç‚¹ä¹‹å¤–è¿˜è¦åœ¨ä¼ å…¥ä¸¤ä¸ªå€¼è¡¨ç¤ºå¼€åŒºé—´çš„èŒƒå›´ï¼Œå…ˆåˆ¤æ–­å½“å‰èŠ‚ç‚¹æ˜¯å¦åœ¨èŒƒå›´å†…ã€‚å¦‚æœæ˜¯åˆ™é€’å½’å·¦å­æ ‘ï¼Œå°†å¼€å±€é—´å³è¾¹ç•Œæ›¿æ¢ä¸ºå½“å‰èŠ‚ç‚¹çš„å€¼ã€‚ç„¶åå†é€’å½’å³å­æ ‘ï¼Œå°†å¼€å±€é—´å·¦è¾¹ç•Œæ›¿æ¢ä¸ºå½“å‰èŠ‚ç‚¹çš„å€¼ã€‚ ä¸­åºéå†ï¼šå…ˆé€’å½’éå†å·¦å­æ ‘ï¼Œå†è®¿é—®æ ¹èŠ‚ç‚¹ï¼Œå†é€’å½’éå†å³å­æ ‘å¾—åˆ°çš„æ˜¯ä¸€ä¸ªå‡åºçš„æ•°ç»„ã€‚å› æ­¤æˆ‘ä»¬è®°å½•è®¿é—®åˆ°çš„ä¸Šä¸€ä¸ªèŠ‚ç‚¹çš„å€¼ç„¶åè¿›è¡Œæ¯”è¾ƒã€‚ ååºéå†ï¼šå…ˆé€’å½’å†åˆ¤æ–­ã€‚ä»å­æ ‘å¼€å§‹éªŒè¯ï¼Œå‘ä¸Šæ±‡æ€»ä¿¡æ¯ã€‚æ¯ä¸ªèŠ‚ç‚¹è¿”å›å…¶å­æ ‘çš„æœ‰æ•ˆæ€§åŠå­æ ‘å€¼çš„èŒƒå›´ [min_val, max_val]. éå†å·¦å³å­æ ‘è·å–ä»–ä»¬çš„æœ€å°å€¼å’Œæœ€å¤§å€¼èŒƒå›´ï¼Œç„¶åæ£€æŸ¥å½“å‰èŠ‚ç‚¹æ˜¯å¦æ»¡è¶³å·¦å­æ ‘æœ€å¤§å€¼ \u0026lt; å½“å‰èŠ‚ç‚¹å€¼ \u0026lt; å³å­æ ‘æœ€å°å€¼ã€‚è‹¥ä¸æ»¡è¶³æ¡ä»¶ï¼Œè¿”å› {LLONG_MIN, LLONG_MAX} ç”¨äºè¿›è¡Œåˆ¤æ–­ï¼Œå¦åˆ™æ›´æ–°å½“å‰æ ¹èŠ‚ç‚¹çš„æœ€å°å€¼å’Œæœ€å¤§å€¼èŒƒå›´åè¿”å›ã€‚ class Solution { bool preOrder(TreeNode* root, long long left, long long right) { if (!root) return true; if (root-\u0026gt;val \u0026lt;= left || root-\u0026gt;val \u0026gt;= right) return false; return preOrder(root-\u0026gt;left, left, root-\u0026gt;val) \u0026amp;\u0026amp; preOrder(root-\u0026gt;right, root-\u0026gt;val, right); } bool midOrder(TreeNode* root, long long\u0026amp; pre) { // reference if (!root) return true; if (!midOrder(root-\u0026gt;left, pre)) return false; if (root-\u0026gt;val \u0026lt;= pre) return false; pre = root-\u0026gt;val; // record the previous node val. return midOrder(root-\u0026gt;right, pre); } pair\u0026lt;long long, long long\u0026gt; postOrder(TreeNode* root) { // return cur tree min, max if (!root) return {LLONG_MAX, LLONG_MIN}; auto[lMin, lMax] = postOrder(root-\u0026gt;left); if (root-\u0026gt;val \u0026lt;= lMax) return {LLONG_MIN, LLONG_MAX}; auto[rMin, rMax] = postOrder(root-\u0026gt;right); if (root-\u0026gt;val \u0026gt;= rMin) return {LLONG_MIN, LLONG_MAX}; return {min(lMin, (long long)root-\u0026gt;val), max(rMax, (long long)root-\u0026gt;val)}; } public: bool isValidBST(TreeNode* root) { //return preOrder(root, LLONG_MIN, LLONG_MAX); // long long x = LLONG_MIN; // return midOrder(root, x); return postOrder(root).second != LLONG_MAX; } }; 938. Range Sum of BST é¢˜ç›®ç½‘å€. ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œåˆ¤æ–­å½“å‰èŠ‚ç‚¹å€¼æ˜¯å¦åœ¨èŒƒå›´å†…ã€‚æ ¹æ® BST æ€§è´¨ï¼š\nå¦‚æœ val \u0026lt; lowï¼Œè·³è¿‡å·¦å­æ ‘ (å·¦å­æ ‘æ‰€æœ‰å€¼éƒ½ \u0026lt; low). å¦‚æœ val \u0026gt; highï¼Œè·³è¿‡å³å­æ ‘ (å³å­æ ‘æ‰€æœ‰å€¼éƒ½ \u0026gt; high). å¦åˆ™ï¼Œé€’å½’å¤„ç†å·¦å³å­æ ‘ï¼Œå¹¶ç´¯åŠ å½“å‰èŠ‚ç‚¹å€¼ã€‚ class Solution { public: int rangeSumBST(TreeNode* root, int low, int high) { if (!root) return 0; if (root-\u0026gt;val \u0026lt; low) return rangeSumBST(root-\u0026gt;right, low, high); if (root-\u0026gt;val \u0026gt; high) return rangeSumBST(root-\u0026gt;left, low, high); return root-\u0026gt;val + rangeSumBST(root-\u0026gt;left, low, high) + rangeSumBST(root-\u0026gt;right, low, high); } }; 105. Construct Binary Tree From Preorder and Inorder Traversal é¢˜ç›®ç½‘å€. å¯¹äºä»»æ„ä¸€é¢—æ ‘è€Œè¨€ï¼Œå‰åºéå†çš„å½¢å¼æ€»æ˜¯ [ æ ¹èŠ‚ç‚¹, [å·¦å­æ ‘çš„å‰åºéå†ç»“æœ], [å³å­æ ‘çš„å‰åºéå†ç»“æœ] ]. æ ¹èŠ‚ç‚¹æ€»æ˜¯å‰åºéå†ä¸­çš„ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ã€‚è€Œä¸­åºéå†çš„å½¢å¼æ€»æ˜¯ [ [å·¦å­æ ‘çš„ä¸­åºéå†ç»“æœ], æ ¹èŠ‚ç‚¹, [å³å­æ ‘çš„ä¸­åºéå†ç»“æœ] ]. æ ¹èŠ‚ç‚¹å°†ä¸­åºéå†åˆ†ä¸ºå·¦å­æ ‘å’Œå³å­æ ‘ä¸¤éƒ¨åˆ†ã€‚\næ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å‰åºéå†å¯ä»¥ç¡®å®šæ ¹èŠ‚ç‚¹ï¼Œé€šè¿‡ä¸­åºéå†å¯ä»¥ç¡®å®šå·¦å­æ ‘å’Œå³å­æ ‘çš„èŒƒå›´ã€‚\né€’å½’æ¨¡å‹: ä»å‰åºéå†çš„ç¬¬ä¸€ä¸ªå…ƒç´ å¾—åˆ°æ ¹èŠ‚ç‚¹ã€‚åœ¨ä¸­åºéå†ä¸­æ‰¾åˆ°æ ¹èŠ‚ç‚¹çš„ä½ç½®ï¼Œæ ¹èŠ‚ç‚¹å·¦ä¾§æ˜¯å·¦å­æ ‘ï¼Œå³ä¾§æ˜¯å³å­æ ‘ã€‚æ ¹æ®ä¸­åºéå†ä¸­å·¦å­æ ‘å’Œå³å­æ ‘çš„èŠ‚ç‚¹æ•°é‡ï¼Œåˆ†å‰²å‰åºéå†æ•°ç»„ï¼Œåˆ†åˆ«é€’å½’æ„å»ºå·¦å­æ ‘å’Œå³å­æ ‘ã€‚ä¸ºäº†å¿«é€Ÿæ‰¾åˆ°ä¸­åºéå†ä¸­æ ¹èŠ‚ç‚¹çš„ä½ç½®ï¼Œå¯ä»¥ä½¿ç”¨å“ˆå¸Œè¡¨å­˜å‚¨ä¸­åºéå†çš„å…ƒç´ åŠå…¶ç´¢å¼•ï¼Œé™ä½æ—¶é—´å¤æ‚åº¦ã€‚ è¾¹ç•Œæ¡ä»¶: æ˜¯å½“å­æ ‘èŒƒå›´ä¸ºç©ºæ—¶è¿”å› nullptr. æ—¶é—´å¤æ‚åº¦ï¼š$O(N)$ï¼Œå…¶ä¸­ N æ˜¯èŠ‚ç‚¹æ•°ã€‚å“ˆå¸Œè¡¨æŸ¥æ‰¾å’Œé€’å½’å¤„ç†æ¯ä¸ªèŠ‚ç‚¹ä¸€æ¬¡ã€‚ç©ºé—´å¤æ‚åº¦ï¼š$O(N)$ï¼Œç”¨äºå“ˆå¸Œè¡¨å’Œé€’å½’è°ƒç”¨æ ˆã€‚\nclass Solution { TreeNode* buildTreeHelper(vector\u0026lt;int\u0026gt;\u0026amp; preorder, int preStart, int preEnd, vector\u0026lt;int\u0026gt;\u0026amp; inorder, int inStart, int inEnd, unordered_map\u0026lt;int, int\u0026gt;\u0026amp; inorderMap) { if (preStart \u0026gt; preEnd || inStart \u0026gt; inEnd) return nullptr; // the first ele in preorder is root TreeNode* root = new TreeNode(preorder[preStart]); int rootIndex = inorderMap[root-\u0026gt;val]; int leftTreeNum = rootIndex - inStart; root-\u0026gt;left = buildTreeHelper(preorder, preStart + 1, preStart + leftTreeNum, inorder, inStart, rootIndex - 1, inorderMap); root-\u0026gt;right = buildTreeHelper(preorder, preStart + leftTreeNum + 1, preEnd, inorder, rootIndex + 1, inEnd, inorderMap); return root; } public: TreeNode* buildTree(vector\u0026lt;int\u0026gt;\u0026amp; preorder, vector\u0026lt;int\u0026gt;\u0026amp; inorder) { // record the index in the inorder unordered_map\u0026lt;int, int\u0026gt; inorderMap; for (int i = 0; i \u0026lt; inorder.size(); i++) inorderMap[inorder[i]] = i; return buildTreeHelper(preorder, 0, preorder.size() - 1, inorder, 0, inorder.size() - 1, inorderMap); } }; 106. Construct Binary Tree From Inorder and Postorder Traversal é¢˜ç›®ç½‘å€. æ€è·¯å’Œä¸Šä¸€é¢˜ç›¸åŒï¼Œååºéå†çš„å½¢å¼æ€»æ˜¯ [ [å·¦å­æ ‘çš„å‰åºéå†ç»“æœ], [å³å­æ ‘çš„å‰åºéå†ç»“æœ], æ ¹èŠ‚ç‚¹ ]. å–å‡ºååºéå†æœ€åä¸€ä¸ªå…ƒç´ ä½œä¸ºæ ¹èŠ‚ç‚¹ä¹‹åé€šè¿‡ä¸­åºéå†ç¡®å®šå…¶å·¦å³å­æ ‘çš„æ•°ç›®ã€‚\nclass Solution { unordered_map\u0026lt;int, int\u0026gt; inorderMap; TreeNode* buildTreeHelper(vector\u0026lt;int\u0026gt;\u0026amp; inorder, int inStart, int inEnd, vector\u0026lt;int\u0026gt;\u0026amp; postorder, int postStart, int postEnd ) { if (inStart \u0026gt; inEnd) return nullptr; TreeNode* root = new TreeNode(postorder[postEnd]); int rootIndex = inorderMap[root-\u0026gt;val]; int leftTreeNum = rootIndex - inStart; root-\u0026gt;left = buildTreeHelper(inorder, inStart, rootIndex - 1, postorder, postStart, postStart + leftTreeNum - 1); root-\u0026gt;right = buildTreeHelper(inorder, rootIndex + 1, inEnd, postorder, postStart + leftTreeNum, postEnd - 1); return root; } public: TreeNode* buildTree(vector\u0026lt;int\u0026gt;\u0026amp; inorder, vector\u0026lt;int\u0026gt;\u0026amp; postorder) { //unordered_map\u0026lt;int, int\u0026gt; inorderMap; for (int i = 0; i \u0026lt; inorder.size(); i++) inorderMap[inorder[i]] = i; return buildTreeHelper(inorder, 0, inorder.size() - 1, postorder, 0, postorder.size() - 1); } }; 889. Construct Binary Tree From Preorder and Postorder Traversal é¢˜ç›®ç½‘å€. å¦‚æœåªçŸ¥é“å‰åºéå†å’Œååºéå†ï¼Œè¿™æ£µäºŒå‰æ ‘ä¸ä¸€å®šæ˜¯å”¯ä¸€çš„ã€‚å› ä¸ºæˆ‘ä»¬æ— æ³•ç¡®å®šå·¦å³å­æ ‘çš„è¾¹ç•Œåœ¨å“ªã€‚è¿™é‡Œå‡è®¾ preorder[preStart + 1] (å³å‰åºéå†çš„ç¬¬äºŒä¸ªå…ƒç´ ) æ˜¯å·¦å­æ ‘çš„æ ¹èŠ‚ç‚¹ï¼Œå¹¶æ‰¾åˆ°å…¶åœ¨ååºéå†ä¸­çš„ä½ç½®æ¥åˆ†å‰²å­æ ‘ã€‚è¿™æ ·é—®é¢˜å°±è½¬æ¢æˆä¹‹å‰ä¸¤é¢˜çš„å½¢å¼ï¼Œ\nclass Solution { unordered_map\u0026lt;int, int\u0026gt; postorderMap; TreeNode* helper(vector\u0026lt;int\u0026gt;\u0026amp; preorder, int preStart, int preEnd, vector\u0026lt;int\u0026gt;\u0026amp; postorder, int postStart, int postEnd) { if (preStart \u0026gt; preEnd) return nullptr; TreeNode* root = new TreeNode(preorder[preStart]); if (preStart == preEnd) return root; int leftVal = preorder[preStart + 1]; // assume preorder[1] is root-\u0026gt;left int leftIndex = postorderMap[leftVal]; int leftTreeNum = leftIndex - postStart + 1; root-\u0026gt;left = helper(preorder, preStart + 1, preStart + leftTreeNum, postorder, postStart, postStart + leftTreeNum - 1); root-\u0026gt;right = helper(preorder, preStart+ leftTreeNum + 1, preEnd, postorder, postStart + leftTreeNum, postEnd - 1); return root; } public: TreeNode* constructFromPrePost(vector\u0026lt;int\u0026gt;\u0026amp; preorder, vector\u0026lt;int\u0026gt;\u0026amp; postorder) { for (int i = 0; i \u0026lt; postorder.size(); i++) { postorderMap[postorder[i]] = i; } return helper(preorder, 0, preorder.size() - 1, postorder, 0, postorder.size() - 1); } }; 1110. Delete Nodes and Return Forest é¢˜ç›®ç½‘å€. è¿™é“é¢˜å¾ˆè‡ªç„¶çš„è¦æƒ³åˆ°ä½¿ç”¨ååºéå†ï¼Œå› ä¸ºå¦‚æœå…ˆåˆ é™¤äº†æ ¹èŠ‚ç‚¹ï¼Œæˆ‘ä»¬æ— æ³•è¿½è¸ªå®ƒçš„å·¦å³å­æ ‘æ˜¯å¦éœ€è¦è¢«åˆ é™¤ã€‚æ‰€ä»¥æˆ‘ä»¬å…ˆåˆ é™¤å…¶å·¦å³å­æ ‘ï¼Œå†åˆ¤æ–­å½“å‰èŠ‚ç‚¹æ˜¯å¦éœ€è¦åˆ é™¤ã€‚è‹¥éœ€è¦åˆ é™¤å°†è¿”å›ä¸ºéç©ºçš„å·¦å³å­æ ‘åŠ å…¥ç­”æ¡ˆï¼Œè¿”å› nullptr. å¦åˆ™è¿”å›æ ¹èŠ‚ç‚¹.\næ³¨æ„é€’å½’ç»“æŸåæˆ‘ä»¬éœ€è¦åˆ¤æ–­é¢˜ç›®æœ¬èº«çš„è·Ÿæ ¹èŠ‚ç‚¹æ˜¯å¦éœ€è¦è¢«åˆ é™¤ï¼Œå¦‚æœä¸ä¼šè¢«åˆ é™¤ä¹Ÿè¦å°†å…¶åŠ å…¥ç­”æ¡ˆã€‚\nclass Solution { vector\u0026lt;TreeNode*\u0026gt; ans; std::unordered_set\u0026lt;int\u0026gt; hashSet; TreeNode* dfs(TreeNode* root) { if (!root) return nullptr; root-\u0026gt;left = dfs(root-\u0026gt;left); root-\u0026gt;right = dfs(root-\u0026gt;right); // if current root need to be deleted, // append its no empty left and right to ans if (hashSet.find(root-\u0026gt;val) != hashSet.end()) { if (root-\u0026gt;left) ans.push_back(root-\u0026gt;left); if (root-\u0026gt;right) ans.push_back(root-\u0026gt;right); return nullptr; } return root; } public: vector\u0026lt;TreeNode*\u0026gt; delNodes(TreeNode* root, vector\u0026lt;int\u0026gt;\u0026amp; to_delete) { hashSet = std::unordered_set\u0026lt;int\u0026gt;(to_delete.begin(), to_delete.end()); if (dfs(root)) ans.push_back(root); return ans; } }; 236. Lowest Common Ancestor of a Binary Tree é¢˜ç›®åœ°å€. é¢˜ç›®è¦æ±‚æ‰¾æœ€è¿‘çš„å…¬å…±ç¥–å…ˆï¼Œæ‰€ä»¥é€’å½’çš„æ—¶å€™æˆ‘ä»¬è¦è‡ªåº•å‘ä¸Šã€‚\nå¯¹äºå½“å‰èŠ‚ç‚¹ rootï¼Œé€’å½’æ£€æŸ¥å·¦å³å­æ ‘ï¼š\nå¦‚æœå½“å‰èŠ‚ç‚¹ä¸ºç©ºï¼Œç›´æ¥è¿”å› nullptr. å¦‚æœ p æˆ– q ç­‰äºå½“å‰èŠ‚ç‚¹ï¼Œåˆ™å½“å‰èŠ‚ç‚¹æ˜¯å€™é€‰èŠ‚ç‚¹ï¼Œç›´æ¥è¿”å› root. å¦‚æœä¸‹é¢æœ‰ q æˆ– pï¼Œé‚£ä¹ˆå½“å‰èŠ‚ç‚¹å°±æ˜¯æœ€è¿‘å…¬å…±ç¥–å…ˆï¼Œç›´æ¥è¿”å›å½“å‰èŠ‚ç‚¹ã€‚å¦‚æœä¸‹é¢æ²¡æœ‰ q å’Œ pï¼Œé‚£æ—¢ç„¶éƒ½æ²¡æœ‰è¦æ‰¾çš„èŠ‚ç‚¹äº†ï¼Œä¹Ÿä¸éœ€è¦é€’å½’ï¼Œç›´æ¥è¿”å›å½“å‰èŠ‚ç‚¹ã€‚\né€’å½’æŸ¥è¯¢å·¦å­æ ‘å’Œå³å­æ ‘ï¼Œåˆ†åˆ«è¿”å›å·¦å­æ ‘å’Œå³å­æ ‘ä¸­æ˜¯å¦æ‰¾åˆ° p æˆ– q. å¦‚æœå·¦å³å­æ ‘éƒ½æ‰¾æ‰¾åˆ° p æˆ– qï¼Œåˆ™å½“å‰èŠ‚ç‚¹ root æ˜¯ LCA. å¦‚æœä»…åœ¨å·¦å­æ ‘æˆ–å³å­æ ‘æ‰¾åˆ° p æˆ– qï¼Œåˆ™è¿”å›æ‰¾åˆ°çš„é‚£ä¸ªèŠ‚ç‚¹ã€‚ å¦‚æœå·¦å³å­æ ‘éƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å› nullptr. è¿”å›å€¼çš„å‡†ç¡®å«ä¹‰æ˜¯ã€Œæœ€è¿‘å…¬å…±ç¥–å…ˆçš„å€™é€‰é¡¹ã€ã€‚å¯¹äºæœ€å¤–å±‚çš„é€’å½’è°ƒç”¨è€…æ¥è¯´ï¼Œè¿”å›å€¼æ˜¯æœ€è¿‘å…¬å…±ç¥–å…ˆçš„æ„æ€ã€‚ä½†æ˜¯ï¼Œåœ¨é€’å½’è¿‡ç¨‹ä¸­ï¼Œè¿”å›å€¼å¯èƒ½æ˜¯æœ€è¿‘å…¬å…±ç¥–å…ˆï¼Œä¹Ÿå¯èƒ½æ˜¯ç©ºèŠ‚ç‚¹ (è¡¨ç¤ºå­æ ‘å†…æ²¡æ‰¾åˆ°ä»»ä½•æœ‰ç”¨ä¿¡æ¯)ã€èŠ‚ç‚¹ p æˆ–è€…èŠ‚ç‚¹ q (å¯èƒ½æˆä¸ºæœ€è¿‘å…¬å…±ç¥–å…ˆï¼Œæˆ–è€…ç”¨æ¥è¾…åŠ©åˆ¤æ–­ä¸Šé¢çš„æŸä¸ªèŠ‚ç‚¹æ˜¯å¦ä¸ºæœ€è¿‘å…¬å…±ç¥–å…ˆ).\nclass Solution { public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) { // if we can find p or q in its subtree, then root is a candidate // otherwise no need to continue recursiving. if (!root || root == p || root == q) return root; TreeNode* left = lowestCommonAncestor(root-\u0026gt;left, p, q); TreeNode* right = lowestCommonAncestor(root-\u0026gt;right, p, q); if (left \u0026amp;\u0026amp; right) // current node is a candidate return root; return left ? left : right; } }; 235. Lowest Common Ancestor of a Binary Search Tree é¢˜ç›®åœ°å€. è·Ÿä¸Šé¢˜æ€è·¯ä¸€æ ·ï¼Œåªä¸è¿‡æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ BST çš„æ€§è´¨ï¼Œå¦‚æœå½“å‰èŠ‚ç‚¹çš„å€¼å¤§äº (å°äº) p å’Œ q çš„å€¼å°±å¯ä»¥åªç”¨åœ¨å…¶å·¦ (å³) å­æ ‘ä¸­è¿›è¡Œé€’å½’ï¼›\nclass Solution { public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) { if (!root || root == p || root == q) return root; TreeNode *left = nullptr, *right = nullptr; if (root-\u0026gt;val \u0026gt; p-\u0026gt;val \u0026amp;\u0026amp; root-\u0026gt;val \u0026gt; q-\u0026gt;val) { // only need find left subtree left = lowestCommonAncestor(root-\u0026gt;left, p, q); } else if (root-\u0026gt;val \u0026lt; p-\u0026gt;val \u0026amp;\u0026amp; root-\u0026gt;val \u0026lt; q-\u0026gt;val) { // only need find right subtree right = lowestCommonAncestor(root-\u0026gt;right, p, q); } else { left = lowestCommonAncestor(root-\u0026gt;left, p, q); right = lowestCommonAncestor(root-\u0026gt;left, p, q); } if (left \u0026amp;\u0026amp; right) // current node is a candidate return root; return left ? left : right; } }; 1123. Lowest Common Ancestor of Deepest Leaves é¢˜ç›®åœ°å€. é¢˜ç›®ä¸­æ‰€è¯´æœ€æ·±å¶å­èŠ‚ç‚¹çš„æœ€è¿‘å…¬å…±ç¥–å…ˆæ„æ€æ˜¯åŒ…å«æ‰€æœ‰æœ€æ·±å¶å­èŠ‚ç‚¹çš„æœ€å°å­æ ‘çš„æ ¹èŠ‚ç‚¹ã€‚ æˆ‘ä»¬ä¸€æ ·ä½¿ç”¨ååºéå†è‡ªåº•å‘ä¸Šè®¿é—®ï¼Œå¯¹äºä»»æ„ä¸€ä¸ªèŠ‚ç‚¹ node:\nå¦‚æœ node çš„å·¦å­æ ‘åŒ…å«æ‰€æœ‰æœ€æ·±çš„å¶å­èŠ‚ç‚¹ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥åœ¨å·¦å­æ ‘é‡Œç»§ç»­å¯»æ‰¾ç­”æ¡ˆã€‚ å¦‚æœ node çš„å³å­æ ‘åŒ…å«æ‰€æœ‰æœ€æ·±çš„å¶å­èŠ‚ç‚¹ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥åœ¨å³å­æ ‘é‡Œç»§ç»­å¯»æ‰¾ç­”æ¡ˆã€‚ å¦‚æœ node çš„å·¦ã€å³å­æ ‘éƒ½åŒ…å«äº†æœ€æ·±çš„å¶å­èŠ‚ç‚¹ (ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ€æ·±çš„å¶å­èŠ‚ç‚¹åˆ†å¸ƒåœ¨å·¦å³ä¸¤ä¾§)ï¼Œé‚£ä¹ˆè¿™ä¸ª node æœ¬èº«å°±æ˜¯æˆ‘ä»¬è¦æ‰¾çš„ç­”æ¡ˆâ€”â€”æœ€è¿‘å…¬å…±ç¥–å…ˆã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡å­æ ‘çš„æ·±åº¦æ¥åˆ¤æ–­å±äºä»¥ä¸Šå“ªç§æƒ…å†µã€‚å¯¹äºä¸€ä¸ªèŠ‚ç‚¹ nodeï¼Œæˆ‘ä»¬è®¡ç®—å®ƒå·¦å­æ ‘çš„æœ€å¤§æ·±åº¦ left_depth å’Œå³å­æ ‘çš„æœ€å¤§æ·±åº¦ right_depth.\nå¦‚æœ left_depth \u0026gt; right_depthï¼Œè¯´æ˜è¿™ä¸ªå­æ ‘é‡Œæœ€æ·±çš„å¶å­åªå­˜åœ¨äºå·¦è¾¹ã€‚ å¦‚æœ right_depth \u0026gt; left_depthï¼Œè¯´æ˜è¿™ä¸ªå­æ ‘é‡Œæœ€æ·±çš„å¶å­åªå­˜åœ¨äºå³è¾¹ã€‚ å¦‚æœ left_depth == right_depthï¼Œè¯´æ˜æœ€æ·±çš„å¶å­åˆ†å¸ƒåœ¨å·¦å³ä¸¤è¾¹ï¼Œé‚£ä¹ˆå½“å‰èŠ‚ç‚¹ node å°±æ˜¯å…¶å­æ ‘èŒƒå›´å†…æœ€æ·±å¶å­çš„ LCA. å› æ­¤è®¾è®¡çš„é€’å½’å‡½æ•°éœ€è¦è¿”å›ä¸¤ä¸ªä¿¡æ¯:\nå½“å‰ node ä¸ºæ ¹çš„å­æ ‘ä¸­ï¼Œæœ€æ·±å¶å­èŠ‚ç‚¹çš„ LCA æ˜¯è°ã€‚ å½“å‰ node ä¸ºæ ¹çš„å­æ ‘çš„æœ€å¤§æ·±åº¦æ˜¯å¤šå°‘ã€‚ class Solution { pair\u0026lt;TreeNode*, int\u0026gt; dfs(TreeNode* root) { if (!root) return pair\u0026lt;TreeNode*, int\u0026gt;{nullptr, 0}; auto[leftLca, leftDepth] = dfs(root-\u0026gt;left); auto[rightLca, rightDepth] = dfs(root-\u0026gt;right); if (leftDepth \u0026gt; rightDepth) { return pair\u0026lt;TreeNode*, int\u0026gt;{leftLca, leftDepth + 1}; } else if (leftDepth \u0026lt; rightDepth) { return pair\u0026lt;TreeNode*, int\u0026gt;{rightLca, rightDepth + 1}; } else { return pair\u0026lt;TreeNode*, int\u0026gt;{root, rightDepth + 1}; } } public: pair\u0026lt;TreeNode*, int\u0026gt; dfs(TreeNode* root) { if (!root) return pair\u0026lt;TreeNode*, int\u0026gt;{nullptr, 0}; auto[leftLca, leftDepth] = dfs(root-\u0026gt;left); auto[rightLca, rightDepth] = dfs(root-\u0026gt;right); if (leftDepth \u0026gt; rightDepth) { return pair\u0026lt;TreeNode*, int\u0026gt;{leftLca, leftDepth + 1}; } else if (leftDepth \u0026lt; rightDepth) { return pair\u0026lt;TreeNode*, int\u0026gt;{rightLca, rightDepth + 1}; } else { return pair\u0026lt;TreeNode*, int\u0026gt;{root, rightDepth + 1}; } } TreeNode* lcaDeepestLeaves(TreeNode* root) { return dfs(root).first; } }; 2096. Step-By-Step Directions From a Binary Tree Node to Another é¢˜ç›®åœ°å€. åœ¨äºŒå‰æ ‘ä¸­ï¼Œä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„å¿…ç„¶ç»è¿‡å®ƒä»¬çš„ LCA. ä¸¤ç‚¹ä¹‹é—´çš„è·¯å¾„å¯ä»¥åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š\nä» startValue å‘ä¸Šåˆ° LCA (å…¨æ˜¯ \u0026lsquo;U\u0026rsquo;)ã€‚ ä» LCA å‘ä¸‹åˆ° destValue (å…¨æ˜¯ \u0026lsquo;L\u0026rsquo; æˆ– \u0026lsquo;R\u0026rsquo;)ã€‚ æ•´ä½“æµç¨‹ä¸º\nä½¿ç”¨ DFS åˆ†åˆ«æ‰¾åˆ°ä»æ ¹åˆ° startValue å’Œä»æ ¹åˆ° destValue çš„è·¯å¾„ (è®°å½• \u0026lsquo;L\u0026rsquo; å’Œ \u0026lsquo;R\u0026rsquo;). æ¯”è¾ƒä¸¤æ¡è·¯å¾„ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸åŒçš„ä½ç½® (å¯¹åº” LCA çš„å­æ ‘åˆ†å‰ç‚¹)ã€‚ å¯¹äº startValue åˆ° LCA çš„è·¯å¾„ï¼Œè½¬æ¢ä¸º \u0026lsquo;U\u0026rsquo; (å› ä¸ºéœ€è¦å‘ä¸Šèµ°). å¯¹äº LCA åˆ° destValue çš„è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨ \u0026lsquo;L\u0026rsquo; å’Œ \u0026lsquo;R\u0026rsquo;. class Solution { string ans; bool findPath(TreeNode* root, int val, string\u0026amp; path) { if (!root) return false; if (root-\u0026gt;val == val) return true; // try left tree path.push_back(\u0026#39;L\u0026#39;); if (findPath(root-\u0026gt;left, val, path)) return true; path.pop_back(); // try right tree path.push_back(\u0026#39;R\u0026#39;); if (findPath(root-\u0026gt;right, val, path)) return true; path.pop_back(); return false; } public: string getDirections(TreeNode* root, int startValue, int destValue) { string startPath, destPath, ans; findPath(root, startValue, startPath); findPath(root, destValue, destPath); int cnt = 0; int len = min(startPath.size(), destPath.size()); for (int i = 0; i \u0026lt; len; i++) { if (startPath[i] != destPath[i]) break; cnt++; } // substitute path from start to LCA with U ans = string(startPath.size() - cnt, \u0026#39;U\u0026#39;); // add remaining L and R from LCA to dest ans += destPath.substr(cnt); return ans; } }; ","permalink":"http://localhost:1313/blogs/leetcode/05_binarytree/","summary":"Algorithm questions about binary tree.","title":"05 Binary Tree"},{"content":"List Reverse Questions 206. Reverse Linked List é¢˜ç›®ç½‘å€.\næ€è·¯å¾ˆç®€å•ï¼Œåˆ©ç”¨ä¸‰ä¸ªæŒ‡é’ˆè¿›è¡Œåè½¬ï¼Œæ³¨æ„ç§»åŠ¨çš„é¡ºåºï¼Œå…ˆç§»åŠ¨ pre å†ç§»åŠ¨ cur. é“¾è¡¨çš„å®šä¹‰å¦‚ä¸‹ï¼Œåç»­é¢˜ç›®ä¸å†é‡å¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */ class Solution { public: ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr; ListNode* cur = head; while (cur) { // not reach the end ListNode* next = cur-\u0026gt;next; // record next node to reverse // be care about order cur-\u0026gt;next = pre; pre = cur; cur = next; } return pre; } }; 92. Reverse Linked List II é¢˜ç›®ç½‘å€.\nå®šä½åè½¬åŒºé—´çš„å‰é©±èŠ‚ç‚¹:\nä½¿ç”¨ä¸€ä¸ªå“‘èŠ‚ç‚¹ (dummy node) æŒ‡å‘å¤´èŠ‚ç‚¹ï¼Œä»¥ä¾¿å¤„ç†åè½¬ä»å¤´èŠ‚ç‚¹å¼€å§‹çš„æƒ…å†µï¼Œæ­¤æ—¶åè½¬ååŸå¤´èŠ‚ç‚¹ä¼šå˜æˆåè½¬åŒºé—´çš„å°¾èŠ‚ç‚¹ã€‚éå†é“¾è¡¨ï¼Œæ‰¾åˆ°ç¬¬ left-1 ä¸ªèŠ‚ç‚¹ (å³åè½¬åŒºé—´çš„å‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œè®°ä¸º p0).\nåè½¬æŒ‡å®šåŒºé—´:\nä»ç¬¬ left ä¸ªèŠ‚ç‚¹åˆ°ç¬¬ right ä¸ªèŠ‚ç‚¹è¿›è¡Œåè½¬ï¼Œç±»ä¼¼äºåè½¬æ•´ä¸ªé“¾è¡¨çš„é€»è¾‘ï¼Œä½†åªæ“ä½œæŒ‡å®šåŒºé—´ã€‚ä½¿ç”¨ä¸‰ä¸ªæŒ‡é’ˆ (preã€curã€next) è¿›è¡Œå±€éƒ¨åè½¬ï¼š\ncur æŒ‡å‘å½“å‰å¤„ç†çš„èŠ‚ç‚¹ã€‚ next ä¿å­˜ cur çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚ å°† cur çš„ next æŒ‡å‘ preï¼Œå®ç°åè½¬ã€‚ ç§»åŠ¨æŒ‡é’ˆï¼špre ç§»åˆ° curï¼Œcur ç§»åˆ° nextï¼Œé‡å¤ç›´åˆ°åè½¬ right - left + 1 æ¬¡ã€‚ è¿æ¥åè½¬åçš„åŒºé—´:\nåè½¬å®Œæˆåï¼Œp0-\u0026gt;next æŒ‡å‘åè½¬åçš„åŒºé—´å¤´èŠ‚ç‚¹ (å³åŸæ¥çš„ç¬¬ right èŠ‚ç‚¹) ã€‚åè½¬åŒºé—´çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ (åŸæ¥çš„ç¬¬ left èŠ‚ç‚¹) è¿æ¥åˆ°å‰©ä½™çš„é“¾è¡¨éƒ¨åˆ†ã€‚\nè¿”å› dummy.next.\næ—¶é—´å¤æ‚åº¦: $O(n)$ï¼Œå…¶ä¸­ n æ˜¯é“¾è¡¨é•¿åº¦ï¼Œéå†ä¸€æ¬¡å®šä½åŒºé—´ï¼Œå†åè½¬æŒ‡å®šåŒºé—´ã€‚ ç©ºé—´å¤æ‚åº¦: $O(1)$ï¼Œåªä½¿ç”¨äº†å¸¸æ•°é¢å¤–ç©ºé—´ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Solution { public: ListNode* reverseBetween(ListNode* head, int left, int right) { // initialize a dummy node to handle from head ListNode dummy(0, head); ListNode* pre = \u0026amp;dummy; int cnt = 0; while (cnt \u0026lt; left - 1) { pre = pre-\u0026gt;next; cnt++; } ListNode* p0 = pre; // record the previous node of the node to be reversed pre = nullptr; ListNode* cur = p0-\u0026gt;next; ListNode* next = cur-\u0026gt;next; while (cnt \u0026lt; right) { next = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = next; cnt++; } p0-\u0026gt;next-\u0026gt;next = cur; p0-\u0026gt;next = pre; return dummy.next; // handle reverse from head } }; 25. Reverse Nodes in k Group é¢˜ç›®ç½‘å€.\néå†ä¸€éé“¾è¡¨ï¼Œå¾—åˆ°æ€»é•¿åº¦ï¼Œè¿™æ ·åç»­å¯ä»¥å¾ˆæ–¹ä¾¿åœ°åˆ¤æ–­å‰©ä½™èŠ‚ç‚¹æ˜¯å¦è¶³å¤Ÿå½¢æˆä¸€ä¸ª k å¤§å°çš„åˆ†ç»„ã€‚ å’Œä¸Šä¸€é¢˜ä¸€æ ·ä½¿ç”¨ä¸€ä¸ª dummy èŠ‚ç‚¹ä½œä¸ºè™šæ‹Ÿå¤´èŠ‚ç‚¹ï¼Œè¿™æå¤§åœ°ç®€åŒ–äº†å¯¹é“¾è¡¨å¤´éƒ¨çš„æ“ä½œï¼Œæ— éœ€ä¸ºç¬¬ä¸€ä¸ª k åˆ†ç»„ç¼–å†™ç‰¹æ®Šçš„å¤„ç†é€»è¾‘ã€‚ è¿›å…¥ä¸»å¾ªç¯ï¼Œåªè¦å‰©ä½™èŠ‚ç‚¹æ•° len å¤§äºç­‰äº kï¼Œå°±å¤„ç†ä¸€ä¸ªåˆ†ç»„ã€‚åœ¨å¾ªç¯å†…éƒ¨ï¼Œé€šè¿‡ä¸€ä¸ª for å¾ªç¯æ¥ç¿»è½¬ k ä¸ªèŠ‚ç‚¹ï¼Œå¹¶åœ¨ for å¾ªç¯ç»“æŸåï¼Œç«‹å³å°†è¿™ä¸ªç¿»è½¬å¥½çš„åˆ†ç»„ä¸é“¾è¡¨çš„å‰åéƒ¨åˆ†è¿æ¥èµ·æ¥ã€‚ä¸Šä¸€ä¸ªåŒºé—´çš„å¼€å¤´åè½¬ååœ¨æœ«å°¾ï¼Œå³ä¸ºä¸‹ä¸€ä¸ªåŒºé—´çš„ p0. æˆ‘ä»¬è¦æå‰è®°å½•ä¸‹å®ƒå†å°†åè½¬å¥½çš„å­é“¾è¡¨æ¥å…¥ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class Solution { public: ListNode* reverseKGroup(ListNode* head, int k) { int len = 0; ListNode* cur = head; while (cur) { // record the list length len++; cur = cur-\u0026gt;next; } ListNode dummy(0, head); ListNode* p0 = \u0026amp;dummy, *pre = \u0026amp;dummy; cur = pre-\u0026gt;next; while (len \u0026gt;= k) { len -= k; for (int i = 0; i \u0026lt; k; i++) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = next; } // ä¸Šä¸€ä¸ªåŒºé—´çš„å¼€å¤´åè½¬ååœ¨æœ«å°¾ï¼Œå³ä¸ºä¸‹ä¸€ä¸ªåŒºé—´çš„ p0 ListNode* next_p0 = p0-\u0026gt;next; p0-\u0026gt;next-\u0026gt;next = cur; p0-\u0026gt;next = pre; p0 = next_p0; } return dummy.next; } }; 24. Swap Nodes in Pairs é¢˜ç›®ç½‘å€. æ€è·¯å¾ˆç®€å•ï¼Œç”¨ä¸‰ä¸ªæŒ‡é’ˆå°±å¯ä»¥å®Œæˆä¸€å¯¹çš„äº¤æ¢ï¼Œæ³¨æ„åˆ¤æ–­æ¡ä»¶ä¸º cur \u0026amp;\u0026amp; cur-\u0026gt;nextï¼Œå¦åˆ™ä¸ç”¨äº¤æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution { public: ListNode* swapPairs(ListNode* head) { if (!head || !head-\u0026gt;next) return head; ListNode dummy(0, head); ListNode* pre = \u0026amp;dummy; ListNode* cur = head; ListNode* next = cur-\u0026gt;next; while (cur \u0026amp;\u0026amp; cur-\u0026gt;next) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = next-\u0026gt;next; next-\u0026gt;next = cur; pre-\u0026gt;next = next; // move to next pair pre = cur; cur = cur-\u0026gt;next; } return dummy.next; } }; 445. Add Two Numbers II é¢˜ç›®ç½‘å€.\nè°ƒç”¨ reverseList ä¸¤æ¬¡ï¼Œå°† l1 å’Œ l2 éƒ½åè½¬ã€‚è¿™æ ·ï¼Œé“¾è¡¨çš„å¤´èŠ‚ç‚¹å°±å˜æˆäº†ä¸ªä½æ•°ï¼Œé—®é¢˜å°±è½¬åŒ–ä¸ºäº†ä¸¤æ•°ç›¸åŠ ã€‚ éå†ä¸¤ä¸ªåè½¬åçš„é“¾è¡¨ï¼Œæ¨¡æ‹ŸåŠ æ³•è¿‡ç¨‹ï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„ç»“æœé“¾è¡¨ã€‚è¿™ä¸ªç»“æœé“¾è¡¨ä¹Ÿæ˜¯åçš„ (ä¸ªä½åœ¨å‰). å°†è¿™ä¸ªæ–°ç”Ÿæˆçš„ç»“æœé“¾è¡¨å†æ¬¡åè½¬ï¼Œå¾—åˆ°æœ€ç»ˆç­”æ¡ˆã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class Solution { ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr; ListNode* cur = head; while (cur) { // pre-\u0026gt;cur-\u0026gt;next ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = pre; // pre\u0026lt;-\u0026gt;cur next pre = cur; // cur-\u0026gt;pre-\u0026gt;next cur = next; } return pre; } public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) { ListNode* reverseL1 = reverseList(l1); ListNode* reverseL2 = reverseList(l2); ListNode dummy(0); ListNode* pre = \u0026amp;dummy; int carry = 0; //ListNode* p1 = reverseL1, *p2 = reverseL2; while (reverseL1 || reverseL2) { int sum = 0; if (reverseL1) { sum += reverseL1-\u0026gt;val; reverseL1 = reverseL1-\u0026gt;next; } if (reverseL2) { sum += reverseL2-\u0026gt;val; reverseL2 = reverseL2-\u0026gt;next; } sum += carry; carry = sum \u0026gt;= 10 ? 1 : 0; int value = carry ? sum - 10 : sum; pre-\u0026gt;next = new ListNode(value); pre = pre-\u0026gt;next; } // carry==1, another node pre-\u0026gt;next = carry ? new ListNode(carry) : nullptr; return reverseList(dummy.next); } }; 2816. Double a Number Represented as a Linked List é¢˜ç›®ç½‘å€. åªéœ€ä¸€æ¬¡éå†ï¼Œåˆ©ç”¨ä¸€ä¸ª pre æŒ‡é’ˆæ¥è®°å½•å½“å‰èŠ‚ç‚¹çš„å‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä»è€Œå°†åœ¨å½“å‰èŠ‚ç‚¹äº§ç”Ÿçš„è¿›ä½ (æœ€å¤šä¸º1) åŠ åˆ°å‰ä¸€ä¸ªèŠ‚ä¸Šã€‚\nåˆ›å»ºä¸€ä¸ª dummy èŠ‚ç‚¹ï¼Œå¹¶è®©å®ƒæŒ‡å‘åŸå§‹é“¾è¡¨çš„å¤´èŠ‚ç‚¹ headã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ç»Ÿä¸€äº†æ‰€æœ‰èŠ‚ç‚¹çš„å¤„ç†é€»è¾‘ï¼Œç‰¹åˆ«æ˜¯å½“åŸå¤´èŠ‚ç‚¹ head è‡ªèº«éœ€è¦è¿›ä½æ—¶ï¼Œè¿›ä½å¯ä»¥è¢«è®°å½•åœ¨ dummy èŠ‚ç‚¹ä¸Šã€‚\nä½¿ç”¨ cur æŒ‡é’ˆä» head å¼€å§‹éå†æ•´ä¸ªé“¾è¡¨ã€‚åœ¨å¾ªç¯ä¸­ï¼Œå…ˆæŠŠå½“å‰èŠ‚ç‚¹ cur çš„å€¼ä¹˜ä»¥ 2. ç„¶åæ£€æŸ¥ cur-\u0026gt;val æ˜¯å¦å¤§äºç­‰äº 10ã€‚å¦‚æœå¤§äº 10ï¼Œè¯´æ˜äº§ç”Ÿäº†è¿›ä½ï¼Œå°† cur-\u0026gt;val å‡å» 10ï¼Œç„¶åå°†å‰ä¸€ä¸ªèŠ‚ç‚¹ pre çš„å€¼åŠ  1 æŠŠè¿›ä½é€ç»™äº†å‰ä¸€ä½ã€‚\néå†ç»“æŸåï¼Œæ£€æŸ¥ dummy èŠ‚ç‚¹çš„å€¼ã€‚å¦‚æœ dummy.val å˜æˆäº† 1ï¼Œè¯´æ˜æ•´ä¸ªé“¾è¡¨çš„æœ€é«˜ä½äº§ç”Ÿäº†è¿›ä½ã€‚è¿™æ—¶ï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ªå€¼ä¸º 1 çš„æ–°å¤´èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶è¿æ¥åˆ°åŸé“¾è¡¨ä¸Šã€‚å¦åˆ™è¯´æ˜æ²¡æœ‰æœ€é«˜ä½è¿›ä½ï¼Œç›´æ¥è¿”å› dummy.next (ä¹Ÿå°±æ˜¯ä¿®æ”¹åçš„åŸé“¾è¡¨å¤´èŠ‚ç‚¹) å³å¯ã€‚\nè¿™é‡Œè¦æ³¨æ„ dummy æ˜¯ä¸€ä¸ªä¸´æ—¶å˜é‡æ— æ³•ç›´æ¥å–åœ°å€è¿”å›éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°çš„æŒ‡å‘ head çš„èŠ‚ç‚¹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution { public: ListNode* doubleIt(ListNode* head) { ListNode* cur = head; ListNode dummy(0, head); ListNode* pre = \u0026amp;dummy; while (cur) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;val *= 2; if (cur-\u0026gt;val \u0026gt;= 10) { cur-\u0026gt;val -= 10; pre-\u0026gt;val++; } pre = cur; cur = next; } // return dummy.val == 1 ? \u0026amp;dummy : dummy.next;return new ListNode(1, dummy.next); // dummy is a tempory variable return dummy.val == 1 ? new ListNode(1, dummy.next) : dummy.next; } }; Fast \u0026amp; Slow Pointers Questions 876. Middle of the Linked List é¢˜ç›®ç½‘å€. æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨ä¸¤ä¸ªæŒ‡é’ˆï¼Œslow å’Œ fastï¼Œå®ƒä»¬éƒ½ä»é“¾è¡¨çš„å¤´ç»“ç‚¹å¼€å§‹ç§»åŠ¨ã€‚slow æŒ‡é’ˆæ¯æ¬¡å‘å‰ç§»åŠ¨ä¸€æ­¥ï¼Œè€Œ fast æŒ‡é’ˆæ¯æ¬¡å‘å‰ç§»åŠ¨ä¸¤æ­¥ã€‚å½“ fast æŒ‡é’ˆåˆ°è¾¾é“¾è¡¨çš„æœ«å°¾æ—¶ï¼Œslow æŒ‡é‡æ­£å¥½æŒ‡å‘é“¾è¡¨çš„ä¸­é—´ç»“ç‚¹ã€‚\né“¾è¡¨é•¿åº¦ä¸ºå¥‡æ•°æ—¶: fast æŒ‡é’ˆæœ€ç»ˆä¼šåœåœ¨æœ€åä¸€ä¸ªèŠ‚ç‚¹ä¸Š (fast-\u0026gt;next == nullptr). æ­¤æ—¶ï¼Œslow æŒ‡é’ˆæ­£å¥½ä½äºé“¾è¡¨çš„æ­£ä¸­é—´ã€‚ é“¾è¡¨é•¿åº¦ä¸ºå¶æ•°æ—¶: fast æŒ‡é’ˆæœ€ç»ˆä¼šè¶Šè¿‡é“¾è¡¨æœ«å°¾ï¼Œå˜ä¸º nullptr. æ ¹æ®é¢˜ç›®è¦æ±‚ï¼Œæˆ‘ä»¬éœ€è¦è¿”å›ç¬¬äºŒä¸ªä¸­é—´ç»“ç‚¹ï¼Œè€Œ slow æŒ‡é’ˆæ­¤æ—¶æ­£å¥½æŒ‡å‘è¿™ä¸ªç»“ç‚¹ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 class Solution { public: ListNode* middleNode(ListNode* head) { ListNode* slow = head, *fast = head; while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { // ensure fast not access nullptr-\u0026gt;next slow = slow-\u0026gt;next; // move one step per loop fast = fast-\u0026gt;next-\u0026gt;next; } // if len is odd, fast is the last ele at the end of loop 2k = (n-1) --\u0026gt; k = (n-1)/2 is the mid of list // even nullptr 2k = n --\u0026gt; k = n/2 is the right mid of list return slow; } }; 141. Linked List Cycle é¢˜ç›®ç½‘å€. åŒæ ·ä½¿ç”¨å¿«æ…¢æŒ‡é’ˆ\nå¦‚æœé“¾è¡¨ä¸­æ²¡æœ‰ç¯ï¼šfast æŒ‡é’ˆå°†é¦–å…ˆåˆ°è¾¾é“¾è¡¨çš„æœ«å°¾ (å³ fast æˆ– fast-\u0026gt;next å˜ä¸º nullptr). å¦‚æœé“¾è¡¨ä¸­å­˜åœ¨ç¯ï¼šfast æŒ‡é’ˆä¼šå…ˆäº slow æŒ‡é’ˆè¿›å…¥ç¯ã€‚ç”±äº fast æ¯” slow ç§»åŠ¨å¾—å¿«ï¼Œå®ƒä¼šåœ¨ç¯å†…è¿½èµ¶ slow æŒ‡é’ˆã€‚å› ä¸ºå®ƒä»¬çš„é€Ÿåº¦å·®æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥ fast æŒ‡é’ˆæœ€ç»ˆå¿…ç„¶ä¼šåœ¨ç¯ä¸­çš„æŸä¸ªèŠ‚ç‚¹è¿½ä¸Šå¹¶ä¸ slow æŒ‡é’ˆç›¸é‡ã€‚ åœ¨éå†è¿‡ç¨‹ä¸­ï¼Œä¸æ–­æ£€æŸ¥ slow å’Œ fast æ˜¯å¦æŒ‡å‘åŒä¸€ä¸ªèŠ‚ç‚¹ã€‚å¦‚æœç›¸é‡ï¼Œåˆ™è¯´æ˜å­˜åœ¨ç¯ï¼›å¦‚æœ fast æŒ‡é’ˆåˆ°è¾¾äº†é“¾è¡¨æœ«å°¾ï¼Œåˆ™è¯´æ˜æ²¡æœ‰ç¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Solution { public: bool hasCycle(ListNode *head) { ListNode* slow = head, *fast=head; while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { fast = fast-\u0026gt;next-\u0026gt;next; slow = slow-\u0026gt;next; if (fast == slow) return true; } return false; } }; 142. Linked List Cycle II é¢˜ç›®ç½‘å€. è§£æ³•åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µ:\nä½¿ç”¨å¿«æ…¢æŒ‡é’ˆåˆ¤æ–­æ˜¯å¦æœ‰ç¯å¹¶æ‰¾åˆ°ç›¸é‡ç‚¹ã€‚ ä»ç›¸é‡ç‚¹æ‰¾åˆ°ç¯çš„å…¥å£ã€‚å½“ slow å’Œ fast ç›¸é‡åï¼Œæˆ‘ä»¬å°†ä»»æ„ä¸€ä¸ªæŒ‡é’ˆé‡æ–°æŒ‡å‘é“¾è¡¨å¤´ headï¼Œå¦ä¸€ä¸ªæŒ‡é’ˆä¿æŒåœ¨ç›¸é‡ç‚¹ä¸åŠ¨ã€‚ç„¶åï¼Œä¸¤ä¸ªæŒ‡é’ˆæ¯æ¬¡å‘å‰ç§»åŠ¨ä¸€æ­¥ï¼Œå½“å®ƒä»¬å†æ¬¡ç›¸é‡æ—¶ï¼Œç›¸é‡çš„èŠ‚ç‚¹å°±æ˜¯ç¯çš„å…¥å£ã€‚è¯æ˜å¦‚ä¸‹ã€‚ a: é“¾è¡¨å¤´åˆ°ç¯å…¥å£çš„è·ç¦»ä¸º=ã€‚ b: ç¯çš„å…¥å£åˆ°å¿«æ…¢æŒ‡é’ˆç›¸é‡ç‚¹çš„è·ç¦»ã€‚ c: ä»ç›¸é‡ç‚¹åˆ°ç¯å…¥å£çš„å‰©ä½™è·ç¦»ã€‚ é‚£ä¹ˆç¯çš„å‘¨é•¿ä¸º L = b + c. å½“ slow å’Œ fast ç¬¬ä¸€æ¬¡ç›¸é‡æ—¶ï¼š\nslow èµ°è¿‡çš„è·ç¦» a + b fast èµ°è¿‡çš„è·ç¦» = 2 * (a + b) (å› ä¸º fast çš„é€Ÿåº¦æ˜¯ slow çš„ä¸¤å€). ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºå®ƒæ¯” slow å¤šèµ°äº† n åœˆç¯çš„é•¿åº¦ (n æ˜¯æ•´æ•°ï¼Œn \u0026gt;= 1): å› æ­¤æˆ‘ä»¬æœ‰\n$$2\\times(a+b)=(a+b)+n\\times(b+c) \\implies a = (n-1)(b+c) + c$$æ„å‘³ç€ä»é“¾è¡¨å¤´åˆ°ç¯å…¥å£çš„è·ç¦» a ç­‰äºä»ç›¸é‡ç‚¹ç»•ç¯ n-1 åœˆï¼Œå†èµ° c æ­¥åˆ°è¾¾ç¯å…¥å£çš„è·ç¦»ã€‚æˆ‘ä»¬è®¾ç½®ä¸¤ä¸ªæŒ‡é’ˆï¼š\nptr1 ä» head å‡ºå‘ï¼Œè¦èµ° a æ­¥æ‰èƒ½åˆ°ç¯å…¥å£ã€‚ ptr2 ä»ç›¸é‡ç‚¹å‡ºå‘ï¼Œä¹Ÿè¦èµ° a æ­¥ (å³ (n-1)L + c æ­¥) æ‰èƒ½åˆ°ç¯å…¥å£ã€‚ å®ƒä»¬å¿…ç„¶ä¼šåœ¨ç¯çš„å…¥å£ç‚¹ç›¸é‡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public: ListNode *detectCycle(ListNode *head) { ListNode* slow = head, *fast = head; while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; if (fast == slow) { ListNode* ptr1 = head; ListNode* ptr2 = slow; while (ptr1 != ptr2) { ptr1=ptr1-\u0026gt;next; ptr2=ptr2-\u0026gt;next; } return ptr1; } } return nullptr; } }; 143. Reorder List é¢˜ç›®ç½‘å€.\nä½¿ç”¨å¿«æ…¢æŒ‡é’ˆæ³•æ‰¾åˆ°é“¾è¡¨çš„ä¸­é—´èŠ‚ç‚¹ã€‚ ä»ä¸­é—´èŠ‚ç‚¹çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å¼€å§‹ï¼Œå°†é“¾è¡¨çš„ååŠéƒ¨åˆ†å®Œå…¨åè½¬ã€‚ å°†åè½¬åçš„ååŠéƒ¨åˆ†é“¾è¡¨ä¸å‰åŠéƒ¨åˆ†é“¾è¡¨è¿›è¡Œâ€œæ‹‰é“¾å¼â€äº¤é”™åˆå¹¶ï¼Œç›´åˆ°åè½¬åçš„ååŠéƒ¨åˆ†é“¾è¡¨ä¸º nullptr. 1-\u0026gt;2-\u0026gt;3-\u0026gt;4 \u0026ndash;\u0026gt; 1-\u0026gt;2-\u0026gt;3 \u0026amp; 4 \u0026ndash;\u0026gt; 1-\u0026gt;(4-\u0026gt;2)-\u0026gt;3\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 class Solution { ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr; ListNode* cur = head; while (cur) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = next; } return pre; } ListNode* middleList(ListNode* head) { ListNode* slow = head, * fast = head; while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; } return slow; } public: void reorderList(ListNode* head) { ListNode* mid = middleList(head); ListNode* midNext = mid-\u0026gt;next; mid-\u0026gt;next = nullptr; ListNode* reverseSecondHead = reverseList(midNext); ListNode* p = head; while (reverseSecondHead != nullptr) { ListNode* firstNext = p-\u0026gt;next; // record first half node p-\u0026gt;next = reverseSecondHead; reverseSecondHead = reverseSecondHead-\u0026gt;next; p = p-\u0026gt;next; p-\u0026gt;next = firstNext; p = p-\u0026gt;next; } } }; 234. Palindrome Linked List é¢˜ç›®ç½‘å€. é€šè¿‡åè½¬ååŠéƒ¨åˆ†é“¾è¡¨æ¥å®ç° $O(1)$ ç©ºé—´å¤æ‚åº¦ã€‚\nä½¿ç”¨å¿«æ…¢æŒ‡é’ˆæ³•æ‰¾åˆ°é“¾è¡¨å‰åŠéƒ¨åˆ†çš„å°¾éƒ¨ã€‚å½“ fast åˆ°è¾¾æˆ–è¶Šè¿‡é“¾è¡¨æœ«å°¾æ—¶ï¼Œslow æ­£å¥½åœåœ¨å‰åŠéƒ¨åˆ†çš„å°¾èŠ‚ç‚¹ä¸Šã€‚ åè½¬ååŠéƒ¨åˆ†é“¾è¡¨ï¼šä» slow çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å¼€å§‹ï¼Œå³ååŠéƒ¨åˆ†çš„å¤´èŠ‚ç‚¹ï¼Œå°†æ•´ä¸ªååŠéƒ¨åˆ†é“¾è¡¨åè½¬ã€‚ ä»ä¸¤ä¸ªå­é“¾è¡¨çš„å¤´éƒ¨å¼€å§‹ï¼Œé€ä¸€æ¯”è¾ƒèŠ‚ç‚¹çš„å€¼ã€‚å¦‚æœå‡ºç°ä»»ä½•ä¸åŒ¹é…ï¼Œé“¾è¡¨å°±ä¸æ˜¯å›æ–‡ã€‚å¦‚æœä¸¤ä¸ªæŒ‡é’ˆéƒ½é¡ºåˆ©èµ°å®Œï¼Œåˆ™è¯´æ˜æ˜¯å›æ–‡ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class Solution { ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr; ListNode* cur = head; while (cur) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = next; } return pre; } ListNode* middleList(ListNode* head) { // return the left node of middle if len is even ListNode* slow = head, * fast = head; while (fast-\u0026gt;next \u0026amp;\u0026amp; fast-\u0026gt;next-\u0026gt;next) { slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; } return slow; } public: bool isPalindrome(ListNode* head) { if (!head-\u0026gt;next) return true; ListNode* firstHalfEnd = middleList(head); ListNode* secondHalfStart = reverseList(firstHalfEnd-\u0026gt;next); while (head \u0026amp;\u0026amp; secondHalfStart) { if (head-\u0026gt;val !=secondHalfStart-\u0026gt;val) return false; head = head-\u0026gt;next; secondHalfStart = secondHalfStart-\u0026gt;next; } return true; } }; 2130. Maximum Twin Sum of a Linked List é¢˜ç›®ç½‘å€. å’Œä¸Šé¢˜ç›®ä¸€æ ·æ€è·¯ï¼Œä¸å†èµ˜è¿°.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class Solution { ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr; ListNode* cur = head; while (cur) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = next; } return pre; } ListNode* middleList(ListNode* head) { // return the left node of middle if len is even ListNode* slow = head, * fast = head; while (fast-\u0026gt;next \u0026amp;\u0026amp; fast-\u0026gt;next-\u0026gt;next) { slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; } return slow; } public: int pairSum(ListNode* head) { ListNode* firstHalfEnd = middleList(head); ListNode* secondHalfStart = reverseList(firstHalfEnd-\u0026gt;next); int ans = 0; while (head \u0026amp;\u0026amp; secondHalfStart) { int sum = 0; sum += head-\u0026gt;val + secondHalfStart-\u0026gt;val; head = head-\u0026gt;next; secondHalfStart = secondHalfStart-\u0026gt;next; ans = max(sum, ans); } return ans; } }; Node Deletion Questions 237. Delete Node in a Linked list é¢˜ç›®ç½‘å€. *node = *node-\u0026gt;next; å¯ä»¥ç§°ä¹‹ä¸ºç‹¸çŒ«æ¢å¤ªå­å°† node å˜æˆä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç„¶åæŠŠçœŸæ­£çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ä»é“¾è¡¨ä¸­åˆ é™¤ã€‚è¿™è¡Œä»£ç çš„æœ¬è´¨æ˜¯å°†ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å¯¹è±¡çš„å†…å®¹å®Œæ•´åœ°å¤åˆ¶åˆ°å½“å‰èŠ‚ç‚¹å¯¹è±¡ä¸­ã€‚\nè¿™ä¸ªæ–¹æ³•æ— æ³•åˆ é™¤é“¾è¡¨ä¸­çš„ æœ€åä¸€ä¸ªèŠ‚ç‚¹ã€‚å› ä¸ºå¦‚æœ node æ˜¯æœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼Œnode-\u0026gt;next å°†æ˜¯ nullptr ï¼Œæ‰§è¡Œ *node-\u0026gt;next ä¼šå¯¼è‡´ç¨‹åºå´©æºƒã€‚ä¸è¿‡ï¼Œé¢˜ç›®ä¿è¯äº†è¦åˆ é™¤çš„èŠ‚ç‚¹ä¸ä¼šæ˜¯å°¾èŠ‚ç‚¹ã€‚ä¸¥æ ¼æ„ä¹‰ä¸Šï¼Œè¯¥æ–¹æ³•å¹¶æ²¡æœ‰é‡Šæ”¾åŸå§‹èŠ‚ç‚¹çš„å†…å­˜ï¼Œè€Œæ˜¯ä¿®æ”¹äº†å®ƒçš„å†…å®¹ã€‚\n1 2 3 4 5 6 7 class Solution { public: void deleteNode(ListNode* node) { // Copy the content of the next node object completely to the current node object. *node = *node-\u0026gt;next; } }; 19. Remove nth Node from End of List é¢˜ç›®ç½‘å€.\nä¸ºäº†èƒ½åˆ é™¤ right æŒ‡å‘çš„èŠ‚ç‚¹ï¼Œæˆ‘ä»¬å®é™…ä¸Šéœ€è¦æ‰¾åˆ°å®ƒå‰é¢çš„é‚£ä¸ªèŠ‚ç‚¹.åˆ›å»ºä¸€ä¸ª dummy èŠ‚ç‚¹ï¼Œè®©å®ƒæŒ‡å‘ head. right å’Œ left éƒ½ä» dummy å¼€å§‹ã€‚ å…ˆè¡Œè®© right æŒ‡é’ˆå…ˆå‘å‰ç§»åŠ¨ n æ­¥ã€‚ç„¶ååŒæ—¶ç§»åŠ¨ right å’Œ slow æŒ‡é’ˆã€‚ å½“ right æŒ‡é’ˆåˆ°è¾¾é“¾è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ æ—¶ï¼Œslow æŒ‡é’ˆæ‰€åœ¨çš„ä½ç½®æ­£å¥½å°±æ˜¯è¦è¢«åˆ é™¤çš„å‰ä¸€ä¸ªèŠ‚ç‚¹ã€‚ç„¶åæ‰§è¡Œåˆ é™¤æ“ä½œã€‚ 83. Remove Duplicates from Sorted List é¢˜ç›®ç½‘å€. ç”¨ä¸€ä¸ªæŒ‡é’ˆå¯¹é“¾è¡¨è¿›è¡Œéå†ï¼Œå½“å‘ç°é‡å¤å…ƒç´ çš„æ—¶å€™å°±ä¸åœè¿›è¡Œåˆ é™¤ï¼Œç„¶åç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ç»§ç»­è¿›è¡Œåˆ¤æ–­ã€‚è¿™é‡Œè™½ç„¶æœ‰ä¸¤ä¸ª while å¾ªç¯ï¼Œä½†æœ€å¤–å±‚å¾ªç¯é€€å‡ºååªéå†äº†é“¾è¡¨ä¸€éï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º $O(N)$.\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Solution { public: ListNode* deleteDuplicates(ListNode* head) { if (!head) return nullptr; ListNode* cur = head; while (cur \u0026amp;\u0026amp; cur-\u0026gt;next) { while (cur-\u0026gt;next \u0026amp;\u0026amp; cur-\u0026gt;val == cur-\u0026gt;next-\u0026gt;val) // handle duplicates cur-\u0026gt;next = cur-\u0026gt;next-\u0026gt;next; cur = cur-\u0026gt;next; } return head; } }; 82. Remove Duplicates from Sorted List II é¢˜ç›®ç½‘å€. æ€è·¯å’Œä¸Šä¸€é¢˜å¤§è‡´ç›¸åŒï¼ŒåŒºåˆ«æ˜¯å› ä¸ºè¦åˆ é™¤æ‰€æœ‰é‡å¤å…ƒç´ çš„èŠ‚ç‚¹ (åŒ…æ‹¬è‡ªå·±)ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæŒ‡é’ˆè®°å½•ç¬¬ä¸€ä¸ªé‡å¤å…ƒç´ çš„å‰ä¸€ä¸ªå…ƒç´ çš„ä½ç½®ã€‚è€Œä¸”å¯èƒ½åˆ é™¤ headï¼Œå› æ­¤è¦åˆå§‹åŒ–ä¸€ä¸ª dummy æŒ‡å‘ head.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution { public: ListNode* deleteDuplicates(ListNode* head) { ListNode dummy(101, head); ListNode* pre = \u0026amp;dummy; ListNode* cur = head; while (cur \u0026amp;\u0026amp; cur-\u0026gt;next) { if (cur-\u0026gt;val == cur-\u0026gt;next-\u0026gt;val) { while (cur-\u0026gt;next \u0026amp;\u0026amp; cur-\u0026gt;val == cur-\u0026gt;next-\u0026gt;val) { // delete duplicates cur-\u0026gt;next = cur-\u0026gt;next-\u0026gt;next; } pre-\u0026gt;next = cur-\u0026gt;next; // delete itself cur = pre-\u0026gt;next; } else { pre = cur; cur = cur-\u0026gt;next; } } return dummy.next; } }; 203. Remove Linked List Elements é¢˜ç›®ç½‘å€. åŒæ ·çš„æ€è·¯ï¼Œå¦‚æœå½“å‰èŠ‚ç‚¹çš„å€¼ç­‰äº valï¼Œå°±åˆ é™¤è¿™ä¸ªèŠ‚ç‚¹ï¼Œå¦åˆ™ç»§ç»­å‘å‰ç§»åŠ¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution { public: ListNode* removeElements(ListNode* head, int val) { if (!head) return nullptr; ListNode dummy(-1, head); ListNode* pre = \u0026amp;dummy; ListNode* cur = head; while (cur) { if (cur \u0026amp;\u0026amp; cur-\u0026gt;val == val) { // delete the target pre-\u0026gt;next = cur-\u0026gt;next; cur = cur-\u0026gt;next; } else { // move forward pre = cur; cur = cur-\u0026gt;next; } } return dummy.next; } }; 3217. Delete Nodes from Linked List Present in Array é¢˜ç›®ç½‘å€. ä¸€æ ·çš„æ€è·¯ï¼Œå…ˆåˆå§‹åŒ–ä¸€ä¸ªå“ˆå¸Œè¡¨ unordered_set å¯¹æ•°ç»„å…ƒç´ è¿›è¡Œå»é‡ï¼Œç„¶åéå†çš„æ—¶å€™åœ¨å…¶ä¸­è¿›è¡ŒæŸ¥æ‰¾åˆ¤æ–­ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution { public: ListNode* modifiedList(vector\u0026lt;int\u0026gt;\u0026amp; nums, ListNode* head) { unordered_set\u0026lt;int\u0026gt; unique_set(nums.begin(), nums.end()); ListNode dummy(-1, head); ListNode* pre = \u0026amp;dummy; ListNode* cur = head; while (cur) { if (cur \u0026amp;\u0026amp; unique_set.find(cur-\u0026gt;val) != unique_set.end()) { // delete the target pre-\u0026gt;next = cur-\u0026gt;next; cur = cur-\u0026gt;next; } else { // move forward pre = cur; cur = cur-\u0026gt;next; } } return dummy.next; } }; 2487. Remove Nodes from Linked List é¢˜ç›®ç½‘å€. ç”±äºæ­£å‘éå†æ— æ³•å¾—çŸ¥å½“å‰èŠ‚ç‚¹æ˜¯å¦éœ€è¦è¢«åˆ é™¤ï¼Œå› æ­¤æˆ‘ä»¬å…ˆå°†é“¾è¡¨åè½¬ï¼Œç„¶åå†éå†ã€‚è‹¥å½“å‰èŠ‚ç‚¹çš„å€¼æ¯”ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å¤§ï¼Œåˆ™è¿›è¡Œåˆ é™¤ï¼›å¦åˆ™ç»§ç»­å‘å³ç§»åŠ¨ã€‚æœ€åå°†åˆ é™¤åçš„é“¾è¡¨å†æ¬¡åè½¬å³ä¸ºç­”æ¡ˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Solution { ListNode* reverseList(ListNode* head) { ListNode* pre = nullptr; ListNode* cur = head; while (cur) { ListNode* next = cur-\u0026gt;next; cur-\u0026gt;next = pre; pre = cur; cur = next; } return pre; } public: ListNode* removeNodes(ListNode* head) { ListNode* revHead = reverseList(head); ListNode* cur = revHead; while (cur-\u0026gt;next) { if (cur-\u0026gt;val \u0026gt; cur-\u0026gt;next-\u0026gt;val) { cur-\u0026gt;next = cur-\u0026gt;next-\u0026gt;next; } else { cur = cur-\u0026gt;next; } } return reverseList(revHead); } }; 1669. Merge in Between Linked Lists é¢˜ç›®ç½‘å€. åˆå§‹åŒ– left æŒ‡å‘ç¬¬ä¸€ä¸ªéœ€è¦è¢«åˆ é™¤çš„èŠ‚ç‚¹çš„å·¦è¾¹çš„èŠ‚ç‚¹ï¼Œright æŒ‡å‘æœ€åä¸€ä¸ªéœ€è¦è¢«åˆ é™¤çš„èŠ‚ç‚¹ã€‚ç„¶åå°† left-\u0026gt;next æ¥å…¥ list2ï¼Œéå†åˆ° list2 çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹çš„æ—¶å€™æ¥å…¥ right-\u0026gt;next.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { public: ListNode* mergeInBetween(ListNode* list1, int a, int b, ListNode* list2) { ListNode dummy(0, list1); ListNode* right = \u0026amp;dummy; for (int i = 0; i \u0026lt; b + 1; i ++) { // move to the last node needs to be deleted right = right-\u0026gt;next; } ListNode* left = \u0026amp;dummy; for (int i = 0; i \u0026lt; a; i++) { // move to the one step before first node need sto be deleted left = left-\u0026gt;next; right = right-\u0026gt;next; } left-\u0026gt;next = list2; while (left-\u0026gt;next) left = left-\u0026gt;next; left-\u0026gt;next = right-\u0026gt;next; return dummy.next; } }; ","permalink":"http://localhost:1313/blogs/leetcode/04_chainlist/","summary":"Algorithm questions about chain list.","title":"04 Chain List"},{"content":"Preliminary: Algorithms for Binary Search in Different Intervals å¯¹äºåœ¨ä¸€ä¸ªæœ‰åºæ•°ç»„é‡Œè¿”å›ç¬¬ä¸€ä¸ª \u0026gt;= target å…ƒç´ çš„ä½ç½®çš„é—®é¢˜ï¼Œå¦‚æœç”¨æš´åŠ›æœç´¢æ³•éå†æ•°ç»„ï¼Œåˆ™æ—¶é—´å¤æ‚åº¦ä¸º $O(n)$ï¼Œè¿™æ˜¯å› ä¸ºæ²¡æœ‰åˆ©ç”¨æ•°ç»„æœ‰åºçš„æ€§è´¨ã€‚\nå¯¹äºé—­åŒºé—´å†™æ³•æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ªå·¦æŒ‡é’ˆ left æŒ‡å‘æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œå³æŒ‡é’ˆ right æŒ‡å‘æ•°ç»„ä¸­æœ€åä¸€ä¸ªå…ƒç´ ã€‚è¦ä¿è¯çš„æ˜¯ left å·¦ä¾§çš„å…ƒç´ å…¨éƒ¨éƒ½å°äº target, right å³ä¾§çš„å…ƒç´ å…¨éƒ¨éƒ½å¤§äºç­‰äº targetï¼Œè¿™ä¹Ÿè¢«ç§°ä¸ºå¾ªç¯ä¸å˜é‡ï¼Œå› æ­¤æ›´æ–°çš„æ—¶å€™æˆ‘ä»¬è¦ä»¤ left = mid + 1 æˆ–è€… right = mid - 1. å½“ left \u0026lt;= right æ—¶ï¼ŒåŒºé—´å†…éƒ½æœ‰å…ƒç´ ã€‚å¾ªç¯ç»“æŸåï¼Œæœ‰ L = R + 1. ä¸ºäº†é˜²æ­¢æº¢å‡ºï¼Œè®¡ç®—ä¸­ç‚¹çš„æ—¶å€™è¦å†™æˆ mid = left + (right - left) / 2.\nå·¦é—­å³å¼€åŒºé—´çš„å†™æ³•ï¼Œéœ€è¦æŠŠ right åˆå§‹åŒ–ä¸ºæ•°ç»„é•¿åº¦ï¼Œright = midï¼Œå› ä¸ºæ­¤æ—¶åŒºé—´ä¸åŒ…æ‹¬ rightï¼ŒåŒºé—´ä¸ä¸ºç©ºçš„æƒ…å†µä¸º left \u0026lt; right. å¾ªç¯ç»“æŸå left å’Œ right æŒ‡å‘çš„æ—¶åŒä¸€ä¸ªä½ç½®ï¼Œè¿”å›è°éƒ½å¯ä»¥ã€‚å¯¹äºå·¦å¼€å³é—­åŒºé—´ä¹Ÿæ˜¯åŒç†ã€‚\næ˜¯å·¦å¼€å³å¼€åŒºé—´çš„å†™æ³•ï¼Œéœ€è¦é¢å¤–æŠŠ left åˆå§‹åŒ–ä¸º -1. åŒºé—´ä¸ä¸ºç©ºçš„æ¡ä»¶ä¸º left + 1 \u0026lt; rightï¼Œæ›´æ–°çš„æ˜¯æ—¶å€™éœ€è¦ä¹Ÿä½¿å¾— left = mid. å¾ªç¯ç»“æŸåè¿”å› right.\nå†è€ƒè™‘é¢å¤–çš„ä¸‰ç§æƒ…å†µï¼Œå¦‚æœæ•°ç»„å…ƒç´ éƒ½æ˜¯æ•´æ•°:\n\u0026gt; target å¯ä»¥çœ‹ä½œ \u0026gt;= target + 1 \u0026lt; target å¯ä»¥çœ‹ä½œ \u0026gt;= target å·¦è¾¹çš„é‚£ä¸ªä½ç½®ã€‚ \u0026lt;= target å¯ä»¥çœ‹ä½œ \u0026gt;= target + 1 å·¦è¾¹çš„é‚£ä¸ªä½ç½®ã€‚ Question Type 1: Maintain Properties Outside the Interval 34. Find First and Last Position of Element in Sorted Array é¢˜ç›®ç½‘å€. æˆ‘ä»¬å…ˆæ±‚å‡ºç¬¬ä¸€ä¸ª \u0026gt;= target å…ƒç´ çš„ä½ç½®ï¼Œè®°ä½œ start. å¦‚æœ start == nums.size() åˆ™è¯´æ˜æ•°ç»„æ‰€æœ‰å…ƒç´ éƒ½ \u0026lt; target. å¦‚æœ nums[start] != target å°±è¯´æ˜æ•°ç»„ä¸­ä¸å­˜åœ¨è¿™ä¸ªå…ƒç´ ã€‚\nå¯¹äº target çš„æœ«å°¾ä½ç½®åˆ™å¯ä»¥çœ‹ä½œ \u0026gt;= target + 1 èµ·å§‹ä½ç½®çš„å·¦è¾¹ä¸€ä¸ªå…ƒç´ ï¼Œç”±äº start å­˜åœ¨é‚£ä¹ˆ end è‚¯å®šå­˜åœ¨ (æœ€å·® = start).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Solution { // return the index of a sorted array where its ele \u0026gt;= target int lowerBoundIndex(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int left = 0, right = nums.size() - 1; while (left \u0026lt;= right) { // loop until the interval is empty, i.e. right + 1 = left int mid = left + (right - left) / 2; // avoid overflow if (nums[mid] \u0026lt; target) { // shows left ele of the interval all \u0026lt; target left = mid + 1; // [mid + 1, right] } else { // shows right ele of the interval all \u0026gt;= target right = mid - 1; // [left, mid - 1] } } return left; } public: vector\u0026lt;int\u0026gt; searchRange(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int start = lowerBoundIndex(nums, target); // all ele \u0026lt; target || all ele \u0026gt; target if (start == nums.size() || nums[start] != target) return {-1, -1}; int end = lowerBoundIndex(nums, target + 1) - 1; return {start, end}; } }; 2529. Maximum Count of Positive Integer and Negative Integer é¢˜ç›®ç½‘å€. æ€è·¯å’Œä¸Šé¢˜ä¸€æ ·ï¼Œè´Ÿæ•°ä¸ªæ•°å³ä¸ºæ•°ç»„ç¬¬ä¸€ä¸ª \u0026gt;= 0 å…ƒç´ çš„ç´¢å¼•ã€‚æ­£æ•°ä¸ªæ•°å³ä¸ºæ•°ç»„é•¿åº¦å‡å»ç¬¬ä¸€ä¸ª \u0026gt;=1 çš„å…ƒç´ çš„ç´¢å¼•ã€‚lowerBoundIndex å‡½æ•°ä¸€æ ·ï¼Œä¸å†èµ˜è¿°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 class Solution { public: int maximumCount(vector\u0026lt;int\u0026gt;\u0026amp; nums) { // Find first index where nums[i] \u0026gt;= 0 (count of negatives) int negCount = lowerBoundIndex(nums, 0); // Find first index where nums[i] \u0026gt;= 1 (start of positives) int startOfPos = lowerBoundIndex(nums, 1); // Positive count is total length minus index of first \u0026gt;= 1 int posCount = nums.size() - startOfPos; return max(negCount, posCount); } }; 2300. Successful Pairs of Spells and Potions é¢˜ç›®ç½‘å€. å¯¹ potions è¿›è¡Œæ’åºï¼Œéå† spellsï¼Œå¯¹äºæ¯ä¸ªå’’è¯­æ‰¾åˆ°æ»¡è¶³ sucess è¦æ±‚çš„æœ€å°è¯æ°´çš„èƒ½é‡å¼ºåº¦å¯¹åº”çš„ç´¢å¼•ï¼Œpotions.size() å‡å»è¯¥ç´¢å¼•åˆ™ä¸ºèƒ½æˆåŠŸé…å¯¹çš„æ•°ç›®ã€‚\nclass Solution { public: vector\u0026lt;int\u0026gt; successfulPairs(vector\u0026lt;int\u0026gt;\u0026amp; spells, vector\u0026lt;int\u0026gt;\u0026amp; potions, long long success) { sort(potions.begin(), potions.end()); vector\u0026lt;int\u0026gt; ans; for (int spell : spells) { long long target = ceil((double)success / spell); ans.push_back((int) potions.size() - lowerBoundIndex(potions, target)); } return ans; } }; 2563. Count the Number of Fair Pairs é¢˜ç›®ç½‘å€. å¯¹ nums è¿›è¡Œæ’åºåä»å·¦å¾€å³éå†ï¼Œå¯¹äºæ¯ä¸ªå…ƒç´ åœ¨å…¶å³ä¾§æ•°ç»„ä¸­æŸ¥æ‰¾ç¬¬ä¸€ä¸ª \u0026gt;= upper + 1 çš„ç´¢å¼•å’Œç¬¬ä¸€ä¸ª \u0026gt;= lower çš„ç´¢å¼•ï¼Œä¸¤è€…ç›¸å‡åˆ™æ˜¯è¯¥å…ƒç´ çš„å…¬å¹³æ•°å¯¹æ•°ç›®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Solution { int lowerBoundIndex(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target, int start, int end) { if (start \u0026lt; 0 || end \u0026gt; nums.size() || start \u0026gt; end) { return -1; } int left = start, right = end - 1; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (nums[mid] \u0026lt; target) { left = mid + 1; } else { right = mid - 1; } } return left; } public: long long countFairPairs(vector\u0026lt;int\u0026gt;\u0026amp; nums, int lower, int upper) { if (nums.size() == 1) return 0; long long ans = 0, n = nums.size(); sort(nums.begin(), nums.end());å¤§äº for (int i = 0; i \u0026lt; nums.size(); i++) { int left = lowerBoundIndex(nums, lower - nums[i], i+1, n); int right = lowerBoundIndex(nums, upper + 1 - nums[i], i+1, n); ans += right - left; } return ans; } }; 275. H Index II é¢˜ç›®ç½‘å€. æˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ä¸ªåˆ†ç•Œç‚¹ midï¼Œä½¿å¾—ä» mid åˆ°æœ«å°¾çš„è®ºæ–‡æ•°é‡ n - mid è‡³å°‘ä¸º citations[mid]. åŒæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ› n - mid å°½å¯èƒ½å°ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°æœ€å°çš„ mid ä½¿å¾— citations[mid] \u0026gt;= n - midï¼Œè¿™æ · h = n - mid å°±æ˜¯æ»¡è¶³æ¡ä»¶çš„æœ€å¤§å€¼ã€‚\næ ¹æ®é—­åŒºé—´çš„å†™æ³•ï¼Œleft å·¦ä¾§çš„å¼•ç”¨æ¬¡æ•°éƒ½æ»¡è¶³ H index çš„å®šä¹‰ï¼Œå³æˆ‘ä»¬éœ€è¦åˆ¤æ–­æ˜¯å¦æœ‰ n - mid è®ºæ–‡ä¸¥æ ¼å¤§äº citation[mid]. å½“å¾ªç¯ç»“æŸæ—¶ï¼Œleft ä¼šæŒ‡å‘ç¬¬ä¸€ä¸ªæ»¡è¶³ citations[mid] \u0026gt;= n - mid çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Solution { public: int hIndex(vector\u0026lt;int\u0026gt;\u0026amp; citations) { int left = 0, right = citations.size() - 1, n = citations.size(); while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (n - mid \u0026gt; citations[mid]) { // try bigger h index, which means smaller mid left = mid + 1; } else { right = mid - 1; } } return n - left; } }; 875. Koko Eating Bananas é¢˜ç›®ç½‘å€. è¿™é‡Œé¢˜ç›®æ„æ€æœ‰ç‚¹éš¾ä»¥ç†è§£ï¼Œæ€»ä¹‹æ¥è¯´å°±æ˜¯åƒæ‰é¦™è•‰èŠ±è´¹æ—¶é—´æ˜¯å‘ä¸Šå–æ•´çš„ã€‚å½“åƒé¦™è•‰çš„æ—¶é—´å°äºç­‰äºè­¦å«å›æ¥çš„é€Ÿåº¦çš„æ—¶å€™æˆ‘ä»¬è®°å½•ä¸‹ç­”æ¡ˆå¹¶å°è¯•æ›´æ…¢çš„é€Ÿåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public: int minEatingSpeed(vector\u0026lt;int\u0026gt;\u0026amp; piles, int h) { int left = 1, right = *max_element(piles.begin(), piles.end()), ans = 1; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; // eating speed = piles[mid] long long time = 0; for (int pile : piles) { time += ceil((double) pile / mid); // convert to double to avoid truncation } if (time \u0026lt;= h) { // try slower speed ans = mid; right = mid - 1; } else { // too slow to eat all piles left = mid + 1; } } return ans; } }; 2187. Minimum Time to Complete Trips é¢˜ç›®ç½‘å€. ä¸€æ ·çš„æ€è·¯ï¼Œåˆ¤æ–­ mid æ—¶é—´å†…èƒ½å®Œæˆçš„è¶Ÿæ•°æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼Œè‹¥æ»¡è¶³åˆ™å°è¯•æ›´çŸ­çš„æ—¶é—´ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Solution { public: long long minimumTime(vector\u0026lt;int\u0026gt;\u0026amp; time, int totalTrips) { long long left = 1; long long right = ranges::min(time) * 1LL * totalTrips; long long ans = 1; while (left \u0026lt;= right) { long long mid = left + (right - left) / 2; long long curTrips = 0; for (int t : time) { curTrips += mid / t; } if (curTrips \u0026lt; totalTrips) { // not enough left = mid + 1; } else { ans = mid; right = mid - 1; } } return ans; } }; 2861. Maximum Number of Alloys é¢˜ç›®ç½‘å€.\néå†æ¯ä¸€ç§åˆé‡‘é…æ–¹ï¼Œè®¡ç®—ä¸€æ¬¡å®ƒæœ€å¤šèƒ½é€ å¤šå°‘ä»¶ã€‚ å¯¹æ¯ç§åˆé‡‘ç”¨äºŒåˆ†æŸ¥æ‰¾æ¥å¯»æ‰¾èƒ½åˆ¶é€ çš„æœ€å¤§æ•°é‡ï¼Œä¸æ–­æ›´æ–°æœ€å¤§å€¼ã€‚ æ¯ä¸€ç§åˆé‡‘æœ€å¤§èƒ½åˆ¶é€ çš„æ•°é‡å¯ä»¥åˆå§‹åŒ–ä¸ºåº“å­˜æœ€å°‘çš„é‡‘å±æ•°é‡åŠ ä¸Š budget (å³å‡è®¾è´­ä¹°é‡‘å±èŠ±è´¹ä¸º 1). åˆ¶é€  mid ä»½éœ€è¦çš„æ€»èŠ±è´¹æˆ‘ä»¬å…ˆéœ€è¦éå†æ¯ç§é‡‘å±éœ€è¦çš„æ•°é‡å’Œå¯¹åº”åº“å­˜çš„å¤§å°ï¼Œä»¥åˆ¤æ–­éœ€ä¸éœ€è¦é¢å¤–è´­ä¹°ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Solution { public: int maxNumberOfAlloys(int n, int k, int budget, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; composition, vector\u0026lt;int\u0026gt;\u0026amp; stock, vector\u0026lt;int\u0026gt;\u0026amp; cost) { long long ans = 0; // Perform binary search on each alloy for (auto comp : composition) { long long left = 0, right = ranges::min(stock) + budget; long long maxNum = 0; while (left \u0026lt;= right) { long long mid = left + (right - left) / 2; long long totalCost = 0; for (int i = 0; i \u0026lt; n; i++) { // compute the cost to produce mid alloys totalCost += max(0LL, mid * comp[i] - stock[i]) * cost[i]; } if (totalCost \u0026lt;= budget) { maxNum = mid; left = mid + 1; } else { right = mid - 1; } } ans = max(ans, maxNum); } return ans; } }; 2439. Minimize Maximum of Array é¢˜ç›®ç½‘å€. è¿™ç±»æœ€å°åŒ–æœ€å¤§å€¼æˆ–æœ€å¤§åŒ–æœ€å°å€¼çš„é—®é¢˜ï¼Œé€šå¸¸æ˜¯äºŒåˆ†æŸ¥æ‰¾ç­”æ¡ˆçš„ç»å…¸åº”ç”¨åœºæ™¯ã€‚\næˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ä¸ªæœ€å°çš„ xï¼Œä½¿å¾—æˆ‘ä»¬å¯ä»¥é€šè¿‡æ“ä½œå°†æ•°ç»„ä¸­æ‰€æœ‰å…ƒç´ éƒ½å˜å¾—ä¸å¤§äº x. å‡è®¾è¿™ä¸ªæœ€å°ç­”æ¡ˆæ˜¯ ans.\nå¦‚æœæˆ‘ä»¬å°è¯•ä¸€ä¸ªç›®æ ‡å€¼ x \u0026gt;= ansï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¸€å®šèƒ½åšåˆ° (å› ä¸ºå¦‚æœèƒ½æŠŠæ‰€æœ‰æ•°éƒ½æ§åˆ¶åœ¨ ans ä»¥ä¸‹ï¼Œé‚£æ§åˆ¶åœ¨æ›´å¤§çš„ x ä»¥ä¸‹å½“ç„¶ä¹Ÿå¯ä»¥). å¦‚æœæˆ‘ä»¬å°è¯•ä¸€ä¸ªç›®æ ‡å€¼ x \u0026lt; ansï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¸€å®šåšä¸åˆ° (å› ä¸º ans å·²ç»æ˜¯èƒ½è¾¾åˆ°çš„æœ€å°å€¼äº†). è§£é¢˜çš„å…³é”®æ˜¯å¦‚ä½•åˆ¤æ–­èƒ½å¦å°†æ‰€æœ‰å…ƒç´ å˜å¾— \u0026lt;= x ? å¯¹äºä»»æ„å‰ç¼€ nums[0...k]ï¼Œæ— è®ºå¦‚ä½•å¯¹è¿™ä¸ªå­æ•°ç»„è¿›è¡Œæ“ä½œï¼Œå…¶æ€»å’Œ sum(nums[0...k]) æ˜¯å›ºå®šçš„ï¼Œå› ä¸ºåªèƒ½å‘å·¦ä¼ é€’å€¼ã€‚å› æ­¤ï¼Œæ£€æŸ¥çš„é€»è¾‘å°±æ˜¯ä»å·¦åˆ°å³éå†æ•°ç»„ï¼Œæ£€æŸ¥æ¯ä¸€ä¸ªå‰ç¼€å­æ•°ç»„æ˜¯å¦æ»¡è¶³æ¡ä»¶ã€‚\nè®¡ç®—å‰ç¼€å’Œ prefixSum = nums[0] + ... + nums[i]. å¦‚æœ prefixSum \u0026gt; (i+1) * xï¼Œè¿™æ„å‘³ç€å³ä¾¿æˆ‘ä»¬æŠŠè¿™ä¸ªå‰ç¼€å’Œ prefixSum å®Œç¾åœ°å¹³å‡åˆ†é…ç»™è¿™ i+1 ä¸ªæ•°ï¼Œå®ƒä»¬çš„å¹³å‡å€¼ä¹Ÿå·²ç»è¶…è¿‡ x äº†ã€‚è¿™è¡¨æ˜è¿™ i+1 ä¸ªæ•°ä¸­è‡³å°‘ä¼šæœ‰ä¸€ä¸ªæ•°å¤§äº x. ç”±äºå€¼ä¸èƒ½å‘å³ä¼ é€’ï¼Œè¿™ä¸ªå‰ç¼€å­æ•°ç»„æ— æ³•ä»åˆ«å¤„è·å¾—å¸®åŠ©æ¥å‡å°è‡ªå·±çš„æ€»å’Œï¼Œæ‰€ä»¥è¿™ç§æƒ…å†µæ˜¯ä¸å¯èƒ½å®ç°çš„ã€‚ç›´æ¥è¿”å› false. å¦‚æœéå†å®Œæ‰€æœ‰å‰ç¼€éƒ½æ²¡æœ‰è¿åè¿™ä¸ªæ¡ä»¶ï¼Œè¯´æ˜ç›®æ ‡ x æ˜¯å¯è¡Œçš„ï¼Œè¿”å› true.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Solution { bool check(vector\u0026lt;int\u0026gt;\u0026amp; nums, long long target) { long long prefixSum = 0; for (int i = 0; i \u0026lt; nums.size(); i++) { prefixSum += nums[i]; if (prefixSum \u0026gt; target * (i + 1)) return false; } return true; } public: int minimizeArrayValue(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int left = nums[0]; // nums[0] cannot decrease during process int right = ranges::max(nums); while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (!check(nums, mid)) { // cannot find min max \u0026lt; mid left = mid + 1; } else { right = mid - 1; } } return left; } }; 2517. Maximum Tastiness of Candy Basket é¢˜ç›®ç½‘å€. æ€è·¯ä¸ä¸Šé¢˜ç›¸åŒï¼Œå…³é”®æ˜¯ç»™å®šä¸€ä¸ªç›®æ ‡ç”œèœœåº¦ xï¼Œå¦‚ä½•åˆ¤æ–­èƒ½å¦é€‰å‡º k ä¸ªç³–æœï¼Œä½¿å¾—å®ƒä»¬ä¸¤ä¸¤ä»·æ ¼å·®è‡³å°‘ä¸º x ? è¿™é‡Œå¯ä»¥ä½¿ç”¨è´ªå¿ƒç­–ç•¥ã€‚ä¸ºäº†è®©ç³–æœä¹‹é—´çš„é—´éš”å°½å¯èƒ½å¤§ï¼Œæˆ‘ä»¬åº”è¯¥è®©å®ƒä»¬åœ¨ä»·æ ¼è½´ä¸Šæ‹‰å¾—æ›´å¼€ã€‚\nå¯¹ price æ•°ç»„è¿›è¡Œå‡åºæ’åºã€‚ä»¥ä¾¿åœ¨ä¸€ä¸ªæœ‰åºçš„åºåˆ—ä¸Šè¿›è¡Œè´ªå¿ƒé€‰æ‹©ã€‚\nè¿›è¡Œè´ªå¿ƒç®—æ³•é€‰æ‹©ç³–æœã€‚\né€‰æ‹©ä»·æ ¼æœ€ä½çš„ç³–æœ price[0] ä½œä¸ºæˆ‘ä»¬ç¤¼ç›’ä¸­çš„ç¬¬ä¸€é¢—ç³–æœã€‚ å‘åéå†æ’åºåçš„ price æ•°ç»„ï¼Œå¯»æ‰¾ä¸‹ä¸€é¢—å¯ä»¥æ”¾å…¥ç¤¼ç›’çš„ç³–æœã€‚è¦æ»¡è¶³ç”œèœœåº¦ä¸º x çš„æ¡ä»¶ï¼Œä¸‹ä¸€é¢—ç³–æœçš„ä»·æ ¼å¿…é¡»ä¸æˆ‘ä»¬ä¸Šä¸€é¢—é€‰å®šçš„ç³–æœçš„ä»·æ ¼å·®è‡³å°‘ä¸º x. å‡è®¾ä¸Šä¸€é¢—é€‰çš„ç³–æœä»·æ ¼æ˜¯ last_priceï¼Œåœ¨æ•°ç»„ä¸­ç»§ç»­å¾€åæ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°ç¬¬ä¸€ä¸ª price[i] æ»¡è¶³ price[i] \u0026gt;= last_price + x. æŠŠè¿™é¢—ç³–æœé€‰å…¥ç¤¼ç›’ï¼Œæ›´æ–° last_price = price[i]ï¼Œç„¶åç»§ç»­ç”¨åŒæ ·çš„æ–¹æ³•å¯»æ‰¾ä¸‹ä¸€é¢—ã€‚ ç»Ÿè®¡ä¸€å…±é€‰å‡ºäº†å¤šå°‘é¢—ç³–æœã€‚å¦‚æœæœ€ç»ˆé€‰å‡ºçš„ç³–æœæ•°é‡ count \u0026gt;= kï¼Œé‚£ä¹ˆè¯´æ˜ç”œèœœåº¦ x æ˜¯å¯ä»¥å®ç°çš„ï¼Œè¿”å› true. å¦åˆ™ï¼Œè¿”å› false.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Solution { bool check(vector\u0026lt;int\u0026gt;\u0026amp; price, int k, int target) { // greedy: always choose first int count = 1; int last_price = price[0]; for (int i = 1; i \u0026lt; price.size(); i++) { if (price[i] - last_price \u0026gt;= target) { count++; last_price = price[i]; } } return count \u0026gt;= k; } public: int maximumTastiness(vector\u0026lt;int\u0026gt;\u0026amp; price, int k) { sort(price.begin(), price.end()); int left = 0, right = ranges::max(price) - price[0]; int ans = 0; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (check(price, k, mid)) { // can find k-1 diff \u0026gt;= mid Tastiness ans = mid; left = mid + 1; } else { right = mid - 1; } } return ans; } }; Question Type 2: Select the Half where the Answer is Located 162. Find Peak Element é¢˜ç›®ç½‘å€. ä¼ ç»Ÿçš„äºŒåˆ†æŸ¥æ‰¾ä¾èµ–äºæ•°ç»„çš„ å•è°ƒæ€§ (å®Œå…¨æœ‰åº). æ¯”å¦‚ï¼Œæˆ‘ä»¬è¦æŸ¥æ‰¾ä¸€ä¸ªæ•° targetï¼Œæˆ‘ä»¬ä¼šæ¯”è¾ƒ nums[mid] å’Œ targetï¼š\nå¦‚æœ nums[mid] \u0026lt; targetï¼Œæˆ‘ä»¬å°±çŸ¥é“ target ä¸å¯èƒ½åœ¨å·¦åŠéƒ¨åˆ†ã€‚ å¦‚æœ nums[mid] \u0026gt; targetï¼Œæˆ‘ä»¬å°±çŸ¥é“ target ä¸å¯èƒ½åœ¨å³åŠéƒ¨åˆ†ã€‚ ç„¶è€Œï¼Œåœ¨æœ¬é¢˜ä¸­ï¼Œæ•°ç»„ nums ä¸æ˜¯æœ‰åºçš„ã€‚é‚£å‡­ä»€ä¹ˆå¯ä»¥èˆå¼ƒä¸€åŠçš„åŒºé—´å‘¢ï¼Ÿè¿™é‡Œçš„å…³é”®åœ¨äºï¼Œæˆ‘ä»¬ä¸æ˜¯åœ¨æ‰¾ä¸€ä¸ªç‰¹å®šçš„å€¼ï¼Œè€Œæ˜¯åœ¨æ‰¾ä¸€ä¸ªæ»¡è¶³ ç‰¹å®šæ€§è´¨ (å³ä¸ºå³°å€¼) çš„å…ƒç´ ã€‚äºŒåˆ†æŸ¥æ‰¾çš„æœ¬è´¨æ˜¯é€šè¿‡æ¯ä¸€æ­¥åˆ¤æ–­ï¼Œå°†æœç´¢ç©ºé—´ç¼©å°ä¸€åŠã€‚æˆ‘ä»¬æ¥çœ‹çœ‹åœ¨è¿™ä¸ªé—®é¢˜é‡Œå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚\næˆ‘ä»¬å–ä¸­é—´å…ƒç´  nums[mid]ï¼Œå¹¶è§‚å¯Ÿå®ƒå’Œå®ƒå³è¾¹é‚»å±… nums[mid+1] çš„å…³ç³»ï¼š\nå¦‚æœ nums[mid] \u0026lt; nums[mid+1]: è¿™æ„å‘³ç€ nums[mid] æœ¬èº«è‚¯å®šä¸æ˜¯å³°å€¼ (å› ä¸ºå®ƒæ¯”å³è¾¹çš„å°)ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¿™è¡¨æ˜ ä» mid åˆ° mid+1 å¤„ï¼Œæ•°ç»„æ˜¯ä¸Šå¡çš„ã€‚æ—¢ç„¶æ˜¯ä¸Šå¡ï¼Œé‚£ä¹ˆåªè¦æˆ‘ä»¬ä¸€ç›´å¾€å³èµ°å°±å¿…ç„¶ ä¼šé‡åˆ°ä¸€ä¸ªå³°å€¼ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæ•°ç»„çš„å³è¾¹ç•Œæ˜¯è´Ÿæ— ç©·ï¼Œä½ ä¸å¯èƒ½æ— é™åœ°ä¸Šå¡ï¼Œæ€»ä¼šæœ‰ä¸€ä¸ªç‚¹å¼€å§‹ä¸‹å¡ï¼Œé‚£ä¸ªè½¬æŠ˜ç‚¹å°±æ˜¯ä¸€ä¸ªå³°å€¼ã€‚\nå› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æ–­å®šåœ¨ mid çš„å³ä¾§åŒºåŸŸ (å³ [mid + 1, right]) å¿…å®šå­˜åœ¨ä¸€ä¸ªå³°å€¼ã€‚äºæ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°èˆå¼ƒå·¦åŠéƒ¨åˆ†ï¼Œä»¤ left = mid + 1.\nå¦‚æœ nums[mid] \u0026gt; nums[mid+1]: è¿™æ„å‘³ç€ nums[mid] æœ¬èº«å¯èƒ½æ˜¯ä¸€ä¸ªå³°å€¼ (å¦‚æœå®ƒä¹Ÿå¤§äºå·¦è¾¹çš„ nums[mid-1]). æ›´é‡è¦çš„æ˜¯ï¼Œè¿™è¡¨æ˜ ä» mid åˆ° mid+1 å¤„ï¼Œæ•°ç»„æ˜¯ä¸‹å¡çš„ã€‚æ—¢ç„¶æ˜¯ä¸‹å¡ï¼Œé‚£ä¹ˆå¾€å·¦çœ‹ï¼Œmid çš„å·¦ä¾§åŒºåŸŸå¿…ç„¶å­˜åœ¨ä¸€ä¸ªå³°å€¼ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæ•°ç»„çš„å·¦è¾¹ç•Œæ˜¯è´Ÿæ— ç©·ï¼Œä¸å¯èƒ½æ— é™åœ°ä¸‹å¡ã€‚åœ¨ mid çš„å·¦è¾¹ï¼Œè¦ä¹ˆ nums[mid] è‡ªå·±å°±æ˜¯ä¸€ä¸ªå³°å€¼ï¼Œè¦ä¹ˆåœ¨å®ƒå·¦è¾¹çš„æŸä¸ªå…ƒç´ æ˜¯å³°å€¼ã€‚\nå› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ æ–­å®š åœ¨ mid åŠ mid çš„å·¦ä¾§åŒºåŸŸ (å³ [left, mid]) å¿…å®šå­˜åœ¨ä¸€ä¸ªå³°å€¼ã€‚äºæ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°èˆå¼ƒå³åŠéƒ¨åˆ†ï¼Œä»¤ right = mid - 1.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Solution { public: int findPeakElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) { if (nums.size() == 1) return 0; int left = 0, right = nums.size() - 2; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (nums[mid] \u0026gt; nums[mid + 1]) { // summit is at left of mid right = mid - 1; } else { left = mid + 1; } } return left; } }; 153. Find Minimum in Rotated Sorted Array é¢˜ç›®ç½‘å€. åˆ©ç”¨æ—‹è½¬çš„ç‰¹æ€§ï¼Œå‡è®¾æ•°ç»„ [0, 1, 2, 4, 5, 6, 7] æ—‹è½¬åå˜æˆ [4, 5, 6, 7, 0, 1, 2]. æ—‹è½¬åçš„æ•°ç»„æœ‰ä»¥ä¸‹ç‰¹ç‚¹:\nå®ƒè¢«åˆ†æˆäº†ä¸¤ä¸ªå„è‡ªæœ‰åºçš„éƒ¨åˆ† [4, 5, 6, 7] å’Œ [0, 1, 2]. ç¬¬ä¸€éƒ¨åˆ†çš„æ‰€æœ‰å…ƒç´ éƒ½å¤§äºç¬¬äºŒéƒ¨åˆ†çš„æ‰€æœ‰å…ƒç´ ã€‚ æœ€å°å€¼å°±æ˜¯ç¬¬äºŒéƒ¨åˆ†çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œå®ƒä¹Ÿæ˜¯æ•´ä¸ªæ•°ç»„ä¸­å”¯ä¸€ä¸€ä¸ªæ¯”å®ƒå‰ä¸€ä¸ªå…ƒç´ å°çš„æ•° (æŠŠæ•°ç»„çœ‹ä½œç¯å½¢). äºŒåˆ†æŸ¥æ‰¾çš„æ ¸å¿ƒæ˜¯æ¯æ¬¡éƒ½èˆå¼ƒä¸€åŠä¸å¯èƒ½æ˜¯ç­”æ¡ˆçš„åŒºé—´ã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•åˆ¤æ–­è¯¥èˆå¼ƒå“ªä¸€åŠå‘¢ï¼Ÿå…³é”®åœ¨äº nums[mid] å’Œæ•°ç»„ç«¯ç‚¹ nums[right] çš„æ¯”è¾ƒã€‚\nnums[mid] \u0026gt; nums[right]: è¯´æ˜ mid è‚¯å®šåœ¨ç¬¬ä¸€æ®µè¾ƒå¤§çš„æœ‰åºæ•°ç»„é‡Œã€‚ ä¾‹å¦‚ä¸€å¼€å§‹åœ¨ [4, 5, 6, 7, 0, 1, 2] ä¸­ï¼Œright æŒ‡å‘ 2, mid æŒ‡å‘ 7ï¼Œé‚£ä¹ˆè¯´æ˜ mid åœ¨ç¬¬ä¸€æ®µï¼Œé‚£ä¹ˆæœ€å°å€¼ (ä¹Ÿå°±æ˜¯ç¬¬äºŒæ®µçš„å¼€å¤´) ä¸€å®šåœ¨ mid çš„å³è¾¹ã€‚æ‰€ä»¥ï¼Œå¯ä»¥å®‰å…¨åœ°èˆå¼ƒ [left, mid] è¿™ä¸ªåŒºé—´, left = mid + 1.\nnums[mid] \u0026lt;= nums[right]: è¯´æ˜ mid è‚¯å®šåœ¨ç¬¬äºŒæ®µè¾ƒå°çš„æœ‰åºæ•°ç»„é‡Œï¼Œæˆ–è€…æ˜¯æ•°ç»„æ²¡æœ‰æ—‹è½¬çš„æƒ…å†µã€‚ ä¾‹å¦‚ç¬¬äºŒæ¬¡å¾ªç¯åœ¨ [4, 5, 6, 7, 0, 1, 2] ä¸­ï¼Œ mid æŒ‡å‘ 1ï¼Œright æŒ‡å‘ 2ï¼Œè¯´æ˜ mid åœ¨ç¬¬äºŒæ®µï¼Œé‚£ä¹ˆæœ€å°å€¼å¯èƒ½æ˜¯ nums[mid] æœ¬èº«ï¼Œæˆ–è€…åœ¨ mid çš„å·¦è¾¹ã€‚ä¸ºäº†ä¸¥æ ¼åº”ç”¨é—­åŒºé—´çš„å†™æ³•ï¼Œæˆ‘ä»¬å¿…é¡»åšä¸€äº›æ¡ä»¶åˆ¤æ–­å¤„ç†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Solution { public: int findMin(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); if (n == 1) return nums[0]; if (nums[0] \u0026lt; nums[n - 1]) // rotate n times return nums[0]; int left = 0, right = nums.size() - 1; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (mid + 1 \u0026lt; n \u0026amp;\u0026amp; nums[mid] \u0026gt; nums[mid + 1]) // find maximum return nums[mid + 1]; if (mid - 1 \u0026gt;= 0 \u0026amp;\u0026amp; nums[mid] \u0026lt; nums[mid - 1]) // find minimum return nums[mid]; if (nums[mid] \u0026gt; nums[right]) { // minimum at right slope left = mid + 1; } else { right = mid - 1; } } return nums[left]; } }; 33. Search in Rotated Sorted Array é¢˜ç›®ç½‘å€. å’Œç¬¬ 153 é¢˜ä¸€æ ·ï¼Œæ•°ç»„çš„æ•´ä½“å•è°ƒæ€§è¢«ç ´åäº†ã€‚ä¸€ä¸ªç®€å•çš„ if (target \u0026lt; nums[mid]) åˆ¤æ–­æ— æ³•å‘Šè¯‰æˆ‘ä»¬åº”è¯¥å»å·¦è¾¹è¿˜æ˜¯å³è¾¹ã€‚ä¾‹å¦‚ï¼Œåœ¨ [4,5,6,7,0,1,2] ä¸­æœç´¢ target = 0ï¼Œç¬¬ä¸€æ¬¡å¾ªç¯ mid = 7ï¼Œè™½ç„¶ 0 \u0026lt; 7ï¼Œä½† 0 å´åœ¨ 7 çš„å³è¾¹ã€‚\nä½†æ— è®ºæ•°ç»„å¦‚ä½•æ—‹è½¬ï¼Œå½“æˆ‘ä»¬å–ä¸­ç‚¹ mid æ—¶ï¼Œ[left, mid] å’Œ [mid, right] è¿™ä¸¤ä¸ªåŒºé—´ä¸­ï¼Œè‡³å°‘æœ‰ä¸€ä¸ªæ˜¯å®Œå…¨æœ‰åºçš„ã€‚é¦–å…ˆåˆ¤æ–­ mid æ‰€æŒ‡å‘çš„ä½ç½®æ˜¯å¦ä¸º target. ç„¶åæˆ‘ä»¬å¯ä»¥åˆ¤æ–­ target æ˜¯å¦å­˜åœ¨æœ‰åºéƒ¨åˆ†çš„å­æ•°ç»„ä¸­æ¥ç§»åŠ¨æŒ‡é’ˆï¼Œå¦‚æœå¾ªç¯ç»“æŸäº†ï¼Œè¯´æ˜æ‰¾ä¸åˆ°ã€‚\nnums[left] \u0026lt;= nums[mid]: è¯´æ˜ä» left åˆ° mid çš„å·¦åŠéƒ¨åˆ†æ˜¯å®Œå…¨æœ‰åºçš„ã€‚ æ—¢ç„¶å·¦åŠè¾¹æœ‰åºï¼Œæˆ‘ä»¬å°±å¯ä»¥å‡†ç¡®åˆ¤æ–­ target æ˜¯å¦è½åœ¨è¿™ä¸ªåŒºé—´å†…ï¼šå¦‚æœ target \u0026gt;= nums[left] å¹¶ä¸” target \u0026lt; nums[mid]ï¼Œé‚£ä¹ˆ target å°±åœ¨è¿™ä¸ªæœ‰åºçš„å·¦åŠéƒ¨åˆ†ã€‚æˆ‘ä»¬å°±å»å·¦è¾¹æ‰¾ï¼Œæ›´æ–° right = mid - 1.å¦åˆ™ï¼Œtarget å°±ä¸åœ¨æœ‰åºçš„å·¦åŠéƒ¨åˆ†ï¼Œé‚£å®ƒåªå¯èƒ½åœ¨æ— åºçš„å³åŠéƒ¨åˆ†ã€‚æˆ‘ä»¬å°±å»å³è¾¹æ‰¾ï¼Œæ›´æ–° left = mid + 1.\nnums[left] \u0026gt; nums[mid]: è¯´æ˜æ—‹è½¬ç‚¹åœ¨ [left, mid] ä¹‹é—´ï¼Œå› æ­¤ä» mid åˆ° right çš„å³åŠéƒ¨åˆ†æ˜¯å®Œå…¨æœ‰åºçš„ã€‚ æ—¢ç„¶å³åŠè¾¹æœ‰åºï¼Œæˆ‘ä»¬å°±å¯ä»¥å‡†ç¡®åˆ¤æ–­ target æ˜¯å¦è½åœ¨è¿™ä¸ªåŒºé—´å†…ï¼šæœ target \u0026gt; nums[mid] å¹¶ä¸” target \u0026lt;= nums[right]ï¼Œé‚£ä¹ˆ target å°±åœ¨è¿™ä¸ªæœ‰åºçš„å³åŠéƒ¨åˆ†ã€‚æˆ‘ä»¬å°±å»å³è¾¹æ‰¾ï¼Œæ›´æ–° left = mid + 1. å¦åˆ™ï¼Œtarget å°±ä¸åœ¨æœ‰åºçš„å³åŠéƒ¨åˆ†ï¼Œé‚£å®ƒåªå¯èƒ½åœ¨æ— åºçš„å·¦åŠéƒ¨åˆ†ã€‚æˆ‘ä»¬å°±å»å·¦è¾¹æ‰¾ï¼Œæ›´æ–° right = mid - 1.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Solution { public: int search(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int left = 0, right = nums.size() - 1; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (nums[mid] == target) return mid; if (nums[mid] \u0026gt;= nums[left]) { // [left, mid] is sorted if (nums[mid] \u0026gt; target \u0026amp;\u0026amp; nums[left] \u0026lt;= target) right = mid - 1; else left = mid + 1; } else { // [mid, right] is sorted if (nums[mid] \u0026lt; target \u0026amp;\u0026amp; nums[right] \u0026gt;= target) left = mid + 1; else right = mid - 1; } } return -1; } }; 154. Find Minimum in Rotated Sorted Array II é¢˜ç›®ç½‘å€. è¿™é“é¢˜å’Œ 153 æœ€å¤§çš„åŒºåˆ«ï¼Œä¹Ÿæ˜¯å”¯ä¸€çš„éš¾ç‚¹ï¼Œå°±åœ¨äºé‡å¤å…ƒç´ çš„å­˜åœ¨ï¼Œä½¿å¾—æˆ‘ä»¬æ— æ³•åœ¨æ‰€æœ‰æƒ…å†µä¸‹é€šè¿‡æ¯”è¾ƒ nums[mid] å’Œç«¯ç‚¹æ¥ç¡®å®šèŒƒå›´ã€‚å½“ä¸¥æ ¼å°äºå’Œä¸¥æ ¼å¤§äºç«¯ç‚¹çš„æƒ…å†µä¸‹å’Œä¹‹å‰ç›¸åŒã€‚nums[mid] == nums[right] æ˜¯æˆ‘ä»¬æ— æ³•åˆ¤æ–­çš„æƒ…å†µã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šçš„æ˜¯ nums[right] è‚¯å®šä¸æ˜¯å”¯ä¸€çš„æœ€å°å€¼å€™é€‰è€… (å› ä¸º mid ä½ç½®è¿˜æœ‰ä¸€ä¸ªå’Œå®ƒä¸€æ ·å¤§çš„æ•°). å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°å°† right æŒ‡é’ˆå‘å·¦ç§»åŠ¨ä¸€ä½ï¼ŒæŠŠ nums[right] è¿™ä¸ªå…ƒç´ å»æ‰ï¼Œç„¶ååœ¨ç¼©å°åçš„åŒºé—´é‡Œç»§ç»­å¯»æ‰¾ã€‚\næœ€å¥½çš„å’Œå¹³å‡æƒ…å†µä¸‹ï¼Œå¤§éƒ¨åˆ†æ—¶é—´è¿˜æ˜¯åœ¨è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾ï¼Œå¤æ‚åº¦æ˜¯ $O(\\log n)$. ä½†åœ¨æ•°ç»„æ‰€æœ‰å…ƒç´ éƒ½ç›¸ç­‰çš„æœ€åçš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚æ•°ç»„æ˜¯ [1, 1, 1, 1, 1]ï¼Œmid å’Œ right æŒ‡å‘çš„å…ƒç´ ä¼šä¸€ç›´ç›¸ç­‰ï¼Œç®—æ³•ä¸€ç›´ä¼šè¿›è¡Œ right\u0026ndash;ï¼Œçº¿æ€§åœ°ä»å³å‘å·¦æ‰«æï¼Œæ—¶é—´å¤æ‚åº¦å˜ä¸º $O(n)$. è¿™æ˜¯ä¸ºäº†å¤„ç†é‡å¤å…ƒç´ æ‰€å¿…é¡»ä»˜å‡ºçš„ä»£ä»·ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution { public: int findMin(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int left = 0, right = nums.size() - 1; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; if (mid + 1 \u0026lt; nums.size() \u0026amp;\u0026amp; nums[mid] \u0026gt; nums[mid + 1]) return nums[mid + 1]; if (mid - 1 \u0026gt;= 0 \u0026amp;\u0026amp; nums[mid] \u0026lt; nums[mid - 1]) return nums[mid]; if (nums[mid] \u0026gt; nums[right]) { left = mid + 1; } else if (nums[mid] \u0026lt; nums[right]) { right = mid - 1; } else { // if nums[right] is minmimum, at least nums[mid] is also. right--; } } return nums[left]; } }; ","permalink":"http://localhost:1313/blogs/leetcode/03_binarysearch/","summary":"Algorithm questions about binary search.","title":"03 BinarySearch"},{"content":"TX8 Hardware Overview TX8 é‡‡ç”¨çš„æ˜¯ç©ºé—´è®¡ç®—å‹ç»“æ„ (Special Computing Architecture)ï¼Œå¸‚é¢ä¸Šæ™®éé‡‡ç”¨çš„å…±äº«å†…å­˜ç»“æ„ (Shared Memory Architecture)ï¼Œå®ƒçš„æ•°æ®é€šä¿¡äº¤äº’ä¸»è¦æ˜¯ä¾èµ–äº DDRï¼Œä¸€ä¸ª thread æŠŠ DDR çš„æ•°æ®æ”¹å˜ä¹‹åï¼Œå¦å¤–ä¸€ä¸ª thread å†ä» DDR ä¸­æ‰èƒ½å¾—çŸ¥åˆ°è¿™ä¸ªæ•°æ®å·²ç»è¢«æ”¹å˜ã€‚è¿™ä¹ˆåšæœ‰ä¸€ä¸ªå¾ˆæ˜æ˜¾çš„ç¼ºé™·ï¼Œå°±æ˜¯å®ƒç“¶é¢ˆåœ¨äºå†…å­˜å®¹é‡ä»¥åŠè®¿é—®å†…å­˜çš„å¸¦å®½å»¶è¿Ÿã€‚ç©ºé—´è®¡ç®—å‹çš„ç»“æ„å®ƒæ˜¯ç”±ä¸­é—´çš„NOC (Network On Chip) æ¥æ„æˆæ¨¡å—ä¹‹é—´çš„äº’è”ã€‚è¿™æ ·å¾ˆå¥½çš„é¿å…äº†è¿™ä¸ª DDR çš„ç“¶é¢ˆï¼ŒåŒæ—¶ä¹Ÿæœ‰äº†æ›´å¥½çš„ scale out èƒ½åŠ›ã€‚\n(a) Shared Memory Architecture (b) Spatial Computing Architecture\nä¸‹å›¾ä¸º TX8 ä¸¤ä¸ªèŠ¯ç‰‡äº’è¿çš„é€»è¾‘ç»“æ„ã€‚æ¯ä¸ªèŠ¯ç‰‡ç”± 4x4 æ€»è®¡ 16 Tile ä»¥ mesh æ‹“æ‰‘ç»“æ„è¿›è¡Œäº’è¿ã€‚æ¯ä¸€ä¸ª Tile æ˜¯ä¸€ä¸ªè®¡ç®—æ ¸å¿ƒï¼Œæ˜¯ä¸€ä¸ªå›¾çµå®Œå¤‡ (Turing Complete) çš„ç³»ç»Ÿï¼Œæ—¢å…·æœ‰è°ƒåº¦æ§åˆ¶ä»¥åŠè®¡ç®—é€šä¿¡ä»¥åŠå­˜å‚¨çš„èƒ½åŠ›ã€‚ç‰‡ä¸Š NoC é‡‡ç”¨çš„æ˜¯ stream (ä¸€ç§è½»é‡çº§ DMA æŠ€æœ¯). ç‰‡ä¸Š DDR å¤§å°ä¸º 64GBï¼ŒèŠ¯ç‰‡ä¹‹é—´æ˜¯é€šè¿‡ high speed IO è¿›è¡Œäº’è¿çš„ã€‚\nTile\nå•èŠ¯ç‰‡ä¸å•å¡ A100 æ€§èƒ½å¯¹æ¯”å¦‚ä¸‹è¡¨æ‰€ç¤º\nTX8 å•å¡æ€§èƒ½ æœ€å¤§ç»„ç½‘æ€§èƒ½ A100 å•å¡æ€§èƒ½ INT8 256T 1E 624T BF16 128T 0.5E 312T TFP32 128T 0.5E 156T FP32 21T 40P 19.5T å†…å­˜å¸¦å®½ 200GB/s - æ˜¾å­˜å¸¦å®½ 1935GB/s PCIe 64GB/s - 64GB/s å†…å­˜å®¹é‡ 64GB 128TB æ˜¾å­˜å®¹é‡ 80GB TsingMicro-Link 1600Gbps - NV-Link 600GB/s Single Tile ä¸‹å›¾æ˜¯å• Tile çš„ç¡¬ä»¶ç»“æ„ï¼Œå®é™…ä¸Šæ¯ä¸ª Tile ä¸Šä¼šæœ‰ä¸¤ä¸ª kernel core å’Œ special coreï¼Œå›¾ä¸­åªç”»äº†ä¸€ä¸ªã€‚è¿˜æœ‰ä¸ª neural coreï¼Œä¸»è¦æ˜¯è´Ÿè´£è®¡ç®—ä»¥åŠæ•°æ®æ¬è¿ç­‰ç­‰ã€‚\nTile Microarchitecture\nkernel core ä¸»è¦ç”¨äºä¸‹å‘æŒ‡ä»¤ã€‚å®ƒä¼šä» DDR ä¸­å–å€ï¼Œç„¶åé€åˆ°è¿™ä¸ª neural core çš„ NCC controller é‡Œé¢ã€‚NCC controller åˆä¼šæŠŠæ ¹æ®è¿™ä¸ªæŒ‡ä»¤çš„ç±»å‹ä¸‹å‘åˆ° CT/NE/LSU. ä»–ä»¬ä¸‰ä¸ªæ˜¯æ‰§è¡Œä¸åŒç§ç±»æŒ‡ä»¤çš„ä¸‰ä¸ªå°æ¨¡å—ï¼Œåé¢ä¼šè®²åˆ°ã€‚è¿™ä¸‰ä¸ªå°æ¨¡å—ä¼šä» SPM (Scratched Pad Memory) ä¸Šè¯»å–æ•°æ®ï¼Œç„¶åå†è®¡ç®—ï¼Œæˆ–è€…å†å­˜å› SPMä¸Šã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLSU æ˜¯ç”¨æ¥è´Ÿè´£è¿™ä¸ªæ•°æ®æ¬è¿çš„ï¼Œæ‰€ä»¥å®ƒå¯ä»¥æŠŠè¿™ä¸ª SPM ä¸Šçš„æ•°æ®ç›´æ¥æ¬åˆ°DDRï¼Œæˆ–è€…æ˜¯ä» DDR æ¬åˆ° SPM ä¸Šã€‚CT å’Œ NE éƒ½æ˜¯è´Ÿè´£è®¡ç®—çš„æ¨¡å—ï¼Œå…¶ä¸­ scalar unit ä½äº NCC controllerï¼Œæ˜¯ä¸€ä¸ªè´Ÿè´£æ ‡é‡è®¡ç®—çš„æ¨¡å—ã€‚\nspecial core ç”¨æ¥å’Œ NOC è¿›è¡Œè¿æ¥ï¼Œå®ƒå¯ä»¥ä» DDR ä¸­è¯»å–æ•°æ®ï¼Œç„¶åé€šè¿‡é…ç½® DTE æ¨¡å—å’Œè¿™ä¸ªè¿œç¨‹çš„ Tile è¿›è¡Œé€šä¿¡ã€‚DTE æ¨¡å—ä¹Ÿå¯ä»¥é€šè¿‡ special core å°†æœ¬ Tile ä¸Šçš„ SPM ä¸è¿œç¨‹ Tile ä¸Šçš„ SPM è¿›è¡Œé€šä¿¡ã€‚\nCGRA Tensor CGRA Tensor æ¨¡å—æ”¯æŒç®—æœ¯è¿ç®—ï¼Œé€»è¾‘è¿ç®—ï¼Œä½æ“ä½œï¼Œæ¿€æ´»å‡½æ•°ï¼Œè¶…è¶Šå‡½æ•°ï¼Œè§„çº¦ï¼Œæ± åŒ–ï¼Œæ•°æ®æ¬ç§»ï¼Œæ ¼å¼è½¬æ¢ï¼Œè¾…åŠ©è®¡ç®—ã€‚\nCGRA\nNeural Core Controller ä¸‹å‘æŒ‡ä»¤åˆ° CTRL_UNITï¼Œç„¶å CTRL_UNIT ä¸‹å‘æŒ‡ä»¤åˆ° RAM_ACC_UNIT. RAM_ACC_UNIT è¯»å…¥ SPM çš„æ•°æ®ï¼Œç„¶åé€å…¥ Pipe Unit è¿›è¡Œè¿ç®—ä¹‹åæŠŠç»“æœå­˜å› SPM.\nCGRA æŒ‡ä»¤æ ¼å¼å¦‚ä¸‹ã€‚ä¾‹å¦‚ CGRATensor_ArithOp_V_V_absï¼ŒæŒ‡ä»¤æ“ä½œæŒ‡çš„æ˜¯å¯¹å‘é‡å…ƒç´ æ±‚ç»å¯¹å€¼ã€‚\næŒ‡ä»¤æ ¼å¼ CGRATensor_function_format_name.type Function æè¿°è¯¥å•å…ƒçš„ä¸»è¦åŠŸèƒ½ï¼Œå¦‚ç®—æ•°è¿ç®—ã€å…³ç³»è¿ç®—ã€é€»è¾‘è¿ç®—ç­‰ï¼› Format æè¿°æ•°æ®çš„å­˜å‚¨æ–¹å¼ï¼Œå¦‚VVã€VSã€Tensorã€VuV åˆ†åˆ«è¡¨ç¤ºå‘é‡ä¸å‘é‡è®¡ç®—ã€å‘é‡ä¸æ ‡é‡è®¡ç®—ã€Tensorè®¡ç®—ã€å‘é‡ä¸å•å…ƒå‘é‡è®¡ç®—ï¼› Name æè¿°å…·ä½“çš„æ“ä½œï¼Œå¦‚åŠ ã€å‡ã€ä¹˜ã€é™¤ç­‰ï¼› Type è¡¨ç¤ºæ•°æ®ç±»å‹ï¼Œå¦‚ bf16/fp32 ç­‰ï¼› ä¸‹é¢å…·ä½“è®²ä¸€ä¸‹åœ¨ BN ç®—å­å¼€å‘ä¸­ç”¨åˆ°çš„ CGRATensor_ArithOp_V_VuV_mul_loop (bf16 *src, bf16 *dst, bf16 *unit, int rnd, int src_elem_num, int unit_elem_num, int full_src_elem_num, int full_unit_elem_num).\nsrc/dst/unit åˆ†åˆ«è¡¨ç¤º ä¹Ÿæ˜¯åŸæ•°æ®/å­˜æ•°/å•å…ƒå‘é‡çš„åœ°å€ã€‚ src_elem_num æ˜¯åšä¸€æ¬¡è¿™ä¸ª VuV ä¸­åŸæ•°æ®çš„ä¸ªæ•°ã€‚ unit_elem_num æ˜¯åšä¸€æ¬¡è¿™ä¸ª VuV ä¸­å•å…ƒå‘é‡æ•°æ®çš„ä¸ªæ•°ã€‚ åœ¨è®² VuV_mul_loop ä¹‹å‰ï¼Œå…ˆæ¥çœ‹ä¸€ä¸‹è¿™ä¸ª VuV_mul ä¹Ÿå°±æ˜¯æ²¡æœ‰å¾ªç¯çš„å•æ¬¡ç‰ˆæœ¬ã€‚åˆ†ä¸ºä¸¤æ¬¡è¿›è¡Œï¼Œç¬¬ä¸€æ¬¡æ˜¯å‰å››ä¸ªè“è‰²çš„æ–¹å—ä¸æ©™è‰²æ–¹å—ç›¸ä¹˜ï¼Œç¬¬äºŒæ¬¡ä¸ºåå››ä¸ªè“è‰²æ–¹å—ä¸æ©™è‰²æ–¹å—ç›¸ä¹˜ã€‚VuV_mul_loop å³æŠŠè¿™ä¸ªè¿‡ç¨‹é‡å¤å¾ˆå¤šæ¬¡ï¼Œæ‰€ä»¥è¦æ±‚ full_src_elem_num/full_unit_elem_num == src_elem_num/unit_elem_numï¼Œå¹¶ä¸”unit_elem_num=64.\nVuV_mul_loop\nTensor Layout layout å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç§\nlayout_str: ä¸­ç«¯ä½¿ç”¨ CNN Op: 1. Feature (NCHW/NHWC) etc. 2. Weight (OIHW/HWOI) etc. Non-CNN Op: å¤§æ¨¡å‹ä¸­å¸¸è§ï¼ŒTensor/NTensorï¼Œå®ƒä»¬çš„åŒºåˆ«æ˜¯ç¬¬ 0 ç»´æ˜¯å¦ä¸º 1. mem_layout: åç«¯ä½¿ç”¨ï¼Œä»£è¡¨äº†åœ¨èŠ¯ç‰‡ä¸Šçš„å®é™…æ’å¸ƒ Tensor/NTensor: æ•°æ®çš„ç´§å¯†æ’å¸ƒ Cx/NCx: å¯¹ Tensor/NTensor æ ¼å¼åŒ–åçš„ç»“æœï¼Œæ–¹ä¾¿æ˜“ç¡¬ä»¶è¯»å–ã€‚ dtype channel description bf16/fp16 /fp32/tf32 c \u0026lt;= 32 NHWC, Cå‘4/8/16/32å¯¹é½ï¼ŒN çš„èµ·å§‹åœ°å€å‘ 2048bit å¯¹é½ c \u0026gt; 32 N[CxHW64, HWC0], C0 å‘ 4/8/16/32 å¯¹é½ï¼ŒN çš„èµ·å§‹åœ°å€å‘2048bit å¯¹é½\nåœ¨ä¸€ä¸ª batch å†…å°† tensor æŒ‰ C åˆ†æˆ Cx*64 å’Œ C0ä¸¤éƒ¨åˆ† int8 c \u0026lt;= 64 NHWC, C å‘ 4/8/16/32/64å¯¹é½ï¼ŒNçš„èµ·å§‹åœ°å€å‘2048bitå¯¹é½ c \u0026gt; 64 N[CxHW128, HWC0], C0 å‘ 4/8/16/32/64 å¯¹é½ï¼ŒNçš„èµ·å§‹åœ°å€å‘ 2048bit å¯¹é½ åœ¨ä¸€ä¸ª batch å†…å°† tensor æŒ‰ C åˆ†æˆ Cx*128 å’ŒC0 ä¸¤éƒ¨åˆ† å¯¹äº fp16 çš„ 2x1x2x131 çš„æ•°æ®ï¼ŒNTensor æ ¼å¼å­˜å‚¨èµ·å§‹åœ°å€ä¸º 0x0000 æŒ‰å„å­˜å‚¨æ ¼å¼æ’åˆ—å¦‚ä¸‹\nNTensor Layout\nNCx: 131 = 64 x 2 + 3, å°† C åˆ†æˆ 2(Cx) ä¸ª 64 å’Œ 4(C0). batch0 çš„ç»“æŸåœ°å€æ˜¯ 0x1080 (4224), batch1 èµ·å§‹åœ°å€éœ€å¯¹é½åˆ° 2048bitï¼Œå³ 4224\u0026ndash;\u0026gt;2048*3=6144 (0x1800).\nNCx Layout\nNeural Engine Neural engine ç±»ä¼¼äº GPU Tensor Coreï¼Œä¸»è¦æ˜¯å®Œæˆå„ç§çŸ©é˜µ (op_Gemm) å’Œå·ç§¯ (op_Conv) ç±»å‹çš„é«˜æ•ˆå¹¶è¡Œ Tensor è®¡ç®—ã€‚PE Array å®ƒçš„è¿›è¡ŒçŸ©é˜µè¿ç®—çš„éƒ¨åˆ†ï¼Œä¸€æ¬¡å®Œæˆ 8x16x8 å¤§å°çš„çŸ©é˜µä¹˜æ³•ã€‚ç„¶åå®ƒçš„è¾“å…¥æœ‰æ¿€æ´» inputï¼Œè¿˜æœ‰ psumï¼Œè¿˜æœ‰ weightï¼Œä¹Ÿå°±æ˜¯æƒé‡ã€‚\nè®¡ç®—ä¹‹åï¼Œè¿˜é¥¿å¯ä»¥è¿›è¡Œåå¤„ç†ï¼Œå¯¹è¿™ä¸ªç»“æœè¿›è¡Œ BN/é‡åŒ–/æ¿€æ´»ç­‰ç­‰ï¼Œç„¶åå†åˆ°è¾“å‡ºï¼Œç„¶åæˆ‘ä»¬è¦ç”¨åˆ°neural engine çš„ç®—å­å…¶å®å¹¶ä¸å¤šï¼Œåªæœ‰ op_Gemm å’Œ op_Conv.\nNeural Engine\nLSU LSU æ˜¯è´Ÿè´£æ•°æ®æ¬è¿çš„ DMA æ§åˆ¶å™¨ã€‚å…·ä½“å®ƒæœ‰ä¸‰éƒ¨åˆ†:\nRDMA: Read DDR \u0026ndash;\u0026gt; SPMï¼Œå¯¹åº”æŒ‡ä»¤æœ‰ op_loadVarï¼Œop_loadConstï¼Œop_rdmaGather. WDMA: Write SPM \u0026ndash;\u0026gt; DDRï¼Œå¯¹åº”æŒ‡ä»¤æœ‰ op_dma_storeï¼Œop_wdmaScatter. TDMA: å¯¹æ‰€å± Tile SPM ä¸Šçš„æ•°æ®è¿›è¡Œæ“ä½œï¼Œå¯¹åº”æŒ‡ä»¤æœ‰ op_reshapeï¼Œop_gatherScatter. LSU\nä¸€ç§ç»å¸¸ä½¿ç”¨ TDMA çš„æƒ…å†µæ˜¯è¿›è¡Œä½ç²¾åº¦åˆ°é«˜ç²¾åº¦çš„è½¬æ¢ã€‚ä»¥ fp16 -\u0026gt; fp32 ä¸ºä¾‹ï¼Œé¦–å…ˆä¼šè°ƒç”¨ op_gatherScatter æŒ‡ä»¤æŠŠç´§å¯†æ’å¸ƒçš„ä½ç²¾åº¦æ•°æ®è¯»è¿›æ¥ç„¶å scatter åˆ° SPM ä¸Šçš„å¯¹åº”ä½ç½®ä»¥ä¿ç•™ç©ºé—´å­˜å‚¨è½¬æ¢åçš„æ•°æ®ï¼›ç„¶åå†è°ƒç”¨ CGAR convert_fp16_fp32 æŒ‡ä»¤è¿›è¡Œç²¾åº¦è½¬æ¢ã€‚\nfp16 to fp32 Conversion\nTX8 Compiler å’Œä¸€èˆ¬ç¼–è¯‘å™¨å·®ä¸å¤šï¼Œå…ˆè·å–å‰ç«¯çš„ Tensorflow/Pytorch ç­‰ç­‰ç”Ÿæˆçš„ mhlo è®¡ç®—å›¾ï¼Œç»è¿‡ä¸­ç«¯çš„å¤„ç†ï¼Œç„¶åè½¬åˆ°åç«¯ã€‚å˜æˆåç«¯ IR. åŒæ—¶åˆä¼šè°ƒç”¨ OPLIB ç®—å­åº“ä¸­çš„ç®—å­æ¥ç”Ÿæˆ main.cï¼Œå°±æ˜¯å¯ä»¥ç›´æ¥æ”¾åœ¨ä¸åŒå¹³å°ä¸Šè¿è¡Œçš„ä¸»ç¨‹åºã€‚å¹³å°å¯ä»¥é€‰æ‹© RISCV å³çœŸå®çš„ç¡¬ä»¶ï¼Œæˆ–è€…æ˜¯ Cmodel è¿›è¡Œæ¨¡æ‹Ÿã€‚\nBEIR ä¸»è¦æ˜¯æ¥è¿‡ä¸­ç«¯ä¼ è¿›æ¥çš„ IRï¼Œç„¶åè¿›è¡Œå„ç±»çš„å›¾ä¼˜åŒ–çš„ Passï¼ŒåŒ…æ‹¬ä¸€äº›ç®—å­åˆ‡åˆ†ï¼Œè¿˜æœ‰å†…å­˜è°ƒåº¦ç­‰ç­‰ã€‚æœ€ç»ˆ codegen è¿™ä¸ªå¯ç¼–è¯‘æ‰§è¡Œçš„ main.c çš„æ–‡ä»¶ã€‚ç„¶åå†æ”¾åœ¨å¹³å°ä¸Šå»ç¼–è¯‘å®Œå†è¿è¡Œã€‚\nTX8 Compiler Workflow\nTX8 BE åç«¯ IR ä½¿ç”¨çš„æ˜¯ MLIRï¼Œç»§æ‰¿ Dialectï¼Œå®šä¹‰äº†è®¸å¤š Operations, Attributes, Types.\ndef Tx8be_Dialect : Dialect { let name = \u0026#34;tx8be\u0026#34;; let summary = \u0026#34;A low-level dialect for tx8 backend specification\u0026#34;; let cppNamespace = \u0026#34;::tx8be_mir::tx8be\u0026#34;; let useDefaultAttributePrinterParser = 1; } Attribute ä¸‹é¢ä»‹ç»ä¸€äº›å¸¸ç”¨çš„ Attribute.\nparallel_attr ä¸»è¦æ˜¯è¡¨ç¤º tensor æ¯ä¸ªç»´åº¦ä¸Šæ•°æ®å¹¶è¡Œå’Œå¼ é‡å¹¶è¡Œçš„åˆ‡åˆ†ç­–ç•¥ã€‚\ndef Tx8be_ParallelAttr : Tx8be_Attr\u0026lt;\u0026#34;Parallel\u0026#34;, \u0026#34;parallel_attr\u0026#34;\u0026gt; { let summary = \u0026#34;Structure of parallel information.\u0026#34;; let parameters = (ins \u0026#34;ParallelModeAttr\u0026#34; : $parallel, \u0026#34;bool\u0026#34; : $is_dp_inner, // dp dimension is in the inner, otherwise tp \u0026#34;i32\u0026#34; : $dp_dim_x, // data parallel dimension at x axis \u0026#34;i32\u0026#34; : $dp_dim_y, // data parallel dimension at y axis \u0026#34;i32\u0026#34; : $dp_dim_z, // data parallel dimension at z axis \u0026#34;i32\u0026#34; : $tp_dim_x, // tensor parallel dimension at x axis \u0026#34;i32\u0026#34; : $tp_dim_y, // tensor parallel dimension at y axis \u0026#34;i32\u0026#34; : $tp_dim_z, // tensor parallel dimension at z axis \u0026#34;bool\u0026#34; : $sharding_is_given, // true: is given, false: is not \u0026#34;::mlir::DenseI32ArrayAttr\u0026#34; : $shape_spatial_sharding // Shape split info ); let cppNamespace = \u0026#34;::tx8be_mir::tx8be\u0026#34;; let assemblyFormat = \u0026#34;`\u0026lt;` struct($params) 1\u0026#34;; } dev_attr å±æ€§åŒ…å«\nimm_sizeï¼Œä¹Ÿå°±æ˜¯ç”¨åˆ°çš„è¿™ä¸ªè¾…åŠ©ç©ºé—´çš„å¤§å°ã€‚ mem_layout ä¹Ÿå°±æ˜¯æ•°æ®çš„å­˜å‚¨æ•°æ®çš„æ’å¸ƒã€‚ multi_buf_en æŒ‡æ˜¯å¦ä½¿ç”¨ double buffer. out_shape_buf_idx æŒ‡çš„æ˜¯è¾“å‡ºä½¿ç”¨ç¬¬å‡ ä¸ªç¼“å†²åŒºã€‚ temporal_mem_slice æ˜¯å•ä¸ª Tile æ¯æ¬¡å¤„ç†çš„æ•°æ®å¤§å°ã€‚ def Tx8be_DevAttr : Tx8be_Attr\u0026lt;\u0026#34;Dev\u0026#34;, \u0026#34;dev_attr\u0026#34;\u0026gt; { let summary = \u0026#34;Structure of op parameters on device.\u0026#34;; let parameters = (ins \u0026#34;uint64_t\u0026#34; : $imm_size, // Output memory addr offset \u0026#34;LayoutModeAttr\u0026#34; : $mem_layout, // Layout \u0026#34;bool\u0026#34; : $multi_buf_en, // for double buffering \u0026#34;int32_t\u0026#34; : $multi_buf_num, // for double buffering \u0026#34;mlir::DenseI64ArrayAttr\u0026#34; : $out_shape_buf_idx, // index for dynamic shape buffer on runtime \u0026#34;mlir::DenseI64ArrayAttr\u0026#34; : $temporal_mem_slice, // for compute local buffer size \u0026#34;int32_t\u0026#34; : $source_type, // Software pipeline stage \u0026#34;int64_t\u0026#34; : $imm_addr, \u0026#34;mlir::DenseI64ArrayAttr\u0026#34; : $mem_addr // use array for multibuffer ); let cppNamespace = \u0026#34;::tx8be_mir::tx8be\u0026#34;; let assemblyFormat = \u0026#34;`\u0026lt;` struct($params) `\u0026gt;`\u0026#34;; } MemScopeMode ç”¨äºæè¿°æ•°æ®å­˜å‚¨åœ¨å“ªé‡Œã€‚\ndef Tx8be_MemScopeMode : I32EnumAttr\u0026lt;\u0026#34;MemScopeMode\u0026#34;, \u0026#34;Specify the memory scope\u0026#34;, [ I32EnumAttrCase\u0026lt;\u0026#34;DDR\u0026#34;, 0\u0026gt;, I32EnumAttrCase\u0026lt;\u0026#34;SPM\u0026#34;, 1\u0026gt;, I32EnumAttrCase\u0026lt;\u0026#34;3DDRAM\u0026#34;, 2\u0026gt; ]\u0026gt; { let genSpecializedAttr = 0; let cppNamespace = \u0026#34;::tx8be_mir::tx8be\u0026#34;; } Types å®šä¹‰äº†å¾ˆå¤šç±»å‹ï¼Œå®é™…ä¸Šå¸¸ç”¨çš„å°±æ˜¯ AnyTensorOrNone.\ndef AnyTensorOrNone: AnyTypeOf\u0026lt;[AnyRankedTensor, NoneType]\u0026gt;; def Tx8be_Tuple : NestedTupleOf\u0026lt;[AnyRankedTensor]\u0026gt;; def AnyTensorOrTuple : AnyTypeOf\u0026lt;[AnyRankedTensor, Tx8be_Tuple]\u0026gt;; def Tx8be_Pred : TypeAlias\u0026lt;I1, \u0026#34;pred (AKA boolean or 1-bit integer)\u0026#34;\u0026gt;; def Tx8be_PredTensor : TensorOf\u0026lt;[Tx8be_Pred]\u0026gt;; def Tx8be_Token : Type\u0026lt;CPred \u0026#34;{$_self-\u0026gt;isa\u0026lt;TokenType\u0026gt;()}\u0026#34;, \u0026#34;token\u0026#34;\u0026gt;; def Tx8be_TensorOrTokenOrTuple : AnyTypeOf\u0026lt;[AnyTensor, Tx8be_Token, Tx8be_Tuple]\u0026gt;; def Tx8be_SInt : SignlessIntOfWidths\u0026lt;[4, 8, 16, 32, 64]\u0026gt;; def Tx8be_UInt : UnsignedIntOfWidths\u0026lt;[4, 8, 16, 32, 64]\u0026gt;; def Tx8be_Int : AnyTypeOf\u0026lt;[Tx8be_SInt, Tx8be_UInt]\u0026gt;; Operations ä»¥å¼€å‘çš„ BatchNorm_InferenceOp ä¸ºä¾‹è®²è§£ä¸€ä¸‹ Tx8be ä¸­å…³äºç®—å­çš„å®šä¹‰ã€‚é¦–å…ˆ batchnorm æ˜¯å°†é€šé“ç»´åº¦è§†ä½œæ ·æœ¬ï¼Œè®¡ç®—å…¶ä»–ç»´åº¦çš„å¹³å‡å€¼å’Œæ–¹å·®åè¿›è¡Œå½’ä¸€åŒ–çš„æ“ä½œã€‚\n$$ \\begin{aligned} BatchNorm\\colon y\u0026=\\gamma\\:\\frac{x-Mean(x)}{\\sqrt{Var(x)+\\varepsilon}}+\\beta\\\\ Mean(x)\u0026=\\frac{1}{N}\\sum_{i=1}^{N}x_{i}\\\\ Var(x)\u0026=\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-Mean(x))^{2}\\end{aligned}$$ä¸­æ‹¬å·å†…æ˜¯ä¸€äº›éœ€è¦ç»§æ‰¿çš„ Interface. å…¶å…è®¸ attributes, operations å’Œ types å…¬å¼€æ–¹æ³•è°ƒç”¨æ¥å£ï¼Œè€Œä¸éœ€è¦è°ƒç”¨è€…çŸ¥é“ç‰¹å®šçš„æ´¾ç”Ÿç±»å‹ã€‚\narguments æŒ‡å®šäº†ç®—å­éœ€è¦çš„è¾“å…¥ï¼ŒåŒ…æ‹¬å‚æ•°ä»¥åŠä¹‹å‰ä»‹ç»åˆ°çš„ä¸€äº›å±æ€§ã€‚\ndef Tx8be_BatchNorm_InferenceOp : Tx8be_Op\u0026lt;\u0026#34;BatchNorm_Inference\u0026#34;, [DeclareOpInterfaceMethods\u0026lt;oplibinterface\u0026gt;, DeclareOpInterfaceMethods\u0026lt;ShardingInterface\u0026gt;, DeclareOpInterfaceMethods\u0026lt;ComputeInterface\u0026gt;] { let summary = \u0026#34;BatchNorm inference\u0026#34;; let description = [{ Normalizes the operand tensor across all dimensions except for the c dimension and produce a result tensor. }]; let arguments = (ins AnyTensor:$input, AnyTensor:$scale, AnyTensor:$offset, AnyTensor:$mean, AnyTensor:$variance, DefaultValueOptionalStrAttr\u0026lt;StrAttr, \u0026#34;Unknown\u0026#34;\u0026gt;:$layout_str, // The following are backend parameters OptionalAttr\u0026lt;Tx8be_ParallelAttr\u0026gt;:$chip_parallel, OptionalAttr\u0026lt;Tx8be_ParallelAttr\u0026gt;:$tile_parallel, OptionalAttr\u0026lt;Tx8be_DevAttr\u0026gt;:$dev_info ); let results = (outs AnyTensor:$output); } Interface Interface å®šä¹‰ä¸€äº›é€šç”¨çš„æ–¹æ³•æˆ–è¡Œä¸ºï¼Œè¿™äº›æ–¹æ³•æ²¡æœ‰å…·ä½“å®ç°ã€‚è¦é€šè¿‡ç»§æ‰¿æŸä¸ª Interface æ¥å…·ä½“å®ç°è¯¥æ¥å£çš„æ–¹æ³•å’Œè¡Œä¸ºã€‚tx8ä¸­å®šä¹‰äº† 5 ä¸ª Interface: OpLibInterface, ComputeInterface, ShapeInferenceOpInterface, ShardingInterface, StreamConfigInterface.\nBatchNorm ç®—å­å¼€å‘ä¸­åªç”¨åˆ°äº†å‰å››ä¸ªï¼Œä¸‹é¢ä¾æ¬¡ä»‹ç»ä¸€ä¸‹ã€‚\nShapeInferenceOpInterface å®šä¹‰äº†ä¸¤ä¸ªæ–¹æ³• inferShapes å’Œ inferLayout. ç»§æ‰¿è¿™ä¸ªæ¥å£çš„è¯å°±éœ€è¦å®ç°è¿™ä¸¤ç§æ–¹æ³•ã€‚æ ¹ä¸»è¦æ˜¯æ ¹æ®è¾“å…¥æ¥æ¨æ–­è¾“å‡ºçš„å½¢çŠ¶å’Œå¸ƒå±€ã€‚\ndef ShapeInferenceOpInterface : OpInterface\u0026lt;\u0026#34;ShapeInferenceOpInterface\u0026#34;\u0026gt; { let description = [{ }]; let cppNamespace = \u0026#34;::tx8be_mlir\u0026#34;; let methods = [ InterfaceMethod\u0026lt; [{ }], /*retType=*/\u0026#34;mlir::LogicalResult\u0026#34;, /*methodName=*/\u0026#34;inferShapes\u0026#34;, // method name /*args=*/(ins \u0026#34;DynamicShapeParam\u0026#34; : $shapeParam) \u0026gt;, InterfaceMethod\u0026lt; [{ }], /*retType=*/\u0026#34;mlir::LogicalResult\u0026#34;, /*methodName=*/\u0026#34;inferLayout\u0026#34;, // method name /*args=*/(ins) \u0026gt; ]; } ç”±äº batchnorm ä¸å¯¹è¿™ä¸¤è€…è¿›è¡Œæ”¹å˜ï¼Œå› æ­¤è¾“å‡ºå’Œè¾“å…¥ç›¸åŒã€‚å¦‚æœæ˜¯éœ€è¦æ”¹å˜çš„ç®—å­æ¯”å¦‚ transpose å°±éœ€è¦è¿›è¡Œæ”¹å˜ã€‚\ninput_data \u0026lt;shape=3x4x5x6, layout=NCHW\u0026gt; --\u0026gt; transpose\u0026lt;permutation=(0,2,3,1)\u0026gt; --\u0026gt; output_data\u0026lt;shape=3x5x6x4, layout=NHWC\u0026gt;\n// BatchNorm_Interface.cpp ::mlir::LogicalResult tx8be::BatchNorm_InferenceOp::inferLayout() { auto in_op = getValidDefiningOp(getInput()); auto cur_op = getValidDefiningOp(getOutput()); ASSERT(in_op-\u0026gt;hasAttr(\u0026#34;layout_str\u0026#34;)); ASSERT(cur_op-\u0026gt;hasAttr(\u0026#34;layout_str\u0026#34;)); auto i_layout = in_op-\u0026gt;getAttr(\u0026#34;layout_str\u0026#34;).cast\u0026lt;mlir::StringAttr\u0026gt;().getValue().str(); auto ctx = cur_op-\u0026gt;getContext(); cur_op-\u0026gt;setAttr(\u0026#34;layout_str\u0026#34;, mlir::StringAttr::get(ctx, i_layout)); if (in_op-\u0026gt;hasAttr(\u0026#34;dev_info\u0026#34;)) { auto i_dev_layout = getDevInfoLayoutMode(in_op); setDevInfoWithLayout(cur_op-\u0026gt;getContext(), cur_op, i_dev_layout); } return ::mlir::success(); } ::mlir::LogicalResult tx8be::BatchNorm_InferenceOp::inferShapes(DynamicShapeParam \u0026amp;shapeParam) { tx8be::BatchNorm_InferenceOp::getOutput().setType(getInput().getType()); return ::mlir::success(); } ShardingInterface tileShardingSplit å’Œå‰é¢çš„ inferShapes ä»¥åŠ inferLayout ä¸ä¸€æ ·ã€‚åä¸¤è€…æ˜¯ä»è¾“å…¥ä¿¡æ¯æ¨å‡ºè¾“å‡ºçš„ä¿¡æ¯ã€‚è€Œ tileShardingSplit æ˜¯ç”±è¾“å‡ºçš„çš„åˆ‡åˆ†çš„å› å­æ¥æ¨æ–­å‡ºå„ä¸ªè¾“å…¥çš„åˆ‡åˆ†å› å­ã€‚\nBatchNorm ShardingInterface\ndef ShardingInterface : OpInterface\u0026lt;\u0026#34;ShardingInterface\u0026#34;\u0026gt; { let description = [{ }]; let cppNamespace = \u0026#34;::tx8be_mlir\u0026#34;; let methods = [ InterfaceMethod\u0026lt; /*desc=*/[{ }], // vector for diff operand\u0026#39;s info /*retType=*/\u0026#34;std::vector\u0026lt;tx8be_mlr::ShardingSplitParam\u0026gt;\u0026#34;, /*methodName=*/\u0026#34;tileShardingSplit\u0026#34;, /*args=*/(ins \u0026#34;ShardingSplitParam\u0026#34; : $param) \u0026gt;, InterfaceMethod\u0026lt; /*desc=*[{ }], /*retType=*/\u0026#34;std::vector\u0026lt;tx8be_mlr::SliceParam\u0026gt;\u0026#34;, /*methodName=*/\u0026#34;temporalSliceShape\u0026#34;, /*args=*/(ins \u0026#34;SliceParam\u0026#34; : $param) \u0026gt;, InterfaceMethod\u0026lt; /*desc=*[{ }], /*retType=*/\u0026#34;std::vector\u0026lt;tx8be_mlr::WindowParam\u0026gt;\u0026#34;, /*methodName=*/\u0026#34;backWindow\u0026#34;, /*args=*/(ins \u0026#34;const WindowParam\u0026#34; : $param) \u0026gt; ]; } Sharding æ˜¯ç©ºé—´ä¸Šçš„åˆ‡åˆ†ï¼Œæ„æ€æ˜¯å°†æ•°æ®åˆ†æ•£åˆ°ä¸åŒçš„ Tile ä¸Šã€‚ Split æ˜¯æ—¶é—´ä¸Šçš„åˆ‡åˆ†ï¼Œæ„æ€æ˜¯åˆ‡åˆ†åˆ° Tile ä¸Šçš„å°†æ•°æ®æŒ‰æµæ°´çº¿æ–¹å¼è½®æµè¿›è¡Œ load. temporalSliceShape è¿”å›çš„æ˜¯ sharding + split åä¸€ä¸ª Tile ä¸Šå•æ¬¡å¤„ç†çš„æ•°æ®çš„å®é™… shape.\nBatchNorm Sharding Split æ ¹æ® batchnorm ç®—å­å®šä¹‰ input åªèƒ½åœ¨é€šé“ç»´åº¦ä¸Š sharding. split æœ‰ä¸¤ç§é€‰æ‹©\nå¯¹äº input å’Œ meanï¼Œvarï¼Œscaleï¼Œshift éƒ½åœ¨ C ç»´åº¦ä¸Šåšç›¸åŒçš„åˆ‡åˆ†ã€‚ ä¸å† split meanï¼Œvarï¼Œscaleï¼Œshiftï¼Œåªå¯¹ input çš„ NHW è¿›è¡Œ split. è¿™é‡Œé‡‡ç”¨çš„æ˜¯åè€…ã€‚ç”±äº mean, variance, scale, shift éƒ½æ˜¯ 1x1x1xC çš„å¼ é‡ï¼Œå› æ­¤ split ä¸º (1, 1, 1, 1). åˆ‡åˆ†æœç´¢å¾—åˆ°çš„ç¬¦åˆè¦æ±‚çš„ ShardingSplitParam (ä¸‹å›¾ä¸­ä¸º cn3) ä¼šç»§ç»­å‘ä¸Šä¼ é€’ã€‚\nSharding Split Search\nstd::vector\u0026lt;ShardingSplitParam\u0026gt; tx8be::BatchNorm_InferenceOp::tileShardingSplit(ShardingSplitParam \u0026amp;param) { auto shape = getOutput().getType().getShape(); ASSERT(shape.size() == param.outSharding.size() \u0026amp;\u0026amp; shape.size() == param.outSplit.size()); int32_t shape_size = shape.size(); std::vector\u0026lt;ShardingSplitParam\u0026gt; result; result.emplace_back(param); // input for (int32_t i = 0; i \u0026lt; shape_size - 1; ++i) { if (result[0].outSharding.size() \u0026gt; 0 \u0026amp;\u0026amp; result[0].outSharding[i] != 1) { // can only shard in dim C result[0].outSharding.clear(); } if (result[0].outSplit.size() \u0026gt; 0 \u0026amp;\u0026amp; result[0].outSplit[shape_size - 1] != 1) { // can only split except dim C result[0].outSplit.clear(); } } ShardingSplitParam paramMean; // scale/shift/mean/variance if (result[0].outSharding.size() \u0026gt; 0) { paramMean.outSharding = result[0].outSharding; } paramMean.outSplit = std::vector\u0026lt;int32_t\u0026gt;(shape_size, 1); // shape is 1x1x1xCï¼Œsplit must be (1, 1, 1, 1) ShardingSplitParam paramVar = paramMean; ShardingSplitParam paramScale = paramMean; ShardingSplitParam paramShift = paramMean; result.emplace_back(paramScale); result.emplace_back(paramShift); result.emplace_back(paramMean); result.emplace_back(paramVar); return result; } OpLibInterface OpLibInterface æœ‰å››ä¸ªæ–¹æ³•ï¼Œ\ngenOpCode: ç”Ÿæˆ main.c æ–‡ä»¶çš„æ—¶å€™æ‰€è°ƒç”¨çš„ä¸€ä¸ªæ¥å£ã€‚ getOpClockCycle: è·å– OP çš„æ‰§è¡Œæ—¶é—´ã€‚ getImmSpSize: è·å– SPM ä¸Šä¸´æ—¶ç©ºé—´æ‰€éœ€è¦çš„å¤§å°ã€‚ queryOpAttr: æŸ¥è¯¢è¿™ä¸ª OP çš„ä¸€äº›å±æ€§ã€‚ def OpLibInterface : OpInterface\u0026lt;\u0026#34;OpLibInterface\u0026#34;\u0026gt; { let description = [{ These are the interfaces for connecting tx8be-oplib and codegen. }]; let cppNamespace = \u0026#34;::tx8be_mlir\u0026#34;; let methods = [ InterfaceMethod\u0026lt; /*desc=*/[{To generate the code of op.}], /*retType=*/\u0026#34;std::string\u0026#34;, /*methodName=*/\u0026#34;genOpCode\u0026#34;, /*args=*/(ins \u0026#34;OpCodeParam\u0026#34; : $param) \u0026gt;, InterfaceMethod\u0026lt; /*desc=*/[{To get clock cycle of the op.}], /*retType=*/\u0026#34;uint64_t\u0026#34;, /*methodName=*/\u0026#34;getOpClockCycle\u0026#34;, /*args=*/(ins) \u0026gt;, InterfaceMethod\u0026lt; /*desc=*/[{To get the immediate SPM buffer size.}], /*retType=*/\u0026#34;uint32_t\u0026#34;, \u0026#34;getImmSpSize\u0026#34;, /*args=*/(ins) \u0026gt;, InterfaceMethod\u0026lt; /*desc=*/[{To get the opAttr info.}], /*retType=*/\u0026#34;tx8be_mlr::opAttr\u0026#34;, /*methodName=*/\u0026#34;queryOpAttr\u0026#34;, /*args=*/(ins) \u0026gt; ]; } å…¶ä¸­ queryOpAttr æ¥å£åªéœ€è¦åœ¨å¯¹åº”çš„æ¥å£é‡Œç»™ OpAttr é‡Œçš„å‚æ•°èµ‹å€¼ã€‚\nalignMode: ç®—å­çš„å¯¹é½è¦æ±‚ï¼Œæœ‰Cxå¯¹é½è¦æ±‚ï¼ŒNCx å¯¹é½è¦æ±‚ï¼Œæˆ–è€…ä¸åœ¨æ„å­˜å‚¨æ ¼å¼çš„ã€‚ defaultLayout: ç®—å­é»˜è®¤çš„æ’å¸ƒã€‚ needPresetToNPU: OP æ˜¯å¦éœ€è¦è¿›è¡Œé¢„è®¾åˆ°å’Œç¡¬ä»¶åŒ¹é…çš„ layout. å½“ç®—å­ç”¨åˆ°çš„æŒ‡ä»¤æ˜¯å¸¦æœ‰ NHWC çš„é…ç½®æ—¶å€™çš„éœ€è¦ã€‚ memInplace: è¾“å…¥å’Œè¾“å‡ºèƒ½å¦ä½¿ç”¨åŒä¸€ç‰‡å†…å­˜ã€‚ needLoad: ç®—å­æ˜¯å¦éœ€è¦ load æ“ä½œï¼Œæ¯”å¦‚ mask, embedding å°±ä¸éœ€è¦ï¼Œä¼šè·³è¿‡loadvar op ç”Ÿæˆã€‚bit0 è¡¨ç¤º arg idx0ï¼Œbit1 è¡¨ç¤º arg idx1ï¼Œä¸€å…±èƒ½è¡¨ç¤º 64 ä¸ªè¾“å…¥æƒ…å†µã€‚å¦‚æœæ˜¯constè¾“å…¥ï¼Œloadconst ä¹Ÿä¼šè·³è¿‡codegen ä¸ç”Ÿæˆ code. ä¸€ä¸ªopå¯èƒ½æœ‰å¤šä¸ª input éƒ½æ²¡æœ‰ loadï¼Œshape æ›´æ–°åªç”¨æœ€åä¸€ä¸ªæ²¡æœ‰ load çš„ operand (ä¸º 0 çš„æœ€é«˜ä½). å¦‚ embedding çš„ shapeä½¿ç”¨æœ€åä¸€ä¸ª operandï¼Œç¬¬ä¸€ä¸ªæ˜¯ weight ä¸ç”¨ç®¡ gshape. scatteræœ‰çš„æœ‰loadï¼Œæœ‰çš„æ²¡æœ‰ï¼Œshape æ›´æ–°åªçœ‹æ²¡æœ‰ load çš„é‚£ä¸ªã€‚\nneedStore: æ•°æ®æ˜¯å¦éœ€è¦è¿›è¡Œ store æ“ä½œï¼Œä¼šè·³è¿‡store op ç”Ÿæˆã€‚ parallel: æ˜¯å¦å…è®¸å¹¶è¡Œæ¨¡å¼ã€‚ alignCx: æœ€ä½ç»´åº¦åˆ‡åˆ†æ˜¯å¦åˆ° 64/128 (i8). struct OpAttr { ALIGN_MODE alignMode{ALIGN_MODE::NPU_UNKNOWN}; // ç®—å­çš„å¯¹é½è¦æ±‚ï¼Œæœ‰Cxå¯¹é½è¦æ±‚ï¼ŒNCxå¯¹é½è¦æ±‚ï¼Œæˆ–è€…ä¸åœ¨æ„å­˜å‚¨æ ¼å¼çš„ std::string defaultLayout{\u0026#34;Tensor\u0026#34;}; // ç®—å­é»˜è®¤çš„layout bool needPresetToNPU{false}; // opæ˜¯å¦éœ€è¦è¿›è¡Œé¢„è®¾åˆ°å’Œç¡¬ä»¶åŒ¹é…çš„layout. å½“ç®—å­ç”¨åˆ°çš„æŒ‡ä»¤æ˜¯å¸¦æœ‰ nhwc çš„é…ç½®æ—¶éœ€è¦ ENGINE_TYPE engine{NPU_ENGINE_CT}; bool memInplace{false}; // opçš„è¾“å…¥å’Œè¾“å‡ºèƒ½å¦ä½¿ç”¨åŒä¸€ç‰‡memoryï¼Œæ¯”å¦‚addçš„outä½¿ç”¨in0çš„ uint64_t needLoad{0xFFFFFFFFFFFFFFFF}; // ç®—å­æ˜¯å¦éœ€è¦loadæ“ä½œ uint64_t needStore{0xFFFFFFFFFFFFFFFF}; // æ•°æ®æ˜¯å¦éœ€è¦è¿›è¡Œstoreæ“ä½œï¼Œä¼šè·³è¿‡store opç”Ÿæˆ bool parallel{1}; // ä¸€èˆ¬è¦ä½¿èƒ½å¹¶è¡Œæ¨¡å¼ï¼Œä¸è¿‡æœ‰çš„memoryå¯èƒ½æœ‰é—®é¢˜ï¼Œå°±ä¸ä½¿èƒ½ bool alignCx{1}; // æœ€ä½ç»´åº¦åˆ‡åˆ†æ˜¯å¦åˆ°64/128(i8) }; batchnorm å…è®¸è¾“å…¥ in çš„ layout ä¸º Cx/NCxï¼Œè¦åœ¨ mlir å±‚çš„ queryOpAttr() é‡Œå°† alignMode è®¾ç½®ä¸ºNPU_ALIGN, ç»´åº¦ä¸º 2/3/4ï¼Œæ•°æ®ç±»å‹ä¸º bf16/fp16/fp32/tf32. å…¶ä»–è¾“å…¥çš„æ ¼å¼ä¸º fp32. è¾“å‡ºçš„ç»´åº¦å’Œç±»å‹ä¸ in ä¿æŒä¸€è‡´ã€‚\nOpAttr tx8be::BatchNorm_InferenceOp::queryOpAttr() { OpAttr attr; // åˆ›å»ºä¸€ä¸ª OpAttr å¯¹è±¡ attr.alignMode = ALIGN_MODE::NPU_ALIGN; // è®¾ç½®å¯¹é½æ¨¡å¼ä¸º NPU_ALIGN attr.needPresetToNPU = true; // è®¾ç½®éœ€è¦é¢„è®¾åˆ° NPU // è·å– in çš„å½¢çŠ¶ï¼Œå¹¶åˆ¤æ–­å…¶ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯å¦ä¸º 1 auto batch = getOperand(0).getType().cast\u0026lt;mlir::ShapedType\u0026gt;().getShape()[0]; attr.defaultLayout = batch == 1 ? \u0026#34;Tensor\u0026#34; : \u0026#34;NTensor\u0026#34;; // æ ¹æ® batch çš„å€¼è®¾ç½®é»˜è®¤å¸ƒå±€ return attr; } å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåç«¯ç¼–è¯‘å™¨ä¼šè°ƒç”¨ genOpCode ç”Ÿæˆç›¸å¯¹åº”çš„ main.c. ç„¶å host.cpp å†æŠŠ main.c æ”¾åˆ°ä¸åŒçš„å¹³å°ä¸Šé¢å»ç¼–è¯‘å®Œå†å»æ‰§è¡Œã€‚\nOpLibInterface\nmain.c ä¸»è¦åšçš„å°±æ˜¯ load \u0026ndash;\u0026gt; compute \u0026ndash;\u0026gt; store è¿™ä¸‰æ­¥ã€‚ä¼ªä»£ç å¦‚ä¸‹ï¼Œç”±äºè¿›è¡Œäº†æ—¶é—´ä¸Šçš„ splitï¼Œéœ€è¦å¾ªç¯å¤šæ¬¡æ‰èƒ½è¯»å–å®Œæ•´çš„æ•°æ®ã€‚\nwhile(!input_done) { // load op_dma_load Input; input_done = Input.load_finish; op_dma_load scale; op_dma_load shift; op_dma_load mean; op_dma_load varience; // compute op_batchnorm_inference(param, input, scale, shift, mean, varience, out); // store op_store_var_ncx out; } op_batchnorm_inference çš„å®šä¹‰å¦‚ä¸‹ï¼Œå…¶ä¸­ imm æ˜¯è¾…åŠ©ç©ºé—´ï¼Œæ­¤å¤„ç”³è¯·äº† 2xsizeof(input) Bytes.\nuint64_t op_batchnorm_inference(BATCHNORM_INFER_PARAM *param, TSR *in, TSR *scale, TSR *shift, TSR *mean, TSR *var, TSR *imm, TSR *out); å…¶ä¸­ TSR æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰çš„ç»“æ„ä½“ï¼ŒåŒ…æ‹¬æ•°æ®æ ¼å¼ï¼Œåœ°å€ä»¥åŠä¸€ä¸ª L_shape (load shape). é‡Œé¢è®°å½•äº†å¼ é‡å®Œæ•´çš„å¤§å° shape_wholeï¼Œä»¥åŠæœ¬ Tile ä¸Šæ¯ä¸ªç»´åº¦èµ·å§‹ä¸‹æ ‡ shape_startï¼Œæ¯ä¸ªç»´åº¦åŠ è½½çš„å¤§å° shape_slice å’Œ shape çš„ç»´åº¦å¤§å° dim.\ntypedef struct L_SHAPE { int32_t shape_whole[MAX_SHAPE_DIM]; // the whole shape int32_t shape_start[MAX_SHAPE_DIM]; // start idx of the shape slice int32_t shape_slice[MAX_SHAPE_DIM]; // length of the shape slice int32_t shape_real[MAX_SHAPE_DIM]; // real length of the shape slice int32_t dim; // dimension of the shape } L_SHAPE; typedef struct G_SHAPE { int32_t spatial_start[MAX_SHAPE_DIM]; // [start, end] int32_t spatial_end[MAX_SHAPE_DIM]; int32_t dynamic_offset[MAX_SHAPE_DIM]; int32_t shape[MAX_SHAPE_DIM]; int32_t dim; int32_t done; // done for dma load finish int32_t batch_offset[MAX_SHAPE_DIM]; } G_SHAPE; typedef struct TSR { Data_Format format; uint64_t addr; L_SHAPE* shape; } TSR; BatchNorm Design\nå¯¹äºé fp32 ç±»å‹æ•°æ® (ä»¥ fp16 ä¸ºä¾‹) è®¡ç®—è¿‡ç¨‹ä¸ç©ºé—´åˆ†é…å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\nç±»å‹è½¬æ¢æˆ fp32: gatherScatter. è°ƒç”¨ fp16-\u0026gt;fp32 å‡½æ•°è¿›è¡Œè½¬æ¢ã€‚ å¾ªç¯è®¡ç®— x-Mean (å› ä¸ºå¯¹ in çš„ NHW ç»´åº¦è¿›è¡Œäº† split)ï¼Œç»“æœå­˜å…¥ imm_a. Varience è‡ªåŠ  epsilon(1e-6). Varience è¿›è¡Œ rsqrt æ“ä½œã€‚ Varience ä¸ x-Mean è¿›è¡Œå¾ªç¯ä¹˜ã€‚ å¾ªç¯ä¹˜ scale. å¾ªç¯åŠ  shift. fp32 è½¬å› f16. gatherScatter åˆ° out å¤„ã€‚ Batchnorm Computation Flow\nè¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ shift(1, 1, 1, C) å’Œå½’ä¸€åŒ–åçš„ x(N, H, W, C) ç›¸ä¹˜çš„æ—¶å€™ï¼Œè¿™æ—¶å€™å°±ç”¨åˆ°äº†ä¹‹å‰æ‰€è¯´çš„ VuV_mul å’Œ VuV_mul_loop æŒ‡ä»¤ã€‚\nå½“ C \u0026lt;= 32 æ—¶ï¼Œä¸€ä¸ª batch å†…çš„æ•°æ®æ’å¸ƒå¦‚ä¸‹ (ä»¥ (4x112x2x30) x (1x1x1x30) ä¸ºä¾‹)ï¼Œæ­¤æ—¶æˆ‘ä»¬åœ¨ batch ç»´åº¦ä¸Šå¾ªç¯è°ƒç”¨ VuV_mul æŒ‡ä»¤å°±å¯ä»¥ã€‚\nChannel \u0026lt;= 32\nå½“ C \u0026gt; 32 æ—¶ï¼Œéœ€è¦å‘ 64 å¯¹é½ï¼Œä¸€ä¸ª batch å†…çš„æ•°æ®æ’å¸ƒå¦‚ä¸‹ (ä»¥ (4x112x2x129) x (1x1x1x129) ä¸ºä¾‹)ï¼Œæ¯ä¸€ä¸ª Cx/C0 å¯¹åº”ç€ä¸€æ¬¡ VuV_mul. æ­¤æ—¶æˆ‘ä»¬åœ¨ batch ç»´åº¦ä¸Šå¾ªç¯è°ƒç”¨ VuV_mul_loop æŒ‡ä»¤å°±å¯ä»¥ã€‚\nChannel \u0026gt; 32\nä¸‹é¢æ¥è¯´æ˜å¦‚ä½•è°ƒç”¨æŒ‡ä»¤ï¼Œé¦–å…ˆè¦æ˜ç¡®è°ƒç”¨çš„æŒ‡ä»¤æ˜¯å±äºå“ªä¸€ä¸ªæ¨¡å—çš„ã€‚ä¾‹å¦‚ç¬¬å››æ­¥åŠ  epsilon æˆ‘ä»¬éœ€è¦è°ƒç”¨ addVs æŒ‡ä»¤ï¼Œå…¶å±äº CGRA æ¨¡å—ã€‚\ntypedef enum OP_INSTR_TYPE { I_CGRA, I_NEUR, I_RDMA, I_WDMA, I_TDMA, I_SCALAR, I_DTE, I_CSR, } OP_INSTR_TYPE; æ¯ä¸ªæ¨¡å—ä¸‹çš„æŒ‡ä»¤æœ‰è‡ªå·±çš„å‚æ•°å½¢å¼ï¼Œä¸‹é¢åˆ—ä¸¾ä¸€äº›ã€‚\n// I_CGRA typedef struct CT_Param { uint32_t inter_type; Ncc_CT_GR_Ctl_Regs ctrl; Ncc_CT_GR_Param_Regs param; } CT_Param; // I_NEUR typedef struct TsmNeInstr { uint32_t inter_type; Ncc_NE_GR_Ctl_Regs ctrl; Ncc_NE_GR_Param_Regs param; } TsmNeInstr; // I_(R/W)DMA typedef struct DMA_Param { uint32_t inter_type; Ncc_DMA_GR_Ctl_Regs ctrl; Ncc_DMA_GR_Param_Regs param; } DMA_Param; // I_TDMA typedef struct TD_Param { uint32_t inter_type; Ncc_TDMA_GR_Ctl_Regs ctrl; Ncc_TDMA_GR_Param_Regs param; } TD_Param; è¿˜æ˜¯ä»¥ AddVS æŒ‡ä»¤ä¸ºä¾‹ï¼Œæµç¨‹å¦‚ä¸‹\nå£°æ˜æ¨¡å—çš„æŒ‡ä»¤å‚æ•°ã€‚ å£°æ˜å¯¹åº”çš„æŒ‡ä»¤ç±»å‹æŒ‡é’ˆï¼ŒAddVS å±äº arith ç±»å‹çš„æŒ‡ä»¤ã€‚getTsmOpPointer()-\u0026gt;arith_pointer;`. æ ¹æ®è°ƒç”¨æŒ‡ä»¤ä¼ å…¥å‚æ•°ï¼ŒæŒ‡ä»¤ä¼šæ ¹æ®ä¼ å…¥å‚æ•°é…ç½®å¥½ ct_param ä¸Šå¯„å­˜å™¨çš„å€¼ã€‚ç„¶åå†è¿›è¡Œ TsmExecute. æœ€åå†æŠŠå•è¯æŒ‡ä»¤çš„æ‰§è¡Œæ—¶é—´è¿›è¡Œç´¯åŠ ã€‚ CT_Param ct_param = {I_CGRA, {0}, {0}}; // step 1 TsmArith *arith = (TsmArith *)getTsmOpPointer()-\u0026gt;arith_pointer; // step 2 // variance add epsilon float epsilon = 1e-6; arith-\u0026gt;addVS(\u0026amp;ct_param, // engine params varAddr, // vector address *(uint32_t *)(\u0026amp;epsilon), // scalar address varAddr, // result address mid_tensor_info.total_num, // vector elements num RND_NEAREST_EVEN, // round method Fmt_FP32); // data format cycle_single = TsmExecute(\u0026amp;ct_param); cycle_total = ADD_VALID_CYCLE(cycle_total, cycle_single); ComputeInteface ComputeInterface è¿™ä¸ªæ¥å£ä¸»è¦æ˜¯æ¯ä¸ª OP é€šè¿‡ onednn å¾—åˆ° CPU ä»£ç ã€‚æˆ–è€…è®¡ç®—æ¯”è¾ƒç®€å•çš„ OP å¦‚æœåœ¨ onednn çš„æ¥å£ä¸­æ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„è®¡ç®—ï¼Œä¹Ÿå¯ä»¥åœ¨ compute æ¥å£ä¸­æ‰‹å†™å½“å‰ OP çš„ CPU å®ç°çš„ C++ä»£ç ã€‚æœ€ç»ˆç”Ÿæˆç»“æœä¼šç”¨æ¥æ£€éªŒç®—å­æ­£ç¡®æ€§ã€‚\ndef ComputeInterface : OpInterface\u0026lt;\u0026#34;ComputeInterface\u0026#34;\u0026gt; { let description = []; let cppNamespace = \u0026#34;::tx8be_mlir\u0026#34;; let methods = [ InterfaceMethod\u0026lt; /*desc=*/[], /*retType=*/\u0026#34;::mlir::LogicalResult\u0026#34;, /*methodName=*/\u0026#34;compute\u0026#34;, /*args=*/(ins \u0026#34;ComputeParam\u0026amp;\u0026#34;:$param) \u0026gt;, ]; } Test Case TestCase ä¸»è¦ä½œç”¨æ˜¯å†™å•ç®—å­æˆ–è€…å¤šä¸ª (å•ç®—å­çš„ä¸Šä¸‹æ–‡ç®—å­) çš„æµ‹è¯•ï¼ŒåŒ…æ‹¬å›ºå®šé…ç½®æµ‹è¯•å’Œéšæœºé…ç½®æµ‹è¯•,éšæœºé…ç½®æ—¶ä¸»è¦å¯¹äºç®—å­æ”¯æŒçš„ä¸åŒ dim, layout, dtype, shape è¿™å››é¡¹åšéšæœºã€‚æµç¨‹ä¸»è¦åšä»¥ä¸‹å‡ ä»¶äº‹ã€‚\ninit_param\né€šè¿‡æ•°ç»„æ¥é…ç½®å›ºå®šæµ‹è¯• case æˆ–è€…éšæœºæµ‹è¯•èŒƒå›´ï¼Œç„¶åé€šè¿‡æŒ‡å®šæˆ–éšæœºçš„æ–¹å¼ç”Ÿæˆå¯¹åº”çš„è¾“å…¥ï¼Œè¾“å‡ºçš„ shapeï¼Œ dim ä¿¡æ¯ï¼Œé™¤æ­¤ä¹‹å¤–å‚ä¸éšæœºçš„ä¸€èˆ¬è¿˜åŒ…æ‹¬æ•°æ®å¯¹é½æ–¹å¼éšæœºï¼Œæ•°æ®ç±»å‹éšæœºï¼Œå³åœ¨ç®—å­å¯æ”¯æŒçš„èŒƒå›´å†…äº§ç”Ÿéšæœºçš„ FP16/FP32 ä¸åŒçš„æ•°æ®ç±»å‹æ¥ä¿è¯æµ‹è¯•çš„å……åˆ†å’Œå…¨é¢ã€‚\né™¤æ­¤ä¹‹å¤–è¿˜ä¼šç”Ÿæˆ MLIR Module. è¿™ä¸ª module æ˜¯åŸæ¥å°±ç»™å®šçš„ï¼Œåœ¨è¿™é‡Œåšçš„äº‹æƒ…æ˜¯é¦–å…ˆæ–°å»ºä¸€ä¸ªç©ºçš„ func. ç„¶ååœ¨è¿™ä¸ª func ä¸­æ„é€ ä¸€ä¸ª blockï¼Œé‡Œé¢å»å¡«å…¥éœ€è¦æµ‹è¯•çš„è¿™äº› OP çš„ç»“æ„ã€‚\nModuleï¼šä¸€ä¸ªç¨‹åºçš„å®¹å™¨ï¼ŒåŒ…å«å¤šä¸ªå‡½æ•°ã€‚ Funcï¼šå®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼ŒåŒ…å«å¤šä¸ª Block. Blockï¼šå®šä¹‰å‡½æ•°çš„åŸºæœ¬æ‰§è¡Œå•å…ƒï¼ŒåŒ…å«å¤šä¸ª Operation. Operationï¼šè¡¨ç¤ºå…·ä½“çš„è®¡ç®—æˆ–æ“ä½œï¼Œæ˜¯ç¨‹åºä¸­çš„åŸºæœ¬æŒ‡ä»¤ã€‚ MLIR Structure init_data\nè¿™ä¸ªæ–¹æ³•ä¸»è¦ç”¨æ¥é€šè¿‡ä¸Šé¢ Param ç”Ÿæˆçš„ dimã€è¾“å…¥æˆ–è€…è¾“å‡º shapeã€æ•°æ®ç±»å‹æ¥ç”Ÿæˆéšæœºçš„æ•°æ®ï¼Œæ•°æ®èŒƒå›´ä¸€å®šè¦æ ¹æ®ç®—å­æƒ…å†µé…ç½®ï¼Œä¸ç„¶æ— æ•ˆæ•°å€¼å¯èƒ½ä¼šåœ¨ç»“æœä¸­å‡ºç° Nan. è¿˜è¦è€ƒè™‘ä¸€äº›ç®—å­çš„ç‰¹ç‚¹ï¼Œä¿è¯æµ‹è¯•çš„å……åˆ†æ€§ï¼Œä¾‹å¦‚åˆ›å»º relu çš„æ•°æ®æ—¶ï¼Œæœ€å¥½æ­£è´Ÿå€¼éƒ½æœ‰è¦†ç›–ã€‚\ncompile\ncompile æ–¹æ³•æœ‰ä¸¤ä¸ªåŠŸèƒ½\nè°ƒç”¨ Computelnterface ç”Ÿæˆ onednn æˆ–è€…æ‰‹å†™ CPU ç®—å­å®ç°çš„ç»“æœã€‚ æ·»åŠ ä¸€äº›é…ç½®å‚æ•°ï¼Œè·‘å‡º tx8be mlir codegen çš„ç»“æœã€‚è¿™å…¶ä¸­ä¼šç»å†ä¸€äº›éå¸¸å¤æ‚çš„ passï¼Œç¨åå†ä»‹ç»ã€‚ saveInfoFile\nsaveInfoFile æ–¹æ³•ä¸»è¦æ˜¯æŠŠåˆ›å»ºå‡ºçš„ Data æ•°æ®å†™æˆ.bin æ–‡ä»¶ä¿å­˜ã€‚å¹¶æŠŠåˆ›å»ºå‡ºçš„ module çš„ä¿¡æ¯ä¿å­˜åœ¨ json æ–‡ä»¶ã€‚\nOverview of Workflow åç«¯æ¥æ”¶çš„æ˜¯ MLIR çš„è®¡ç®—å›¾ï¼Œç„¶åç»è¿‡ç¼–è¯‘å™¨åç«¯çš„å¤„ç†ï¼Œç„¶åç”Ÿæˆæœ€åçš„ BE IRï¼Œå…¶ä¸­ä¸­åŒ…å«äº†ä¸€äº› Oplib çš„ç®—å­ã€‚æœ€ç»ˆè¿™ä¸ª BEIR ä¼šè°ƒç”¨ OP çš„ç®—å­ï¼Œç„¶åå»è·‘åœ¨ C model æˆ–è€…æ˜¯å®é™…çš„ç¡¬ä»¶èŠ¯ç‰‡ä¸Šé¢ã€‚åç«¯ç¼–è¯‘å™¨ä¸»è¦è´Ÿè´£å››ä¸ªæ–¹é¢ layout åˆå§‹åŒ–å’Œä¼ é€’ã€const ç®¡ç†ã€åˆ‡åˆ†ç­–ç•¥åŠå…¶ SPM åˆ†é…å’Œ DDR åˆ†é…ã€‚\nLayout Initialization and Pass. layout å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç§\nlayout_str: ä¸­ç«¯ä½¿ç”¨ CNN Op: 1. Feature (NCHW/NHWC) etc. 2. Weight (OIHW/HWOI) etc. Non-CNN Op: å¤§æ¨¡å‹ä¸­å¸¸è§ï¼ŒTensor/NTensorï¼Œå®ƒä»¬çš„åŒºåˆ«æ˜¯ç¬¬ 0 ç»´æ˜¯å¦ä¸º 1. mem_layout: åç«¯ä½¿ç”¨ï¼Œä»£è¡¨äº†åœ¨èŠ¯ç‰‡ä¸Šçš„å®é™…æ’å¸ƒ Tensor/NTensor: æ•°æ®çš„ç´§å¯†æ’å¸ƒ Cx/NCx: å¯¹ Tensor/NTensor æ ¼å¼åŒ–åçš„ç»“æœï¼Œæ–¹ä¾¿æ˜“ç¡¬ä»¶è¯»å–ã€‚ dtype channel description bf16/fp16 /fp32/tf32 c \u0026lt;= 32 NHWC, Cå‘4/8/16/32å¯¹é½ï¼ŒN çš„èµ·å§‹åœ°å€å‘ 2048bit å¯¹é½ c \u0026gt; 32 N[CxHW64, HWC0], C0 å‘ 4/8/16/32 å¯¹é½ï¼ŒN çš„èµ·å§‹åœ°å€å‘2048bit å¯¹é½\nåœ¨ä¸€ä¸ª batch å†…å°† tensor æŒ‰ C åˆ†æˆ Cx*64 å’Œ C0ä¸¤éƒ¨åˆ† int8 c \u0026lt;= 64 NHWC, C å‘ 4/8/16/32/64å¯¹é½ï¼ŒNçš„èµ·å§‹åœ°å€å‘2048bitå¯¹é½ c \u0026gt; 64 N[CxHW128, HWC0], C0 å‘ 4/8/16/32/64 å¯¹é½ï¼ŒNçš„èµ·å§‹åœ°å€å‘ 2048bit å¯¹é½ åœ¨ä¸€ä¸ª batch å†…å°† tensor æŒ‰ C åˆ†æˆ Cx*128 å’ŒC0 ä¸¤éƒ¨åˆ† layoutInitPass layoutInitPass ç”¨äºåˆå§‹åŒ–è®¡ç®—å›¾ä¸­ GemmOP å’Œ ConvOP çš„ layout_strï¼Œå…¶ä»–çš„æ‰€æœ‰ç®—å­ layout_str éƒ½è®¾ç½®ä¸º UNKNOWN. ä¸‹å›¾ä¸­çš„ GemmOP layout_str = \u0026quot;Tensor-Tensor-Tensor\u0026quot; åˆ†åˆ«è¡¨ç¤ºä¸¤ä¸ªè¾“å…¥å’Œè¾“å‡ºçš„æ•°æ®æ’å¸ƒã€‚\nLayoutStr\nlayoutTransmitPass layoutTransmitPass ä¼šç”¨å·²çŸ¥çš„ GemmOP å’Œ ConvOP layout ä¿¡æ¯è¿›è¡Œæ‰©æ•£ï¼Œå¾—åˆ°å…¨å›¾çš„ layout_str.\næ¯ä¸ªç®—å­åˆå§‹åŒ–ä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œæœ‰inputNodeså®¹å™¨å’ŒoutputNodeså®¹å™¨åˆ†åˆ«å­˜æ”¾è‡ªå·±çš„è¾“å…¥å’Œè¾“å‡ºèŠ‚ç‚¹ã€‚ GemmOp å’Œ ConvOp ä½œä¸ºèµ·å§‹èŠ‚ç‚¹ï¼Œå‘å‰å’Œå‘åæ¨å¯¼ layout (ç®—å­çš„ inferlayout() æ¥å£)ï¼Œæ–°æ¨å‡ºlayout çš„èŠ‚ç‚¹ä½œä¸ºä¸‹ä¸€æ‰¹èµ·å§‹èŠ‚ç‚¹é€’å½’æ¨å¯¼ã€‚ é‡åˆ°æ— æ³•æ¨å¯¼çš„èŠ‚ç‚¹ (å¦‚ Reshapeï¼ŒBroadCast) åˆ™ç»ˆæ­¢æ¨å¯¼ã€‚å°†å…¶ä½™æ— æ³•æ¨å¯¼çš„èŠ‚ç‚¹ layout ç›´æ¥åˆå§‹åŒ–ä¸º Tensor. layoutTransmitPass\nlayoutAlignToNpuPass layoutAlignToNpuPass ç”¨äºåœ¨æ•°æ®å¯¹é½å†²çªçš„åœ°æ–¹æ’å…¥ channelNormï¼Œå¹¶å°† layout_str æ˜ å°„åˆ° mem_layout. åœ¨ NPU ä¸ŠæŸäº›ç®—å­åªæ”¯æŒ COMPACT layoutï¼Œæœ‰äº›åªæ”¯æŒ ALIGN layoutï¼Œæœ‰äº›åˆ™éƒ½å¯ä»¥ BOTH.\nè¾“å…¥é»˜è®¤éå¯¹é½æ’å¸ƒï¼Œä»è¾“å…¥å‡ºå‘éå†æ•´å›¾ï¼Œæ£€æŸ¥å½“å‰ç®—å­ä¸å…¶æ‰€æœ‰ user ä¹‹é—´çš„å¯¹é½è¦æ±‚ï¼Œè‹¥å†²çªï¼Œè®°å½•æ’å…¥ç‚¹ (ç®—å­çš„å¯¹é½è¦æ±‚å¯ä»¥åœ¨ OpLibInterface æ¥å£ä¸­çš„ queryOpAttr() æ–¹æ³•ä¸­æŸ¥è¯¢åˆ°). æ ¹æ®è®°å½•çš„æ’å…¥ç‚¹ï¼Œå†æ¬¡åˆ†ææ’å…¥ç‚¹å‰åçš„ç®—å­å¯¹é½è¦æ±‚ï¼Œä»¥ç¡®å®šchannelnormçš„æ–¹å‘ï¼Œæ’å…¥ channelnorm. èµ‹å€¼ dev_infoï¼Œå°† layout_str æ˜ å°„åˆ° mem_layout. dev_infoç”¨æ¥æè¿°æ•°æ®åœ¨è®¾å¤‡ä¸Šçš„ä¸€äº›å±æ€§ï¼Œæœ‰æˆå‘˜ï¼šimm_size (è¾…åŠ©ç©ºé—´å¤§å°), mem_layout, temporal_mem_slice, imm_addr, mem_addr.\nlayoutAlignToNpuPass\nLayoutAlignOptPass åº”ç”¨å‡ ä¸ª RewritePattern ç”¨äºåˆ é™¤å†—ä½™çš„ channelnorm.\nConstChannelNormErase: ConstantOp ç»´åº¦ä¸º 1 å¹¶ä¸”åªæœ‰ 1 ä¸ª user çš„æ—¶å€™å¯ä»¥åˆ å»å¹¶ä¸”å°† devInfolayout è®¾ç½®ä¸º Cx. ConstChannelNormErase Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // const can be directly considered to be aligned // constop(dim \u0026lt; 2) -\u0026gt; channelNorm -\u0026gt; constop struct ConstChannelNormErase : public mlir::OpRewritePattern\u0026lt;txbe::ConstantOp\u0026gt; { ConstChannelNormErase(mlir::MLIRContext *context, /*benefit=*/1) {} mlir::LogicalResult matchAndRewrite(txbe::ConstantOp op, mlir::PatternRewriter \u0026amp;rewriter) const override { // If const has multi user, can not erase if (!op-\u0026gt;hasOneUse()) return mlir::failure(); auto user = *op-\u0026gt;getUsers().begin(); if (!isa\u0026lt;txbe::ChannelNormOp\u0026gt;(user)) return mlir::failure(); auto shape = op-\u0026gt;getResult(0).getType().dyn_cast\u0026lt;mlir::ShapedType\u0026gt;().getShape(); if (shape.size() \u0026gt; 1) return mlir::failure(); llvm::SmallVector\u0026lt;Operation*\u0026gt; userVec; userVec.insert(userVec.end(), user-\u0026gt;getUsers().begin(), user-\u0026gt;getUsers().end()); for (auto channelNormUser : userVec) { channelNormUser-\u0026gt;replaceUsesOfWith(user-\u0026gt;getResult(0), op-\u0026gt;getResult(0)); } // set align=true setDevInfoWithLayout(op-\u0026gt;getContext(), op-\u0026gt;getLayoutStr().str(), true); if (user-\u0026gt;use_empty()) rewriter.eraseOp(user); return success(); } }; RedudantChannelnormErase Implementation RedudantChannelnormErase: å¦‚æœè¯¥ channelnormOp çš„è¾“å…¥æ˜¯æ¥è‡ªä¸€ä¸ª constOp å¹¶ä¸”åªæœ‰ä¸€ä¸ªè¾“å‡ºï¼Œåˆ™æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–çš„ channelnormOp ä¹Ÿä½¿ç”¨ã€‚å¦‚æœæ˜¯ï¼Œåˆ™è®©å®ƒä»¬ç›´æ¥ä½¿ç”¨è¯¥ channelnormOp çš„ç»“æœï¼Œä»¥æ¶ˆé™¤å¤šä½™çš„ channelnormOp. // A pass to erase redundant channel normalization operations struct RedundantChannelNormErase : public mlir::OpRewritePattern\u0026lt;tx8be::ChannelNormOp\u0026gt; { RedundantChannelNormErase(mlir::MLIRContext *context) : OpRewritePattern\u0026lt;tx8be::ChannelNormOp\u0026gt;(context, /*benefit=*/1) {} mlir::LogicalResult matchAndRewrite(tx8be::ChannelNormOp op, mlir::PatternRewriter \u0026amp;rewriter) const override { // Define the input operation and its defining operation // def represents the operation that generates the op input data auto def = op.getInput().getDefiningOp(); // Check if the defining operation is a ConstantOp and has more than one result if (isa\u0026lt;tx8be::ConstantOp\u0026gt;(def) \u0026amp;\u0026amp; (def-\u0026gt;getNumResults() \u0026gt; 1)) { return mlir::failure(); // Fail if conditions are not met } // Get the size in bits of the input shape auto size = op.getInput().getType().cast\u0026lt;ShapedType\u0026gt;().getSizeInBits(); Operation *sameOp = nullptr; // Pointer to a potentially redundant operation // Iterate over all users of the defining operation for (auto user : def-\u0026gt;getUsers()) { if (user == op) { // Skip if the user is the current operation continue; } if (isa\u0026lt;tx8be::ChannelNormOp\u0026gt;(user)) { // Check if the user is another ChannelNormOp sameOp = user; // Store the redundant operation break; } } if (!sameOp) return mlir::failure(); // Fail if no redundant operation is found // Replace all uses of the redundant operation with the current operation\u0026#39;s results op-\u0026gt;replaceAllUsesWith(sameOp-\u0026gt;getOpResults()); if (op-\u0026gt;use_empty()) { // Erase the current operation if it has no more uses rewriter.eraseOp(op); } return success(); // Return success if the rewrite is completed } }; Const Management å¸¸é‡ç»Ÿä¸€ä½¿ç”¨ ConstContainer ç±»æ¥è¿›è¡Œç®¡ç†ã€‚é€šè¿‡ map æ¥è®°å½•æ¯ä¸ªå¸¸é‡å¯¹åº”çš„ ParamInfo. ä¸€ä¸ªå¸¸é‡å¯èƒ½è¢«åˆ†é…åˆ°å¤šä¸ªèŠ¯ç‰‡ä¸Šï¼Œæ¯ä¸ªèŠ¯ç‰‡ä¸Šæ•°æ®å¯èƒ½ç›¸åŒï¼Œä¹Ÿå¯èƒ½ä¸åŒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 struct ParamInfo { std::vector\u0026lt;uint8_t\u0026gt;* data_ptr; // const value std::set\u0026lt;int32_t\u0026gt; chip_id; // which chips has this const, -1 indicates all chip has the same param. uint32_t label; // Indicates whether the data is assigned to a certain chip_id. }; // class ConstContainer { class ConstContainer { public: ConstContainer(); virtual ~ConstContainer(); // some public functions private: std::map\u0026lt;uint32_t, std::vector\u0026lt;ParamInfo\u0026gt;\u0026gt; _data; std::map\u0026lt;uint32_t, std::map\u0026lt;int32_t, uint64_t\u0026gt;\u0026gt; oidToSize; std::map\u0026lt;uint32_t, uint32_t\u0026gt; oidToNid; }; MoveConstantPass MoveConstantPass: åˆ›å»ºå›¾çš„ ConstContainerï¼Œç„¶ååº”ç”¨ ConstantToLoadConst Rewrite Pattern. è½¬æ¢å®Œæˆåä¼šè°ƒç”¨ updateConstContainer æ›´æ–° ConstContainer å„ä¸ª const çš„ ID. ç”¨ä¸€ä¸ªå¤§å°ä¸º 4*1024*tile_num (DDR_BANK_SIZE) thresholdSize å°†å¤§äºè¿™ä¸ªå€¼çš„ const å…¨éƒ¨æ”¾åœ¨å‰é¢ï¼Œå°çš„æ”¾åœ¨åé¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 void MoveConstantPass::runOnOperation() { // create constant container createConstContainer(); // get module op ModuleOp module = getOperation(); // Set pattern MLIRContext *context = \u0026amp;getContext(); RewritePatternSet patterns(context); patterns.insert\u0026lt;ConstantToLoadConst\u0026gt;(context); const FrozenRewritePatternSet frozen_patterns = FrozenRewritePatternSet(std::move(patterns)); // Set config GreedyRewriteConfig config; config.useTopDownTraversal = true; for (auto func : module.getOps\u0026lt;func::FuncOp\u0026gt;()) { Region \u0026amp;body = func.getBody(); if (failed(applyPatternsAndFoldGreedily(body, frozen_patterns, config))) { llvm::errs() \u0026lt;\u0026lt; \u0026#34;Failed when move const in main graph.\\n\u0026#34;; signalPassFailure(); } } for (auto subgraph : module.getOps\u0026lt;tx8be::SubgraphOp\u0026gt;()) { Region \u0026amp;body = subgraph.getBody(); if (failed(applyPatternsAndFoldGreedily(body, frozen_patterns, config))) { llvm::errs() \u0026lt;\u0026lt; \u0026#34;Failed when move const in subgraph.\\n\u0026#34;; signalPassFailure(); } } TileInfo tinfo = get_tileinfo(module); updateConstContainer(tinfo.tile_num); // update id by thresholdSize updateLdConstop(); } ConstantToLoadConst é¦–å…ˆé€šè¿‡åˆ†æè¯¥å¸¸é‡çš„æ‰€æœ‰ usersï¼Œæ¥åˆ¤æ–­è¿™ä¸ªå¸¸é‡æ˜¯å¦éœ€è¦ LoadConstOp. å¦‚æœéœ€è¦åŠ è½½ï¼Œå®ƒä¼šå°†åŸå§‹å¸¸é‡çš„æ•°æ®æ³¨å†Œåˆ°ä¸€ä¸ªå…¨å±€å®¹å™¨ä¸­å¹¶è·å¾—ä¸€ä¸ª IDï¼Œç„¶ååˆ›å»ºä¸€ä¸ªæ–°çš„ LoadConstOp ï¼Œå¹¶å°†æ­¤ ID åŠå…¶ä»–ç¡¬ä»¶å±æ€§èµ‹äºˆå®ƒã€‚æ¥ç€ï¼Œå®ƒä¼šæ›´æ–°æ‰€æœ‰ä½¿ç”¨è€…ï¼Œå°†å®ƒä»¬çš„è¾“å…¥ä»æ—§çš„ ConstantOp é‡å®šå‘åˆ°è¿™ä¸ªæ–°çš„ LoadConstOpï¼Œæœ€åå†åˆ é™¤æ— ç”¨çš„åŸå§‹å¸¸é‡ã€‚æœ€åå†æ›´æ–°æ‰€æœ‰ const çš„ ID.\nConstantToLoadConst Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 struct ConstantToLoadConst : public mlir::OpRewritePattern\u0026lt;tx8be::ConstantOp\u0026gt; { ConstantToLoadConst(mlir::MLIRContext *context) : OpRewritePattern\u0026lt;tx8be::ConstantOp\u0026gt;(context, /*benefit=*/) {} mlir::LogicalResult matchAndRewrite(tx8be::ConstantOp op, mlir::PatternRewriter \u0026amp;rewriter) const override { uint32_t id = 0; // Store constant data to constant container // ... // Determine if this constant operation needs an explicit load instruction. bool needLoad = false; auto v = op.getOutput(); // Iterate over all operations that use this output value. for (auto user_op : v.getUsers()) { // Get the argument index of the user op that corresponds to our output value. int32_t arg_idx = getArgumentIdx(user_op, v); // Assert that the user operation implements our custom OpLibInterface. ASSERT(llvm::dyn_cast\u0026lt;tx8be::OpLibInterface\u0026gt;(user_op)); // Get the library attributes for this user operation. auto opAttr = llvm::dyn_cast\u0026lt;tx8be::OpLibInterface\u0026gt;(user_op).queryOpAttr(); // Skip if the user is a TupleOp, which might have special handling. if (isa\u0026lt;tx8be::TupleOp\u0026gt;(user_op)) { continue; } if (opAttr.needLoad \u0026amp; (1 \u0026lt;\u0026lt; arg_idx)) { // Check if the \u0026#39;needLoad\u0026#39; attribute needLoad = true; } else { ASSERT(needLoad == false); } } // Set attributes // ... // Safely iterate over the users. This is important because we are modifying the use-list inside the loop. for (auto \u0026amp;use : llvm::make_early_inc_range(op.getOutput().getUses())) { Operation *userOp = use.getOwner(); // Create the new, hardware-specific LoadConst operation. txbe::LoadConstOp newLoadConst = rewriter.create\u0026lt;txbe::LoadConstOp\u0026gt;(op.getLoc(), op.getOutput().getType(), ValueRange{}, attrs); if (!needLoad) { // this constant does not need an explicit load... // Get a builder to set attributes. OpBuilder builder(newLoadConst.getContext()); // Set a \u0026#39;bypasscodegen\u0026#39; attribute, signaling special handling for this op in later stages. newLoadConst.getOperation()-\u0026gt;setAttr(\u0026#34;bypasscodegen\u0026#34;, builder.getBoolAttr(true)); } // Set the layout string attribute on the new LoadConst op. newLoadConst-\u0026gt;setAttr(\u0026#34;layout_str\u0026#34;, op-\u0026gt;getAttr(\u0026#34;layout_str\u0026#34;)); // CRITICAL STEP: Rewire the user\u0026#39;s operand to point to the result of the new LoadConst op. userOp-\u0026gt;setOperand(use.getOperandNumber(), newLoadConst); } // After all uses have been replaced, erase the original, now-dead ConstantOp. rewriter.eraseOp(op); return success(); } } constNormPass constNormPass: éå†å›¾ä¸­çš„ LoadConstOp. å®ƒä¼šå¯»æ‰¾ä¸€ä¸ªç‰¹å®šçš„æ¨¡å¼ï¼šå¦‚æœä¸€ä¸ª LoadConstOp çš„å”¯ä¸€ user æ˜¯ä¸€ä¸ª ChannelNormOpï¼Œé‚£ä¹ˆä¼šé€šè¿‡ constChannelNormErase å‡½æ•°è¿›è¡Œæ¶ˆé™¤å’Œå°†å¯¹å…¶ä¿¡æ¯åŒæ­¥åˆ° LoadConstOp. æœ€åé€šè¿‡ processMultiUse ç¡®ä¿æ‰€æœ‰åŠ è½½åŒä¸€ä¸ªåº•å±‚å¸¸é‡æ•°æ®çš„ LoadConstOp å®ä¾‹ï¼Œéƒ½å…·æœ‰å®Œå…¨ç›¸åŒçš„å†…å­˜å¸ƒå±€ã€‚\nConstNormPass Implementation void ConstNormPass::runOnOperation() { ModuleOp module = getOperation(); func::FuncOp mainGraphFunc = getMainFuncOp(module); SmallVector\u0026lt;Operation *\u0026gt; deletedChannelnorm; // Walk the main function to find a specific pattern: LoadConst -\u0026gt; ChannelNorm. mainGraphFunc.walk([\u0026amp;](Operation* constOp) { if (isa\u0026lt;tx8be::LoadConstOp\u0026gt;(constOp)) { std::unordered_set\u0026lt;Operation*\u0026gt; users; users.insert(constOp-\u0026gt;getUsers().begin(), constOp-\u0026gt;getUsers().end()); bool flag = false; // Check if any user is a ChannelNormOp. for (auto user : users) { if (isa\u0026lt;tx8be::ChannelNormOp\u0026gt;(user)) { flag = true; break; } } // If the LoadConst has exactly one user, and that user is a ChannelNormOp, // mark the ChannelNormOp for deletion. if (flag \u0026amp;\u0026amp; users.size() == 1) { for (auto it : users) { // The erase logic is commented out, maybe handled by constChannelNormErase or done later. deletedChannelnorm.push_back(it); } } } }); // Erase all the marked ChannelNormOps. This is done in a separate loop // to avoid iterator invalidation issues. for (auto op : deletedChannelnorm) { op-\u0026gt;erase(); } // Set up and run a nested pass pipeline. OpPassManager thisPM(this-\u0026gt;getOpName().value()); // This pipeline will only apply to LoadConstOp operations inside functions. OpPassManager \u0026amp;loadConstOpPM = thisPM.nest\u0026lt;func::FuncOp\u0026gt;().nest\u0026lt;tx8be::LoadConstOp\u0026gt;(); // Add the ConstNormDoPass to the pipeline. loadConstOpPM.addPass(std::make_unique\u0026lt;ConstNormDoPass\u0026gt;()); // Run the newly constructed pipeline on the module. auto result = this-\u0026gt;runPipeline(thisPM, getOperation()); // After the pipeline, run a final cleanup/consistency check function. processMultiUse(module); // change unpack input0 qweight shape after ConstNormDoPass. (Original comment) // This logic is likely inside the runOnOperation() method of ConstNormDoPass. mainGraphFunc.walk([\u0026amp;](Operation* constOp) { if (isa\u0026lt;tx8be::LoadConstOp\u0026gt;(constOp)) { // Collect all users of this LoadConstOp. std::unordered_set\u0026lt;Operation*\u0026gt; users; users.insert(constOp-\u0026gt;getUsers().begin(), constOp-\u0026gt;getUsers().end()); // Check if any user is an UnpackOp. bool flag = false; for (auto user : users) { if (isa\u0026lt;tx8be::UnpackOp\u0026gt;(user)) { flag = true; break; } } // If there is exactly one user, and it\u0026#39;s an UnpackOp... if (flag \u0026amp;\u0026amp; users.size() == 1) { for (auto it : users) { // This check seems to ensure we are modifying the correct operand. if (constOp-\u0026gt;getResult(0) == it-\u0026gt;getOperand(0)) { // Get the original shape and type. llvm::SmallVector\u0026lt;int64_t, 6\u0026gt; oShape; auto type = constOp-\u0026gt;getResult(0).getType().cast\u0026lt;ShapedType\u0026gt;(); auto shape = type.getShape(); // Apply the shape transformation: e.g., for unpacking packed data. oShape.push_back((int32_t)shape[0] / 4); oShape.push_back((int32_t)shape[1] * 4); // Create a new tensor type with the new shape. auto oType = mlir::RankedTensorType::get(oShape, type.getElementType()); // Update the type of the LoadConstOp\u0026#39;s result in-place. constOp-\u0026gt;getResult(0).setType(oType); } } } } }); } constChannelNormErase å¤„ç† LoadConstOp -\u0026gt; ChannelNormOp è¿™ç§æ¨¡å¼ã€‚è®©æ‰€æœ‰åŸæœ¬ä½¿ç”¨ ChannelNormOp è®¡ç®—ç»“æœçš„æ“ä½œï¼Œç°åœ¨æ”¹ä¸ºç›´æ¥ä½¿ç”¨ ChannelNormOp çš„è¾“å…¥æ•°æ®ã€‚è·å– LoadConstOp å½“å‰çš„è®¾å¤‡ä¿¡æ¯å’Œ layoutï¼Œè®¡ç®—å‡ºä¸€ä¸ªæ–°çš„ç»è¿‡å¯¹é½çš„å¸ƒå±€ align_dev_layoutï¼Œç„¶åç”¨è¿™ä¸ªæ–°å¸ƒå±€å»æ›´æ–° LoadConstOp.\nconstChannelNormErase Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // This function erases a ChannelNormOp by bypassing it and updating the source constant\u0026#39;s layout. void constChannelNormErase(tx8be::ChannelNormOp op) { // Find the defining operation of the ChannelNorm\u0026#39;s operand, which should be a LoadConstOp. auto defOp = llvm::dyn_cast_or_null\u0026lt;tx8be::LoadConstOp\u0026gt;(op-\u0026gt;getOperand(0).getDefiningOp()); // If the source is not a LoadConstOp, do nothing. if (!defOp) return; // Collect all users of the ChannelNormOp\u0026#39;s result. llvm::SmallVector\u0026lt;Operation*\u0026gt; userVec; userVec.insert(userVec.end(), op-\u0026gt;getUsers().begin(), op-\u0026gt;getUsers().end()); for (auto user : userVec) { // Replace all uses of the ChannelNormOp\u0026#39;s result with the result of the LoadConstOp.. user-\u0026gt;replaceUsesOfWith(op-\u0026gt;getResult(0), op-\u0026gt;getOperand(0)); } // After bypassing, the layout of the source constant might need to be adjusted // to reflect the transformation that the ChannelNormOp was supposed to perform. // set const layout to cx mode auto dev_layout = getDevInfoLayoutMode(defOp); auto align_dev_layout = get_aligned_layout((LAYOUT_MODE)dev_layout); setDevInfoWithLayout(defOp-\u0026gt;getContext(), defOp, static_cast\u0026lt;tx8be::LayoutMode\u0026gt;(align_dev_layout)); } processMultiUse ä¿è¯æ‰€æœ‰å¯¹åŒä¸€ä»½å¸¸é‡æ•°æ®çš„å¼•ç”¨ï¼Œå…¶ mem_layout éƒ½æ˜¯å®Œå…¨ä¸€è‡´çš„ã€‚æµç¨‹å¦‚ä¸‹\nprocessMultiUse éå†è®¡ç®—å›¾ä¸­çš„æ‰€æœ‰ LoadConstOpï¼Œä»¥ const_map_id ä¸º keyï¼Œå°†æ‰€æœ‰æŒ‡å‘åŒä¸€ä¸ªç‰©ç†å¸¸é‡çš„ LoadConstOp å®ä¾‹åˆ†ç»„å­˜æ”¾åœ¨ä¸€èµ·ã€‚ éå†è¿™ä¸ª mapï¼Œåªå¤„ç†é‚£äº›åŒ…å«å¤šä¸ª LoadConstOp å®ä¾‹çš„ç»„ (kv.second.size() \u0026gt; 1). åœ¨æ¯ä¸ªç»„å†…ï¼Œç¡®å®šä¸€ä¸ªæ­£ç¡®çš„å¸ƒå±€ã€‚ä»£ç é€»è¾‘æ˜¯ä»¥ç»„å†…çš„ç¬¬ä¸€ä¸ª LoadConstOp çš„å¸ƒå±€ä¸ºåŸºå‡†ï¼Œä½†å¦‚æœå‘ç°ç»„å†…æœ‰ is_cx_layoutï¼Œåˆ™ä¼šé‡‡ç”¨è¿™ä¸ªä¼˜å…ˆçš„å¸ƒå±€ä½œä¸ºæ ‡å‡†ã€‚ ä¸€æ—¦ç¡®å®šäº†æ ‡å‡†å¸ƒå±€ï¼Œä¼šå†æ¬¡éå†è¯¥ç»„å†…çš„æ‰€æœ‰ LoadConstOp å®ä¾‹ã€‚è°ƒç”¨ setDevInfoWithLayout å‡½æ•°ï¼Œå¼ºåˆ¶å°†æ¯ä¸€ä¸ªå®ä¾‹çš„å¸ƒå±€å±æ€§ä¿®æ”¹ä¸ºåˆšæ‰ç¡®å®šçš„é‚£ä¸ªæ ‡å‡†å¸ƒå±€ã€‚ processMultiUse Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 // This function processes multi-use constants to ensure their layouts are consistent. void ConstNormPass::processMultiUse(ModuleOp module) { func::FuncOp mainGraphFunc = getMainFuncOp(module); // When a const is used by multiple users, multiple loadconsts will be generated, // but only one loadconst will have its layout set. The others will be skipped. // We need to go over them uniformly. // First, find all previous useless constant ops. // Group all LoadConstOp instances by their underlying constant data ID (const_map_id). std::unordered_map\u0026lt;int32_t, std::vector\u0026lt;mlir::Operation *\u0026gt;\u0026gt; allconst; mainGraphFunc.walk([\u0026amp;](Operation* constOp) { if (isa\u0026lt;tx8be::LoadConstOp\u0026gt;(constOp)) { auto cOp = llvm::dyn_cast\u0026lt;tx8be::LoadConstOp\u0026gt;(constOp); uint32_t t_map_id = cOp.getConstMapId(); allconst[t_map_id].emplace_back(constOp); } }); // Based on duplication, find if the layout needs to be changed to cx. // Check if there is also a Cx with the same layout. // Iterate over each group of LoadConstOps that share the same data. for (auto \u0026amp;kv : allconst) { if (kv.second.size() \u0026gt; 1) { // Process only if there are multiple users. // Assume the layout of the first user is the correct one. auto layout = (LAYOUT_MODE)getDevInfoLayoutMode(kv.second.front()); // This loop is for validation, checking if layouts are inconsistent. for (auto op : kv.second) { auto layout2 = (LAYOUT_MODE)getDevInfoLayoutMode(op); if (is_cx_layout(layout2) != ALIGN_NOT) { layout = layout2; break; } } // Force all LoadConstOps in this group to have the same, correct layout. for (auto op : kv.second) { auto ctx = op-\u0026gt;getContext(); ASSERT(op-\u0026gt;hasAttr(\u0026#34;dev_info\u0026#34;) \u0026amp;\u0026amp; \u0026#34;Must have dev_info!\u0026#34;); setDevInfoWithLayout(ctx, op, (tx8be::LayoutMode)layout); } } } } Sharding Search and SPM Management ç¬¬ä¸€æ­¥æ˜¯å¯¹ç®—å­è¿›è¡Œ Group åˆ’åˆ†ï¼Œæ’å…¥ load \u0026amp; store. å¯¹æ¯ä¸€ä¸ª subGraph ä¼šåº”ç”¨å¦‚ä¸‹çš„ 3 ä¸ª Pass:\nGroupPatternPassï¼šåº”ç”¨é…ç½®å¥½çš„ group config (opt_group). GroupOptimizationPass: å¦‚æœæ²¡æœ‰é…ç½®ï¼Œåˆ™ä¼šä¸ºæ¯ä¸ª compute op åˆ›å»ºä¸€ä¸ª group. GroupLdStPass: ä¸ºæ¯ä¸ªéœ€è¦çš„ groupOp æ’ å…¥loadOp å’Œ storeOpï¼Œå¹¶æ·»åŠ  group_tag. group_tag = 0: éœ€è¦ load æˆ– storeï¼Œæ„å‘³ç€è¯¥ group éœ€è¦åç»­çš„åˆ‡åˆ†æœç´¢ã€‚ group_tag = 2: ä¸éœ€è¦ load æˆ– storeï¼Œæ„å‘³ç€è¯¥ group çš„op éƒ½åœ¨ DDR ä¸Šæ“ä½œï¼Œæ— éœ€å‚ä¸åç»­çš„åˆ‡åˆ†æœç´¢ã€‚ SPM ä¸Šä¸€å®šè¦èƒ½æ”¾ä¸‹åˆ‡åˆ†åçš„ç»“æœã€‚Group æ˜¯åˆ‡åˆ†æœç´¢å’Œ SPM åˆ†é…çš„åŸºæœ¬çš„å•ä½ã€‚æ€æƒ³å°±æ˜¯å°½é‡æŠŠè¿ç»­æ‰§è¡Œçš„ç®—å­ç»„åˆåœ¨ä¸€èµ·ï¼Œä¸€ç›´åœ¨ SPM ä¸Šè¿è¡Œè€Œä¸æ˜¯å­˜å› DDR å†è¯»å…¥ï¼Œä»¥æ­¤æ¥å‡å°‘è®¿å­˜æ—¶é—´ã€‚GroupOp åœ¨ td æ–‡ä»¶ä¸­å®šä¹‰æ‰€åŒ…å«çš„è¾“å…¥å¦‚ä¸‹:\nlet regions = (region SizedRegion\u0026lt;1\u0026gt;:$body); let arguments = (ins Variadic\u0026lt;AnyTensorOrNone\u0026gt;:$operands, // è¾“å…¥å‚æ•°ä¸º æ“ä½œæ•°çš„æ•°é‡å¯å˜çš„çš„å¼ é‡ DefaultValuedAttr\u0026lt;BoolAttr, \u0026#34;false\u0026#34;\u0026gt;:$pipeline_parallel, // æ˜¯å¦ç”¨æµæ°´çº¿å¹¶è¡Œ DefaultValuedAttr\u0026lt;I32Attr, \u0026#34;1\u0026#34;\u0026gt;:$sp_stage_num, OptionalAttr\u0026lt;Tx8e_RegionAttr\u0026gt;:$dev_region, // è®¾å¤‡çš„ç©ºé—´å±æ€§ OptionalAttr\u0026lt;UI32Attr\u0026gt;:$spm_alloc_size, // groupå ç”¨çš„spmå¤§å° OptionalAttr\u0026lt;I32Attr\u0026gt;:$group_tag, // 0: æ­£å¸¸åˆ‡åˆ†, 1: split nht, 2: ä¸åˆ‡åˆ† (reshape) OptionalAttr\u0026lt;DenseI32ArrayAttr\u0026gt;:$stream_online_check, OptionalAttr\u0026lt;DenseI32ArrayAttr\u0026gt;:$stream_offline, DefaultValuedAttr\u0026lt;BoolAttr, \u0026#34;true\u0026#34;\u0026gt;:$need_barrier, // æ˜¯å¦éœ€è¦tileåŒæ­¥ DefaultValuedAttr\u0026lt;SI32Attr, \u0026#34;-1\u0026#34;\u0026gt;:$group_id, // group idåºå· DefaultValuedAttr\u0026lt;SI32Attr, \u0026#34;-1\u0026#34;\u0026gt;:$template_id // å¤ç”¨å…¶ä»–groupçš„id, å°äº0ä¸ºä¸å¤ç”¨ ); let results = (outs Variadic\u0026lt;AnyTensorOrNone\u0026gt;:$results); è¿˜æœ‰ä¸€äº›å¸¸ç”¨åˆ°çš„ç»“æ„ä½“ SecsInfo è®°å½•äº†å•ä¸ª Opåœ¨åˆ†å¸ƒå¼ç­–ç•¥æœç´¢è¿‡ç¨‹ä¸­çš„æ‰€æœ‰çŠ¶æ€å’Œä¿¡æ¯ã€‚\nstruct SecsInfo { std::vector\u0026lt;int32_t\u0026gt; sharding; // space std::vector\u0026lt;int32_t\u0026gt; split; // time std::vector\u0026lt;int32_t\u0026gt; splitry; // å½“å‰æœç´¢çš„ sharding çš„ split std::vector\u0026lt;int32_t\u0026gt; reduceSplit; // é’ˆå¯¹éœ€è¦è¿›è¡Œè§„çº¦ (Reduction) çš„ç»´åº¦çš„åˆ‡åˆ†ç­–ç•¥ã€‚ int32_t reducesplit[0]; // ä¸€ä¸ªæ ‡è®°ä½ï¼Œç”¨äºæŒ‡ç¤ºreduceSplitæ˜¯å¦è¢«ä½¿ç”¨ // ******************** ä»¥ä¸‹å˜é‡ä¸ºfactorSpaceä½¿ç”¨éƒ¨åˆ† ******************** bool sfinish[1]; // æ ‡è®° split/reduceSplit ç›¸å…³çš„ç­–ç•¥æ˜¯å¦å·²ç¡®å®šã€‚ // æšä¸¾ç±»å‹ï¼Œå®šä¹‰äº†å½“å‰ç®—å­æ‰€å¤„çš„åˆ‡åˆ†æ¨¡å¼ï¼Œç‰¹åˆ«å…³æ³¨éœ€è¦é€šä¿¡çš„Reduceç»´åº¦ã€‚ /* SHARDING_MODE çš„å¯èƒ½å€¼è§£é‡Šï¼š * SHARDING_INIT: åˆå§‹çŠ¶æ€ï¼Œå°šæœªç¡®å®šæ¨¡å¼ã€‚ * 0: ä¸åˆ‡åˆ†è§„çº¦ (reduce) ç»´åº¦ã€‚æ„å‘³ç€æ•°æ®åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šæ˜¯å®Œæ•´çš„ï¼Œæ— éœ€é€šä¿¡ã€‚ * 1: å•è¾¹åˆ‡åˆ†è§„çº¦ç»´åº¦ã€‚ä¾‹å¦‚ï¼Œåªåˆ‡åˆ†æƒé‡ï¼Œä¸åˆ‡åˆ†è¾“å…¥ï¼Œæ•°æ®åœ¨ä¸åŒtileä¸Šéœ€è¦é€šä¿¡ã€‚ * 2: ä¸¤è¾¹éƒ½åˆ‡åˆ†è§„çº¦ç»´åº¦ã€‚ * 3: å¯¹æƒé‡(weight)çš„è¾“å‡ºé€šé“(output channel)ç»´åº¦è¿›è¡Œåˆ‡åˆ†ï¼Œä½†ä¸å±äºå¼ é‡å¹¶è¡Œ(TP)ï¼Œå¯èƒ½éœ€è¦fn/océ€šä¿¡ã€‚ */ SHARDING_MODE shardingMode{SHARDING_INIT}; bool rfinish[1]; // æ ‡è®° reduceSplit ç›¸å…³çš„ç­–ç•¥æ˜¯å¦å·²å®Œæˆå¤„ç†ã€‚ bool nfirst[0]; // æ ‡è®°æœç´¢æ–¹å‘ã€‚1: search from dim0 -\u0026gt; dim n-1 bool finish[0]; // è¡¨ç¤ºè¯¥ç®—å­çš„ç­–ç•¥æœç´¢æ˜¯å¦å·²å…¨éƒ¨å®Œæˆã€‚æ•´ä¸ªæœç´¢æµç¨‹: sharding -\u0026gt; shardingmode -\u0026gt; split -\u0026gt; reduceSplit std::vector\u0026lt;bool\u0026gt; sliceShapeMin; // æ ‡è®°åˆ‡åˆ†åçš„å¼ é‡ (slice) åœ¨æ¯ä¸ªç»´åº¦ä¸Šæ˜¯å¦å·²è¾¾åˆ°æŸä¸ªæœ€å°å°ºå¯¸é™åˆ¶ã€‚ // ******************** ä»¥ä¸‹å˜é‡ä¸ºsliceInfoä½¿ç”¨éƒ¨åˆ† ******************** std::vector\u0026lt;int64_t\u0026gt; TemporalShape; // åˆ‡åˆ†åï¼Œä¸´æ—¶çš„å¼ é‡å½¢çŠ¶ std::vector\u0026lt;int\u0026gt; reduce_sharding_space; // è§„çº¦ç»´åº¦åˆ‡åˆ†çš„æœç´¢ç©ºé—´ std::vector\u0026lt;int\u0026gt; reduce_sharding; // // æœ€ç»ˆé€‰å®šçš„è§„çº¦ç»´åº¦åˆ‡åˆ†ç­–ç•¥ bool sharding2_finish[0]; // æ ‡è®°ç¬¬äºŒé˜¶æ®µåˆ‡åˆ† (å¯èƒ½ä¸è§„çº¦ç›¸å…³) æ˜¯å¦å®Œæˆ }; GroupPatternPass GroupPatternPass å…¶æ ¸å¿ƒåŠŸèƒ½æ˜¯åœ¨ç»™å®šçš„è®¡ç®—å›¾ (subgraphOp) ä¸­ï¼Œé€šè¿‡ä¸€ç§é«˜æ•ˆçš„æ¨¡å¼åŒ¹é…ç®—æ³•ï¼Œè¯†åˆ«å‡ºé¢„å®šä¹‰çš„ã€å¯ä¼˜åŒ–çš„å­å›¾æ¨¡å¼ (Operator Patterns)ï¼Œå¹¶å°†åŒ¹é…åˆ°çš„ç®—å­ (Operations) è¿›è¡Œåˆ†ç»„ã€‚è¿™ç§åˆ†ç»„é€šå¸¸æ˜¯å›¾ä¼˜åŒ– (å¦‚ç®—å­èåˆã€ç®—å­è°ƒåº¦) çš„ç¬¬ä¸€æ­¥ã€‚\nè¯¥ Pass é¦–å…ˆè·å–é…ç½®ï¼Œå†³å®šä»å“ªé‡ŒåŠ è½½æ¨¡å¼ (ä¸€ä¸ª mapï¼Œå…¶é”®æ˜¯æ¨¡å¼ï¼Œå³ä¸€ä¸ªç®—å­åºåˆ— std::vector\u0026lt;TX8BE_OPS\u0026gt;ï¼Œå€¼æ˜¯ä¸€ä¸ªæ•´æ•° intï¼Œä»£è¡¨æ¨¡å¼ä¼˜å…ˆçº§ï¼Œè¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜) ã€‚ç„¶åï¼Œå®ƒè°ƒç”¨ aca.insertPatterns å°†è¿™äº›æ¨¡å¼\u0026quot;ç¼–è¯‘\u0026quot;åˆ° Automation å¼•æ“ä¸­ã€‚æ¥ç€ï¼Œè°ƒç”¨ aca.search æ‰§è¡ŒåŒ¹é…ã€‚æœ€åï¼Œä» manager ä¸­è·å–åŒ¹é…ç»“æœ (groups) ï¼Œå¹¶å¯¹è¿™äº› groups è¿›è¡Œåç»­å¤„ç†ï¼Œä¾‹å¦‚åˆ›å»ºæ–°çš„é€»è¾‘åˆ†ç»„å’Œè¿›è¡Œæ‹“æ‰‘æ’åºã€‚\nvoid GroupPatternPass::runOnOperation() { TFUNC_SCOPE(DEBUG); auto subgraphOp = getOperation(); // Get the current operation (e.g., a function) the pass is running on. PatternManager manager; // A manager to hold graph rewriting information. Automation aca(\u0026amp;manager); // Custom \u0026#39;Automation\u0026#39; class for pattern matching logic. auto minfo = getModuleConfig(getModuleByOp(getOperation())); std::string path = \u0026#34;\u0026#34;; auto temp = path != \u0026#34;\u0026#34; ? getPatternsFromFile(path) // Load patterns from a file if path is specified. : (patternConfigMap.at(static_cast\u0026lt;GroupPatternMode\u0026gt;(minfo.opt_group))); // Otherwise, load from a pre-defined map using a config key. TLOG(INFO) \u0026lt;\u0026lt; \u0026#34;[GroupPatternPass] config id: \u0026#34; \u0026lt;\u0026lt; minfo.opt_group; aca.insertPatterns(temp); // Insert the loaded patterns into the Automation engine. This is the starting point for building the matching structure. TLOG(INFO) \u0026lt;\u0026lt; \u0026#34;[Automation]: \\n\u0026#34; \u0026lt;\u0026lt; printTree(aca.root); aca.search(subgraphOp); // Execute the search for all patterns on the given subgraph. (search function code is not provided but its role is clear). manager.applyAll(); auto groups = manager.getGroups(); // Retrieve the groups of operations that were matched. manager.show(); auto newGroups = createGroups(subgraphOp, groups); // Create new group structures from the matched results. for (auto group : newGroups) { sortTopologically(group-\u0026gt;getBlock()); // Topologically sort the operations within each new group to maintain data dependencies. } } insertPatterns å¯¹äºæ¯ä¸€ä¸ªæ¨¡å¼ï¼Œå®ƒé¦–å…ˆè°ƒç”¨ processPattern æ¥å¤„ç†å…¶ä¸­çš„ OR, WILDCARD ç®—å­ã€‚\nå½“é‡åˆ° OR æ—¶ï¼Œå®ƒä¼šå°†æ¨¡å¼æ‹†åˆ†ã€‚ä¾‹å¦‚ï¼ŒA B OR C D è¿™æ ·çš„æ¨¡å¼ä¼šè¢«æ‹†è§£æˆä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å¼ A B å’Œ C D è¿›è¡Œå¤„ç†ã€‚ å½“é‡åˆ° WILDCARD æ—¶ï¼Œå®ƒä¼šç”Ÿæˆå¤šä¸ªæ¨¡å¼ã€‚æ ¹æ®ä»£ç  for (int i = 0; i \u0026lt; 5; i++) å’Œ temp.push_back(*(it - 1))ï¼ŒOP * å¯èƒ½ä¼šè¢«æ‰©å±•æˆ OP, OP OP, OP OP OP, OP OP OP OP ç­‰ä¸€ç³»åˆ—é‡å¤æ¨¡å¼ã€‚ å®ƒé€šè¿‡é€’å½’è°ƒç”¨è‡ªèº«ï¼Œä»¥å¤„ç†ä¸€ä¸ªæ¨¡å¼ä¸­åŒ…å«å¤šä¸ªç‰¹æ®Šç®—å­çš„æƒ…å†µã€‚ æœ€ç»ˆï¼Œå®ƒè¿”å›ä¸€ä¸ªç”±å¤šä¸ªå…·ä½“ã€æ— ç‰¹æ®Šç®—å­çš„æ¨¡å¼ç»„æˆçš„åˆ—è¡¨ã€‚ç„¶åï¼Œå®ƒå°†è¿™äº›æ‰©å±•åçš„å…·ä½“æ¨¡å¼é€ä¸€ä¼ é€’ç»™ insertPattern å‡½æ•°ï¼Œä»¥æ„å»º Trie æ ‘ã€‚ void Automation::insertPatterns(std::map\u0026lt;std::vector\u0026lt;TX8BE_OPS\u0026gt;, int\u0026gt; patterns) { std::vector\u0026lt;std::vector\u0026lt;TX8BE_OPS\u0026gt;\u0026gt; tempPatterns; for (auto it : patterns) { // Iterate through each pattern from the input map. auto temp = processPattern(it.first); // Pre-process the pattern. This can expand one pattern into many. for (auto p : temp) { // For each of the generated concrete patterns... insertPattern(p, it.second); // ...insert it into the main data structure (the Trie). } } } insertPattern æ¥æ”¶ä¸€ä¸ªå…·ä½“çš„æ¨¡å¼ï¼Œå¹¶å°†å…¶æ’å…¥åˆ° Trie æ ‘ä¸­ã€‚Trie æ ‘æ˜¯å®ç°é«˜æ•ˆå‰ç¼€åŒ¹é…çš„å…³é”®ã€‚ä»rootèŠ‚ç‚¹å¼€å§‹ éå†æ¨¡å¼ä¸­çš„æ¯ä¸ª op. å¦‚æœå½“å‰èŠ‚ç‚¹æ²¡æœ‰æŒ‡å‘opçš„å­èŠ‚ç‚¹ï¼Œå°±åˆ›å»ºä¸€ä¸ªç„¶åç§»åŠ¨åˆ°è¯¥å­èŠ‚ç‚¹ã€‚å½“æ¨¡å¼éå†å®Œæˆåï¼Œåœ¨æœ€ç»ˆçš„èŠ‚ç‚¹ä¸Šå­˜å‚¨å®Œæ•´æ¨¡å¼æœ¬èº« (node-\u0026gt;pattern) å’Œå®ƒçš„ ID (node-\u0026gt;output) ã€‚è¿™è¡¨æ˜ä¸€ä¸ªæœ‰æ•ˆçš„æ¨¡å¼åœ¨æ­¤ç»“æŸã€‚\ninsertPattern Implementation struct TrieNode { TrieNode(TX8BE_OPS id) : id(id) {} // Constructor to initialize the node with an operation ID. TX8BE_OPS id; // The operation (Op) type this node represents. This is the \u0026#39;character\u0026#39; in our sequence. std::vector\u0026lt;int\u0026gt; output; // Stores the integer IDs of the patterns that end at this node. A non-empty vector indicates a valid pattern match. std::vector\u0026lt;TX8BE_OPS\u0026gt; pattern; // Stores the complete operator sequence for the pattern that ends here. std::unordered_map\u0026lt;TX8BE_OPS, NodePtr\u0026gt; children; // A map from an operation type to the next node in the trie. `NodePtr` is likely a shared_ptr or unique_ptr to another TrieNode. }; void Automation::insertPattern(const std::vector\u0026lt;TX8BE_OPS\u0026gt; pattern, int index) { patterns_.push_back(pattern); // Store the raw pattern vector. auto node = root; // Start from the root of the Trie. for (auto op : pattern) { // Iterate through each operation in the pattern sequence. if (node-\u0026gt;children.find(op) == node-\u0026gt;children.end()) { // If a path for this operation does not exist... node-\u0026gt;children[op] = std::make_shared\u0026lt;TrieNode\u0026gt;(op); // ...create a new node in the Trie. } node = node-\u0026gt;children[op]; // Move to the next node in the Trie. } node-\u0026gt;pattern = pattern; // At the end of the pattern, mark this node as a terminal node by storing the full pattern. node-\u0026gt;output.push_back(index); // Store the original pattern index/ID at this terminal node. } searchOp å‡½æ•°çš„åŠŸèƒ½æ˜¯ï¼šç»™å®šä¸€ä¸ªèµ·å§‹ Trie èŠ‚ç‚¹ (parentNode) å’Œä¸€ä¸ªMLIRç®—å­ (op)ï¼Œå®ƒä¼šå°è¯•å°† op ä¸parentNode çš„å­èŠ‚ç‚¹è¿›è¡ŒåŒ¹é…ï¼Œå¹¶åœ¨åŒ¹é…æˆåŠŸåï¼Œé€’å½’åœ°å¯¹å…¶æ‰€æœ‰åç»§ç®—å­ (users) è¿›è¡Œ DFS æ¨¡å¼åŒ¹é…ï¼Œæœ€ç»ˆè¿”å›è¿™æ¡è·¯å¾„ä¸Šæ‰€èƒ½æ‰¾åˆ°çš„â€œæœ€ä½³â€åŒ¹é…æ¨¡å¼çš„æœ«ç«¯TrieèŠ‚ç‚¹ã€‚\nè¿™é‡Œçš„â€œæœ€ä½³â€é€šå¸¸æŒ‡æœ€é•¿çš„åŒ¹é…æ¨¡å¼ï¼Œæˆ–è€…åœ¨æœ‰å¤šä¸ªåŒæ ·é•¿åº¦çš„æ¨¡å¼æ—¶ï¼Œé€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„é‚£ä¸ª (æ ¹æ®èŠ‚ç‚¹ä¸­çš„ output.front()) å¤§å°æ¯”è¾ƒæ¥åˆ¤æ–­ã€‚\nsearchOp Implementation NodePtr Automation::searchOp(NodePtr parentNode, Operation* op) { auto opId = getOpId(op); // Get the enumerated ID (e.g., TX8BE_OPS::CONV) for the current MLIR operation. if (isRealOp(op) \u0026amp;\u0026amp; parentNode-\u0026gt;children.find(opId) == parentNode-\u0026gt;children.end()) { // If the current op is a \u0026#34;real\u0026#34; operation (not a terminator, etc.) but cannot be found in the children of the parent Trie node, it\u0026#39;s a mismatch. // This \u0026#39;if\u0026#39; block seems to be an early exit for a specific case, possibly redundant with the final return. } if (parentNode-\u0026gt;children.find(opId) != parentNode-\u0026gt;children.end()) { // If a path exists in the Trie for the current operation `opId`. This is a potential match. // If the current op matches, continue downwards auto currentNode = parentNode-\u0026gt;children[opId]; // Move to the matched Trie node. auto tempNode = currentNode; // `tempNode` will store the longest match found so far starting from this path. // --- Query Operation Attributes and Users --- auto queryInterface = llvm::dyn_cast\u0026lt;tx8e_mlir::OpLibInterface\u0026gt;(op); // Get a specific interface from the operation for querying attributes. auto needStore = queryInterface.queryOpAttr().needStore; // Check an attribute, e.g., if the op\u0026#39;s result needs to be stored. llvm::SmallSet\u0026lt;Operation*, 1\u0026gt; users; // Find all direct users of the current operation\u0026#39;s result. for (auto user : op-\u0026gt;getUsers()) { users.insert(user); } auto sortedUsers = manager_-\u0026gt;sortOps(users); // Sort the users, likely topologically or based on some priority. // --- Recursively Search Through Users --- for (auto user : sortedUsers) { if (!isRealOp(user)) continue; // Skip non-essential ops. auto interface = llvm::dyn_cast\u0026lt;tx8e_mlir::OpLibInterface\u0026gt;(user); auto needLoad = interface.queryOpAttr().needLoad; if (!needStore \u0026amp;\u0026amp; needLoad) continue; // Skip paths with certain attribute mismatches (e.g., store-load dependency). // Recursively call searchOp for the user operation, starting from the current Trie node. auto terminalNode = searchOp(currentNode, user); // --- Update Best Match --- if (!terminalNode-\u0026gt;output.empty() \u0026amp;\u0026amp; !tempNode-\u0026gt;output.empty()) { // If both the previous best match (`tempNode`) and the new match (`terminalNode`) are valid patterns... // Compare priority, take the one with the highest priority as the current node pattern) if (terminalNode-\u0026gt;output.front() \u0026gt; tempNode-\u0026gt;output.front()) { / ...update `tempNode` to the new one if it has a higher priority (assuming the int ID represents priority). tempNode = terminalNode; } } else if (!terminalNode-\u0026gt;output.empty()) { // If `tempNode` was not a valid pattern end, but `terminalNode` is, update it. tempNode = terminalNode; } } // TFOOTER(TRACE) return tempNode; // Return the node corresponding to the longest/best pattern found from this point. } // Indicates parent node cannot match current op, return parent node) return parentNode; // If no match was found for `opId` in the Trie, return the original `parentNode`. } searchéå†è®¡ç®—å­å›¾ (subgraph) ä¸­çš„æ¯ä¸€ä¸ªç®—å­ï¼Œå¹¶ä»¥è¯¥ç®—å­ä¸ºèµ·ç‚¹ï¼Œå°è¯•è¿›è¡Œæ¨¡å¼åŒ¹é…ã€‚\né¢„å¤„ç†é˜¶æ®µ (ç¬¬ä¸€ä¸ª walk) åœ¨æ­£å¼å¼€å§‹åŒ¹é…ä¹‹å‰ï¼Œå‡½æ•°ä¼šå…ˆéå†ä¸€æ¬¡æ•´ä¸ªå­å›¾ï¼Œç›®çš„æ˜¯æ”¶é›†å’Œæ³¨å†Œä¸€äº›å…ƒæ•°æ®ï¼š manager_-\u0026gt;opOrder_: ä¸€ä¸ª vector è®°å½•å›¾ä¸­æ‰€æœ‰ç®—å­çš„å‡ºç°é¡ºåºã€‚ manager_-\u0026gt;opIndexMap_: ä¸ºæ¯ä¸ªç®—å­åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°ç´¢å¼•ã€‚ è¿™äº›ä¿¡æ¯å¯¹äºåç»­çš„ç®¡ç†å’Œå¯èƒ½çš„å›¾å˜æ¢ (å¦‚æ‹“æ‰‘æ’åº) éå¸¸é‡è¦ã€‚ é€ç‚¹åŒ¹é…é˜¶æ®µ (ç¬¬äºŒä¸ª walk)å®ƒå†æ¬¡éå†å­å›¾ä¸­çš„æ¯ä¸€ä¸ªç®—å­ op æ¯æ¬¡éƒ½æ˜¯ä» Trie æ ‘çš„æ ¹èŠ‚ç‚¹ root å¼€å§‹ searchOp(root, op) å‡½æ•°ã€‚æ„å‘³ç€å°è¯•ä»é›¶å¼€å§‹åŒ¹é…æ‰€æœ‰å·²çŸ¥çš„æ¨¡å¼ã€‚ searchOp ä¼šè¿”å›ä» op å¼€å§‹èƒ½æ‰¾åˆ°çš„æœ€é•¿/æœ€ä¼˜çš„åŒ¹é…æ¨¡å¼çš„æœ«ç«¯èŠ‚ç‚¹ (terminalNode). å¦‚æœå…¶ output åˆ—è¡¨ä¸ä¸ºç©ºï¼Œè¯´æ˜ searchOp æˆåŠŸåœ°æ‰¾åˆ°äº†ä¸€æ¡å®Œæ•´çš„åŒ¹é…è·¯å¾„ã€‚å‡½æ•°å°±ä¼šå°†è¿™ä¸ªåŒ¹é…ç»“æœè®°å½•ä¸‹æ¥ï¼šåœ¨ manager ä¸­æ›´æ–° Pattern å¯¹è±¡ï¼Œå¹¶åœ¨æœ¬åœ°çš„ result map ä¸­å»ºç«‹ä»èµ·å§‹ç®—å­ opåˆ°æ¨¡å¼IDçš„æ˜ å°„ã€‚ åä¹‹è¯´æ˜ä» op å¼€å§‹æ— æ³•åŒ¹é…ä»»ä½•å®Œæ•´çš„æ¨¡å¼ï¼Œäºæ˜¯å°±ä»€ä¹ˆä¹Ÿä¸åšï¼Œç»§ç»­æ£€æŸ¥ä¸‹ä¸€ä¸ªç®—å­ã€‚ search Implementation void Automation::search(tx8e::SubgraphOp subgraph) { // k: the starting operation of a matched pattern // v: the type/ID of the matched pattern std::map\u0026lt;Operation*, int\u0026gt; result; manager_-\u0026gt;initDefsMap(subgraph); // Initialize manager with definition information from the subgraph. subgraph-\u0026gt;walk([\u0026amp;](Operation* op) { // First pass: walk through the subgraph to gather metadata. manager_-\u0026gt;opOrder_.insert(op); // Record the sequential order of all operations. manager_-\u0026gt;opIndexMap_[op] = index++; // Assign a unique index to each operation. }); // Second pass: walk through the subgraph again to perform the actual pattern matching. subgraph-\u0026gt;walk([\u0026amp;](Operation* op) { // Skip the return operation of the subgraph as it\u0026#39;s not part of a computational pattern. if (isa\u0026lt;tx8e::SubgraphOp, tx8e::SubgraphReturnOp\u0026gt;(op)) { return WalkResult::skip(); // In newer MLIR, this might be `return;`. Skips processing this op\u0026#39;s children. } auto pattern = std::make_shared\u0026lt;Pattern\u0026gt;(op); // Create a Pattern object, representing a potential match starting at `op`. manager_-\u0026gt;patterns_.push_back(pattern); // Add this potential pattern to the manager\u0026#39;s list. manager_-\u0026gt;patternMap_[op] = pattern; // Map the operation `op` to its corresponding Pattern object. // terminalNode å°±æ˜¯æœ€ååŒ¹é…åˆ°çš„ä¸€ä¸ªNode (terminalNode is the final matched Node) // This is the main call to the recursive search function, starting from the Trie root for each `op`. auto terminalNode = searchOp(root, op); // If the Node has an output, it means a match was found. If multiple matches exist, they are replaced based on priority during the search phase // The final result is a match for the highest-priority pattern if (!terminalNode-\u0026gt;output.empty()) { // Check if the search returned a valid pattern-terminating node. // If a match was found, update the Pattern object with the results from the terminal node. pattern-\u0026gt;setPattern(terminalNode-\u0026gt;output.front(), terminalNode-\u0026gt;pattern); // Record the result: map the starting operation `op` to the matched pattern\u0026#39;s ID. result[op] = terminalNode-\u0026gt;output.front(); } return WalkResult::advance(); // Proceed to the next operation in the walk. }); } GroupOptimizationPass ä¼šéå†ä¸€ä¸ªè®¡ç®— subGraph ä¸­çš„æ‰€æœ‰ OP. å¯¹äºæ¯ä¸€ä¸ªé€šè¿‡ç­›é€‰çš„æ™®é€šè®¡ç®—æ“ä½œï¼Œä¼šè°ƒç”¨ createSingleGroup å‡½æ•°æ¥ä¸ºå…¶åˆ›å»ºä¸€ä¸ªä¸“å±çš„ GroupOp. createSingleGroup ä¼šæ£€æŸ¥åŸå§‹ OP çš„æ‰€æœ‰è¾“å…¥ã€‚å¦‚æœè¾“å…¥æ¥è‡ªå¦ä¸€ä¸ªè®¡ç®—æ“ä½œï¼Œé‚£ä¹ˆè¿™ä¸ªè¾“å…¥å°±ä¼šæˆä¸ºæ–° GroupOp çš„è¾“å…¥ã€‚å¦‚æœè¾“å…¥æ˜¯ LoadConstOpï¼Œåˆ™è¢«è§†ä¸ºè¿™ä¸ªåˆ†ç»„çš„å†…éƒ¨ä¾èµ–ï¼Œè€Œä¸æ˜¯å¤–éƒ¨è¾“å…¥ã€‚åŸå§‹ op çš„æ‰€æœ‰è¾“å‡ºä¼šç›´æ¥æˆä¸ºæ–° GroupOp çš„è¾“å‡ºã€‚\næ–°çš„ GroupOp æ‹¥æœ‰ä¸Šä¸€æ­¥å®šä¹‰çš„è¾“å…¥å’Œè¾“å‡ºã€‚åŸå§‹çš„æ“ä½œ op å’Œå®ƒçš„å¸¸é‡ä¾èµ– (dependencies) è¢«ç§»åŠ¨åˆ°è¿™ä¸ªæ–°åˆ›å»ºçš„ GroupOp å†…éƒ¨ã€‚æœ€åï¼Œä¿®æ”¹åŸå§‹æ“ä½œ OP çš„è¿æ¥å…³ç³»ï¼Œä½¿å…¶åœ¨åˆ†ç»„å†…éƒ¨èƒ½å¤Ÿæ­£ç¡®åœ°æ¥æ”¶è¾“å…¥å¹¶äº§ç”Ÿè¾“å‡ºã€‚ä¼ªä»£ç å¦‚ä¸‹\nfor op in subGraph.ops: // æ£€æŸ¥æ“ä½œçš„ç±»å‹ if op == (GroupOp || ReturnOp || LoadConstOp || NoneOp): continue createSingleGroup(op) ------------------------------------ createSingleGroup(op): for pre_op in op.inputsOp: // åˆ¤æ–­å‰ç½®æ“ä½œæ˜¯å¦ä¸ºâ€œåŠ è½½å¸¸é‡â€æˆ–â€œç©ºæ“ä½œâ€ if pre_op == (LoadConstOp || NoneOp): // å¦‚æœæ˜¯ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°ä¾èµ–é¡¹ (dependencies) é›†åˆä¸­ dependencies.add(pre_op) else: // å¦‚æœæ˜¯å…¶ä»–æ™®é€šæ“ä½œï¼Œåˆ™å°†å…¶ç»“æœæ·»åŠ åˆ°æ–°åˆ†ç»„çš„è¾“å…¥ (groupInput) ä¸­ groupInput.add(pre_op.result) for result in op.results: // éå†å½“å‰æ“ä½œçš„æ‰€æœ‰è¾“å‡ºç»“æœ // å°†è¿™äº›ç»“æœæ·»åŠ åˆ°æ–°åˆ†ç»„çš„è¾“å‡º (groupOutput) ä¸­ groupOutput.add(result) // ä½¿ç”¨æ”¶é›†å¥½çš„è¾“å…¥å’Œè¾“å‡ºåˆ›å»ºä¸€ä¸ªæ–°çš„ GroupOp (åˆ†ç»„æ“ä½œ) create GroupOp(groupInput, groupOutput) // å°†ä¾èµ–é¡¹ (å¦‚å¸¸é‡) ç§»åŠ¨åˆ°æ–°åˆ†ç»„çš„æœ«å°¾ (æˆ–å†…éƒ¨) move dependencies to group end // å°†åŸå§‹æ“ä½œ op æœ¬èº«ä¹Ÿç§»åŠ¨åˆ°æ–°åˆ†ç»„çš„æœ«å°¾ (æˆ–å†…éƒ¨) move op to group end // ä¿®æ”¹åŸå§‹æ“ä½œ op çš„è¾“å…¥å’Œè¾“å‡ºï¼Œä½¿å…¶åœ¨æ–°åˆ†ç»„å†…éƒ¨æ­£ç¡®è¿æ¥ change op input and output GroupOptimizationPass\nGroupLdStPass GroupLdStPass ä½œç”¨ç”¨æ˜¯å¤„ç† GroupOp çš„è¾“å…¥å’Œè¾“å‡ºï¼Œé€šè¿‡æ˜¾å¼æ’å…¥ Load å’Œ Store æ“ä½œï¼Œæ¥â€œå›ºåŒ–â€å’Œâ€œéš”ç¦»â€GroupOp çš„è¾¹ç•Œã€‚\nLoad æ’å…¥æµç¨‹\nè¯†åˆ« Load éœ€æ±‚: å‡½æ•°éå† GroupOp çš„æ¯ä¸€ä¸ªè¾“å…¥å‚æ•°vã€‚ç„¶åï¼Œå®ƒæŸ¥æ‰¾æ‰€æœ‰åœ¨ GroupOp å¤–éƒ¨ä½¿ç”¨ v çš„ç®—å­ (userOp) ã€‚é€šè¿‡æ£€æŸ¥è¿™äº›userOpçš„å±æ€§ (needLoad) ï¼Œå®ƒåˆ¤æ–­å“ªäº› userOp éœ€è¦ä¸€ä¸ªæ˜¾å¼çš„ Load æ“ä½œæ¥è·å– v çš„å€¼ã€‚ å¤„ç†ç‰¹æ®Šå¸ƒå±€: ä»£ç ä¸­æœ‰ä¸€æ®µç‰¹æ®Šçš„é€»è¾‘ (if(isa\u0026lt;...\u0026gt;)) ï¼Œç”¨äºå¤„ç† Addã€Sub ç­‰äºŒå…ƒç®—å­ã€‚å®ƒæ£€æŸ¥è¾“å…¥çš„layout å¦‚æœå­˜åœ¨ä¸åŒ¹é…çš„æƒ…å†µ (ä¾‹å¦‚ä¸€ä¸ªNCxå¸ƒå±€å’Œä¸€ä¸ªTensorå¸ƒå±€) ï¼Œå®ƒå¯èƒ½ä¼šå¼ºåˆ¶layoutç»Ÿä¸€ï¼Œä»¥ç¡®ä¿ç¡¬ä»¶èƒ½å¤Ÿæ­£ç¡®è®¡ç®—ã€‚ æ’å…¥ LoadVarOp: åœ¨ç¡®å®šäº†æ‰€æœ‰éœ€è¦ Load çš„å¤–éƒ¨ç”¨æˆ·åï¼Œå¦‚æœè¿™æ ·çš„ç”¨æˆ·å­˜åœ¨ (usersLoad.size() != 0)ï¼Œå®ƒä¼šåœ¨GroupOpçš„å…¥å£å¤„åˆ›å»ºä¸€ä¸ªtx8e::LoadVarOpæ“ä½œã€‚ é‡å®šå‘æ•°æ®æµ: å°†æ‰€æœ‰å¤–éƒ¨ç”¨æˆ·å¯¹åŸå§‹è¾“å…¥ v çš„è¿æ¥ (SSA use-def chain) ï¼Œå…¨éƒ¨æ–­å¼€ï¼Œå¹¶é‡æ–°è¿æ¥åˆ°æ–°åˆ›å»ºçš„LoadVarOpçš„è¾“å‡ºä¸Š (replaceUsesOfWith). Store æ’å…¥æµç¨‹\nè¯†åˆ«å­˜å‚¨éœ€æ±‚: å‡½æ•°æ‰¾åˆ° GroupOp å†…éƒ¨çš„ return æ“ä½œï¼Œå¹¶éå†å®ƒçš„æ¯ä¸€ä¸ªæ“ä½œæ•° (å³ GroupOp çš„è¾“å‡ºå€¼). é€šè¿‡æ£€æŸ¥äº§ç”Ÿè¿™äº›è¾“å‡ºå€¼çš„å†…éƒ¨ç®—å­ (pre_op) çš„needStoreå±æ€§ï¼Œæ¥åˆ¤æ–­å“ªäº›è¾“å‡ºéœ€è¦è¢«æ˜¾å¼åœ°Storeï¼Œä»¥ä¾¿å¤–éƒ¨ä¸–ç•Œèƒ½å¤Ÿè®¿é—®ã€‚ æ’å…¥ StoreVarOp: å¦‚æœä¸€ä¸ªè¾“å‡ºå€¼éœ€è¦è¢«å­˜å‚¨ï¼Œå‡½æ•°ä¼šåœ¨ GroupOp çš„æœ«å°¾ã€return æ“ä½œä¹‹å‰ï¼Œåˆ›å»ºä¸€ä¸ªtx8e::StoreVarOp æ¥æ”¶ GroupOp çš„å†…éƒ¨è®¡ç®—ç»“æœã€‚ æ›´æ–°è¿”å›ç»“æœ: StoreVarOpæœ¬èº«ä¹Ÿæœ‰ä¸€ä¸ªè¾“å‡ºã€‚å‡½æ•°ä¼šæ›´æ–° GroupOp çš„ return æ“ä½œï¼Œä½¿å…¶è¿”å› StoreVarOp çš„è¾“å‡ºï¼Œè€Œä¸æ˜¯åŸå§‹çš„å†…éƒ¨è®¡ç®—ç»“æœã€‚ GroupLdStPass Implementation void GroupLdStPass::runOnOperation() { subgraph.walk([\u0026amp;](tx8e::GroupOp g_op) { // ... // For each group\u0026#39;s input, insert a load. If used by multiple ops, multiple loads are inserted for (auto v : g_op.getBody().front().getArguments()) { // Iterate over each input argument of the group. Operation* pre_op = getValidDefiningOp(v); // Find the operation that produces this input. // ... std::map\u0026lt;Operation*, int32_t\u0026gt; usersLoad; // A map to store users that need to load this input. for (auto userOp : v.getUsers()) { // Find all users of this input argument. // ... // Check if the user needs a \u0026#39;load\u0026#39; based on its attributes. if ((!opAttr.needLoad \u0026amp;\u0026amp; (1 \u0026lt;\u0026lt; arg_idx))) { continue; } // If a load is needed, record the user and its argument index. usersLoad.insert(std::make_pair(userOp, arg_idx)); // This block handles complex layout logic for Add/Sub/Mul/Div ops. // It seems to ensure that if one input to \u0026#39;add\u0026#39; is rank1 tensor, the other is also handled correctly, // potentially by forcing a specific layout (`LayoutMode::Cx`). if (isa\u0026lt;tx8e::AddOp, tx8e::SubOp, tx8e::DivOp, tx8e::MulOp\u0026gt;(userOp)) { // ... [å¤æ‚å¸ƒå±€é€»è¾‘] } if (usersLoad.size() != 0) { // there are users that require a load operation. std::vector\u0026lt;NamedAttribute\u0026gt; tmp_attrs; // ... [æ„å»ºLoadVarOpçš„å±æ€§] // Create the Load operation. auto ld = builder.create\u0026lt;tx8e::LoadVarOp\u0026gt;(g_op.getLoc(), v.getType(), v, tmp_attrs); // ... [è®¾ç½®åŠ¨æ€shapeå±æ€§] // For each user that needs the load... for (auto userOp : usersLoad) { // ...replace its use of the original input `v` with the result of the new `Load` operation `ld`. userOp.first-\u0026gt;replaceUsesOfWith(v, ld.getOutput()); } } } // For each group\u0026#39;s output, insert a store builder.setInsertionPointToEnd(\u0026amp;block); // Set the insertion point to the end of the group\u0026#39;s body. Operation *g_return = g_op.getBody().front().getTerminator(); // Get the return operation of the group. for (int i = 0; i \u0026lt; g_return-\u0026gt;getNumOperands(); ++i) { // Iterate over each output of the group. auto value = g_return-\u0026gt;getOperand(i); auto pre_op = value.getDefiningOp(); // Find the operation inside the group that produces this output. // ... // Check if this output value needs to be stored for external users. if (!(llvm::dyn_cast\u0026lt;tx8e::OpLibInterface\u0026gt;(pre_op)).queryOpAttr().needStore \u0026amp;\u0026amp; (1 \u0026lt;\u0026lt; i)) { continue; } // ... [æ„å»ºStoreVarOpçš„å±æ€§] // Create the Store operation. auto st = builder.create\u0026lt;tx8e::StoreVarOp\u0026gt;(g_op.getLoc(), value.getType(), value, st_attrs); // ... [è®¾ç½®åŠ¨æ€shapeå±æ€§] // Update the group\u0026#39;s return instruction to return the result of the store op. g_return-\u0026gt;setOperand(i, st.getOutput()); } g_return-\u0026gt;moveBefore(gBlock, block.end()); // Move the return instruction (not standard MLIR, might be custom logic). updateIR(g_op); // Update the IR of the group op. } }); } GroupMappingPass GroupMappingPass ä½œç”¨æ˜¯å°†é¡¶å±‚æ¨¡å— (Module) ä¸­å®šä¹‰çš„å…¨å±€ç»´åº¦ä¿¡æ¯ (x_dim å’Œ y_dim) è®¾ç½®åˆ°æ¯ä¸€ä¸ª GroupOp æˆ– GroupOp çš„è°ƒç”¨ç‚¹ä¸Šã€‚\nGroupMappingPass Implementation // Defines a function to perform a simple mapping of groups. void simpleGroupMapping(ModuleOp module) { // Get x and y dimension from the module\u0026#39;s attributes. // These attributes are likely defined globally for the entire compilation. uint32_t x_dim = module-\u0026gt;getAttrOfType\u0026lt;IntegerAttr\u0026gt;(tx8e::ModuleAttr::TileDx).getInt(); uint32_t y_dim = module-\u0026gt;getAttrOfType\u0026lt;IntegerAttr\u0026gt;(tx8e::ModuleAttr::TileDy).getInt(); // Create an OpBuilder instance, which is a helper to create/modify MLIR operations. OpBuilder builder(module.getContext()); // Get the \u0026#39;main\u0026#39; function from the module. func::FuncOp main = module.getMainFuncOp(); // Get the first block (entry block) of the main function. auto\u0026amp; main_block = main.getBody().front(); for (auto\u0026amp; inner : main_block.getOperations()) { // Iterate over all operations within the main function\u0026#39;s body if (isa\u0026lt;tx8e::CallOp\u0026gt;(inner)) { // The module\u0026#39;s main function contains CallOps. This implies an indirect call to a subgraph. // Find the subgraph definition (\u0026#39;SubraphOp\u0026#39;) using the symbol name from the CallOp. tx8e::SubgraphOp sg = module.lookupSymbol\u0026lt;tx8e::SubgraphOp\u0026gt;( llvm::dyn_cast\u0026lt;tx8e::CallOp\u0026gt;(inner).getCallee()); // Walk through the operations inside the called subgraph. // We are looking for the \u0026#39;GroupOp\u0026#39; which is the actual unit of computation. sg.walk([\u0026amp;](tx8e::GroupOp gop) { // Set a \u0026#39;dev_region\u0026#39; attribute on the located GroupOp. setDevRegionAttr(builder, module.getContext(), gop.getOperation(), x_dim, y_dim); }); } if (isa\u0026lt;tx8e::GroupOp\u0026gt;(inner)) { // The module\u0026#39;s main function directly contains GroupOps. // Directly set the \u0026#39;dev_region\u0026#39; attribute on the GroupOp found in the main function. setDevRegionAttr(builder, module.getContext(), llvm::dyn_cast\u0026lt;tx8e::GroupOp\u0026gt;(inner).getOperation(), x_dim, y_dim); } } } void GroupMappingPass::runOnOperation() { // It will operate on the entire ModuleOp. auto module = getOperation(); simpleGroupMapping(module); } GroupCostPass GroupCostPass ä½œç”¨æ˜¯ä¸ºä¸€ä¸ª GroupOp åœ¨æ‰€æœ‰å¯èƒ½çš„åˆ‡åˆ†ç­–ç•¥ä¸­ï¼Œé€šè¿‡ Cost Model æœç´¢å¹¶åº”ç”¨æœ€ä¼˜çš„ä¸€ä¸ªã€‚ç®—æ³•æµç¨‹å¦‚ä¸‹ã€‚\nå‡†å¤‡é˜¶æ®µ (Preparation):\nBailout Condition: if (gop-\u0026gt;hasAttr(\u0026quot;group_tag\u0026quot;) \u0026amp;\u0026amp; ... == 2) return; å¦‚æœ GroupOpçš„ group_tag==2ï¼Œé‚£ä¹ˆè¿™ä¸ª Pass å°±æ— éœ€ä¸ºå®ƒæœç´¢åˆ‡åˆ†ç­–ç•¥äº†ï¼Œç›´æ¥è¿”å›ã€‚ æ‹·è´ç¼–è¯‘é€‰é¡¹: costoption_lg.dynCompile = compileOption_-\u0026gt;dynCompile; ä»ä¸€ä¸ªå…¨å±€çš„compileOption_ ä¸­æ‹·è´äº†ä¸€ç³»åˆ—ç¼–è¯‘å‚æ•°åˆ°å±€éƒ¨çš„ costoption_lg ä¸­. è¡¨æ˜ Pass çš„è¡Œä¸ºå¯ä»¥è¢«å¤–éƒ¨é…ç½®æ‰€å½±å“ã€‚ åˆ›å»ºæœç´¢ç©ºé—´: auto space = std::make_shared\u0026lt;SliceSpace\u0026gt;(); åˆ›å»ºäº†ä¸€ä¸ªåä¸º space çš„å¯¹è±¡ï¼Œè¿™ä¸ª SliceSpace ç±»å°è£…äº†è¯¥ GroupOp çš„å®Œæ•´æœç´¢ç©ºé—´ã€‚å®ƒåŒ…å«äº†æ‰€æœ‰å¯èƒ½çš„å¼ é‡åˆ‡åˆ†æ–¹å¼ã€‚ æ¨¡æ¿æœºåˆ¶: if (useTemplate) { ... } æ£€æŸ¥ compileOption_-\u0026gt;sliceHelpMap çš„å…¨å±€æ˜ å°„ã€‚å¦‚æœä¹‹å‰å·²ç»ä¸ºç›¸ä¼¼çš„ GroupOp (ç”± GroupKey æ ‡è¯†) è®¡ç®—è¿‡æœ€ä¼˜ç­–ç•¥ï¼Œå®ƒå°±ä¼šç›´æ¥ä»ç¼“å­˜ä¸­è¯»å–ç»“æœ (sliceHelp) ï¼Œä»è€Œé¿å…æ˜‚è´µçš„é‡å¤æœç´¢ã€‚å¦‚æœæ‰¾åˆ°äº†æ¨¡æ¿ï¼Œå®ƒä¼šç›´æ¥åº”ç”¨å¹¶æå‰è¿”å›ã€‚ æœè¿­ä»£æœç´¢å¾ªç¯ (The Core: Iterative Search Loop)\nwhile (1) å¾ªç¯: è¿™ä¸ªæ— é™å¾ªç¯æ˜¯æœç´¢ç®—æ³•çš„ä¸»ä½“ã€‚ æ¢ç´¢ç­–ç•¥: åœ¨å¾ªç¯å†…éƒ¨ï¼Œspaceå¯¹è±¡ä¼šç”Ÿæˆä¸€ä¸ªå€™é€‰çš„åˆ‡åˆ†ç­–ç•¥ã€‚è¿™é€šè¿‡ space-\u0026gt;shardingLevel å’Œspace-\u0026gt;factorSpace_ æ¥æ§åˆ¶ï¼Œå®ƒä»¬å…±åŒå®šä¹‰äº†å½“å‰æ­£åœ¨å°è¯•çš„åˆ‡åˆ†ç»´åº¦å’Œæ–¹å¼ã€‚ åˆ¤æ–­æœç´¢æ˜¯å¦å®Œæˆ: if (space-\u0026gt;shardingLevel.isSpaceFinish() \u0026amp;\u0026amp; ...). åœ¨æ¯æ¬¡è¿­ä»£å¼€å§‹æ—¶ï¼Œå®ƒä¼šæ£€æŸ¥æ˜¯å¦å·²ç»éå†äº†æ‰€æœ‰çš„åˆ‡åˆ†å¯èƒ½æ€§ã€‚å¦‚æœæœç´¢ç©ºé—´å·²è€—å°½ï¼Œå¾ªç¯å°±ä¼šç»ˆæ­¢ã€‚ æˆæœ¬ä¼°ç®—: å¦‚æœæ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„å€™é€‰ç­–ç•¥ï¼Œæ¥ä¸‹æ¥å°±æ˜¯ä¼°ç®—è¿™ä¸ªç­–ç•¥çš„æˆæœ¬ã€‚åŠ¨æ€æ„å»ºPassæµæ°´çº¿: auto pm = std::make_unique\u0026lt;LgPassManager\u0026gt;(...); æ·»åŠ ä¸€ç³»åˆ—ä¼°ç®—Pass: pm-\u0026gt;add_pass(createDataSplitNewPass(space)); // æ ¹æ®ç­–ç•¥è¿›è¡Œæ•°æ®åˆ‡åˆ† pm-\u0026gt;add_pass(createTimeStepNewPass(space)); // åˆ’åˆ†æ—¶é—´æ­¥ pm-\u0026gt;add_pass(createSPMAllocPass(space)); // æ¨¡æ‹ŸSPM (ç‰‡ä¸Šå†…å­˜) åˆ†é… pm-\u0026gt;add_pass(createEstimatePass(space)); // ä¼°ç®—æ€§èƒ½/æˆæœ¬ è¿è¡Œä¼°ç®—æµç¨‹: pm-\u0026gt;run(gop); æ¯”è¾ƒå’Œé€‰æ‹©æœ€ä¼˜è§£: ä¼°ç®—å®Œæˆåï¼Œspace-\u0026gt;status ä¼šè¢«æ›´æ–° (SSTATUS_OK è¡¨ç¤ºä¼°ç®—æˆåŠŸï¼ŒSSTATUS_SA_MemAlloc è¡¨ç¤ºå†…å­˜åˆ†é…å¤±è´¥) . å¦‚æœä¼°ç®—æˆåŠŸï¼Œå®ƒä¼šè·å–æˆæœ¬ tï¼Œå¹¶ä¸å·²çŸ¥çš„ bestCost è¿›è¡Œæ¯”è¾ƒã€‚å¦‚æœå½“å‰ç­–ç•¥æ›´ä¼˜ï¼Œå°±æ›´æ–° bestCost å’Œ bestStrategyã€‚ åº”ç”¨æœ€ä¼˜ç­–ç•¥ (Applying the Best Strategy)\nåº”ç”¨ç­–ç•¥: sliceHelp.strategy = space-\u0026gt;strategy; å’Œåç»­çš„ compileOption_-\u0026gt;IRHelp.ops[gop] = space-\u0026gt;stageOps; ç­‰èµ‹å€¼æ“ä½œï¼Œå°±æ˜¯å°†æœç´¢åˆ°çš„æœ€ä¼˜ç­–ç•¥ç»“æœ (åŒ…æ‹¬æ¯ä¸ªæ“ä½œçš„åˆ‡åˆ†æ–¹å¼ã€å¾ªç¯ä¿¡æ¯ç­‰) ä¿å­˜åˆ° compileOption_ä¸­ï¼Œä¾›åç»­çš„ Pass ä½¿ç”¨ã€‚ å…·ä½“è®¡ç®—: gop-\u0026gt;walk(...) å®ƒéå† GroupOp å†…éƒ¨çš„æ“ä½œ (å¦‚GemmOp) ï¼Œå¹¶æ ¹æ®ç­–ç•¥ (lSharding, rSharding) è®¡ç®—å‡ºå…·ä½“çš„å¾ªç¯è¾¹ç•Œ (ls, rs) å’Œåˆ†ç‰‡é•¿åº¦ (pLen) ï¼Œè¿™äº›ä¿¡æ¯ä¼šè¢«å­˜å…¥ gls (GroupLoopSpace) å¯¹è±¡ä¸­ã€‚ DataSplitNewPass å…¶ä¸­ä¹ŸåŒ…æ‹¬å¥½å‡ ä¸ª pass DS_SpaceInitPass ä½œç”¨æ˜¯åˆå§‹åŒ–åˆ†å¸ƒå¼ç­–ç•¥çš„æœç´¢ç©ºé—´ã€‚å¯¹ groupOp ä¸­çš„æ¯ä¸€ä¸ªç®—å­ï¼Œå®ƒä¼šè°ƒç”¨ space_-\u0026gt;shardinglevel.init è¿™ä¸ªå‡½æ•°ä¼šæ ¹æ®ç®—å­è‡ªèº«çš„ç‰¹æ€§ã€å…¨å±€çº¦æŸ (å¦‚ max_sharding) ä»¥åŠç”¨æˆ·é…ç½® (å¦‚ opt_search) ï¼Œç”Ÿæˆè¯¥ç®—å­æ‰€æœ‰å¯èƒ½çš„åˆ‡åˆ†æ–¹å¼ã€‚\ninit å‡½æ•°é¦–å…ˆè·å–äº†ç®—å­çš„ç»´åº¦ dim å’Œç›®æ ‡åˆ‡åˆ†è·¯æ•° maxShardingï¼Œç„¶åè°ƒç”¨ getShardings æ‰¾å‡ºä¸€ä¸ªå¼ é‡åœ¨æ‰€æœ‰ç»´åº¦ä¸Šè¿›è¡Œæ•´æ•°å€åˆ‡åˆ†ã€ä¸”æ€»åˆ‡åˆ†è·¯æ•°æ°å¥½ç­‰äº maxSharding çš„æ‰€æœ‰ç»„åˆæ¥å¡«å…… shardings åˆ—è¡¨ã€‚éšåï¼Œå°†è¿™äº›ç»„åˆ (å¹¶é¢å¤–åŠ ä¸Šäº†ä¸åˆ‡åˆ†çš„æ–¹æ¡ˆ) åŒ…è£…æˆå¸¦æœ‰æ€§èƒ½è¯„ä¼°å› å­çš„ ShardingSpace å¯¹è±¡ï¼Œå¹¶å­˜å…¥ä¸€ä¸ªæœ‰åºé›†åˆ std::set\u0026lt;ShardingSpace\u0026gt; spaces ä¸­ã€‚ShardingSpace é‡è½½äº†å°äºæ“ä½œç¬¦ç”¨äºå¯¹åˆ‡åˆ†ç­–ç•¥æ’åºã€‚\nstruct ShardingSpace { std::list\u0026lt;ShardingInfo\u0026gt; shardings; // é¢„ä¼°çš„æ€§èƒ½å‚æ•°ï¼Œå³ç©ºé—´ä¸Šèƒ½ç”¨åˆ°pow(2,x)ä¸ªtile uint8_t factor[4]; // å…³é”®ç‚¹ï¼šé‡è½½å°äºæ“ä½œç¬¦ï¼Œå®šä¹‰æ’åºè§„åˆ™ bool operator\u0026lt;(const ShardingSpace \u0026amp;other) const { // æ€§èƒ½é«˜çš„åœ¨å‰é¢ return factor \u0026gt; other.factor; } bool operator==(const ShardingSpace \u0026amp;other) const { return factor == other.factor; } }; void ShardingLevel::init(mlir::Operation* op, int32_t maxSharding, bool nFirst, int32_t opt_search) { // ... æ¸…ç†å’Œå‡†å¤‡å·¥ä½œ ... // 1. è·å–ç®—å­è¾“å‡ºTensorçš„ç»´åº¦æ•°é‡ (Rank) int32_t dim = op-\u0026gt;getResult(0).getType().cast\u0026lt;ShapedType\u0026gt;().getRank(); // 2. å‡†å¤‡å®¹å™¨ std::vector\u0026lt;std::vector\u0026lt;int32_t\u0026gt;\u0026gt; shardings; // ç”¨äºæ¥æ”¶æ‰€æœ‰åˆæ³•çš„shardingæ–¹æ¡ˆ std::vector\u0026lt;int32_t\u0026gt; tempSharding(dim, 0); // ä¸€ä¸ªä¸´æ—¶çš„ã€å¤§å°ä¸ºdimçš„å‘é‡ï¼Œç”¨äºé€’å½’ // 3. è°ƒç”¨æ ¸å¿ƒé€’å½’å‡½æ•°ï¼Œå¯åŠ¨æœç´¢ // - curDim=0: ä»ç¬¬0ç»´å¼€å§‹æœç´¢ // - allDim=dim: æ€»å…±æœ‰dimä¸ªç»´åº¦ // - curSharded=1: å½“å‰å·²ç´¯ä¹˜çš„åˆ‡åˆ†ç³»æ•°ä¸º1 (ä¹˜æ³•å•ä½å…ƒ) // - maxSharding: æœ€å¤§åˆ‡åˆ†æ•°ç›®ï¼Œå³ä¸ºæ¯ä¸ª chip çš„ tile æ•°ç›® (16) getShardings(0, dim, 1, maxSharding, shardings, tempSharding); // 4. æ‰‹åŠ¨æ·»åŠ â€œä¸åˆ‡åˆ†â€çš„æ–¹æ¡ˆ // é€’å½’å‡½æ•°åªä¼šå¯»æ‰¾ä¹˜ç§¯ç­‰äºmaxShardingçš„ç»„åˆï¼Œä½†[1, 1, ..., 1] (ä¸åˆ‡åˆ†) // æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„åŸºç¡€æ–¹æ¡ˆï¼Œè¿™é‡Œæ‰‹åŠ¨æ·»åŠ è¿›å»ã€‚ shardings.push_back(std::vector\u0026lt;int32_t\u0026gt;(dim, 1)); // ... åç»­å¤„ç† ... for (auto sharding : shardings) { ShardingSpace newShardingSpace; if (isValid) { // 1. ä¸ºæ¯ä¸ªshardingæ–¹æ¡ˆè®¡ç®—æ€§èƒ½å› å­ newShardingSpace.factor = getFactor(op, sharding); } // ... (çœç•¥éƒ¨åˆ†é€»è¾‘) ... // 2. å°†åŒ…å«factorçš„ShardingSpaceå¯¹è±¡æ’å…¥setä¸­ spaces.insert(newShardingSpace); } } getShardings å‡½æ•°é‡‡ç”¨çš„æ˜¯é€’å½’ç®—æ³•ï¼Œç›®æ ‡æ˜¯æ‰¾åˆ°æ‰€æœ‰æ•´æ•°å‘é‡ s = {s_0, s_1, ..., s_{dim-1}}ï¼Œä½¿å¾— s_0 * s_1 * ... * s_{dim-1} == maxSharding.\nvoid ShardingLevel::getShardings(int32_t curDim, int32_t allDim, int32_t curSharded, int32_t maxSharding, std::vector\u0026lt;std::vector\u0026lt;int32_t\u0026gt;\u0026gt;\u0026amp; shardings, std::vector\u0026lt;int32_t\u0026gt;\u0026amp; sharding) { // 1. é€’å½’ç»ˆæ­¢æ¡ä»¶ (Base Case) if (curDim == allDim) { // å·²ç»å¤„ç†å®Œæ‰€æœ‰ç»´åº¦ if (curSharded == maxSharding) { // å¹¶ä¸”ç´¯ä¹˜ç»“æœæ­£å¥½ç­‰äºç›®æ ‡ // // succeeded shardings.emplace_back(sharding); // æ‰¾åˆ°äº†ä¸€ä¸ªåˆæ³•è§£ï¼Œå­˜å…¥ç»“æœåˆ—è¡¨ } return; // å›æº¯ } // 2. é€’å½’ä¸»ä½“ï¼šéå†å½“å‰ç»´åº¦çš„æ‰€æœ‰å¯èƒ½åˆ‡åˆ†ç³»æ•° for (int32_t i = 1; i \u0026lt;= maxSharding; ++i) { // å°è¯•å°†å½“å‰ç»´åº¦(curDim)çš„åˆ‡åˆ†ç³»æ•°è®¾ä¸º i sharding[curDim] = i; // æ›´æ–°å·²ç´¯ä¹˜çš„åˆ‡åˆ†ç³»æ•° curSharded *= i; // 3. å‰ªæä¼˜åŒ– (Pruning) ï¼šè¿™æ˜¯ç®—æ³•æ•ˆç‡çš„å…³é”®ï¼ // å¦‚æœå½“å‰ç´¯ä¹˜çš„ç»“æœå·²ç»è¶…è¿‡äº†ç›®æ ‡ï¼Œé‚£ä¹ˆæ— è®ºåç»­ç»´åº¦å¦‚ä½•å–å€¼ï¼Œ // æœ€ç»ˆç»“æœå¿…ç„¶å¤§äº maxShardingï¼Œæ‰€ä»¥æ²¡æœ‰å¿…è¦ç»§ç»­é€’å½’ä¸‹å»äº†ã€‚ if (curSharded \u0026lt;= maxSharding) { // å¦‚æœè¿˜æœ‰å¸Œæœ›ï¼Œåˆ™å¯¹ä¸‹ä¸€ä¸ªç»´åº¦è¿›è¡Œé€’å½’æœç´¢ getShardings(curDim + 1, allDim, curSharded, maxSharding, shardings, sharding); } // 4. å›æº¯ (Backtracking) // æ— è®ºä¸Šé¢çš„é€’å½’æ˜¯å¦æˆåŠŸï¼Œå½“å®ƒè¿”å›åï¼Œæˆ‘ä»¬éœ€è¦â€œæ’¤é”€â€å½“å‰çš„é€‰æ‹©ï¼Œ // ä»¥ä¾¿åœ¨ for å¾ªç¯çš„ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­å°è¯•æ–°çš„å€¼ã€‚ curSharded /= i; } } getFactor éå†æ¯ä¸ªç»´åº¦ï¼ŒåŸºäºå†…å­˜å¯¹é½ç­‰ç¡¬ä»¶é™åˆ¶ï¼Œè®¡ç®—å‡ºè¯¥ç»´åº¦ä¸Šæœ€å¤§åˆç†çš„åˆ‡åˆ†æ•°é‡ maxShardingDim. å°†ç”¨æˆ·æè®®çš„åˆ‡åˆ†æ•°é‡ sharding[i] ä¸ maxShardingDim å–æœ€å°å€¼ï¼Œå¾—åˆ°è¯¥ç»´åº¦ä¸Šçš„æœ‰æ•ˆåˆ‡åˆ†æ•°é‡ã€‚å°†æ‰€æœ‰ç»´åº¦ä¸Šçš„æœ‰æ•ˆåˆ‡åˆ†æ•°é‡ç›¸ä¹˜ï¼Œå¾—åˆ°æ€»çš„æœ‰æ•ˆå¹¶è¡Œåº¦ tileNum. å¯¹ tileNum å–ä»¥2ä¸ºåº•çš„å¯¹æ•°å¹¶å‘ä¸Šå–æ•´åè¿”å›ã€‚\nuint8_t ShadingLevel::getFactor(mlir::Operation* op, std::vector\u0026lt;uint32_t\u0026gt; sharding) { int tileNum = 1; for (int i=0; i\u0026lt;rank; ++i) { // a. åˆ¤æ–­æ˜¯å¦éœ€è¦å¯¹é½ï¼šè¿™é‡Œåªå¯¹æœ€åä¸€ä¸ªç»´åº¦ç‰¹æ®Šå¤„ç† bool align = i == rank - 1; // b. è·å–å¯¹é½åŸºæ•° (alignBase) // å¦‚æœéœ€è¦å¯¹é½ï¼Œåˆ™è°ƒç”¨ GetAlignBase è·å–ä¸€ä¸ªå¯¹é½å€¼ï¼Œå¦åˆ™ä¸º1 (ç›¸å½“äºä¸å¯¹é½) ã€‚ // è¿™ä¸ª alignBase å¾ˆå¯èƒ½ä»£è¡¨ç¡¬ä»¶ä¸€æ¬¡æœ€ä¼˜å¤„ç†çš„æœ€å°æ•°æ®å—å¤§å°ã€‚ uint32_t alignBase = align ? GetAlignBase(shape[i], dtype) : 1; // c. è®¡ç®—å½“å‰ç»´åº¦çš„æœ€å¤§åˆç†åˆ‡åˆ†è·¯æ•° (maxShardingDim) // ä¸€ä¸ªç»´åº¦èƒ½è¢«åˆ‡æˆå¤šå°‘ä»½ï¼Œä¸ä»…å–å†³äºå®ƒçš„æ€»å¤§å°ï¼Œè¿˜å–å†³äºå¯¹é½è¦æ±‚ã€‚ // ä¾‹å¦‚ï¼Œä¸€ä¸ªç»´åº¦å¤§å°ä¸º100ï¼Œä½†ç¡¬ä»¶è¦æ±‚å¿…é¡»æŒ‰16å¯¹é½å¤„ç†ï¼Œé‚£ä¹ˆæœ€å¤šåªèƒ½åˆ‡æˆ ceil(100/16) = 7 ä»½ã€‚ auto maxShardingDim = CEIL(shape[i], alignBase); // d. è®¡ç®—â€œæœ‰æ•ˆâ€çš„åˆ‡åˆ†è·¯æ•°å¹¶ç´¯ä¹˜ // è¿™æ˜¯å…³é”®ï¼å®ƒåœ¨â€œæè®®çš„åˆ‡åˆ†è·¯æ•°(sharding[i])â€å’Œâ€œæœ€å¤§åˆç†åˆ‡åˆ†è·¯æ•°(maxShardingDim)â€ä¹‹é—´å–æœ€å°å€¼ã€‚ // è¿™æ„å‘³ç€ï¼Œå³ä½¿ä½ æè®®å°†ä¸€ä¸ªç»´åº¦åˆ‡16ä»½ï¼Œä½†å¦‚æœç¡¬ä»¶é™åˆ¶æœ€å¤šåªèƒ½åˆ‡7ä»½ï¼Œé‚£ä¹Ÿåªèƒ½ç®—7ä»½çš„è´¡çŒ®ã€‚ // è¿™å¯ä»¥é˜²æ­¢å¯¹ä¸€ä¸ªç»´åº¦è¿›è¡Œâ€œæ— æ•ˆçš„è¿‡åº¦åˆ‡åˆ†â€ã€‚ tileNum *= MIN(maxShardingDim, sharding[i]); return static_cast\u0026lt;uint8_t\u0026gt;(std::ceil(log2(tileNum))); // å‘ä¸Šå–æ•´ } } ä¸€ä¸ªä¾‹å­å¦‚ä¸‹\nstoreOp outShape[3, 4, 128, 4096] level0: [1, 1, 1, 16], [1, 1, 2, 8], [1, 1, 4, 4]... factor=16 level1:[1, 8, 1, 2], [1, 8, 2, 1].... factor=8 level2:[1, 16, 1, 1] factor=4 level3:[16, 1, 1, 1] factor=2 DS_TileShardingPass æŒ‰é¡ºåºéå† groupOp ä¸­çš„ç®—å­ï¼Œå¹¶åƒä¸€ä¸ªçŠ¶æ€æœºä¸€æ ·æ£€æŸ¥å’Œæ›´æ–°å„ç®—å­çš„åˆ†å¸ƒå¼ç­–ç•¥çŠ¶æ€ã€‚å…¶åœ¨æ¯æ¬¡æ‰§è¡Œæ—¶ï¼Œä»…ä¸ºå½“å‰çš„å¾…å®šç®—å­ï¼Œä»å…¶é¢„å…ˆç”Ÿæˆå¹¶æ’å¥½åºçš„å€™é€‰ç­–ç•¥åˆ—è¡¨ä¸­ï¼Œé€‰å‡ºä¸‹ä¸€ä¸ªæœ€ä¼˜çš„åˆ‡åˆ†æ–¹æ¡ˆå¹¶è¿›è¡Œæ›´æ–°ï¼Œç„¶åç«‹å³ç»ˆæ­¢å½“æ¬¡è¿è¡Œã€‚æ•´ä¸ªå›¾çš„æœ€ç»ˆåˆ‡åˆ†æ–¹æ¡ˆæ˜¯é€šè¿‡åå¤æ‰§è¡Œæ­¤ Passï¼Œå°†å†³ç­–ä»å›¾çš„å…¥å£é€æ­¥ä¼ æ’­åˆ°å‡ºå£è€Œæœ€ç»ˆç¡®å®šçš„ã€‚\nAn Example of Sharding\nDS_TileSplitPass é¦–å…ˆæ£€æŸ¥ç®—å­æ˜¯å¦éœ€è¦ reduceSplit (ä¾‹å¦‚ GeMM åˆ‡åˆ† k ç»´åº¦). å¦‚æœ reduce ç»´åº¦åˆ‡åˆ†çŠ¶æ€ä¸º s.srfinish = true æ‰ä¼šè¿›è¡Œåç»­çš„ split æ–¹æ¡ˆã€‚\nä»åå‘å‰ (æˆ–æ ¹æ® nFirst æ ‡å¿—å†³å®šæ–¹å‘) æ£€æŸ¥ç®—å­çš„å„ä¸ªç»´åº¦ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªâ€œè¿˜å¯ä»¥å†åˆ‡åˆ†â€çš„ç»´åº¦ã€‚åˆ¤æ–­ä¾æ®æ˜¯è¯¥ç»´åº¦åˆ‡åˆ†åçš„å¤§å°æ˜¯å¦å·²è¾¾åˆ°ç³»ç»Ÿè®¾å®šçš„æœ€å°å€¼ (s.sliceShapeMin) . ä¸€æ—¦æ‰¾åˆ°ç›®æ ‡ç»´åº¦ updateDimï¼Œå®ƒä¼šè°ƒç”¨ä¸€ä¸ªåä¸º getNextSplit çš„å‡½æ•°ã€‚å®ƒä¼šæ ¹æ®å½“å‰ç»´åº¦çš„åˆ‡åˆ†å€¼ s.splitTry[updateDim] è®¡ç®—å‡ºä¸‹ä¸€ä¸ªå¯èƒ½çš„åˆ‡åˆ†å€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå½“å‰æ˜¯ 2ï¼ŒgetNextSplit å¯èƒ½ä¼šè¿”å› 4. æ›´æ–°ä¸è®°å½•ï¼šå®ƒå°†è¿™ä¸ªæ–°çš„åˆ‡åˆ†å€¼æ›´æ–°åˆ°å°è¯•æ€§æ–¹æ¡ˆ s.splitTry ä¸­ï¼Œå¹¶è®°å½•ä¸‹è¿™æ¬¡æ›´æ–°space_-\u0026gt;splitRecord.update(...). åœ¨å¯¹å½“å‰ç®—å­çš„å¾ªç¯ç»“æŸæ—¶ï¼Œå®ƒä¼šå°†æ¢ç´¢å‡ºçš„ s.splitTry èµ‹å€¼ç»™æœ€ç»ˆæ–¹æ¡ˆ s.split. An Example of Split try of above Sharding\nDS_SlicePropagatePass ååºéå† (å³ä» groupOp çš„è¾“å‡ºåˆ°è¾“å…¥) çš„æ–¹å¼åå‘ä¼ æ’­åˆ‡åˆ†å†³ç­–ï¼Œå…¶é€»è¾‘æ˜¯ï¼šå¯¹äºæ¯ä¸€ä¸ªç®—å­ (æ¶ˆè´¹è€…)ï¼Œå®ƒä¼šè°ƒç”¨è¯¥ç®—å­å®ç°çš„ ShardingInterface æ¥å£ä¸­çš„ tileShardingSplit æ–¹æ³•ï¼Œæ¥ç²¾ç¡®è®¡ç®—å‡ºå…¶ä¸Šæ¸¸ç®—å­ (ç”Ÿäº§è€…) åº”è¯¥å¦‚ä½•åˆ‡åˆ†æ•°æ®ä»¥æ»¡è¶³æ¶ˆè´¹è€…çš„éœ€æ±‚ã€‚è¿™å¦‚æœè‡ªåŠ¨æ¥å£æ¨å¯¼å¤±è´¥ï¼Œå®ƒä¼šå›é€€å»è¯»å–ç®—å­ä¸Šé¢„è®¾çš„ tile_parallel å±æ€§ä½œä¸ºäººå·¥æŒ‡ä»¤ã€‚\nAn Example of Propagation\nDS_UpdateSliceIRPass æ ¸å¿ƒç­–ç•¥æ˜¯é€šè¿‡åˆ†æå›¾ä¸­ reduceOp æ¥åå‘æ¨æ–­å’Œåˆ’åˆ†æµæ°´çº¿é˜¶æ®µã€‚é€šè¿‡æ£€æŸ¥æ¯ä¸ª reduceOp è‡ªèº«çš„å¹¶è¡Œå¤æ‚åº¦ (ä¾‹å¦‚ï¼ŒtpSplit \u0026gt; 1) æ¥åˆ¤æ–­å…¶ä¸Šæ¸¸çš„è®¡ç®—ç±»å‹ï¼Œä»è€Œä¸ºä¸åŒçš„æµæ°´çº¿æ‰“ä¸Šè¯¸å¦‚ STAGEIC2OC (æ¨¡å‹å¹¶è¡Œè§„çº¦æ®µ) æˆ– STAGEOC2NH (æ¨¡å¼åˆ‡æ¢æ®µ) çš„æ ‡ç­¾ã€‚åœ¨å®Œæˆå¯¹æ‰€æœ‰ç®—å­çš„é˜¶æ®µåˆ’åˆ†åï¼Œå®ƒä¼šæœ€ç»ˆè®¡ç®—æ¯ä¸ªé˜¶æ®µçš„æµæ°´çº¿æ·±åº¦ï¼Œå¹¶æ•´ç†è¾“å‡ºä¸€ä»½åŒ…å«å¹¶è¡Œå¾ªç¯ç±»å‹ã€ç®—å­åˆ†ç»„å’Œæµæ°´çº¿é˜¶æ®µä¿¡æ¯çš„å®Œæ•´æ‰§è¡Œã€‚\né¦–å…ˆä» reduceOps æ ˆä¸­å–å‡ºä¸€ä¸ªå…³å¡ç®—å­ã€‚ç„¶åï¼Œå®ƒåˆ©ç”¨ getNEOPTPSlice ç­‰è¾…åŠ©å‡½æ•°ï¼Œåˆ†æè¿™ä¸ªç®—å­è‡ªèº«çš„åˆ‡åˆ†ç­–ç•¥ï¼Œåˆ¤æ–­å®ƒå…·ä½“é‡‡ç”¨äº†å“ªç§å¼ é‡å¹¶è¡Œæ–¹å¼ã€‚\nç¡®å®šè¿æ¥åˆ°å½“å‰è¿™ä¸ª reduceOp çš„ä¸Šä¸€æ®µæµæ°´çº¿æ˜¯ä»€ä¹ˆç±»å‹\nif (tpSplit \u0026gt; 1): å¦‚æœè¿™ä¸ªå…³å¡ç®—å­æœ¬èº«æ˜¯ä¸€ä¸ªå¼ é‡å¹¶è¡Œåº¦å¤§äº 1 çš„ç®—å­ï¼Œä»£ç å°±åˆ¤æ–­å‡ºï¼šé€šå¾€è¿™ä¸ªç®—å­çš„è·¯å¾„ï¼Œæ˜¯ä¸€æ®µéœ€è¦æœ€ç»ˆè¿›è¡Œé›†åˆé€šä¿¡ (C) çš„è·¯å¾„ã€‚å› æ­¤ï¼Œå®ƒå°†è¿™æ®µè·¯å¾„çš„ç±»å‹æ ‡è®°ä¸º STAGEIC2OC. else if (s.reduceSplit \u0026gt; 1)ï¼šå¦‚æœä¸æ˜¯ä¸Šé¢é‚£ç§æƒ…å†µï¼Œä»£ç ä¼šæ£€æŸ¥å¦ä¸€ç§æ¨¡å‹å¹¶è¡Œæ¨¡å¼ã€‚å¦‚æœä¸€ä¸ªç®—å­çš„è§„çº¦ç»´åº¦è¢«åˆ‡åˆ†äº†ï¼ŒåŒæ ·æ„å‘³ç€åç»­éœ€è¦ä¸€ä¸ª AllReduce é›†åˆé€šä¿¡ã€‚å› æ­¤ï¼Œå®ƒæŠŠè¿™æ®µè·¯å¾„æ ‡è®°ä¸º STAGEIC2IC. å¦‚æœä¸¤ä¸ªæ¡ä»¶éƒ½ä¸æ»¡è¶³ï¼Œæ„å‘³ç€è¿™å¯èƒ½æ˜¯ä¸€ä¸ªä¸åŒå¹¶è¡Œæ¨¡å¼ä¹‹é—´çš„åˆ‡æ¢ï¼Œä¾‹å¦‚ä»æ¨¡å‹å¹¶è¡Œåˆ‡æ¢å›æ•°æ®å¹¶è¡Œï¼Œæ­¤æ—¶ä¼šä½¿ç”¨é»˜è®¤çš„ STAGEOC2NH æ ‡è®°. é€šè¿‡ updateLoopStage å‡½æ•°ï¼Œå°†ä¸¤ä¸ª reduceOp ç®—å­ä¹‹é—´çš„æ‰€æœ‰æ™®é€šç®—å­ï¼Œéƒ½å½’ç±»åˆ°åˆšåˆšåœ¨ç¬¬ 2 æ­¥ä¸­å†³ç­–å‡ºçš„ lastRuduceLoopStage. å¤„ç†å®Œæ‰€æœ‰çš„ reduceOp åéå†æ‰€æœ‰ç®—å­ï¼Œæ ¹æ® LoopStageMap_ ä¸­çš„è®°å½•ï¼Œå°†ç®—å­æ”¾å…¥å¯¹åº”çš„â€œç¯®å­â€é‡Œã€‚ DS_UpdateSliceIRPass\nTS_SwPipelinePass TS_SwPipelinePass æ ¸å¿ƒæ˜¯è°ƒç”¨ getPipeline å‡½æ•°ã€‚å…¶å†…éƒ¨é€šè¿‡é¡ºåºæ‰§è¡Œä»¥ä¸‹ä¸‰ä¸ªå…³é”®æ­¥éª¤ï¼Œã€‚\ngetInitPipelineOps\nä¸ºæ¯ä¸ªæµæ°´çº¿é˜¶æ®µ (å¦‚ STAGENH2OC, STAGEOC2ICç­‰) åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ pipeline åˆ—è¡¨ã€‚ æŒ‰ IC -\u0026gt; OC -\u0026gt; NH é¡ºåºæ¥æ‹¼æ¥è¿™äº›åˆ—è¡¨ã€‚åœ¨æ‹¼æ¥æ—¶ï¼Œå®ƒä¼šæ£€æŸ¥æ¯ä¸ªé˜¶æ®µçš„å¾ªç¯æ¬¡æ•°ã€‚å¦‚æœå¾ªç¯æ¬¡æ•°å¤§äº1ï¼šå®ƒå¹¶ä¸ä¼šç®€å•åœ°å°†æ“ä½œåˆ—è¡¨å¤åˆ¶å¤šæ¬¡ï¼Œè€Œæ˜¯åˆ›å»ºä¸€ä¸ªç‰¹æ®Šçš„ã€ç±»å‹ä¸º PipelineOpsBase çš„ Repeat èŠ‚ç‚¹ã€‚è¿™ä¸ªèŠ‚ç‚¹å†…éƒ¨åŒ…å«éœ€è¦é‡å¤çš„å­æµæ°´çº¿ (repeatBase.repeat) å’Œé‡å¤æ¬¡æ•° (repeatBase.repeatTimes) . ç„¶åï¼Œå®ƒå°†è¿™ä¸ªRepeat èŠ‚ç‚¹ä½œä¸ºä¸€ä¸ªå•ä¸€çš„ã€åŸå­æ€§çš„å…ƒç´ ï¼Œæ’å…¥åˆ°ä¸‹ä¸€ä¸ªé˜¶æ®µçš„æµæ°´çº¿ä¸­ã€‚è¿™æ˜¯ä¸€ç§é«˜æ•ˆè¡¨ç¤ºåµŒå¥—å¾ªç¯çš„æ–¹æ³•ã€‚ å¦‚æœå¾ªç¯æ¬¡æ•°ä¸ä¸º 1ï¼šå®ƒå°±ç›´æ¥ä½¿ç”¨ splice æ“ä½œï¼Œå°†å½“å‰é˜¶æ®µçš„ç®—å­åˆ—è¡¨å®Œæ•´åœ°ç§»åŠ¨å¹¶æ‹¼æ¥åˆ°ä¸‹ä¸€ä¸ªé˜¶æ®µçš„å°¾éƒ¨ã€‚ ç»è¿‡å±‚å±‚æ‹¼æ¥å’ŒåµŒå¥—ï¼Œè¯¥å‡½æ•°æœ€ç»ˆè¿”å›ä¸€ä¸ªåä¸º groupPipeline çš„ std::listã€‚è¿™ä¸ªåˆ—è¡¨å°±æ˜¯ä¸€ä»½å®Œæ•´çš„ã€çº¿æ€§çš„é€»è¾‘æ‰§è¡Œå‰§æœ¬ï¼Œå…¶ä¸­æ‰€æœ‰çš„åµŒå¥—å¾ªç¯éƒ½è¢«æŠ½è±¡æˆäº† Repeat èŠ‚ç‚¹ã€‚\ngetInitPipelineOps\npipeline ä¸»è¦å·¥ä½œæ˜¯å¤„ç†ä¸Šä¸€é˜¶æ®µç”Ÿæˆçš„ Repeat èŠ‚ç‚¹ï¼Œå¹¶å¯¹æµæ°´çº¿çš„è¡”æ¥å¤„è¿›è¡Œæ·±åº¦ä¼˜åŒ–ï¼Œä»¥å‡å°‘æ°”æ³¡ (ç¡¬ä»¶ç©ºé—²å‘¨æœŸ) ã€‚\nå½“å®ƒåœ¨æµæ°´çº¿ä¸­é‡åˆ°ä¸€ä¸ª Repeat èŠ‚ç‚¹æ—¶ï¼Œå®ƒä¼šå¯¹è¯¥èŠ‚ç‚¹å†…éƒ¨çš„å­æµæ°´çº¿å†æ¬¡è°ƒç”¨pipelineå‡½æ•° (auto inner = pipeline((it).repeat, ...)). é€šè¿‡è¿™ç§æ–¹å¼å±•å¼€ä»»æ„å±‚çº§çš„åµŒå¥—å¾ªç¯ã€‚\nåœ¨å¤„ç†å¾ªç¯çš„è¾¹ç•Œæ—¶ï¼Œå®ƒè°ƒç”¨ getRetract å’Œ doRetract è¿™å¯¹å¤æ‚çš„ä¼˜åŒ–å·¥å…·ã€‚\ngetRetract: åœ¨è¿æ¥ä¸¤ä¸ªå¾ªç¯è¿­ä»£ (æˆ–ä¸åŒçš„æµæ°´çº¿æ®µ) æ—¶ï¼Œé€šè¿‡ canParallel å‡½æ•°æ£€æŸ¥åä¸€ä¸ªè¿­ä»£çš„â€œå¤´éƒ¨æŒ‡ä»¤â€æ˜¯å¦å¯ä»¥å’Œå‰ä¸€ä¸ªè¿­ä»£çš„â€œå°¾éƒ¨æŒ‡ä»¤â€å¹¶è¡Œæ‰§è¡Œï¼Œä»è€Œè®¡ç®—å‡ºæœ€å¤§å¯ä»¥â€œå›ç¼©â€ (å³æå‰æ‰§è¡Œ) çš„æŒ‡ä»¤æ•°é‡ã€‚ doRetract: åœ¨ getRetract æ¢æ˜äº†å¯å›ç¼©çš„æ•°é‡åï¼ŒdoRetract è´Ÿè´£ç‰©ç†åœ°ä¿®æ”¹æµæ°´çº¿ã€‚å®ƒé€šè¿‡ splice æ“ä½œï¼Œå°†åä¸€ä¸ªè¿­ä»£å¤´éƒ¨çš„æŒ‡ä»¤ï¼Œåˆå¹¶åˆ°å‰ä¸€ä¸ªè¿­ä»£å°¾éƒ¨çš„æŒ‡ä»¤åˆ—è¡¨ä¸­ï¼Œä»è€Œå¡«è¡¥äº†æ½œåœ¨çš„æ‰§è¡Œç©ºéš™ã€‚ getEnginsPipeline å°†ä¼˜åŒ–åçš„æ“ä½œåºåˆ—ï¼Œç¿»è¯‘æˆå…·ä½“çš„ã€åˆ†é…åˆ°ä¸åŒç¡¬ä»¶å¼•æ“çš„æŒ‡ä»¤ã€‚\nå‡½æ•°éå†è¾“å…¥çš„ pipelineOps åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´  opsBase ä»£è¡¨ä¸€ä¸ªæµæ°´çº¿å‘¨æœŸ (ä¸€â€œå¸§â€) å†…éœ€è¦å…±åŒæ‰§è¡Œçš„ä¸€ç»„MLIRæ“ä½œã€‚\nå¯¹äºæ¯ä¸ªå‘¨æœŸï¼Œå®ƒåˆ›å»ºä¸€ä¸ª enginsBase å¯¹è±¡ã€‚è¿™ä¸ªå¯¹è±¡æ˜¯ä¸€ä¸ªç»“æ„ä½“ï¼ŒåŒ…å«äº†åˆ†åˆ«å¯¹åº”ä¸åŒç¡¬ä»¶å¼•æ“ (å¦‚ ld for Load, st for Store, ne for Neural Engine, tdma for DMA) çš„æˆå‘˜å˜é‡ã€‚\néå†å½“å‰å‘¨æœŸçš„æ‰€æœ‰ opï¼Œé€šè¿‡æŸ¥è¯¢æ¯ä¸ª op çš„ engine å±æ€§ queryOpAttr().engineï¼Œå¾—çŸ¥è¿™ä¸ªæ“ä½œé¢„å®šç”±å“ªä¸ªç¡¬ä»¶å¼•æ“æ¥æ‰§è¡Œã€‚æ¥ç€ï¼Œå®ƒå°†è¿™ä¸ª op çš„æŒ‡é’ˆå­˜æ”¾åˆ° enginsBase å¯¹è±¡ä¸­å¯¹åº”çš„å¼•æ“ slot é‡Œã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ª NPU_ENGINE_LOAD ç±»å‹çš„æ“ä½œä¼šè¢«æ”¾å…¥ enginsBase.ld åˆ—è¡¨ã€‚\nå‡½æ•°æœ€ç»ˆè¿”å›ä¸€ä¸ª std::list\u0026lt;PipelineBase\u0026gt; æè¿°äº†åœ¨åŒä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå†…ï¼ŒåŠ è½½ã€å­˜å‚¨ã€è®¡ç®—ç­‰å¤šä¸ªç¡¬ä»¶å•å…ƒåº”è¯¥åŒæ—¶æ‰§è¡Œ**å“ªäº›ä¸åŒçš„æ“ä½œã€‚\nSPMAllocPass SPMAllocPass åŒ…æ‹¬ä¸‰ä¸ª passï¼Œä¸‹é¢ä¾æ¬¡ä»‹ç»ï¼Œé¦–å…ˆä»‹ç»ç”¨åˆ°çš„æ•°æ®ç»“æ„\nBufferLabel ä½œä¸ºç¼“å†²åŒºçš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå°†å…¶é“¾æ¥åˆ°ç¨‹åºä¸­çš„ç‰¹å®š mlir::Value ï¼Œå¹¶æ³¨æ„å®ƒæ˜¯å¦ä¸º Imm.\n/** * @struct BufferLabel * @brief A unique identifier for a memory buffer. * * This struct links a buffer to a specific MLIR Value and tracks whether it\u0026#39;s * a special \u0026#34;immediate\u0026#34; buffer. It\u0026#39;s used as a key in maps to associate * MLIR Values with their buffer metadata. */ struct BufferLabel { // The MLIR Value that this buffer represents, typically a tensor produced // by an operation. mlir::Value v; // A flag indicating if this buffer holds a special \u0026#34;immediate\u0026#34; value. // Immediate values might be treated differently during allocation (e.g., // small constants or internal scratchpads for an op). bool isImm{false}; /** * @brief Equality operator to compare two labels. * * Two labels are considered equal if they refer to the same MLIR Value * and have the same \u0026#39;isImm\u0026#39; status. This is necessary for using * BufferLabel as a key in std::map or std::unordered_map. */ bool operator==(const BufferLabel\u0026amp; other) const { return (v == other.v) \u0026amp;\u0026amp; (isImm == other.isImm); } }; ValueBuffer åŒ…å«å•ä¸ªç¼“å†²åŒºæ‰€éœ€çš„æ‰€æœ‰å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬å…¶æ ‡è¯†ã€ç”Ÿå­˜æœŸã€å¤§å°å’Œæœ€ç»ˆå†…å­˜ä½ç½®ã€‚\n/** * @struct ValueBuffer * @brief Represents the metadata for a single memory buffer, including its * lifetime, size, and allocation information. */ struct ValueBuffer { // The unique identifier for this buffer. BufferLabel label; // Represents the starting point of the buffer\u0026#39;s lifetime (inclusive), // measured in pipeline cycles. After memory allocation, this field may be // repurposed to store the starting memory address. int64_t start; // Represents the ending point of the buffer\u0026#39;s lifetime (inclusive), // measured in pipeline cycles. After memory allocation, this field may be // repurposed to store the ending memory address. int64_t end; // The total size of this buffer in bytes, as required by its tensor shape. int64_t allSize{0}; // Size of an intermediate/temporary buffer that an operator might need // internally. This is often allocated contiguously with the main output // buffer. For example, the final output address would be \u0026#39;offset + immSize\u0026#39;. int64_t immSize{0}; // The final memory offset assigned to this buffer in the scratchpad memory. // This value is determined by the final memory allocation pass. int64_t offset{0}; /** * @brief Less-than operator, used for sorting ValueBuffer objects. * * The active implementation sorts buffers primarily by their lifetime start * time. This is a common strategy for greedy \u0026#34;first fit\u0026#34; style memory * allocation algorithms. The commented-out code shows an alternative * strategy of sorting by buffer size. */ bool operator\u0026lt;(const ValueBuffer\u0026amp; other) const { // return this-\u0026gt;allSize \u0026lt; other.allSize; // Alternative sorting by size return this-\u0026gt;start \u0026lt;= other.start; } }; SA_BufferLifePassçš„æ ¸å¿ƒåŠŸèƒ½æ˜¯åˆ†æå¹¶ç¡®å®šæ¯ä¸€ä¸ªéœ€è¦å­˜æ”¾åœ¨ ScratchPad Memory ä¸­çš„æ•°æ®å— (Bufferï¼Œå³mlir::Valueå¯¹åº”çš„å¼ é‡) çš„ç”Ÿå‘½å‘¨æœŸã€‚\næ„å»ºâ€œå®šä¹‰-ä½¿ç”¨â€æ—¶é—´è¡¨ã€‚Pass çš„è¾“å…¥æ˜¯ TS_SwPipelinePass ç”Ÿæˆçš„æœ€ç»ˆæµæ°´çº¿æ‰§è¡Œåºåˆ— pipelineReal. è¿™ä¸ªåºåˆ—çš„æ¯ä¸€é¡¹éƒ½ä»£è¡¨ä¸€ä¸ªæµæ°´çº¿å‘¨æœŸï¼Œä»¥åŠè¯¥å‘¨æœŸå†…å„ä¸ªç¡¬ä»¶å¼•æ“æ‰§è¡Œçš„æ“ä½œã€‚ä»£ç éå†è¿™ä¸ªæµæ°´çº¿åºåˆ—ï¼Œé€ä¸ªå‘¨æœŸ (ç”±timeStepNumè®¡æ•°) åœ°åˆ†æã€‚å®ƒä¼šæ„å»ºä¸¤ä¸ªæ ¸å¿ƒçš„æ˜ å°„è¡¨ï¼š opIsTemp: è®°å½•åœ¨å“ªä¸€ä¸ªæ—¶é—´æ­¥ (timeStepNum) ï¼Œæœ‰å“ªäº›å€¼ (mlir::Value) è¢«å®šä¹‰æˆ–äº§å‡ºã€‚ä¾‹å¦‚ï¼Œld (åŠ è½½) å’Œ ne (è®¡ç®—) æ“ä½œçš„è¾“å‡ºéƒ½ä¼šè¢«è®°å½•ã€‚ consumerOps: è®°å½•åœ¨å“ªä¸€ä¸ªæ—¶é—´æ­¥ï¼Œæœ‰å“ªäº›å€¼è¢«ä½œä¸ºè¾“å…¥æ¶ˆè´¹æ‰äº†ã€‚ äº§å‡ºï¼šè¿™ä¸ªæ­¥éª¤å®Œæˆåï¼ŒPasså°±æ‹¥æœ‰äº†ä¸€ä»½å®Œæ•´çš„ã€æŒ‰æ—¶é—´æ­¥ç´¢å¼•çš„â€œè°åœ¨ä½•æ—¶è¢«åˆ›å»ºâ€å’Œâ€œè°åœ¨ä½•æ—¶è¢«ä½¿ç”¨â€çš„æ¸…å•ã€‚\nç¡®å®šæ¯ä¸ªBufferçš„ç”Ÿå‘½å‘¨æœŸã€‚Passä¼šéå†æ‰€æœ‰ç®—å­å’Œå®ƒä»¬çš„è¾“å…¥ (operands) ï¼Œä¸ºæ¯ä¸€ä¸ªä½œä¸ºè¾“å…¥çš„ Value (å³inValue) è®¡ç®—å…¶ç”Ÿå‘½å‘¨æœŸã€‚ ç¡®å®šç”Ÿå‘½å‘¨æœŸç»ˆç‚¹ (end)ï¼šä¸€ä¸ª Value çš„ç”Ÿå‘½å‘¨æœŸï¼Œåœ¨å…¶è¢«ä½œä¸ºè¾“å…¥ (è¢«æ¶ˆè´¹) æ—¶è¾¾åˆ°ä¸€ä¸ªç»ˆç‚¹ã€‚å› æ­¤ï¼Œå½“ä»£ç åœ¨æ—¶é—´æ­¥ curTs å¤„ç†ä¸€ä¸ªæ¶ˆè´¹è€…ç®—å­æ—¶ï¼Œå…¶è¾“å…¥ inValue çš„ buf.end å°±è¢«è®¾ç½®ä¸º curTs. ç¡®å®šç”Ÿå‘½å‘¨æœŸèµ·ç‚¹ (start)ï¼šä¸ºäº†æ‰¾åˆ°inValueä½•æ—¶è¢«åˆ›å»ºï¼Œä»£ç ä¼šè°ƒç”¨ä¸€ä¸ª getNearestProducer çš„å‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°ä¼šæ‹¿ç€å½“å‰çš„æ¶ˆè´¹æ—¶é—´ curTs å’Œ inValueï¼Œå»ç¬¬ä¸€æ­¥ç”Ÿæˆçš„ opIsTemp (å®šä¹‰æ—¶é—´è¡¨) ä¸­åå‘æŸ¥æ‰¾ï¼Œæ‰¾åˆ°ç¦» curTs æœ€è¿‘çš„ã€inValue è¢«å®šä¹‰çš„é‚£ä¸ªæ—¶é—´æ­¥ buf.start. è®¡ç®—å‡ºçš„ start å’Œ endï¼Œè¿åŒ Value çš„æ ‡è¯† (BufferLabel) ï¼Œè¢«å°è£…åœ¨ ValueBuffer ç»“æ„ä½“ä¸­ï¼Œå¹¶å­˜å…¥ä¸€ä¸ªå…¨å±€çš„æ•°æ®ç»“æ„ space_-\u0026gt;vBuffer é‡Œã€‚\nç‰¹æ®Šæƒ…å†µå¤„ç† In-place: å¯¹äºè¾“å…¥å’Œè¾“å‡ºå¤ç”¨åŒä¸€å—å†…å­˜çš„ in-place æ“ä½œï¼Œå…¶ç”Ÿå‘½å‘¨æœŸè®¡ç®—å¿…é¡»è¿½æº¯åˆ°æœ€åˆæä¾›è¿™å—å†…å­˜çš„é‚£ä¸ªéin-placeç®—å­ã€‚ä»£ç é€šè¿‡ getInplaceIndex é€’å½’åœ°å›æº¯in-placeé“¾ï¼Œä»¥ç¡®ä¿ç”Ÿå‘½å‘¨æœŸçš„ start æ—¶é—´æ˜¯æ­£ç¡®çš„ã€æœ€å¼€å§‹çš„é‚£ä¸ªå®šä¹‰æ—¶é—´ã€‚ ä¸­é—´å€¼ (imm) ä¸ç´¯åŠ å€¼ (Psum): ä»£ç ä¼šè¯†åˆ«ä¸€äº›ç‰¹æ®Šçš„ã€å¯èƒ½åœ¨å¤šä¸ªæ—¶é—´æ­¥ä¸­å­˜åœ¨çš„ä¸­é—´å€¼æˆ–ç´¯åŠ å€¼ (ç”±getImmSize æˆ– isPsumValue è¯†åˆ«) . å¯¹äºè¿™äº›å€¼ï¼Œå®ƒä»¬å¯èƒ½ä¼šæœ‰å¤šä¸ªç¦»æ•£çš„ç”Ÿå­˜åŒºé—´ã€‚Pass ä¸­å¯èƒ½åŒ…å«ä¸€äº›åå¤„ç†é€»è¾‘ï¼Œå°†è¿™äº›ç¦»æ•£çš„åŒºé—´åˆå¹¶æˆä¸€ä¸ªä»â€œæœ€æ—©çš„startâ€åˆ°â€œæœ€æ™šçš„endâ€çš„è¿ç»­å¤§åŒºé—´ï¼Œä»¥ç®€åŒ–åç»­çš„å†…å­˜åˆ†é…ã€‚ SA_BufferMergePass çš„ä»»åŠ¡å°±æ˜¯æ¸…ç†è¿™äº›å†—ä½™æˆ–å¤æ‚çš„ç”Ÿå‘½å‘¨æœŸè®°å½•ï¼Œå…·ä½“æ¥è¯´ï¼Œå°±æ˜¯åˆå¹¶é‚£äº›å­˜åœ¨æ—¶é—´ä¸Šé‡å æˆ–åŒ…å«å…³ç³»çš„ç”Ÿå‘½å‘¨æœŸåŒºé—´ï¼Œä¸ºåç»­çš„å†…å­˜åˆ†é…å™¨æä¾›ä¸€ä¸ªæœ€ç°¡æ´ã€æ— å†—ä½™çš„åŒºé—´åˆ—è¡¨ã€‚\néå†ç”±ä¸Šä¸€ä¸ª Pass ç”Ÿæˆçš„ space_-\u0026gt;vBuffer è¿™ä¸ªmap. å…¶ä¸­çš„æ¯ä¸€é¡¹ï¼Œkey æ˜¯ç¼“å†²åŒºçš„å”¯ä¸€æ ‡è¯† BufferLabelï¼Œvalueæ˜¯è¯¥ç¼“å†²åŒºæ‰€æœ‰ç”Ÿå‘½å‘¨æœŸåŒºé—´çš„åˆ—è¡¨ std::vector\u0026lt;ValueBuffer\u0026gt;. å¯¹äºæ¯ä¸€ä¸ªvalueçš„ç”Ÿå‘½å‘¨æœŸåˆ—è¡¨ï¼Œå®ƒéƒ½è°ƒç”¨ mergeOverlap æ¥è¿›è¡Œå¤„ç†ã€‚æœ€åï¼Œå®ƒç”¨å‡½æ•°è¿”å›çš„ã€ç»è¿‡æ¸…ç†å’Œåˆå¹¶çš„æ–°çš„åˆ—è¡¨ï¼Œæ¥æ›¿æ¢æ‰ map ä¸­æ—§çš„åˆ—è¡¨ã€‚è¯¥å‡½æ•°æµç¨‹å¦‚ä¸‹\næ ¹æ® ValueBuffer é‡è½½çš„ operator\u0026lt; (å³æŒ‰ start æ—¶é—´å‡åº) ï¼Œå°†æ‰€æœ‰ç”Ÿå‘½å‘¨æœŸåŒºé—´è¿›è¡Œæ’åºã€‚ éå†å·²æ’åºçš„åˆ—è¡¨ï¼Œå°† start æ—¶é—´ç›¸åŒçš„è¿ç»­åŒºé—´æ”¶é›†åˆ°ä¸€ä¸ªä¸´æ—¶çš„ buf å‘é‡ä¸­ã€‚é‡åˆ°ä¸€ä¸ªä¸åŒ start æ—¶é—´çš„åŒºé—´æ—¶ï¼Œå®ƒä¼šæŒ‰ç…§ç»“æŸæ—¶é—´ end æ’åºä¹‹å‰æ”¶é›†çš„ bufï¼Œç„¶åå°†å¤„ç†åçš„ç»“æœ (é™¤äº†æœ€åä¸€ä¸ªå…ƒç´ ) é‡æ–°æ”¾å› valueBuf. åˆå¹¶è¢«å®Œå…¨åŒ…å«çš„å­åŒºé—´ã€‚å®ƒç»´æŠ¤ç€å½“å‰æœ€å¤§çš„ç”Ÿå‘½å‘¨æœŸåŒºé—´ ([usedTSStart, usedTSEnd]). éå†åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªåŒºé—´ *it. æ ¹æ® bool isSub = ((*it).start \u0026gt;= usedTSStart) \u0026amp;\u0026amp; ((*it).end \u0026lt;= usedTSEnd); åˆ¤æ–­åŒºé—´æ˜¯å¦åœ¨æ—¶é—´ä¸Šè¢«ä¸Šä¸€ä¸ªâ€œæ¿€æ´»â€çš„åŒºé—´å®Œå…¨è¦†ç›–ã€‚ å¦‚æœ isSub ä¸º trueï¼Œæ„å‘³ç€ *it æ˜¯ä¸€ä¸ªå†—ä½™çš„å­åŒºé—´ã€‚å› ä¸ºåªè¦ä¸ºé‚£ä¸ªæ›´å¤§çš„æ¿€æ´»åŒºé—´åˆ†é…äº†å†…å­˜ï¼Œè¿™ä¸ªå­åŒºé—´çš„å†…å­˜éœ€æ±‚è‡ªç„¶ä¹Ÿå°±æ»¡è¶³äº†ã€‚å› æ­¤ï¼Œä»£ç é€šè¿‡ valueBuf.erase(it); å°†è¿™ä¸ªå†—ä½™çš„å­åŒºé—´ç›´æ¥åˆ é™¤ã€‚ å¦‚æœ isSub ä¸º falseï¼Œè¯´æ˜é‡åˆ°äº†ä¸€ä¸ªæ–°çš„ã€æ²¡æœ‰è¢«è¦†ç›–çš„ç”Ÿå‘½å‘¨æœŸï¼Œäºæ˜¯å®ƒå°†æˆä¸ºæ–°çš„â€œæ¿€æ´»â€åŒºé—´ï¼Œç”¨äºå’Œåç»­çš„åŒºé—´è¿›è¡Œæ¯”è¾ƒã€‚ Compile Option 1: opt_barrier ç”± groupDAGPass å®ç°ã€‚é€šè¿‡ group é—´çš„ä¾èµ–å…³ç³»æ¥ç»™ group å®šå±‚çº§ï¼ŒåŒä¸€å±‚çº§çš„ group åªæœ‰æœ€åä¸€ä¸ª group éœ€è¦ barrier.\nåˆå§‹åŒ–æ‰€æœ‰ group çš„ need_barrier å±æ€§ä¸º falseã€‚\nä»åå¾€å‰éå† groupï¼Œè‹¥ group çš„ç»“æœæ—  user æˆ–è¦ returnï¼Œè®¾ç½® layerNum ä¸º 0ï¼Œå¦åˆ™è®¾ç½®ä¸º userOp çš„ layerNum + 1. åŒæ—¶ç»´æŠ¤ä¸¤ä¸ª vector: firstOpInLayers å’ŒlastOpInLayers æ¥è®°å½•æ¯ä¸€å±‚çº§çš„ç¬¬ä¸€ä¸ª op å’Œæœ€åä¸€ä¸ª op. éå†ç»“æŸæŠŠ lastOpInLayersä¸­çš„ group çš„ need_barrier å±æ€§è®¾ä¸º true.\nopt_barrier\nCompile Option 1: opt_ddr ç”± ddrConstReorderPass å’Œ ddrVarReorderPass å®ç°ã€‚é€šè¿‡æ”¹å˜ const å’Œ var åœ¨ ddr ä¸­çš„æ’å¸ƒï¼Œä½¿å…¶å¯¹é½ DDR_BANK(4096Bytes)ï¼Œå®ç°åŠ é€Ÿè¯»å–ã€‚\nopt_ddr\n","permalink":"http://localhost:1313/blogs/tx8_backend/","summary":"TX8 backend description.","title":"TX8 Backend"},{"content":"209. Minimum Size Subarray Sum é¢˜ç›®ç½‘å€. è¿™é¢˜æ˜¯æ»‘åŠ¨çª—å£çš„å…¸å‹ä¾‹é¢˜ï¼Œæˆ‘ä»¬ç»´æŠ¤ä¸€ä¸ª left å’Œ right æŒ‡é’ˆæ„æˆçš„ä¸€ä¸ªçª—å£ï¼Œå¯¹å­æ•°ç»„çš„å³ç«¯ç‚¹ä¸æ–­å³ç§»è¿›è¡Œæšä¸¾ã€‚æ¯è¿›è¡Œä¸€æ¬¡å³ç§» (çª—å£æ‰©å¤§ä¹‹å)ï¼Œæˆ‘ä»¬åˆ¤æ–­å°†å·¦ç«¯ç‚¹è¿›è¡Œå³ç§»ä¹‹åçš„å­æ•°ç»„ä¹‹å’Œæ˜¯å¦ \u0026gt;= targetï¼Œå¦‚æœæ˜¯åˆ™æ›´æ–°ç­”æ¡ˆï¼Œåä¹‹åˆ™ç»§ç»­æ‰©å¤§çª—å£ç›´åˆ°æ»¡è¶³æ¡ä»¶ä¸ºæ­¢ã€‚\nè¿™é‡Œçš„ while å¾ªç¯ä¸­ä¸éœ€è¦åˆ¤æ–­ left \u0026lt;= right çš„æ¡ä»¶ï¼Œå½“ä¸¤ä¸ªæŒ‡é’ˆæŒ‡å‘åŒä¸€ä½ç½®æ—¶ï¼ŒæŠŠ sum - nums[left] ç»“æœä¸º 0ï¼Œè€Œ target æ˜¯ä¸€ä¸ªæ­£æ•´æ•°ï¼Œæ¡ä»¶è‡ªåŠ¨ä¸æ»¡è¶³ï¼Œè¿™ä¹Ÿæ˜¯æšä¸¾å³ç«¯ç‚¹çš„ä¸€ä¸ªå¥½å¤„ã€‚è™½ç„¶æ­¤å¤„æ˜¯ä¸¤ä¸ªå¾ªç¯ï¼Œä½†æ˜¯ç›´åˆ°å¤–å±‚ for å¾ªç¯ç»“æŸï¼Œå†…å¾ªç¯çš„ left æœ€å¤šç§»åŠ¨äº† n æ¬¡ï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º $O(n)$. ç”±äºåªç”¨åˆ°äº†å‡ ä¸ªå˜é‡ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(1)$.\nä½¿ç”¨æ»‘åŠ¨çª—å£éœ€è¦é—®é¢˜å…·æœ‰å•è°ƒæ€§ï¼Œæœ¬é¢˜ä¸­çª—å£æ‰©å¤§è‚¯å®šå­æ•°ç»„ä¹‹å’Œè¶Šæ¥è¶Šå¤§ï¼Œåä¹‹å’Œè¶Šæ¥è¶Šå°ã€‚æ»‘åŠ¨çª—å£çš„æ ¸å¿ƒè¦ç‚¹ä¸º\nç»´æŠ¤ä¸€ä¸ªæœ‰æ¡ä»¶çš„æ»‘åŠ¨çª—å£ï¼› å³ç«¯ç‚¹å³ç§»ï¼Œå¯¼è‡´çª—å£æ‰©å¤§ï¼Œæ˜¯ä¸æ»¡è¶³æ¡ä»¶çš„ç½ªé­ç¥¸é¦–ï¼› å·¦ç«¯ç‚¹å³ç§»ç›®çš„æ˜¯ä¸ºäº†ç¼©å°çª—å£ï¼Œé‡æ–°æ»¡è¶³æ¡ä»¶ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Solution { public: int minSubArrayLen(int target, vector\u0026lt;int\u0026gt;\u0026amp; nums) { int ans = nums.size() + 1; // subarray length can\u0026#39;t exceed len+1 int left = 0, sum = 0; for (int right = 0; right \u0026lt; nums.size(); right++) { // right pointer move right to unsatisfy the condition sum += nums[right]; while (sum \u0026gt;= target) { // inner loop max interation is n during the outloop, so the time complexity is O(n) ans = min(ans, right - left + 1); sum -= nums[left]; left++; } } return ans \u0026lt; nums.size() + 1 ? ans : 0; } }; Subarray Product Less Than k é¢˜ç›®ç½‘å€. è¿™é¢˜æ€è·¯ä¸ä¸Šä¸€é¢˜ä¸€æ ·ï¼Œä½†éœ€è¦æ³¨æ„çš„æ˜¯éœ€è¦è¿”å›çš„æ˜¯å…ƒç´ çš„ä¹˜ç§¯ä¸¥æ ¼å°äº k çš„è¿ç»­å­æ•°ç»„çš„æ•°ç›®ã€‚å½“çª—å£ [left, right] å¯¹åº”çš„å­æ•°ç»„æ»¡è¶³è¦æ±‚æ—¶ï¼Œ[left + 1, right], [left + 2, right], ..., [right, right] å…¨éƒ½æ»¡è¶³è¦æ±‚ï¼Œå› æ­¤ç­”æ¡ˆä¸ªæ•°åŠ ä¸Š right - left + 1.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Solution { public: int numSubarrayProductLessThanK(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { int ans = 0; int left = 0, product = 1; if (k \u0026lt;= 1) return 0; for (int right = 0; right \u0026lt; nums.size(); right++) { product *= nums[right]; while (product \u0026gt;= k) { product /= nums[left]; left++; } ans += right - left + 1; } return ans; } }; ","permalink":"http://localhost:1313/blogs/leetcode/02_slidingwindow/","summary":"Algorithm questions about sliding window.","title":"02 Sliding Window"},{"content":"167. Two Sum II é¢˜ç›®ç½‘å€ã€‚å¦‚æœé‡‡ç”¨æš´åŠ›æšä¸¾æ³•ï¼Œå¯¹äºæ¯ä¸€ä¸ªæ•°éƒ½æšä¸¾åé¢çš„æ•°ä¸å…¶ç›¸åŠ çš„ç»“æœæ˜¯å¦ç­‰äº targetï¼Œåˆ™éœ€è¦ä¸¤é‡ for å¾ªç¯ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$. æš´åŠ›æšä¸¾å¹¶æ²¡æœ‰ä½¿ç”¨åˆ°é¢˜ç›®ä¸­æ•°ç»„å·²ç»æ’å¥½åºçš„æ¡ä»¶ï¼Œå¦‚æœé€‰å–ä¿©ä¸¤ä¸ªæ•°åŠ èµ·æ¥ \u0026gt; targetï¼Œé‚£ä¹ˆè¯´æ˜ä»–ä»¬ä¸­é—´å’Œå³è¾¹çš„æ•°åŠ èµ·æ¥è‚¯å®š \u0026gt; targetï¼Œå°±å¯ä»¥æŠŠå³è¾¹çš„æ•°å»æ‰ï¼Œåä¹‹å¯ä»¥æŠŠå·¦è¾¹çš„æ•°å»æ‰ï¼Œç›´åˆ°ä¸¤ä¸ªæŒ‡é’ˆç›¸é‡ã€‚è¿™ç§åŒæŒ‡é’ˆçš„ä½œæ³•æ—¶é—´å¤æ‚åº¦ä¸º $O(n)$. æ ¹æ® 0x3f çš„è§£é‡Šä¸ºèŠ±è´¹ $O(1)$ çš„æ—¶é—´ (é€šè¿‡å·¦å³æŒ‡é’ˆçš„ä¸¤ä¸ªæ•°) å¾—åˆ°äº† $O(n)$ çš„ä¿¡æ¯ (å·¦å³æŒ‡é’ˆä¸­é—´çš„æ•°ç›¸åŠ åçš„ç»“æœä¸ target çš„å…³ç³»). åªç”¨åˆ°äº†ä¸¤ä¸ªé¢å¤–å˜é‡ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(1)$.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution { public: vector\u0026lt;int\u0026gt; twoSum(vector\u0026lt;int\u0026gt;\u0026amp; numbers, int target) { // vector is ascend order int left = 0, right = numbers.size() - 1; // two pointers vector\u0026lt;int\u0026gt; ans(2); for (int i = 0; i \u0026lt; numbers.size(); i++) { if (numbers[left] + numbers[right] == target) { // the question requires index start from 1. ans[0] = left + 1; ans[1] = right + 1; break; } else if (numbers[left] + numbers[right] \u0026lt; target) { left++; } else { right--; } } return ans; } }; 15. 3Sum æœ‰äº†ä¸Šä¸€é¢˜çš„ç»éªŒï¼Œä¸ºäº†ä½¿ç”¨åŒæŒ‡é’ˆï¼Œæˆ‘ä»¬é¦–å…ˆå¯¹æ•°ç»„è¿›è¡Œæ’åºã€‚ç”±äºé¢˜ç›®è¯´è¾“å‡ºçš„ä¸‰å…ƒç»„çš„é¡ºåºå¹¶ä¸é‡è¦ï¼Œå‡å®šä¸‰å…ƒç»„ä¸­æ»¡è¶³ i \u0026lt; j \u0026lt; kï¼Œå¯ä»¥é€šè¿‡æšä¸¾ nums[i] å°†é—®é¢˜è½¬æ¢æˆä¸Šä¸€é¢˜çš„å½¢å¼ã€‚ç”±äºä¸èƒ½å‡ºç°ç›¸åŒçš„ä¸‰å…ƒç»„ï¼Œå› æ­¤å¦‚æœå½“å‰æšä¸¾çš„æ•°å’Œå‰ä¸€ä¸ªæ•°ç›¸åŒçš„è¯å°±è·³è¿‡è¿™ä¸ªæ•°ã€‚æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n\\log n)$, äºŒé‡å¾ªç¯çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œæ‰€ä»¥ç®—æ³•æ€»ä½“æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$. æ²¡æœ‰ç”¨åˆ°é¢å¤–å˜é‡ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(1)$.\nä¼˜åŒ– 1: å¯¹äºå½“å‰æšä¸¾çš„æ•°ï¼Œå¦‚æœä¸åçš„ä¸¤ä¸ªæ•°ç›¸åŠ ç»“æœéƒ½ \u0026gt; 0ï¼Œè¯´æ˜æ•´ä¸ªæ•°ç»„çš„åç»­æ•°ä¸­ä¸å¯èƒ½å‡ºç°ä¸‰æ•°ä¹‹å’Œ = 0 çš„æƒ…å†µï¼Œç›´æ¥é€€å‡ºå¾ªç¯ã€‚ ä¼˜åŒ– 2: å¯¹äºå½“å‰æšä¸¾çš„æ•°ï¼Œå¦‚æœä¸æ•°ç»„æœ«å°¾çš„ä¸¤ä¸ªæ•°ç›¸åŠ ç»“æœéƒ½ \u0026lt; 0ï¼Œè¯´æ˜å½“å‰æšä¸¾çš„æ•°åç»­æ•°ä¸­ä¸å¯èƒ½å‡ºç°ä¸‰æ•°ä¹‹å’Œ = 0 çš„æƒ…å†µï¼Œç›´æ¥è¿›è¡Œä¸‹ä¸€æ¬¡å¾ªç¯ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; threeSum(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; // the question doesn\u0026#39;t require the order of answer. sort(nums.begin(), nums.end()); // can only apply double-pointer in sorted array for (int i = 0; i \u0026lt; nums.size() - 2; i++) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) continue; // avoid repeat int j = i + 1; int k = nums.size() - 1; if (nums[i] + nums[k] + nums[k - 1] \u0026lt; 0) // can\u0026#39;t find other 2 ele at idx i continue; // iter next i if ((nums[i] + nums[j] + nums[j + 1] \u0026gt; 0)) // can\u0026#39;t find other 2 ele from idx i break; // return while (j \u0026lt; k) { if (nums[i] + nums[j] + nums[k] \u0026lt; 0) { j++; } else if (nums[i] + nums[j] + nums[k] \u0026gt; 0) { k--; } else { ans.push_back({nums[i], nums[j], nums[k]}); // find next j++; k--; // avoid repeat while ((j \u0026lt; k) \u0026amp;\u0026amp; nums[j] == nums[j - 1]) j++; while ((j \u0026lt; k) \u0026amp;\u0026amp; nums[j] == nums[k + 1]) k--; } } } return ans; } }; 2824. Count Pairs whose Sum is Less than Target é¢˜ç›®ç½‘å€. æ•°ç»„çš„é¡ºåºå¯¹å’Œæ²¡æœ‰å½±å“ï¼Œå› æ­¤å…ˆè¿›è¡Œæ’åºåå†å¥—åŒæŒ‡é’ˆæ¨¡æ¿ã€‚ä¸€æ—¦æ‰¾åˆ°å’Œå°äº target çš„å·¦å³æŒ‡é’ˆä½ç½®ï¼Œåˆ™è¯´æ˜ä»–ä»¬ä¸­é—´æ‰€æœ‰çš„ä¸‹æ ‡å¯¹ä¹‹å’Œéƒ½å°äº target.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Solution { public: int countPairs(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { sort(nums.begin(), nums.end()); int ans = 0, left = 0, right = nums.size() - 1; while (left \u0026lt; right) { if (nums[left] + nums[right] \u0026gt;= target) { right--; } else { // numbers between left and right all little than target ans += right - left; left++; } } return ans; } }; 16. 3sum-cloest é¢˜ç›®ç½‘å€. ä¾ç„¶æ˜¯å…ˆæ’åºå†ä½¿ç”¨åŒæŒ‡é’ˆï¼Œä½†è¿™é‡Œè¦æ³¨æ„çš„æ˜¯æ ¹æ®æ˜¯ä»è´Ÿæ–¹å‘æ¥è¿‘è¿˜æ˜¯ä»æ­£æ–¹å‘æ¥è¿‘æ¥ç§»åŠ¨æŒ‡é’ˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Solution { public: int threeSumClosest(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { sort(nums.begin(), nums.end()); int ans = 0, diff = INT_MAX; for (int i = 0; i \u0026lt; nums.size() - 2; i++) { int j = i + 1; int k = nums.size() - 1; while (j \u0026lt; k) { int sum = nums[i] + nums[j] + nums[k]; if (sum - target \u0026gt; diff) { k--; } else if (sum - target \u0026lt; -diff) { j++; } else { diff = abs(sum - target); ans = sum; if (sum - target \u0026lt; 0) j++; else k--; } } } return ans; } }; 18. 4sum é¢˜ç›®ç½‘å€. ä¸ä¸‰æ•°ä¹‹å’Œä¸€æ ·ï¼Œå…ˆå¯¹æ•°ç»„è¿›è¡Œæ’åºï¼Œè¦ä½¿ç”¨åŒæŒ‡é’ˆçš„è¯æˆ‘ä»¬éœ€è¦ç”¨ä¸¤é‡ for å¾ªç¯æšä¸¾ä¸¤ä¸ªæ•°ï¼Œé—®é¢˜åˆ™å˜æˆæ‰¾åˆ°å¦å¤–ä¸¤ä¸ªæ•°ä½¿å¾—å››æ•°ä¹‹å’Œç­‰äº targetï¼Œå°±å¯ä»¥ä½¿ç”¨åŒæŒ‡é’ˆè§£é¢˜ã€‚å…¶ä¸­ä¼˜åŒ–è·³è¿‡æƒ…å†µçš„é“ç†å’Œ 3sum ç›¸åŒã€‚ç›¸åŠ ç»“æœå¯èƒ½è¶…è¿‡ int(32bit) èŒƒå›´ï¼Œéœ€è¦ç”¨ long long(64 bit) å­˜å‚¨ã€‚\nå¾ªç¯çš„æ—¶å€™éœ€è¦æ³¨æ„\nåœ¨ C++ æ ‡å‡†åº“ä¸­ï¼Œstd::vector::size() è¿”å›çš„ç±»å‹æ˜¯ size_tï¼Œä¸€ä¸ªæ— ç¬¦å·æ•´æ•°ç±»å‹ï¼Œæ„å‘³ç€å®ƒä¸èƒ½è¡¨ç¤ºè´Ÿæ•°ã€‚ å½“ nums çš„å…ƒç´ å°‘äº 4 ä¸ªæ—¶ nums.size() - 3 ä¼šå˜æˆè´Ÿæ•°ã€‚ä½†å› ä¸º nums.size() æ˜¯æ— ç¬¦å·çš„ size_tï¼Œæ‰€ä»¥è¿™ä¸ªè®¡ç®—æ˜¯åœ¨æ— ç¬¦å·æ•´æ•°çš„ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œçš„ã€‚åœ¨æ— ç¬¦å·æ•´æ•°çš„ä¸–ç•Œé‡Œä¼šè¢« wrap around å˜æˆä¸€ä¸ªéå¸¸å¤§çš„æ­£æ•°ï¼ˆã€‚ äºæ˜¯ï¼Œå¾ªç¯æ¡ä»¶ i \u0026lt; nums.size() - 3 å°±å˜æˆäº† i \u0026lt; ä¸€ä¸ªå·¨å¤§çš„æ­£æ•°ã€‚å¾ªç¯ä¼šå¯åŠ¨ï¼Œåœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶ï¼Œå½“ i = 0ï¼Œä»£ç å°è¯•è®¿é—® nums[0]. å¦‚æœ nums ä¸ºç©ºï¼Œè¿™ä¼šç«‹å³å¯¼è‡´æ®µé”™è¯¯ã€‚å³ä½¿ nums æœ‰ 0-3 ä¸ªå…ƒç´ ï¼Œå¾ªç¯ä¹Ÿä¼šç»§ç»­æ‰§è¡Œï¼Œè¯•å›¾è®¿é—® nums[0], nums[1], nums[2], nums[3]\u0026hellip; å¾ˆå¿«å°±ä¼šè¶…å‡ºå‘é‡çš„è¾¹ç•Œï¼Œä»è€Œå¼•å‘ heap-buffer-overflow. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; fourSum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { ranges::sort(nums); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; int n = nums.size(); for (int i = 0; i \u0026lt; n - 3; i++) { long long x = nums[i]; if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) continue; if (x + nums[i + 1] + nums[i + 2] + nums[i + 3] \u0026gt; target) break; if (x + nums[n - 1] + nums[n - 2] + nums[n - 3] \u0026lt; target) continue; for (int j = i + 1; j \u0026lt; n - 2; j++) { long long y = nums[j]; if (j \u0026gt; i + 1 \u0026amp;\u0026amp; nums[j] == nums[j - 1]) continue; if (x + y + nums[j + 1] + nums[j + 2] \u0026gt; target) break; if (x + y + nums[n - 1] + nums[n - 2] \u0026lt; target) continue; int k = j + 1; int l = n - 1; while (k \u0026lt; l) { long long sum = x + y + nums[k] + nums[l]; if (sum \u0026gt; target) { l--; } else if (sum \u0026lt; target) { k++; } else { ans.push_back({nums[i], nums[j], nums[k], nums[l]}); k++; l--; while (k \u0026lt; l \u0026amp;\u0026amp; nums[k] == nums[k - 1]) k++; while (k \u0026lt; l \u0026amp;\u0026amp; nums[l] == nums[l + 1]) l--; } } } } return ans; } }; 611. Valid Triangle Number é¢˜ç›®ç½‘å€. è¿™ä¸ªé¢˜æ¯”è¾ƒå·§çš„ä¸€ç‚¹æ˜¯æˆ‘ä»¬å¯¹æ’åºåçš„æ•°ç»„ä»æœ€å¤§è¾¹å¼€å§‹å¾€å‰éå†ï¼Œè¿™æ ·å¯ä»¥ä¿è¯æ‰¾åˆ°åŒæŒ‡é’ˆå¯¹åº”çš„è¾¹é•¿åŠ èµ·æ¥å¤§äºæšä¸¾çš„è¾¹é•¿æ—¶å…¶ä»–ä¸¤æ¡è¾¹åŠ èµ·æ¥ä¹Ÿå¤§äºç¬¬ä¸‰è¾¹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public: int triangleNumber(vector\u0026lt;int\u0026gt;\u0026amp; nums) { sort(nums.begin(), nums.end()); int ans = 0; // reverse iteration can ensure if left + right \u0026gt; i, then a triangle exists. for (int i = nums.size() - 1; i \u0026gt; 1; i--) { int left = 0, right = i - 1; while (left \u0026lt; right) { if (nums[left] + nums[right] \u0026gt; nums[i]) { ans += right - left; right--; } else { left++; } } } return ans; } }; 11. Container with Most Water é¢˜ç›®ç½‘å€. å‡è®¾å·¦å³æŒ‡é’ˆçš„æŸ±å­å·²ç»åœˆå®šäº†ä¸€ä¸ªèŒƒå›´ï¼Œå¦‚æœæƒ³æ‰¾åˆ°æ¯”å®ƒé¢ç§¯æ›´å¤§çš„èŒƒå›´ï¼Œåªèƒ½ç§»åŠ¨æŒ‡é’ˆæ‰¾ä¸€ä¸ªæ›´é«˜çš„æŸ±å­ï¼Œè¿™æ ·è™½ç„¶å®½åº¦å˜å°äº†ä½†æ˜¯é«˜åº¦å¢åŠ äº†ï¼Œé¢ç§¯æœ‰å¯èƒ½å˜å¤§ã€‚å› æ­¤ä»ä¸¤ç«¯å¼€å§‹æˆ‘ä»¬ä¸æ–­ç§»åŠ¨é«˜åº¦è¾ƒå°çš„æŒ‡é’ˆç›´è‡³ç›¸é‡ã€‚åˆ°ç›¸é‡æ—¶éå†äº†æ•°ç»„ä¸€éï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º $O(n)$. åªç”¨åˆ°äº†å¸¸æ•°ä¸ªé¢å¤–å˜é‡ï¼Œå› æ­¤ç©ºé—´å¤æ‚åº¦ä¸º $O(1)$.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution { public: int maxArea(vector\u0026lt;int\u0026gt;\u0026amp; height) { // area = (right - left) * min(height[left], height[right]) int left = 0, right = height.size() - 1; int ans = 0; while (left \u0026lt; right) { int area = (right - left) * min(height[left], height[right]); ans = max(ans, area); // if (height[left] \u0026lt; height[right]) { // left++; // width decrease but height may increase // } else { // right--; // } height[left] \u0026lt; height[right] ? left++ : right--; } return ans; } }; 42. Trapping Rain Water é¢˜ç›®ç½‘å€. å‡è®¾æ¯ä¸ªä½ç½®æ˜¯ä¸€ä¸ªå®½åº¦ä¸º 1 çš„æ¡¶ï¼Œè¯¥ä½ç½®èƒ½æ¥å¤šå°‘æ°´å–å†³äºè¯¥ä½ç½®å·¦ä¾§æœ¨æ¿æœ€å¤§é«˜åº¦å’Œå³ä¾§æœ¨æ¿æœ€å¤§é«˜åº¦ä¸­è¾ƒå°è€…ã€‚åˆå§‹åŒ–å·¦å³æŒ‡é’ˆç›¸å‘ç§»åŠ¨ï¼Œå¹¶è®°å½•è¯¥ä¾§çš„å½“å‰æœ€å¤§æŸ±å­é«˜åº¦ï¼Œå¯¹äºå·¦å³æŒ‡é’ˆæ‰€å¤„çš„ä½ç½®æˆ‘ä»¬å¯ä»¥ç¡®å®šçš„æ˜¯è¾ƒçŸ®è€…èƒ½è£…å¤šå°‘æ°´ï¼Œè®¡ç®—ä¹‹åå°±å¯ä»¥ç§»åŠ¨è¯¥æŒ‡é’ˆã€‚åˆ°ç›¸é‡æ—¶éå†äº†æ•°ç»„ä¸€éï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º $O(n)$. åªç”¨åˆ°äº†å¸¸æ•°ä¸ªé¢å¤–å˜é‡ï¼Œå› æ­¤ç©ºé—´å¤æ‚åº¦ä¸º $O(1)$.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution { public: int trap(vector\u0026lt;int\u0026gt;\u0026amp; height) { // each pos can hold water min(lMax - height[pos], rMax - height[pos]) int ans = 0, lMax = 0, rMax = 0; int left = 0, right = height.size() - 1; while (left \u0026lt; right) { // update prefix \u0026amp; suffix max lMax = max(lMax, height[left]); rMax = max(rMax, height[right]); if (lMax \u0026lt; rMax) { ans += lMax - height[left]; left++; } else { ans += rMax - height[right]; right--; } } return ans; } }; 125. Valid Palindrome é¢˜ç›®ç½‘å€. è¿™é¢˜çš„æ€è·¯æ¯”è¾ƒç›´è§‚ï¼Œåˆå§‹åŒ–å·¦å³æŒ‡é’ˆåè‹¥å…¶ä¸­ä¸€æ–¹ç¢°è§éæ•°å­—æˆ–å­—æ¯å°±ç›´æ¥ç§»åŠ¨ã€‚å¦åˆ™è¿›è¡Œåˆ¤æ–­ï¼Œå‘ç°æœ‰ä¸€å¤„ä¸ç›¸ç­‰æ—¶å³å¯è·³å‡ºå¾ªç¯è¿”å› false.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { public: bool isPalindrome(string s) { int left = 0, right = s.size() - 1; bool ans = true; while (left \u0026lt; right) { if (!(isalpha(s[left]) || isalnum(s[left]))) { left++; continue; } if (!(isalpha(s[right]) || isalnum(s[right]))) { right--; continue; } if (tolower(s[left]) == tolower(s[right])) { left++; right--; } else { ans = false; break; } } return ans; } }; 2105. Watering Plants II é¢˜ç›®ç½‘å€. è¿™é¢˜æ€è·¯ä¹Ÿæ¯”è¾ƒç›´è§‚ï¼Œåˆå§‹åŒ–å·¦å³æŒ‡é’ˆåç›¸å‘ç§»åŠ¨ï¼ŒæŸä¸€æ–¹çš„æ°´ä¸å¤Ÿæ—¶å°±éœ€è¦è¡¥å……å¹¶æ›´æ–°å®¹é‡ä¸ºæµ‡æ°´å®Œä¹‹åçš„å®¹é‡ï¼Œå¢åŠ è®¡æ•°å™¨ã€‚è‹¥æœ€åä¸¤è€…ç›¸é‡åˆ™è¿˜éœ€è¦åˆ¤æ–­å½“å‰å‰©ä½™æ°´é‡å¤šçš„ä¸€æ–¹æ˜¯å¦è¶³å¤Ÿã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Solution { public: int minimumRefill(vector\u0026lt;int\u0026gt;\u0026amp; plants, int capacityA, int capacityB) { int left = 0, right = plants.size() - 1; int volumeA = capacityA, volumeB = capacityB; int ans = 0; while (left \u0026lt; right) { if (volumeA \u0026gt;= plants[left]) { volumeA -= plants[left]; left++; } else { volumeA = capacityA - plants[left]; // fill then watering ans++; left++; } if (volumeB \u0026gt;= plants[right]) { volumeB -= plants[right]; right--; } else { volumeB = capacityB - plants[right]; // fill then watering ans++; right--; } } if (left == right \u0026amp;\u0026amp; max(volumeA, volumeB) \u0026lt; plants[left]) ans++; return ans; } }; ","permalink":"http://localhost:1313/blogs/leetcode/01_doublepointer/","summary":"Algorithm questions about double-pointer.","title":"01 Double-pointer"},{"content":"Introduction è¿™ç¯‡æ–‡ç« çš„æ ¸å¿ƒç›®æ ‡æ˜¯æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰å¤„ç†è§†é¢‘çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¤„ç†é•¿ä¸”ä¿¡æ¯ä¸°å¯Œçš„è§†é¢‘ä¸Šä¸‹æ–‡ï¼ˆLong and Rich Context, LRCï¼‰çš„èƒ½åŠ› ã€‚ç›®å‰ï¼Œä¸»æµçš„ MLLM åœ¨å¤„ç†é•¿è§†é¢‘æ—¶å¾€å¾€ä¼šé‡åˆ°å›°éš¾ï¼Œè¦ä¹ˆå› ä¸ºè®¡ç®—èµ„æºä¸å ªé‡è´Ÿè€Œå†…å­˜æº¢å‡ºï¼Œè¦ä¹ˆåœ¨é•¿æ—¶åºä¸­ä¸¢å¤±å…³é”®çš„ç»†èŠ‚ä¿¡æ¯ï¼Œå¯¼è‡´ç†è§£å’Œæ¨ç†èƒ½åŠ›ä¸‹é™ã€‚è¿™ç¯‡è®ºæ–‡çš„å·¥ä½œæ—¨åœ¨å¢å¼ºæ¨¡å‹çš„å¤„ç†é•¿è§†é¢‘ (length) çš„èƒ½åŠ›å’Œæ•æ‰ç²¾ç»†ç»†èŠ‚ (fineness) çš„èƒ½åŠ›ã€‚\næ–‡ç« æå‡ºäº†ä¸¤å¤§æ ¸å¿ƒæŠ€æœ¯ï¼šHierarchical Token Compression (HiCo) \u0026amp; Task Preference Optimization (TPO).\nHiCo ä¸»è¦è§£å†³å¤„ç†é•¿è§†é¢‘çš„é—®é¢˜ã€‚è§†é¢‘ä¸­å­˜åœ¨å¤§é‡çš„å†—ä½™ä¿¡æ¯ï¼Œæ¯”å¦‚ç›¸é‚»å¸§ä¹‹é—´èƒŒæ™¯å˜åŒ–å¾ˆå°ï¼Œæˆ–è€…åœ¨ä¸€ä¸ªé•¿é•œå¤´ä¸­è¯­ä¹‰ä¿¡æ¯æ˜¯ç›¸ä¼¼çš„ã€‚HiCo å‰”é™¤è¿™äº›å†—ä½™ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚å®ƒé€šè¿‡ä¸€ä¸ªä¸‰æ­¥èµ°çš„éå­¦ä¹ æ€§è¿‡ç¨‹æ¥å®ç°ï¼š\nè‡ªé€‚åº”æ—¶é—´é‡‡æ ·ï¼šæ ¹æ®è§†é¢‘çš„é•¿çŸ­å’Œå†…å®¹ç‰¹æ€§ï¼ŒåŠ¨æ€è°ƒæ•´é‡‡æ ·é¢‘ç‡ã€‚çŸ­è§†é¢‘ï¼ˆå¦‚åŠ¨ä½œç‰‡æ®µï¼‰éœ€è¦å¯†é›†é‡‡æ ·æ¥æ•æ‰ç»†èŠ‚ï¼Œè€Œé•¿è§†é¢‘ï¼ˆå¦‚ç”µå½±ï¼‰åˆ™ç¨€ç–é‡‡æ ·ä»¥æŠŠæ¡äº‹ä»¶è„‰ç»œã€‚ Spatiotemporal Token Merging: å®ƒä½¿ç”¨äº†ä¸€ç§åä¸ºToMe (Token Merging) çš„æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯é€šè¿‡è®¡ç®— token ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œå°†ç›¸ä¼¼çš„è¿›è¡Œåˆå¹¶ã€‚æŠŠè§†é¢‘ä¸­æ„æ€ç›¸è¿‘çš„ç”»é¢ä¿¡æ¯æåœ¨ä¸€èµ·ï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·ç²—æš´åœ°ä¸¢å¼ƒæˆ–å¹³å‡ã€‚è®ºæ–‡ç‰¹åˆ«æŒ‡å‡ºï¼Œä¸éœ€è¦å¤§é‡é¢å¤–å‚æ•°å’Œå¤æ‚è®­ç»ƒçš„Q-Former ç­‰å‹ç¼©æ–¹æ³•ç›¸æ¯”ï¼ŒToMe æ˜¯å³æ’å³ç”¨çš„ï¼Œæ•ˆç‡æé«˜ã€‚ Multimodal Token Dropoutï¼šåœ¨æ¨¡å‹çš„æ·±å±‚ï¼Œæ ¹æ®æ³¨æ„åŠ›æƒé‡åŠ¨æ€ä¸¢å¼ƒé‚£äº›ä¸å½“å‰ä»»åŠ¡ä¸å¤ªç›¸å…³çš„è§†è§‰é€šè¯ï¼Œè¿›ä¸€æ­¥ç²¾ç®€ä¿¡æ¯æµï¼Œè®©æ¨¡å‹èƒ½æ›´ä¸“æ³¨äºæ ¸å¿ƒå†…å®¹ ã€‚ é€šè¿‡ HiCoï¼Œæ¨¡å‹å¯ä»¥åœ¨ä¸ç‰ºç‰²è¿‡å¤šæ€§èƒ½çš„å‰æä¸‹ï¼Œå¤„ç†æ›´é•¿çš„è§†é¢‘åºåˆ—ã€‚å®éªŒç»“æœæå…·è¯´æœåŠ›ï¼šåœ¨å¤§æµ·æé’ˆï¼ˆNeedle-in-a-Haystackï¼‰æµ‹è¯•ä¸­ï¼ŒåŸºç¡€æ¨¡å‹ InternVL2.5 åœ¨å¤„ç† 500 å¸§è§†é¢‘æ—¶å°±å·²ç»å¾ˆåƒåŠ›ï¼Œè¶…è¿‡1000 å¸§ä¾¿ä¼šå†…å­˜æº¢å‡º ã€‚è€Œåº”ç”¨äº† HiCo çš„ InternVideo2.5ï¼Œä¸ä»…èƒ½è½»æ¾å¤„ç†è¶…è¿‡ 5000 å¸§çš„è§†é¢‘ï¼Œè¿˜èƒ½åœ¨ 3000 å¸§çš„é•¿åº¦å†…ä¿æŒæé«˜çš„ä¿¡æ¯æ£€ç´¢å‡†ç¡®ç‡ã€‚å¯ä»¥è¯´è®°ä½æ¯”åŸæ¥é•¿ 6 å€ä»¥ä¸Šçš„è§†é¢‘å¹¶éè™šè¨€ã€‚\nTPO ä¸»è¦è§£å†³ä¿¡æ¯ä¸°å¯Œçš„é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯æå‡æ¨¡å‹å¯¹ç²¾ç»†è§†è§‰ç»†èŠ‚çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯è®©ä¸“å®¶æ¥æ•™é€šæ‰ã€‚é€šç”¨çš„ MLLM è™½ç„¶èƒ½åŠ›å…¨é¢ï¼Œä½†åœ¨ç‰¹å®šè§†è§‰ä»»åŠ¡ä¸Šï¼ˆå¦‚ç‰©ä½“åˆ†å‰²ã€æ—¶é—´å®šä½ï¼‰å¾€å¾€ä¸å¦‚é‚£äº›ä¸“é—¨è®­ç»ƒçš„ä¸“å®¶æ¨¡å‹ã€‚TPOé€šè¿‡ Direct Preference Optimization (DPO )æŠ€æœ¯ï¼Œå°†è¿™äº›ä¸“å®¶æ¨¡å‹å¯¹ç‰¹å®šä»»åŠ¡çš„åå¥½ï¼ˆå³æ›´å‡†ç¡®çš„è¾“å‡ºï¼‰æ³¨å…¥åˆ° MLLM ä¸­ã€‚\nå…·ä½“æ¥è¯´ï¼Œå®ƒä¸º MLLM å¢åŠ äº†ä¸“é—¨çš„â€œä»»åŠ¡å¤´â€ï¼ˆTask Headï¼‰ï¼Œæ¯”å¦‚ç”¨äºæ—¶é—´å®šä½çš„\nTemporal Headå’Œç”¨äºå®ä¾‹åˆ†å‰²çš„Mask Head ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œä¸ä»…ä¼˜åŒ–MLLMçš„åŸºç¡€å¯¹è¯èƒ½åŠ›ï¼Œè¿˜åˆ©ç”¨ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ï¼ˆå¦‚åˆ†å‰²ã€å®šä½æ•°æ®é›†ï¼‰æ¥ä¼˜åŒ–è¿™äº›ä»»åŠ¡å¤´çš„è¡¨ç°ã€‚è¿™æ ·ä¸€æ¥ï¼ŒMLLMå°±å¥½åƒå­¦ä¼šäº†åœ¨éœ€è¦çš„æ—¶å€™â€œè°ƒç”¨â€è¿™äº›ä¸“å®¶èƒ½åŠ›ã€‚\n","permalink":"http://localhost:1313/blogs/internvideo2.5/","summary":"Technical report reading of InternVideo2.5","title":"InternVideo2.5"},{"content":"Regular Expression Rules Detailed Explanation æ­£åˆ™è¡¨è¾¾å¼ (Regular Expressionï¼Œç®€ç§° regex) æ˜¯ä¸€ç§ç”¨äºåŒ¹é…å’Œæ“ä½œæ–‡æœ¬çš„å¼ºå¤§å·¥å…·ã€‚å®ƒé€šè¿‡å®šä¹‰ç‰¹å®šçš„æ¨¡å¼æ¥æŸ¥æ‰¾ã€éªŒè¯æˆ–æ›¿æ¢å­—ç¬¦ä¸²ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»æ­£åˆ™è¡¨è¾¾å¼çš„è§„åˆ™ï¼ŒåŒ…æ‹¬åŸºæœ¬è¯­æ³•ã€å¸¸ç”¨å…ƒå­—ç¬¦ã€é‡è¯ã€æ•è·ç»„ç­‰ï¼Œå¹¶æä¾›ç¤ºä¾‹ã€‚\n1. Regular Expression Basics æ­£åˆ™è¡¨è¾¾å¼ç”±æ™®é€šå­—ç¬¦å’Œå…ƒå­—ç¬¦ç»„æˆï¼š\næ™®é€šå­—ç¬¦ï¼šå¦‚å­—æ¯ã€æ•°å­—ã€ç¬¦å· (å¦‚ aã€1ã€@)ï¼Œç›´æ¥åŒ¹é…è‡ªèº«ã€‚ å…ƒå­—ç¬¦ï¼šå…·æœ‰ç‰¹æ®Šæ„ä¹‰çš„å­—ç¬¦ï¼Œå¦‚ .ã€^ã€* ç­‰ï¼Œç”¨äºå®šä¹‰åŒ¹é…è§„åˆ™ã€‚ æ­£åˆ™è¡¨è¾¾å¼é€šå¸¸ç”¨æ–œæ  / åŒ…è£¹ (å¦‚ /abc/)ï¼Œä½†åœ¨ä¸åŒè¯­è¨€ä¸­å¯èƒ½æœ‰æ‰€ä¸åŒ (ä¾‹å¦‚ Python ç”¨å­—ç¬¦ä¸²è¡¨ç¤ºï¼ŒJavaScript ç”¨ /.../) ã€‚\n2. Common Metacharacters ä»¥ä¸‹æ˜¯æ­£åˆ™è¡¨è¾¾å¼ä¸­å¸¸ç”¨çš„å…ƒå­—ç¬¦åŠå…¶å«ä¹‰ï¼š\nå…ƒå­—ç¬¦ æè¿° ç¤ºä¾‹ åŒ¹é…ç»“æœ . åŒ¹é…é™¤æ¢è¡Œç¬¦ (\\n) å¤–çš„ä»»æ„å•ä¸ªå­—ç¬¦ a.c abc, a1c, a@c ^ åŒ¹é…å­—ç¬¦ä¸²çš„å¼€å¤´ ^abc abc (ä»…åœ¨å­—ç¬¦ä¸²å¼€å¤´) $ åŒ¹é…å­—ç¬¦ä¸²çš„ç»“å°¾ abc$ abc (ä»…åœ¨å­—ç¬¦ä¸²ç»“å°¾) * åŒ¹é…å‰é¢çš„å­—ç¬¦æˆ–å­è¡¨è¾¾å¼ 0 æ¬¡æˆ–å¤šæ¬¡ ab*c ac, abc, abbc + åŒ¹é…å‰é¢çš„å­—ç¬¦æˆ–å­è¡¨è¾¾å¼ 1 æ¬¡æˆ–å¤šæ¬¡ ab+c abc, abbc (ä¸åŒ¹é… ac) ? åŒ¹é…å‰é¢çš„å­—ç¬¦æˆ–å­è¡¨è¾¾å¼ 0 æ¬¡æˆ– 1 æ¬¡ ab?c ac, abc ` ` æˆ–è¿ç®—ï¼ŒåŒ¹é…å·¦ä¾§æˆ–å³ä¾§çš„æ¨¡å¼ `a [] åŒ¹é…æ–¹æ‹¬å·å†…çš„ä»»æ„ä¸€ä¸ªå­—ç¬¦ [abc] a, b, æˆ– c [^] åŒ¹é…ä¸åœ¨æ–¹æ‹¬å·å†…çš„ä»»æ„å­—ç¬¦ [^abc] é aã€bã€c çš„å­—ç¬¦ () å®šä¹‰å­è¡¨è¾¾å¼æˆ–æ•è·ç»„ (abc) åŒ¹é… abc ä½œä¸ºä¸€ä¸ªæ•´ä½“ {n} ç²¾ç¡®åŒ¹é…å‰é¢çš„å­—ç¬¦æˆ–å­è¡¨è¾¾å¼ n æ¬¡ a{3} aaa {n,} åŒ¹é…å‰é¢çš„å­—ç¬¦æˆ–å­è¡¨è¾¾å¼è‡³å°‘ n æ¬¡ a{2,} aa, aaa, aaaa {n,m} åŒ¹é…å‰é¢çš„å­—ç¬¦æˆ–å­è¡¨è¾¾å¼ n åˆ° m æ¬¡ a{2,3} aa, aaa 3. Character Classes å­—ç¬¦ç±»ç”¨äºåŒ¹é…ç‰¹å®šèŒƒå›´æˆ–ç±»å‹çš„å­—ç¬¦ï¼š\né¢„å®šä¹‰å­—ç¬¦ç±»ï¼š \\dï¼šåŒ¹é…ä»»æ„æ•°å­—ï¼Œç­‰ä»·äº [0-9]. \\Dï¼šåŒ¹é…éæ•°å­—ï¼Œç­‰ä»·äº [^0-9]. \\wï¼šåŒ¹é…ä»»æ„å­—æ¯ã€æ•°å­—æˆ–ä¸‹åˆ’çº¿ï¼Œç­‰ä»·äº [a-zA-Z0-9_] dissuades \\Wï¼šåŒ¹é…éå­—æ¯ã€æ•°å­—æˆ–ä¸‹åˆ’çº¿ï¼Œç­‰ä»·äº [^a-zA-Z0-9_]. \\sï¼šåŒ¹é…ä»»æ„ç©ºç™½å­—ç¬¦ (å¦‚ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€æ¢è¡Œç¬¦) ã€‚ \\Sï¼šåŒ¹é…éç©ºç™½å­—ç¬¦ã€‚ è‡ªå®šä¹‰å­—ç¬¦ç±»ï¼š [a-z]ï¼šåŒ¹é…å°å†™å­—æ¯ a åˆ° z. [A-Z]ï¼šåŒ¹é…å¤§å†™å­—æ¯ A åˆ° Z. [0-9]ï¼šåŒ¹é…æ•°å­— 0 åˆ° 9. [a-zA-Z]ï¼šåŒ¹é…ä»»æ„å­—æ¯ã€‚ [a-dm-p]ï¼šåŒ¹é… a åˆ° d æˆ– m åˆ° p çš„å­—ç¬¦ã€‚ ç¤ºä¾‹ï¼š\n\\d{3}ï¼šåŒ¹é…ä¸‰ä¸ªæ•°å­—ï¼Œå¦‚ 123. [a-zA-Z]+ï¼šåŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªå­—æ¯ï¼Œå¦‚ hello. 4. Quantifiers é‡è¯æ§åˆ¶å‰é¢çš„å­—ç¬¦æˆ–å­è¡¨è¾¾å¼çš„é‡å¤æ¬¡æ•°ï¼š\n*ï¼š0 æ¬¡æˆ–å¤šæ¬¡ã€‚ +ï¼š1 æ¬¡æˆ–å¤šæ¬¡ã€‚ ?ï¼š0 æ¬¡æˆ– 1 æ¬¡ã€‚ {n}ï¼šç²¾ç¡® n æ¬¡ã€‚ {n,}ï¼šè‡³å°‘ n æ¬¡ã€‚ {n,m}ï¼šn åˆ° m æ¬¡ã€‚ è´ªå©ªæ¨¡å¼ä¸éè´ªå©ªæ¨¡å¼ï¼š\né»˜è®¤æƒ…å†µä¸‹ï¼Œé‡è¯æ˜¯è´ªå©ªæ¨¡å¼ï¼ŒåŒ¹é…å°½å¯èƒ½å¤šçš„å­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œa.*b åŒ¹é… a123b456b ä¸­çš„ a123b456b. æ·»åŠ  ? åå˜ä¸ºéè´ªå©ªæ¨¡å¼ï¼ŒåŒ¹é…å°½å¯èƒ½å°‘çš„å­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œa.*?b åŒ¹é… a123b456b ä¸­çš„ a123b. 5. Capture Groups and Non-Capture Groups æ•è·ç»„ï¼šç”¨ () åŒ…è£¹çš„å­è¡¨è¾¾å¼ï¼Œå¯ä»¥æå–åŒ¹é…çš„å†…å®¹æˆ–è¿›è¡Œåå‘å¼•ç”¨ã€‚ ç¤ºä¾‹ï¼š(\\d{2})-(\\d{2}) åŒ¹é… 12-34ï¼Œæ•è·ç»„ 1 ä¸º 12ï¼Œæ•è·ç»„ 2 ä¸º 34. åå‘å¼•ç”¨ï¼šä½¿ç”¨ \\n (n ä¸ºç»„ç¼–å·) å¼•ç”¨æ•è·ç»„ã€‚ä¾‹å¦‚ï¼Œ(a)\\1 åŒ¹é… aa (ä¸¤ä¸ªç›¸åŒçš„ a) ã€‚ éæ•è·ç»„ï¼šç”¨ (?:...) å®šä¹‰ï¼Œä¸ä¿å­˜åŒ¹é…å†…å®¹ï¼Œä»…ç”¨äºåˆ†ç»„ã€‚ ç¤ºä¾‹ï¼š(?:abc) åŒ¹é… abcï¼Œä½†ä¸æ•è·ã€‚ 6. Boundaries and Assertions å•è¯è¾¹ç•Œï¼š \\bï¼šåŒ¹é…å•è¯è¾¹ç•Œã€‚ä¾‹å¦‚ï¼Œ\\bcat\\b åŒ¹é… catï¼Œä½†ä¸åŒ¹é… category ä¸­çš„ cat. \\Bï¼šåŒ¹é…éå•è¯è¾¹ç•Œã€‚ å‰ç»ä¸åé¡¾æ–­è¨€ï¼š (?=...)ï¼šæ­£å‘å‰ç»ï¼ŒåŒ¹é…åé¢è·Ÿç€æŸæ¨¡å¼çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼Œa(?=b) åŒ¹é… ab ä¸­çš„ a. (?!...)ï¼šè´Ÿå‘å‰ç»ï¼ŒåŒ¹é…åé¢ä¸è·ŸæŸæ¨¡å¼çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼Œa(?!b) åŒ¹é… ac ä¸­çš„ a. (?\u0026lt;=...)ï¼šæ­£å‘åé¡¾ï¼ŒåŒ¹é…å‰é¢æ˜¯æŸæ¨¡å¼çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼Œ(?\u0026lt;=b)a åŒ¹é… ba ä¸­çš„ a. (?\u0026lt;!...)ï¼šè´Ÿå‘åé¡¾ï¼ŒåŒ¹é…å‰é¢ä¸æ˜¯æŸæ¨¡å¼çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼Œ(?\u0026lt;!b)a åŒ¹é… ca ä¸­çš„ a. 7. Modifiers (Flags) ä¿®é¥°ç¬¦æ§åˆ¶æ­£åˆ™è¡¨è¾¾å¼çš„è¡Œä¸ºï¼Œå¸¸è§ä¿®é¥°ç¬¦åŒ…æ‹¬ï¼š\niï¼šå¿½ç•¥å¤§å°å†™ã€‚ä¾‹å¦‚ï¼Œ/abc/i åŒ¹é… ABC. gï¼šå…¨å±€åŒ¹é…ï¼ŒæŸ¥æ‰¾æ‰€æœ‰åŒ¹é…é¡¹ã€‚ mï¼šå¤šè¡Œæ¨¡å¼ï¼Œ^ å’Œ $ åŒ¹é…æ¯è¡Œçš„å¼€å¤´å’Œç»“å°¾ã€‚ æ³¨æ„ï¼š ä¿®é¥°ç¬¦çš„å†™æ³•å› è¯­è¨€è€Œå¼‚ã€‚ä¾‹å¦‚ï¼Œåœ¨ JavaScript ä¸­ï¼Œä¿®é¥°ç¬¦å†™åœ¨æ­£åˆ™è¡¨è¾¾å¼å (å¦‚ /abc/gi) ï¼Œè€Œåœ¨ Python ä¸­é€šè¿‡ re.compile(pattern, re.IGNORECASE) æŒ‡å®šã€‚ 8. Common Application Examples ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„æ­£åˆ™è¡¨è¾¾å¼åº”ç”¨åœºæ™¯åŠå…¶ç¤ºä¾‹ï¼š\néªŒè¯é‚®ç®±æ ¼å¼: ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$ æå– URL: https?://[^\\s]+ éªŒè¯å¯†ç  (è‡³å°‘ 8 ä½ï¼ŒåŒ…å«å­—æ¯ã€æ•°å­—ã€ç‰¹æ®Šå­—ç¬¦): ^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[@$!%*?\u0026amp;])[A-Za-z\\d@$!%*?\u0026amp;]{8,}$ åŒ¹é…æ—¥æœŸæ ¼å¼ (YYYY-MM-DD): \\d{4}-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01]) ","permalink":"http://localhost:1313/blogs/productivity/regularexpression/","summary":"Regular Expression note.","title":"Regular Expression Rules"},{"content":"Visual Studio Code (VSCode) Common Shortcut Keys ä»¥ä¸‹å¿«æ·é”®æ¶µç›– æ–‡ä»¶æ“ä½œã€ä»£ç ç¼–è¾‘ã€å¯¼èˆªã€æœç´¢ã€è°ƒè¯• ç­‰é«˜é¢‘åœºæ™¯ã€‚\nFile \u0026amp; Editor Operations åŠŸèƒ½ Windows/Linux macOS æ–°å»ºæ–‡ä»¶ Ctrl + N Cmd + N æ‰“å¼€æ–‡ä»¶ Ctrl + O Cmd + O ä¿å­˜æ–‡ä»¶ Ctrl + S Cmd + S å¦å­˜ä¸º Ctrl + Shift + S Cmd + Shift + S å…³é—­å½“å‰æ ‡ç­¾ Ctrl + W Cmd + W é‡æ–°æ‰“å¼€å·²å…³é—­æ–‡ä»¶ Ctrl + Shift + T Cmd + Shift + T æ‹†åˆ†ç¼–è¾‘å™¨ (åˆ†å±) Ctrl + \\ Cmd + \\ åˆ‡æ¢ç¼–è¾‘å™¨ç»„ Ctrl + 1/2/3 Cmd + 1/2/3 Code Edition åŠŸèƒ½ Windows/Linux macOS å¤åˆ¶å½“å‰è¡Œ Ctrl + C (ä¸é€‰ä¸­å†…å®¹æ—¶) Cmd + C å‰ªåˆ‡å½“å‰è¡Œ Ctrl + X (ä¸é€‰ä¸­å†…å®¹æ—¶) Cmd + X åˆ é™¤å½“å‰è¡Œ Ctrl + Shift + K Cmd + Shift + K ä¸Šä¸‹ç§»åŠ¨è¡Œ Alt + â†‘/â†“ Option + â†‘/â†“ å¿«é€Ÿå¤åˆ¶è¡Œ Shift + Alt + â†‘/â†“ Shift + Option + â†‘/â†“ è·³è½¬åˆ°åŒ¹é…æ‹¬å· Ctrl + Shift + \\ Cmd + Shift + \\ ä»£ç æ ¼å¼åŒ– Shift + Alt + F Shift + Option + F è¡Œæ³¨é‡Š/å–æ¶ˆæ³¨é‡Š Ctrl + / Cmd + / å—æ³¨é‡Š Shift + Alt + A Shift + Option + A Cusor Operations åŠŸèƒ½ Windows/Linux macOS å¤šå…‰æ ‡ç¼–è¾‘ Alt + å•å‡» Option + å•å‡» å‘ä¸‹å¤šå…‰æ ‡ Ctrl + Alt + â†“ Cmd + Option + â†“ å‘ä¸Šå¤šå…‰æ ‡ Ctrl + Alt + â†‘ Cmd + Option + â†‘ é€‰ä¸­å½“å‰å•è¯ Ctrl + D Cmd + D é€‰ä¸­æ‰€æœ‰åŒ¹é…é¡¹ Ctrl + Shift + L Cmd + Shift + L è·³è½¬åˆ°è¡Œé¦–/è¡Œå°¾ Home / End Cmd + â† / Cmd + â†’ Search \u0026amp; Substitution åŠŸèƒ½ Windows/Linux macOS å…¨å±€æœç´¢ Ctrl + Shift + F Cmd + Shift + F æ–‡ä»¶å†…æœç´¢ Ctrl + F Cmd + F æ–‡ä»¶å†…æ›¿æ¢ Ctrl + H Cmd + Option + F è·³è½¬åˆ°ç¬¦å· (å‡½æ•°/ç±») Ctrl + Shift + O Cmd + Shift + O è·³è½¬åˆ°è¡Œå· Ctrl + G Ctrl + G Debug \u0026amp; Terminal åŠŸèƒ½ Windows/Linux macOS å¯åŠ¨è°ƒè¯• F5 F5 åˆ‡æ¢æ–­ç‚¹ F9 F9 æ‰“å¼€ç»ˆç«¯ Ctrl + `` Ctrl + `` åˆ‡æ¢ç»ˆç«¯é¢æ¿ Ctrl + J Cmd + J Other Efficient Operation åŠŸèƒ½ Windows/Linux macOS å‘½ä»¤é¢æ¿ (ä¸‡èƒ½å¿«æ·é”®) Ctrl + Shift + P Cmd + Shift + P å¿«é€Ÿæ‰“å¼€æ–‡ä»¶ Ctrl + P Cmd + P é‡å‘½åç¬¦å· (å˜é‡/å‡½æ•°) F2 F2 æŠ˜å /å±•å¼€ä»£ç å— Ctrl + Shift + [ / ] Cmd + Option + [ / ] æŠ˜å æ‰€æœ‰åŒºåŸŸ Ctrl + K, Ctrl + 0 Cmd + K, Cmd + 0 å±•å¼€æ‰€æœ‰åŒºåŸŸ Ctrl + K, Ctrl + J Cmd + K, Cmd + J Customized Shortcut Keys æ‰“å¼€å‘½ä»¤é¢æ¿ï¼šCtrl + Shift + P (Win/Linux) / Cmd + Shift + P (Mac). æœç´¢ Preferences: Open Keyboard Shortcuts. ä¿®æ”¹æˆ–ç»‘å®šä»»æ„å¿«æ·é”®ã€‚ ","permalink":"http://localhost:1313/blogs/productivity/vscode_commands/","summary":"Useful VSCode Shortcut keys","title":"ğŸ”‘ Useful VSCode Shortcut keys"},{"content":"Preliminary æœ¬èŠ‚å…ˆå›é¡¾æµæ°´çº¿å¹¶è¡Œä»¥åŠ DeepSeek-V3 ä¸­ä½œä¸º baseline çš„ PipeDream è®ºæ–‡ä¸­çš„ 1F1B å’Œ ZeroBubble è®ºæ–‡ä¸­çš„ ZB1P (ZB-H1 çš„è‡ªåŠ¨æœç´¢ç»“æœ).\nPipeDream 1F1B 1F1B (One-Forward-One-Backward) çš„å·¥ä½œæµç¨‹å¦‚å›¾æ‰€ç¤ºï¼Œæƒ³è±¡ä¸€æ¡å·¥å‚æµæ°´çº¿ï¼Œç”¨äºç»„è£…ä¸€ä¸ªå¤æ‚çš„è®¾å¤‡ã€‚è¿™ä¸ªè®¾å¤‡éœ€è¦ç»è¿‡å¤šä¸ªå·¥ä½ï¼ˆGPUï¼‰ï¼Œæ¯ä¸ªå·¥ä½è´Ÿè´£ä¸€éƒ¨åˆ†è£…é…ä»»åŠ¡ï¼ˆæ¨¡å‹çš„ä¸åŒå±‚ï¼‰ã€‚å½“ç¬¬ä¸€ä¸ªäº§å“çš„ç¬¬ä¸€ä¸ªéƒ¨ä»¶åœ¨å·¥ä½1ä¸ŠåŠ å·¥æ—¶ï¼Œå…¶ä»–æ‰€æœ‰å·¥ä½éƒ½åœ¨é—²ç½®ç­‰å¾…ã€‚å½“å®ƒè¢«ä¼ é€’åˆ°å·¥ä½2æ—¶ï¼Œå·¥ä½1å¼€å§‹åŠ å·¥ç¬¬äºŒä¸ªäº§å“ï¼Œä½†å·¥ä½3ã€4â€¦ä¾ç„¶åœ¨ç­‰å¾…ã€‚è¿™ç§åœ¨æµæ°´çº¿å¯åŠ¨å’Œç»“æŸé˜¶æ®µäº§ç”Ÿçš„è®¾å¤‡ç©ºé—²æ—¶é—´ï¼Œå°±æ˜¯æµæ°´çº¿æ°”æ³¡ (Pipeline Bubble). åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­ï¼Œè¿™æ„å‘³ç€ GPU ç®—åŠ›è¢«æµªè´¹ï¼Œç›´æ¥å¯¼è‡´è®­ç»ƒæ—¶é—´å»¶é•¿å’Œæˆæœ¬å¢åŠ ã€‚\n1F1B pipeline Schedule\nåç»­æ‰¹æ¬¡çš„åå‘ä¼ æ’­æ°¸è¿œåœ¨å‰ä¸€æ‰¹æ¬¡çš„åå‘ä¼ æ’­å…¨éƒ¨å¯åŠ¨åæ‰å¼€å§‹ï¼Œä¸ºäº†é˜²æ­¢æ¿€æ´»å ç”¨å†…å­˜è¿‡å¤šï¼Œå›¾ä¸­ 1F1B çš„ bs=8ï¼Œæµæ°´çº¿å¹¶è¡Œè¿‡ç¨‹ä¸­æœ€å¤šä¿å­˜ 4 ä¸ª batch çš„æ¿€æ´»ï¼Œå½“ batch1 åå‘ä¼ æ’­ç»“æŸåå†è¿›è¡Œ batch5 çš„æ­£å‘ä¼ æ’­ã€‚ä¸ºäº†å‡å°‘æ¿€æ´»å ç”¨ï¼Œ1F1B ä¸­è¿›è¡Œåå‘ä¼ æ’­çš„ä¼˜å…ˆçº§é«˜äºæ­£å‘ä¼ æ’­ã€‚\nZeroBubble ZB1P ZeroBubble å‡å°‘æ°”æ³¡çš„å…³é”®æ˜¯å°†åå‘ä¼ æ’­ä¸­å¯¹äºæƒé‡å’Œè¾“å…¥çš„æ¢¯åº¦è®¡ç®—åˆ†å¼€è¿›è¡Œã€‚ä¼ ç»Ÿä¸Šï¼Œä¸€ä¸ªå±‚çš„åå‘ä¼ æ’­åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒä»»åŠ¡:\nB Pass: è®¡ç®—å…³äºè¾“å…¥æ¢¯åº¦å¹¶å°†å…¶ä¼ é€’ç»™å‰ä¸€å±‚ï¼Œè¿™æ˜¯è¯¯å·®åå‘ä¼ æ’­é“¾çš„ä¸€éƒ¨åˆ†ã€‚ W Pass: è®¡ç®—è¯¥å±‚è‡ªèº«æƒé‡çš„æ¢¯åº¦ï¼Œç”¨äºåç»­çš„å‚æ•°æ›´æ–°ã€‚ å¦‚å›¾æ‰€ç¤ºç¬¬ i-1 å±‚çš„ B Pass ä¾èµ–äºç¬¬ i å±‚çš„ B Pass. ä½†ç¬¬ i å±‚çš„ W Passï¼Œåªè¦åœ¨å…¶ B Pass å®Œæˆä¹‹åï¼Œå¯ä»¥è¢«çµæ´»åœ°å®‰æ’åœ¨ä»»ä½•æ—¶é—´ç‚¹æ‰§è¡Œã€‚\nComputation Graph for MLP Handcrafted Pipeline Schedule\nåŸºäºè¿™ä¸ªæ€æƒ³ï¼Œæ–‡ä¸­æå‡ºäº†ä¸¤ä¸ªæ‰‹å·¥è®¾è®¡çš„è°ƒåº¦æ–¹æ¡ˆä½œä¸ºæ¦‚å¿µéªŒè¯:\nZB-H1 (Memory Efficient Schedule): åœ¨ç»´æŒä¸ 1F1B ç›¸ä¼¼å³°å€¼å†…å­˜æ¶ˆè€—çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å°† W Pass æ¨è¿Ÿæ‰§è¡Œï¼Œå¡«å……äº†æµæ°´çº¿æœ«å°¾çš„ cooldown æ°”æ³¡ï¼ŒæˆåŠŸå°†æ°”æ³¡å¤§å°å‡å°‘åˆ° 1F1B çš„ä¸‰åˆ†ä¹‹ä¸€ã€‚ ZB-H2 (Zero Bubble Schedule): å½“å†…å­˜é¢„ç®—æ›´å®½æ¾æ—¶ï¼Œåœ¨æµæ°´çº¿ warm-up å®‰æ’æ›´å¤šçš„ F Passï¼Œå¹¶å·§å¦™åœ°é‡æ’ W Passï¼Œå°†æ•´ä¸ªæµæ°´çº¿çš„æ‰§è¡Œè¿‡ç¨‹ä»ä¸€ä¸ªæ¢¯å½¢å˜æˆäº†ä¸€ä¸ªå¹³è¡Œå››è¾¹å½¢ï¼Œä»è€Œåœ¨ç†è®ºä¸Šå®Œå…¨æ¶ˆé™¤äº†æ°”æ³¡ã€‚ Handcrafted pipeline schedules ZB-H1 (top) \u0026amp; ZB-H2 (bottom)\næ–‡ä¸­åŸºäºä¸€ä¸ªæ ‡å‡†çš„ Transformeræ¶æ„ï¼Œå…¶ä¸­ FFN çš„ä¸­é—´å±‚ç»´åº¦æ˜¯æ¨¡å‹éšè—ç»´åº¦ h çš„4å€ã€‚ç»™å‡ºäº† F, B, W å„è‡ªçš„è®¡ç®—é‡å’Œæ¿€æ´»å ç”¨ã€‚å…¶ä¸­è®¡ç®—é‡åªç»Ÿè®¡å æ®ä¸»è¦éƒ¨åˆ†çš„çŸ©é˜µä¹˜æ³•çš„æµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚\nb: microbatch size s: sequence length h: hidden dimension size a: number of attention heads Transformer Architecture Table1: FLOPs and activations memory required per transformer layer for each pass\nPass FLOPs Activations Memory Required F $sbh(24h+4s)$ 0 B $sbh(24h+8s)$ $sb(34h+5as)$ W $sbh(24h)$ $32sbh$ å‰å‘ä¼ æ’­ $T_F \\approx (8bsh^2 + 4bs^2h) + 16bsh^2 = 24bsh^2 + 4bs^2h = sbh(24h + 4s)$. åå‘ä¼ æ’­å…³äºæƒé‡çš„è®¡ç®—é‡ç­‰äº Linear å±‚çš„ GEMM.\nSelf-Attention: $6bsh^2 + 2bs^2h + 2bs^2h + 2bsh^2 = 8bsh^2 + 4bs^2h$\nQ, K, V Projectionï¼šè¾“å…¥ (b, s, h) é€šè¿‡ä¸æƒé‡çŸ©é˜µ (h, h) ç›¸ä¹˜ï¼Œç”ŸæˆQ, K, Vã€‚è¿™æ¶‰åŠåˆ°3æ¬¡çŸ©é˜µä¹˜æ³•ã€‚$\\text{FLOPs} \\approx 2 \\times b \\times s \\times h \\times 3h = 6bsh^2$ Attention Score:Q (b, a, s, h/a) ä¸ K^T (b, a, h/a, s) ç›¸ä¹˜ã€‚$\\text{FLOPs} \\approx 2 \\times b \\times a \\times s \\times (h/a) \\times s = 2bshs$. Score@Vï¼šæ³¨æ„åŠ›åˆ†æ•° (b, a, s, s) ä¸ V (b, a, s, h/a) ç›¸ä¹˜ã€‚$\\text{FLOPs} \\approx 2 \\times b \\times a \\times s \\times s \\times (h/a) = 2bshs$. O Projecyionï¼šç»“æœä¸è¾“å‡ºæƒé‡çŸ©é˜µ (h, h) ç›¸ä¹˜ã€‚$\\text{FLOPs} \\approx 2 \\times b \\times s \\times h \\times h = 2bsh^2$. FFN FLOPs: $8bsh^2 + 8bsh^2 = 16bsh^2$\nUp Projectionï¼šè¾“å…¥ (b, s, h) ä¸æƒé‡çŸ©é˜µ (h, 4h) ç›¸ä¹˜ã€‚$\\text{FLOPs} \\approx 2 \\times b \\times s \\times h \\times 4h = 8bsh^2$. Down Projectionï¼šä¸­é—´ç»“æœ (b, s, 4h) ä¸æƒé‡çŸ©é˜µ (4h, h) ç›¸ä¹˜ã€‚$\\text{FLOPs} \\approx 2 \\times b \\times s \\times 4h \\times h = 8bsh^2$. æ¿€æ´»å ç”¨æ–¹é¢é™¤äº† Dropout Mask æ˜¯ INT8 ç±»å‹ä»¥å¤–ï¼Œå‡è®¾ activations å‡ä»¥ 16-bit float ç±»å‹ä¿å­˜ã€‚è¡¨ä¸­çš„ activation memory å‡ä»¥å­—èŠ‚ä¸ºå•ä½è¿›è¡Œç»Ÿè®¡ã€‚å’Œæƒé‡æ¢¯åº¦æ— å…³çš„éƒ¨åˆ†åªæœ‰ dropout ç›¸å…³çš„ä»¥åŠ Softmax output.\nCategory Item Original TP Attention Total $11sbh + 5as^2b$ $3sbh + \\frac{8sbh}{t} + \\frac{5as^2b}{t}$ QKV input $2sbh$ $2sbh$ QK^T $4sbh$ $\\frac{4sbh}{t}$ Softmax output $2as^2b$ $\\frac{2as^2b}{t}$ Dropout mask $as^2b$ $\\frac{as^2b}{t}$ Dropout output $2as^2b$ $\\frac{2as^2b}{t}$ V $2sbh$ $\\frac{2sbh}{t}$ Linear projection input $2sbh$ $\\frac{2sbh}{t}$ Attention dropout mask $sbh$ $sbh$ MLP Total $19sbh$ $3sbh + \\frac{16sbh}{t}$ Linear1 input $2sbh$ $2sbh$ GeLU input $8sbh$ $\\frac{8sbh}{t}$ Linear2 input $8sbh$ $\\frac{8sbh}{t}$ Dropout mask $sbh$ $sbh$ LayerNorm Total $4sbh$ $4sbh$ LayerNorm1 input $2sbh$ $2sbh$ LayerNorm2 input $2sbh$ $2sbh$ åœ¨æ²¡æœ‰ $T_F = T_B = T_W$ å‡è®¾çš„æƒ…å†µä¸‹ï¼ŒZB-H1 å’Œ ZB-H2 çš„å³°å€¼æ¿€æ´»å†…å­˜å’Œæ°”æ³¡å¤§å°å¦‚ Table 2 æ‰€ç¤ºã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¯¹äºè®¾å¤‡ iï¼Œå…¶åœ¨ ZB-H1 æ–¹æ¡ˆä¸‹çš„æ¿€æ´»å†…å­˜ä¸º $(p-i+1)M_B + (i-1)M_W$ï¼Œåœ¨ ZB-H2 æ–¹æ¡ˆä¸‹çš„æ¿€æ´»å†…å­˜ä¸º $(2p - 2i + 1)M_B + (2i - 2)M_W$ã€‚å¦‚ Table 1 æ‰€ç¤ºï¼ŒW æ‰€éœ€çš„æ¿€æ´»å†…å­˜å°äº B æ‰€éœ€çš„æ¿€æ´»å†…å­˜ã€‚å› æ­¤ï¼ŒZB-H1 å’Œ ZB-H2 çš„å³°å€¼æ¿€æ´»å†…å­˜åˆ†åˆ«ä¸º $pM_B$ å’Œ $(2p-1)M_B$ã€‚\nTable 2: Comparison between 1F1B and our handcrafted schedules.\nSchedule Bubble size Peak activations memory 1F1B $(p-1)(T_{F}+T_{B}+T_{W})$ $pM_{B}$ ZB-H1 $(p-1)(T_{F}+T_{B}-T_{W})$ $pM_{B}$ ZB-H2 $(p-1)(T_{F}+T_{B}-2T_{W})$ $(2p-1)M_{B}$ Automatic Pipeline Scheduling\næ‰‹å·¥è°ƒåº¦ä¾èµ–äº Fã€Bã€W çš„æ‰§è¡Œæ—¶é—´ç›¸ç­‰çš„ç†æƒ³æƒ…å†µã€‚ä¸ºäº†åº”å¯¹çœŸå®ä¸–ç•Œä¸­å¤æ‚çš„æ‰§è¡Œæ—¶é—´å’Œé€šä¿¡å»¶è¿Ÿï¼Œè¯¥æ–‡å¼€å‘äº†ä¸€ä¸ªè‡ªåŠ¨åŒ–æµæ°´çº¿è°ƒåº¦ç®—æ³•ã€‚è¯¥ç®—æ³•é€šè¿‡ä¸€ç³»åˆ—å¯å‘å¼ç­–ç•¥ï¼Œåœ¨ä¸€ä¸ªç»™å®šçš„å†…å­˜é™åˆ¶ä¸‹ï¼Œè‡ªåŠ¨åœ°ä¸ºæµæ°´çº¿ç”Ÿæˆä¸€ä¸ªé«˜æ•ˆçš„è°ƒåº¦æ–¹æ¡ˆã€‚æ ¸\nWarm-upï¼š\nåœ¨å†…å­˜é™åˆ¶çš„èŒƒå›´å†…ï¼Œç®—æ³•ä¼šå°½å¯èƒ½å¤šåœ°è°ƒåº¦ F pass ï¼Œä»¥æœ€å°åŒ–åœ¨ç¬¬ä¸€ä¸ª B pass å¼€å§‹å‰äº§ç”Ÿçš„æ°”æ³¡ã€‚ æ­¤é˜¶æ®µä½¿ç”¨ä¸€ä¸ªè¶…å‚æ•°æ¥æ§åˆ¶æ˜¯å¦è¦è°ƒåº¦ä¸€ä¸ªå¯èƒ½ä¼šå»¶è¿Ÿåç»­B Passçš„é¢å¤–F Passã€‚ Steady Stateï¼š\nçƒ­èº«é˜¶æ®µç»“æŸåï¼Œè°ƒåº¦è¿›å…¥ä¸€ä¸ªè¿­ä»£æ¨¡å¼ï¼Œè½®æµè°ƒåº¦ä¸€ä¸ªF Passå’Œä¸€ä¸ªB Passã€‚ ä¸ºäº†å¡«å……æ°”æ³¡ï¼Œç®—æ³•ä¼šä¼ºæœºæ’å…¥ W pass. æ’å…¥ç­–ç•¥æ˜¯ï¼š å½“å‡ºç°ä¸€ä¸ªå¤§äº $T_W$ (W Pass æ‰§è¡Œæ—¶é—´) çš„æ°”æ³¡æ—¶ï¼Œç›´æ¥æ’å…¥ä¸€ä¸ªW Pass. å½“å‡ºç°ä¸€ä¸ªå°äº $T_W$ çš„æ°”æ³¡æ—¶ï¼Œå¦‚æœè¿™ä¸ªæ°”æ³¡ä¼šå¯¼è‡´å½“å‰é˜¶æ®µçš„ç´¯è®¡æ°”æ³¡æ—¶é—´æˆä¸ºæ‰€æœ‰é˜¶æ®µä¸­æœ€é•¿çš„ï¼Œé‚£ä¹ˆä»ç„¶ä¼šæ’å…¥ä¸€ä¸ªW Pass. å½“å†…å­˜è¾¾åˆ°ä¸Šé™æ—¶ï¼Œä¹Ÿä¼šæ’å…¥ W Pass ä»¥å›æ”¶å’Œé‡Šæ”¾éƒ¨åˆ†å†…å­˜ã€‚ é€šå¸¸è¿™ä¸ªå¯å‘å¼ç­–ç•¥åœ¨ç¨³æ€é˜¶æ®µä¼šå½¢æˆä¸€ä¸ª 1F-1B-1W çš„è°ƒåº¦æ¨¡å¼ã€‚ Global Scheduleï¼š\nåœ¨æ•´ä¸ªè°ƒåº¦è¿‡ç¨‹ä¸­ï¼Œç®—æ³•å§‹ç»ˆä¿è¯åœ¨ F Pass ç”¨å®Œä¹‹å‰ï¼Œç¬¬ i é˜¶æ®µè°ƒåº¦çš„ F Pass æ•°é‡è‡³å°‘æ¯”ç¬¬ i+1 é˜¶æ®µå¤šä¸€ä¸ªã€‚ å½“è¿™ä¸ªæ•°é‡å·®è¶…è¿‡ä¸€æ—¶ï¼Œä¼šä½¿ç”¨å¦ä¸€ä¸ªè¶…å‚æ•°æ¥å†³å®šåœ¨ä¸äº§ç”Ÿé¢å¤–æ°”æ³¡çš„å‰æä¸‹ï¼Œæ˜¯å¦è¦è·³è¿‡ç¬¬ i é˜¶æ®µçš„ä¸€æ¬¡F Passè°ƒåº¦ã€‚ ç®—æ³•ä¼šé€šè¿‡ grid search æ¥å¯»æ‰¾è¿™äº›è¶…å‚æ•°çš„æœ€ä½³ç»„åˆã€‚ Finalï¼šå½“æŸä¸ªé˜¶æ®µçš„ F Pass å’Œ B Pass éƒ½æ‰§è¡Œå®Œæ¯•åï¼Œç®—æ³•ä¼šä¸€æ¬¡æ€§é€ä¸ªè°ƒåº¦å®Œæ‰€æœ‰å‰©ä½™çš„ W Pass.\nBypassing Optimizer Synchronization\nè¦å®ç°å®Œç¾çš„å¹³è¡Œå››è¾¹å½¢è°ƒåº¦ï¼Œè¿˜éœ€è¦è§£å†³ä¼˜åŒ–å™¨åŒæ­¥ï¼ˆOptimizer Synchronizationï¼‰. åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œé€šå¸¸éœ€è¦åœ¨æ›´æ–°æ¨¡å‹å‚æ•°å‰ï¼Œåœ¨æ‰€æœ‰ GPU é—´è¿›è¡Œä¸€æ¬¡ All-Reduceï¼Œä»¥è¿›è¡Œæ¢¯åº¦è£å‰ªï¼ˆGradient Clippingï¼‰æˆ–æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§ (NaN/INF). è¿™ä¸ªåŒæ­¥ç‚¹ä¼šå¼ºåˆ¶æ‰€æœ‰è®¾å¤‡ç­‰å¾…ï¼Œä»è€Œç ´åå¹³è¡Œå››è¾¹å½¢ï¼Œé‡æ–°å¼•å…¥æ°”æ³¡ã€‚\nè®ºæ–‡æå‡ºäº† Bypassing Optimizer Synchronizationï¼Œæ¯ä¸ª GPU åœ¨æ‰§è¡Œä¼˜åŒ–å™¨æ›´æ–°æ­¥éª¤æ—¶ï¼Œä¸å†ç­‰å¾…å…¨å±€åŒæ­¥ï¼Œè€Œæ˜¯åŸºäºä»å‰ä¸€ä¸ª GPU ä¼ æ¥çš„éƒ¨åˆ† reduce çš„ä¿¡æ¯è¿›è¡Œæ¨æµ‹æ€§æ›´æ–°ã€‚è¯¥ micro-batch å®Œæ•´çš„å…¨å±€çŠ¶æ€ä¼šåœ¨ä¸‹ä¸€ä¸ªè¿­ä»£çš„ warp é˜¶æ®µå¼‚æ­¥åœ°ä¼ å›ã€‚æ¯ä¸ª GPU åœ¨æ”¶åˆ°æœ€ç»ˆçš„å…¨å±€çŠ¶æ€åï¼Œä¼šéªŒè¯è‡ªå·±ä¸Šä¸€æ­¥çš„æ›´æ–°æ˜¯å¦åˆæ³•ã€‚å¦‚æœå‘ç°ä¸ä¸€è‡´ï¼ˆä¾‹å¦‚ï¼Œå…¨å±€æ¢¯åº¦èŒƒæ•°è¶…å‡ºäº†è£å‰ªé˜ˆå€¼ï¼‰ï¼Œå®ƒä¼šæ‰§è¡Œä¸€æ¬¡åŸåœ°å›æ»šï¼ˆIn-place Rollbackï¼‰ï¼Œç„¶åä½¿ç”¨æ­£ç¡®çš„å…¨å±€çŠ¶æ€é‡æ–°æ‰§è¡Œä¼˜åŒ–å™¨æ­¥éª¤ã€‚\nThe Post-validation Strategy to Replace Optimizer Synchronization\nDualPipe DualPipe æ˜¯ä¸€ç§åˆ›æ–°çš„åŒå‘æµæ°´çº¿å¹¶è¡Œç®—æ³•ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨ä¸€ç»„è®¾å¤‡ä¸ŠåŒæ—¶å¤„ç†ä¸¤ä¸ªæ–¹å‘çš„æ•°æ®æµï¼šä¸€ä¸ªå‰å‘æµæ°´çº¿å’Œä¸€ä¸ªåå‘æµæ°´çº¿ã€‚ä½¿å¾—è®¡ç®—å’Œé€šä¿¡èƒ½å¤Ÿæ›´å……åˆ†åœ°é‡å ï¼Œä»è€Œå‡å°‘æµæ°´çº¿æ°”æ³¡ï¼ˆå³ GPU ç©ºé—²æ—¶é—´ï¼‰.\nä¸ä¼ ç»Ÿçš„ GPipeï¼ˆ1F1Bï¼‰åªæœ‰ä¸€ä¸ªæ•°æ®æµæ–¹å‘ä¸åŒï¼ŒDualPipe å°†è®¾å¤‡å¯¹æŠ˜ï¼Œå½¢æˆä¸¤æ¡å¯¹ç§°çš„æµæ°´çº¿ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªæœ‰ 8 ä¸ª PP ranks (GPU) çš„è®¾ç½®ä¸­ï¼š\nå‰å‘æµæ°´çº¿ (Forward Pipeline): æ•°æ®ä» rank 0 -\u0026gt; 1 -\u0026gt; 2 -\u0026gt; 3. åå‘æµæ°´çº¿ (Backward Pipeline): åŒæ—¶æœ‰å¦ä¸€ç»„æ•°æ®ä» rank 7 -\u0026gt; 6 -\u0026gt; 5 -\u0026gt; 4. Rank 3 å’Œ Rank 4 æˆä¸ºä¸¤æ¡æµæ°´çº¿çš„ä¸­é—´èŠ‚ç‚¹ï¼Œå®ƒä»¬ä¹‹é—´ä¼šäº¤æ¢æ•°æ®ã€‚æ¯ä¸ªè®¾å¤‡å®é™…ä¸Šä¼šå¤„ç†ä¸¤ä¸ªæµæ°´çº¿é˜¶æ®µçš„æ¨¡å‹å—ï¼Œä¸€ä¸ªç”¨äºå‰å‘æµæ°´çº¿ï¼Œå¦ä¸€ä¸ªç”¨äºåå‘æµæ°´çº¿ã€‚ Initialization modules: æ¯ä¸ª DualPipe å®ä¾‹æ¥æ”¶ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ä¸¤ä¸ª nn.Module. modules[0] ç”¨äºå¤„ç†å‰å‘-\u0026gt;åå‘çš„è®¡ç®—ï¼Œmodules[1] ç”¨äºå¤„ç†åå‘-\u0026gt;å‰å‘çš„è®¡ç®—ã€‚ Rank è§’è‰²åˆ¤æ–­: ä»£ç ä¼šæ ¹æ®å½“å‰ rank çš„ ID åˆ¤æ–­å…¶åœ¨æ•´ä¸ªæµæ°´çº¿ä¸­çš„ä½ç½®ï¼ˆæ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ªã€æœ€åä¸€ä¸ªã€æ˜¯å¦åœ¨ååŠéƒ¨åˆ†ã€æ˜¯å¦æ˜¯ä¸­é—´èŠ‚ç‚¹ï¼‰. è¿™ä¸ªè§’è‰²åˆ¤æ–­å¯¹äºåç»­çš„é€šä¿¡å’Œè®¡ç®—è°ƒåº¦è‡³å…³é‡è¦ã€‚ä¾‹å¦‚ is_in_second_half å†³å®šäº†è¯¥ rank çš„ phase 0 å’Œ phase 1 ç©¶ç«Ÿå¯¹åº”å‰å‘æµæ°´çº¿è¿˜æ˜¯åå‘æµæ°´çº¿ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class DualPipe(nn.Module): def __init__( self, modules: Tuple[nn.Module, nn.Module], # ... ) -\u0026gt; None: super().__init__() # æ¯ä¸ª rank æŒæœ‰ä¸¤ä¸ªæ¨¡å‹æ¨¡å— self.module = nn.ModuleList(modules) # ... self.group = process_group or dist.distributed_c10d._get_default_group() self.num_ranks = self.group.size() # ... # è®¡ç®—å½“å‰ rank åœ¨æµæ°´çº¿ä¸­çš„è§’è‰² self.rank = rank_mapping[self.group.rank()] self.is_first_rank = self.rank == 0 self.is_last_rank = self.rank == self.num_ranks - 1 # åˆ¤æ–­ rank æ˜¯å¦åœ¨å¯¹æŠ˜åçš„ååŠéƒ¨åˆ† self.is_in_second_half = self.rank \u0026gt;= self.num_ranks // 2 # åˆ¤æ–­æ˜¯å¦ä¸ºä¸­é—´çš„ rank self.is_middle_rank = (self.rank == self.num_ranks // 2 - 1) or (self.rank == self.num_ranks // 2) Core Function: step step æ–¹æ³•æ˜¯ DualPipe çš„æ ¸å¿ƒï¼Œå®ƒåè°ƒäº†æ‰€æœ‰ micro-batches çš„è®¡ç®—å’Œé€šä¿¡ã€‚æ•´ä¸ªè¿‡ç¨‹è¢«åˆ’åˆ†ä¸º 8 ä¸ªé˜¶æ®µï¼Œä»¥å®ç°æœ€å¤§ç¨‹åº¦çš„è®¡ç®—-é€šä¿¡é‡å ã€‚\nè¾“å…¥å¤„ç†: åªæœ‰ rank 0 å’Œ rank N-1 ä¼šæ¥æ”¶å¤–éƒ¨è¾“å…¥æ•°æ® inputs å’Œ labels. è¿™äº›æ•°æ®è¢« scatter (dualpipe/utils.py) åˆ‡åˆ†æˆ half_num_chunk ä¸ª micro-batch ã€‚Rank 0 çš„è¾“å…¥ç”¨äºå‰å‘æµæ°´çº¿ï¼ŒRank N-1 çš„è¾“å…¥ç”¨äºåå‘æµæ°´çº¿ã€‚\ndef step( self, *inputs: Optional[torch.Tensor], num_chunks: int = 0, # ... ) -\u0026gt; Tuple[Optional[torch.Tensor], Optional[Union[torch.Tensor, Tuple[torch.Tensor]]]]: # ... # é‡ç½®çŠ¶æ€ self._reset_states() # å°†è¾“å…¥æ•°æ®åˆ‡åˆ†æˆ micro-batch inputs = scatter(inputs, half_num_chunks, self.batch_dim) labels = scatter(labels, half_num_chunks, self.batch_dim) if self.is_first_rank: self.input_chunks = (inputs, []) self.labels = ([], labels) elif self.is_last_rank: self.input_chunks = ([], inputs) self.labels = (labels, []) # ... æ¥ä¸‹æ¥æ˜¯ 8 ä¸ªæ ¸å¿ƒè°ƒåº¦é˜¶æ®µçš„ï¼Œåœ¨æ­¤ä¹‹å‰ä¼šè¿›è¡Œä¸€äº›å‡†å¤‡å·¥ä½œï¼š\nçŠ¶æ€é‡ç½®: _reset_states() æ¸…ç©ºä¸Šä¸€è½®è¿­ä»£çš„ç¼“å­˜ï¼Œå¦‚è¾“å…¥/è¾“å‡ºå—ã€æ¢¯åº¦ã€æŸå¤±ç­‰ã€‚ rank ç¡®å®š: è®¡ç®— num_half_ranksï¼ˆæµæ°´çº¿å¯¹æŠ˜åçš„ä¸€åŠè®¾å¤‡æ•°ï¼‰å’Œ half_rankï¼ˆå½“å‰ç§©åœ¨å¯¹æŠ˜æµæ°´çº¿ä¸­çš„ä½ç½®. è¿™äº›å˜é‡å°†å†³å®šæ¯ä¸ªé˜¶æ®µçš„å¾ªç¯æ¬¡æ•°ã€‚ æ•°æ®åˆ†å‘: scatter å‡½æ•°å°†è¾“å…¥æ•°æ® inputs å’Œ labels åˆ‡åˆ†æˆ half_num_chunks ä¸ª micro-batch ã€‚æ ¹æ® is_first_rank æˆ– is_last_rankï¼Œå°†è¿™äº› micro-batch å­˜æ”¾åˆ° self.input_chunks å’Œ self.labels ä¸­ã€‚ è°ƒåº¦ç¤ºæ„å›¾å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œçº¢è‰²çº¿åˆ†éš”äº†æ¯ä¸ªæ­¥éª¤\nDualPipe Schedule\nStep 1: Warm-up Forward nF0\nè¿™æ˜¯ä¸€ä¸ªçº¯å‰å‘è®¡ç®—é˜¶æ®µï¼Œç”¨äºå¡«æ»¡æµæ°´çº¿ã€‚è·ç¦»æµæ°´çº¿ä¸­ç‚¹è¶Šè¿œçš„ rankï¼ˆhalf_rank è¶Šå°ï¼‰æ‰§è¡Œçš„é¢„çƒ­æ­¥éª¤è¶Šå¤šã€‚ _forward_chunk(0) è¢«è°ƒç”¨ï¼Œåœ¨æ­¤å‡½æ•°å†…éƒ¨:\n_recv_forward(0): å°è¯•æ¥æ”¶å‰ä¸€ä¸ª rank çš„æ•°æ®ã€‚å¯¹äº rank 0 æ¥è¯´ï¼Œå®ƒç›´æ¥ä½¿ç”¨ self.input_chunks çš„æ•°æ®ï¼Œä¸æ¥æ”¶ã€‚ _commit_and_wait_comm(): ç­‰å¾…æ•°æ®æ¥æ”¶å®Œæˆã€‚ _forward_compute_chunk(0): æ‰§è¡Œ self.module[0] çš„å‰å‘è®¡ç®—ã€‚ _send_forward(0): å°†è®¡ç®—ç»“æœå¼‚æ­¥åœ°å‘é€ç»™ä¸‹ä¸€ä¸ª rank. 1 2 3 step_1 = (num_half_ranks - half_rank - 1) * 2 for i in range(step_1): self._forward_chunk(0) Step 2: Dual Forward nF0F1\nä¸¤æ¡æµæ°´çº¿éƒ½å¼€å§‹æ‰§è¡Œå‰å‘è®¡ç®—ã€‚ä¸¤æ¡æµæ°´çº¿éƒ½å¼€å§‹å·¥ä½œã€‚å½“å‰ rank ä¸ä»…ç»§ç»­å¤„ç† phase 0 çš„å‰å‘è®¡ç®—ï¼Œä¹Ÿå¼€å§‹å¤„ç†ä»å¦ä¸€ç«¯ï¼ˆphase 1ï¼‰ä¼ æ¥çš„æ•°æ®çš„å‰å‘è®¡ç®—ã€‚\n_forward_chunk(0, recv=False, ...) å¤„ç†ä¸€ä¸ª phase 0 çš„ micro-batch ï¼Œä½†ä¸ç«‹å³æ¥æ”¶ä¸‹ä¸€ä¸ªï¼Œå› ä¸ºå‰é¢å·²ç»è°ƒç”¨äº† _recv_forward(0). _forward_chunk(1, ...): å¤„ç†ä¸€ä¸ª phase 1 çš„ micro-batch ã€‚ 1 2 3 4 5 6 7 8 9 # Step 2: nF0F1 step_2 = half_rank + 1 self._recv_forward(0) for i in range(step_2): self._forward_chunk(0, recv=False, send=self.is_middle_rank) self._recv_forward(0) self._forward_chunk(1, send=(not self.is_middle_rank) or (i \u0026lt; step_2 - 1)) if not self.is_middle_rank: self._send_forward(0) Step 3: å‰å‘-åå‘-æƒé‡æ··åˆé˜¶æ®µ (Zero Bubble) nB1W1F1\nè¿™æ˜¯ DualPipe æé«˜æ•ˆç‡çš„å…³é”®ã€‚å½“ä¸€æ¡æµæ°´çº¿å¼€å§‹è¿›è¡Œåå‘è®¡ç®—æ—¶ï¼Œå¦ä¸€æ¡æµæ°´çº¿ä»åœ¨è¿›è¡Œå‰å‘è®¡ç®—ã€‚\n_backward_chunk(1, enable_zb=True): æ‰§è¡Œåå‘è®¡ç®—ï¼Œå¹¶å¯ç”¨ Zero Bubble (ZB) ä¼˜åŒ–ã€‚ZB é€šè¿‡ WeightGradStore å°†æƒé‡æ¢¯åº¦ï¼ˆweight gradientsï¼‰çš„è®¡ç®—ï¼ˆé€šå¸¸åœ¨åå‘ä¼ æ’­ä¸­é˜»å¡ï¼‰ç¼“å­˜èµ·æ¥ï¼Œæ¨è¿Ÿæ‰§è¡Œï¼Œä»è€Œè®©è·¯ç»™å…¶ä»–è®¡ç®—æˆ–é€šä¿¡ã€‚ _weight_chunk(): æ‰§è¡Œè¢«æ¨è¿Ÿçš„æƒé‡æ¢¯åº¦è®¡ç®—ã€‚ _forward_chunk(1): åŒæ—¶æ‰§è¡Œå¦ä¸€ä¸ªæ–¹å‘çš„å‰å‘è®¡ç®—ã€‚ # Step 3: nB1W1F1 (Use zero bubble) step_3 = num_half_ranks - half_rank - 1 for i in range(step_3): self._backward_chunk(1, enable_zb=True) self._recv_forward(1) self._weight_chunk() self._forward_chunk(1, recv=False) Step 4: Main Steady State nF0B1F1B0\nè¿™æ˜¯æµæ°´çº¿å®Œå…¨å¡«æ»¡åçš„ä¸»å¾ªç¯ã€‚åœ¨ä¸€ä¸ªå¾ªç¯è¿­ä»£ä¸­ï¼Œä¸€ä¸ª rank ä¼šæ‰§è¡Œä¸¤æ¬¡è®¡ç®—å’Œé€šä¿¡çš„é‡å æ“ä½œï¼šä¸€æ¬¡æ˜¯ï¼ˆå‰å‘è®¡ç®— + åå‘è®¡ç®—ï¼‰ï¼Œå¦ä¸€æ¬¡ä¹Ÿæ˜¯ï¼ˆå‰å‘è®¡ç®— + åå‘è®¡ç®—ï¼‰. è¿™é‡Œè°ƒç”¨ _forward_backward_chunk(0, 1) å’Œ _forward_backward_chunk(1, 0). è¿™ä¸ªå‡½æ•°å°è¯•å°†ä¸€ä¸ªæ–¹å‘çš„å‰å‘è®¡ç®—ï¼ˆFï¼‰ä¸å¦ä¸€ä¸ªæ–¹å‘çš„åå‘è®¡ç®—ï¼ˆBï¼‰æ‰“åŒ…åœ¨ä¸€èµ·æ‰§è¡Œï¼Œå®ç° F\u0026amp;B é‡å ã€‚\n# Step 4 (Main step): nF0B1F1B0 step_4 = half_num_chunks - num_ranks + half_rank + 1 for i in range(step_4): # ... self._forward_backward_chunk(0, 1) # i != 0 self._forward_backward_chunk(1, 0) Step 5 \u0026amp; 6: åå‘-åå‘æ··åˆé˜¶æ®µ (Cooldown Backward) nB1F1B0 å’Œ nB1B0\nå½“å‰å‘æ•°æ®æµè€—å°½åï¼Œæµæ°´çº¿è¿›å…¥æ”¶å°¾é˜¶æ®µã€‚è¿™ä¸ªé˜¶æ®µä¸»è¦æ‰§è¡Œå‰©ä½™çš„åå‘è®¡ç®—ã€‚åŒæ ·ï¼ŒZB ä¼˜åŒ–åœ¨ååŠæ®µè¢«å¯ç”¨ï¼Œä»¥å‡å°‘æ°”æ³¡ã€‚\n# Step 5: nB1F1B0 step_5 = num_half_ranks - half_rank - 1 for i in range(step_5): self._backward_chunk(1) self._forward_backward_chunk(1, 0) # Step 6: nB1B0 (The second half of the chunks use zero bubble) step_6 = half_rank + 1 enable_zb = False for i in range(step_6): if i == step_6 // 2 and half_rank % 2 == 1: enable_zb = True self._backward_chunk(1, enable_zb=enable_zb) if i == step_6 // 2 and half_rank % 2 == 0: enable_zb = True self._backward_chunk(0, enable_zb=enable_zb) Step 7 \u0026amp; 8: æƒé‡æ›´æ–°æ”¶å°¾é˜¶æ®µ nWB0 å’Œ nW\nStep 7 å°†æœ€åçš„åå‘è®¡ç®—ä¸æƒé‡è®¡ç®—é‡å ã€‚ Step 8 æ˜¯çº¯ç²¹çš„æƒé‡è®¡ç®—é˜¶æ®µï¼Œå¾ªç¯è°ƒç”¨ _weight_chunk() ç›´åˆ° WeightGradStore.funcs_queue é˜Ÿåˆ—ä¸ºç©ºï¼Œç¡®ä¿æ‰€æœ‰æ¢¯åº¦éƒ½å·²è®¡ç®—å®Œæ¯•ã€‚ # Step 7: nWB0 (Use zero bubble) step_7 = num_half_ranks - half_rank - 1 for i in range(step_7): self._weight_chunk() self._backward_chunk(0, enable_zb=True) # Step 8: nW step_8 = half_rank + 1 for i in range(step_8): self._weight_chunk() assert WeightGradStore.funcs_queue.empty() Computation-Communication Overlap _forward_backward_compute_chunk å‡½æ•°æ˜¯å®ç°è®¡ç®—é‡å çš„å…³é”®ã€‚åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼ˆå¦‚æœæ¨¡å‹ç»“æ„æ”¯æŒï¼‰ï¼Œå®ƒå¯ä»¥å°†ä¸€ä¸ª micro-batch çš„å‰å‘è®¡ç®—å’Œå¦ä¸€ä¸ª micro-batch çš„åå‘è®¡ç®—åœ¨åŒä¸€ä¸ªå‡½æ•°è°ƒç”¨ä¸­å®Œæˆã€‚è¯¥å‡½æ•°åœ¨ step4 ä½¿ç”¨çš„_forward_backward_chunk å‡½æ•°ä¸­è¢«è°ƒç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 def _forward_backward_compute_chunk(self, phase0: int, phase1: int) -\u0026gt; None: # ... if not self.overlapped_forward_backward: self._forward_compute_chunk(phase0) self._backward_compute_chunk(phase1) return # ... # forward \u0026amp; backward outputs0, loss0 = type(module0).overlapped_forward_backward( module0, inputs0, criterion0, labels0, module1, loss1, outputs1, output_grads1, ) # ... å¦‚æœæ¨¡å‹å®šä¹‰äº†ä¸€ä¸ª overlapped_forward_backward (@classmethod)ï¼ŒDualPipe å°±ä¼šè°ƒç”¨å®ƒã€‚åœ¨è¿™ä¸ªæ–¹æ³•é‡Œï¼Œå¼€å‘è€…å¯ä»¥è‡ªå®šä¹‰å‰å‘å’Œåå‘è®¡ç®—çš„äº¤é”™æ‰§è¡Œé¡ºåºï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„é‡å æ•ˆæœã€‚DeepSeek-v3 çš„é‡å æ–¹æ³•åœ¨æŠ€æœ¯æŠ¥å‘Šé‡Œå·²ç»è®²è§£ã€‚\nReal Case é€šè¿‡ examples/example_dualpipe.py ä¸­çš„ main å‡½æ•°æ¥è¯¦ç»†è®²è§£ä¸€ä¸ªå®Œæ•´çš„ DualPipe æµç¨‹ã€‚\nç¯å¢ƒåˆå§‹åŒ–å’Œé…ç½® åˆ†å¸ƒå¼è®¾ç½®: main å‡½æ•°é¦–å…ˆåˆå§‹åŒ– PyTorch çš„åˆ†å¸ƒå¼é€šä¿¡ç»„ï¼ˆinit_process_groupï¼‰ï¼Œå¹¶ä¸ºæ¯ä¸ªè¿›ç¨‹ï¼ˆrankï¼‰åˆ†é…ä¸€ä¸ª GPU. å‚æ•°é…ç½®: å®šä¹‰äº† micro-batch æ•°é‡ (num_chunks)ã€æ¯ä¸ª micro-batch çš„å¤§å° (micro_batch_size) ç­‰è¶…å‚æ•°ã€‚ P2Pé€šä¿¡è®¾ç½®: åœ¨æ‰§è¡Œ DualPipe çš„ step æ–¹æ³•å‰ï¼Œå¿…é¡»è°ƒç”¨ set_p2p_tensor_shapes å’Œ set_p2p_tensor_dtype æ¥å‘ŠçŸ¥ DualPipe åœ¨æµæ°´çº¿ä¸­ä¼ é€’çš„å¼ é‡çš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹ã€‚è¿™æ˜¯å› ä¸º DualPipe éœ€è¦é¢„å…ˆåˆ†é…å†…å­˜æ¥æ¥æ”¶æ¥è‡ªå…¶ä»– rank çš„æ•°æ®ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def main(rank, pp_size): # åˆ¤æ–­å½“å‰è¿›ç¨‹çš„è§’è‰² is_first_rank = rank == 0 is_last_rank = rank == pp_size - 1 # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ dist.init_process_group(backend=\u0026#39;nccl\u0026#39;, init_method=\u0026#34;env://\u0026#34;, world_size=pp_size, rank=rank) torch.cuda.set_device(rank) torch.set_default_device(f\u0026#34;cuda:{rank}\u0026#34;) torch.manual_seed(233) os.environ[\u0026#34;CUBLAS_WORKSPACE_CONFIG\u0026#34;] = \u0026#34;:4096:8\u0026#34; # å®šä¹‰æµæ°´çº¿å‚æ•° num_chunks = 20 micro_batch_size = 3 seq_len = 256 hidden_size = 512 if is_first_rank: print(f\u0026#34;{pp_size=}, {num_chunks=}, {seq_len=}, {hidden_size=}\u0026#34;, flush=True) # è®¾ç½®P2Pé€šä¿¡çš„Tensorå½¢çŠ¶å’Œç±»å‹ set_p2p_tensor_shapes([(micro_batch_size, seq_len, hidden_size)]) set_p2p_tensor_dtype(torch.float32) æ¨¡å‹å’Œå‚è€ƒåŸºå‡†çš„åˆ›å»º 1 2 3 4 5 6 7 8 9 # åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ã€æœªåˆ†å‰²çš„æ¨¡å‹ full_modules = nn.Sequential(*[PipelineStage(hidden_size) for _ in range(pp_size)]) # åˆ›å»ºå®Œæ•´çš„è¾“å…¥æ•°æ® full_x = torch.randn(num_chunks * micro_batch_size, seq_len, hidden_size) full_l = torch.randn(num_chunks * micro_batch_size, seq_len, hidden_size) # å‚è€ƒæ­¥éª¤ï¼šåœ¨ä¸€ä¸ªGPUä¸Šï¼Œç”¨æ ‡å‡†çš„æ•°æ®å¹¶è¡Œæ–¹å¼è¿è¡Œå®Œæ•´æ¨¡å‹ï¼Œå¾—åˆ°åŸºå‡†ç»“æœ loss_ref, output_ref = ref_step(full_x, full_l, full_modules, num_chunks) åˆ›å»ºæ¨¡å‹: ä»£ç é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªå®Œæ•´çš„ nn.Sequential æ¨¡å‹ (full_modules)ï¼Œå®ƒåŒ…å«äº†æµæ°´çº¿æ‰€æœ‰çš„é˜¶æ®µã€‚ å‚è€ƒæ­¥éª¤ (ref_step): ä¸ºäº†éªŒè¯ DualPipe çš„æ­£ç¡®æ€§ï¼Œref_step å‡½æ•°æ¨¡æ‹Ÿäº†æ ‡å‡†çš„ã€éæµæ°´çº¿å¹¶è¡Œçš„è®­ç»ƒè¿‡ç¨‹ã€‚å®ƒå°†æ•°æ®åˆ†å—ï¼Œä¾æ¬¡é€šè¿‡å®Œæ•´æ¨¡å‹è®¡ç®—æŸå¤±å’Œè¾“å‡ºã€‚loss_ref å’Œ output_ref å°†ä½œä¸ºåç»­æ¯”è¾ƒçš„æ­£ç¡®ç­”æ¡ˆã€‚ DualPipeæ¨¡å‹çš„åˆ›å»ºå’Œè¾“å…¥å‡†å¤‡ æ¨¡å‹åˆ†å‰²: æ¯ä¸ª rank r ä¼šæŒæœ‰ä¸¤ä¸ª PipelineStage: ä¸€ä¸ªæ˜¯ full_modules[r]ï¼Œå¦ä¸€ä¸ªæ˜¯ full_modules[pp_size - 1 - r]. è¿™å°±æ˜¯ Dual (åŒå‘) çš„ä½“ç°ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ª 4-GPU çš„è®¾ç½®ä¸­ï¼š Rank 0 æŒæœ‰ stage 0 å’Œ stage 3 çš„æ¨¡å‹ã€‚ Rank 1 æŒæœ‰ stage 1 å’Œ stage 2 çš„æ¨¡å‹ã€‚ Rank 2 æŒæœ‰ stage 2 å’Œ stage 1 çš„æ¨¡å‹ã€‚ Rank 3 æŒæœ‰ stage 3 å’Œ stage 0 çš„æ¨¡å‹ã€‚ è¾“å…¥æ•°æ®åˆ†å‰²: DualPipe æœ‰ä¸¤ä¸ªæ•°æ®å…¥å£ç‚¹ï¼šrank 0 å’Œæœ€åä¸€ä¸ª rank. rank 0 æ¥æ”¶å‰åŠéƒ¨åˆ†çš„è¾“å…¥ (full_x.chunk(2)[0]) å’Œ ååŠéƒ¨åˆ† çš„æ ‡ç­¾ (full_l.chunk(2)[1]). last rank æ¥æ”¶ååŠéƒ¨åˆ†çš„è¾“å…¥ (full_x.chunk(2)[1]) å’Œ å‰åŠéƒ¨åˆ† çš„æ ‡ç­¾ (full_l.chunk(2)[0]). ä¸€å…±æœ‰ä¸¤ä¸ªæ•°æ®æµ: ä¸€ä¸ªä» rank 0 å¼€å§‹ï¼Œå…¶å¯¹åº”çš„æ ‡ç­¾åœ¨æœ€åä¸€ä¸ª rankï¼›å¦ä¸€ä¸ªä»æœ€åä¸€ä¸ª rank å¼€å§‹ï¼Œå…¶å¯¹åº”çš„æ ‡ç­¾åœ¨ rank 0.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # DualPipe æ¨¡å‹åˆ›å»º # æ¯ä¸ª rank è·å–ä¸¤ä¸ªå¤„äºå¯¹ç§°ä½ç½®çš„æ¨¡å‹å— local_full_modules = nn.Sequential(full_modules[rank], full_modules[pp_size - 1 - rank]) local_modules = nn.Sequential(PipelineStage(hidden_size), PipelineStage(hidden_size)) # ... åŠ è½½æƒé‡ ... dualpipe_model = DualPipe(local_modules) # DualPipeè¾“å…¥æ•°æ®å‡†å¤‡ if is_first_rank: x = full_x.chunk(2)[0] l = full_l.chunk(2)[1] elif is_last_rank: x = full_x.chunk(2)[1] l = full_l.chunk(2)[0] else: x = None l = None æ‰§è¡Œè®­ç»ƒæ­¥éª¤ è°ƒç”¨ dualpipe_model.stepï¼Œè§¦å‘äº†å‰é¢è®²è§£ä¸­æåˆ°çš„å¤æ‚çš„8é˜¶æ®µè°ƒåº¦æµç¨‹ã€‚\nloss, outputs = dualpipe_model.step(x, num_chunks=num_chunks, criterion=criterion, labels=(l,), return_outputs=False) ç»“æœéªŒè¯ æ£€æŸ¥æŸå¤±\nif is_first_rank: assert torch.equal(loss, loss_ref.chunk(2)[1]) elif is_last_rank: assert torch.equal(loss, loss_ref.chunk(2)[0]) else: assert loss is None è®­ç»ƒæ­¥éª¤å®Œæˆåï¼Œstep æ–¹æ³•ä¼šè¿”å›è®¡ç®—å‡ºçš„æŸå¤±ã€‚\nrank0 è®¡ç®—å‡ºçš„ loss å¯¹åº”çš„æ˜¯ä» last rank è¾“å…¥çš„æ•°æ®æµï¼Œç­‰äºå‚è€ƒæŸå¤±çš„ååŠéƒ¨åˆ† (loss_ref.chunk(2)[1]). åŒç†ï¼Œlast rank è®¡ç®—å‡ºçš„ loss å¯¹åº”çš„æ˜¯ä» rank0 è¾“å…¥çš„æ•°æ®æµï¼Œç­‰äºå‚è€ƒæŸå¤±çš„å‰åŠéƒ¨åˆ† (loss_ref.chunk(2)[0]). ä¸­é—´çš„ ranks ä¸è®¡ç®—æœ€ç»ˆæŸå¤±ï¼Œè¿”å› None. æ£€æŸ¥æ¢¯åº¦\n1 2 3 4 5 6 7 8 9 for (p0, p1) in zip(local_modules[0].parameters(), local_modules[1].parameters()): # ... dist.all_gather_into_tensor(p0all, p0.grad) dist.all_gather_into_tensor(p1all, p1.grad) # æ‰‹åŠ¨èšåˆå¯¹ç§°rankçš„æ¢¯åº¦ p0.grad += p1all[pp_size - 1 - rank] p1.grad += p0all[pp_size - 1 - rank] for ((n, p), p_ref) in zip(local_modules.named_parameters(), local_full_modules.parameters()): assert cal_diff(p.grad, p_ref.grad) \u0026lt; 1e-13 ç”±äºæ¯ä¸ª rank r æŒæœ‰ r å’Œ pp_size - 1 - r ä¸¤ä¸ªé˜¶æ®µçš„æ¨¡å‹ï¼Œå¦‚æœè¿™ä¸¤ä¸ªé˜¶æ®µåœ¨é€»è¾‘ä¸Šæ˜¯åŒä¸€ä¸ªæƒé‡ï¼ˆä¾‹å¦‚ï¼Œåœ¨Encoder-Decoderç»“æ„ä¸­å…±äº«æƒé‡ï¼‰ï¼Œé‚£ä¹ˆå®ƒä»¬çš„æ¢¯åº¦éœ€è¦æ‰‹åŠ¨èšåˆã€‚ç¤ºä¾‹é€šè¿‡ dist.all_gather_into_tensor æ”¶é›†æ‰€æœ‰ rank ä¸Šå¯¹ç§°æ¨¡å—çš„æ¢¯åº¦ï¼Œç„¶åæ‰‹åŠ¨å°†å®ƒä»¬ç›¸åŠ ã€‚æœ€åï¼Œå°†èšåˆåçš„æ¢¯åº¦ä¸ ref_step ä¸­è®¡ç®—å‡ºçš„å‚è€ƒæ¢¯åº¦è¿›è¡Œæ¯”è¾ƒï¼ŒéªŒè¯åå‘ä¼ æ’­çš„æ­£ç¡®æ€§ã€‚\n","permalink":"http://localhost:1313/blogs/deepseek/dualpipe/","summary":"Source code reading of DualPipe","title":"DualPipe"},{"content":"Abstract DeepSeek-V3 (671B) æ˜¯ MoE æ¨¡å‹ï¼Œæ¯ä¸ª token ä¼šæ¿€æ´» 37B çš„å‚æ•°ã€‚é‡‡ç”¨ Multi-head Latent Attention (MLA) å’Œè‡ªåˆ›çš„ DeepSeek MoE ç»“æ„ï¼Œåœ¨è¿™ä¸¤ç¯‡æ–‡ç« ä¸­å·²ç»åšè¿‡è®²è§£ã€‚åŒæ—¶é‡‡ç”¨äº† auxiliary-loss-free ç­–ç•¥æ¥å®ç°ä¸“å®¶è´Ÿè½½å¹³è¡¡å¹¶ä¸”ä½¿ç”¨äº† Multi-token Prediction (MTP) æ¥åŠ é€Ÿè®­ç»ƒã€‚æ•´ä¸ªé¢„è®­ç»ƒæ•°æ®é›†ä¸€å…±æœ‰ 14.8T tokensï¼Œé€šè¿‡ Suprvised Fine-Tuning (SFT) å’Œ å¼ºåŒ–å­¦ä¹ æ¥åŠ å¼ºæ€§èƒ½ã€‚è®­ç»ƒæ—¶é•¿ä¸º 2.788M H800 GPU å°æ—¶ã€‚\n1. Introduction æ¨¡å‹æ¶æ„åˆ›æ–°:\nMulti-head Latent Attention (MLA): åŠ é€Ÿæ¨ç†ã€‚ DeepSeek MoE: å‡å°‘è®­ç»ƒå¼€é”€ã€‚ å¢å¼ºæ¨¡å‹èƒ½åŠ›çš„ç­–ç•¥:\nauxiliary-loss-free: å®ç°è´Ÿè½½å¹³è¡¡ã€‚ Multi-token Prediction (MTP): å¢å¼ºæ¨¡å‹è¡¨ç°ã€‚ æé«˜è®­ç»ƒæ•ˆç‡çš„æ–¹æ³•:\nFP8 æ··åˆç²¾åº¦è®­ç»ƒ: åŠ é€Ÿè®­ç»ƒå’Œå‡å°‘ GPU å†…å­˜ä½¿ç”¨ã€‚ DualPipe æµæ°´çº¿å¹¶è¡Œç®—æ³•: å‡å°‘æ°”æ³¡å¹¶ä¸”åœ¨è®­ç»ƒæ—¶å€™é€šè¿‡è®¡ç®—æ©ç›–äº†å¤§éƒ¨åˆ†é€šä¿¡ã€‚ æ–°çš„èŠ‚ç‚¹é—´ All-to-all é€šä¿¡ç®—å­: æ›´å¥½åœ°åˆ©ç”¨ InfiniBand (IB) and NVLink å¸¦å®½ã€‚ ä¼˜åŒ–äº†å†…å­˜å DeepSeek-V3 è®­ç»ƒæ²¡æœ‰ä½¿ç”¨ TP. è®­ç»ƒè¿‡ç¨‹:\npre-training: åœ¨ 14.8T tokens ä¸Šè¿›è¡Œã€‚ stage 1: æ‰©å±•æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦åˆ° 32K. stage 2: æ‰©å±•æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦åˆ° 128K. post-training: ä½¿ç”¨ Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) å¹¶ä¸”è’¸é¦äº† DeepSeek-R1 ç³»åˆ—æ¨¡å‹æ¥è·å¾—æ¨ç†èƒ½åŠ›ã€‚ DeepSeek-V3 ä¸Šè®­ç»ƒæ¯ 1T token åªéœ€è¦180K H800 GPUå°æ—¶ï¼Œå³åœ¨ 2048 ä¸ª H800 GPU çš„é›†ç¾¤ä¸Šéœ€è¦ 3.7 å¤©ã€‚\n2. Architecture Illustration of the Basic Architecture of DeepSeek-V3\n2.1 MLA åœ¨ç›¸å…³æ–‡ç« ä¸­å·²ç»ä»‹ç»ã€‚\n2.2 DeepSeekMoE with Auxiliary-Loss-Free Load Balancing $$\r\\begin{align}\r\\mathbf{h}'_t \u0026= \\mathbf{u}_t + \\sum_{i=1}^{N_s} \\text{FFN}_i^{(s)} (\\mathbf{u}_t) + \\sum_{i=1}^{N_r} g_{i,t} \\text{FFN}_i^{(r)} (\\mathbf{u}_t), \\\\\rg_{i,t} \u0026= \\frac{g'_{i,t}}{\\sum_{j=1}^{N_r} g'_{j,t}}, \\\\\rg'_{i,t} \u0026= \\begin{cases} s_{i,t}, \u0026 s_{i,t} \\in \\text{Topk}(\\{s_{j,t}|1 \\le j \\le N_r\\}, K_r), \\\\ 0, \u0026 \\text{otherwise}, \\end{cases} \\\\\rs_{i,t} \u0026= \\text{Sigmoid}(\\mathbf{u}_t^T \\mathbf{e}_i),\r\\end{align}\r$$Basic Architecture of DeepSeekMoE. åœ¨ç›¸å…³æ–‡ç« ä¸­å·²ç»ä»‹ç»ï¼ŒV3 å’Œ V2 ä¸åŒä¹‹å¤„åœ¨äºä½¿ç”¨sigmoidå‡½æ•°æ¥è®¡ç®—äº²å’Œåˆ†æ•°ï¼Œå¹¶åœ¨å½’ä¸€åŒ–æ‰€æœ‰é€‰å®šçš„äº²å’Œåˆ†æ•°ä¹‹é—´æ¥äº§ç”Ÿé—¨æ§åˆ¶å€¼ã€‚\nAuxiliary-Loss-Free Load Balancing. ä¸ºæ¯ä¸ªä¸“å®¶å¼•å…¥ä¸€ä¸ªåå·®é¡¹ $b_i$ï¼Œå¹¶å°†å…¶ä¸ç›¸åº”çš„äº²å’ŒåŠ›åˆ†æ•°$s_{i,t}$ ç›¸åŠ ï¼Œä»¥ç¡®å®š top-K è·¯ç”±\n$$\rg'_{i,t} = \\begin{cases} s_{i,t}, \u0026 s_{i,t} + b_i \\in \\text{Topk}(\\{s_{j,t} + b_j | 1 \\le j \\le N_r\\}, K_r), \\\\ 0, \u0026 \\text{otherwise}. \\end{cases} \\tag{16}\r$$è¿™ä¸ªåç½®é¡¹ä»…ç”¨äºè·¯ç”±ï¼Œç”¨äºå’Œ FFN è¾“å‡ºç›¸ä¹˜çš„é—¨æ§å€¼è¿˜æ˜¯æ¥è‡ªäºåŸå…ˆçš„åŸå…ˆçš„ $s_{i,t}$. åœ¨æ¯ä¸€æ­¥ç»“æŸæ—¶ï¼Œå¦‚æœå…¶å¯¹åº”çš„ä¸“å®¶è¿‡è½½ï¼Œ DeepSeek-V3 å°†åå·®é¡¹å‡å°‘ $\\gamma$ (ä¸€ä¸ªè¶…å‚æ•°ï¼Œè¢«ç§°ä½œ bias update speed)ï¼Œå¦‚æœå…¶å¯¹åº”çš„ä¸“å®¶è´Ÿè½½ä¸è¶³ï¼Œ DeepSeek-V3 å°†åå·®é¡¹å¢åŠ  $\\gamma$.\nV3 ä½¿ç”¨ sequence-wise balance lossï¼Œç±»ä¼¼äº V2 ä¸­ Expert-Level Balance Lossã€‚ ä¸åŒä¹‹å¤„åœ¨äºä½¿ç”¨å½’ä¸€åŒ–çš„äº²å’Œåˆ†æ•°ã€‚\n$$\r\\begin{align}\r\\mathcal{L}_{\\text{Bal}} \u0026= \\alpha \\sum_{i=1}^{N_r} f_i P_i, \\\\\rf_i \u0026= \\frac{N_r}{K_r T} \\sum_{t=1}^{T} 1 (s_{i,t} \\in \\text{Topk}(\\{s_{j,t}|1 \\le j \\le N_r\\}, K_r)), \\\\\rs'_{i,t} \u0026= \\frac{s_{i,t}}{\\sum_{j=1}^{N_r} s_{j,t}}, \\\\\rP_i \u0026= \\frac{1}{T} \\sum_{t=1}^{T} s'_{i,t} \\end{align}\r$$Node-Limited Routing. å¯¹äºæ¯ä¸ª token è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹è®¡ç®—äº²å’Œåº¦åˆ†æ•°å‰ $\\frac {K_r}M$ çš„ä¸“å®¶æ±‚å’Œï¼Œé€‰å–å‰ $M$ ä¸ªä½œä¸ºè·¯ç”±èŠ‚ç‚¹ã€‚\nNo Token-Dropping. è®­ç»ƒå’Œæ¨ç†ä¸­å‡ä¸é‡‡ç”¨ã€‚Token DroppingæŒ‡çš„æ˜¯åœ¨ MoE å½“è·¯ç”±åˆ°æŸä¸ªä¸“å®¶çš„ Token æ•°é‡è¶…è¿‡äº†è¯¥ä¸“å®¶çš„å¤„ç†å®¹é‡æ—¶ï¼Œç³»ç»Ÿä¼šæ•…æ„ä¸¢è·³è¿‡é‚£äº›è¶…å‡ºå®¹é‡çš„ tokenï¼Œä¸è®©å®ƒä»¬è¢«è¿™ä¸ªä¸“å®¶å¤„ç†ã€‚è¿™äº› token é€šå¸¸ä¼šé€šè¿‡ä¸€ä¸ªæ®‹å·®è¿æ¥ï¼Œå°†å…¶è¾“å…¥æ—¶çš„çŠ¶æ€ç›´æ¥ä¼ é€’åˆ°ä¸‹ä¸€å±‚ã€‚\n2.3 Multi-Token Prediction Illustration of Multi-Token Prediction (MTP) implementation\nä¸ Gloeckle ç­‰äººä½¿ç”¨ç‹¬ç«‹çš„è¾“å‡ºå¤´å¹¶è¡Œé¢„æµ‹ D ä¸ªé¢å¤– token ä¸åŒï¼Œ DeepSeek-V3 é¡ºåºé¢„æµ‹é¢å¤– token å¹¶åœ¨æ¯ä¸ªé¢„æµ‹æ·±åº¦ä¿æŒå®Œæ•´çš„å› æœé“¾ã€‚\nMTP Modules. DeepSeek-V3 ä½¿ç”¨ D ä¸ªé¡ºåºæ¨¡å—æ¥é¢„æµ‹ D ä¸ªé¢å¤– tokenã€‚ç¬¬ k ä¸ª MTP æ¨¡å—ç”±ä¸€ä¸ªå…±äº«åµŒå…¥å±‚ Emb(Â·)ã€ä¸€ä¸ªå…±äº«è¾“å‡ºå¤´ OutHead(Â·)ã€ä¸€ä¸ª Transformer å— TRM_k(Â·) å’Œä¸€ä¸ªæŠ•å½±çŸ©é˜µ $M_k \\in \\mathbb{R}^{d \\times 2d}$ ç»„æˆã€‚å¯¹äºç¬¬ i ä¸ªè¾“å…¥ token $t_i$ï¼Œåœ¨ç¬¬ k ä¸ªé¢„æµ‹æ·±åº¦ï¼Œ DeepSeek-V3 é¦–å…ˆé€šè¿‡çº¿æ€§æ˜ å°„ç»“åˆç¬¬ i ä¸ª token åœ¨ç¬¬ (kâˆ’1) ä¸ªæ·±åº¦ä¸Šçš„è¡¨ç¤º $h_i^{k-1} \\in \\mathbb{R}^d$ å’Œç¬¬ (i+k) ä¸ª token çš„åµŒå…¥ $\\text{Emb}(t_{i+k}) \\in \\mathbb{R}^d$\n$$\rh_t^k = M_k[\\text{RMSNorm}(h_t^{k-1}); \\text{RMSNorm}(\\text{Emb}(t_{i+k}))], \\tag{21}\r$$å…¶ä¸­ [Â·;Â·] è¡¨ç¤ºæ‹¼æ¥æ“ä½œã€‚ç‰¹åˆ«åœ°ï¼Œå½“ k = 1 æ—¶ï¼Œ$h_t^{k-1}$ æŒ‡çš„æ˜¯ç”±ä¸»æ¨¡å‹ç»™å‡ºçš„è¡¨ç¤ºã€‚è¯·æ³¨æ„ï¼Œå¯¹äºæ¯ä¸ª MTP æ¨¡å—ï¼Œå…¶åµŒå…¥å±‚ä¸ä¸»æ¨¡å‹å…±äº«ã€‚åˆå¹¶åçš„ $h_t^k$ ä½œä¸ºç¬¬ k ä¸ªæ·±åº¦ä¸Š Transformer å—çš„è¾“å…¥ï¼Œä»¥åœ¨å½“å‰æ·±åº¦ç”Ÿæˆè¾“å‡ºè¡¨ç¤º $h_t^k$: $$\rh_{1:T-k}^k = \\text{TRM}_k(h_{1:T-k}^k), \\tag{22}\r$$ å…¶ä¸­ T ä»£è¡¨è¾“å…¥åºåˆ—é•¿åº¦ï¼Œè€Œ $_{1:T-k}$ è¡¨ç¤ºåˆ‡ç‰‡æ“ä½œ (åŒ…å«å·¦å³è¾¹ç•Œ)ã€‚æœ€åï¼Œå°† $h_T^k$ ä½œä¸ºè¾“å…¥ï¼Œå…±äº«è¾“å‡ºå¤´å°†è®¡ç®—ç¬¬ k ä¸ªé¢å¤–é¢„æµ‹ token çš„æ¦‚ç‡åˆ†å¸ƒ $p_{t+k+1}^k \\in \\mathbb{R}^V$ï¼Œå…¶ä¸­ $V$ æ˜¯è¯æ±‡è¡¨çš„å¤§å°: $$\rp_{t+k+1}^k = \\text{OutHead}(h_T^k). \\tag{23}\r$$ è¾“å‡ºå¤´ OutHead(Â·) å°†è¡¨ç¤ºçº¿æ€§æ˜ å°„åˆ° logitsï¼Œéšååº”ç”¨ Softmax å‡½æ•°æ¥è®¡ç®—ç¬¬ k ä¸ªé¢å¤– token çš„é¢„æµ‹æ¦‚ç‡ã€‚æ­¤å¤–ï¼Œå¯¹äºæ¯ä¸ª MTP æ¨¡å—ï¼Œå…¶è¾“å‡ºå¤´ä¸ä¸»æ¨¡å‹å…±äº«ã€‚DeepSeek-V3 ç»´æŒé¢„æµ‹å› æœé“¾çš„åŸåˆ™ä¸ EAGLE (Li et al., 2024b) çš„åŸåˆ™ç›¸ä¼¼ï¼Œä½†å…¶ä¸»è¦ç›®æ ‡æ˜¯æ¨æµ‹è§£ç  (Leviathan et al., 2023; Xia et al., 2023)ï¼ŒDeepSeek-V3 è€Œ åˆ©ç”¨ MTP æ¥æ”¹è¿›è®­ç»ƒã€‚\nMTP Training Objective. å¯¹äºæ¯ä¸ªé¢„æµ‹æ·±åº¦ï¼Œè®¡ç®—ä¸€ä¸ªäº¤å‰ç†µæŸå¤± $\\mathcal{L}_{\\text{MTP}}^k$ï¼š\n$$\r\\mathcal{L}_{\\text{MTP}}^k = \\text{CrossEntropy}(P_{2+k:T+1}^k, t_{2+k:T+1}) = -\\frac{1}{T}\\sum_{i=2+k}^{T+1} \\log p_i^k[t_i], \\tag{24}\r$$ $T$: è¾“å…¥åºåˆ—é•¿åº¦ $t_i$: ç¬¬ i ä¸ªä½ç½®çš„çœŸå® (ground-truth) token $p_i^k[t_i]$: ä»£è¡¨ç¬¬ $k$ ä¸ª MTP æ¨¡å—å¯¹äºç¬¬ $i$ ä¸ªä½ç½®çš„é¢„æµ‹ä¸­ï¼Œèµ‹ç»™çœŸå®æ­£ç¡® token $t_i$** çš„æ¦‚ç‡ã€‚ æœ€åè®¡ç®—æ‰€æœ‰æ·±åº¦çš„ MTP æŸå¤±çš„å¹³å‡å€¼ï¼Œå¹¶ä¹˜ä»¥ä¸€ä¸ªåŠ æƒå› å­ $\\lambda$ æ¥è·å¾—æ€»ä½“çš„ MTP æŸå¤± $\\mathcal{L}_{\\text{MTP}}$ï¼Œä½œä¸º DeepSeek-V3 çš„ä¸€ä¸ªé¢å¤–è®­ç»ƒç›®æ ‡ï¼š\n$$\r\\mathcal{L}_{\\text{MTP}} = \\frac{\\lambda}{D} \\sum_{k=1}^{D} \\mathcal{L}_{\\text{MTP}}^k. \\tag{25}\r$$MTP in Inference. MTP ç­–ç•¥ä¸»è¦æ—¨åœ¨æå‡ä¸»æ¨¡å‹çš„æ€§èƒ½ï¼Œå› æ­¤åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯ä»¥ç›´æ¥ä¸¢å¼ƒ MTP æ¨¡å—ï¼Œä¸»æ¨¡å‹å¯ä»¥ç‹¬ç«‹ä¸”æ­£å¸¸åœ°è¿ä½œã€‚æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥é‡æ–°åˆ©ç”¨è¿™äº› MTP æ¨¡å—è¿›è¡Œæ¨æµ‹è§£ç  (speculative decoding) ï¼Œä»¥è¿›ä¸€æ­¥æ”¹å–„ç”Ÿæˆå»¶è¿Ÿã€‚\n3. Infrastructure 3.1 Compute Clusters DeepSeek-V3 åœ¨ 2048 NVIDIA H800 GPU ç»„æˆçš„é›†ç¾¤ä¸Šè®­ç»ƒã€‚æ¯ä¸ªèŠ‚ç‚¹æœ‰ 8 å¼ é€šè¿‡ NVLink å’Œ NVSwitch è¿æ¥çš„ H800. èŠ‚ç‚¹ä¹‹é—´é€šè¿‡ InfiniBand (IB) è¿æ¥ã€‚\n3.2 Training Framework DeepSeek-V3 ä½¿ç”¨ 16-way Pipeline Parallelism (PP), æ¨ªè·¨ 8 ä¸ªèŠ‚ç‚¹é—´çš„ 64-way Expert Parallelism (EP) ä»¥åŠ ZeRO-1 Data Parallelism (DP). è®­ç»ƒæœŸé—´ä¸ä½¿ç”¨ Tensor Parallelism (TP).\n3.2.1 DualPipe and Computation-Communication Overlap DeepSeek-V3 ä¸­ä¸“å®¶å¹¶è¡Œå¯¼è‡´çš„è·¨èŠ‚ç‚¹ All-to-all é€šä¿¡æ‰€å¯¹åº”çš„è®¡ç®—é€šä¿¡æ¯”æ¥è¿‘ 1:1ï¼Œæ•ˆç‡å¾ˆä½ã€‚\nDualPipe çš„æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨ä¸€å¯¹ç‹¬ç«‹çš„ forward \u0026amp; backword chunk å†…éƒ¨é‡å è®¡ç®—å’Œé€šä¿¡ã€‚å…·ä½“æ¥è¯´ï¼Œå°†æ¯ä¸ª chunk åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†: attention, all-to-all dispatchï¼Œ MLP å’Œ all-to-all combine. ç‰¹åˆ«åœ°ï¼Œå¯¹äº backword chunk, attention å’Œ MLP éƒ½åƒåœ¨ ZeroBubble (Qi et al., 2023b) ä¸­ä¸€æ ·ï¼Œè¢«è¿›ä¸€æ­¥æ‹†åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šé’ˆå¯¹è¾“å…¥çš„åå‘ä¼ æ’­å’Œé’ˆå¯¹æƒé‡çš„åå‘ä¼ æ’­ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªæµæ°´çº¿å¹¶è¡Œé€šä¿¡ç»„ä»¶ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯¹äºä¸€å¯¹ forward \u0026amp; backword chunkï¼Œé‡æ’è¿™äº›ç»„ä»¶ï¼Œå¹¶æ‰‹åŠ¨è°ƒæ•´ä¸“ç”¨äºé€šä¿¡ä¸è®¡ç®—çš„ GPU SM çš„æ¯”ä¾‹ã€‚é€šè¿‡è¿™ç§é‡å ç­–ç•¥ï¼Œå¯ä»¥ç¡®ä¿ all-to-all å’Œ PP é€šä¿¡åœ¨æ‰§è¡ŒæœŸé—´éƒ½èƒ½å¤Ÿè¢«å®Œå…¨éšè—ã€‚\nOverlapping Strategy for a Pair of Individual Forward and Backward Chunks\nåŸºäºè¿™ç§é«˜æ•ˆçš„é‡å ç­–ç•¥ï¼Œå®Œæ•´çš„ DualPipe è°ƒåº¦æ–¹æ¡ˆå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å®ƒé‡‡ç”¨äº†ä¸€ç§åŒå‘æµæ°´çº¿è°ƒåº¦ï¼Œå³åŒæ—¶ä»æµæ°´çº¿çš„ä¸¤ç«¯é€å…¥ micro-batchesï¼Œä»è€Œä½¿å¾—ä¸€å¤§éƒ¨åˆ†é€šä¿¡å¯ä»¥è¢«å®Œå…¨é‡å ã€‚è¿™ç§é‡å è¿˜ç¡®ä¿éšç€æ¨¡å‹è§„æ¨¡çš„è¿›ä¸€æ­¥æ‰©å¤§ï¼Œåªè¦ä¿æŒæ’å®šçš„è®¡ç®—ä¸é€šä¿¡æ¯”ç‡ï¼Œä»ç„¶å¯ä»¥åœ¨èŠ‚ç‚¹é—´ä½¿ç”¨ç»†ç²’åº¦çš„ä¸“å®¶ (fine-grained experts)ï¼ŒåŒæ—¶å®ç°æ¥è¿‘äºé›¶çš„all-to-allé€šä¿¡å¼€é”€ã€‚å…·ä½“çš„åˆ†æè§ç›¸å…³æ–‡ç« ã€‚\nDualPipe Schedule\n3.2.2 Efficient Implementation of Cross-Node All-to-All Communication DeepSeek-V3 å®šåˆ¶äº†é«˜æ•ˆçš„è·¨èŠ‚ç‚¹ All-to-all é€šä¿¡å†…æ ¸ï¼Œä»¥èŠ‚çœä¸“ç”¨äºé€šä¿¡çš„ SM æ•°é‡ã€‚å†…æ ¸çš„å®ç°ä¸MoEé—¨æ§ç®—æ³•å’Œ DeepSeek-V3 é›†ç¾¤çš„ç½‘ç»œæ‹“æ‰‘å…±åŒè®¾è®¡ã€‚é›†ç¾¤ä¸­è·¨èŠ‚ç‚¹ GPU é€šè¿‡ IB(50 GB/s) å…¨è¿æ¥ï¼ŒèŠ‚ç‚¹å†…é€šä¿¡é€šè¿‡ NVLink(160GB/s) å¤„ç†ã€‚ä¸ºäº†æœ‰æ•ˆåœ°åˆ©ç”¨ IB å’Œ NVLink çš„ä¸åŒå¸¦å®½ï¼Œæ¯ä¸ª token é™åˆ¶æœ€å¤šè¢« dispatch åˆ° 4 ä¸ªèŠ‚ç‚¹ä»¥å‡å°‘ IB æµé‡ã€‚\nç»è¿‡æµ‹è¯•æ¯ä¸ª token åœ¨æ¯ä¸ªèŠ‚ç‚¹å¹³å‡é€‰æ‹© 3.2 ä¸ªä¸“å®¶çš„åŒæ—¶ä¸ä¼šäº§ç”Ÿé¢å¤–çš„ NVLink é€šä¿¡å¼€é”€ã€‚æ„å‘³ç€è™½ç„¶ DeepSeek-V3 è™½ç„¶å®é™…ä¸Šåªé€‰æ‹© 8 ä¸ªè·¯ç”±ä¸“å®¶ï¼Œä½†å®ƒå¯ä»¥åœ¨ä¿æŒç›¸åŒé€šä¿¡æˆæœ¬çš„æƒ…å†µä¸‹æœ€å¤šé€‰æ‹© 13 ä¸ªä¸“å®¶ (4 èŠ‚ç‚¹x 3.2 ä¸“å®¶/èŠ‚ç‚¹). åœ¨è¿™ç§é€šä¿¡ç­–ç•¥ä¸‹ï¼Œä»… 20 ä¸ª SMs å°±è¶³ä»¥å……åˆ†åˆ©ç”¨ IB å’Œ NVLink çš„å¸¦å®½ã€‚è¯¦ç»†åœ°è¯´ï¼ŒDeepSeek-V3 é‡‡ç”¨äº† warp specialization æŠ€æœ¯ï¼Œå¹¶å°† 20 ä¸ª SMs åˆ’åˆ†ä¸º 10 ä¸ªé€šä¿¡é€šé“ã€‚åœ¨ dispatch è¿‡ç¨‹ä¸­çš„é€šä¿¡é“¾è·¯ä¸º (1)IBå‘é€ï¼Œ(2) IB-to-NVLink è½¬å‘ï¼Œ(3) NVLink æ¥æ”¶ç”±å„è‡ªçš„ warp å¤„ç†ã€‚combine è¿‡ç¨‹åˆ™æ˜¯ç›¸åçš„é€šä¿¡é“¾è·¯ã€‚\n3.2.3 Extremely Memory Saving with Minimal Overhead DeepSeek-V3 é‡‡å–äº†å¦‚ä¸‹æŠ€æœ¯æ¥å‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­çš„å†…å­˜å ç”¨ã€‚\né‡è®¡ç®— RMSNorm å’Œ MLA å‡ç»´æŠ•å½±ã€‚ Exponential Moving Average (EMA) å‚æ•°è¢«å­˜æ”¾åœ¨ CPU ä¸­å¹¶ä¸”å¼‚æ­¥æ›´æ–°ã€‚ MTP çš„ Embedding å’Œè¾“å‡ºå¤´åœ¨ PP rank ç›¸åŒçš„è®¾å¤‡ä¸Šæ˜¯å…±äº«çš„ã€‚ 3.3 FP8 Training ä½ç²¾åº¦è®¡ç®—åœ¨ç´¯åŠ è¿‡ç¨‹ä¸­å®¹æ˜“å‡ºç°çš„é—®é¢˜æœ‰:\næº¢å‡º (Overflow): å½“è®¸å¤šæ•°å­—ç›¸åŠ æ—¶ï¼Œå®ƒä»¬çš„å’Œå¾ˆå®¹æ˜“ä¼šè¶…å‡º FP8 æ ¼å¼æ‰€èƒ½è¡¨ç¤ºçš„æœ€å¤§å€¼ã€‚ ç²¾åº¦æŸå¤± (Precision Loss/Underflow): åœ¨ç´¯åŠ è¿‡ç¨‹ä¸­ï¼Œå¦‚æœä¸€ä¸ªå¾ˆå¤§çš„ä¸­é—´å’Œä¸ä¸€ä¸ªå¾ˆå°çš„ä¹˜ç§¯ç›¸åŠ ï¼Œè¿™ä¸ªå¾ˆå°çš„ä¹˜ç§¯å¯èƒ½ä¼šå› ä¸ºç²¾åº¦é™åˆ¶è€Œè¢«åæ‰ï¼Œç›´æ¥å˜æˆé›¶ï¼Œå¯¹æœ€ç»ˆç»“æœæ¯«æ— è´¡çŒ®ã€‚ DeepSeek-V3 å¼•å…¥äº†ä¸€ç§ç»†ç²’åº¦çš„é‡åŒ–ç­–ç•¥: $1\\times N_c$ å…ƒç´ çš„ tile åˆ†ç»„æˆ– $N_cN_c\\times N_c$ å…ƒç´ çš„ block åˆ†ç»„ã€‚å¹¶ä¸”åœ¨å…¶è®¾è®¡çš„é«˜ç²¾åº¦ç´¯åŠ è¿‡ç¨‹è¿‡ç¨‹ä¸­ï¼Œç›¸å…³çš„åé‡åŒ–å¼€é”€åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¾—åˆ°äº†ç¼“è§£ã€‚æ­¤å¤–ï¼Œä¸ºäº†è¿›ä¸€æ­¥å‡å°‘ MoE è®­ç»ƒä¸­çš„å†…å­˜å’Œé€šä¿¡å¼€é”€ï¼ŒDeepSeek-V3 ç”¨ FP8 æ ¼å¼ç¼“å­˜å’Œ dispatch æ¿€æ´»ï¼Œä»¥ BF16 æ ¼å¼å­˜å‚¨ä½ç²¾åº¦ä¼˜åŒ–å™¨çŠ¶æ€ã€‚ç›¸è¾ƒäº BF16 baseline, FP8 è®­ç»ƒçš„ç›¸å¯¹è¯¯å·®ä½äº 0.25%.\n3.3.1 Mixed Precision Framework å¦‚å›¾ä¸­æ‰€ç¤º Fprop(forward pass), Dgrad(activation backward pass) ä»¥åŠ Wgrad(weight backward pass) GEMM æ“ä½œçš„è¾“å…¥æ˜¯ FP8 æ ¼å¼ï¼Œè¾“å‡ºä¸º BF16 æˆ–è€… FP32 æ ¼å¼ã€‚ä»¥ FP8 æ ¼å¼è¿›è¡Œ Wgrad å…è®¸æ¿€æ´»ä¹Ÿä»¥ FP8 æ ¼å¼è¿›è¡Œå­˜å‚¨ï¼Œå‡å°‘äº†å†…å­˜å ç”¨ã€‚\nThe Overall Mixed Precision Framework with FP8 Data Format\nä¸€äº›ä½å¼€é”€çš„ç®—å­å¯ä»¥ä½¿ç”¨æ›´é«˜ç²¾åº¦å¹¶ä¸”å¯¹è®­ç»ƒå¼€é”€çš„å½±å“å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚DeepSeek-V3 å¯¹è¿™äº›æ¨¡å—ä½¿ç”¨åŸæ ¼å¼è¿›è¡Œè¿ç®—ï¼šEmbeddingï¼Œè¾“å‡ºå¤´ï¼ŒMoE é—¨æ§ï¼Œå½’ä¸€åŒ–æ“ä½œä»¥åŠ Attention æ“ä½œã€‚åŒæ—¶ä¸ºäº†æ•°å€¼ç¨³å®šæ€§ï¼Œä»¥æ›´é«˜ç²¾åº¦å­˜å‚¨ master weights(FP32), weight gradients(FP32) \u0026amp; optimizer states(BF16). è¿™äº›é«˜ç²¾åº¦éƒ¨åˆ†å¸¦æ¥çš„å†…å­˜å¼€é”€å¯ä»¥è¢« DP å‡è½»ã€‚\n3.3.2 Improved Precision from Quantization and Multiplication DeepSeek-V3 ä½¿ç”¨äº†å¦‚ä¸‹æŠ€æœ¯æ¥æé«˜ä½ç²¾åº¦è®­ç»ƒçš„å‡†ç¡®æ€§:\nAs a standard practice, the input distribution is aligned to the representable range of the FP8 format by scaling the maximum absolute value of the input tensor to the maximum representable value of FP8 (Narang et al., 2017). This method makes lowprecision training highly sensitive to activation outliers, which can heavily degrade quantization accuracy.\nFine-Grained Quantization. å¦‚ä¸‹å›¾ æ‰€ç¤º DeepSeek-V3 é‡‡å–æ›´ç»†ç²’åº¦çš„æ–¹å¼å¯¹è¾“å…¥è¿›è¡Œç¼©æ”¾åˆ° FP8 çš„è¡¨ç¤ºèŒƒå›´: (1) å¯¹äºæ¿€æ´»ä»¥ 1x128 tile è¿›è¡Œåˆ†ç»„å’Œç¼©æ”¾ (æ¯ä¸ª token çš„ 128 é€šé“ä¸ºä¸€ç»„); (2) å¯¹äºæƒé‡ä»¥ 128x128 è¿›è¡Œåˆ†ç»„å’Œç¼©æ”¾ (æ¯ 128 ä¸ªè¾“å…¥å’Œè¾“å‡ºé€šé“ä¸ºä¸€ç»„). è™½ç„¶åŸç”Ÿçš„ FP8 GEMM ä¸æ”¯æŒå¯¹ reduction ç»´åº¦è¿›è¡ŒæŒ‰ç»„ç¼©æ”¾ï¼Œä½†å¯ä»¥å’Œä¸‹é¢ä»‹ç»çš„ FP32 ç´¯åŠ ç­–ç•¥è¿›è¡Œé…åˆä½¿ç”¨ã€‚\nFine-grained Quantization\nIncreasing Accumulation Precision. NVIDIA H800 GPU ä¸Šçš„ FP8 GEMM ç´¯åŠ ç²¾åº¦è¢«é™åˆ¶åœ¨ 14 bits (è¿œä½äº FP32). ä¸ºåœ¨ä½ç²¾åº¦è®¡ç®—ä¸­ç¡®ä¿æœ€ç»ˆçš„æ•°å€¼ç²¾åº¦ï¼ŒDeepSeek-V3 é‡‡ç”¨äº†ä¸€ç§ç»“åˆ Tensor Cores ä¸ CUDA Cores çš„æ··åˆè®¡ç®—æµç¨‹ã€‚é¦–å…ˆåˆ©ç”¨ Tensor Cores çš„é«˜ååé‡ç‰¹æ€§æ¥æ‰§è¡Œ MMA (Matrix Multiply-Accumulate) è¿ç®—ï¼Œä¸­é—´ç»“æœåœ¨ç¡¬ä»¶åŸç”Ÿçš„æœ‰é™ä½å®½ç´¯åŠ å™¨ä¸­è¿›è¡Œé˜¶æ®µæ€§ç´¯åŠ ã€‚å½“ç´¯åŠ æ“ä½œè¿›è¡Œ $N_c$ æ¬¡åï¼Œæ‰€äº§ç”Ÿçš„éƒ¨åˆ†å’Œå°†è¢«ç«‹å³å¤åˆ¶åˆ° CUDA Cores ä¸Šçš„ FP32 å¯„å­˜å™¨ä¸­ï¼Œå¹¶ä¸å„è‡ªå¯¹åº”çš„ç»†ç²’åº¦é‡åŒ–ç¼©æ”¾å› å­ç›¸ä¹˜ï¼Œä»è€Œåœ¨æ‰§è¡Œå…¨ç²¾åº¦ FP32 æœ€ç»ˆç´¯åŠ çš„åŒæ—¶ï¼Œé«˜æ•ˆåœ°å®Œæˆäº†åé‡åŒ–æ“ä½œã€‚è¿™æ ·èƒ½å°†åé‡åŒ–å¼€é”€æ— ç¼èå…¥åˆ°é«˜ç²¾åº¦ç´¯åŠ æ­¥éª¤ä¸­ï¼Œä»è€Œä»¥æœ€å°çš„æ€§èƒ½ä»£ä»·ä¿è¯äº†æœ€ç»ˆç»“æœçš„ç²¾ç¡®æ€§ã€‚\nIncreasing Accumulation Precision\nåœ¨ H800 æ¶æ„ä¸Šï¼Œå…¸å‹çš„æƒ…å†µæ˜¯ä¸¤ä¸ª WGMMA åŒæ—¶å­˜åœ¨ï¼Œå½“ä¸€ä¸ª warp group æ‰§è¡Œ promotion åˆ° CUDA Core æ“ä½œæ—¶ï¼Œå¦ä¸€ä¸ª warp group èƒ½å¤Ÿæ‰§è¡Œ MMA æ“ä½œã€‚å®éªŒä¸­å– $N_c=128$ï¼Œå¯¹åº”äº 4 ä¸ª WGMMA.\nMantissa over Exponents. å¯¹æ‰€æœ‰é«˜ç²¾åº¦çš„å¼ é‡ä½¿ç”¨ 4EM3 æ ¼å¼ã€‚\nHow to Compute Float Point Value ä¸€ä¸ªå¸¸è§„æµ®ç‚¹æ•° (å³éé›¶ã€éæ— ç©·å¤§ç­‰ç‰¹æ®Šå€¼) çš„è®¡ç®—å…¬å¼ä¸ºï¼š\n$$\r\\text{Value} = (-1)^S \\times (1.M)_{\\text{binary}} \\times 2^{(E_{\\text{decimal}} - \\text{Bias})}\r$$è¦ç†è§£è¿™ä¸ªå…¬å¼ï¼Œ DeepSeek-V3 éœ€è¦æ‹†è§£é‡Œé¢çš„ä¸‰ä¸ªå…³é”®éƒ¨åˆ†ï¼šç¬¦å·ã€å°¾æ•°å’ŒæŒ‡æ•°ã€‚\nç¡®å®šç¬¦å· (Sign)\nS = 0ï¼Œåˆ™æ•°å€¼ä¸ºæ­£ï¼Œ$(-1)^0 = 1$ S = 1ï¼Œåˆ™æ•°å€¼ä¸ºè´Ÿï¼Œ$(-1)^1 = -1$ è®¡ç®—å°¾æ•°çš„å€¼ (Mantissa)\nä¸èƒ½ç›´æ¥ä½¿ç”¨ M çš„äºŒè¿›åˆ¶å€¼ã€‚åœ¨å¸¸è§„æµ®ç‚¹æ•°ä¸­ï¼Œæ ‡å‡†è§„å®šå°¾æ•°éƒ¨åˆ†æ°¸è¿œä»¥ 1. å¼€å¤´ã€‚è¿™æ ·ï¼Œè¿™ä¸ª 1 å°±ä¸éœ€è¦å®é™…å­˜å‚¨ï¼Œä»è€Œå¯ä»¥èŠ‚çœä¸€ä¸ªæ¯”ç‰¹ä½æ¥æé«˜ç²¾åº¦ã€‚å› æ­¤ï¼Œå°¾æ•°çš„å®é™…å€¼æ˜¯ (1.M) çš„äºŒè¿›åˆ¶å½¢å¼ã€‚\nå‡è®¾å°¾æ•°ä½æ˜¯ $m_1 m_2 m_3 \\dots$ï¼Œå…¶ä»£è¡¨çš„å°æ•°å€¼ä¸º\n$$\rm_1 \\times 2^{-1} + m_2 \\times 2^{-2} + m_3 \\times 2^{-3} + \\dots\r$$.\næœ€ç»ˆå°¾æ•°é¡¹çš„å€¼ä¸º $1 + (m_1 \\times 2^{-1} + m_2 \\times 2^{-2} + m_3 \\times 2^{-3} + \\dots)$.\nè®¡ç®—æŒ‡æ•°çš„å€¼ (Exponent) æŒ‡æ•°éƒ¨åˆ†ä¹Ÿä¸èƒ½ç›´æ¥ä½¿ç”¨ã€‚ä¸ºäº†èƒ½è¡¨ç¤ºæ­£ã€è´ŸæŒ‡æ•°ï¼Œå¼•å…¥äº†åç½®å€¼ (Bias). é¦–å…ˆä» E çš„äºŒè¿›åˆ¶å€¼è®¡ç®—å‡ºå…¶åè¿›åˆ¶å€¼ $E_{\\text{decimal}}$ åå‡å» Bias($2^{k-1} - 1$). å…¶ä¸­ k æ˜¯æŒ‡æ•°ä½çš„æ¯”ç‰¹æ•°ã€‚\nå¯¹äº E4M3 (k=4)ï¼ŒBias = $2^{(4-1)} - 1 = 2^3 - 1 = 7$. å¯¹äº E5M2 (k=5)ï¼ŒBias = $2^{(5-1)} - 1 = 2^4 - 1 = 15$. ç‰¹æ®Šå€¼è¯´æ˜ å½“æŒ‡æ•° E å…¨ä¸º 0æˆ–å…¨ä¸º 1 æ—¶ï¼Œä»£è¡¨çš„æ˜¯ä¸€äº›ç‰¹æ®Šå€¼ï¼Œè®¡ç®—è§„åˆ™ä¹Ÿä¸åŒ: E å…¨ä¸º 0: å¦‚æœ M ä¹Ÿå…¨ä¸º 0ï¼Œä»£è¡¨é›¶ (Zero). å¦‚æœ M ä¸ä¸º 0ï¼Œä»£è¡¨éè§„æ ¼åŒ–æ•° (Subnormal Numbers)ï¼Œè®¡ç®—å…¬å¼å˜ä¸º $(-1)^S \\times (0.M) \\times 2^{(1 - \\text{Bias})}$ï¼Œæ­¤æ—¶æ²¡æœ‰éšå«çš„ 1. E å…¨ä¸º 1: å¦‚æœ M å…¨ä¸º0ï¼Œä»£è¡¨æ— ç©·å¤§ (Infinity)ã€‚ å¦‚æœ M ä¸ä¸º0ï¼Œä»£è¡¨NaN(Not a Number). Online Quantization. é‡‡ç”¨ online æ–¹å¼è®¡ç®—æ¯ä¸ª 1x128 æ¿€æ´» tile å’Œ 128x128 æƒé‡ block çš„æœ€å¤§ç»å¯¹å€¼ã€‚\n3.3.3 Low-Precision Storage and Communication Low-Precision Optimizer States. ç”¨ BF16 æ ¼å¼å­˜å‚¨ AdamW ä¼˜åŒ–å™¨çš„ä¸€é˜¶å’ŒäºŒé˜¶åŠ¨é‡ã€‚ä¼˜åŒ–å™¨å­˜å‚¨çš„ master weights å’Œ betch çš„ç´¯åŠ æ¢¯åº¦ä»ä»¥ FP32 æ ¼å¼å­˜å‚¨ã€‚\nLow-Precision Activation. å¤§éƒ¨åˆ†æ¿€æ´»ä»¥ FP8 æ ¼å¼å­˜å‚¨ï¼Œä½†ä»¥ä¸‹è¿™äº›æ˜¯ä¾‹å¤–ã€‚\nInputs of the Linear after the attention operator. è¿™äº›æ¿€æ´»ä¼šåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä½œä¸º attention çš„è¾“å…¥ï¼Œå¯¹ç²¾åº¦æ¯”è¾ƒæ•æ„Ÿï¼Œå› æ­¤é‡‡ç”¨ E5M6 æ ¼å¼å­˜å‚¨ã€‚é‡åŒ–è¿‡ç¨‹çš„ç¼©æ”¾å› å­è¢«é™åˆ¶ä¸º 2 çš„æ•´æ•°æ¬¡å¹‚ã€‚ Inputs of the SwiGLU operator in MoE. ä»¥ FP8 æ ¼å¼å­˜å‚¨ SwiGLU çš„è¾“å…¥ç„¶åå†åå‘ä¼ æ’­ä¸­é‡è®¡ç®—ã€‚ Low-Precision Communication. åœ¨ dispatch ä¹‹å‰å¯¹ MoE up-projections çš„è¾“å…¥è¿›è¡Œ FP8 é‡åŒ–ã€‚ä¸“å®¶æ¥æ”¶åˆ° FP8 æ•°æ®åï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå…¼å®¹çš„ FP8 å‰å‘ä¼ æ’­ã€‚é‡åŒ–è¿‡ç¨‹çš„ç¼©æ”¾å› å­è¢«é™åˆ¶ä¸º 2 çš„æ•´æ•°æ¬¡å¹‚ã€‚åœ¨åå‘ä¼ æ’­è¿›å…¥ MoE down-projections ä¹‹å‰åŒæ ·ä½¿ç”¨è¯¥ç­–ç•¥ã€‚å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ combine åçš„ç»“æœä»¥ FP16 æ ¼å¼å­˜å‚¨ã€‚\n3.4 Inference and Deployment ä¸ºäº†åŒæ—¶ä¿è¯ Service-Level Objective (SLO) å’Œé«˜ååé‡, prefilling å’Œ decoding é˜¶æ®µé‡‡ç”¨äº†ä¸åŒçš„éƒ¨ç½²ç­–ç•¥ã€‚\nprefilling é˜¶æ®µçš„éƒ¨ç½²å•å…ƒä¸º 4 ä¸ªèŠ‚ç‚¹ (32 GPUs). å¹¶è¡Œç­–ç•¥å¦‚ä¸‹\nattention part: é‡‡ç”¨å¸¦æœ‰ Sequence Parallel (SP) çš„ 4-way Tensor Parallel (TP4)ï¼Œå¹¶ä¸”å’Œ 8-way Data Parallelism (DP8) ä¸€èµ·ä½¿ç”¨ã€‚ MoE part: é‡‡ç”¨ 32-way Expert Parallelism (EP32), shallow layer ä¸ä½¿ç”¨ TP. å…¶ä»–éƒ¨ç½²ç»†èŠ‚:\nredundant experts: éƒ¨ç½² 32 é«˜è´Ÿè½½çš„ä¸“å®¶ (æ¯ååˆ†é’Ÿç»Ÿè®¡ä¸€æ¬¡è¿›è¡Œè°ƒæ•´) å‰¯æœ¬ã€‚æ¯ä¸ª GPU é™¤äº†æœ‰è‡ªå·±çš„ 8 ä¸ªä¸“å®¶ä¹‹å¤–è¿˜æœ‰ 1 ä¸ªé«˜è´Ÿè½½ä¸“å®¶ã€‚ åŒæ—¶å¤„ç†ä¸¤ä¸ªè®¡ç®—é‡å·®ä¸å¤šçš„ micro-batchesï¼Œæ¥æ©ç›– All-to-all å’Œ TP çš„é€šä¿¡ã€‚å³å°†ä¸€ä¸ª micro-batch çš„ attention+MoE å’Œå¦ä¸€ä¸ª batch çš„ dispatch+combine é‡å ã€‚ dynamic redundancy: æ¯ä¸ª GPU ä¸Šæ”¾ç½® 16 ä¸ªä¸“å®¶ï¼Œä½†æ¯æ¬¡åªæœ‰ 9 ä¸ªè¢«æ¿€æ´»ã€‚ decoding é˜¶æ®µçš„éƒ¨ç½²å•å…ƒä¸º 40 ä¸ªèŠ‚ç‚¹ (320 GPUs). å¹¶è¡Œç­–ç•¥å¦‚ä¸‹\nattention part: é‡‡ç”¨å¸¦æœ‰ SP çš„ TP4ï¼Œå¹¶ä¸”å’Œ DP80 ä¸€èµ·ä½¿ç”¨ã€‚ MoE part: é‡‡ç”¨ EP320. 256 GPU è¢«ç”¨æ¥æ”¾ç½®è·¯ç”±ä¸“å®¶ï¼Œ64 GPU è¢«ç”¨æ¥æ”¾ç½®å…±äº«ä¸“å®¶å’Œå†—ä½™ä¸“å®¶ã€‚ All-to-all é€šè¿‡ IB è¿›è¡Œç‚¹å¯¹ç‚¹ç›´æ¥ä¼ è¾“ã€‚åŒæ—¶åˆ©ç”¨ IBGDA æŠ€æœ¯è®©ç½‘å¡ç›´æ¥è¯»å†™ GPU å†…å­˜ã€‚ç³»ç»Ÿä¼šæ ¹æ®æµé‡ç»Ÿè®¡å‘¨æœŸæ€§åœ°åˆ¤æ–­å“ªäº›å¸¸è§„è·¯ç”±ä¸“å®¶æ˜¯å½“å‰æœ€çƒ­é—¨çš„ï¼Œç„¶ååŠ¨æ€åœ°è®©é‚£ 64 ä¸ªGPUå»æ‰®æ¼”è¿™äº›çƒ­é—¨ä¸“å®¶çš„å‰¯æœ¬ã€‚å› ä¸ºæ¯ä¸ª GPU åªè¢«æ”¾ç½®ä¸€ä¸ªä¸“å®¶ï¼Œæ‰€ä»¥å½“éœ€è¦æ›´æ”¹å†—ä½™ç­–ç•¥æ—¶ç³»ç»Ÿåªéœ€è¦æ”¹å˜è·¯ç”±é€»è¾‘ï¼Œä¸éœ€è¦åœ¨ç‰©ç†ä¸Šç§»åŠ¨æˆ–é‡æ–°åŠ è½½æ¨¡å‹æƒé‡ã€‚\nåœ¨ decoding è¿‡ç¨‹ä¸­ attention ä¼šè€—è´¹æ›´å¤šæ—¶é—´ã€‚å› æ­¤å°†ä¸€ä¸ª micro-batch çš„ attention å’Œå¦ä¸€ä¸ªçš„ dispatch+MoE+combine é‡å ã€‚decoding é˜¶æ®µæ¯ä¸ª GPU åªéœ€è¦åŠ è½½ä¸€ä¸ªä¸“å®¶çš„å‚æ•°ï¼Œå› æ­¤å¯ä»¥åˆ†é…æ›´å¤šçš„ SM ç»™ attention éƒ¨åˆ†æ¥åŠ é€Ÿå…¶è®¡ç®—ã€‚\n3.5 Suggestions on Hardware Design åŸºäº All-to-all å®ç°å’Œ FP8 è®­ç»ƒæ¡†æ¶ï¼ŒDeepSeek-V3 å¯¹ AI ç¡¬ä»¶å‚å•†æå‡ºäº†ä¸€äº›å»ºè®®ã€‚\n3.5.1 Communication Hardware å½“å‰é€šä¿¡ç®—å­çš„å®ç°ä¾èµ–äº SMï¼ŒDeepSeek-V3 ä½¿ç”¨äº† 20 ä¸ª H800 SMs (ä¸€å…± 132 ä¸ª) ç”¨äºé€šä¿¡ï¼Œä½†ä½¿ç”¨ SM è¿›è¡Œé€šä¿¡ä¼šå¯¼è‡´ tensor core åˆ©ç”¨ç‡å¾ˆä½ã€‚\nå½“å‰ SM ä¸»è¦åœ¨ All-to-all é€šä¿¡ä¸­æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡:\nIB å’Œ NVLink åŸŸä¹‹é—´çš„æ•°æ®è½¬å‘ï¼Œå°†ç›®çš„åœ°ä¸ºåŒä¸€èŠ‚ç‚¹å†…å¤šä¸ªä¸åŒ GPU çš„æµé‡ï¼Œé¦–å…ˆæ±‡èšåˆ°å•ä¸ªä»£ç†GPUä¸Šã€‚ åœ¨ RDMA ç¼“å†²åŒº (å·²æ³¨å†Œçš„ GPU å†…å­˜åŒºåŸŸ) ä¸æ¨¡å‹çš„è¾“å…¥/è¾“å‡ºç¼“å†²åŒºä¹‹é—´è¿›è¡Œæ•°æ®æ¬è¿ã€‚ ä¸º All-to-all é€šä¿¡çš„ combine é˜¶æ®µæ‰§è¡Œ reduce æ“ä½œã€‚ åœ¨éœ€è¦è·¨è¶Š IB å’Œ NVLink ç½‘ç»œåŸŸã€å‘å¤šä¸ªä¸åŒä¸“å®¶è¿›è¡Œåˆ†å—æ•°æ®ä¼ è¾“åœ¨ä¸€ä¸ª GPUä¸Š çš„tokensï¼Œå…¶ä¸­ä¸€äº›å¯èƒ½è¦å»å½“å‰èŠ‚ç‚¹å†…çš„ä¸“å®¶ (é€šè¿‡NVLink)ï¼Œå¦ä¸€äº›åˆ™è¦å»å…¶ä»–èŠ‚ç‚¹ä¸Šçš„ä¸“å®¶ (é€šè¿‡IB). åœ¨å‘é€ä¹‹å‰ï¼ŒGPUå¿…é¡»åœ¨è‡ªå·±çš„å†…å­˜é‡Œè¿›è¡Œä¸€æ¬¡æ•°æ®é‡æ’ï¼ŒæŠŠæ‰€æœ‰ç›®çš„åœ°æ˜¯ä¸“å®¶ A çš„ tokens æ‰“åŒ…æˆä¸€ä¸ªè¿ç»­çš„å†…å­˜å—ï¼Œæ‰€æœ‰å»ä¸“å®¶ B çš„ tokens æ‰“åŒ…æˆå¦ä¸€ä¸ªå†…å­˜å—ã€‚\rçš„è¿‡ç¨‹ä¸­ï¼Œç®¡ç†ç»†ç²’åº¦çš„å†…å­˜å¸ƒå±€ã€‚ 3.5.2 Compute Hardware Higher FP8 GEMM Accumulation Precision in Tensor Cores. åœ¨ç›®å‰ NVIDIA Hopper æ¶æ„çš„ Tensor Core å®ç°ä¸­ï¼ŒFP8 GEMM çš„ç´¯ç§¯ç²¾åº¦æœ‰é™ã€‚åœ¨æ ¹æ®æœ€å¤§æŒ‡æ•°å³ç§»å¯¹é½ 32 ä¸ªå°¾æ•°ä¹˜ç§¯åï¼ŒTensor Core åªä½¿ç”¨æ¯ä¸ªå°¾æ•°ä¹˜ç§¯çš„æœ€é«˜ 14 ä½è¿›è¡ŒåŠ æ³•ï¼Œå¹¶æˆªæ–­è¶…è¿‡æ­¤èŒƒå›´çš„ä½ã€‚å°†åŠ æ³•ç»“æœç´¯åŠ åˆ°å¯„å­˜å™¨ä¸­ä¹Ÿé‡‡ç”¨ 14 ä½ç²¾åº¦ã€‚\nSupport for Tile- and Block-Wise Quantization. ç›®å‰çš„ GPU åªæ”¯æŒé€å¼ é‡é‡åŒ–ï¼Œç¼ºä¹å¯¹ç»†ç²’åº¦é‡åŒ–çš„åŸç”Ÿæ”¯æŒï¼Œæ¯”å¦‚ DeepSeek çš„ tile é‡åŒ–å’Œ block é‡åŒ–ã€‚åœ¨å½“å‰çš„å®ç°ä¸­ï¼Œå½“ç´¯åŠ  $N_c$ æ¬¡æ—¶ï¼Œéƒ¨åˆ†ç»“æœå°†ä» Tensor Core å¤åˆ¶åˆ° CUDA Coreï¼Œä¹˜ä»¥ç¼©æ”¾å› å­ï¼Œå¹¶ç´¯åŠ åˆ° CUDA Core ä¸Šçš„FP32 å¯„å­˜å™¨ã€‚å°½ç®¡ä¸ç²¾ç¡®çš„ FP32 ç´¯åŠ ç­–ç•¥ç›¸ç»“åˆï¼Œåé‡åŒ–å¼€é”€æ˜¾ç€å‡è½»ï¼Œä½† Tensor Core å’Œ CUDA Core ä¹‹é—´é¢‘ç¹çš„æ•°æ®ç§»åŠ¨ä»ç„¶é™åˆ¶äº†è®¡ç®—æ•ˆç‡ã€‚\nSupport for Online Quantization. å½“å‰æƒ…å†µä¸‹éœ€è¦ä» HBM ä¸­è¯»å– 128 ä¸ª BF16 æ¿€æ´»å€¼ (ä¹‹å‰è®¡ç®—çš„è¾“å‡º) è¿›è¡Œé‡åŒ–ï¼Œç„¶åå°†é‡åŒ–åçš„ FP8 å€¼å†™å› HBMï¼Œç„¶åå†æ¬¡è¯»å–ä»¥è¿›è¡Œ MMA.\nSupport for Transposed GEMM Operations. åœ¨å½“å‰å·¥ä½œæµç¨‹ä¸­ï¼Œå‰å‘ä¼ æ’­çš„æ¿€æ´»è¢«é‡åŒ–ä¸º 1x128 FP8 tile å¹¶å­˜å‚¨ã€‚åœ¨åå‘ä¼ æ’­ä¸­ï¼ŒçŸ©é˜µéœ€è¦è¢«è¯»å‡ºã€åé‡åŒ–ã€è½¬ç½®ã€é‡æ–°é‡åŒ–ä¸º 128x1 tileï¼Œå¹¶å­˜å‚¨åœ¨ HBM ä¸­ã€‚\nDeepSeek-V3 çš„é¢„è®­ç»ƒé˜¶æ®µå›´ç»•ç€é«˜è´¨é‡çš„æ•°æ®æ„å»ºã€ç²¾å¿ƒè®¾è®¡çš„è¶…å‚æ•°ã€é•¿ä¸Šä¸‹æ–‡æ‰©å±•ä»¥åŠå…¨é¢çš„æ€§èƒ½è¯„æµ‹å±•å¼€ã€‚\n4. Pretraining 4.1 Data Construction è®­ç»ƒè¯­æ–™: æ¨¡å‹åœ¨ä¸€ä¸ªåŒ…å« 14.8T é«˜è´¨é‡ã€å¤šæ ·åŒ– token çš„è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚ ä¸ DeepSeek-V2 ç›¸æ¯”ï¼Œæ–°è¯­æ–™æå‡äº†æ•°å­¦å’Œç¼–ç¨‹ç›¸å…³æ ·æœ¬çš„æ¯”ä¾‹ï¼Œå¹¶æ‰©å±•äº†é™¤ä¸­è‹±æ–‡ä¹‹å¤–çš„å¤šè¯­è¨€è¦†ç›–èŒƒå›´ã€‚ æ•°æ®å¤„ç†æµç¨‹ç»è¿‡ä¼˜åŒ–ï¼Œæ—¨åœ¨æœ€å°åŒ–å†—ä½™ï¼ŒåŒæ—¶ä¿æŒè¯­æ–™çš„å¤šæ ·æ€§ã€‚ FIM ç­–ç•¥: æ¨¡å‹è®­ç»ƒä¸­é‡‡ç”¨äº† FIM (Fill-in-Middle) ç­–ç•¥ï¼Œè¯¥ç­–ç•¥è¢«è¯æ˜åœ¨ä¸æŸå®³å¸¸è§„â€œä¸‹ä¸€è¯é¢„æµ‹â€èƒ½åŠ›çš„åŒæ—¶ï¼Œèµ‹äºˆäº†æ¨¡å‹æ ¹æ®ä¸Šä¸‹æ–‡å‡†ç¡®é¢„æµ‹ä¸­é—´æ–‡æœ¬çš„èƒ½åŠ›ã€‚ FIM ç­–ç•¥åœ¨æ–‡æ¡£å±‚é¢ä»¥ 10% çš„åº”ç”¨ç‡å®æ–½ï¼Œå¹¶é‡‡ç”¨ Prefix-Suffix-Middle (PSM) æ¡†æ¶æ„å»ºæ•°æ®æ ¼å¼ã€‚ åˆ†è¯å™¨: åˆ†è¯å™¨é‡‡ç”¨ Byte-level BPEï¼Œè¯æ±‡è¡¨å¤§å°æ‰©å±•è‡³ 128K. ä¸ºäº†ä¼˜åŒ–å¤šè¯­è¨€å‹ç¼©æ•ˆç‡ï¼Œå¯¹é¢„åˆ†è¯å™¨å’Œè®­ç»ƒæ•°æ®è¿›è¡Œäº†ä¿®æ”¹ã€‚ ä¸ºäº†è§£å†³å› åˆå¹¶æ ‡ç‚¹å’Œæ¢è¡Œç¬¦å¯èƒ½å¯¼è‡´çš„ tokenè¾¹ç•Œåå·®ï¼Œè®­ç»ƒä¸­ä¼šéšæœºæ‹†åˆ†ä¸€éƒ¨åˆ†è¿™ç±»ç»„åˆ token. 4.2 Hyper-Parameters æ¨¡å‹ç»“æ„è¶…å‚æ•°: æ€»å…±æœ‰ 61 å±‚ Transformerï¼Œéšè—å±‚ç»´åº¦ä¸º 7168. MLA æ³¨æ„åŠ›å¤´æ•° $n_h$ ä¸º128ï¼Œæ¯ä¸ªå¤´çš„ç»´åº¦ä¸º 128. KV å‹ç¼©ç»´åº¦ $d_c$ ä¸º 512ï¼ŒQuery å‹ç¼©ç»´åº¦ $d_c^{'}$ ä¸º1536. é™¤äº†å‰ä¸‰å±‚ï¼Œå…¶ä½™æ‰€æœ‰ FFN éƒ½è¢«æ›¿æ¢ä¸º MoE å±‚ã€‚ æ¯ä¸ª MoE å±‚åŒ…å« 1ä¸ªå…±äº«ä¸“å®¶ å’Œ 256ä¸ªè·¯ç”±ä¸“å®¶ã€‚æ¯ä¸ª token ä¼šæ¿€æ´»å…¶ä¸­çš„ 8ä¸ª è·¯ç”±ä¸“ã€‚ é‡‡ç”¨ MTP ç­–ç•¥ï¼Œé¢„æµ‹æ·±åº¦ä¸º 1ï¼Œå³é™¤äº†ä¸‹ä¸€ä¸ªè¯ï¼Œè¿˜ä¼šé¢å¤–å†é¢„æµ‹ä¸€ä¸ªè¯ã€‚ æœ€ç»ˆæ¨¡å‹æ€»å‚æ•°é‡ä¸º 671Bï¼Œæ¯ä¸ª token çš„æ¿€æ´»å‚æ•°é‡ä¸º 37B. è®­ç»ƒè¶…å‚æ•°: ä¼˜åŒ–å™¨é‡‡ç”¨ AdamWï¼Œå…¶ä¸­ $\\beta_{1}=0.9, \\beta_{2}=0.95$ï¼Œæƒé‡è¡°å‡ä¸º 0.1. é¢„è®­ç»ƒé˜¶æ®µçš„æœ€å¤§åºåˆ—é•¿åº¦ä¸º 4K. å­¦ä¹ ç‡è°ƒåº¦ï¼šå…ˆåœ¨ 2K æ­¥å†…çº¿æ€§å¢é•¿è‡³ $2.2\\times10^{-4}$ï¼Œä¿æŒè¯¥é€Ÿç‡ç›´åˆ°æ¶ˆè€—10T tokenï¼Œç„¶ååœ¨ 4.3T token å†…ä½™å¼¦è¡°å‡è‡³ $2.2\\times10^{-5}$ï¼Œæœ€ååœ¨ 500B token çš„è®­ç»ƒä¸­è¿›ä¸€æ­¥è°ƒæ•´ã€‚ é‡‡ç”¨äº†æ‰¹æ¬¡å¤§å°è°ƒåº¦ç­–ç•¥ï¼Œä» 3072 é€æ­¥å¢åŠ åˆ°15360. è·¯ç”±æœºåˆ¶è¢«é™åˆ¶ä¸ºæ¯ä¸ª token æœ€å¤šå‘é€åˆ° 4 ä¸ªèŠ‚ç‚¹ï¼Œä»¥å¹³è¡¡è´Ÿè½½ã€‚ è´Ÿè½½å‡è¡¡ç­–ç•¥ä¸»è¦é‡‡ç”¨ auxiliary-loss-freeï¼Œåç½®æ›´æ–°é€Ÿç‡ $\\gamma$ åœ¨å‰ 14.3 Token æ—¶ä¸º 0.001ï¼Œå 500B token æ—¶ä¸º 0.0. å¯¹äºåºåˆ—çº§å¹³è¡¡æŸå¤± $\\alpha=0.00001$ï¼Œä»¥é˜²æ­¢å•ä¸€æ ·æœ¬å†…çš„æç«¯ä¸å¹³è¡¡ã€‚ MTP loss æƒé‡ $\\lambda$ å¯¹äºå‰ 10T token ä¸º 0.3ï¼Œå¯¹äºå 4.8T token ä¸º 0.1. 4.3 Long Context Extension æ‰©å±•æ–¹æ³•: é‡‡ç”¨ä¸ DeepSeek-V2 ç±»ä¼¼çš„æ–¹æ³•ï¼Œåœ¨é¢„è®­ç»ƒååº”ç”¨ YaRN æŠ€æœ¯è¿›è¡Œä¸Šä¸‹æ–‡æ‰©å±•ã€‚ æ‰©å±•é˜¶æ®µ: åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«å°†ä¸Šä¸‹æ–‡çª—å£ä» 4K æ‰©å±•åˆ° 32Kï¼Œå†è¿›ä¸€æ­¥æ‰©å±•åˆ° 128K. æ•ˆæœéªŒè¯: é€šè¿‡å¤§æµ·æé’ˆ (Needle In A Haystack) æµ‹è¯•è¡¨æ˜ï¼Œæ¨¡å‹åœ¨é«˜è¾¾ 128K çš„å®Œæ•´ä¸Šä¸‹æ–‡é•¿åº¦å†…å‡è¡¨ç°å‡ºè‰²ä¸”ç¨³å®šã€‚ 4.4 Evaluations è¯„æµ‹èŒƒå›´: ä¸»è¦åœ¨ä¸­è‹±æ–‡åŸºå‡†æµ‹è¯•ä»¥åŠä¸€ä¸ªå¤šè¯­è¨€åŸºå‡†ä¸Šè¿›è¡Œè¯„æµ‹ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„å¼€æºåŸºç¡€æ¨¡å‹è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚ DeepSeek-V2-Base, Qwen2.5 72B Base, å’Œ LLaMA-3.1 405B Base. è¯„æµ‹ç»“æœ: DeepSeek-V3-Base å…¨é¢è¶…è¶Šäº† DeepSeek-V2-Base å’Œ Qwen2.5 72B Baseï¼Œå¹¶åœ¨ç»å¤§å¤šæ•°åŸºå‡†ä¸Šè¶…è¿‡äº† LLaMA-3.1 405B Baseï¼Œæˆä¸ºå½“å‰æœ€å¼ºçš„å¼€æºæ¨¡å‹ã€‚ ä¸æ‹¥æœ‰ 11 å€æ¿€æ´»å‚æ•°é‡çš„ LLaMA-3.1 405B Base ç›¸æ¯”ï¼ŒDeepSeek-V3-Base åœ¨å¤šè¯­è¨€ã€ä»£ç å’Œæ•°å­¦åŸºå‡†ä¸Šè¡¨ç°å‡ºå¥½å¾—å¤šçš„æ€§èƒ½ã€‚ åœ¨è‹±è¯­å’Œä¸­æ–‡è¯­è¨€åŸºå‡†ä¸Šï¼ŒDeepSeek-V3-Base ä¹Ÿå±•ç°å‡ºæœ‰ç«äº‰åŠ›æˆ–æ›´å¥½çš„æ€§èƒ½ã€‚ è®­ç»ƒæ•ˆç‡: å¾—ç›Šäºé«˜æ•ˆçš„æ¶æ„å’Œå·¥ç¨‹ä¼˜åŒ–ï¼ŒDeepSeek-V3 çš„è®­ç»ƒæ•ˆç‡æé«˜ã€‚æ¯è®­ç»ƒ 1T token ä»…éœ€ 180K H800 GPU å°æ—¶ï¼Œè¿œæ¯”è®­ç»ƒ 72B æˆ– 405B çš„å¯†é›†æ¨¡å‹ä¾¿å®œã€‚ 4.5 Discussion æœ¬èŠ‚é€šè¿‡ä¸€ç³»åˆ—æ¶ˆèå®éªŒï¼Œæ·±å…¥æ¢è®¨äº†æ¨¡å‹é‡‡ç”¨çš„ä¸¤ä¸ªå…³é”®æ–°ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å¯¹è´Ÿè½½å‡è¡¡çš„ä¸åŒå®ç°æ–¹å¼è¿›è¡Œäº†å¯¹æ¯”åˆ†æã€‚\n4.5.1 Ablation Studies for Multi-Token Prediction å®éªŒè®¾ç½®: åœ¨ä¸¤ä¸ªä¸åŒè§„æ¨¡ (ä¸€ä¸ª15.7Bï¼Œä¸€ä¸ª228.7B) baseline MoEæ¨¡å‹ä¸Šè¿›è¡ŒéªŒè¯ã€‚ å¯¹æ¯”æ¨¡å‹åœ¨ baseline æ¨¡å‹çš„åŸºç¡€ä¸Šå¢åŠ äº†ä¸€ä¸ªé¢„æµ‹æ·±åº¦ä¸º 1 çš„MTPæ¨¡å—ï¼Œå…¶ä»–è®¾ç½® (å¦‚è®­ç»ƒæ•°æ®ã€æ¶æ„) ä¿æŒä¸å˜ã€‚ ä¸ºäº†ä¿è¯å…¬å¹³æ¯”è¾ƒï¼Œåœ¨æ¨ç†é˜¶æ®µä¼šä¸¢å¼ƒMTPæ¨¡å—ï¼Œå› æ­¤å¯¹æ¯”æ¨¡å‹çš„æ¨ç†æˆæœ¬å®Œå…¨ç›¸åŒã€‚ å®éªŒç»“è®º: å®éªŒç»“æœ (Table 4) è¡¨æ˜ï¼ŒMTPç­–ç•¥åœ¨ç»å¤§å¤šæ•°è¯„æµ‹åŸºå‡†ä¸Šéƒ½èƒ½ç¨³å®šåœ°æå‡æ¨¡å‹æ€§èƒ½ã€‚ ä¾‹å¦‚ï¼Œåœ¨å¤§å‹æ¨¡å‹ä¸Šï¼ŒHumanEval (ä»£ç ç”Ÿæˆ) å’Œ GSM8K (æ•°å­¦æ¨ç†) ç­‰ä»»åŠ¡çš„æ€§èƒ½å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚ 4.5.2 Ablation Studies for the Auxiliary-Loss-Free Balancing Strategy å®éªŒè®¾ç½®: åŒæ ·åœ¨ä¸¤ä¸ªä¸åŒè§„æ¨¡ (ä¸€ä¸ªå°å‹15.7Bï¼Œä¸€ä¸ªå¤§å‹228.7B) baseline MoE æ¨¡å‹ä¸Šè¿›è¡ŒéªŒè¯ã€‚ baseline æ¨¡å‹å®Œå…¨ä¾èµ–ä¼ ç»Ÿçš„è¾…åŠ©æŸå¤±å‡½æ•°æ¥ä¿ƒè¿›ä¸“å®¶è´Ÿè½½å‡è¡¡ã€‚ å¯¹æ¯”æ¨¡å‹åˆ™ç§»é™¤äº†æ‰€æœ‰è¾…åŠ©æŸå¤±ï¼Œå¹¶å¼•å…¥äº† Auxiliary-Loss-Free çš„å‡è¡¡ç­–ç•¥ï¼Œå…¶ä»–è®¾ç½®ä¿æŒä¸€è‡´ã€‚ å®éªŒç»“è®º: å®éªŒç»“æœ (Table 5) æ˜¾ç¤ºï¼ŒAuxiliary-Loss-Free ç­–ç•¥åœ¨ç»å¤§å¤šæ•°è¯„æµ‹åŸºå‡†ä¸Šéƒ½å–å¾—äº†æ¯”çº¯è¾…åŠ©æŸå¤±æ–¹æ³•æ›´å¥½çš„æ¨¡å‹æ€§èƒ½ã€‚ åœ¨ä»£ç å’Œæ•°å­¦ç­‰ä»»åŠ¡ä¸Šï¼Œæ€§èƒ½æå‡å°¤ä¸ºæ˜æ˜¾ã€‚ 4.5.3 Batch-Wise Load Balance VS. Sequence-Wise Load Balance æ ¸å¿ƒåŒºåˆ«: Auxiliary-Loss-Free ç­–ç•¥æ˜¯åœ¨æ•´ä¸ªè®­ç»ƒæ‰¹æ¬¡ (batch-wise) ä¸Šå®ç°å‡è¡¡ï¼Œè€Œä¼ ç»Ÿçš„è¾…åŠ©æŸå¤±åˆ™æ˜¯åœ¨æ¯ä¸ªåºåˆ— (sequence-wise) å†…éƒ¨å¼ºåˆ¶å®ç°å‡è¡¡ã€‚ ç†è®ºä¼˜åŠ¿: æ‰¹æ¬¡çº§çš„å‡è¡¡çº¦æŸæ›´ä¸ºçµæ´»ï¼Œå®ƒä¸å¼ºåˆ¶æ¯ä¸ªåºåˆ—å†…éƒ¨çš„ä¸“å®¶ä½¿ç”¨é¢‘ç‡éƒ½ä¸€æ ·ï¼Œä»è€Œå…è®¸ä¸“å®¶æ›´å¥½åœ°ä¸“ç²¾äºç‰¹å®šé¢†åŸŸ (å¦‚ä»£ç ã€æ•°å­¦ç­‰). å®éªŒéªŒè¯: é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸åŒé¢†åŸŸæ•°æ®ä¸Šçš„ä¸“å®¶è´Ÿè½½ï¼Œè§‚æµ‹åˆ° Auxiliary-Loss-Free æ¨¡å‹å±•ç°å‡ºäº†æ›´å¼ºçš„ä¸“å®¶ç‰¹åŒ–æ¨¡å¼ã€‚ è¿›ä¸€æ­¥çš„å®éªŒè¡¨æ˜ï¼Œåªè¦èƒ½å®ç°ç›¸ä¼¼æ°´å¹³çš„æ‰¹æ¬¡çº§è´Ÿè½½å‡è¡¡ï¼Œæ— è®ºæ˜¯ä½¿ç”¨ Auxiliary-Loss-Free æ–¹æ³•è¿˜æ˜¯æ–°è®¾è®¡çš„æ‰¹æ¬¡çº§ Auxiliary-Loss-Free æ–¹æ³•ï¼Œéƒ½èƒ½è¾¾åˆ°ç›¸ä¼¼çš„ä¼˜å¼‚æ¨¡å‹æ€§èƒ½ï¼Œä¸”å‡ä¼˜äºåºåˆ—çº§è¾…åŠ©æŸå¤±æ–¹æ³•ã€‚ æ½œåœ¨æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ: æ‰¹æ¬¡çº§å‡è¡¡å¯èƒ½é¢ä¸´ä¸¤ä¸ªæŒ‘æˆ˜ï¼šå•ä¸ªåºåˆ—æˆ–å°æ‰¹æ¬¡å†…çš„è´Ÿè½½ä¸å‡ï¼Œä»¥åŠæ¨ç†æ—¶å› é¢†åŸŸåˆ‡æ¢å¯¼è‡´çš„è´Ÿè½½ä¸å‡ã€‚ ç¬¬ä¸€ä¸ªæŒ‘æˆ˜é€šè¿‡ä½¿ç”¨å¤§è§„æ¨¡çš„ä¸“å®¶å¹¶è¡Œå’Œæ•°æ®å¹¶è¡Œ (ç¡®ä¿äº†æ¯ä¸ªå¾®æ‰¹æ¬¡çš„è§„æ¨¡è¶³å¤Ÿå¤§) å¾—ä»¥è‡ªç„¶è§£å†³ã€‚ ç¬¬äºŒä¸ªæŒ‘æˆ˜åˆ™é€šè¿‡åœ¨æ¨ç†éƒ¨ç½²ä¸­é‡‡ç”¨å†—ä½™ä¸“å®¶ç­–ç•¥æ¥å…‹æœã€‚ 5. Post-Training åè®­ç»ƒé˜¶æ®µæ—¨åœ¨å°†é¢„è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹ä¸äººç±»åå¥½å¯¹é½ï¼Œå¹¶è¿›ä¸€æ­¥è§£é”å…¶æ½œåŠ›ã€‚è¯¥é˜¶æ®µä¸»è¦åŒ…æ‹¬ç›‘ç£å¾®è°ƒ (SFT) å’Œå¼ºåŒ–å­¦ä¹  (RL)ï¼Œå¹¶æ¶‰åŠä» DeepSeek-R1 ç³»åˆ—æ¨¡å‹ä¸­è’¸é¦æ¨ç†èƒ½åŠ›ã€‚\n5.1 Supervised Fine-Tuning, SFT æ•°æ®é›†æ„å»º: SFT æ•°æ®é›†åŒ…å« 150 ä¸‡ä¸ªå®ä¾‹ï¼Œæ¶µç›–å¤šä¸ªé¢†åŸŸã€‚ æ¨ç†æ•°æ®: å¯¹äºæ•°å­¦ã€ä»£ç ã€é€»è¾‘ç­‰æ¨ç†ä»»åŠ¡ï¼Œåˆ©ç”¨å†…éƒ¨çš„ DeepSeek-R1 æ¨¡å‹ç”Ÿæˆæ•°æ®ã€‚è™½ç„¶ R1 ç”Ÿæˆçš„æ•°æ®å‡†ç¡®æ€§é«˜ï¼Œä½†å­˜åœ¨è¿‡åº¦æ€è€ƒã€æ ¼å¼ä¸ä½³å’Œé•¿åº¦è¿‡é•¿ç­‰é—®é¢˜ã€‚ä¸ºäº†å¹³è¡¡å‡†ç¡®æ€§ä¸ç®€æ´æ€§ï¼ŒSFT è®­ç»ƒä¸­ä¼šæ··åˆä½¿ç”¨åŸå§‹åº”ç­”å’Œç»è¿‡ç²¾å¿ƒè®¾è®¡çš„ç³»ç»Ÿæç¤ºè¯å¼•å¯¼ä¸‹çš„ R1 åº”ç­”ã€‚ éæ¨ç†æ•°æ®: å¯¹äºåˆ›æ„å†™ä½œã€è§’è‰²æ‰®æ¼”ç­‰ä»»åŠ¡ï¼Œä½¿ç”¨ DeepSeek-V2.5 ç”Ÿæˆåº”ç­”ï¼Œå¹¶ç”±äººç±»æ ‡æ³¨å‘˜è¿›è¡ŒéªŒè¯ã€‚ SFT è®¾ç½®: æ¨¡å‹åœ¨ SFT æ•°æ®é›†ä¸Šå¾®è°ƒäº† 2 ä¸ª epoch. å­¦ä¹ ç‡é‡‡ç”¨ä½™å¼¦è¡°å‡ç­–ç•¥ï¼Œä» $5\\times10^{-6}$ é™è‡³ $1\\times10^{-6}$. è®­ç»ƒåºåˆ—ç”±å¤šä¸ªæ ·æœ¬æ‰“åŒ…è€Œæˆï¼Œä½†é‡‡ç”¨æ ·æœ¬æ©ç ç­–ç•¥ç¡®ä¿æ ·æœ¬é—´ç›¸äº’éš”ç¦»ã€‚ 5.2 Reinforcement Learning 5.2.1 Reward Model RL è¿‡ç¨‹é‡‡ç”¨äº† Rule-Based æ¨¡å‹å’Œ Model-Based çš„å¥–åŠ±æ¨¡å‹ã€‚\nRule-Based RM: ç”¨äºæœ‰æ˜ç¡®éªŒè¯è§„åˆ™çš„é—®é¢˜ï¼Œå¦‚æ•°å­¦é¢˜çš„ç¡®å®šæ€§ç­”æ¡ˆæˆ–ä»£ç é¢˜çš„å•å…ƒæµ‹è¯•ç»“æœã€‚è¿™ç§æ–¹å¼å¯é æ€§é«˜ï¼Œä¸æ˜“è¢«æ¨¡å‹é’»ç©ºå­ã€‚ Model-Based RM: ç”¨äºç­”æ¡ˆæ›´å¼€æ”¾ã€æ²¡æœ‰ç¡®å®šæ€§å¯¹é”™çš„é—®é¢˜ã€‚è¯¥å¥–åŠ±æ¨¡å‹ç”± DeepSeek-V3 çš„ SFT ç‰ˆæœ¬è®­ç»ƒè€Œæ¥ï¼Œå¹¶é€šè¿‡åŒ…å«æ€ç»´é“¾çš„åå¥½æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»¥é™ä½ reward hacking çš„é£é™©ã€‚ 5.2.2 GRPO é‡‡ç”¨äº† GRPO (Group Relative Policy Optimization) ç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚ GRPO çš„ä¸€ä¸ªç‰¹ç‚¹æ˜¯å®ƒä¸éœ€è¦ä¸€ä¸ªä¸ç­–ç•¥æ¨¡å‹åŒç­‰å¤§å°çš„ critic æ¨¡å‹ï¼Œè€Œæ˜¯ä»ä¸€ç»„é‡‡æ ·è¾“å‡ºçš„åˆ†æ•°ä¸­ä¼°è®¡ baseline. RL è¿‡ç¨‹èåˆäº†æ¥è‡ªç¼–ç ã€æ•°å­¦ã€å†™ä½œã€è§’è‰²æ‰®æ¼”ç­‰ä¸åŒé¢†åŸŸçš„æç¤ºè¯ï¼Œè¿™ä¸ä»…ä½¿æ¨¡å‹ä¸äººç±»åå¥½æ›´å¯¹é½ï¼Œä¹Ÿæå‡äº†åœ¨ SFT æ•°æ®æœ‰é™åœºæ™¯ä¸‹çš„åŸºå‡†æµ‹è¯•æ€§èƒ½ã€‚ 5.3 Evaluations è¯„æµ‹è®¾ç½®: é™¤äº†åŸºç¡€æ¨¡å‹è¯„æµ‹ç”¨çš„åŸºå‡†å¤–ï¼Œè¿›ä¸€æ­¥åœ¨ IFEval, GPQA, LongBench v2, SWE-Bench Verified, Aider, Codeforces, AIME 2024 ç­‰æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚ å¯¹æ¯”çš„ baseline æ¨¡å‹åŒ…æ‹¬å…¶ä»–å¼ºå¤§çš„å¼€æºå’Œé—­æºæ¨¡å‹ï¼Œå¦‚ Qwen2.5-72B-Inst, LLaMA-3.1-405B-Inst, Claude-3.5-Sonnet, å’Œ GPT-4o-0513ã€‚ Standard Evaluation: è¯„æµ‹ç»“æœ (Table 6) æ˜¾ç¤ºï¼ŒDeepSeek-V3 æ˜¯è¡¨ç°æœ€å¥½çš„å¼€æºèŠå¤©æ¨¡å‹ã€‚ åœ¨çŸ¥è¯†åŸºå‡† (MMLU, MMLU-Pro, GPQA-Diamond) ä¸Šï¼Œå…¶æ€§èƒ½ä¸é¡¶çº§çš„é—­æºæ¨¡å‹ç›¸å½“æˆ–ç›¸è¿‘ã€‚ åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£åŸºå‡† (DROP, LongBench v2, FRAMES) ä¸Šï¼Œè¡¨ç°å‡ºé¡¶çº§æ°´å¹³ï¼Œä¾‹å¦‚åœ¨ DROP ä¸Šå–å¾—äº† 91.6 çš„ F1 åˆ†æ•°ï¼Œè¶…è¶Šäº†æ‰€æœ‰å…¶ä»–æ¨¡å‹ã€‚ åœ¨ä»£ç å’Œæ•°å­¦åŸºå‡†ä¸Šè¡¨ç°å“è¶Šï¼Œå°¤å…¶æ˜¯åœ¨ AIME, MATH-500 ç­‰é«˜éš¾åº¦æ•°å­¦ç«èµ›åŸºå‡†ä¸Šï¼Œç»å¯¹å¾—åˆ†é¢†å…ˆç¬¬äºŒåçº¦ 10%ï¼Œä¼˜åŠ¿å·¨å¤§ã€‚ åœ¨ä¸­æ–‡åŸºå‡†ä¸Šï¼Œå¦‚ C-SimpleQAï¼Œå…¶è¡¨ç°ä¹Ÿè¶…è¶Šäº†åŒ…æ‹¬ Qwen2.5 åœ¨å†…çš„å…¶ä»–æ¨¡å‹ã€‚ Open-Ended Evaluation: åœ¨ Arena-Hard åŸºå‡†æµ‹è¯•ä¸­ï¼ŒDeepSeek-V3 å–å¾—äº†è¶…è¿‡ 85% çš„èƒœç‡ï¼Œä¸é¡¶çº§çš„ Claude-3.5-Sonnet-1022 è¡¨ç°æŒå¹³ï¼Œæˆä¸ºé¦–ä¸ªåœ¨è¯¥åŸºå‡†ä¸Šçªç ´ 85% çš„å¼€æºæ¨¡å‹ã€‚ åœ¨ AlpacaEval 2.0 ä¸Šï¼Œå…¶è¡¨ç°åŒæ ·å‡ºè‰²ï¼Œè¶…è¶Šäº†æ‰€æœ‰å¯¹æ¯”çš„å¼€æºå’Œé—­æºæ¨¡å‹ã€‚ ä½œä¸ºå¥–åŠ±æ¨¡å‹çš„èƒ½åŠ›: åœ¨ RewardBench åŸºå‡†ä¸Šè¯„æµ‹å…¶ä½œä¸ºå¥–åŠ±æ¨¡å‹çš„åˆ¤æ–­èƒ½åŠ›ï¼Œç»“æœæ˜¾ç¤º DeepSeek-V3 ä¸æœ€æ–°ç‰ˆæœ¬çš„ GPT-4o å’Œ Claude-3.5-Sonnet è¡¨ç°ç›¸å½“ã€‚ 5.4 Discussion ä» DeepSeek-R1 è’¸é¦çŸ¥è¯†: æ¶ˆèå®éªŒ (Table 9) è¯æ˜ï¼Œä»é•¿æ€ç»´é“¾ (long-CoT) æ¨¡å‹ DeepSeek-R1 ä¸­è’¸é¦çŸ¥è¯†çš„ç­–ç•¥éå¸¸æœ‰æ•ˆï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ LiveCodeBench å’Œ MATH-500 ä¸Šçš„æ€§èƒ½ã€‚ å®éªŒä¹Ÿæ­ç¤ºäº†ä¸€ä¸ªæƒè¡¡ï¼šè’¸é¦å¸¦æ¥äº†æ€§èƒ½æå‡ï¼Œä½†ä¹Ÿæ˜¾è‘—å¢åŠ äº†å›åº”çš„å¹³å‡é•¿åº¦ã€‚å› æ­¤ï¼Œåœ¨ DeepSeek-V3 çš„å¼€å‘ä¸­å¯¹è’¸é¦è®¾ç½®è¿›è¡Œäº†ä»”ç»†é€‰æ‹©ä»¥æ±‚å¹³è¡¡ã€‚ Self-Rewarding: åœ¨ç¼ºä¹æ˜ç¡®éªŒè¯è§„åˆ™çš„é€šç”¨åœºæ™¯ä¸­ï¼Œæ¨¡å‹å¼€å‘é‡‡ç”¨äº† constitutional AI çš„æ–¹æ³•ï¼Œå³ä½¿ç”¨ DeepSeek-V3 è‡ªèº«çš„æŠ•ç¥¨è¯„ä¼°ç»“æœä½œä¸ºåé¦ˆæºæ¥è¿›è¡Œä¼˜åŒ–ã€‚ è¿™ç§è‡ªå¥–åŠ±çš„èŒƒå¼äº§ç”Ÿäº†æ˜¾è‘—çš„å¯¹é½æ•ˆæœï¼Œå¹¶è¢«è®¤ä¸ºæ˜¯å®ç°LLMè‡ªæˆ‘æ”¹è¿›çš„é‡è¦æ–¹å‘ã€‚ MTP è¯„æµ‹: æ¨¡å‹é‡‡ç”¨çš„ MTP æŠ€æœ¯å¯ä»¥é¢„æµ‹ç¬¬ 2 ä¸ªtoken. è¯„æµ‹æ˜¾ç¤ºï¼Œè¿™ä¸ªé¢å¤–é¢„æµ‹çš„ token çš„æ¥å—ç‡åœ¨ 85%-90%ä¹‹é—´ã€‚ ç»“åˆ speculative decoding æ¡†æ¶ï¼Œè¿™ä¸ªé«˜æ¥å—ç‡ä½¿å¾—æ¨¡å‹çš„è§£ç é€Ÿåº¦ (TPS) æå‡äº†1.8å€. ","permalink":"http://localhost:1313/blogs/deepseek/deepseek-v3technicalreport/","summary":"Paper Reading of DeepSeek-V3 Technical Report","title":"DeepSeek-V3 Technical Report"},{"content":"Preliminary: Mixture-of-Experts for Transformers ä¸€ä¸ªæ ‡å‡†çš„ Transformer backbone LLM ç”±å †å å±‚æ ‡å‡† Transformer å—æ„æˆï¼Œæ¯ä¸ªå—å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹:\n$$\r\\mathbf{h}_t^l = \\sum_{i=1}^{N} \\left( g_{i,t} \\text{FFN}_i(\\mathbf{u}_t^l) \\right) + \\mathbf{u}_t^l \\tag{3}\r$$$$\rg_{i,t} = \\begin{cases} s_{i,t} \u0026 \\text{if } s_{i,t} \\in \\text{Topk}(\\{s_{j,t} | 1 \\le j \\le N\\}, K) \\\\ 0 \u0026 \\text{otherwise} \\end{cases} \\tag{4}\r$$$$\rs_{i,t} = \\text{Softmax}_i(\\mathbf{u}_t^T \\mathbf{e}_i^l) \\tag{5}\r$$ $N$: ä¸“å®¶æ€»æ•° $\\text{FFN}_i(\\cdot)$: ç¬¬ $i$ ä¸ªä¸“å®¶çš„ FFN. $g_{i,t}$: ç¬¬ $i$ ä¸ªä¸“å®¶çš„é—¨æ§å€¼ã€‚ $s_{i,t}$: token å¯¹ä¸“å®¶çš„äº²å’Œåº¦ã€‚ $\\text{Topk}(\\cdot, K)$: åœ¨ä¸ºç¬¬ $t$ ä¸ª token å’Œæ‰€æœ‰ $N$ ä¸ªä¸“å®¶è®¡ç®—å‡ºçš„äº²å’Œåº¦åˆ†æ•°ä¸­ï¼ŒåŒ…å« $K$ ä¸ªæœ€é«˜åˆ†æ•°çš„é›†åˆï¼Œ $\\mathbf{e}_i^l$: ç¬¬ $l$ å±‚ä¸­ç¬¬ $i$ ä¸ªä¸“å®¶çš„ä¸­å¿ƒã€‚ æ³¨æ„åˆ° $g_{i,t}$ æ˜¯ç¨€ç–çš„ï¼Œè¯´æ˜åœ¨ $N$ ä¸ªé—¨æ§å€¼ä¸­åªæœ‰ $K$ ä¸ªéé›¶ã€‚è¿™ç§ç¨€ç–æ€§ç¡®ä¿äº† MoE å±‚å†…çš„è®¡ç®—æ•ˆç‡ï¼Œå³æ¯ä¸ª token åªä¼šè¢«åˆ†é…ç»™ $K$ ä¸ªä¸“å®¶å¹¶ç”±å®ƒä»¬è®¡ç®—ã€‚æ­¤å¤–ï¼Œåœ¨ä¸Šè¿°å…¬å¼ä¸­ï¼Œä¸ºäº†ç®€æ´èµ·è§ï¼Œæˆ‘ä»¬çœç•¥äº†å±‚å½’ä¸€åŒ–æ“ä½œã€‚\nDeepSeekMoE Architecture Illustration of DeepSeek MoE\nFine-Grained Expert Segmentation åœ¨ä¸Šå›¾ (a) çš„æƒ…å†µä¸‹å°†æ¯ä¸ªä¸“å®¶ FFN çš„ä¸­é—´éšè—å±‚ç»´åº¦ç¼©å°åˆ°åŸå…ˆçš„ 1/mï¼Œä¸“å®¶æ•°å¢åŠ  m å€ã€‚è¿™æ ·å¯ä»¥åœ¨å‚æ•°é‡å’Œè®¡ç®—é‡ä¿æŒä¸å˜çš„æƒ…å†µä¸‹ä½¿å¾—æ¯ä¸ª token è¢«è·¯ç”±åˆ°æ›´å¤šçš„ä¸“å®¶ã€‚é€šè¿‡ç»†ç²’åº¦çš„ä¸“å®¶åˆ’åˆ†ï¼ŒMoE å±‚çš„è¾“å‡ºå¯ä»¥è¡¨ç¤ºä¸º\n$$\r\\begin{aligned}\r\\mathbf{h}_t^l \u0026= \\sum_{i=1}^{mN} \\left( g_{i,t} \\text{FFN}_i(\\mathbf{u}_t^l) \\right) + \\mathbf{u}_t^l \\quad\u0026(6)\\\\\rg_{i,t} \u0026= \\begin{cases} s_{i,t} \u0026 \\text{if } s_{i,t} \\in \\text{Topk}(\\{s_{j,t} | 1 \\le j \\le mN\\}, mK) \\\\ 0 \u0026 \\text{otherwise} \\end{cases} \\quad\u0026(7)\\\\\rs_{i,t} \u0026= \\text{Softmax}_i(\\mathbf{u}_t^T \\mathbf{e}_i^l) \\quad\u0026(8)\r\\end{aligned}\r$$ $mN$: ç»†ç²’åº¦ä¸“å®¶çš„æ€»æ•°ã€‚ $mK$: éé›¶é—¨æ§å€¼çš„æ•°é‡ä¹Ÿå°†å¢åŠ åˆ°ã€‚ ä¸“å®¶å‚æ•°æ€»æ•°ç­‰äº $N$ ä¹˜ä»¥æ ‡å‡† FFN ä¸­çš„å‚æ•°æ•°é‡ã€‚ä»ç»„åˆå¯èƒ½æ€§çš„è§’åº¦æ¥çœ‹ï¼Œç»†ç²’åº¦ä¸“å®¶åˆ†å‰²ç­–ç•¥æ˜¾è‘—å¢å¼ºäº†æ¿€æ´»ä¸“å®¶çš„ç»„åˆçµæ´»æ€§ã€‚\nShared Expert Isolation å¦‚ä¸Šå›¾ (c) æ‰€ç¤º å°† $K_s$ ä¸ªä¸“å®¶éš”ç¦»å‡ºæ¥ä½œä¸ºå…±äº«ä¸“å®¶ã€‚æ— è®ºè·¯ç”±æ¨¡å—å¦‚ä½•ï¼Œæ¯ä¸ª token éƒ½ä¼šè¢«ç¡®å®šæ€§åœ°åˆ†é…ç»™è¿™äº›å…±äº«ä¸“å®¶ã€‚ä¸ºäº†ä¿æŒè®¡ç®—é‡ä¸å˜ï¼Œå…¶ä»–è·¯ç”±ä¸“å®¶ä¸­æ¿€æ´»çš„ä¸“å®¶æ•°é‡å°†å‡å°‘ $K_s$.\n$$\r\\begin{aligned}\r\\mathbf{h}_t^l \u0026= \\sum_{i=1}^{K_S} \\text{FFN}_i(\\mathbf{u}_t^l) + \\sum_{i=K_S+1}^{mN} \\left( g_{i,t} \\text{FFN}_i(\\mathbf{u}_t^l) \\right) + \\mathbf{u}_t^l \\quad\u0026(9)\\\\\rg_{i,t} \u0026= \\begin{cases} s_{i,t} \u0026 \\text{if } s_{i,t} \\in \\text{Topk}(\\{s_{j,t} | K_S+1 \\le j \\le mN\\}, mK - K_S) \\\\ 0 \u0026 \\text{otherwise} \\end{cases} \\quad\u0026(10)\\\\\rs_{i,t} \u0026= \\text{Softmax}_i(\\mathbf{u}_t^T \\mathbf{e}_i^l) \\quad\u0026(11)\r\\end{aligned}\r$$äºæ˜¯åœ¨ DeepSeekMoE ä¸­ï¼Œå…±äº«ä¸“å®¶çš„æ•°é‡ä¸º $K_S$ï¼Œè·¯ç”±ä¸“å®¶çš„æ€»æ•°ä¸º $mN - K_S$ï¼Œéé›¶é—¨æ§å€¼çš„æ•°é‡æ˜¯ $mK - K_S$\nLoad Balance Consideration è‡ªåŠ¨å­¦ä¹ çš„è·¯ç”±ç­–ç•¥å¯èƒ½ä¼šé‡åˆ°è´Ÿè½½ä¸å¹³è¡¡çš„é—®é¢˜\nå­˜åœ¨è·¯ç”±å´©æºƒçš„é£é™©ï¼Œå³æ¨¡å‹æ€»æ˜¯åªé€‰æ‹©å°‘æ•°å‡ ä¸ªä¸“å®¶ï¼Œå¯¼è‡´å…¶ä»–ä¸“å®¶æ— æ³•å¾—åˆ°å……åˆ†è®­ç»ƒã€‚ å¦‚æœä¸“å®¶åˆ†å¸ƒåœ¨å¤šä¸ªè®¾å¤‡ä¸Šï¼Œè´Ÿè½½ä¸å¹³è¡¡ä¼šåŠ å‰§è®¡ç®—ç“¶é¢ˆã€‚ Expert-Level Balance Loss. $$ \\begin{aligned}\r\\mathcal{L}_{\\text{ExpBal}} \u0026= \\alpha_1 \\sum_{i=1}^{N'} f_i P_i \\quad\u0026(12)\\\\\rf_i \u0026= \\frac{N'}{K'T} \\sum_{t=1}^{T} \\mathbf{1}(\\text{Token } t \\text{ selects Expert } i) \\quad\u0026(13)\\\\\rP_i \u0026= \\frac{1}{T} \\sum_{t=1}^{T} s_{i,t} \\quad\u0026(14)\r\\end{aligned}\r$$$\\mathcal{L}_{\\text{ExpBal}}$ çš„ç›®çš„æ˜¯ä¿ƒè¿›ä¸“å®¶ä¹‹é—´çš„è´Ÿè½½å‡è¡¡ï¼Œé¿å…å‡ºç°æŸäº›ä¸“å®¶è¿‡è½½ (è¢«é€‰ä¸­å¤ªå¤šæ¬¡) è€Œå…¶ä»–ä¸“å®¶é—²ç½® (å¾ˆå°‘è¢«é€‰ä¸­) çš„æƒ…å†µã€‚\n$N'$: è¡¨ç¤ºå¯è·¯ç”±çš„ä¸“å®¶æ€»æ•°ï¼Œå³ $mN - K_S$ã€‚ $K'$: è¡¨ç¤ºæ¯ä¸ª token é€‰æ‹©çš„è·¯ç”±ä¸“å®¶æ•°é‡ï¼Œå³ $mK - K_S$ã€‚ $T$: è¡¨ç¤ºæ€»çš„ token æ•°é‡ã€‚ è¯¥æŸå¤±å‡½æ•°çš„è§£é‡Šå¦‚ä¸‹\n$f_i$ (Expert Load/Utilization): å…¬å¼ (13) è®¡ç®—çš„æ˜¯ä¸“å®¶ $i$ åœ¨ä¸€ä¸ªæ‰¹æ¬¡/åºåˆ—ä¸­è¢«é€‰ä¸­çš„é¢‘ç‡ã€‚ $\\mathbf{1}(\\text{Token } t \\text{ selects Expert } i)$ æ˜¯ä¸€ä¸ªæŒ‡ç¤ºå‡½æ•°ï¼Œå¦‚æœ token $t$ é€‰ä¸­äº†ä¸“å®¶ $i$ï¼Œåˆ™ä¸º 1ï¼Œå¦åˆ™ä¸º 0ã€‚ $\\frac{1}{T} \\sum_{t=1}^{T} \\mathbf{1}(\\text{Token } t \\text{ selects Expert } i)$ å¾—åˆ°äº†ä¸“å®¶ $i$ åœ¨ $T$ ä¸ª token ä¸­è¢«é€‰ä¸­çš„å¹³å‡æ¬¡æ•° (é¢‘ç‡) ã€‚ å‰é¢çš„ $\\frac{N'}{K'}$ æ˜¯ä¸€ä¸ªå½’ä¸€åŒ–å› å­ã€‚å½“æ‰€æœ‰ä¸“å®¶è¢«å‡åŒ€é€‰ä¸­æ—¶ï¼Œæ¯ä¸ªä¸“å®¶è¢«é€‰æ‹©çš„å¹³å‡æ¬¡æ•°ä¸º$TK'/N'$ï¼Œæ­¤æ—¶ $f_i$ çš„æœŸæœ›å€¼ä¸º 1. å¦‚æœä¸“å®¶ $i$ è¢«é€‰ä¸­æ¬¡æ•°å¤šäºå¹³å‡ï¼Œåˆ™ $f_i \u003e 1$ï¼›åä¹‹ $f_i \u003c 1$. $f_i$ å¯ä»¥ç†è§£ä¸ºä¸“å®¶ $i$ çš„å½’ä¸€åŒ–è´Ÿè½½æˆ–åˆ©ç”¨ç‡ã€‚\n$P_i$ (Expert Routing Probability): å…¬å¼ (14) è®¡ç®—çš„æ˜¯ä¸“å®¶ $i$ åœ¨æ‰€æœ‰ token ä¸­å¹³å‡çš„é—¨æ§äº²å’Œåº¦åˆ†æ•°ã€‚ $s_{i,t}$ æ˜¯ token $t$ å¯¹ä¸“å®¶ $i$ çš„åŸå§‹äº²å’Œåº¦åˆ†æ•° (Softmax ä¹‹å‰çš„è¾“å‡º) ã€‚ $P_i$ å¯ä»¥ç†è§£ä¸ºä¸“å®¶ $i$ è¢«é—¨æ§ç½‘ç»œé€‰æ‹©çš„å¹³å‡å€¾å‘æ€§ã€‚\n$\\mathcal{L}_{\\text{ExpBal}} = \\alpha_1 \\sum_{i=1}^{N'} f_i P_i$: è¿™ä¸ªæŸå¤±é¡¹æ˜¯ $f_i$ å’Œ $P_i$ ä¹˜ç§¯çš„å’Œã€‚å®ƒçš„ç›®æ ‡æ˜¯æœ€å°åŒ–è¿™ä¸ªå’Œã€‚ å¦‚æœæŸä¸ªä¸“å®¶ $i$ çš„ $f_i$ (è´Ÿè½½é«˜) å’Œ $P_i$ (è¢«å€¾å‘æ€§é€‰æ‹©çš„æ¦‚ç‡é«˜) éƒ½å¾ˆå¤§ï¼Œé‚£ä¹ˆ $f_i P_i$ å°±ä¼šå¾ˆå¤§ï¼Œå¯¼è‡´æŸå¤±å¢å¤§ã€‚ é€šè¿‡æœ€å°åŒ–è¿™ä¸ªæŸå¤±ï¼Œæ¨¡å‹ä¼šè¢«æ¿€åŠ±å°† token åˆ†é…ç»™é‚£äº›è´Ÿè½½è¾ƒä½æˆ–è¢«é€‰æ‹©å€¾å‘æ€§è¾ƒä½çš„ä¸“å®¶ã€‚è¿™æœ‰åŠ©äºåˆ†æ•£è´Ÿè½½ï¼Œä½¿å¾—æ‰€æœ‰ä¸“å®¶éƒ½èƒ½å¾—åˆ°è®­ç»ƒå’Œåˆ©ç”¨ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•´ä½“æ•ˆç‡å’Œæ€§èƒ½ã€‚ $\\alpha_1$ æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨äºæ§åˆ¶è¿™ä¸ªå¹³è¡¡æŸå¤±åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡ã€‚ Device-Level Balance Loss. $$\r\\begin{aligned}\r\\mathcal{L}_{\\text{DevBal}} \u0026= \\alpha_2 \\sum_{i=1}^{D} \\hat{f}_i \\hat{P}_i \\quad\u0026(15)\\\\\r\\hat{f}_i \u0026= \\frac{1}{|\\mathcal{E}_i|} \\sum_{j \\in \\mathcal{E}_i} f_j \\quad\u0026(16)\\\\\r\\hat{P}_i \u0026= \\sum_{j \\in \\mathcal{E}_i} P_j \\quad\u0026(17)\r\\end{aligned}\r$$$\\mathcal{L}_{\\text{DevBal}}$ çš„ç›®çš„æ˜¯ä¿ƒè¿›ä¸“å®¶åœ¨ä¸åŒè®¡ç®—è®¾å¤‡ä¹‹é—´çš„è´Ÿè½½å‡è¡¡ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œé€šå¸¸ä¼šå°†ä¸“å®¶åˆ†æ•£åˆ°ä¸åŒçš„è®¾å¤‡ä¸Šï¼Œå¦‚æœæŸäº›è®¾å¤‡ä¸Šçš„ä¸“å®¶è¿‡äºç¹å¿™ï¼Œè€Œå¦ä¸€äº›è®¾å¤‡ä¸Šçš„ä¸“å®¶é—²ç½®ï¼Œå°±ä¼šå¯¼è‡´è®¡ç®—ç“¶é¢ˆå’Œæ•ˆç‡ä½ä¸‹ã€‚\n$D$: è¡¨ç¤ºè®¡ç®—è®¾å¤‡çš„æ•°é‡ã€‚ $\\mathcal{E}_i$: è¡¨ç¤ºåˆ†é…ç»™ç¬¬ $i$ ä¸ªè®¾å¤‡çš„æ‰€æœ‰ä¸“å®¶çš„é›†åˆã€‚$|\\mathcal{E}_i|$ æ˜¯è¿™ä¸ªé›†åˆä¸­ä¸“å®¶çš„æ•°é‡ã€‚ è¯¥æŸå¤±çš„è§£é‡Šå¦‚ä¸‹\n$\\hat{f}_i$ (Device-level Expert Load): å…¬å¼ (16) è®¡ç®—çš„æ˜¯ç¬¬ $i$ ä¸ªè®¾å¤‡ä¸Šæ‰€æœ‰ä¸“å®¶çš„å¹³å‡è´Ÿè½½ ($f_j$). ä»£è¡¨äº†è®¾å¤‡ $i$ çš„æ€»ä½“è®¡ç®—è´Ÿè½½ã€‚\n$\\hat{P}_i$ (Device-level Routing Probability): å…¬å¼ (17) è®¡ç®—çš„æ˜¯ç¬¬ $i$ ä¸ªè®¾å¤‡ä¸Šæ‰€æœ‰ä¸“å®¶çš„å¹³å‡è·¯ç”±å€¾å‘æ€§ ($P_j$) çš„æ€»å’Œã€‚ä»£è¡¨äº†è®¾å¤‡ $i$ çš„ä¸“å®¶é›†åˆè¢«é—¨æ§ç½‘ç»œé€‰æ‹©çš„æ€»ä½“å€¾å‘æ€§ã€‚\n$\\mathcal{L}_{\\text{DevBal}} = \\alpha_2 \\sum_{i=1}^{D} \\hat{f}_i \\hat{P}_i$:\nè¿™ä¸ªæŸå¤±é¡¹æ˜¯ $\\hat{f}_i$ å’Œ $\\hat{P}_i$ ä¹˜ç§¯çš„å’Œï¼Œç›®æ ‡ä¹Ÿæ˜¯æœ€å°åŒ–è¿™ä¸ªå’Œã€‚ å¦‚æœæŸä¸ªè®¾å¤‡ $i$ çš„ $\\hat{f}_i$ (è´Ÿè½½é«˜) å’Œ $\\hat{P}_i$ (è¢«é€‰æ‹©å€¾å‘æ€§é«˜) éƒ½å¾ˆå¤§ï¼Œé‚£ä¹ˆ $\\hat{f}_i \\hat{P}_i$ å°±ä¼šå¾ˆå¤§ï¼Œå¯¼è‡´æŸå¤±å¢å¤§ã€‚ é€šè¿‡æœ€å°åŒ–è¿™ä¸ªæŸå¤±ï¼Œæ¨¡å‹ä¼šè¢«æ¿€åŠ±å°† token è·¯ç”±åˆ°é‚£äº›æ•´ä½“è´Ÿè½½è¾ƒä½çš„è®¾å¤‡ä¸Šçš„ä¸“å®¶ã€‚è¿™ç¡®ä¿äº†åˆ†å¸ƒå¼è®­ç»ƒæˆ–æ¨ç†æ—¶ï¼Œæ‰€æœ‰è®¾å¤‡éƒ½èƒ½å¾—åˆ°æ›´å‡åŒ€çš„åˆ©ç”¨ï¼Œé¿å…äº†å•ä¸ªè®¾å¤‡æˆä¸ºç“¶é¢ˆã€‚ $\\alpha_2$ æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨äºæ§åˆ¶è¿™ä¸ªæŸå¤±åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡ã€‚ è¶…å‚æ•° $\\alpha_1$ å’Œ $\\alpha_2$ çš„è®¾ç½®ç­–ç•¥:\n**å°çš„ $\\alpha_1$ (ä¸“å®¶çº§å¹³è¡¡å› å­) : ç”¨äºâ€œå‡è½»è·¯ç”±å´©æºƒçš„é£é™©â€ã€‚è·¯ç”±å´©æºƒæŒ‡çš„æ˜¯å°‘æ•°ä¸“å®¶è¢«è¿‡åº¦ä½¿ç”¨ï¼Œå¯¼è‡´å®ƒä»¬â€œé¥±å’Œâ€è€Œæ— æ³•æœ‰æ•ˆå­¦ä¹ ï¼ŒåŒæ—¶å…¶ä»–ä¸“å®¶åˆ™å®Œå…¨æœªè¢«ä½¿ç”¨ã€‚è¾ƒå°çš„ $\\alpha_1$ æ„å‘³ç€æˆ‘ä»¬å…è®¸ä¸€å®šç¨‹åº¦çš„ä¸“å®¶ä¸“ä¸šåŒ–ï¼Œä½†ä»ä¼šè¿›è¡Œå¾®è°ƒä»¥é¿å…æç«¯çš„ä¸å¹³è¡¡ã€‚ **å¤§çš„ $\\alpha_2$ (è®¾å¤‡çº§å¹³è¡¡å› å­) : ç”¨äºâ€œä¿ƒè¿›è·¨è®¾å¤‡çš„å¹³è¡¡è®¡ç®—â€ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬æ›´å¼ºçƒˆåœ°è¦æ±‚æ¨¡å‹å°†è®¡ç®—è´Ÿè½½å‡åŒ€åœ°åˆ†æ•£åˆ°æ‰€æœ‰å¯ç”¨çš„è®¡ç®—è®¾å¤‡ä¸Šï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜å¹¶è¡Œæ•ˆç‡ã€‚è®¾å¤‡çº§çš„è´Ÿè½½å‡è¡¡å¯¹äºåˆ†å¸ƒå¼ç³»ç»Ÿè€Œè¨€è‡³å…³é‡è¦ã€‚ ","permalink":"http://localhost:1313/blogs/deepseek/deepseekmoe/","summary":"Paper Reading of DeepSeekMoE","title":"DeepSeekMoE"},{"content":"Preliminary: What is RoPE Introduction æ—‹è½¬ä½ç½®ç¼–ç  (RoPE) æ˜¯ä¸€ç§æ–°é¢–çš„ã€åŸºäºç›¸å¯¹ä½ç½®çš„ç¼–ç æ–¹æ³•ï¼Œå®ƒè¢«è®¾è®¡ç”¨äºæé«˜ Transformer æ¨¡å‹å¤„ç†é•¿åºåˆ—çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡ã€‚ä¸ä¼ ç»Ÿçš„ç»å¯¹ä½ç½®ç¼–ç  (å¦‚æ­£å¼¦/ä½™å¼¦ä½ç½®ç¼–ç ) æˆ–ç›´æ¥çš„ç›¸å¯¹ä½ç½®ç¼–ç  (å¦‚ T5 ä¸­ä½¿ç”¨çš„ç›¸å¯¹åç½®) ä¸åŒï¼ŒRoPE å°†ä½ç½®ä¿¡æ¯é›†æˆåˆ°è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ Q å’Œ K çš„è¡¨ç¤ºä¸­ï¼Œä½¿å¾— Q å’Œ K çš„ç‚¹ç§¯è‡ªç„¶åœ°ç¼–ç äº†ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚\nRoPE çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œé€šè¿‡å¯¹æŸ¥è¯¢å’Œé”®å‘é‡åº”ç”¨ç‰¹å®šçš„æ—‹è½¬æ“ä½œï¼Œä½¿å¾—ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯ç»“æœåªä¾èµ–äºå®ƒä»¬ä¹‹é—´çš„ç›¸å¯¹è·ç¦»ï¼Œè€Œä¸æ˜¯å®ƒä»¬çš„ç»å¯¹ä½ç½®ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æ›´é•¿çš„åºåˆ—ï¼Œå¹¶ä¸”åœ¨å¤„ç†ä½ç½®ä¿¡æ¯æ—¶æ›´åŠ é«˜æ•ˆã€‚\nRoPE çš„ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬ï¼š\nç¼–ç ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼š è‡ªç„¶åœ°å°†ç›¸å¯¹ä½ç½®ä¿¡æ¯èå…¥åˆ°æ³¨æ„åŠ›åˆ†æ•°ä¸­ã€‚ é•¿åºåˆ—å¤–æ¨èƒ½åŠ›ï¼š æé«˜äº†æ¨¡å‹åœ¨è®­ç»ƒæ—¶æœªè§è¿‡çš„æ›´é•¿åºåˆ—ä¸Šçš„æ€§èƒ½ã€‚ ä¸è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å…¼å®¹æ€§ï¼š æ— ç¼é›†æˆåˆ° QKV ç‚¹ç§¯æ³¨æ„åŠ›ä¸­ã€‚ ç®€å•ä¸”é«˜æ•ˆï¼š å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸”ä¸ä¼šæ˜¾è‘—å¢åŠ è®¡ç®—å¤æ‚åº¦ã€‚ Formular RoPE çš„ä¸»è¦æ€æƒ³æ˜¯é€šè¿‡å¯¹æŸ¥è¯¢ $q$ å’Œé”® $k$ åº”ç”¨ä¸€ä¸ªæ—‹è½¬çŸ©é˜µ $R_t$ (å–å†³äºå…¶ç»å¯¹ä½ç½® $t$) ï¼Œä½¿å¾—ç‚¹ç§¯ $q_m^T k_n$ èƒ½å¤Ÿé€šè¿‡æŸç§æ–¹å¼è½¬åŒ–ä¸ºåªä¾èµ–äºç›¸å¯¹ä½ç½® $m-n$ çš„å‡½æ•°ã€‚\nå¯¹äºä¸€ä¸ªå‘é‡ $x \\in \\mathbb{R}^d$ åœ¨ä½ç½® $m$ å¤„ï¼ŒRoPE çš„å˜æ¢å‡½æ•° $f(x, m)$ å¯ä»¥å®šä¹‰å¦‚ä¸‹ï¼š\nå¦‚æœå‘é‡ç»´åº¦æ˜¯å¶æ•° $d$ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶åˆ†æˆ $d/2$ å¯¹ï¼Œæ¯å¯¹æ‰§è¡Œä¸€ä¸ªäºŒç»´æ—‹è½¬ã€‚ å¯¹äºå‘é‡ $x = [x_0, x_1, \\ldots, x_{d-1}]^T$ï¼ŒRoPE å¯¹å…¶æ¯ä¸ªç»´åº¦å¯¹ $(x_{2i}, x_{2i+1})$ åº”ç”¨æ—‹è½¬ï¼š\n$$\rf(x, m)_{2i} = x_{2i} \\cos(m\\theta_i) - x_{2i+1} \\sin(m\\theta_i) \\\\\rf(x, m)_{2i+1} = x_{2i} \\sin(m\\theta_i) + x_{2i+1} \\cos(m\\theta_i)\r$$å…¶ä¸­ $\\theta_i$ æ˜¯é¢„è®¾çš„é¢‘ç‡ï¼Œé€šå¸¸å®šä¹‰ä¸º $\\theta_i = 10000^{-2i/d}$. $i=0, \\dots, d/2 - 1$ æ˜¯ç»´åº¦å¯¹çš„ç´¢å¼•ã€‚\nç”¨çŸ©é˜µå½¢å¼è¡¨ç¤ºï¼š æˆ‘ä»¬å¯ä»¥å°†è¿™ç§æ—‹è½¬æ“ä½œè¡¨ç¤ºä¸ºä¸€ä¸ªç¨€ç–çš„å—å¯¹è§’çŸ©é˜µ $R_m^d$ï¼Œå…¶å½¢å¼ä¸ºï¼š $$R_m^d = \\begin{pmatrix}\r\\cos(m\\theta_0) \u0026 -\\sin(m\\theta_0) \u0026 0 \u0026 0 \u0026 \\cdots \\\\\r\\sin(m\\theta_0) \u0026 \\cos(m\\theta_0) \u0026 0 \u0026 0 \u0026 \\cdots \\\\\r0 \u0026 0 \u0026 \\cos(m\\theta_1) \u0026 -\\sin(m\\theta_1) \u0026 \\cdots \\\\\r0 \u0026 0 \u0026 \\sin(m\\theta_1) \u0026 \\cos(m\\theta_1) \u0026 \\cdots \\\\\r\\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots\r\\end{pmatrix}$$ é‚£ä¹ˆï¼Œç»è¿‡ RoPE ç¼–ç çš„æŸ¥è¯¢å’Œé”®å¯ä»¥è¡¨ç¤ºä¸ºï¼š $$\\mathbf{q}_m = R_m^d \\mathbf{q}$$ $$\\mathbf{k}_n = R_n^d \\mathbf{k}$$ å…¶ä¸­ $\\mathbf{q}$ å’Œ $\\mathbf{k}$ æ˜¯åŸå§‹çš„æŸ¥è¯¢å’Œé”®å‘é‡ (ä¸å«ä½ç½®ä¿¡æ¯) ï¼Œ$\\mathbf{q}_m$ å’Œ $\\mathbf{k}_n$ æ˜¯ç»è¿‡ RoPE å¤„ç†åçš„æŸ¥è¯¢å’Œé”®å‘é‡ã€‚\nRoPE çš„å…³é”®ç‰¹æ€§ï¼šç‚¹ç§¯ä¸ç›¸å¯¹ä½ç½® ç»è¿‡ RoPE å˜æ¢åï¼Œæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„ç‚¹ç§¯å¯ä»¥åˆ†è§£ä¸ºï¼š $$\\mathbf{q}_m^T \\mathbf{k}_n = (R_m^d \\mathbf{q})^T (R_n^d \\mathbf{k})$$ ç”±äº $R_m^d$ æ˜¯æ­£äº¤çŸ©é˜µï¼Œå…¶é€†çŸ©é˜µç­‰äºå…¶è½¬ç½®ï¼Œå³ $(R_m^d)^T = (R_m^d)^{-1} = R_{-m}^d$. å› æ­¤æœ‰ $$\\mathbf{q}_m^T \\mathbf{k}_n = \\mathbf{q}^T (R_m^d)^T R_n^d \\mathbf{k} = \\mathbf{q}^T R_{-m}^d R_n^d \\mathbf{k} = \\mathbf{q}^T R_{n-m}^d \\mathbf{k}$$ è¿™ä¸ªæœ€ç»ˆç»“æœ $\\mathbf{q}^T R_{n-m}^d \\mathbf{k}$ è¡¨æ˜ï¼Œä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯åªä¾èµ–äºå®ƒä»¬çš„ç›¸å¯¹ä½ç½®å·® $n-m$ï¼Œè€Œä¸å®ƒä»¬çš„ç»å¯¹ä½ç½® $n$ å’Œ $m$ æ— å…³ã€‚è¿™å°±æ˜¯ RoPE èƒ½å¤Ÿç¼–ç ç›¸å¯¹ä½ç½®ä¿¡æ¯çš„æ•°å­¦åŸºç¡€ã€‚\nWorkflow Notation $d$: embedding ç»´åº¦ $d_h$: æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦ $\\mathbf{h}_t\\in\\mathbb{R}^d$: æŸä¸ª attention å±‚ç¬¬ t ä¸ª token çš„è¾“å…¥ã€‚ KV Compression $$\r\\textcolor{red}{c_t^{KV}} = W^{DKV}h_t \\tag{1}\r$$ $$\r[k_{t,1}^{C}, k_{t,2}^{C}, \\ldots, k_{t,n_h}^{C}] = k_t^C = W^{UK}c_t^{KV} \\tag{2}\r$$ $$\r\\textcolor{red}{k_t^R} = \\text{RoPE}(W^{KR}h_t) \\tag{3}\r$$ $$\rk_{t,i} = [k_{t,i}^C, k_{t}^R] \\tag{4}\r$$ $$\r[v_{t,1}^C, v_{t,2}^C, \\ldots, v_{t,n_h}^C] = v_t^C = W^{UV}c_t^{KV} \\tag{5}\r$$ $c_t^{KV} \\in \\mathbb{R}^{d_c}$: å‹ç¼©åçš„ KV æ½œåœ¨å‘é‡ã€‚ $d_c (\\ll d_h n_h)$: KV å‹ç¼©åˆ°çš„ç»´åº¦ã€‚ $W^{DKV} \\in \\mathbb{R}^{d_c \\times d}$: KV é™ç»´æŠ•å½±çŸ©é˜µã€‚ $W^{UK}, W^{UV} \\in \\mathbb{R}^{d_h n_h \\times d_c}$ åˆ†åˆ«æ˜¯ K \u0026amp; V çš„å‡ç»´æŠ•å½±çŸ©é˜µã€‚ $W^{KR} \\in \\mathbb{R}^{d_h^R \\times d}$: ç”¨äºç”Ÿæˆæºå¸¦ RoPE çš„è§£è€¦é”®çš„çŸ©é˜µ (Su et al., 2024) çº¢è‰²çš„æ˜¯éœ€è¦ç¼“å­˜çš„å‘é‡ï¼Œåç»­è¯´æ˜åŸå› ã€‚æ³¨æ„åˆ°å¯¹ K è¿›è¡Œ RoPE ä¹‹å‰æ˜¯å¯¹è¾“å…¥å‘é‡ä¹˜ä»¥äº†ä¸ªæŠ•å½±å†è¿›è¡Œçš„ã€‚è€Œä¸” K çš„æ¯ä¸ªæ³¨æ„åŠ›å¤´è¢«æ‹¼æ¥çš„éƒ½æ˜¯åŒä¸€ä¸ª $k_{t}^R$ï¼Œæœ‰ç‚¹ç±»ä¼¼äº MQA.\nQ Compression $$c_t^Q = W^{DQ}h_t \\tag{6}$$ $$[q_{t,1}^C, q_{t,2}^C, \\ldots, q_{t,n_h}^C] = q_t^C = W^{UQ}c_t^Q \\tag{7}$$ $$[q_{t,1}^R, q_{t,2}^R, \\ldots, q_{t,n_h}^R] = q_t^R = \\text{RoPE}(W^{QR}q_t^C) \\tag{8}$$ $$q_{t,i} = [q_{t,i}^C, q_{t,i}^R] \\tag{9}$$ $c_t^Q \\in \\mathbb{R}^{d_c'}$: Q å‹ç¼©åçš„æ½œåœ¨å‘é‡ã€‚ $d_c'(\\ll d_h n_h)$ è¡¨ç¤º Q å‹ç¼©åçš„ç»´åº¦ã€‚ $W^{DQ} \\in \\mathbb{R}^{d_c' \\times d}, W^{UQ} \\in \\mathbb{R}^{d_h n_h \\times d_c'}$: åˆ†åˆ«æ˜¯ Q çš„é™ç»´å’Œå‡ç»´çŸ©é˜µã€‚ $W^{QR} \\in \\mathbb{R}^{d_h^R n_h \\times d_c'}$ æ˜¯ç”¨äºç”Ÿæˆæºå¸¦ RoPE çš„è§£è€¦ Q çš„çŸ©é˜µã€‚ æ³¨æ„åˆ°å¯¹ Q çš„ RoPE æ˜¯åœ¨å‹ç¼©åè¿›è¡Œçš„ï¼Œå³ä¸ºæ¯ä¸ªæ³¨æ„åŠ›å¤´éƒ½ç”Ÿæˆäº†ä¸€ä¸ªä½ç½®ç¼–ç ä¿¡æ¯åè¿›è¡Œæ‹¼æ¥ã€‚\nAttention Computation æœ€ç»ˆ $q_{t,i}$, $k_{j,i}$, $v_{j,i}^C$ è¢«ç»„åˆèµ·æ¥ä»¥ç”Ÿæˆæœ€ç»ˆçš„æ³¨æ„åŠ›è¾“å‡º $u_t$\n$$\\mathbf{o}_{t,i} = \\sum_{j=1}^{t} \\text{Softmax}\\left(\\frac{q_{t,i}^T \\mathbf{k}_{j,i}}{\\sqrt{d_h + d_R}}\\right)v_{j,i}^C \\tag{10}$$ $$\\mathbf{u}_t = W^O[\\mathbf{o}_{t,1}, \\mathbf{o}_{t,2}, \\ldots, \\mathbf{o}_{t,n_h}] \\tag{11}$$ $W^O \\in \\mathbb{R}^{d \\times d_h n_h}$: è¾“å‡ºæŠ•å½±çŸ©é˜µã€‚ Why Decoupled RoPE å‡è®¾ä¸åŠ  RoPE çš„æƒ…å†µä¸‹è¿›è¡Œ $q_{t,i}$, $k_{j,i}$ çš„å†…ç§¯åˆ™æœ‰\n$$\rq_{t,i}^{T}\\times k_{j,i}=(W_{(i)}^{UQ}c_{t}^{Q})^{T}\\times W_{(i)}^{UK}c_{j}^{KV}=(c_{t}^{Q})^{T}\\times(W_{(i)}^{UQ})^{T}W_{(i)}^{UK}\\times c_{j}^{KV} \\tag{12}\r$$RoPE é€šè¿‡å¯¹å‘é‡åº”ç”¨ä¸€ä¸ªä½ç½®ä¾èµ–çš„æ—‹è½¬å˜æ¢æ¥æ³¨å…¥ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚å¯¹äºä¸€ä¸ªå‘é‡ $X$ åœ¨ä½ç½® $t$ï¼ŒRoPE å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªæ—‹è½¬çŸ©é˜µ $R_t$ ä¹˜ä»¥ $X$ï¼š $$\\text{RoPE}(X, t) = R_t X$$ è¿™é‡Œçš„ $R_t$ æ˜¯ä¸€ä¸ªæ­£äº¤æ—‹è½¬çŸ©é˜µï¼Œå®ƒå–å†³äºä½ç½® $t$.\nå¦‚æœç›´æ¥å¯¹å‹ç¼©å $k_t^C$ çš„ ä½¿ç”¨ RoPE é‚£ä¹ˆæƒ…å†µä¼šå˜æˆ\n$$\r\\begin{aligned}\rq_{t,i}^{T}\\times k_{j,i}\u0026=(\\mathcal{R}_{t}W_{(i)}^{UQ}c_{t}^{Q})^{T}\\times\\mathcal{R}_{j}W_{(i)}^{UK}c_{j}^{KV} \\\\\r\u0026=(c_{t}^{Q})^{T}\\times(W_{(i)}^{UQ})^{T}\\mathcal{R}_{t}^{T}\\mathcal{R}_{j}W_{(i)}^{UK}\\times c_{j}^{KV}\\\\\r\u0026=(c_{t}^{Q})^{T}\\times(W_{(i)}^{UQ})^{T}\\mathcal{R}_{t-j}W_{(i)}^{UK}\\times c_{j}^{KV}\r\\end{aligned} \\tag{13}\r$$ä¸­é—´çš„çŸ©é˜µä¸ç›¸å¯¹ä½ç½®æœ‰å…³ï¼Œæ— æ³•æå‰è®¡ç®—å‡ºæ¥ã€‚å› æ­¤æ–‡ä¸­å°±æ˜¯å¯¹æ‰€æœ‰å¤´éƒ½ä½¿ç”¨åŒä¸€ä¸ª k å’Œè®¡ç®— RoPE. æ‹¼æ¥åçš„å‘é‡å†è®¡ç®—æ—¶\n$$\rq_{t,i}^T\\times k_{j,i}=[q_{t,i}^C;q_{t,i}^R]^T\\times[k_{j,i}^C;k_t^R]=(q_{t,i}^C,k_{j,i}^C)+(q_{t,i}^R,k_t^R) \\tag{14}\r$$å‰ä¸€éƒ¨åˆ†æŒ‰ç…§å…¬å¼ (12) è¿›è¡Œè®¡ç®—ï¼Œåä¸€éƒ¨åˆ†æŒ‰ç…§ MQA æ–¹å¼è®¡ç®—ã€‚å› æ­¤åªç”¨ç¼“å­˜ $c_t^{KV}$ å’Œ $k_t^R$.\nSource Code DeepSeek-V3 MLA å¯¹åº”çš„æºç ä½ç½®\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 class MLA(nn.Module): \u0026#34;\u0026#34;\u0026#34; Multi-Head Latent Attention (MLA) Layer. Attributes: dim (int): Dimensionality of the input features. n_heads (int): Number of attention heads. n_local_heads (int): Number of local attention heads for distributed systems. q_lora_rank (int): Rank for low-rank query projection. kv_lora_rank (int): Rank for low-rank key/value projection. qk_nope_head_dim (int): Dimensionality of non-positional query/key projections. qk_rope_head_dim (int): Dimensionality of rotary-positional query/key projections. qk_head_dim (int): Total dimensionality of query/key projections. v_head_dim (int): Dimensionality of value projections. softmax_scale (float): Scaling factor for softmax in attention computation. \u0026#34;\u0026#34;\u0026#34; def __init__(self, args: ModelArgs): super().__init__() self.dim = args.dim self.n_heads = args.n_heads # è®¡ç®—å½“å‰è¿›ç¨‹ï¼ˆå¡ï¼‰è´Ÿè´£çš„æ³¨æ„åŠ›å¤´æ•°é‡ï¼Œç”¨äºæ¨¡å‹å¹¶è¡Œ self.n_local_heads = args.n_heads // world_size self.q_lora_rank = args.q_lora_rank self.kv_lora_rank = args.kv_lora_rank self.qk_nope_head_dim = args.qk_nope_head_dim self.qk_rope_head_dim = args.qk_rope_head_dim # QK å¤´æ€»ç»´åº¦ = é RoPE éƒ¨åˆ† + RoPE éƒ¨åˆ† self.qk_head_dim = args.qk_nope_head_dim + args.qk_rope_head_dim self.v_head_dim = args.v_head_dim # æŸ¥è¯¢æŠ•å½± (wq) çš„ LoRA å®ç° if self.q_lora_rank == 0: # å¦‚æœ q_lora_rank ä¸º 0ï¼Œè¡¨ç¤ºä¸ä½¿ç”¨ LoRAï¼Œç›´æ¥è¿›è¡Œå…¨ç§©æŠ•å½± # å°† dim ç»´åº¦çš„è¾“å…¥æŠ•å½±åˆ° n_heads * qk_head_dim ç»´åº¦ self.wq = ColumnParallelLinear(self.dim, self.n_heads * self.qk_head_dim) else: # å¦‚æœ q_lora_rank \u0026gt; 0ï¼Œä½¿ç”¨ LoRA ç»“æ„è¿›è¡Œä½ç§©æŠ•å½± # wq_a: dim -\u0026gt; q_lora_rank (ä½ç§©æŠ•å½±çš„ç¬¬ä¸€æ­¥) self.wq_a = Linear(self.dim, self.q_lora_rank) # q_norm: RMSNorm åº”ç”¨äºä½ç§©ç»´åº¦ self.q_norm = RMSNorm(self.q_lora_rank) # wq_b: q_lora_rank -\u0026gt; n_heads * qk_head_dim (ä½ç§©æŠ•å½±çš„ç¬¬äºŒæ­¥) self.wq_b = ColumnParallelLinear(self.q_lora_rank, self.n_heads * self.qk_head_dim) # é”®å€¼æŠ•å½± (wkv) çš„ LoRA å®ç° # wkv_a: dim -\u0026gt; kv_lora_rank + qk_rope_head_dim # å¯¹åº”å›¾ä¸­çš„ W^{DKV} æŠ•å½±åˆ°ä½ç§© KV æ½œåœ¨ç©ºé—´ (kv_lora_rank) å’Œè§£è€¦çš„ RoPE é”® (qk_rope_head_dim) # è¿™é‡Œçš„ kv_lora_rank å¯¹åº”å…¬å¼ä¸­çš„ d_c # è¿™é‡Œçš„ qk_rope_head_dim å¯¹åº”å…¬å¼ä¸­çš„ d_h self.wkv_a = Linear(self.dim, self.kv_lora_rank + self.qk_rope_head_dim) # kv_norm: RMSNorm åº”ç”¨äºä½ç§©ç»´åº¦ self.kv_norm = RMSNorm(self.kv_lora_rank) # wkv_b: kv_lora_rank -\u0026gt; n_heads * (qk_nope_head_dim + v_head_dim) # å¯¹åº”å›¾ä¸­çš„ W^{UK} å’Œ W^{UV} çš„ç»„åˆ # å®ƒå°†å‹ç¼©åçš„ KV æ½œåœ¨å‘é‡ (kv_lora_rank) æŠ•å½±å›é RoPE é”® (qk_nope_head_dim) å’Œå€¼ (v_head_dim) çš„é«˜ç»´åº¦ç©ºé—´ self.wkv_b = ColumnParallelLinear(self.kv_lora_rank, self.n_heads * (self.qk_nope_head_dim + self.v_head_dim)) # è¾“å‡ºæŠ•å½± (wo) self.wo = RowParallelLinear(self.n_heads * self.v_head_dim, self.dim) # Softmax ç¼©æ”¾å› å­ï¼Œç”¨äºæ³¨æ„åŠ›åˆ†æ•°çš„ç¼©æ”¾ï¼Œé˜²æ­¢å†…ç§¯è¿‡å¤§ self.softmax_scale = self.qk_head_dim ** -0.5 # å¦‚æœåºåˆ—é•¿åº¦è¶…è¿‡åŸå§‹è®­ç»ƒé•¿åº¦ï¼Œæ ¹æ® RopeFactor è¿›è¡Œé¢å¤–ç¼©æ”¾ï¼Œç”¨äºå¤„ç†é•¿åºåˆ—å¤–æ¨é—®é¢˜ if args.max_seq_len \u0026gt; args.original_seq_len: mscale = 0.1 * args.mscale * math.log(args.rope_factor) + 1.0 self.softmax_scale = self.softmax_scale * mscale * mscale # æ ¹æ®æ³¨æ„åŠ›å®ç°æ–¹å¼ï¼ˆnaive æˆ– optimizedï¼‰é€‰æ‹©ä¸åŒçš„ KV ç¼“å­˜ç»“æ„ if attn_impl == \u0026#34;naive\u0026#34;: # naive å®ç°ç›´æ¥ç¼“å­˜å®Œæ•´é”® K å’Œå€¼ V # k_cache: (max_batch_size, max_seq_len, n_local_heads, qk_head_dim) self.register_buffer(\u0026#34;k_cache\u0026#34;, torch.zeros(args.max_batch_size, args.max_seq_len, self.n_local_heads, self.qk_head_dim), persistent=False) # v_cache: (max_batch_size, max_seq_len, n_local_heads, v_head_dim) self.register_buffer(\u0026#34;v_cache\u0026#34;, torch.zeros(args.max_batch_size, args.max_seq_len, self.n_local_heads, self.v_head_dim), persistent=False) else: # optimized å®ç°ç¼“å­˜å‹ç¼©åçš„ KV æ½œåœ¨å‘é‡å’Œè§£è€¦çš„ RoPE é”® # kv_cache: (max_batch_size, max_seq_len, kv_lora_rank) - å¯¹åº”è®ºæ–‡ä¸­çš„ c_t^{KV} self.register_buffer(\u0026#34;kv_cache\u0026#34;, torch.zeros(args.max_batch_size, args.max_seq_len, self.kv_lora_rank), persistent=False) # pe_cache: (max_batch_size, max_seq_len, qk_rope_head_dim) - å¯¹åº”è®ºæ–‡ä¸­çš„ k_t^R self.register_buffer(\u0026#34;pe_cache\u0026#34;, torch.zeros(args.max_batch_size, args.max_seq_len, self.qk_rope_head_dim), persistent=False) def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]): \u0026#34;\u0026#34;\u0026#34; Forward pass for the Multi-Head Latent Attention (MLA) Layer. Args: x (torch.Tensor): Input tensor of shape (batch_size, seq_len, dim). start_pos (int): Starting position in the sequence for caching. freqs_cis (torch.Tensor): Precomputed complex exponential values for rotary embeddings. mask (Optional[torch.Tensor]): Mask tensor to exclude certain positions from attention. Returns: torch.Tensor: Output tensor with the same shape as the input. \u0026#34;\u0026#34;\u0026#34; bsz, seqlen, _ = x.size() end_pos = start_pos + seqlen # 1. æŸ¥è¯¢ (Q) çš„ç”Ÿæˆ if self.q_lora_rank == 0: # å…¨ç§©æŠ•å½± q = self.wq(x) else: # LoRA æŠ•å½±ï¼šx -\u0026gt; wq_a -\u0026gt; q_norm -\u0026gt; wq_b q = self.wq_b(self.q_norm(self.wq_a(x))) # reshape Q q = q.view(bsz, seqlen, self.n_local_heads, self.qk_head_dim) # åˆ†ç¦» Q çš„é RoPE éƒ¨åˆ†å’Œ RoPE éƒ¨åˆ† # q_nope å¯¹åº”è®ºæ–‡ä¸­çš„ q_{t,i}^C (éä½ç½®ä¿¡æ¯æŸ¥è¯¢) # q_pe å¯¹åº”è®ºæ–‡ä¸­çš„ q_{t,i}^R (æºå¸¦ RoPE çš„è§£è€¦æŸ¥è¯¢) q_nope, q_pe = torch.split(q, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1) # å¯¹ Q çš„ RoPE éƒ¨åˆ†åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç  # å¯¹åº”è®ºæ–‡ä¸­çš„ q_t^R = RoPE(W^{QR}c_t^Q) çš„ RoPE éƒ¨åˆ† q_pe = apply_rotary_emb(q_pe, freqs_cis) # 2. é”®å€¼ (KV) çš„ç”Ÿæˆ # å°†è¾“å…¥ x æŠ•å½±åˆ°ä½ç§© KV æ½œåœ¨ç©ºé—´å’Œè§£è€¦çš„ RoPE é”® # å¯¹åº”è®ºæ–‡ä¸­çš„ c_t^{KV} å’Œ k_t^R kv = self.wkv_a(x) # åˆ†ç¦»å‡º KV æ½œåœ¨å‘é‡å’Œè§£è€¦çš„ RoPE é”® # kv å¯¹åº”è®ºæ–‡ä¸­çš„ c_t^{KV} # k_pe å¯¹åº”è®ºæ–‡ä¸­çš„ k_t^R (RoPE è§£è€¦é”®) kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1) # å¯¹ K çš„ RoPE éƒ¨åˆ†åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç  # æ³¨æ„ k_pe.unsqueeze(2) æ˜¯å› ä¸º apply_rotary_emb æœŸæœ› (..., seq_len, head_dim) ç»“æ„ # è¿™é‡Œçš„ k_pe å¯èƒ½æ˜¯ (bsz, seqlen, qk_rope_head_dim)ï¼Œéœ€è¦æ·»åŠ ä¸€ä¸ª head ç»´åº¦ k_pe = apply_rotary_emb(k_pe.unsqueeze(2), freqs_cis) # 3. æ³¨æ„åŠ›è®¡ç®—ï¼šæ ¹æ®å®ç°æ–¹å¼ (naive æˆ– optimized) if attn_impl == \u0026#34;naive\u0026#34;: # Naive å®ç°ç›´æ¥æ‹¼æ¥ Q çš„ RoPE å’Œé RoPE éƒ¨åˆ† q = torch.cat([q_nope, q_pe], dim=-1) # Q æ¢å¤ä¸º (bsz, seqlen, n_local_heads, qk_head_dim) # å¯¹ KV æ½œåœ¨å‘é‡åº”ç”¨å½’ä¸€åŒ–ï¼Œå¹¶è¿›è¡Œç¬¬äºŒé˜¶æ®µæŠ•å½± # å¯¹åº”è®ºæ–‡ä¸­å°† c_t^{KV} æŠ•å½±åˆ°é RoPE é”®å’Œå€¼çš„éƒ¨åˆ† (k_t^C å’Œ v_t^C) kv = self.wkv_b(self.kv_norm(kv)) # å°† KV ç»“æœé‡å¡‘ä¸º (batch_size, seq_len, n_local_heads, qk_nope_head_dim + v_head_dim) kv = kv.view(bsz, seqlen, self.n_local_heads, self.qk_nope_head_dim + self.v_head_dim) # åˆ†ç¦»å‡ºé RoPE é”®å’Œå€¼ k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1) # æ‹¼æ¥é RoPE é”®å’Œ RoPE é”®ï¼Œç»„æˆå®Œæ•´çš„é”® K # k_pe ä¹‹å‰æ˜¯ (bsz, seqlen, 1, qk_rope_head_dim)ï¼Œéœ€è¦ expand åˆ° n_local_heads k = torch.cat([k_nope, k_pe.expand(-1, -1, self.n_local_heads, -1)], dim=-1) # æ›´æ–° K å’Œ V ç¼“å­˜ (åœ¨æ¨ç†æ—¶ç”¨äºè‡ªå›å½’ç”Ÿæˆ) self.k_cache[:bsz, start_pos:end_pos] = k self.v_cache[:bsz, start_pos:end_pos] = v # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° (Q @ K^T) # scores: (batch_size, q_seq_len, n_local_heads, k_seq_len) # ä½¿ç”¨æ•´ä¸ªç¼“å­˜ä¸­çš„é”®è¿›è¡Œè®¡ç®— scores = torch.einsum(\u0026#34;bshd,bthd-\u0026gt;bsht\u0026#34;, q, self.k_cache[:bsz, :end_pos]) * self.softmax_scale else: # optimized å®ç° # è·å– wkv_b æƒé‡ï¼Œå¦‚æœä½¿ç”¨äº†é‡åŒ–åˆ™è¿›è¡Œåé‡åŒ– wkv_b = self.wkv_b.weight if self.wkv_b.scale is None else weight_dequant(self.wkv_b.weight, self.wkv_b.scale, block_size) # å°† wkv_b é‡å¡‘ä¸º (n_local_heads, head_dim, kv_lora_rank) ä»¥ä¾¿è¿›è¡Œé€å¤´çš„æ“ä½œ wkv_b = wkv_b.view(self.n_local_heads, -1, self.kv_lora_rank) # (n_heads, (qk_nope+v), kv_rank) # è®¡ç®— Q_nope ä¸ K_nope çš„ç‚¹ç§¯ (é€šè¿‡ kv ç¼“å­˜) # q_nope: (bsz, seqlen, n_local_heads, qk_nope_head_dim) # wkv_b[:, :self.qk_nope_head_dim] æ˜¯ W^{UK} çš„éƒ¨åˆ† # è¿™å¯¹åº”è®ºæ–‡ä¸­çš„ Softmax(q_{t,i}^C @ c_{j,i}^{KV}) çš„ç¬¬ä¸€é¡¹ q_nope = torch.einsum(\u0026#34;bshd,hdc-\u0026gt;bshc\u0026#34;, q_nope, wkv_b[:, :self.qk_nope_head_dim]) # æ›´æ–° KV ç¼“å­˜ (kv_cache å¯¹åº”è®ºæ–‡ä¸­çš„ c_t^{KV}) self.kv_cache[:bsz, start_pos:end_pos] = self.kv_norm(kv) # æ›´æ–° PE ç¼“å­˜ (pe_cache å¯¹åº”è®ºæ–‡ä¸­çš„ k_t^R) # k_pe ä¹‹å‰æ˜¯ (bsz, seqlen, 1, qk_rope_head_dim)ï¼Œsqueeze æ‰é‚£ä¸ª 1 ç»´åº¦ self.pe_cache[:bsz, start_pos:end_pos] = k_pe.squeeze(2) # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° # ç¬¬ä¸€é¡¹: é RoPE æŸ¥è¯¢ q_nope ä¸ç¼“å­˜çš„ kv_cache (å‹ç¼©é”®) çš„ç‚¹ç§¯ # å¯¹åº”è®ºæ–‡ä¸­çš„ Softmax(q_{t,i}^C @ c_{j,i}^{KV}) çš„ç¬¬ä¸€éƒ¨åˆ† scores = torch.einsum(\u0026#34;bshc,btc-\u0026gt;bsht\u0026#34;, q_nope, self.kv_cache[:bsz, :end_pos]) + \\ # ç¬¬äºŒé¡¹: RoPE æŸ¥è¯¢ q_pe ä¸ç¼“å­˜çš„ pe_cache (è§£è€¦ RoPE é”®) çš„ç‚¹ç§¯ # å¯¹åº”è®ºæ–‡ä¸­çš„ Softmax(q_{t,i}^R @ k_{j,i}^R) çš„ç¬¬äºŒéƒ¨åˆ† torch.einsum(\u0026#34;bshr,btr-\u0026gt;bsht\u0026#34;, q_pe, self.pe_cache[:bsz, :end_pos]) scores *= self.softmax_scale # åº”ç”¨ç¼©æ”¾å› å­ # åº”ç”¨æ³¨æ„åŠ›æ©ç  (å¦‚å› æœæ©ç ï¼Œé˜²æ­¢çœ‹åˆ°æœªæ¥ä¿¡æ¯) if mask is not None: scores += mask.unsqueeze(1) # unsqueeze(1) å¹¿æ’­åˆ° heads ç»´åº¦ # å¯¹åˆ†æ•°åº”ç”¨ Softmax å¾—åˆ°æ³¨æ„åŠ›æƒé‡ scores = scores.softmax(dim=-1, dtype=torch.float32).type_as(x) # 4. å€¼ (V) çš„åŠ æƒæ±‚å’Œ if attn_impl == \u0026#34;naive\u0026#34;: # Naive å®ç°ç›´æ¥ä¸ V ç¼“å­˜è¿›è¡Œç‚¹ç§¯ # å¯¹åº”è®ºæ–‡ä¸­çš„ sum(Softmax(...) * v_{j,i}^C) x = torch.einsum(\u0026#34;bsht,bthd-\u0026gt;bshd\u0026#34;, scores, self.v_cache[:bsz, :end_pos]) else: # optimized å®ç° # optimized å®ç°é€šè¿‡ wkv_b çš„å€¼éƒ¨åˆ†å°†åŠ æƒåçš„å‹ç¼© KV è¿˜åŸä¸º V # ç¬¬ä¸€æ­¥: å°†æ³¨æ„åŠ›æƒé‡ä¸ç¼“å­˜çš„ kv_cache (å‹ç¼©å€¼) è¿›è¡Œç‚¹ç§¯ # å¯¹åº”è®ºæ–‡ä¸­çš„ Softmax(...) * c_{j,i}^{KV} çš„ç¬¬ä¸€éƒ¨åˆ† x = torch.einsum(\u0026#34;bsht,btc-\u0026gt;bshc\u0026#34;, scores, self.kv_cache[:bsz, :end_pos]) # ç¬¬äºŒæ­¥: å°†åŠ æƒåçš„å‹ç¼©å€¼é€šè¿‡ wkv_b çš„å€¼æŠ•å½±éƒ¨åˆ†è¿˜åŸä¸ºæœ€ç»ˆçš„å€¼å‘é‡ # wkv_b[:, -self.v_head_dim:] æ˜¯ W^{UV} çš„éƒ¨åˆ† # å¯¹åº”è®ºæ–‡ä¸­çš„ Softmax(...) * v_{j,i}^C çš„ç¬¬äºŒéƒ¨åˆ† x = torch.einsum(\u0026#34;bshc,hdc-\u0026gt;bshd\u0026#34;, x, wkv_b[:, -self.v_head_dim:]) # å°†æ‰€æœ‰å¤´çš„ç»“æœå±•å¹³å¹¶è¿›è¡Œæœ€ç»ˆçš„è¾“å‡ºæŠ•å½± x = self.wo(x.flatten(2)) # x.flatten(2) å°† (bsz, seqlen, n_local_heads, v_head_dim) å±•å¹³ä¸º (bsz, seqlen, n_local_heads * v_head_dim) return x ","permalink":"http://localhost:1313/blogs/deepseek/deepseekmla/","summary":"Principle of DeepSeekV3 MLA","title":"DeepSeekMLA"},{"content":"Abstract CloudMatrix384ç¡¬ä»¶æ¶æ„:\nè®ºæ–‡æå‡ºäº†ä¸€ç§ peer-to-peer çš„ç¡¬ä»¶è®¾è®¡ï¼ŒåŒ…å« 384 ä¸ª Ascend 910C NPU å’Œ 192 ä¸ª Kunpeng CPUï¼Œé€šè¿‡ Unified Bus (UB) Network äº’è”ã€‚UB ç½‘ç»œæ”¯æŒé«˜å¸¦å®½ (392 GB/så•å‘å¸¦å®½)å’Œä½å»¶è¿Ÿ (1.9 Âµs)çš„å…¨å±€é€šä¿¡ï¼Œè§£å†³äº†ä¼ ç»ŸAIé›†ç¾¤ä¸­è·¨èŠ‚ç‚¹é€šä¿¡çš„ç“¶é¢ˆé—®é¢˜ã€‚ æ¶æ„ç‰¹ç‚¹åŒ…æ‹¬: èµ„æºè§£è€¦å’Œæ± åŒ–: è®¡ç®—ã€å­˜å‚¨å’Œç½‘ç»œèµ„æºå¯ä»¥åŠ¨æ€åˆ†é…ï¼Œæ”¯æŒçµæ´»çš„å¹¶è¡Œç­–ç•¥ (å¦‚ä¸“å®¶å¹¶è¡ŒEPã€æ•°æ®å¹¶è¡ŒDP). ä¸‰å±‚ç½‘ç»œå¹³é¢: UBå¹³é¢ (è¶…èŠ‚ç‚¹å†…é€šä¿¡)ã€RDMAå¹³é¢ (è·¨è¶…èŠ‚ç‚¹é€šä¿¡)å’ŒVPCå¹³é¢ (æ•°æ®ä¸­å¿ƒç½‘ç»œæ¥å…¥)ã€‚ CloudMatrix-Inferè½¯ä»¶ä¼˜åŒ–:\né¢„å¡«å……-è§£ç -ç¼“å­˜ (PDC)è§£è€¦æ¶æ„: å°†LLMæ¨ç†æ‹†åˆ†ä¸ºPrefill, Decode \u0026amp; Caching ä¸‰ä¸ªå­ç³»ç»Ÿï¼Œé€šè¿‡ UBç½‘ç»œå®ç°é«˜æ•ˆååŒã€‚ large-scale expert parallelism (EP) strategy: æ”¯æŒé«˜è¾¾EP320çš„ä¸“å®¶å¹¶è¡Œåº¦ï¼Œæ¯ä¸ªNPUèŠ¯ç‰‡æ‰¿è½½ä¸€ä¸ªä¸“å®¶ï¼Œå‡å°‘MoEæ¨¡å‹ä¸­çš„é€šä¿¡å¼€é”€ã€‚ UBé©±åŠ¨çš„åˆ†å¸ƒå¼ç¼“å­˜: åˆ©ç”¨ å¼¹æ€§å†…å­˜æœåŠ¡ (EMS) æ„å»ºå…¨å±€ç¼“å­˜æ± ï¼Œæ”¯æŒKVç¼“å­˜å’Œæ¨¡å‹æƒé‡çš„å¿«é€Ÿè®¿é—®ã€‚ æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯:\n** micro-batch æµæ°´çº¿ (Microbatch Pipeline)**: é‡å è®¡ç®—å’Œé€šä¿¡ï¼Œæå‡èµ„æºåˆ©ç”¨ç‡ã€‚ INT8é‡åŒ–: åœ¨Ascend 910C ä¸Šå®ç°é«˜æ•ˆçš„8ä½æ¨ç†ï¼Œä¿æŒæ¨¡å‹ç²¾åº¦ã€‚ è®ºæ–‡ä½¿ç”¨DeepSeek-R1 (671Bå‚æ•°MoEæ¨¡å‹)éªŒè¯äº† CloudMatrix-Infer çš„æ€§èƒ½:\né¢„å¡«å……ååé‡: 6,688 tokens/s/NPU (4.45 tokens/s/TFLOPS)ï¼Œä¼˜äº NVIDIA H100 çš„ SGLang (3.75 tokens/s/TFLOPS). è§£ç ååé‡: 1,943 tokens/s/NPU (1.29 tokens/s/TFLOPS)ï¼Œåœ¨TPOT \u0026lt;50 msçº¦æŸä¸‹ä»èƒ½ä¿æŒé«˜ååã€‚ ç¼“å­˜å‘½ä¸­ç‡æå‡: ä¸Šä¸‹æ–‡ç¼“å­˜ (Context Caching)åœ¨ 90% é‡ç”¨ç‡æ—¶ï¼Œé¢„å¡«å……æ—¶é—´å‡å°‘ 59%. 1. Introduction LLM çš„å‘å±•è¶‹åŠ¿æœ‰ä»¥ä¸‹å‡ ç‚¹:\nå‚æ•°è§„æ¨¡çš„æŒ‡æ•°çº§å¢é•¿ã€‚DeepSeek-R1, LLaMA-4 å’Œ Qwen-3 é€šå¸¸æ‰©å±•åˆ°æ•°åƒäº¿ç”šè‡³æ•°ä¸‡äº¿å‚æ•°. ä¸“å®¶æ··åˆ (MoE)æ¶æ„çš„å¹¿æ³›é‡‡ç”¨ã€‚MoE é€šè¿‡æ¯ä¸ª token é€‰æ‹©æ€§æ¿€æ´»å°‘æ•°ä¸“å®¶ï¼Œå¼•å…¥äº†ç»“æ„ç¨€ç–æ€§ï¼Œå®ç°äº†æ›´å¤§æ¨¡å‹ä¸‹çš„æ•ˆç‡æå‡ï¼Œä½†åŒæ—¶åœ¨ä¸“å®¶è·¯ç”±å’ŒåŒæ­¥æ–¹é¢å¸¦æ¥äº†æ–°çš„ç³»ç»Ÿçº§æŒ‘æˆ˜ã€‚ ä¸Šä¸‹æ–‡é•¿åº¦çš„å¤§å¹…æé«˜ã€‚ä¸Šä¸‹æ–‡çª—å£ä»æ•°ä¸‡ token æ‰©å±•åˆ°è¶…è¿‡ä¸€ç™¾ä¸‡ tokenï¼Œå¯¹æ³¨æ„åŠ›è®¡ç®—å’Œ KV cache å­˜å‚¨æ–½åŠ äº†å·¨å¤§å‹åŠ›ã€‚ KV Cache å¤§å°éšç€å¹¶å‘ç”¨æˆ·æ•°é‡çº¿æ€§å¢é•¿ï¼Œè¿™å¯¹å…¶çš„åˆ†å¸ƒã€æ”¾ç½®å’Œè®¿é—®æ–¹å¼æå‡ºäº†é‡å¤§é™åˆ¶ã€‚ LLM æœåŠ¡ç³»ç»Ÿå¿…é¡»é€‚åº”å¯å˜é•¿åº¦çš„ç”¨æˆ·è¾“å…¥ã€è·¨ token çš„ä¸å¹³è¡¡ä¸“å®¶æ¿€æ´»ä»¥åŠé«˜åº¦çªå‘çš„ç”¨æˆ·æŸ¥è¯¢ï¼ŒåŒæ—¶ä¿æŒä¸¥æ ¼çš„å»¶è¿Ÿå’Œååé‡ç›®æ ‡ã€‚æ»¡è¶³è¿™äº›éœ€æ±‚ä¸ä»…ä»…æ˜¯ç®€å•åœ°æ‰©å±•ç¡¬ä»¶èµ„æºï¼Œè€Œæ˜¯éœ€è¦å…¨é¢çš„è½¯ç¡¬ä»¶ååŒè®¾è®¡ï¼ŒåŒ…æ‹¬ç´§å¯†é›†æˆçš„è®¡ç®—ã€å†…å­˜å’Œç½‘ç»œç¡¬ä»¶èµ„æºï¼Œè¾…ä»¥æ™ºèƒ½ä»»åŠ¡è°ƒåº¦ã€è‡ªé€‚åº”è¿è¡Œæ—¶ç¼–æ’ä»¥åŠå¼¹æ€§èµ„æºç®¡ç†ç­–ç•¥ï¼Œèƒ½å¤ŸåŠ¨æ€å“åº”ä¸æ–­æ¼”å˜çš„æ¨¡å‹ç»“æ„å’Œæ³¢åŠ¨çš„å·¥ä½œè´Ÿè½½ã€‚\nä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œè®ºæ–‡å¼•å…¥äº† åä¸ºCloudMatrixï¼Œä¸€ä¸ªæ—¨åœ¨é‡å¡‘ AI åŸºç¡€è®¾æ–½åŸºç¡€çš„ä¸‹ä¸€ä»£ AI æ•°æ®ä¸­å¿ƒæ¶æ„ã€‚å…¶é¦–ä¸ªç”Ÿäº§çº§å®ç°æ˜¯ CloudMatrix384ï¼Œå®ƒå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒç‰¹ç‚¹:\nç¡¬ä»¶æ„æˆ: å®ƒæ˜¯ä¸€ä¸ªé›†æˆäº†384ä¸ªæ˜‡è…¾ (Ascend)910C NPUã€192ä¸ª é²²é¹ (Kunpeng)CPU çš„AIè¶…çº§èŠ‚ç‚¹ã€‚ æ ¸å¿ƒç½‘ç»œ: æ‰€æœ‰ç»„ä»¶é€šè¿‡ä¸€ä¸ªè¶…é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ UB ç½‘ç»œäº’è”ï¼Œå®ç°äº†ç¡¬ä»¶ä¸Šçš„ **å®Œå…¨ç‚¹å¯¹ç‚¹ (peer-to-peer)**é€šä¿¡ã€‚ æ¶æ„ä¼˜åŠ¿: ä¸ä¼ ç»Ÿå±‚çº§å¼è®¾è®¡ä¸åŒï¼ŒUBç½‘ç»œå…è®¸è®¡ç®—ã€å†…å­˜ç­‰èµ„æºè¢«åŠ¨æ€æ± åŒ–ã€ç»Ÿä¸€è®¿é—®å’Œç‹¬ç«‹æ‰©å±•ï¼Œç‰¹åˆ«é€‚åˆå¤„ç†MoEä¸“å®¶å¹¶è¡Œå’Œåˆ†å¸ƒå¼KVç¼“å­˜è®¿é—®è¿™ç±»é€šä¿¡å¯†é›†å‹æ“ä½œã€‚ åŸºäºCloudMatrix384ç¡¬ä»¶ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸º CloudMatrix-Infer çš„ç»¼åˆæ€§LLMæœåŠ¡è§£å†³æ–¹æ¡ˆï¼Œå…¶åŒ…å«äº†ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°:\nç‚¹å¯¹ç‚¹æœåŠ¡æ¶æ„: è¯¥æ¶æ„å°†æ¨ç†ç³»ç»Ÿè§£è€¦ä¸º é¢„å¡«å…… (prefill), è§£ç  (decode) å’Œ ç¼“å­˜ (caching) ä¸‰ä¸ªå¯ç‹¬ç«‹æ‰©å±•çš„èµ„æºæ± ã€‚å€ŸåŠ©UBç½‘ç»œï¼Œæ‰€æœ‰ NPU éƒ½èƒ½ç»Ÿä¸€è®¿é—®å…±äº«çš„ç¼“å­˜æ•°æ®ï¼Œä»è€Œæ‘†è„±äº†ä¼ ç»Ÿæ¶æ„ä¸­å› æ•°æ®å±€éƒ¨æ€§é™åˆ¶è€Œå¯¼è‡´çš„è°ƒåº¦å¤æ‚æ€§å’Œæ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚\nå¤§è§„æ¨¡ä¸“å®¶å¹¶è¡Œ (LEP)ç­–ç•¥: è¯¥ç­–ç•¥ä¸“ä¸ºMoEæ¨¡å‹ä¼˜åŒ–ï¼Œåˆ©ç”¨UBç½‘ç»œé«˜æ•ˆåœ°è¿›è¡Œ token åˆ†å‘å’Œä¸“å®¶è¾“å‡ºåˆå¹¶ã€‚å®ƒæ”¯æŒæé«˜çš„ä¸“å®¶å¹¶è¡Œåº¦ (å¦‚ EP320 )ï¼Œå…è®¸æ¯ä¸ª NPU Die åªæ‰¿è½½ä¸€ä¸ªä¸“å®¶ï¼Œä»è€Œæ˜¾è‘—é™ä½è§£ç å»¶è¿Ÿã€‚\nç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–: åŒ…æ‹¬ä¸ºæ˜‡è…¾èŠ¯ç‰‡é«˜åº¦ä¼˜åŒ–çš„ç®—å­ã€åŸºäº micro-batch çš„æµæ°´çº¿æŠ€æœ¯ (ä»¥é‡å è®¡ç®—å’Œé€šä¿¡)ä»¥åŠINT8é‡åŒ– (ä»¥æå‡è®¡ç®—æ•ˆç‡å’Œå‡å°‘å†…å­˜æ¶ˆè€—)ã€‚\nåœ¨ DeepSeek-R1 æ¨¡å‹ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒCloudMatrix-Infer å®ç°äº†ä¸šç•Œé¢†å…ˆçš„æ€§èƒ½å’Œæ•ˆç‡:\né¢„å¡«å……æ€§èƒ½: æ¯ä¸ªNPUçš„ååé‡ä¸º 6,688 tokens/sï¼Œè®¡ç®—æ•ˆç‡ä¸º 4.45 tokens/s/TFLOPS. è§£ç æ€§èƒ½: åœ¨ä½äº50msçš„å•Tokenè¾“å‡ºå»¶è¿Ÿ (TPOT)ä¸‹ï¼Œæ¯ä¸ªNPUçš„ååé‡ä¸º1,943 tokens/sï¼Œè®¡ç®—æ•ˆç‡ä¸º 1.29 tokens/s/TFLOPS. æ€§èƒ½å¯¹æ¯”: é¢„å¡«å……å’Œè§£ç çš„è®¡ç®—æ•ˆç‡å‡è¶…è¿‡äº†åœ¨NVIDIA H100ä¸Šè¿è¡ŒSGLangå’Œåœ¨NVIDIA H800ä¸Šè¿è¡ŒDeepSeekçš„å…¬å¼€æ•°æ®. å‡†ç¡®æ€§: åœ¨æ˜‡è…¾910Cä¸Šè¿›è¡Œçš„ INT8 é‡åŒ–ï¼Œå…¶æ¨¡å‹å‡†ç¡®ç‡ä¸å®˜æ–¹ DeepSeek-R1 API åœ¨ 16 ä¸ªåŸºå‡†æµ‹è¯•ä¸­ç›¸å½“ã€‚ 2. LLM Trends and Their Challenges for Datacenter Infrastructure 2.1. LLM Trends Ever-Larger Parameter Counts. scaling law è¡¨æ˜ï¼Œå¢åŠ  LLM çš„å‚æ•°æ•°é‡å¯ä»¥æå‡å…¶åœ¨å„ç§ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚è¿™ä¸€è¶‹åŠ¿çš„å…¸å‹ä»£è¡¨åŒ…æ‹¬:\nMeta çš„ Llama 4 Behemoth: æ‹¥æœ‰è¿‘ 2 ä¸‡äº¿å‚æ•°ã€‚ DeepSeek-V3: åŒ…å« 6710 äº¿å‚æ•°ã€‚ Google çš„ PaLM: åŒ…å« 5400 äº¿å‚æ•°ã€‚ xAI çš„ Grok-1: æ‹¥æœ‰ 3140 äº¿å‚æ•°ã€‚ Sparsity through MoE. ä¸ºäº†æ§åˆ¶ä¸æ–­æ”€å‡çš„è®­ç»ƒå’Œæ¨ç†æˆæœ¬ï¼Œç°ä»£ LLM è¶Šæ¥è¶Šå¤šåœ°é‡‡ç”¨ç¨€ç–æ¿€æ´»çš„ MoE æ¶æ„ã€‚è¿™ç§æ¶æ„å°†æ¨¡å‹çš„æ€»å¤§å°ä¸å¤„ç†æ¯ä¸ª token æ‰€éœ€çš„è®¡ç®—é‡è§£è€¦:\nMixtral 8x7B: æ€»å‚æ•°é‡ä¸º 467 äº¿ï¼Œä½†æ¯ä¸ª token åªæ¿€æ´» 129 äº¿å‚æ•°ã€‚ Databricks çš„ DBRX: æ€»å‚æ•°é‡ä¸º 1320 äº¿ï¼Œæ¯ä¸ª token æ¿€æ´» 360 äº¿å‚æ•°ã€‚ Meta çš„ Llama 4 ç³»åˆ—: Llama 4 Maverick ä½¿ç”¨ 128 ä¸ªä¸“å®¶ï¼Œè€Œ Llama 4 Scout ä½¿ç”¨ 16 ä¸ªä¸“å®¶ã€‚ DeepSeek-V3: å°†æ¯å±‚çš„ä¸“å®¶æ•°é‡ä» 160 ä¸ªå¢åŠ åˆ° 256 ä¸ªï¼Œä»è€Œåœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—è´Ÿè½½çš„æƒ…å†µä¸‹æå‡äº†æ¨¡å‹å®¹é‡ã€‚ é˜¿é‡Œå·´å·´çš„ Qwen3-235B: é›†æˆäº† 128 ä¸ªä¸“å®¶ï¼Œæ¯ä¸ª token æ¿€æ´» 220 äº¿å‚æ•°ã€‚ åä¸ºçš„ç›˜å¤ Ultra MoE: æ€»å‚æ•°é‡è¾¾ 7180 äº¿ï¼Œæ¯ä¸ª token æ¿€æ´» 390 äº¿å‚æ•°ã€‚ è¿™äº›æ¨¡å‹å…±åŒå‡¸æ˜¾äº† LLM æ‰©å±•ç­–ç•¥çš„èŒƒå¼è½¬å˜ï¼Œå³æ›´å¼ºè°ƒé€šè¿‡æ¶æ„ç¨€ç–æ€§è€Œéå•çº¯çš„å‚æ•°æ•°é‡æ¥æå‡æ€§èƒ½å’Œæ•ˆç‡ã€‚\nExtension of Context Windows. LLM ä¸Šä¸‹æ–‡çª—å£çš„æ‰©å¤§ä½¿å…¶èƒ½å¤Ÿå¤„ç†æ›´é•¿çš„åºåˆ—ï¼Œè¿™å¯¹äºéœ€è¦æ‰©å±•æ¨ç†å’Œè¿è´¯æ€§çš„ä»»åŠ¡è‡³å…³é‡è¦ã€‚è¿‘æœŸçš„è¿›å±•åŒ…æ‹¬:\nOpenAI çš„ GPT-4.5: æ”¯æŒ 128,000 ä¸ª token çš„ä¸Šä¸‹æ–‡çª—å£ã€‚ Google çš„ Gemini 2.5 Pro: æä¾›é«˜è¾¾ 100 ä¸‡ä¸ª token çš„ä¸Šä¸‹æ–‡çª—å£ã€‚ ç„¶è€Œå¤„ç†é•¿æ–‡æœ¬ä¼šæ˜¾è‘—å¢åŠ è®¡ç®—æˆæœ¬å’Œæ¨ç†å»¶è¿Ÿã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œç”Ÿäº§ç³»ç»Ÿæ™®éé‡‡ç”¨ä¸Šä¸‹æ–‡ç¼“å­˜ (context caching) æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯é€šè¿‡å­˜å‚¨å’Œå¤ç”¨ç”±å…ˆå‰æç¤ºç‰‡æ®µç”Ÿæˆçš„ KV blockï¼Œæ¥æ¶ˆé™¤å¯¹æç¤ºçš„å†—ä½™æ³¨æ„åŠ›è®¡ç®—ï¼Œä»è€Œé™ä½å»¶è¿Ÿå¹¶æé«˜æ•ˆç‡ã€‚\n2.2. Challenges for Datacenter Infrastructure ä¸Šè¿° LLM çš„å‘å±•è¶‹åŠ¿å¯¹åº•å±‚çš„æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½æå‡ºäº†ä¸¥å³»çš„æ–°è¦æ±‚ã€‚éšç€æ¨¡å‹èƒ½åŠ›çš„æ‰©å±•ï¼Œå®ƒä»¬å‚¬ç”Ÿäº†å¦‚å¼ºåŒ–å­¦ä¹ ã€äº¤äº’å¼åª’ä½“ç”Ÿæˆå’Œè‡ªä¸» AI ä»£ç†ç­‰æ—¥ç›Šå¤æ‚çš„å·¥ä½œè´Ÿè½½ã€‚è¿™äº›åº”ç”¨ä¸ä»…éœ€è¦æµ·é‡çš„è®¡ç®—å’Œå†…å­˜èµ„æºï¼Œè¿˜éœ€è¦å¯¹åŸºç¡€è®¾æ–½è¿›è¡Œæ ¹æœ¬æ€§çš„é‡æ–°æ¶æ„ï¼Œä»¥æ”¯æŒé«˜å¸¦å®½é€šä¿¡å’Œä½å»¶è¿Ÿå­˜å‚¨ï¼Œä»è€Œåœ¨åŠ¨æ€ã€å¼‚æ„çš„çœŸå®ä¸–ç•Œæ¡ä»¶ä¸‹æ»¡è¶³ä¸¥æ ¼çš„æœåŠ¡æ°´å¹³ç›®æ ‡ã€‚\nScaling Communication-Intensive Parallelism.. éšç€æ¨¡å‹è§„æ¨¡çš„å¢é•¿ï¼Œå•ä¸ªè®¡ç®—èŠ‚ç‚¹å·²æ— æ³•å®¹çº³æœ€å…ˆè¿›çš„ AI æ¨¡å‹ï¼Œå¿…é¡»ä½¿ç”¨å¤šèŠ‚ç‚¹å¹¶è¡Œç­–ç•¥ã€‚å°½ç®¡ç°æœ‰çš„ AI é›†ç¾¤é€šè¿‡ RDMA ç½‘ç»œæ”¯æŒè·¨èŠ‚ç‚¹é€šä¿¡ï¼Œä½†å…¶å¸¦å®½å’Œæ‹“æ‰‘ç»“æ„é€šå¸¸åªä¸ºæ•°æ®å¹¶è¡Œ (DP) æˆ–æµæ°´çº¿å¹¶è¡Œ (PP) ç­‰é€šä¿¡é‡è¾ƒå°çš„åœºæ™¯ä¼˜åŒ–ã€‚ç„¶è€Œï¼Œå¼ é‡å¹¶è¡Œ (Tensor Parallelism, TP) å’Œ ä¸“å®¶å¹¶è¡Œ (Expert Parallelism, EP) éœ€è¦é¢‘ç¹ã€ç»†ç²’åº¦ä¸”ä½å»¶è¿Ÿçš„é€šä¿¡ï¼Œè¿™ç§é€šä¿¡æ¨¡å¼éš¾ä»¥åœ¨èŠ‚ç‚¹ä¹‹é—´é«˜æ•ˆæ‰©å±•ã€‚è¿™è¿«ä½¿è®¸å¤šéƒ¨ç½²æ–¹æ¡ˆå°† TP å’Œ EP é™åˆ¶åœ¨å•ä¸ªè®¡ç®—èŠ‚ç‚¹å†…ï¼Œä»è€Œé™åˆ¶äº†å¯æ‰©å±•æ€§ã€‚\nMaintaining High Utilization under Heterogeneous AI Workloads. ç°ä»£ AI å·¥ä½œè´Ÿè½½è¡¨ç°å‡ºé«˜åº¦å¤šæ ·åŒ–å’ŒåŠ¨æ€çš„èµ„æºéœ€æ±‚:\nè®­ç»ƒä»»åŠ¡é€šå¸¸æ˜¯è®¡ç®—å¯†é›†å‹çš„ã€‚ LLM æ¨ç†çš„è§£ç é˜¶æ®µå¾€å¾€å—é™å†…å­˜å¸¦å®½ã€‚ è‡ªåŠ¨é©¾é©¶æ¨¡å‹è®­ç»ƒç­‰ä»»åŠ¡æ¶‰åŠå¤§é‡çš„ CPU ç«¯æ•°æ®é¢„å¤„ç†ã€‚ å›ºå®šçš„èŠ‚ç‚¹é…ç½®æ— æ³•é«˜æ•ˆåœ°é€‚åº”è¿™ç§å¤šæ ·æ€§ï¼Œå¸¸å¸¸å¯¼è‡´èµ„æºè¿‡é…æˆ–åˆ©ç”¨ä¸è¶³ã€‚ä¸ºäº†æœ€å¤§åŒ–æ•ˆç‡å’Œé€‚åº”æ€§ï¼Œç°ä»£ AI åŸºç¡€è®¾æ–½å¿…é¡»èƒ½å¤Ÿæ ¹æ®æ¯ç§å·¥ä½œè´Ÿè½½çš„ç‰¹å®šéœ€æ±‚ï¼ŒåŠ¨æ€ã€ç»†ç²’åº¦åœ°ç»„åˆå¼‚æ„èµ„æº (å¦‚ NPU, CPU å’Œå†…å­˜).\nEnabling Converged Execution of AI and Data-Intensive Workloads. AI å·¥ä½œæµä¸ä¼ ç»Ÿæ•°æ®å¯†é›†å‹æ“ä½œ (å¦‚æ•°æ®æ‘„å–ã€é¢„å¤„ç†ã€æ£€ç´¢ã€åˆ†æå’Œæ¨¡æ‹Ÿ) çš„äº¤å‰è¶Šæ¥è¶Šé¢‘ç¹ã€‚åŒæ—¶ï¼Œæ•°æ®åº“ã€å¤§æ•°æ®å’Œé«˜æ€§èƒ½è®¡ç®— (HPC) ç­‰é€šç”¨å·¥ä½œè´Ÿè½½æœ¬èº«ä¹Ÿåœ¨ä¸æ–­é›†æˆ AI åŠŸèƒ½ã€‚è¿™ç§èåˆæ‰§è¡Œæ¨¡å¼è¦æ±‚é«˜ååã€ä½å»¶è¿Ÿçš„é€šä¿¡å’Œçµæ´»çš„èµ„æºç¼–æ’ã€‚ç„¶è€Œï¼Œä¸»è¦ä¸ºä¼ ç»Ÿé€šç”¨å·¥ä½œè´Ÿè½½ä¼˜åŒ–çš„è€æ—§æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½éš¾ä»¥æ»¡è¶³è¿™äº›è‹›åˆ»çš„è¦æ±‚ã€‚\nDelivering Memory-class Storage Performance. ç°ä»£ AI æµæ°´çº¿æ“ä½œçš„æ•°æ®è§„æ¨¡å·²è¿œè¶…ä¼ ç»Ÿå­˜å‚¨ç³»ç»Ÿçš„èƒ½åŠ›ã€‚è¯¸å¦‚æ‘„å– PB çº§æ•°æ®é›†ã€ç®¡ç† TB çº§æ¨¡å‹æ£€æŸ¥ç‚¹ä»¥åŠæ”¯æŒå»¶è¿Ÿæ•æ„Ÿçš„æ¨ç† (ç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨å¤§å‹ KV cache å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆ RAG æ¨¡å—æ—¶) ç­‰ä»»åŠ¡ï¼Œéƒ½éœ€è¦å­˜å‚¨å­ç³»ç»Ÿå…·å¤‡å†…å­˜çº§çš„å¸¦å®½ã€å»¶è¿Ÿå’Œ IOPS (Input/Output Operations Per Second). å›´ç»•ç£ç›˜è®¿é—®æ¨¡å¼è®¾è®¡çš„ä¼ ç»Ÿå­˜å‚¨å±‚æ¬¡ç»“æ„é¢‘ç¹åœ°æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œå› æ•°æ®ä¾›ç»™ä¸è¶³è€Œå¯¼è‡´ NPU åˆ©ç”¨ç‡ä½ä¸‹ã€‚\n3 Huawei CloudMatrix 3.1. Vision for Huawei CloudMatrix å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒCloudMatrix è¶…è¶Šäº†ä¼ ç»Ÿä»¥ CPU ä¸ºä¸­å¿ƒçš„åˆ†å±‚è®¾è®¡ï¼Œå®ç°äº†æ— éœ€ CPU ä»‹è´¨ä¸‹åŒ…æ‹¬ NPUã€CPUã€DRAMã€SSDã€NIC åŠé¢†åŸŸä¸“ç”¨åŠ é€Ÿå™¨åœ¨å†…çš„æ‰€æœ‰å¼‚æ„ç³»ç»Ÿç»„ä»¶ä¹‹é—´çš„ç›´æ¥é«˜æ€§èƒ½é€šä¿¡ã€‚è¯¥æ¶æ„çš„æ ¸å¿ƒæ˜¯è¶…é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ UB ç½‘ç»œã€‚\nScalable Communication for TP/EP. UB ç½‘ç»œå¯ä»¥ä¸ºå¼ é‡å¹¶è¡Œ (TP) å’Œä¸“å®¶å¹¶è¡Œ (EP) æä¾›å¼ºå¤§çš„é€šä¿¡æ”¯æŒï¼Œä½¿å…¶èƒ½å¤Ÿè½»æ¾æ‰©å±•åˆ°å•èŠ‚ç‚¹è¾¹ç•Œä¹‹å¤–ã€‚\nFlexible Resource Composition for Heterogeneous Workloads. å°† CPUã€NPUã€å†…å­˜ç­‰èµ„æºè§£è€¦æˆç‹¬ç«‹çš„èµ„æºæ± ï¼Œå…è®¸æ ¹æ®å·¥ä½œè´Ÿè½½æŒ‰éœ€ã€ç»†ç²’åº¦åœ°è¿›è¡Œç»„åˆã€‚\nUnified Infrastructure for Converged Workloads. åœ¨å•ä¸€æ¶æ„å†…åŒæ—¶æ”¯æŒ AI å’Œæ•°æ®å¯†é›†å‹å·¥ä½œè´Ÿè½½çš„èåˆæ‰§è¡Œã€‚\nMemory-class Storage via Disaggregated Memory Pool. é€šè¿‡èšåˆé›†ç¾¤ä¸­æ‰€æœ‰ CPU æŒ‚è½½çš„ DRAMï¼Œå½¢æˆä¸€ä¸ªå¯é€šè¿‡ UB è®¿é—®çš„å…±äº«é«˜æ€§èƒ½å†…å­˜æ± ï¼Œä¸º KV cache å¤ç”¨ã€å‚æ•°åŠ è½½ç­‰æä¾›åŠ é€Ÿã€‚\n3.2. CloudMatrix384 Overview: A Fully Peer-to-Peer Hardware Architecture CloudMatrix384 æ˜¯ä¸€ä¸ªé›†æˆäº† 384 ä¸ªæ˜‡è…¾ (Ascend) 910C NPU å’Œ 192 ä¸ªé²²é¹ (Kunpeng) CPU çš„ AI è¶…çº§èŠ‚ç‚¹ã€‚å…¶æœ€æ˜¾è‘—çš„ç‰¹ç‚¹æ˜¯ï¼Œé€šè¿‡ UB ç½‘ç»œå®ç°äº†è·¨èŠ‚ç‚¹é€šä¿¡æ€§èƒ½ä¸èŠ‚ç‚¹å†…æ€§èƒ½çš„é«˜åº¦ä¸€è‡´ (å¸¦å®½ä¸‹é™ \u0026lt; 3%ï¼Œå»¶è¿Ÿå¢åŠ  \u0026lt; 1Âµs). CloudMatrix384 åŒ…å«ä¸‰ä¸ªäº’è¡¥çš„ç½‘ç»œå¹³é¢:\nUB å¹³é¢: è¶…çº§èŠ‚ç‚¹å†…çš„ä¸»è¦çºµå‘æ‰©å±• (Scale-Up) ç½‘ç»œï¼Œä»¥å…¨äº’è”ã€æ— é˜»å¡çš„æ–¹å¼è¿æ¥æ‰€æœ‰ 384 ä¸ª NPU å’Œ 192 ä¸ª CPU. æ¯ä¸ªæ˜‡è…¾ 910C NPU ä¸ºè¯¥å¹³é¢è´¡çŒ®è¶…è¿‡ 392 GB/s çš„å•å‘å¸¦å®½ã€‚ RDMA å¹³é¢: ç”¨äºè¶…çº§èŠ‚ç‚¹é—´çš„æ¨ªå‘æ‰©å±• (Scale-Out) é€šä¿¡ï¼Œé‡‡ç”¨ RoCE åè®®ï¼Œç¡®ä¿ä¸ç°æœ‰ RDMA ç”Ÿæ€çš„å…¼å®¹æ€§ã€‚æ¯ä¸ª NPU ä¸ºè¯¥å¹³é¢è´¡çŒ®é«˜è¾¾ 400 Gbps çš„å•å‘å¸¦å®½ã€‚ VPC å¹³é¢: é€šè¿‡æ“å¤©å¡ (Qingtian Card) å°†è¶…çº§èŠ‚ç‚¹æ¥å…¥æ›´å¹¿æ³›çš„æ•°æ®ä¸­å¿ƒç½‘ç»œï¼Œç”¨äºç®¡ç†ã€æ§åˆ¶å’Œè®¿é—®æŒä¹…åŒ–å­˜å‚¨ç­‰æ“ä½œã€‚ 3.3. Hardware Components æ˜‡è…¾ 910C èŠ¯ç‰‡: ä½œä¸ºç³»ç»Ÿçš„æ ¸å¿ƒï¼Œå®ƒé‡‡ç”¨åŒæ™¶ç²’ (dual-die) å°è£…ã€‚æ¯ä¸ªèŠ¯ç‰‡åŒ…æä¾› 752 TFLOPS çš„ BF16/FP16 ç®—åŠ›ï¼Œæ”¯æŒ INT8 æ•°æ®ç±»å‹ã€‚å®ƒé›†æˆ 128 GB ç‰‡ä¸Šå†…å­˜ï¼Œæ€»å¸¦å®½é«˜è¾¾ 3.2 TB/s. æ˜‡è…¾ 910C èŠ‚ç‚¹: æ¯ä¸ªè®¡ç®—èŠ‚ç‚¹é›†æˆ 8 ä¸ªæ˜‡è…¾ 910C NPU å’Œ 4 ä¸ªé²²é¹ CPU. UB äº¤æ¢ç³»ç»Ÿ: é‡‡ç”¨ä¸¤çº§ (L1/L2) æ— é˜»å¡äº¤æ¢ç½‘ç»œæ‹“æ‰‘ï¼Œå°†æ‰€æœ‰èŠ‚ç‚¹ç´§å¯†è¿æ¥æˆä¸€ä¸ªç»Ÿä¸€çš„è¶…çº§èŠ‚ç‚¹ã€‚ 3.4. Software Stack CANN (ç¥ç»ç½‘ç»œè®¡ç®—æ¶æ„): åä¸ºä¸ºæ˜‡è…¾ NPU å¼€å‘çš„å®Œæ•´è½¯ä»¶ç”Ÿæ€ç³»ç»Ÿï¼Œç±»ä¼¼äº NVIDIA çš„ CUDA. å®ƒåŒ…å«é©±åŠ¨å±‚ã€è¿è¡Œæ—¶å±‚ (Runtime) å’Œåº“å±‚ (å¦‚ç”¨äºåˆ†å¸ƒå¼é€šä¿¡çš„ HCCL)ï¼Œå¹¶é€šè¿‡å›¾å¼•æ“ (Graph Engine, GE) å¯¹ä¸Šå±‚æ¡†æ¶ (å¦‚ PyTorch, TensorFlow) çš„è®¡ç®—å›¾è¿›è¡Œç¼–è¯‘å’Œä¼˜åŒ–ã€‚ äº‘éƒ¨ç½²åŸºç¡€è®¾æ–½è½¯ä»¶: åŒ…æ‹¬ MatrixResourceã€MatrixLinkã€MatrixCompute å’Œ MatrixContainer ç­‰ä¸€ç³»åˆ—è½¯ä»¶ï¼Œç”¨äºåœ¨äº‘ç¯å¢ƒä¸­å¯¹ CloudMatrix é›†ç¾¤è¿›è¡Œèµ„æºç®¡ç†ã€ç½‘ç»œé…ç½®å’Œå®¹å™¨åŒ–éƒ¨ç½²ã€‚ä¸Šå±‚çš„ ModelArts å¹³å°åˆ™æä¾›ç«¯åˆ°ç«¯çš„ AI å¼€å‘å’Œ MLOps æœåŠ¡ã€‚ 3.5. Suitability Analysis for DeepSeek Models DeepSeek Models and Their Deployment on NVIDIA H800 DeepSeek åœ¨ç”± NVIDIA H800 GPU ç»„æˆçš„é›†ç¾¤ä¸Šéƒ¨ç½²å…¶ V3 å’Œ R1 æ¨¡å‹ï¼Œæ¯ä¸ª GPU å†…å­˜ 80 GBï¼ŒèŠ‚ç‚¹å†…é€šè¿‡ NVLink è¿æ¥ï¼ŒèŠ‚ç‚¹é—´é€šè¿‡ 400 Gbps InfiniBand è¿æ¥ã€‚è¯¥éƒ¨ç½²é‡‡ç”¨äº†åˆ†ç¦»å¼é¢„å¡«å……-è§£ç æ¶æ„ã€‚åœ¨é¢„å¡«å……é˜¶æ®µï¼ŒDeepSeek å°†å››ä¸ª H800 èŠ‚ç‚¹ï¼ˆå…± 32 ä¸ª GPUï¼‰ç»„ç»‡æˆä¸€ä¸ªéƒ¨ç½²å•å…ƒã€‚åœ¨æ¯ä¸ªå•å…ƒå†…ï¼Œ256 ä¸ªè·¯ç”±ä¸“å®¶è¢«ç­–ç•¥æ€§åœ°åˆ†å¸ƒåœ¨ GPU ä¸Šï¼Œæ¯ä¸ª GPU è´Ÿè´£ 9 ä¸ªè·¯ç”±ä¸“å®¶å’Œ 1 ä¸ªå…±äº«ä¸“å®¶ã€‚è¯¥é…ç½®æ ‡ä¸º DP32+EP32ï¼Œåˆ©ç”¨ 32 ä¸ª GPU ä¹‹é—´çš„ EPï¼ŒåŒæ—¶å…±äº«ä¸“å®¶å’Œ MLA æœºåˆ¶é€šè¿‡ DP åœ¨åŒä¸€ç»„ GPU ä¸Šå¤åˆ¶ã€‚åœ¨è§£ç é˜¶æ®µï¼ŒDeepSeek è¿›ä¸€æ­¥æ‰©å±•å¹¶è¡Œåº¦è‡³ DP144+EP144ï¼Œå°† 18 ä¸ªèŠ‚ç‚¹ç»„åˆæˆæ€»è®¡ 144 ä¸ª GPUã€‚åœ¨è¿™ä¸€æ›´å¤§è§„æ¨¡çš„éƒ¨ç½²ä¸­ï¼Œæ¯ä¸ª GPU ç®¡ç†ä¸¤ä¸ªè·¯ç”±ä¸“å®¶å’Œä¸€ä¸ªå…±äº«ä¸“å®¶ï¼Œä¿æŒç³»ç»ŸèŒƒå›´å†… 32 ä¸ªè·¯ç”±ä¸“å®¶å‰¯æœ¬çš„å†—ä½™ã€‚\nDeepSeek é‡‡ç”¨äº† DualPipe ç­–ç•¥ç”¨äºé‡å è®¡ç®—å’Œ All-to-all é€šä¿¡ã€‚å½“ä¸€ä¸ª micro-batch æ­£åœ¨è¿›è¡Œ MoE ç›¸å…³çš„ dispatch å’Œ combine æ—¶ï¼Œä¸‹ä¸€ä¸ª micro-batch åˆ™åŒæ—¶è¿›è¡Œå±€éƒ¨æ³¨æ„åŠ›æˆ– MLP è®¡ç®—ã€‚\næ¯ä¸ª H800 GPU åœ¨ prefill é˜¶æ®µè¾¾åˆ°æœ€é«˜ 9,213 token/s (6.3% çš„ä¸Šä¸‹æ–‡ç¼“å­˜å‘½ä¸­ç‡). å‰”é™¤ç¼“å­˜å‘½ä¸­åæœ‰æ•ˆååé‡ä¸º 4,026 token/s. Decode é˜¶æ®µï¼Œæ¯ä¸ª GPU ç»´æŒå¹³å‡ 1,850 token/s çš„ååé‡ã€‚\næœ¬èŠ‚åˆ†æäº† CloudMatrix384 çš„æ¶æ„ç‰¹æ€§ä¸ºä½•ä¸å¤§è§„æ¨¡ MoE æ¨¡å‹ (ä»¥ DeepSeek-R1 ä¸ºä¾‹) çš„éœ€æ±‚é«˜åº¦ååŒã€‚\nMoE é€šä¿¡ååŒ: é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ UB ç½‘ç»œéå¸¸é€‚åˆ MoE æ¨¡å‹ä¸­é€šä¿¡å¼€é”€å·¨å¤§çš„ token dispatch å’Œä¸“å®¶è¾“å‡º combine é˜¶æ®µã€‚ å†…å­˜å®¹é‡ä¸ç®¡ç†: æ•´ä¸ªè¶…çº§èŠ‚ç‚¹æä¾›é«˜è¾¾ 49.2 TB çš„ NPU å†…å­˜ï¼Œè¶³ä»¥å®¹çº³åƒ DeepSeek-R1 (671B å‚æ•°) è¿™æ ·çš„å·¨å‹æ¨¡å‹åŠå…¶åºå¤§çš„ KV cache. ä¸Šä¸‹æ–‡ç¼“å­˜å¤ç”¨: UB ç½‘ç»œä½¿ NPU èƒ½å¤Ÿä»¥å†…å­˜çº§çš„é€Ÿåº¦ç›´æ¥è®¿é—®ç”± CPU DRAM æ„æˆçš„è§£è€¦å†…å­˜æ± ï¼Œæå¤§åœ°åŠ é€Ÿäº†å†å² KV cache çš„è¯»å–ï¼Œä»è€Œé™ä½äº†é¦– token ç”Ÿæˆå»¶è¿Ÿ (TTFT). é‡åŒ–æ”¯æŒ: æ˜‡è…¾ 910C å¯¹ INT8 è®¡ç®—çš„åŸç”Ÿæ”¯æŒï¼Œä¸ºé€šè¿‡é‡åŒ–æ¥é™ä½æ¨¡å‹å†…å­˜å ç”¨ã€å‡å°‘è®¡ç®—å¼€é”€å’Œæå‡æ¨ç†æ€§èƒ½æä¾›äº†å®è´µçš„æœºä¼šã€‚ 4. DeepSeek Serving on Huawei CloudMatrix384 4.1. Overview: A Peer-to-Peer Serving Architecture with PDC Disaggregation å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ–‡ä¸­æå‡ºäº†ä¸€ç§ç‹¬ç‰¹çš„ç‚¹å¯¹ç‚¹æœåŠ¡æ¶æ„ï¼Œå°†ç³»ç»Ÿåˆ’åˆ†ä¸ºä¸‰ä¸ªåŠŸèƒ½å­ç³»ç»Ÿï¼Œprefill, decode å’Œ caching (PDC)ï¼Œæ¯ä¸ªå­ç³»ç»Ÿç‹¬ç«‹è¿è¡Œï¼Œå¹¶é€šè¿‡æ˜¾å¼çš„ KV cache ä¼ è¾“æ¥å£è¿›è¡Œé€šä¿¡ã€‚\nKVCache-centric vs. Peer-to-Peer Serving Architectures: ç°æœ‰çš„ LLM æœåŠ¡ç³»ç»Ÿå¦‚ NVIDIA Dynamoï¼ˆNVIDIA Corporationï¼Œ2025ï¼‰å’Œ Mooncakeï¼ˆQin ç­‰ï¼Œ2025ï¼‰é‡‡ç”¨ KVCache ä¸ºä¸­å¿ƒçš„è®¾è®¡ï¼Œå…¶ä¸­è¯·æ±‚è°ƒåº¦ä¸ KV cache çš„å±€éƒ¨æ€§ç´§å¯†è€¦åˆã€‚åœ¨è¿™äº›ç³»ç»Ÿä¸­ï¼Œè¯·æ±‚é€šå¸¸è¢«è·¯ç”±åˆ°å·²ç»æŒæœ‰å¯¹åº” KV cache çš„ç‰¹å®šè®¡ç®—èŠ‚ç‚¹ã€‚æ­¤ç±»ç¼“å­˜æ„ŸçŸ¥è°ƒåº¦å¯¹äºç¼“è§£è¿œç¨‹å†…å­˜è®¿é—®å¸¦æ¥çš„æ˜¾è‘—æ€§èƒ½æŸå¤±è‡³å…³é‡è¦ï¼Œå› ä¸ºèŠ‚ç‚¹å†…å­˜è®¿é—®ï¼ˆä¾‹å¦‚é€šè¿‡ PCIeï¼Œçº¦ 256 GB/sï¼‰è¿œè¿œå¿«äºèŠ‚ç‚¹é—´å¸¦å®½ï¼ˆé€šå¸¸çº¦ 25 GB/s æˆ– 200 Gbpsï¼‰ã€‚å› æ­¤ï¼Œè¿œç¨‹ KV cache åŠ è½½é€šå¸¸ä¼šå¸¦æ¥è¾ƒå¤§å»¶è¿Ÿã€‚ç„¶è€Œï¼Œè¿™ç§è®¾è®¡å¼•å…¥äº†å¤æ‚çš„è°ƒåº¦éš¾é¢˜ï¼Œå¹¶ä¸”åœ¨åŠ¨æ€å·¥ä½œè´Ÿè½½ä¸‹å¯èƒ½å¯¼è‡´è´Ÿè½½å‡è¡¡æ¶åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥è®¾è®¡é™åˆ¶äº†å…¨å±€èµ„æºæ•ˆç‡ï¼Œå› ä¸ºè§£ç èŠ‚ç‚¹ä¸Šçš„ DRAM é€šå¸¸å¤„äºå­¤ç«‹çŠ¶æ€ä¸”åˆ©ç”¨ç‡ä½ï¼Œæ— æ³•æœ‰æ•ˆè´¡çŒ®äºå…±äº«ç¼“å­˜å®¹é‡ã€‚\nCloudMatrix-Infer ä¸­çš„ç‚¹å¯¹ç‚¹æœåŠ¡æ¶æ„å……åˆ†åˆ©ç”¨äº† CloudMatrix384 çš„è¶…é«˜å¸¦å®½ UB äº’è”ã€‚è¿™ä½¿å¾—åŸºäºè§£è€¦å†…å­˜æ± æ„å»ºçš„åˆ†å¸ƒå¼ç¼“å­˜é›†ç¾¤ (4.4) èƒ½å¤Ÿå®ç°ç»Ÿä¸€è®¿é—®ã€‚æ— è®º NPU æ˜¯æ‰§è¡Œé¢„å¡«å……ä»»åŠ¡è¿˜æ˜¯è§£ç ä»»åŠ¡ï¼Œéƒ½å¯ä»¥ç›´æ¥è®¿é—®å…±äº«è§£è€¦å†…å­˜æ± ã€‚è¿™ç§å®Œå…¨çš„ç‚¹å¯¹ç‚¹è®¾è®¡æœ‰æ•ˆåœ°æ‰å¹³åŒ–äº†å†…å­˜å±‚æ¬¡ç»“æ„ï¼Œå¼¥è¡¥äº†æœ¬åœ°è®¿é—®å’Œè¿œç¨‹è®¿é—®å»¶è¿Ÿä¹‹é—´çš„ä¼ ç»Ÿå·®è·ã€‚è¿™ç§å°†è¯·æ±‚è°ƒåº¦ä¸ KV ç¼“å­˜æ”¾ç½®è§£è€¦å¸¦æ¥äº†å‡ ä¸ªå…³é”®ä¼˜åŠ¿ã€‚\nä½¿æ¨ç†è¯·æ±‚å¯ä»¥è°ƒåº¦åˆ°ä»»ä½•å¯ç”¨çš„ NPU å®ä¾‹ï¼Œè€Œä¸å—æ•°æ®å±€éƒ¨æ€§çš„é™åˆ¶ã€‚æ˜¾è‘—æå‡äº†ç³»ç»ŸèŒƒå›´å†…çš„è´Ÿè½½å‡è¡¡å’Œ NPU åˆ©ç”¨ç‡ã€‚ æ¶ˆé™¤äº†å¯¹å¤æ‚çš„äº²å’Œæ€§è°ƒåº¦æœºåˆ¶çš„éœ€æ±‚ï¼Œä»è€Œé™ä½äº†æ¶æ„å¤æ‚æ€§ï¼Œç®€åŒ–äº†ç³»ç»Ÿç»´æŠ¤ã€‚ é€šè¿‡åœ¨é¢„å¡«å……å’Œè§£ç èŠ‚ç‚¹ä¹‹é—´å…±äº« DRAM èµ„æºï¼Œç³»ç»Ÿå½¢æˆäº†ä¸€ä¸ªç»Ÿä¸€çš„å¼¹æ€§ç¼“å­˜åº•å±‚ï¼Œæé«˜äº†å†…å­˜åˆ©ç”¨ç‡ï¼Œå¢åŠ äº†ç¼“å­˜å‘½ä¸­ç‡ï¼Œå¹¶åœ¨è´Ÿè½½å¤±è¡¡æˆ–çªå‘æƒ…å†µä¸‹æä¾›äº†æ›´å¼ºçš„å¼¹æ€§ã€‚ æ¯ä¸ªé¢„å¡«å……å®ä¾‹åœ¨ CloudMatrix384 ä¸Šé…å¤‡ 16 ä¸ª Ascend 910C NPUï¼ˆ32 ä¸ªèŠ¯ç‰‡ï¼‰ï¼Œå¹¶ä»¥ 32 è·¯ä¸“å®¶å¹¶è¡Œï¼ˆEP32ï¼‰è¿è¡Œã€‚æ¯ä¸ª rank ä¸Šæ”¾ç½® 10 ä¸ªä¸“å®¶: 1 ä¸ªå…±äº«ä¸“å®¶ã€8ä¸ªè·¯ç”±ä¸“å®¶å’Œ 1 ä¸ªå†—ä½™è·¯ç”±ä¸“å®¶ï¼Œä»¥æ”¯æŒä¸“å®¶å¹¶è¡Œè´Ÿè½½å‡è¡¡ï¼ˆEPLBï¼‰ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ•ˆç‡ï¼Œå¯¹ MLA è®¡ç®—é‡‡ç”¨æ··åˆå¹¶è¡Œç­–ç•¥ï¼Œå¹¶åº”ç”¨åŸºäº micro-batch çš„æµæ°´çº¿ä»¥é‡å é€šä¿¡å¼€é”€ï¼ˆ4.3ï¼‰ã€‚\næ¯ä¸ªè§£ç å®ä¾‹åˆ†é…äº† 160 ä¸ª Ascend 910C NPUï¼ˆ320 ä¸ªèŠ¯ç‰‡ï¼‰åº”äº MoE å±‚çš„ 320 è·¯ä¸“å®¶å¹¶è¡Œï¼ˆEP320ï¼‰. æ¯ä¸ª rank æ‰¿è½½ä¸€ä¸ªä¸“å®¶ï¼Œæ•´ä½“é…ç½®åŒ…æ‹¬ 32 ä¸ªå…±äº«ä¸“å®¶ã€256 ä¸ªç‹¬ç«‹è·¯ç”±ä¸“å®¶å’Œ 32 ä¸ªå†—ä½™è·¯ç”±ä¸“å®¶ï¼Œä»¥æ”¯æŒ EPLBã€‚ä¸ºäº†è¿›ä¸€æ­¥åŠ é€Ÿè§£ç ï¼Œå¼•å…¥äº†ä¼˜åŒ–çš„ Ascend åŸç”Ÿç®—å­ã€æµæ°´çº¿è§£ç ç­–ç•¥ä»¥åŠ MTP (4.2).\n4.2. Tightly-Coupled Decode with Large-scale Expert Parallelism 4.2.1 Fused Communication Operators for LEP MoE è®¡ç®—æµç¨‹ä¸º: åœ¨ gate network ä¸ºæ¯ä¸ª token é€‰æ‹© Top-K ä¸“å®¶åï¼Œè¿›å…¥ FFN é˜¶æ®µå‰éœ€è¦ä¸¤æ¬¡ all-to-all é€šä¿¡ã€‚ç¬¬ä¸€æ¬¡ all-to-all æ“ä½œäº¤æ¢è·¯ç”±ä¿¡æ¯ (å¦‚ token åˆ°ä¸“å®¶çš„åˆ†é…ä¿¡æ¯). ç¬¬äºŒæ¬¡ all-to-all æ“ä½œäº¤æ¢å®é™…çš„ token æ•°æ®ã€‚è¯¥æ•°æ®æœ€åˆä»¥ BF16 æ ¼å¼å­˜å‚¨ï¼Œä¸ºå‡å°‘é€šä¿¡å’Œè®¡ç®—å¼€é”€æ¯ä¸ª NPU è¿›è¡Œé‡åŒ–ä¸º INT8 æ ¼å¼ï¼Œç„¶åç”±åˆ†é…çš„ FFN å¤„ç†ã€‚è®¡ç®—å®Œæˆåï¼Œç¬¬ä¸‰æ¬¡ all-to-all é€šä¿¡å°†ä¸“å®¶è¾“å‡ºå‘é€å›å…¶åŸå…ˆçš„ rankï¼Œæ¯ä¸ª NPU æ‰§è¡Œæœ€ç»ˆçš„ token åˆå¹¶ä»¥é‡æ„è¾“å‡ºã€‚è¯¥æµç¨‹å­˜åœ¨ä¸‰ä¸ªä½æ•ˆé—®é¢˜:\né€šä¿¡å¼€é”€å¤§: ä¸‰æ¬¡ all-to-all é€šä¿¡å¼•åŠ ä¸Šé€šä¿¡æ¨ªè·¨å‡ ç™¾ä¸ª NPU å¯¼è‡´å»¶è¿Ÿå¾ˆå¤§ã€‚ åŠ¨æ€å½¢çŠ¶: å› ä¸ºæ¯æ¬¡è§£ç è¿­ä»£ä¸­åˆ†é…ç»™æ¯ä¸ªä¸“å®¶çš„ token æ•°é‡ä¸åŒï¼Œå¯¼è‡´ all2ll é€šä¿¡ä¸­æ•°æ®å½¢çŠ¶ä¸å›ºå®šã€‚éœ€è¦åŠ¨æ€å†…å­˜åˆ†é…å’Œé¢‘ç¹çš„ CPU-NPU åŒæ­¥ï¼Œé™ä½äº†æ‰§è¡Œæ•ˆç‡ã€‚ é¡ºåºä¾èµ–:MoE è®¡ç®—çš„é¡ºåºæ‰§è¡Œç‰¹æ€§å¯¼è‡´æ­¥éª¤ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œé™ä½äº†èµ„æºåˆ©ç”¨ç‡å’Œååé‡ã€‚ ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡å¼€å‘äº† FusedDispatch å’Œ FusedCombine ä¸¤ä¸ªèåˆç®—å­ï¼Œå°†é€šä¿¡å’Œè®¡ç®—é›†æˆåœ¨ä¸€èµ·ï¼Œä¸“é—¨è®¾è®¡ç”¨äºåœ¨ CloudMatrix384 ä¸Šå®ç°æœ€ä½³çš„è§£ç æ€§èƒ½ã€‚\nAIV-Direct Communication across NPUs: AIV-Direct ä½¿ AI vector æ ¸å¿ƒèƒ½å¤Ÿé€šè¿‡ UB äº’è¿ç›´æ¥å°†æ•°æ®å†™å…¥è¿œç¨‹ NPU çš„å†…å­˜ï¼Œå®Œå…¨ç»•è¿‡äº†æ˜“äº§ç”Ÿå»¶è¿Ÿçš„ Serial Direct Memory Access (SDMA) è·¯å¾„ (ä¸‹å›¾è“çº¿).\nEarly Quantization: Dispatch çš„æ—¶å€™ä¸å†å‘é€ BF16 æ•°æ®ï¼Œè€Œæ˜¯ä¼ è¾“ INT8 é‡åŒ–åçš„æ•°æ®åŠå…¶ç¼©æ”¾å› å­ã€‚INT8 è¡¨ç¤ºæ¯ä¸ª token (7,168 ç»´) éœ€è¦ 7 KBã€‚ ç¼©æ”¾å› å­å ç”¨ 4 å­—èŠ‚ï¼ˆINT32ï¼‰ï¼Œä½†ä¸ºäº†å¯¹é½åˆ†é… 512 B ç»™ç¼©æ”¾å› å­ã€‚å› æ­¤ï¼Œæ¯ä¸ª token çš„ä¼ è¾“æ¶ˆæ¯å¤§å°ä¸º 7.5 KB.\nStatic Execution via Sharedâ€‘Memory Preâ€‘allocation: åœ¨æ¯ä¸ª NPU rank ä¸­é™æ€é¢„åˆ†é…å…±äº«å†…å­˜ç¼“å†²åŒºã€‚\n$$\rbuffer_size = rank_num Ã— max_tokens Ã— msg_size\r$$ å…¶ä¸­ $max_tokens = local_batch Ã— \\min(topK, experts_per_die)$. msg_size æ˜¯æ¯ä¸ª token çš„æ¶ˆæ¯é•¿åº¦ï¼ˆINT8 é‡åŒ–åï¼Œdispatch ä¸º 7.5 KBï¼Œcombine ä¸º 14 KBï¼‰\nç”±äº FusedDispatch å’Œ FusedCombine æ˜¯è¿ç»­æ‰§è¡Œçš„ï¼Œå…±ç”¨ä¸€ä¸ªç¼“å†²åŒºä¼šäº§ç”Ÿç«äº‰ï¼Œå› æ­¤é‡‡ç”¨åŒç¼“å†²æœºåˆ¶æ¥é¿å…å†™å…¥è¦†ç›–ã€‚æœ¬æ–‡è®¾ç½®ä¸­æ¯ä¸ªèŠ¯ç‰‡å¤„ç†æœ€å¤š local_batch=96ï¼Œå¹¶æœ€å¤šæ”¾ç½® 2 ä¸“å®¶ï¼Œäº§ç”Ÿ max_tokens=96Ã—minâ¡(8,1)=96. åœ¨åŒ…å« 320 ä¸ªè®¾å¤‡çš„é€šä¿¡åŸŸä¸­ï¼Œåˆ†å‘ç¼“å†²åŒºå ç”¨ 320Ã—96Ã—7.5â¢KBâ‰ˆ225â¢MB ï¼Œåˆå¹¶ç¼“å†²åŒºå ç”¨ 320Ã—96Ã—14â¢KBâ‰ˆ420â¢MB.\nData-Sending Pipeline: è¿œç¨‹æ•°æ®å†™å…¥éœ€è¦è®¡ç®—ç›®æ ‡ NPU é¢„åˆ†é…ç¼“å†²åŒºçš„åç§»é‡ï¼Œä½†é¡ºåºæ‰§è¡Œæ­¤è®¡ç®—å’Œä¼ è¾“ä¼šå¯¼è‡´æ‰§è¡Œé˜»å¡ã€‚å› æ­¤æ–‡ä¸­å°†æ‰§è¡Œåˆ†æˆä¸‰é˜¶æ®µæµæ°´çº¿\nå°†ä¸‹ä¸€ä¸ª micro-batch å¤åˆ¶åˆ°æœ¬åœ° UBuffer. è®¡ç®—è¿œç¨‹ç¼“å†²åŒºåç§»é‡ï¼Œå¹¶è¿›è¡Œ INT8 é‡åŒ–ã€‚ å‘å¯¹åº” NPU çš„å†…å­˜å‘èµ· AIV-Direct å†™å…¥ã€‚ å®Œæ•´çš„ FusedDispatch å¦‚ä¸‹:\næ¯ä¸ªè®¾å¤‡ä¼šæ£€æŸ¥è‡ªå·±æœ‰å“ªäº› token è¦å‘ç»™å…¶ä»–è®¾å¤‡çš„ä¸“å®¶ã€‚ AIV æ ¸å¿ƒä»å†…å­˜é‡ŒæŠŠ token è¯»åˆ°æœ¬åœ°çš„ UBuffer. æŠŠæ•°æ®é‡åŒ–æˆ INT8 æ ¼å¼ï¼ŒåŒæ—¶è®°å½•ç¼©æ”¾å› å­ã€‚ç»™æ¯ä¸ª token åŠ ä¸Šæ ‡ç­¾ï¼ŒåŒ…æ‹¬ï¼šæº rank IDï¼Œtoken å±äºå“ªä¸ªæ‰¹æ¬¡ï¼ˆbatch-slot IDï¼‰ä»¥åŠ token åœ¨æ•°æ®é‡Œçš„ä½ç½®ï¼ˆkey offsetï¼‰.é€šè¿‡ AIV-direct æŠŠæ‰“åŒ…å¥½çš„æ•°æ®å†™åˆ°ç›®æ ‡èŠ‚ç‚¹çš„é¢„åˆ†é…å†…å­˜é‡Œã€‚ ç­‰æ‰€æœ‰ token æ•°æ®éƒ½é€šè¿‡ AIV-direct å‘å®Œåï¼Œç³»ç»Ÿä¼šè®¾ç½®ä¸€ä¸ª barrierï¼Œç¡®ä¿æ¯ä¸ªè®¾å¤‡çš„æ•°æ®éƒ½å†™å®Œäº†ã€‚è®¾å¤‡è®¡ç®—æ¯ä¸ªä¸“å®¶æ”¶åˆ°äº†å¤šå°‘ token åä¼šäº’ç›¸åŒæ­¥ï¼Œç¡®ä¿è®¡æ•°æ²¡å‡ºé”™ã€‚æœ€åè®¾å¤‡é€šè¿‡ AIV-direct å†å‘ä¸€ä¸ªå®Œæˆæ ‡å¿—å’Œè®¾å¤‡ä¸Šæ¯ä¸ªä¸“å®¶çš„ token è®¡æ•° (æ¯ä¸ªä¸“å®¶å‘äº†å‡ ä¸ª token). æ¯ä¸ªè®¾å¤‡ä¼šä¸€ç›´æ£€æŸ¥åˆ«äººå‘æ¥çš„å®Œæˆæ ‡å¿—ï¼Œç­‰ç€æ‰€æœ‰æ ‡å¿—éƒ½å˜æˆ 1. æ”¶åˆ°æ‰€æœ‰æ ‡å¿—åï¼Œè®¾å¤‡ä¼šè¯»å–æ¯ä¸ªä¸“å®¶çš„ token è®¡æ•°ï¼Œç®—å‡ºæ•°æ®åœ¨å†…å­˜é‡Œçš„åç§»ã€‚ç„¶åï¼Œè®¾å¤‡é‡Œçš„ AIV æ ¸å¿ƒä¼šå¹¶è¡Œå·¥ä½œï¼ŒæŠŠæ”¶åˆ°çš„æ•°æ®ä»å…±äº«å†…å­˜é‡Œå–å‡ºæ¥ï¼Œæ•´ç†æˆä¸€ä¸ªè¿ç»­çš„çš„è¾“å‡ºç¼“å†²åŒºã€‚ å®Œæ•´çš„ FusedCombine å¦‚ä¸‹:\nç»“åˆ AIV æ ¸å¿ƒéå†å…¶è´Ÿè´£çš„ peer è®¾å¤‡ï¼Œæ ¹æ®æ¥æ”¶è®¡æ•°ï¼Œä»å†…å­˜ä¸­æå– FFN ç»“æœæ•°æ®ï¼Œå­˜å…¥æœ¬åœ° UBufferã€‚æ ¸å¿ƒåˆ©ç”¨ token å…ƒæ•°æ®è®¡ç®—åŸå§‹è®¾å¤‡çš„æ¥æ”¶åœ°å€ï¼Œé€šè¿‡ AIV-direct é€šé“å°†æ•°æ®ä¼ è¾“è‡³åŸå§‹èŠ‚ç‚¹çš„é¢„åˆ†é…ç¼“å†²åŒºã€‚ æ ‡å¿—æ›´æ–° æ ¸å¿ƒæ ¹æ® token å…ƒæ•°æ®æ¨ç®—ç›®æ ‡è®¾å¤‡çš„æ ‡å¿—åœ°å€ï¼Œé€šè¿‡ AIV-direct å‘å‡ºåŸå­åŠ æ“ä½œï¼Œåœ¨å¯¹ç›®æ ‡èŠ‚ç‚¹ä¸Šçš„æ ‡å¿—å¢é‡è®¡æ•°ã€‚ æ¯ä¸ªèŠ‚ç‚¹çš„æ ¸å¿ƒä¼šä¸€ç›´æ£€æŸ¥è‡ªå·±çš„æ ‡å¿—ï¼Œç­‰å¾…æ‰€æœ‰æ ‡å¿—éƒ½å˜æˆ 1. éšåä»å…±äº«å†…å­˜æ”¶é›† FFN è¾“å‡ºï¼Œæå–å¯¹åº”ç¼©æ”¾å› å­ï¼Œè¿›è¡Œé€å…ƒç´ ç¼©æ”¾å¹¶æ±‚å’Œã€‚å°†åˆå¹¶ç»“æœåŠ åˆ°å…±äº«çš„ FFN è¾“å‡ºä¸­ï¼Œç”Ÿæˆæœ€ç»ˆçš„ token è¾“å‡ºã€‚ 4.2.2 MLA Optimization ","permalink":"http://localhost:1313/blogs/servingllmsonhuaweicloudmatrix384/","summary":"Serving Large Language Models on Huawei CloudMatrix384","title":"ServingLLMsOnHuaweiCloudMatrix384"},{"content":"model \u0026amp; config Network Definition\n{ \u0026#34;architectures\u0026#34;: [ \u0026#34;InternLM3ForCausalLM\u0026#34; ], \u0026#34;attention_dropout\u0026#34;: 0.0, \u0026#34;auto_map\u0026#34;: { \u0026#34;AutoConfig\u0026#34;: \u0026#34;configuration_internlm3.InternLM3Config\u0026#34;, \u0026#34;AutoModel\u0026#34;: \u0026#34;modeling_internlm3.InternLM3Model\u0026#34;, \u0026#34;AutoModelForCausalLM\u0026#34;: \u0026#34;modeling_internlm3.InternLM3ForCausalLM\u0026#34; }, \u0026#34;bias\u0026#34;: false, \u0026#34;bos_token_id\u0026#34;: 1, \u0026#34;eos_token_id\u0026#34;: 2, \u0026#34;head_dim\u0026#34;: 128, \u0026#34;hidden_act\u0026#34;: \u0026#34;silu\u0026#34;, \u0026#34;hidden_size\u0026#34;: 4096, \u0026#34;initializer_range\u0026#34;: 0.02, \u0026#34;intermediate_size\u0026#34;: 10240, \u0026#34;max_position_embeddings\u0026#34;: 32768, \u0026#34;model_type\u0026#34;: \u0026#34;internlm3\u0026#34;, \u0026#34;num_attention_heads\u0026#34;: 32, \u0026#34;num_hidden_layers\u0026#34;: 48, \u0026#34;num_key_value_heads\u0026#34;: 2, \u0026#34;pad_token_id\u0026#34;: 2, \u0026#34;qkv_bias\u0026#34;: false, \u0026#34;rms_norm_eps\u0026#34;: 1e-05, \u0026#34;rope_scaling\u0026#34;: { \u0026#34;factor\u0026#34;: 6.0, \u0026#34;rope_type\u0026#34;: \u0026#34;dynamic\u0026#34; }, \u0026#34;rope_theta\u0026#34;: 50000000, \u0026#34;tie_word_embeddings\u0026#34;: false, \u0026#34;torch_dtype\u0026#34;: \u0026#34;bfloat16\u0026#34;, \u0026#34;transformers_version\u0026#34;: \u0026#34;4.47.1\u0026#34;, \u0026#34;use_cache\u0026#34;: true, \u0026#34;vocab_size\u0026#34;: 128512 } æ¨¡å— (Module) å­æ¨¡å— (Sub-module) åŠŸèƒ½æè¿° é…ç½®å‚æ•° InternLM3ForCausalLM model: InternLM3Model æ¨¡å‹ä¸»å¹²ï¼ŒåŒ…å«è¯åµŒå…¥å’Œè§£ç å™¨å±‚ã€‚ - lm_head: Linear çº¿æ€§è¾“å‡ºå±‚ï¼Œå°†éšè—çŠ¶æ€æ˜ å°„åˆ°è¯æ±‡è¡¨å¤§å°ï¼Œç”Ÿæˆé¢„æµ‹ logitsã€‚ hidden_size: 4096, vocab_size: 128512 \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; InternLM3Model embed_tokens: Embedding å°†è¾“å…¥çš„ token IDs è½¬æ¢ä¸ºç¨ å¯†å‘é‡ï¼ˆEmbeddingsï¼‰ã€‚ vocab_size: 128512, hidden_size: 4096 layers: ModuleList[InternLM3DecoderLayer] åŒ…å«å¤šä¸ªï¼ˆ48ä¸ªï¼‰Transformerè§£ç å™¨å±‚ã€‚ num_hidden_layers: 48 norm: RMSNorm åœ¨æ‰€æœ‰è§£ç å™¨å±‚ä¹‹åï¼Œå¯¹æœ€ç»ˆçš„éšè—çŠ¶æ€è¿›è¡Œå½’ä¸€åŒ–ã€‚ hidden_size: 4096, rms_norm_eps: 1e-05 rotary_emb: RotaryEmbedding è®¡ç®—æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰ï¼Œç”¨äºåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­èå…¥ä½ç½®ä¿¡æ¯ã€‚ head_dim: 128, max_position_embeddings: 32768, rope_theta: 50000000, rope_scaling: {\u0026quot;factor\u0026quot;: 6.0, \u0026quot;rope_type\u0026quot;: \u0026quot;dynamic\u0026quot;} \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; InternLM3DecoderLayer self_attn: InternLM3Attention å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºæ•æ‰è¾“å…¥åºåˆ—ä¸­çš„ä¾èµ–å…³ç³»ã€‚ - mlp: InternLM3MLP å‰é¦ˆç¥ç»ç½‘ç»œï¼Œç”¨äºå¯¹æ³¨æ„åŠ›è¾“å‡ºè¿›è¡Œéçº¿æ€§å˜æ¢ã€‚ - input_layernorm: RMSNorm åœ¨è‡ªæ³¨æ„åŠ›æ¨¡å—ä¹‹å‰å¯¹è¾“å…¥è¿›è¡Œå±‚å½’ä¸€åŒ–ã€‚ hidden_size: 4096, rms_norm_eps: 1e-05 post_attention_layernorm: RMSNorm åœ¨è‡ªæ³¨æ„åŠ›æ¨¡å—ä¹‹åã€MLPæ¨¡å—ä¹‹å‰è¿›è¡Œå±‚å½’ä¸€åŒ–ã€‚ hidden_size: 4096, rms_norm_eps: 1e-05 \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; InternLM3Attention qkv_proj: Linear å°†è¾“å…¥çš„éšè—çŠ¶æ€çº¿æ€§å˜æ¢ä¸ºæŸ¥è¯¢ï¼ˆQï¼‰ã€é”®ï¼ˆKï¼‰ã€å€¼ï¼ˆVï¼‰ã€‚é‡‡ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGQAï¼‰ã€‚ hidden_size: 4096, num_attention_heads: 32 (Q), num_key_value_heads: 2 (K, V) o_proj: Linear å°†æ³¨æ„åŠ›æ¨¡å—çš„è¾“å‡ºçº¿æ€§å˜æ¢å›éšè—çŠ¶æ€çš„ç»´åº¦ã€‚ hidden_size: 4096 apply_rotary_pos_emb å°†æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰åº”ç”¨äºQå’ŒKã€‚ - \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; InternLM3MLP gate_up_proj: Linear ä¸¤ä¸ªå¹¶è¡Œçš„çº¿æ€§å±‚ï¼ˆgate å’Œ upï¼‰ï¼Œå°†éšè—çŠ¶æ€æ˜ å°„åˆ°ä¸­é—´ç»´åº¦ã€‚ hidden_size: 4096, intermediate_size: 10240 act_fn: SiluAndMul ä½¿ç”¨ SiLU (Swish) æ¿€æ´»å‡½æ•°å¹¶è¿›è¡Œé€å…ƒç´ ç›¸ä¹˜ã€‚ hidden_act: \u0026quot;silu\u0026quot; down_proj: Linear å°†æ¿€æ´»åçš„ä¸­é—´çŠ¶æ€æ˜ å°„å›éšè—çŠ¶æ€çš„ç»´åº¦ã€‚ intermediate_size: 10240, hidden_size: 4096 InternLM3DecoderLayer è¿ç®—æµç¨‹ å‡è®¾è¾“å…¥ä¸º hidden_states å’Œ residual (åœ¨å‰ä¸€å±‚è®¡ç®—å¾—å‡ºï¼Œç¬¬ä¸€å±‚æ—¶ residual ç­‰äº hidden_states)ã€‚\næ­¥éª¤ æ¨¡å—/æ“ä½œ è¾“å…¥ è¿ç®—æè¿° è¾“å‡º 1. è¾“å…¥å½’ä¸€åŒ– input_layernorm (RMSNorm) hidden_states, residual å¯¹ hidden_states è¿›è¡Œ RMS å½’ä¸€åŒ–ã€‚åŒæ—¶ï¼Œå°† hidden_states åŠ ä¸Šä¸Šä¸€å±‚çš„æ®‹å·® residualï¼Œä¸ºåç»­çš„æ®‹å·®è¿æ¥åšå‡†å¤‡ã€‚ norm_hidden_states, new_residual 2. è‡ªæ³¨æ„åŠ› (Self-Attention) self_attn (InternLM3Attention) norm_hidden_states è¿™æ˜¯æœ€å¤æ‚çš„éƒ¨åˆ†ï¼Œå†…å«å¤šä¸ªå­æ­¥éª¤ï¼š\na. QKV æŠ•å°„: qkv_proj å°† norm_hidden_states çº¿æ€§å˜æ¢ï¼Œç”ŸæˆæŸ¥è¯¢ Qã€é”® K å’Œå€¼ Vã€‚\nb. ä½ç½®ç¼–ç : apply_rotary_pos_emb å°†æ—‹è½¬ä½ç½®ç¼–ç  (RoPE) åº”ç”¨äº Q å’Œ Kï¼Œæ³¨å…¥ä½ç½®ä¿¡æ¯ã€‚\nc. æ³¨æ„åŠ›è®¡ç®—: attn_fwd æ ¹æ® Qã€Kã€V è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼Œå¹¶ç”ŸæˆåŠ æƒå’Œã€‚\nd. è¾“å‡ºæŠ•å°„: o_proj å°†æ³¨æ„åŠ›è®¡ç®—ç»“æœçº¿æ€§å˜æ¢å› hidden_size ç»´åº¦ã€‚ attn_output 3. ç¬¬ä¸€æ¬¡æ®‹å·®è¿æ¥ + attn_output, new_residual å°†æ­¥éª¤ 2 çš„ attn_output ä¸æ­¥éª¤ 1 çš„ new_residual é€å…ƒç´ ç›¸åŠ ã€‚ attn_residual_output 4. æ³¨æ„åŠ›åå½’ä¸€åŒ– post_attention_layernorm (RMSNorm) attn_residual_output å¯¹æ®‹å·®è¿æ¥åçš„ç»“æœè¿›è¡Œç¬¬äºŒæ¬¡ RMS å½’ä¸€åŒ–ã€‚ norm_attn_output 5. MLP (å‰é¦ˆç½‘ç»œ) mlp (InternLM3MLP) norm_attn_output åŒ…å«ä¸‰ä¸ªå­æ­¥éª¤ï¼š\na. Gate \u0026amp; Up æŠ•å°„: gate_up_proj åŒæ—¶å°† norm_attn_output çº¿æ€§å˜æ¢åˆ° intermediate_sizeï¼Œå¾—åˆ° gate å’Œ up ä¸¤ä¸ªå¼ é‡ã€‚\nb. æ¿€æ´»: act_fn (SiLU and Multiply) å¯¹ gate åº”ç”¨ SiLU æ¿€æ´»å‡½æ•°ï¼Œç„¶åä¸ up é€å…ƒç´ ç›¸ä¹˜ã€‚\nc. Down æŠ•å°„: down_proj å°†æ¿€æ´»åçš„ç»“æœä» intermediate_size çº¿æ€§å˜æ¢å› hidden_sizeã€‚ mlp_output 6. ç¬¬äºŒæ¬¡æ®‹å·®è¿æ¥ + mlp_output, norm_attn_output å°†æ­¥éª¤ 5 çš„ mlp_output ä¸æ­¥éª¤ 4 çš„ norm_attn_output é€å…ƒç´ ç›¸åŠ ã€‚ final_hidden_states 7. è¾“å‡º - - è¿™ä¸€å±‚çš„æœ€ç»ˆè¾“å‡º hidden_states å°†ä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œè€Œ final_residual å°†ä½œä¸ºä¸‹ä¸€å±‚çš„æ®‹å·®è¾“å…¥ã€‚ hidden_states (ç”¨äºä¸‹ä¸€å±‚), residual (ç”¨äºä¸‹ä¸€å±‚) graph TD\rsubgraph \u0026#34;InternLM3DecoderLayer å†…éƒ¨æµç¨‹\u0026#34;\rdirection LR\r%% å®šä¹‰è¾“å…¥\rInput[Input: hidden_states\u0026lt;br\u0026gt;Input: residual_in] --\u0026gt; Norm1\r%% ç¬¬ä¸€ä¸ªæ¨¡å—ï¼šæ³¨æ„åŠ›\rsubgraph \u0026#34;æ¨¡å—1: æ³¨æ„åŠ› (Pre-Norm)\u0026#34;\rNorm1(RMSNorm:\u0026lt;br\u0026gt;input_layernorm) --\u0026gt; Attention[Self-Attention]\rInput -- residual --o Add1\rAttention -- attn_output --o Add1\rend\r%% ç¬¬äºŒä¸ªæ¨¡å—ï¼šMLP\rsubgraph \u0026#34;æ¨¡å—2: MLP (Pre-Norm)\u0026#34;\rAdd1(ç¬¬ä¸€æ¬¡\u0026lt;br\u0026gt;æ®‹å·®è¿æ¥ +) --\u0026gt; Norm2(RMSNorm:\u0026lt;br\u0026gt;post_attention_layernorm)\rNorm2 --\u0026gt; MLP[MLP Block]\rAdd1 -- residual --o Add2\rMLP -- mlp_output --o Add2\rend\r%% å®šä¹‰è¾“å‡º\rAdd2(ç¬¬äºŒæ¬¡\u0026lt;br\u0026gt;æ®‹å·®è¿æ¥ +) --\u0026gt; Output[Output: hidden_states\u0026lt;br\u0026gt;Output: residual_out]\rend\r%% æ ·å¼å®šä¹‰\rclassDef default fill:#f9f9f9,stroke:#333,stroke-width:2px;\rclassDef subgraph_style fill:#eef,stroke:#333,stroke-width:2px,color:#333;\rclass Input,Output,Add1,Add2,Norm1,Norm2,Attention,MLP subgraph_style Group Pattern åœ¨ include/tx8be_mlir/OpHelper.h ä¸­æ·»åŠ ä½ è‡ªå·±å®šä¹‰çš„ pattern åˆ°\ntypedef enum { // ... GROUP_NAME = id, } GroupPatternMode; åœ¨ include/tx8be_mlir/Transforms/LayerGroup/GroupPattern.h å®šä¹‰å¥½ä½ è‡ªå·±çš„\nconst std::map\u0026lt;std::vector\u0026lt;TX8BE_OPS\u0026gt;, int\u0026gt; PATTERN_NAME { // ... }; ç„¶åæ·»åŠ è¿› patternConfigMap ä¸­\nconst std::map\u0026lt;int, std::map\u0026lt;std::vector\u0026lt;TX8BE_OPS\u0026gt;\u0026gt; patternConfigMap { {GROUP_NAME, PATTERN_NAME}, } æœ€ååœ¨ lib/Support/OpHelper.cpp çš„ getGroupPatternMode å‡½æ•°é‡Œæ·»åŠ \nelse if (lowerOption.find(\u0026#34;opt_group_name\u0026#34;)) { mode = GROUP_NAME; } opt_group_name ç”± run_codegen_layer å‘½ä»¤çš„ --opt_group=opt_group_name å‚æ•°æŒ‡å®š\n","permalink":"http://localhost:1313/blogs/internlm3-8b-instruct/","summary":"\u003ch1 id=\"model--config\"\u003emodel \u0026amp; config\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/InternLM/lmdeploy/blob/7ca466599f01e5ef93e8951771c62163136e21b2/lmdeploy/pytorch/models/internlm3.py#L304\"\u003eNetwork Definition\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-JSON\" data-lang=\"JSON\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;architectures\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;InternLM3ForCausalLM\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;attention_dropout\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;auto_map\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;AutoConfig\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;configuration_internlm3.InternLM3Config\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;AutoModel\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;modeling_internlm3.InternLM3Model\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;AutoModelForCausalLM\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;modeling_internlm3.InternLM3ForCausalLM\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;bias\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;bos_token_id\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;eos_token_id\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;head_dim\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;hidden_act\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;silu\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;hidden_size\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e4096\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;initializer_range\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.02\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;intermediate_size\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e10240\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;max_position_embeddings\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e32768\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;model_type\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;internlm3\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;num_attention_heads\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;num_hidden_layers\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e48\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;num_key_value_heads\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;pad_token_id\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;qkv_bias\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;rms_norm_eps\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1e-05\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;rope_scaling\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;factor\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e6.0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;rope_type\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;dynamic\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;rope_theta\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e50000000\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;tie_word_embeddings\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;torch_dtype\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;bfloat16\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;transformers_version\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;4.47.1\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;use_cache\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;vocab_size\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e128512\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003cstrong\u003eæ¨¡å— (Module)\u003c/strong\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003cstrong\u003eå­æ¨¡å— (Sub-module)\u003c/strong\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003cstrong\u003eåŠŸèƒ½æè¿°\u003c/strong\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003cstrong\u003eé…ç½®å‚æ•°\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eInternLM3ForCausalLM\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emodel: InternLM3Model\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eæ¨¡å‹ä¸»å¹²ï¼ŒåŒ…å«è¯åµŒå…¥å’Œè§£ç å™¨å±‚ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e-\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003elm_head: Linear\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eçº¿æ€§è¾“å‡ºå±‚ï¼Œå°†éšè—çŠ¶æ€æ˜ å°„åˆ°è¯æ±‡è¡¨å¤§å°ï¼Œç”Ÿæˆé¢„æµ‹ logitsã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_size: 4096\u003c/code\u003e, \u003ccode\u003evocab_size: 128512\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eInternLM3Model\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eembed_tokens: Embedding\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eå°†è¾“å…¥çš„ token IDs è½¬æ¢ä¸ºç¨ å¯†å‘é‡ï¼ˆEmbeddingsï¼‰ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003evocab_size: 128512\u003c/code\u003e, \u003ccode\u003ehidden_size: 4096\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003elayers: ModuleList[InternLM3DecoderLayer]\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eåŒ…å«å¤šä¸ªï¼ˆ48ä¸ªï¼‰Transformerè§£ç å™¨å±‚ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003enum_hidden_layers: 48\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003enorm: RMSNorm\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eåœ¨æ‰€æœ‰è§£ç å™¨å±‚ä¹‹åï¼Œå¯¹æœ€ç»ˆçš„éšè—çŠ¶æ€è¿›è¡Œå½’ä¸€åŒ–ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_size: 4096\u003c/code\u003e, \u003ccode\u003erms_norm_eps: 1e-05\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003erotary_emb: RotaryEmbedding\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eè®¡ç®—æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰ï¼Œç”¨äºåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­èå…¥ä½ç½®ä¿¡æ¯ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehead_dim: 128\u003c/code\u003e, \u003ccode\u003emax_position_embeddings: 32768\u003c/code\u003e, \u003ccode\u003erope_theta: 50000000\u003c/code\u003e, \u003ccode\u003erope_scaling: {\u0026quot;factor\u0026quot;: 6.0, \u0026quot;rope_type\u0026quot;: \u0026quot;dynamic\u0026quot;}\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eInternLM3DecoderLayer\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eself_attn: InternLM3Attention\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eå¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºæ•æ‰è¾“å…¥åºåˆ—ä¸­çš„ä¾èµ–å…³ç³»ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e-\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emlp: InternLM3MLP\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eå‰é¦ˆç¥ç»ç½‘ç»œï¼Œç”¨äºå¯¹æ³¨æ„åŠ›è¾“å‡ºè¿›è¡Œéçº¿æ€§å˜æ¢ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e-\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003einput_layernorm: RMSNorm\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eåœ¨è‡ªæ³¨æ„åŠ›æ¨¡å—ä¹‹å‰å¯¹è¾“å…¥è¿›è¡Œå±‚å½’ä¸€åŒ–ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_size: 4096\u003c/code\u003e, \u003ccode\u003erms_norm_eps: 1e-05\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003epost_attention_layernorm: RMSNorm\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eåœ¨è‡ªæ³¨æ„åŠ›æ¨¡å—ä¹‹åã€MLPæ¨¡å—ä¹‹å‰è¿›è¡Œå±‚å½’ä¸€åŒ–ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_size: 4096\u003c/code\u003e, \u003ccode\u003erms_norm_eps: 1e-05\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eInternLM3Attention\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eqkv_proj: Linear\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eå°†è¾“å…¥çš„éšè—çŠ¶æ€çº¿æ€§å˜æ¢ä¸ºæŸ¥è¯¢ï¼ˆQï¼‰ã€é”®ï¼ˆKï¼‰ã€å€¼ï¼ˆVï¼‰ã€‚é‡‡ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGQAï¼‰ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_size: 4096\u003c/code\u003e, \u003ccode\u003enum_attention_heads: 32\u003c/code\u003e (Q), \u003ccode\u003enum_key_value_heads: 2\u003c/code\u003e (K, V)\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eo_proj: Linear\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eå°†æ³¨æ„åŠ›æ¨¡å—çš„è¾“å‡ºçº¿æ€§å˜æ¢å›éšè—çŠ¶æ€çš„ç»´åº¦ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_size: 4096\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eapply_rotary_pos_emb\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eå°†æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰åº”ç”¨äºQå’ŒKã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e-\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u0026mdash;\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eInternLM3MLP\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003egate_up_proj: Linear\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eä¸¤ä¸ªå¹¶è¡Œçš„çº¿æ€§å±‚ï¼ˆgate å’Œ upï¼‰ï¼Œå°†éšè—çŠ¶æ€æ˜ å°„åˆ°ä¸­é—´ç»´åº¦ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_size: 4096\u003c/code\u003e, \u003ccode\u003eintermediate_size: 10240\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eact_fn: SiluAndMul\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eä½¿ç”¨ SiLU (Swish) æ¿€æ´»å‡½æ•°å¹¶è¿›è¡Œé€å…ƒç´ ç›¸ä¹˜ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehidden_act: \u0026quot;silu\u0026quot;\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003edown_proj: Linear\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eå°†æ¿€æ´»åçš„ä¸­é—´çŠ¶æ€æ˜ å°„å›éšè—çŠ¶æ€çš„ç»´åº¦ã€‚\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003eintermediate_size: 10240\u003c/code\u003e, \u003ccode\u003ehidden_size: 4096\u003c/code\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"internlm3decoderlayer-è¿ç®—æµç¨‹\"\u003eInternLM3DecoderLayer è¿ç®—æµç¨‹\u003c/h3\u003e\n\u003cp\u003eå‡è®¾è¾“å…¥ä¸º \u003ccode\u003ehidden_states\u003c/code\u003e å’Œ \u003ccode\u003eresidual\u003c/code\u003e (åœ¨å‰ä¸€å±‚è®¡ç®—å¾—å‡ºï¼Œç¬¬ä¸€å±‚æ—¶ \u003ccode\u003eresidual\u003c/code\u003e ç­‰äº \u003ccode\u003ehidden_states\u003c/code\u003e)ã€‚\u003c/p\u003e","title":"InternLM3 8B Instruct"},{"content":"Abstract PipeFusion æ˜¯ä¸€ç§åˆ©ç”¨å¤š GPU å¹¶è¡Œæ¥è¿›è¡Œ DiT æ¨¡å‹æ¨ç†çš„æ–¹æ³•ã€‚\nå°†å›¾åƒåˆ†å‰²æˆ patchï¼Œå¹¶å°† Transformer Blocks åˆ†å¸ƒåœ¨å¤šä¸ªè®¾å¤‡ä¸Šã€‚ é€šè¿‡é‡ç”¨ä¸Šä¸€æ­¥ (one-step stale) çš„ç‰¹å¾å›¾ä½œä¸ºå½“å‰æ­¥çš„ä¸Šä¸‹æ–‡ï¼Œæ¶ˆé™¤äº†æµæ°´çº¿ä¸­çš„ç­‰å¾…æ—¶é—´ã€‚ Introduction ç”±äº Attention çš„è®¡ç®—ç‰¹æ€§ï¼Œè®¡ç®—æ—¶é—´ä¸åºåˆ—é•¿åº¦çš„å¹³æ–¹æˆæ­£æ¯”ï¼Œä½¿å¾— DiT æ¨¡å‹ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾å½¢ (é•¿è§†è§‰åºåˆ—) çš„æ¨ç†å»¶è¿Ÿéå¸¸é«˜ã€‚ DistriFusion è§‚å¯Ÿåˆ°åœ¨ç›¸é‚»çš„æ‰©æ•£æ—¶é—´æ­¥ä¸­è¾“å…¥å’Œæ¿€æ´»å­˜åœ¨é«˜åº¦ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬å°†è¿™ç§ç°è±¡ç§°ä¸ºè¾“å…¥æ—¶é—´å†—ä½™ (input temporal redundancy). å®ƒä¿ç•™æ‰€æœ‰å±‚ KV çš„å®Œæ•´å½¢çŠ¶ã€‚å†…å­˜å¼€é”€ä¸ä¼šéšç€è®¡ç®—è®¾å¤‡æ•°é‡çš„å¢åŠ è€Œå‡å°‘ï¼Œåœ¨å¯æ‰©å±•æ€§æ–¹é¢è¡¨ç°ä¸ä½³ã€‚\nå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒDistriFusion åœ¨ 2 ä¸ªè®¾å¤‡ä¸Šéƒ½ä¿å­˜ä¸€ä»½ DiT å‚æ•°ã€‚å®ƒå°†å›¾åƒåˆ†æˆ 2 ä¸ªå°å—ï¼Œå¹¶å¯¹æ¯ä¸€å±‚çš„æ¿€æ´»ä½¿ç”¨å¼‚æ­¥ allgather. PipeFusion å°† DiT å‚æ•°åˆ‡åˆ†åˆ° 2 ä¸ªè®¾å¤‡ä¸Šï¼Œå°†å›¾åƒåˆ†æˆ 4 ä¸ª patch ï¼Œä¸¤ä¸ªè®¾å¤‡ä¹‹é—´é‡‡ç”¨å¼‚æ­¥ P2P é€šä¿¡æ¥ä¼ è¾“æ¿€æ´»ã€‚å®ƒåªåœ¨æ¯ä¸ªè®¾å¤‡ä¸Šä¼ è¾“åˆå§‹å±‚çš„è¾“å…¥æ¿€æ´»å’Œæœ€ç»ˆå±‚çš„è¾“å‡ºæ¿€æ´»\nComparsion Between DistriFusion \u0026amp; PipeFusion\nBackground \u0026amp; Related Works æ‰©æ•£æ¨¡å‹é€šå¸¸ä½¿ç”¨ DNN é¢„æµ‹å™ªå£°ã€‚ç»™å®šæœ‰å™ªå£°çš„å›¾åƒ xtï¼Œæ¨¡å‹ ÏµÎ¸ å°† xtã€å»å™ªæ—¶é—´æ­¥ t å’Œé™„åŠ æ¡ä»¶ c (ä¾‹å¦‚æ–‡æœ¬ã€å›¾åƒ) ä½œä¸ºè¾“å…¥ï¼Œä»¥é¢„æµ‹ xt ä¸­ç›¸åº”çš„å™ªå£°Ïµt.\næ‰©æ•£æ¨¡å‹å…·æœ‰è¾ƒé•¿çš„åºåˆ—é•¿åº¦å’Œè¾ƒå°çš„æ¨¡å‹å¤§å°ï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­é€šä¿¡å¼€é”€ä»ç„¶å¾ˆå¤§ã€‚DistriFusion ä¸º U-Net ä¸ºä¸»å¹²çš„æ‰©æ•£æ¨¡å‹å¼•å…¥äº†ä½ç§» patch å¹¶è¡Œ(displacement patch parallelism)ï¼Œå°†æ¨¡å‹çš„è¾“å…¥åˆ’åˆ†ä¸ºå¤šä¸ª patchï¼Œä¾¿äºæ¿€æ´»çš„å¼‚æ­¥é€šä¿¡å¹¶ä¸”ä½¿å¾—é€šä¿¡ä¸è®¡ç®—é‡å ã€‚ç„¶è€Œï¼Œå½“å°†è¯¥æ–¹æ³•åº”ç”¨äº DiT æ—¶ï¼Œå†…å­˜ç¼“å†²åŒºçš„å¼€é”€å°†å¯¼è‡´å·¨å¤§çš„å†…å­˜å¼€é”€ã€‚\nMethods ä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹ DiT å•æ­¥æ‰©æ•£è¿‡ç¨‹çš„æ¯”è¾ƒå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚\np: ç”Ÿæˆçš„åºåˆ—é•¿åº¦ (å³éšç©ºé—´ä¸‹çš„åƒç´ æ•°é‡). hs: æ¨¡å‹çš„éšè—é€šé“å¤§å°ã€‚ N: è®¾å¤‡æ•°é‡ã€‚ M: å›¾åƒåˆ‡åˆ†çš„ patch æ•°é‡ã€‚ L: Transformer Blocks å±‚æ•°ã€‚ P: æ¨¡å‹æ€»å‚æ•°é‡ã€‚ A: Attention çš„è¿‡ç¨‹ä¸­çš„æ¿€æ´»å¤§å° (Q, K, V, O å¤§å°ä¸€æ ·) åç§°åé¢çš„ * è¡¨ç¤ºé‡‡ç”¨å¼‚æ­¥é€šä¿¡ï¼Œé€šä¿¡å¼€é”€å¯ä»¥é€šè¿‡è®¡ç®—éšè—ã€‚\nattn-KV communication cost param QO Activations KV Activations Tensor Parallel fresh 4O(p Ã— hs)L P/N (2/N) A = (1/N) QO (2/N) A = (1/N) KV DistriFusion* stale 2O(p Ã— hs)L P A 2AL = (KV)L Ring Seq Parallel* fresh NA P A A Ulysses Seq Parallel fresh 4O(p Ã— hs)L P (2/N) A = (1/N) QO (2/N) A = (1/N) KV PipeFusion* stale- 2O(p Ã— hs) P/N (2/M) A = (1/M) QO (2L/N) A = (1/N) (KV)L Sequence Parallelism \u0026amp; Tensor Parallelism é’ˆå¯¹ LLM æå‡ºçš„å¼ é‡å¹¶è¡Œ (tensor parallelism, TP) å’Œåºåˆ—å¹¶è¡Œ (sequence parallelism, SP) å¯ä»¥åº”ç”¨äº DiT æ¨ç†ã€‚å› ä¸ºä»–ä»¬çš„ä¸»å¹²éƒ½æ˜¯ Transformer. åœ¨ TP1 ä¸­ï¼Œæƒé‡çŸ©é˜µæŒ‰åˆ—è¢«åˆ‡åˆ†ä¸º N ä»½ï¼Œè¿™æ ·çŸ©é˜µä¹˜æ³•åæ¿€æ´»å€¼ä¹Ÿè¢«åˆ‡åˆ†æˆ N ä»½ï¼Œä½¿å¾—æ¯ä¸ªè®¾å¤‡çš„å‚æ•°é‡å’Œæ¿€æ´»é‡å‡ä¸ºåŸæ¥çš„ 1/N. åœ¨ attention è®¡ç®—å’Œ FFN å±‚ä¹‹åéƒ½éœ€è¦è¿›è¡Œä¸¤æ¬¡åŒæ­¥ all-reduce æ“ä½œï¼Œå› æ­¤æ¯ä¸€å±‚é€šä¿¡é‡ä¸º 4O(p Ã— hs).\nåœ¨ SP ä¸­ï¼Œå¯ä»¥å°†è¾“å…¥å›¾åƒåˆ†å‰²æˆ patchï¼ŒDiT ä¸­çš„å¤šå¤´æ³¨æ„æ¨¡å—å¯ä»¥é‡‡ç”¨ Ring-Attention2ï¼ŒDeepSpeed-Ulysses3ï¼Œæˆ–è€…ä¸¤è€…çš„ç»„åˆã€‚Ulysses SP å¹¶è¡Œéœ€è¦ 4 æ¬¡ all-to-all æ“ä½œï¼Œå› æ­¤æ¯ä¸€å±‚é€šä¿¡é‡ä¸º 4O(p Ã— hs), å’Œ TP ç›¸åŒã€‚\nTP å’Œ SP å¯ä»¥åœ¨ DiT æ¨ç†ä¸­ä¸€èµ·ä½¿ç”¨ã€‚\nDisplaced Patch Parallelism è¾“å…¥æ—¶é—´å†—ä½™æ„å‘³ç€ç»™å®šå±‚ä¸­æ¿€æ´» patch çš„è®¡ç®—å¹¶ä¸å®Œå…¨å–å†³äºå…¶ä»– patch çš„æœ€æ–°æ¿€æ´»ã€‚åœ¨å‰ä¸€ä¸ªæ‰©æ•£æ­¥éª¤ä¸­åŠ å…¥ç¨å¾®è¿‡æ—¶çš„æ¿€æ´»æ˜¯å¯è¡Œçš„ã€‚è¯¥æ–¹æ³•å°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸º N ä¸ªpatchï¼Œæ¯ä¸ªè®¾å¤‡è®¡ç®—å…¶å„è‡ª patch çš„è¾“å‡ºç»“æœã€‚ å¦‚ä¸‹å›¾æ‰€ç¤º attention æ¨¡å—éœ€è¦å…·æœ‰å®Œæ•´å½¢çŠ¶çš„ KV æ¿€æ´»ã€‚å®ƒé‡‡ç”¨å¼‚æ­¥ all-gather æ”¶é›†ä¸Šä¸€æ­¥æ‰©æ•£æ­¥éª¤çš„ KV æ¿€æ´»ï¼Œå¹¶ç”¨å…¶è¿›è¡Œå½“å‰æ­¥çš„ attention è®¡ç®—ã€‚\nDistriFusion4 å¯ä»¥çœ‹ä½œæ˜¯å¼‚æ­¥ SQ çš„ä¸€ç§å½¢å¼ã€‚å®ƒé€šè¿‡æ­£å‘è®¡ç®—æ‰©æ•£æ­¥éª¤æ¥éšè— KV é€šä¿¡ï¼Œä½†ä»£ä»·æ˜¯æ¶ˆè€—æ›´å¤šå†…å­˜ã€‚DistriFusion åˆ©ç”¨ N-1/N çš„ T+1 æ­¥çš„ KV æ¿€æ´»å’Œ T æ­¥çš„ 1/N çš„å±€éƒ¨ KV æ¿€æ´»ç›¸ç»“åˆã€‚ä¸ Ring-Attention ç›¸æ¯”ï¼ŒDistriFusion å¯ä»¥æ›´æœ‰æ•ˆåœ°éšè—é€šä¿¡å¼€é”€ï¼Œå› ä¸ºå®ƒå…è®¸ KV é€šä¿¡ä¸æ‰©æ•£æ­¥éª¤çš„æ•´ä¸ªå‰å‘è®¡ç®—é‡å ï¼Œè€Œ Ring-Attention åªå…è®¸é€šä¿¡åœ¨æ³¨æ„æ¨¡å—å†…éƒ¨é‡å ã€‚\nDistriFusion vs. Ring-Attention SQ for an Attention Module\nåœ¨ Ring-Attentionä¸­ï¼Œå…¶é€šä¿¡ç¼“å†²åŒº c Ã— hs å¯ç”±å›¾ä¸­å—å¤§å° c æ§åˆ¶ï¼Œå…¶å€¼å°äº p/N. DistriFusionè¦æ±‚æ¯ä¸ªè®¡ç®—è®¾å¤‡å§‹ç»ˆä¿æŒ KV çš„å®Œæ•´å½¢çŠ¶çš„é€šä¿¡ç¼“å†²åŒºï¼Œå› æ­¤é€šä¿¡å¼€é”€æ€»å…±æ˜¯ AL.\nDisplaced Patch Pipeline Parallelism PipeFusion ç›¸æ¯”äº DistriFusion æœ‰ç€æ›´é«˜çš„å†…å­˜æ•ˆç‡å’Œæ›´ä½çš„é€šä¿¡æˆæœ¬ã€‚å®ƒå°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸º M ä¸ªä¸é‡å çš„ patchï¼ŒDiT Blocks è¢«åˆ’åˆ†ä¸º N ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µæŒ‰é¡ºåºåˆ†é…ç»™ N ä¸ªè®¡ç®—è®¾å¤‡ã€‚æ¯ä¸ªè®¾å¤‡åœ¨å…¶è¢«åˆ†é…çš„é˜¶æ®µä»¥æµæ°´çº¿æ–¹å¼å¤„ç†ä¸€ä¸ª patch çš„è®¡ç®—ä»»åŠ¡ã€‚\nDiT æ¨¡å‹ä¸­å› æœ‰è®¸å¤šç›¸åŒçš„ transformer blockï¼Œå¾ˆå®¹æ˜“å°†å»å™ªç½‘ç»œçš„å·¥ä½œè´Ÿè½½å‡åŒ€åœ°åˆ’åˆ†ä¸º N ä¸ªéƒ¨åˆ†ã€‚ç„¶è€Œï¼ŒU-Net æ‰©æ•£æ¨¡å‹æ²¡æœ‰è¿™ç§é‡å¤ç»“æ„ã€‚\nä¸€ä¸ª M=4, N=4 çš„ PipeFusion ä¾‹å­å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåˆ©ç”¨è¾“å…¥æ—¶é—´å†—ä½™ï¼Œè®¾å¤‡ä¸éœ€è¦ç­‰å¾…æ¥æ”¶åˆ°å½“å‰æ­¥éª¤çš„å®Œæ•´å½¢çŠ¶æ¿€æ´»ï¼Œåˆ©ç”¨ä¸Šä¸€æ­¥çš„æ¿€æ´»å°±å¯ä»¥å¼€å§‹è‡ªå·±æ‰€å¤„é˜¶æ®µçš„è®¡ç®—ã€‚è€ƒè™‘æµæ°´çº¿æ°”æ³¡ï¼Œæµæ°´çº¿çš„æœ‰æ•ˆè®¡ç®—æ¯”ä¸º MS/MS+Nâˆ’1ï¼Œå…¶ä¸­ S ä¸ºæ‰©æ•£æ­¥é•¿æ•°ã€‚\nThe Workflow of Displaced Patch Pipeline Parallelism\nPipeFusion åœ¨è®¡ç®—è®¾å¤‡ä¹‹é—´ä»…ä¼ è¾“å±äºä¸€ä¸ªé˜¶æ®µçš„ (è¿ç»­ transformerl blocks) çš„è¾“å…¥å’Œè¾“å‡ºçš„æ¿€æ´»ï¼Œå› æ­¤é€šä¿¡å¼€é”€ä¸º 2O(p Ã— hs). PipeFusion é€šè¿‡å¼‚æ­¥ P2P ä¼ è¾“å‰ä¸€æ­¥ Patch æ•°æ®å’Œæ¥æ”¶åä¸€æ­¥éª¤ Patch æ•°æ®æ¥ä¸å½“å‰ Patch è®¡ç®—é‡å ï¼Œä»è€Œå°†é€šä¿¡éšè—åœ¨è®¡ç®—ä¸­ã€‚PipeFusion ä¸­çš„æ¯ä¸ªè®¾å¤‡ä»…å­˜å‚¨ä¸å…¶ç‰¹å®šé˜¶æ®µç›¸å…³çš„ 1/N ä»½å‚æ•°ã€‚ç”±äºä½¿ç”¨é™ˆæ—§ KV è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ï¼Œè¦æ±‚æ¯ä¸ªè®¾å¤‡ä¿æŒå…¶é˜¶æ®µå¯¹åº”çš„ L/N å±‚çš„å®Œæ•´ KV.\nPipeDiffusion ç†è®ºä¸Šä¼˜äº DistriFusionï¼Œå› ä¸ºå®ƒåˆ©ç”¨äº†æ›´å¤šçš„æ–°æ¿€æ´»ã€‚å¦‚å›¾æ‰€ç¤ºï¼Œåœ¨å•ä¸ªæ‰©æ•£æ­¥éª¤å†…ï¼ŒPipeDiffusion ä¸­æœ€æ–°æ¿€æ´»çš„å æ¯”éšç€æµæ°´çº¿æ‰§è¡Œè€Œå¢åŠ ã€‚è€Œ DistriFusion ä¸­æœ€æ–°æ¿€æ´»çš„å æ¯”ä¸€ç›´éƒ½æ˜¯ 1/N.\nå°½ç®¡ DiT æ²¡æœ‰é‡‡ç”¨ GroupNorm å±‚ï¼Œä½†åœ¨ PipeFusion ä¸­ï¼ŒU-Net ä¸­ DistriFusion å¯¹ GroupNorm å±‚çš„ç²¾åº¦ä¿æŒè®¾è®¡ï¼Œç‰¹åˆ«æ˜¯æ ¡æ­£å¼‚æ­¥ç¾¤å½’ä¸€åŒ– (Corrected Asynchronous GroupNorm)ï¼Œå¯ä»¥æ— ç¼åœ°åº”ç”¨äº PipeFusion.\nThe Fresh Part of Activations\nç”±äºä½¿ç”¨è¾“å…¥æ—¶é—´å†—ä½™éœ€è¦ä¸€ä¸ªé¢„çƒ­æœŸï¼ŒDistriFusion ä½¿ç”¨äº†å‡ æ¬¡åŒæ­¥ path å¹¶è¡Œçš„é¢„çƒ­æ­¥éª¤ä½œä¸ºé¢„å¤‡é˜¶æ®µã€‚ä¸ºäº†ä¼˜åŒ–é¢„çƒ­å¼€é”€ï¼Œå¯ä»¥å°†é¢„çƒ­æ­¥éª¤ä¸å…¶ä½™æ­¥éª¤åˆ†å¼€ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ä¸åŒçš„è®¡ç®—èµ„æºã€‚\nExperiments æˆ‘ä»¬åœ¨ Pixart-Î± ä¸Šè¿›è¡Œå®éªŒ (0.6B)ï¼Œå®ƒæ”¯æŒåˆ†è¾¨ç‡ 1024px çš„é«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆï¼Œé‡‡ç”¨æ ‡å‡†çš„ DiTï¼Œå¹¶ç»“åˆäº¤å‰æ³¨æ„æ¨¡å—æ³¨å…¥æ–‡æœ¬æ¡ä»¶ã€‚ä½¿ç”¨äº†ä¸‰ä¸ª GPU é›†ç¾¤ï¼ŒåŒ…æ‹¬ 4xGPU A100 80GB (PCIe) é›†ç¾¤ï¼Œ8xGPU A100 80GB (NVLink) é›†ç¾¤å’Œ 8xGPU L20 40GB (PCIe) é›†ç¾¤ã€‚æµ‹è¯•çš„ GPU P2P å¸¦å®½åˆ†åˆ«ä¸º23 GB/sã€268 GB/s å’Œ 26 GB/s. åˆ‡åˆ†çš„ patch æ•°ç›® M ä» 2,4,8,16,32 ä¸­æœç´¢æ¥ç¡®å®šæœ€ä½³å»¶è¿Ÿæ€§èƒ½ã€‚\nTP: å‚è€ƒ Megatron-LMå® ç°äº†ä¸€ä¸ª TP DiT. SP: é‡‡ç”¨äº†ä¸¤ç§ä¸åŒçš„åºåˆ—å¹¶è¡Œï¼ŒDeepSpeed-Ulysses å’Œ Ring-Attention. DistriFusion: å°† U-Net æ‰©æ•£æ¨¡å‹ä¸­çš„å®˜æ–¹ DistriFusion åº”ç”¨äºDiT. Original:åœ¨å•ä¸ª GPU ä¸Šçš„ä¸²è¡Œå®ç°ã€‚ Note\nåœ¨ VAE ä¸­ç”±äºå·ç§¯ç®—å­çš„ä¸´æ—¶å†…å­˜ä½¿ç”¨ä¼šäº§ç”Ÿå†…å­˜å³°å€¼ï¼Œå› æ­¤ VAE æ¯” DiT å±‚éœ€è¦æ›´å¤šçš„å†…å­˜ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†å·ç§¯å±‚çš„è¾“å…¥å›¾åƒåˆ†æˆå‡ ä¸ªå—ï¼Œå°†å•ä¸ªå·ç§¯æ“ä½œè½¬æ¢ä¸ºæŒ‰é¡ºåºæ‰§è¡Œçš„å¤šä¸ªæ“ä½œçš„åºåˆ—ã€‚\nQuality Results ä½¿ç”¨ 20 æ­¥ DPM-Solverï¼Œé¢„çƒ­æ­¥éª¤ä¸º 4 æ­¥ã€‚å½“ patch æ•°ä¸º 1 æ—¶ï¼ŒPipeFusion çš„ç²¾åº¦ä¸ DistriFusion ç›¸å½“ã€‚å½“ patch æ•°è¶…è¿‡ 1 æ—¶ï¼Œå…¶ç²¾åº¦åœ¨ç†è®ºä¸Šæ¯” PipeFusion æ›´æ¥è¿‘åŸå§‹ç‰ˆæœ¬ã€‚PipeFusion åœ¨ FID æ–¹é¢ç•¥ä¼˜äº DistriFusion.\nLatency and Memory 20 æ­¥ DPM-Solverï¼Œé¢„çƒ­æ­¥éª¤ä¸º 1 æ­¥ã€‚\n4xA100 (PCIe)é›†ç¾¤ä¸Š: å¯¹äº 8192px çš„æƒ…å†µï¼Œåœ¨ï¼ŒDistriFusion å’Œ SQ éƒ½ä¼šé‡åˆ°å†…å­˜ä¸è¶³ (OOM) é—®é¢˜ã€‚ 8xL20 (PCIe)é›†ç¾¤ä¸Š: ç”Ÿæˆ 4096px åˆ†è¾¨ç‡çš„å›¾åƒæ—¶ï¼ŒDistriFusion å’Œ SQ éƒ½ä¼šé‡åˆ° OOM é—®é¢˜ã€‚ 8xA100 (NVLink) é›†ç¾¤ä¸Š: ä½¿ç”¨å¼‚æ­¥é€šä¿¡çš„ SQ (Ulysses) çš„å»¶è¿Ÿä¸å¼‚æ­¥ DistriFusion éå¸¸ç›¸ä¼¼ï¼Œå¹¶ä¸”ä¼˜äº Ring ç‰ˆæœ¬ã€‚æ­¤å¤–ï¼ŒPixArt-Î± åœ¨è·¨ 8 ä¸ªè®¾å¤‡éƒ¨ç½²æ—¶é¢ä¸´é™åˆ¶ï¼Œå› ä¸º28ä¸ªDiTå±‚ä¸èƒ½åœ¨å‡åˆ†ï¼Œä»è€Œå¯¼è‡´é¢å¤–çš„å¼€é”€ã€‚ 4x A100 (PCIe) é›†ç¾¤ Latency PipeFusion Tensor Parallel DistriFusion Seq Parallel (Ulysses) Seq Parallel (Ring) Single-GPU 1024px 1.00x 2.41x 2.69x 2.01x 3.04x 2.4x 2048px 1.00x 3.02x 1.79x 1.48x 2.06x 3.02x 4096px 1.02x 1.77x 1.16x 1.00x 1.12x 3.05x 8192px 1.00x 1.10x OOM OOM OOM 3.1x Overall Latency on a 4Ã—A100-80GB (PCIe)\nå†…å­˜æ•ˆç‡æ–¹é¢ï¼ŒPipeFusionä¼˜äºé™¤äº†å¼ é‡å¹¶è¡Œçš„å…¶ä»–æ–¹æ³•ã€‚è™½ç„¶å¼ é‡å¹¶è¡Œçš„å†…å­˜å ç”¨æœ€ä½ï¼Œä½†ä¸å…¶ä»–å¹¶è¡ŒåŒ–ç­–ç•¥ç›¸æ¯”ï¼Œç”±äºé€šä¿¡é‡å¤§ä¼šå¯¼è‡´æ›´é«˜çš„å»¶è¿Ÿã€‚\nMax Memory PipeFusion (Baseline) Original Tensor Parallel DistriFusion Seq Parallel (Ulysses) 1024px 1.00x 1.04x 0.98x 1.21x 1.21x 2048px 1.00x 0.98x 0.90x 1.54x 1.33x 4096px 1.00x 1.18x 0.69x 2.35x 1.63x 8192px 1.00x 1.41x 0.71x 2.34x OOM Overall GPU Memory on a 4Ã—A100-80GB (PCIe)\n8x L20 (PCIe) é›†ç¾¤ Latency PipeFusion Tensor Parallel DistriFusion Seq Parallel (Ulysses) Seq Parallel (Ring) Single-GPU 1024px 1.00x 2.46x 3.26x 1.48x 4.42x 2.46x 2048px 0.99x 2.26x 1.00x 1.58x 1.09x 4.16x 4096px 1.00x 1.16x OOM 1.31x 4.40x 4.30x Overall latency on a 8Ã—L20 (PCIe)\n8x A100 (NVLink) é›†ç¾¤ Latency PipeFusion Tensor Parallel DistriFusion Seq Parallel (Ulysses) Seq Parallel (Ring) Single-GPU 1024px 1.26x 1.59x 1.00x 1.79x 3.38x 2.15x 2048px 1.64x 2.85x 1.00x 1.00x 1.43x 3.99x 4096px 1.08x 1.56x 1.00x 1.18x 1.93x 7.28x 8192px 1.35x 1.00x OOM OOM OOM 5.98x Overall latency on a 8Ã—A100 (NVLink)\nScalability PipeFusion åœ¨ NVLink å’Œ PCIe ä¸Šçš„æ—¶å»¶ç›¸ä¼¼ï¼ŒPCIe ç”šè‡³åœ¨è¡¨ç°å‡ºäº†è½»å¾®çš„ä¼˜åŠ¿ã€‚åœ¨ PCIe é›†ç¾¤ä¸Šï¼Œå¯¹äºç›¸åŒçš„ä»»åŠ¡ï¼ŒPipeFusion æ€»æ˜¯æ¯” DistriFusion å¿«ã€‚è¯´æ˜ PipeFusion çš„é€šä¿¡å¸¦å®½è¦æ±‚éå¸¸ä½ï¼Œå› æ­¤ä¸éœ€è¦ä½¿ç”¨ NVLink ç­‰é«˜å¸¦å®½ç½‘ç»œã€‚\nScalability of PipeFusion and DistriFusion on A100 PCIe vs. NVLink cluster\nAblation Studies éšç€ patch æ•°ç›® M çš„å¢åŠ ï¼Œå†…å­˜æ¶ˆè€—å‡å°‘ï¼Œå¹¶ä¸”å¯¹é€šä¿¡æ²¡æœ‰å½±å“ã€‚ä½†åœ¨å®è·µä¸­ï¼ŒM ä¸åº”è¯¥è®¾ç½®å¾—å¤ªé«˜ã€‚ç”Ÿæˆ 1024px å’Œ 2048px å›¾åƒæ—¶ï¼Œå½“ M è¶…è¿‡ä¸€å®šé˜ˆå€¼æ—¶ï¼Œæ•´ä½“å»¶è¿Ÿå¢åŠ ã€‚ç„¶è€Œï¼Œè¿™ç§ç°è±¡å¾ˆå°‘å‡ºç°åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒ 4KÃ—4K çš„æƒ…å†µä¸‹ã€‚è¿™æ˜¯å› ä¸ºè¿‡äºç»†ç²’åº¦çš„è®¡ç®—åˆ†åŒºä¼šå¯¼è‡´ GPU çš„ç†è®ºååé‡ä¸‹é™ã€‚\nLatency of PipeFusion with various patch numbers M\nç»å¤§å¤šæ•°å·®å¼‚å¯ä»¥å¿½ç•¥ä¸è®¡æˆ–æ¥è¿‘é›¶ï¼Œå³æ‰©æ•£è¿‡ç¨‹ä¸­è¿ç»­æ­¥éª¤è¾“å…¥ä¹‹é—´çš„é«˜åº¦ç›¸ä¼¼æ€§ã€‚\næœ‰ä¸€äº›æ–¹æ³•å¯ä»¥å‡è½»ç”±é¢„çƒ­æ­¥éª¤å¼•èµ·çš„æ€§èƒ½æŸå¤±: å¢åŠ é‡‡æ ·æ­¥éª¤ï¼Œåœ¨å•ç‹¬çš„è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œåˆ©ç”¨åºåˆ—æˆ–å¼ é‡å¹¶è¡Œã€‚\nSummary æˆ‘ä»¬çš„æ–¹æ³•æ˜¯å…ˆç”¨ Pipeline Parallel å°†æ¨¡å‹çš„ transformer block åˆ‡åˆ†æˆå¤šä¸ª stage, å†ç”¨ Tensor Parallel (Megatron: åˆ‡åˆ†å‰ä¸€ä¸ªæƒé‡çš„åˆ—ï¼Œåä¸€ä¸ªæƒé‡çš„è¡Œ, Two-dimenson: åˆ‡åˆ†è¾“å…¥çš„åˆ—ï¼Œåˆ‡åˆ†æƒé‡çš„è¡Œå’Œåˆ—)ï¼Œæ¯ä¸€å±‚çš„ KV ç»“æœéœ€è¦è¿›è¡Œ all-reduce æˆ–è€… all-gather + reduce-scatter. ä¸åŒ stage ä¹‹é—´æ˜¯ P2P é€šä¿¡.\nPipeFusion è¡Œä¸ºæ›´åƒå•çº¯çš„ Pipeline Parallelï¼Œåˆ©ç”¨ä¸Šä¸€æ­¥çš„ KV å®Œæˆå½“å‰æ­¥çš„è®¡ç®—ï¼ŒP2P é€šä¿¡çš„æ˜¯è‡ªå·±æ‰€å¤„ stage çš„æ¿€æ´» (ä¸åˆ‡åˆ†çš„ patch æ•°æˆåæ¯”)ï¼Œä¸ transformer block çš„å±‚æ•°æ— å…³ã€‚\nxDiTçš„åˆ†æä¸­æåˆ°è¿‡å°†å¹¶è¡Œç»´åº¦ä»å°åˆ°å¤§å¯ä»¥åˆ†ä¸º TP-SP-PP-CFG-DPï¼Œå…¶ä¸­ CFG å’Œ DP å®é™…ä¸Šæ˜¯å¯¹ æ•°æ®çš„ batchsize ç»´åº¦è¿›è¡Œåˆ‡åˆ†ï¼ŒPP çš„å¤§å°å–å†³äºåˆ’åˆ†çš„ patch æ•°ï¼Œæ¯ä¸ª stage çš„ transformer block è®¡ç®—çš„æ—¶å€™å¯ä»¥è¿›ä¸€æ­¥å†è¿›è¡Œ SP å’Œ TP.\nReferences https://darkenstar.github.io/blogs/MegatronLM/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://darkenstar.github.io/blogs/ringattention/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://darkenstar.github.io/blogs/deepspeedulysses/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://darkenstar.github.io/blogs/distrifusion/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blogs/pipefusion/","summary":"Paper Reading of PipeFusion","title":"PipeFusion"},{"content":"Introduction Diffusion LLMs è¢«è§†ä¸ºä¸‹ä¸€ä»£æ–‡æœ¬ç”ŸæˆæŠ€æœ¯çš„æœ‰åŠ›ç«äº‰è€…ï¼Œå…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºç†è®ºä¸Šå¯ä»¥å¹¶è¡Œç”Ÿæˆå¤šä¸ª tokenï¼Œä»è€Œæœ‰æœ›å®ç°æ¯”è‡ªå›å½’æ¨¡å‹å¿«å‡ ä¸ªæ•°é‡çº§çš„æ¨ç†é€Ÿåº¦ã€‚è°·æ­Œçš„ Gemini Diffusion å’Œ Inception Labs çš„Mercuryç­‰æ¨¡å‹å·²ç»å±•ç¤ºäº†å…¶æƒŠäººçš„æ½œåŠ›ï¼Œå®£ç§°èƒ½è¾¾åˆ°æ¯ç§’ä¸Šåƒ token çš„ç”Ÿæˆé€Ÿåº¦ã€‚\nå½“å‰å¼€æºçš„æ‰©æ•£LLM (LLaDAã€Dream) åœ¨å®é™…åº”ç”¨ä¸­çš„é€Ÿåº¦è¿œè¿œè¾¾ä¸åˆ°é¢„æœŸï¼Œç”šè‡³æ¯”ä¼˜åŒ–è‰¯å¥½çš„è‡ªå›å½’æ¨¡å‹è¿˜è¦æ…¢ã€‚è¿™ç¯‡è®ºæ–‡çš„å·¥ä½œï¼Œå°±æ˜¯è¦æ‹†æ‰é˜»ç¢æ‰©æ•£ LLM èµ·é£çš„ä¸¤åº§å¤§å±±ã€‚\næ— æ³•ä½¿ç”¨ KV Cache æ‰©æ•£LLMçš„æ³¨æ„åŠ›æœºåˆ¶æ˜¯åŒå‘çš„ï¼Œå³ä¸€ä¸ª token çš„ç”Ÿæˆä¸ä»…ä¾èµ–äºå®ƒå‰é¢çš„å†…å®¹ï¼Œä¹Ÿä¾èµ–äºå®ƒåé¢çš„å†…å®¹ (å°½ç®¡åé¢å¯èƒ½æ˜¯æœªçŸ¥çš„ MASK token ) ã€‚è¿™ç§ç‰¹æ€§ä½¿å¾—è¿‡å»çš„ä¿¡æ¯å’Œæœªæ¥çš„ä¿¡æ¯ç›¸äº’çº ç¼ ï¼Œæ— æ³•åƒè‡ªå›å½’æ¨¡å‹é‚£æ ·ç®€å•åœ°ç¼“å­˜å’Œå¤ç”¨è¿‡å»çš„ä¿¡æ¯ã€‚å¯¼è‡´æ‰©æ•£LLMåœ¨æ¯ä¸€æ­¥æ¨ç†ä¸­éƒ½éœ€è¦è¿›è¡Œå¤§é‡çš„é‡å¤è®¡ç®—ï¼Œä¸¥é‡æ‹–æ…¢äº†é€Ÿåº¦ã€‚\nFast-dLLM çš„ç¬¬ä¸€ä¸ªæ ¸å¿ƒè´¡çŒ®ï¼Œå°±æ˜¯æå‡ºäº†ä¸€ç§åˆ†å—è¿‘ä¼¼ (block-wise approximate) KV Cache æœºåˆ¶ã€‚\nWhile the bidirectional nature of attention in Diffusion LLMs precludes a fully equivalent KV Cache, our approximation closely resembles an ideal cache in practice.\nå®ƒå°†å¾…ç”Ÿæˆçš„æ–‡æœ¬åºåˆ—åˆ†æˆè‹¥å¹²ä¸ªå—. åœ¨ç”ŸæˆæŸä¸€ä¸ªå— (æ¯”å¦‚Block 1) æ—¶ï¼Œå®ƒä¼šæå‰è®¡ç®—å¹¶ç¼“å­˜å…¶ä»–æ‰€æœ‰å— (æ¯”å¦‚ Prompt å’Œ Block 0) çš„ KV. åœ¨è¿™ä¸ªå—çš„å†…éƒ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œè¿™äº›ç¼“å­˜è¢«åå¤åˆ©ç”¨ã€‚å½“è¿™ä¸ªå—ç”Ÿæˆå®Œæ¯•åï¼Œå†æ•´ä½“æ›´æ–°ä¸€æ¬¡æ‰€æœ‰å—çš„KVç¼“å­˜ ã€‚\nè¿™ä¸ªæ–¹æ³•çš„è¿‘ä¼¼åœ¨äºï¼Œåœ¨ä¸€ä¸ªå—çš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç¼“å­˜æ˜¯å›ºå®šçš„ï¼Œè€Œå®é™…ä¸Šéšç€å—å†… token çš„ä¸æ–­å»å™ªå’Œæ¸…æ™°åŒ–ï¼Œè¿™äº›ç¼“å­˜ç†è®ºä¸Šä¹Ÿåº”è¯¥éšä¹‹å¾®è°ƒã€‚ä½†è®ºæ–‡é€šè¿‡å¯è§†åŒ–å®éªŒ (å›¾3) æœ‰åŠ›åœ°è¯æ˜ï¼Œåœ¨ç›¸é‚»çš„æ¨ç†æ­¥éª¤ä¸­ï¼ŒKV æ¿€æ´»å€¼çš„ ä½™å¼¦ç›¸ä¼¼åº¦éå¸¸é«˜ï¼Œå‡ ä¹æ¥è¿‘äº1. è¿™è¯´æ˜ä½¿ç”¨å›ºå®šçš„è¿‘ä¼¼ç¼“å­˜å¸¦æ¥çš„è¯¯å·®å¾®ä¹å…¶å¾®ï¼Œå®Œå…¨å¯ä»¥ç”¨æå°çš„ç²¾åº¦æŸå¤±æ¢å–å·¨å¤§çš„é€Ÿåº¦æå‡ã€‚\nè®ºæ–‡è¿˜è¿›ä¸€æ­¥æå‡ºäº†åŒç¼“å­˜ (DualCache) ç‰ˆæœ¬ï¼Œä¸ä»…ç¼“å­˜äº†å‰é¢çš„â€œå‰ç¼€â€ (prefix) ï¼Œè¿˜ç¼“å­˜äº†åé¢çš„â€œåç¼€â€ (suffixï¼Œé€šå¸¸æ˜¯ MASK token ) ï¼Œä»è€Œè¿›ä¸€æ­¥å‹æ¦¨äº†è®¡ç®—ä¼˜åŒ–çš„ç©ºé—´ï¼Œå®ç°äº†æ›´å¿«çš„é€Ÿåº¦ã€‚\nå¹¶è¡Œè§£ç å¸¦æ¥çš„è´¨é‡ä¸‹é™ æ‰©æ•£LLMçš„å¦ä¸€å¤§ç†è®ºä¼˜åŠ¿æ˜¯ å¹¶è¡Œè§£ç  (Parallel Decoding)ï¼Œå³ä¸€æ¬¡æ€§é¢„æµ‹å’Œç”Ÿæˆå¤šä¸ª token ã€‚ç„¶è€Œï¼Œå®è·µå†æ¬¡è¯æ˜ï¼Œå½“å¹¶è¡Œè§£ç çš„ token æ•°é‡å¢å¤šæ—¶ï¼Œç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ä¼šæ€¥å‰§ä¸‹é™ ã€‚\nè®ºæ–‡æ·±åˆ»åœ°å‰–æäº†å…¶æ ¹æºï¼šæ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ (conditional independence assumption) çš„ç ´å ã€‚åœ¨å¹¶è¡Œè§£ç æ—¶ï¼Œæ¨¡å‹æ˜¯ç‹¬ç«‹åœ°ä¸ºæ¯ä¸ªå¾…ç”Ÿæˆçš„ MASK ä½ç½®é¢„æµ‹ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åä»ä¸­é‡‡æ ·ã€‚ä½†å®é™…ä¸Šï¼Œä¸€å¥è¯ä¸­çš„ token ä¹‹é—´å­˜åœ¨ç€å¼ºçƒˆçš„ä¾èµ–å…³ç³»ã€‚è®ºæ–‡ä¸¾äº†ä¸€ä¸ªä¾‹å­:\nConsider an example from [30]: The list of poker hands that consist of two English words are: The subsequent two words could be, for instance, \u0026ldquo;high card,\u0026rdquo; \u0026ldquo;two pair,\u0026rdquo; \u0026ldquo;full house,\u0026rdquo; or \u0026ldquo;straight flush.\u0026rdquo; [\u0026hellip;] However, the multi-token prediction procedure in MDMs first generates a probability distribution for each token and then samples from these distributions independently. This independent sampling can lead to undesirable combinations, such as \u0026ldquo;high house.\u0026rdquo;\næ¨¡å‹å¯èƒ½ä¼šç‹¬ç«‹åœ°é¢„æµ‹å‡º \u0026ldquo;high\u0026rdquo; å’Œ \u0026ldquo;house\u0026quot;è¿™ä¸¤ä¸ªè¯ï¼Œä½†æŠŠå®ƒä»¬ç»„åˆåœ¨ä¸€èµ·å°±æˆäº†æ¯«æ— æ„ä¹‰çš„ high house. è¿™æ˜¯å› ä¸ºæ¨¡å‹åœ¨å¹¶è¡Œé¢„æµ‹æ—¶å¿½ç•¥äº† token é—´çš„è”åˆæ¦‚ç‡ï¼Œè€Œé”™è¯¯åœ°ç›´æ¥ä½¿ç”¨äº†è¾¹ç¼˜æ¦‚ç‡çš„ä¹˜ç§¯ã€‚\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒFast-dLLMæå‡ºäº†ç¬¬äºŒä¸ªæ ¸å¿ƒè´¡çŒ®ï¼šç½®ä¿¡åº¦æ„ŸçŸ¥å¹¶è¡Œè§£ç  (Confidence-Aware Parallel Decoding) ç­–ç•¥ ã€‚è¿™ä¸ªæƒ³æ³•éå¸¸ç›´è§‚ä¸”æœ‰æ•ˆï¼šæˆ‘ä»¬åªå¯¹é‚£äº›æ¨¡å‹éå¸¸æœ‰æŠŠæ¡çš„ token è¿›è¡Œå¹¶è¡Œè§£ç ã€‚\nå…·ä½“æ¥è¯´ï¼Œåœ¨æ¯ä¸€æ­¥è§£ç æ—¶ï¼Œæ¨¡å‹ä¼šä¸ºæ¯ä¸ªå¾…ç”Ÿæˆçš„ MASK ä½ç½®è®¡ç®—ä¸€ä¸ª ç½®ä¿¡åº¦åˆ†æ•° (æ¯”å¦‚softmaxæ¦‚ç‡çš„æœ€å¤§å€¼). ç„¶åï¼Œè®¾å®šä¸€ä¸ªå…¨å±€çš„ç½®ä¿¡åº¦é˜ˆå€¼ Ï„ï¼Œåªæœ‰é‚£äº›ç½®ä¿¡åº¦è¶…è¿‡è¿™ä¸ªé˜ˆå€¼çš„ token æ‰ä¼šè¢«æ­å¼€ï¼Œè€Œç½®ä¿¡åº¦ä¸è¶³çš„ token åˆ™ç»§ç»­ä¿æŒ MASK çŠ¶æ€ï¼Œç•™åˆ°ä¸‹ä¸€æ­¥å†åšå†³ç­–ã€‚ä¸ºäº†é¿å…æ— é™å¾ªç¯ï¼Œå¦‚æœæ²¡æœ‰ä»»ä½• token çš„ç½®ä¿¡åº¦è¾¾æ ‡ï¼Œæ¨¡å‹ä¼šå¼ºåˆ¶è§£ç ç½®ä¿¡åº¦æœ€é«˜çš„é‚£ä¸€ä¸ªã€‚\nè¿™ä¸ªç­–ç•¥çš„ç²¾å¦™ä¹‹å¤„åœ¨äºï¼Œå®ƒåœ¨ç†è®ºä¸Šæ˜¯ç«™å¾—ä½è„šçš„ã€‚è®ºæ–‡é€šè¿‡å®šç†ä¸€ä»æ•°å­¦ä¸Šè¯æ˜äº†ï¼šå½“æ¨¡å‹å¯¹ä¸€ç»„ token çš„é¢„æµ‹ç½®ä¿¡åº¦è¶³å¤Ÿé«˜æ—¶ (å³ p\u0026gt;1âˆ’Ïµï¼Œä¸” Ïµ è¶³å¤Ÿå°)ï¼ŒåŸºäºç‹¬ç«‹è¾¹ç¼˜æ¦‚ç‡çš„â€œè´ªå¿ƒå¹¶è¡Œè§£ç â€ä¸åŸºäºçœŸå®è”åˆæ¦‚ç‡çš„â€œè´ªå¿ƒä¸²è¡Œè§£ç â€ä¼šå¾—åˆ°å®Œå…¨ç›¸åŒçš„ç»“æœã€‚\nEffectiveness of Components of Fast-dLLM across Different Approaches\nFast-dLLM çš„åˆ›æ–°æ€§ä½“ç°åœ¨å®ƒæ˜¯ä¸€ç§ training-free çš„åŠ é€Ÿæ¡†æ¶ã€‚å®ƒæ²¡æœ‰ä¿®æ”¹æ¨¡å‹ç»“æ„ï¼Œä¹Ÿä¸éœ€è¦é‡æ–°è®­ç»ƒï¼Œè€Œæ˜¯é€šè¿‡ä¸¤é¡¹å³æ’å³ç”¨çš„æ¨ç†ç­–ç•¥â€”â€”â€œåˆ†å—è¿‘ä¼¼KVç¼“å­˜â€å’Œâ€œç½®ä¿¡åº¦æ„ŸçŸ¥å¹¶è¡Œè§£ç â€ï¼Œåˆ†åˆ«ä»å‡å°‘é‡å¤è®¡ç®—å’Œæå‡å¹¶è¡Œæ•ˆç‡ä¸¤ä¸ªç»´åº¦ï¼Œç²¾å‡†åœ°è§£å†³äº†å½“å‰å¼€æºæ‰©æ•£ LLM é¢ä¸´çš„æ ¸å¿ƒç“¶é¢ˆã€‚ å®éªŒç»“æœåœ¨ LLaDA å’Œ Dream ç­‰æ¨¡å‹ä¸Šï¼Œç»“åˆä¸¤ç§ç­–ç•¥ï¼Œå®ç°äº†é«˜è¾¾ 27.6 å€çš„ç«¯åˆ°ç«¯ååé‡æå‡ï¼ŒåŒæ—¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå‡ ä¹æ²¡æœ‰ç²¾åº¦æŸå¤±ã€‚\n2. Preliminary 2.1. Masked Diffusion Model é’ˆå¯¹ç¦»æ•£æ•°æ®çš„æ‰©æ•£æ¨¡å‹æœ€æ—©åœ¨ Argmax Flows and Multinomial Diffusion å’Œ Deep Unsupervised Learning using Nonequilibrium Thermodynamics ä¸­è¢«æ¢æå‡ºã€‚éšå D3PM æå‡ºäº†ä¸€ä¸ªæ›´é€šç”¨çš„æ¡†æ¶ï¼Œé€šè¿‡ç‰¹å®šçš„è½¬ç§»çŸ©é˜µ $Q_{t}$ å®šä¹‰äº†å‰å‘åŠ å™ªè¿‡ç¨‹çš„ç¦»æ•£çŠ¶æ€é©¬å°”å¯å¤«é“¾ï¼Œå¹¶é€šè¿‡æœ€å¤§åŒ– ELBO æ¥å­¦ä¹ åå‘è¿‡ç¨‹çš„å‚æ•°åŒ–æ¨¡å‹ $p_{\\theta}(x_{0}|x_{t})$. CTMC è¿›ä¸€æ­¥å°† D3PM æ‰©å±•åˆ°è¿ç»­æ—¶é—´ï¼Œå°†å…¶å½¢å¼åŒ–ä¸ºä¸€ä¸ªè¿ç»­æ—¶é—´é©¬å°”å¯å¤«é“¾ (CTMC) æ¡†æ¶ã€‚åœ¨å¦ä¸€ç§ä¸åŒçš„æ–¹æ³•ä¸­ï¼ŒSEDD é€šè¿‡å‚æ•°åŒ–ä¼¼ç„¶æ¯” $\\frac{p_{t}(y)}{p_{t}(x)}$ æ¥å­¦ä¹ åå‘è¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨å»å™ªåˆ†æ•°ç†µæ¥è®­ç»ƒè¯¥æ¯”ç‡ã€‚\nåœ¨å„ç§ç¦»æ•£æ‰©æ•£çš„å™ªå£°å¤„ç†æ–¹å¼ä¸­ï¼ŒMasked Diffusion Models, MDMsï¼Œä¹Ÿè¢«ç§°ä¸ºå¸æ”¶çŠ¶æ€ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼Œè·å¾—äº†ç›¸å½“å¤§çš„å…³æ³¨ã€‚MDMs é‡‡ç”¨ä¸€ç§å‰å‘åŠ å™ªè¿‡ç¨‹ï¼Œå…¶ä¸­ token è¢«é€æ­¥æ›¿æ¢ä¸ºä¸€ä¸ªç‰¹æ®Šçš„ MASK token ã€‚è¿™ä¸ªè¿‡ç¨‹ç”±ä»¥ä¸‹è½¬ç§»æ¦‚ç‡å®šä¹‰ï¼š\n$$\rq_{t|0}(x_{t}|x_{0})=\\prod_{i=1}^{n}q_{t|0}(x_{t}^{i}|x_{0}^{i})=\\prod_{i=1}^{n}Cat(x_{t}^{i};(1-t)\\delta_{x_{0}^{i}}+t\\delta_{[MASK]}) \\tag{1}\r$$ $q_{t|0}(x_t|x_0)$: è¡¨ç¤ºç»™å®šåŸå§‹åºåˆ— $x_0$ï¼Œå¾—åˆ°å™ªå£°åºåˆ— $x_t$ çš„æ¦‚ç‡ ã€‚ $\\prod_{i=1}^{n}$: è¿ä¹˜ç¬¦å·ï¼Œè¡¨ç¤ºæ•´ä¸ªåºåˆ—çš„å™ªå£°è¿‡ç¨‹æ˜¯åºåˆ—ä¸­æ¯ä¸ª token (token) ç‹¬ç«‹è¿›è¡Œå™ªå£°è¿‡ç¨‹çš„æ¦‚ç‡ä¹˜ç§¯ ã€‚ $Cat(\\cdot)$: ä»£è¡¨ç±»åˆ«åˆ†å¸ƒ (Categorical Distribution) ã€‚ $t \\in [0,1]$: è¡¨ç¤ºæ‰©æ•£æ—¶é—´æˆ–æ©ç çº§åˆ«ã€‚å½“ $t=0$ æ—¶ï¼Œåºåˆ—å®Œå…¨æ˜¯åŸå§‹çš„ï¼›å½“ $t=1$ æ—¶ï¼Œåºåˆ—è¢«å®Œå…¨æ›¿æ¢ä¸º [MASK] token ã€‚ $(1-t)\\delta_{x_{0}^{i}}+t\\delta_{[MASK]}$: åœ¨æ—¶é—´ tï¼Œç¬¬ i ä¸ª token æœ‰ $1-t$ çš„æ¦‚ç‡ä¿æŒå…¶åŸå§‹èº«ä»½ $x_0^i$ï¼Œæœ‰ $t$ çš„æ¦‚ç‡å˜æˆ [MASK] token ã€‚$\\delta$ æ˜¯å…‹ç½—å†…å…‹å‡½æ•°ï¼Œç”¨äºæŒ‡å®šæ¦‚ç‡ã€‚ æœ€è¿‘ï¼ŒMDLM å’Œ RADD çš„å·¥ä½œè¡¨æ˜ï¼Œå¯¹äº MDMs ä¸åŒçš„å‚æ•°åŒ–æ˜¯ç­‰ä»·çš„ã€‚æ­¤å¤–ï¼Œä»–ä»¬è¯æ˜äº† MDMs çš„è®­ç»ƒç›®æ ‡å¯ä»¥è¢«ç®€åŒ–æˆ–ç›´æ¥ä»æ•°æ®ä¼¼ç„¶ä¸­æ¨å¯¼å‡ºæ¥ ã€‚è¿™å¯¼å‡ºäº†ä»¥ä¸‹ç›®æ ‡å‡½æ•°ï¼Œå³ $log~p_{\\theta}(x)$ çš„ä¸€ä¸ª ELBO:\nReparameterized Absorbing Discrete Diffusion, RADD å®šç† 1ï¼ˆTheorem 1ï¼‰ $$\r\\frac{p_t(\\hat{x}_t)}{p_t(x_t)} = \\underbrace{\\frac{e^{-\\bar{\\sigma}(t)}}{1-e^{-\\bar{\\sigma}(t)}}}_{\\text{æ—¶é—´ç›¸å…³çš„æ ‡é‡}} \\cdot \\underbrace{p_0(\\hat{x}_t^i | x_t^{UM})}_{\\text{å¹²å‡€æ•°æ®çš„æ¡ä»¶æ¦‚ç‡}}\r$$ $p_t(x_t)$ æ˜¯æ—¶é—´æ­¥ $t$ çš„æ•°æ®åˆ†å¸ƒ $x_t$ æ˜¯å¸¦å™ªå£°ï¼ˆè¢«æ©ç ï¼‰çš„åºåˆ— $x_t^{UM}$ æ˜¯å…¶ä¸­æœªè¢«æ©ç çš„éƒ¨åˆ† $\\hat{x}_t$ æ˜¯åœ¨ $x_t$ çš„ä¸€ä¸ªæ©ç ä½ç½®ä¸Šå¡«å…¥ä¸€ä¸ªæ–° token åçš„åºåˆ— $p_0$ æ˜¯åŸå§‹å¹²å‡€æ•°æ®çš„åˆ†å¸ƒï¼Œ$\\bar{\\sigma}(t)$ æ˜¯ä¸€ä¸ªä¸å™ªå£°æ°´å¹³ç›¸å…³çš„å‡½æ•°ã€‚ è¿™ä¸ªå…¬å¼è¡¨æ˜ï¼Œæ¨¡å‹éœ€è¦å­¦ä¹ çš„ç›®æ ‡å¯ä»¥åˆ†è§£ã€‚å…¶ä¸­ä¸€éƒ¨åˆ†æ˜¯ä¸€ä¸ªå¯ä»¥ç²¾ç¡®è®¡ç®—çš„ã€åªä¸æ—¶é—´ $t$ æœ‰å…³çš„æ ‡é‡ï¼Œè€Œå¦ä¸€éƒ¨åˆ†åˆ™æ˜¯ä¸€ä¸ªä¸æ—¶é—´æ— å…³çš„ã€åœ¨ç»™å®šå…¶ä»–å¯è§ token çš„æ¡ä»¶ä¸‹ï¼Œé¢„æµ‹è¢«æ©ç  token çš„æ¡ä»¶æ¦‚ç‡ã€‚æ­£æ˜¯LLM æ‰€åšçš„äº‹æƒ…ã€‚è¿™ä¸ªçœ‹ä¼¼ç®€å•çš„æ”¹åŠ¨å¸¦æ¥äº†å·¨å¤§çš„å®é™…ä¼˜åŠ¿ï¼š\næ¶æ„ç®€åŒ–ï¼šç§»é™¤äº†æ—¶é—´ç¼–ç å’Œç›¸å…³çš„è‡ªé€‚åº”å½’ä¸€åŒ–å±‚ï¼Œä½¿å¾—æ¨¡å‹å‚æ•°æ›´å°‘ï¼Œç»“æ„æ›´ç®€æ´ ã€‚ é‡‡æ ·åŠ é€Ÿï¼šç”±äºæ¨¡å‹è¾“å‡ºä¸å†ä¾èµ–äºæ—¶é—´ $t$ï¼Œå½“è¾“å…¥åºåˆ— $x_t$ åœ¨æŸä¸ªé‡‡æ ·åŒºé—´å†…æ²¡æœ‰å‘ç”Ÿå˜åŒ–æ—¶ï¼Œå¯ä»¥ç›´æ¥ç¼“å­˜ä¸Šä¸€æ­¥çš„è®¡ç®—ç»“æœï¼Œè€Œæ— éœ€å†æ¬¡è°ƒç”¨ç½‘ç»œã€‚è¿™æå¤§åœ°å‡å°‘äº†å‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼ˆNumber of Function Evaluations, NFEsï¼‰ã€‚è®ºæ–‡ç»™å‡ºäº†åœ¨ç‰¹å®šé‡‡æ ·ç­–ç•¥ä¸‹ï¼ŒæœŸæœ›å‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼ˆE-NFEsï¼‰çš„è§£æå…¬å¼ ï¼š $$\rE\\text{-}NFEs(n) = n \\left( 1 - \\left( 1 - \\frac{1}{n} \\right)^l \\right)\r$$å®šç† 2ï¼ˆTheorem 2ï¼‰\nè¯æ˜äº†å¸æ”¶æ€æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒç›®æ ‡ï¼ˆå…·ä½“æ¥è¯´æ˜¯ DSE æŸå¤±ï¼‰åœ¨æ•°å­¦ä¸Šç­‰ä»·äº**ä»»æ„é˜¶è‡ªå›å½’æ¨¡å‹ï¼ˆAny-Order Autoregressive Models, AO-ARMsï¼‰**çš„è®­ç»ƒç›®æ ‡ ã€‚\nAO-ARMs æ˜¯ä¸€ç±»ç‰¹æ®Šçš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä»¬ä¸åƒæ ‡å‡†è‡ªå›å½’æ¨¡å‹é‚£æ ·å›ºå®šä»å·¦åˆ°å³çš„ç”Ÿæˆé¡ºåºï¼Œè€Œæ˜¯å­¦ä¹ åœ¨æ‰€æœ‰å¯èƒ½çš„ $d!$ï¼ˆ$d$ ä¸ºåºåˆ—é•¿åº¦ï¼‰ç§ç”Ÿæˆé¡ºåºä¸‹å¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡ã€‚è®ºæ–‡é€šè¿‡ä¸€ç³»åˆ—ç²¾å·§çš„æ•°å­¦æ¨å¯¼ï¼Œå»ºç«‹äº†å››ç§ä¸åŒæŸå¤±å‡½æ•°ä¹‹é—´çš„ç­‰ä»·å…³ç³»é“¾ ï¼š\n$\\mathcal{L}_{DSE} \\iff \\mathcal{L}_{t-DCE} \\iff \\mathcal{L}_{\\lambda-DCE} \\iff \\mathcal{L}_{AO}$\nå®ƒè¡¨æ˜å¸æ”¶æ€æ‰©æ•£æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯åœ¨å­¦ä¹ ä¸€ä¸ªé›†æˆäº†æ‰€æœ‰å¯èƒ½ç”Ÿæˆé¡ºåºçš„è‡ªå›å½’æ¨¡å‹çš„æœŸæœ› ã€‚è¿™å¯èƒ½è§£é‡Šäº†ä¸ºä»€ä¹ˆå®ƒä»¬åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°å¾—éå¸¸ç¨³å¥ã€‚\n$$\r-log~p_{\\theta}(x)\\le\\int_{0}^{1}\\frac{1}{t}\\mathbb{E}_{q_{t,0}(x_{t}|x_{0})}[\\sum_{i:x_{t}^{i}=[MASK]}-log~p_{\\theta}(x_{0}^{i}|x_{t})]dt:=\\mathcal{L}_{MDM}. \\tag{2}\r$$ $-log~p_{\\theta}(x)$: æ¨¡å‹çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ç”ŸæˆçœŸå®æ•°æ® $x$ çš„å¯¹æ•°ä¼¼ç„¶ï¼Œè¿™ç­‰ä»·äºæœ€å°åŒ–å®ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚è¿™ä¸ªå…¬å¼ç»™å‡ºäº†è´Ÿå¯¹æ•°ä¼¼ç„¶çš„ä¸€ä¸ª* ELBO. $\\int_{0}^{1}...dt$: å¯¹æ‰€æœ‰å¯èƒ½çš„å™ªå£°çº§åˆ« t (ä»0åˆ°1) è¿›è¡Œç§¯åˆ†ï¼Œæ„å‘³ç€æ¨¡å‹éœ€è¦å­¦ä¼šåœ¨ä»»ä½•å™ªå£°æ°´å¹³ä¸‹éƒ½èƒ½å¾ˆå¥½åœ°å¤åŸæ•°æ® ã€‚ $\\mathbb{E}_{q_{t,0}(x_{t}|x_{0})}[...]$: è¡¨ç¤ºå¯¹æ‰€æœ‰å¯èƒ½çš„å™ªå£°æ ·æœ¬æ±‚æœŸæœ›ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬æ ¹æ®å…¬å¼(1)éšæœºç”Ÿæˆä¸€ä¸ªå¸¦ [MASK] çš„å™ªå£°åºåˆ— $x_t$. $\\sum_{i:x_{t}^{i}=[MASK]}-log~p_{\\theta}(x_{0}^{i}|x_{t})$: $\\sum_{i:x_{t}^{i}=[MASK]}$: å¯¹æ‰€æœ‰è¢« [MASK] çš„ä½ç½® i è¿›è¡Œæ±‚å’Œ ã€‚ $-log~p_{\\theta}(x_{0}^{i}|x_{t})$: è¿™æ˜¯äº¤å‰ç†µæŸå¤±ã€‚å®ƒçš„æ„æ€æ˜¯ï¼Œç»™å®šå¸¦æœ‰ [MASK] çš„åºåˆ— $x_t$ï¼Œæ¨¡å‹ $p_{\\theta}$ éœ€è¦é¢„æµ‹åœ¨ä½ç½® i ä¸Šçš„åŸå§‹ token $x_0^i$ åº”è¯¥æ˜¯ä»€ä¹ˆã€‚æ¨¡å‹é¢„æµ‹å¾—è¶Šå‡†ï¼Œè¿™ä¸ªæŸå¤±å€¼å°±è¶Šå°ã€‚ 2.2. MDMs çš„ç”Ÿæˆè¿‡ç¨‹ å¯¹äºå…¬å¼1ä¸­å®šä¹‰çš„å‰å‘è¿‡ç¨‹ï¼Œå…¶è§£æä¸Šçš„é€†è¿‡ç¨‹åœ¨ç”Ÿæˆæ—¶è®¡ç®—æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºå®ƒé€šå¸¸æ¯æ­¥åªä¿®æ”¹ä¸€ä¸ª token ã€‚ä¸€ä¸ªå¸¸è§çš„åŠ é€Ÿç­–ç•¥æ˜¯é‡‡ç”¨ $\\tau$-leaping è¿‘ä¼¼æ³•æ¥å¤„ç†åå‘è¿‡ç¨‹ã€‚åœ¨ MDMs çš„èƒŒæ™¯ä¸‹ï¼Œè¿™å…è®¸ä¸€ä¸ªè¿­ä»£å¼çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œå…¶ä¸­å¤šä¸ªè¢«æ©ç çš„ token å¯ä»¥ä»ä¸€ä¸ªå™ªå£°æ°´å¹³ t è¿‘ä¼¼åœ°å•æ­¥æ¢å¤åˆ°ä¸€ä¸ªæ›´æ—©çš„æ°´å¹³ s \u0026lt; t.\n$$\rq_{s|t}(x_s|x_t)=\\prod_{i=0}^{n-1}q_{s|t}(x_{s}^{i}|x_{t})\r$$å…¶ä¸­\n$$\rq_{s|t}(x_{s}^{i}|x_{t})=\\begin{cases}1, \u0026 \\text{if } x_{t}^{i}\\ne[MASK], x_{s}^{i}=x_{t}^{i} \\\\ \\frac{s}{t}, \u0026 \\text{if } x_{t}^{i}=[MASK], x_{s}^{i}=[MASK] \\\\ \\frac{t-s}{t}q_{0|t}(x_{s}^{i}|x_{t}), \u0026 \\text{if } x_{t}^{i}=[MASK], x_{s}^{i}\\ne[MASK]\\end{cases} \\tag{3}\r$$ $q_{s|t}(x_{s}^{i}|x_{t})$: è¡¨ç¤ºä» t æ—¶åˆ»çš„ token $x_t^i$ å˜ä¸º s æ—¶åˆ»çš„ token $x_s^i$ çš„æ¦‚ç‡ ã€‚ Case 1: å¦‚æœä¸€ä¸ª token åœ¨ t æ—¶åˆ»å°±ä¸æ˜¯ [MASK]ï¼Œé‚£ä¹ˆå®ƒåœ¨æ›´æ—©çš„ s æ—¶åˆ»ä¹Ÿä¿æŒä¸å˜ ã€‚ Case 2: ä¸€ä¸ªåœ¨ t æ—¶åˆ»æ˜¯ [MASK] çš„ token ï¼Œåœ¨æ›´æ—©çš„ s æ—¶åˆ»ä»ç„¶æ˜¯ [MASK]. Case 3: è¿™æ˜¯å…³é”®çš„å»å™ªæ­¥éª¤ã€‚å¦‚æœä¸€ä¸ª token åœ¨ t æ—¶åˆ»æ˜¯ [MASK]ï¼Œæ¨¡å‹ä¼šå°è¯•åœ¨ s æ—¶åˆ»é¢„æµ‹å‡ºä¸€ä¸ªå…·ä½“çš„ token. $\\frac{t-s}{t}$: ä»£è¡¨ä¸€ä¸ªåœ¨ t æ—¶åˆ»è¢«æ©ç çš„ tokenï¼Œåœ¨ s æ—¶åˆ»è¢«â€œæ­ç¤ºâ€å‡ºæ¥çš„æ¦‚ç‡ ã€‚ $q_{0|t}(x_{s}^{i}|x_{t})$: è¿™æ˜¯ç”±ç¥ç»ç½‘ç»œæ¨¡å‹ç»™å‡ºçš„é¢„æµ‹åˆ†å¸ƒã€‚æ¨¡å‹ä¼šè§‚å¯Ÿæ•´ä¸ªå¸¦æœ‰ [MASK] çš„ä¸Šä¸‹æ–‡ $x_t$ï¼Œç„¶åä¸ºå½“å‰ä½ç½®é¢„æµ‹ä¸€ä¸ªæœ€æœ‰å¯èƒ½çš„åŸå§‹ token ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªåœ¨æ•´ä¸ªè¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒ ã€‚ åœ¨æ¶‰åŠæ¡ä»¶æ•°æ®çš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚æ ¹æ®ä¸€ä¸ª propmt p ç”Ÿæˆä¸€ä¸ªå›åº” $x_{0}$ï¼ŒMDM çš„åå‘è¿‡ç¨‹ (å…¬å¼3æ‰€å®šä¹‰) éœ€è¦è¿›è¡Œè°ƒæ•´ã€‚å…·ä½“æ¥è¯´ï¼Œæ¨¡å‹ç”¨äºæ­ç¤ºä¸€ä¸ª token $x_{s}^{i}$ çš„é¢„æµ‹åˆ†å¸ƒ $q_{0|t}(x_{s}^{i}|x_{t})$ ç°åœ¨ä¹Ÿéœ€è¦ä»¥ prompt p ä¸ºæ¡ä»¶ï¼Œå³ $q_{0|t}(x_{s}^{i}|x_{t},p)$ ã€‚\nå¹¶è¡Œè§£ç çš„è¯…å’’ ç›´æ¥é€†è½¬å…¬å¼1çš„å‰å‘è¿‡ç¨‹æ¥è¿›è¡Œç”Ÿæˆæ˜¯ç¼“æ…¢çš„ï¼Œé€šå¸¸æ¯æ­¥åªæ”¹å˜ä¸€ä¸ª token. ä¸€ä¸ªå¸¸è§çš„åŠ é€Ÿç­–ç•¥æ˜¯é‡‡ç”¨ $\\tau$-leaping è¿‘ä¼¼æ³•æ¥å¤„ç†åå‘è¿‡ç¨‹ã€‚å¯¹äº MDMsï¼Œè¿™æ„å‘³ç€å¤šä¸ªè¢«æ©ç çš„ token å°†åœ¨ä¸€ä¸ªæ­¥éª¤ä¸­å¹¶è¡Œç”Ÿæˆã€‚ç„¶è€Œï¼Œç”±äºæ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ï¼Œå¤š token é¢„æµ‹ä¸­å‡ºç°äº†ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚è€ƒè™‘ä¸€ä¸ªä¾‹å­ï¼šç”±ä¸¤ä¸ªè‹±æ–‡å•è¯ç»„æˆçš„æ‰‘å…‹æ‰‹ç‰Œåˆ—è¡¨æ˜¯ï¼šéšåçš„ä¸¤ä¸ªè¯å¯èƒ½æ˜¯ï¼Œä¾‹å¦‚ï¼Œhigh cardï¼Œtwo pairï¼Œfull houseï¼Œæˆ– straight flush. å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸¤ä¸ªè¯ä¹‹é—´å­˜åœ¨ç€å…³è”ã€‚ç„¶è€Œï¼ŒMDMs ä¸­çš„å¤š token é¢„æµ‹è¿‡ç¨‹é¦–å…ˆä¸ºæ¯ä¸ª token ç”Ÿæˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åç‹¬ç«‹åœ°ä»è¿™äº›åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·ã€‚è¿™ç§ç‹¬ç«‹é‡‡æ ·å¯èƒ½å¯¼è‡´ä¸å¸Œæœ›çš„ç»„åˆï¼Œä¾‹å¦‚ high house.\nä¸ºäº†å°†å…¶å½¢å¼åŒ–ï¼Œè€ƒè™‘æ­ç¤ºä¸¤ä¸ª token ä½ç½® i å’Œ j. ç”±äºæ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ï¼ŒMDMs ä» $p(x_{s}^{i}|x_{t})\\cdot p(x_{s}^{j}|x_{t})$ ä¸­é‡‡æ ·è¿™äº› token. ç„¶è€Œï¼ŒçœŸå®çš„è”åˆæ¦‚ç‡éœ€è¦è€ƒè™‘å®ƒä»¬ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼š\n$$\rp(x_{s}^{i},x_{s}^{j}|x_{t})=p(x_{s}^{i}|x_{t})\\cdot p(x_{s}^{j}|x_{t},x_{s}^{i})\r$$æˆ–è€…å¯¹ç§°åœ°ï¼Œé€šè¿‡å°† i ä¾èµ–äºæ¡ä»¶ j. è¿™ç§å‡è®¾çš„ç‹¬ç«‹ç”Ÿæˆä¸çœŸå®çš„ä¾èµ–æ€§æ•°æ®åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œä¼šé™ä½ç”Ÿæˆåºåˆ—çš„è´¨é‡å’Œè¿è´¯æ€§ã€‚å½“åœ¨å•ä¸€æ­¥éª¤ä¸­åŒæ—¶æ­ç¤ºå¤§é‡ token æ—¶ï¼Œè¿™ä¸ªé—®é¢˜ä¼šå˜å¾—æ›´åŠ ä¸¥é‡ã€‚\n3. Methodology 3.1. Pipeline Overview Fast-dLLMï¼Œå»ºç«‹åœ¨ MDM æ¶æ„ä¹‹ä¸Šï¼Œä»¥å®ç°é«˜æ•ˆå’Œé«˜è´¨é‡çš„åºåˆ—ç”Ÿæˆã€‚ä¸ºäº†åŠ é€Ÿæ¨ç†ï¼Œæ•´ä½“æµæ°´çº¿èåˆäº†ä¸¤å¤§å…³é”®ç­–ç•¥ï¼šé€šè¿‡ KV Cache å®ç°çš„é«˜æ•ˆæ³¨æ„åŠ›è®¡ç®—ï¼Œä»¥åŠä¸€ä¸ªç”±é¢„æµ‹ç½®ä¿¡åº¦å¼•å¯¼çš„ å¹¶è¡Œè§£ç æ–¹æ¡ˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†åˆ†å—è§£ç è®¾è®¡çš„ KV Cacheï¼Œå®ƒå…è®¸åœ¨ä¸åŒæ­¥éª¤é—´å¤ç”¨æ³¨æ„åŠ›æ¿€æ´»å€¼ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†å†—ä½™è®¡ç®—ã€‚åœ¨æ¯ä¸ªå—å†…éƒ¨ï¼Œè¿›ä¸€æ­¥æå‡ºäº†ç½®ä¿¡åº¦æ„ŸçŸ¥çš„å¹¶è¡Œè§£ç ï¼Œå®ƒèƒ½æ ¹æ®ç½®ä¿¡åº¦åˆ†æ•°é€‰æ‹©æ€§åœ°æ›´æ–° token ï¼Œä»è€Œåœ¨ä¿æŒè¾“å‡ºè´¨é‡çš„åŒæ—¶æé«˜æ•ˆç‡ã€‚é€šè¿‡ç»“åˆè¿™äº›ç­–ç•¥ï¼ŒFast-dLLM åœ¨å¯¹ç”Ÿæˆæ€§èƒ½å½±å“æœ€å°çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—åŠ å¿«äº† MDM çš„æ¨ç†é€Ÿåº¦ã€‚æ•´ä½“æµç¨‹åœ¨ç®—æ³• 1 ä¸­è¿›è¡Œäº†æ€»ç»“ã€‚\n3.2. Key-Value Cache for Block-Wise Decoding Illustration of our Key-Value Cache for Block-Wise Decoding\nå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§åˆ†å—è§£ç çš„ç­–ç•¥æ¥æ”¯æŒ KV Cache çš„ä½¿ç”¨ã€‚ä¸€å¼€å§‹è®¡ç®—å¹¶å­˜å‚¨ prompt çš„ KV ç¼“å­˜ï¼Œè¿™ä¸ªç¼“å­˜å°†åœ¨æ•´ä¸ªå— 0çš„è§£ç è¿‡ç¨‹ä¸­è¢«å¤ç”¨ã€‚åœ¨æ¯ä¸ªå—çš„å†…éƒ¨ï¼Œç›¸åŒçš„ç¼“å­˜ä¼šè¢«å¤šä¸ªè§£ç æ­¥éª¤å¤ç”¨ã€‚åœ¨å®Œæˆä¸€ä¸ªå—çš„è§£ç ä¹‹åï¼Œæ›´æ–°æ‰€æœ‰ token (ä¸ä»…ä»…æ˜¯æ–°ç”Ÿæˆçš„ token) çš„ç¼“å­˜ã€‚è¿™ä¸ªç¼“å­˜æ›´æ–°å¯ä»¥ä¸è§£ç æ­¥éª¤è”åˆæ‰§è¡Œï¼Œå› æ­¤ä¸ä¸ä½¿ç”¨ç¼“å­˜ç›¸æ¯”ï¼Œæ²¡æœ‰é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚ç”±äºæ©ç æ‰©æ•£æ¨¡å‹ä¸­ä½¿ç”¨çš„æ˜¯å®Œå…¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿™ç§æ–¹æ³•å¯¼è‡´äº†ä¸€ä¸ªè¿‘ä¼¼çš„è§£ç è¿‡ç¨‹ã€‚\næˆ‘ä»¬çš„è¿‘ä¼¼ KV ç¼“å­˜æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæºäºæˆ‘ä»¬è§‚å¯Ÿåˆ° KV æ¿€æ´»å€¼åœ¨ç›¸é‚»çš„æ¨ç†æ­¥éª¤ä¸­è¡¨ç°å‡ºé«˜åº¦çš„ç›¸ä¼¼æ€§ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å›¾ a ä¸­çº¢è‰²æ–¹æ¡†åŒºåŸŸçªæ˜¾äº†å—å†…çš„ç›¸ä¼¼æ€§åˆ†æ•°ï¼Œè¿™äº›åˆ†æ•°å§‹ç»ˆæ¥è¿‘äº 1. è¡¨æ˜åœ¨åˆ†å—è§£ç æœŸé—´ï¼Œå‰ç¼€ (prefix) çš„é”®å’Œå€¼çš„å·®å¼‚å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿå®‰å…¨åœ°å¤ç”¨ç¼“å­˜è€Œä¸ä¼šæœ‰æ˜¾è‘—çš„å‡†ç¡®ç‡æŸå¤±ã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªæˆ‘ä»¬ KV ç¼“å­˜æœºåˆ¶çš„åŒå‘ç‰ˆæœ¬ï¼Œåä¸º DualCacheï¼Œå®ƒä¸ä»…ç¼“å­˜å‰ç¼€ token ï¼Œè¿˜ç¼“å­˜åç¼€ (suffix) token ï¼Œåœ¨æˆ‘ä»¬çš„åˆ†å—è§£ç æ–¹æ¡ˆä¸­ï¼Œåç¼€å®Œå…¨ç”±æ©ç  token ç»„æˆã€‚å¦‚è¡¨3æ‰€ç¤ºï¼ŒDualCache å¸¦æ¥äº†è¿›ä¸€æ­¥çš„åŠ é€Ÿã€‚å›¾ b ä¸­çš„çº¢è‰²æ–¹æ¡†åŒºåŸŸè¿›ä¸€æ­¥è¯æ˜ï¼Œåœ¨åˆ†å—è§£ç æœŸé—´ï¼Œåç¼€çš„é”®å’Œå€¼çš„å·®å¼‚ä¹Ÿå¯ä»¥å¿½ç•¥ä¸è®¡ã€‚\nHeatmaps of Key-Value Activation Cosine Similarity Across Inference Steps in LLaDA\n3.3. Confidence-Aware Parallel Decoding å°½ç®¡å­˜åœ¨ä¸€äº›æ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨è¾…åŠ©æ¨¡å‹æ¥æ˜¾å¼åœ°æ•æ‰ä¸åŒä½ç½® token ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œä½†å®ƒä»¬é€šå¸¸ä¼šå¢åŠ æ•´ä¸ªæµæ°´çº¿çš„å¤æ‚æ€§ã€‚ä¸è¿™äº›æ–¹æ³•ç›¸åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„ç½®ä¿¡åº¦æ„ŸçŸ¥è§£ç ç®—æ³•ï¼Œæ—¨åœ¨ç¼“è§£è¿™ç§æ¡ä»¶ç‹¬ç«‹æ€§é—®é¢˜ã€‚\nåœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬ä¸æ˜¯å†’ç„¶åœ°ä½¿ç”¨å®ƒä»¬ç‹¬ç«‹çš„è¾¹ç¼˜æ¦‚ç‡æ¥æ­ç¤ºæ‰€æœ‰è¢«æ©ç çš„ token ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ª token è®¡ç®—ä¸€ä¸ªç½®ä¿¡åº¦åˆ†æ•° (ä¾‹å¦‚æœ€å¤§çš„ softmax æ¦‚ç‡). åªæœ‰é‚£äº›ç½®ä¿¡åº¦è¶…è¿‡ä¸€ä¸ªé˜ˆå€¼çš„ token æ‰ä¼šåœ¨å½“å‰æ­¥éª¤è¢«æ­ç¤ºï¼›å…¶ä½™çš„åˆ™ä¿æŒæ©ç çŠ¶æ€ï¼Œå¹¶åœ¨æœªæ¥çš„æ­¥éª¤ä¸­é‡æ–°è€ƒè™‘ã€‚å¦‚æœæ²¡æœ‰ token çš„ç½®ä¿¡åº¦è¶…è¿‡é˜ˆå€¼ï¼Œå°±æ­ç¤ºç½®ä¿¡åº¦æœ€é«˜çš„é‚£ä¸€ä¸ªï¼Œä»¥ç¡®ä¿è¿‡ç¨‹èƒ½å¤Ÿè¿›è¡Œå¹¶é˜²æ­¢æ— é™å¾ªç¯ã€‚è¿™ä¸ªç­–ç•¥åœ¨åŠ é€Ÿç”Ÿæˆçš„åŒæ—¶ï¼Œå‡å°‘äº†ç”±ä¸ç¡®å®šæˆ–æ¨¡ç³Šé¢„æµ‹å¼•èµ·çš„é”™è¯¯ã€‚\nä¸€ä¸ªå…³é”®é—®é¢˜æ˜¯\nWhen is it theoretically justifiable to decode tokens in parallel using independent marginals, despite the true joint distribution potentially containing dependencies?\nä»¥ä¸‹ç»“æœæ¥å›ç­”äº†åœ¨é«˜ç½®ä¿¡åº¦æƒ…å†µä¸‹ï¼Œgreedy parallel è§£ç ç­‰åŒäº greedy sequential è§£ç çš„æ¡ä»¶ï¼Œå¹¶é‡åŒ–äº†ä¸¤ç§åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚åœ¨ç»™å‡ºå®šç†ä¹‹å‰ï¼Œæˆ‘ä»¬å°†å®šä¹‰å…¶è¡¨è¿°ä¸­ä½¿ç”¨çš„æ•°å­¦ç¬¦å·ã€‚\nè®¾ $p_{\\theta}(\\cdot|E)$ è¡¨ç¤ºä¸€ä¸ª MDM åœ¨ç»™å®š E (åŒ…æ‹¬ prompt $p_{0}$ å’Œå…ˆå‰ç”Ÿæˆçš„ token) çš„æ¡ä»¶ä¸‹ç»™å‡ºçš„ PMF. å‡è®¾æ¨¡å‹è¦ä¸ºä¸åœ¨ E ä¸­çš„ä½ç½® $i_{1},...,i_{n}$ é¢„æµ‹ n ä¸ª token.\nä»¤ $X=(X_{i_{1}},...,X_{i_{n}})$ æ˜¯ n ä¸ª token çš„å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ª $X_{i_{j}}$ åœ¨è¯æ±‡è¡¨ V ä¸­å–å€¼ã€‚è®¾ $p(X|E)\\equiv p_{\\theta}(X_{i_{1}},...,X_{i_{n}}|E)$ æ˜¯æ¨¡å‹ç»™å‡ºçš„è”åˆæ¡ä»¶ PMFã€‚è®¾ $p_{j}(X_{i_{j}}|E)\\equiv p_{\\theta}(X_{i_{j}}|E)$ æ˜¯ä½ç½® $i_{j}$ çš„è¾¹ç¼˜æ¡ä»¶ PMFã€‚å¹¶è¡Œè§£ç ä½¿ç”¨è¾¹ç¼˜æ¦‚ç‡çš„ä¹˜ç§¯æ¥ç”Ÿæˆ token ï¼š$q(X|E)=\\tilde{\\prod}_{j=1}^{n}p_{j}(X_{i_{j}}|E)$ã€‚å®šç†1çš„è¯æ˜åŠç›¸å…³è®¨è®ºè§é™„å½•Aã€‚\nå®šç† 1 (é«˜ç½®ä¿¡åº¦ä¸‹çš„å¹¶è¡Œè§£ç ). å‡è®¾å­˜åœ¨ä¸€ä¸ªç‰¹å®šçš„ token åºåˆ— $x^{*}=(x_{i_{1}},...,x_{i_{n}})$ï¼Œä½¿å¾—å¯¹äºæ¯ä¸ª $j\\in\\{1,...,n\\}$ï¼Œæ¨¡å‹å¯¹ $x_{i_{j}}$ éƒ½æœ‰å¾ˆé«˜çš„ç½®ä¿¡åº¦ï¼š$p_{j}(X_{i_{j}}=x_{i_{j}}|E)\u003e1-\\epsilon$ï¼Œå¯¹äºæŸä¸ªå¾ˆå°çš„ $\\epsilon\u003e0$. é‚£ä¹ˆï¼Œä»¥ä¸‹ç»“è®ºæˆç«‹ï¼š\nEquivalence of Greedy Decodingï¼šå¦‚æœ $(n+1)\\epsilon\\le1$ (å³ $\\epsilon\\le\\frac{1}{n+1}$) ï¼Œé‚£ä¹ˆ $$\r\\text{argmax}_{z} p(z|E) = \\text{argmax}_{z} q(z|E) = x^{*}. \\tag{4}\r$$ è¿™æ„å‘³ç€ greedy parallel è§£ç  (é€‰æ‹© argmax q) ä¸è´ªå©ªåºè´¯è§£ç  (é€‰æ‹© argmax p) äº§ç”Ÿç›¸åŒçš„ç»“æœã€‚ è¿™ä¸ªç•Œæ˜¯ç´§çš„ï¼šå¦‚æœ $\\epsilon \u003e \\frac{1}{n+1}$ï¼Œåˆ™å­˜åœ¨æ»¡è¶³é«˜ç½®ä¿¡åº¦è¾¹ç¼˜å‡è®¾çš„åˆ†å¸ƒ $p(X|E)$ï¼Œä½¿å¾— argmax $p(z|E)$ â‰  argmax $q(z|E)$ã€‚\nDistance and Divergence Boundsï¼šä¸ºç®€æ´èµ·è§ï¼Œå°† $p(\\cdot|E)$ å’Œ $q(\\cdot|E)$ è¡¨ç¤ºä¸º p å’Œ q. $L_p$ Distance ($p \\ge 1$): å¯¹äº $n\u003e1$ï¼Œ$D_{p}(p,q)\u003c((n-1)^{p}+2n)^{1/p}\\epsilon$ã€‚ç‰¹åˆ«åœ°ï¼Œå¯¹äºæ€»å˜å·®è·ç¦» ($D_{TV}(p,q)=\\frac{1}{2}D_{1}(p,q)$)ï¼Œ$D_{TV}(p,q)\u003c\\frac{3n-1}{2}\\epsilon$.\nè¿™ä¸ªå…¬å¼è¯´æ˜ï¼ŒçœŸå®åˆ†å¸ƒ p å’Œè¿‘ä¼¼åˆ†å¸ƒ q ä¹‹é—´çš„æ€»å˜å·®è·ç¦»æœ‰ä¸€ä¸ªä¸Šé™ã€‚è¿™ä¸ªä¸Šé™å–å†³äºä¸¤ä¸ªå› ç´ ï¼š\n$n$: ç”Ÿæˆåºåˆ—çš„é•¿åº¦ã€‚åºåˆ—è¶Šé•¿ï¼Œè¿™ä¸ªä¸Šé™å°±è¶Šå¤§ã€‚è¿™æ˜¯ç¬¦åˆç›´è§‰çš„ï¼Œå› ä¸ºæ¯å¢åŠ ä¸€ä¸ª tokenï¼Œè¿‘ä¼¼æ‰€ç´¯ç§¯çš„æ½œåœ¨è¯¯å·®å°±å¯èƒ½å¢åŠ ä¸€ç‚¹ã€‚ $\\epsilon$: æ¨¡å‹åœ¨æ¯ä¸ªä½ç½®ä¸Šçš„â€œä¸ç¡®å®šæ€§â€ã€‚$\\epsilon$ è¶Šå° (å³æ¨¡å‹è¶Šè‡ªä¿¡)ï¼Œè¿™ä¸ªä¸Šé™å°±è¶Šä½ã€‚ Forward KL Divergence: å¯¹äº $n \u003e 1$ï¼Œ$D_{KL}(p||q)\u003c(n-1)(H_{b}(\\epsilon)+\\epsilon~ln(|\\mathcal{V}|-1))$ï¼Œå…¶ä¸­ $H_{b}(\\epsilon)=-\\epsilon~ln~\\epsilon-(1-\\epsilon)ln(1-\\epsilon)$ æ˜¯äºŒå…ƒç†µå‡½æ•°ï¼Œè€Œ $|\\mathcal{V}|$ æ˜¯è¯æ±‡è¡¨çš„å¤§å°ã€‚\n$n-1$: åŒæ ·ï¼ŒæŸå¤±ä¼šéšç€åºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ã€‚ $H_{b}(\\epsilon)$: å®ƒè¡¡é‡äº†ä¸€ä¸ªæ¦‚ç‡ä¸º $\\epsilon$ çš„äº‹ä»¶å¸¦æ¥çš„â€œæ„å¤–ç¨‹åº¦â€æˆ–ä¸ç¡®å®šæ€§ã€‚å½“ $\\epsilon$ å¾ˆå°æ—¶ï¼Œ$H_b(\\epsilon)$ ä¹Ÿéå¸¸å°ã€‚ $\\epsilon~ln(|\\mathcal{V}|-1)$: è¿™ä¸€é¡¹åæ˜ äº†é‚£éƒ¨åˆ†å¾®å°çš„ $\\epsilon$ æ¦‚ç‡è¢«åˆ†é…åˆ°è¯æ±‡è¡¨ $\\mathcal{V}$ ä¸­å…¶ä»–æ‰€æœ‰ token ä¸Šæ‰€å¸¦æ¥çš„ä¸ç¡®å®šæ€§ã€‚å³ä½¿ $\\epsilon$ å¾ˆå°ï¼Œå¦‚æœè¯æ±‡è¡¨éå¸¸å·¨å¤§ ($|\\mathcal{V}|$ å¾ˆå¤§)ï¼Œè¿™ä¸€é¡¹ä¹Ÿå¯èƒ½æœ‰å½±å“ã€‚ $L_p$ è·ç¦»è¯´æ˜åœ¨é«˜ç½®ä¿¡åº¦ä¸‹ï¼Œä¸¤ç§æ–¹æ³•æ‰¾åˆ°çš„æœ€ä½³ç­”æ¡ˆæ˜¯ç›¸åŒçš„ã€‚ KL æ•£åº¦è¯´æ˜é«˜ç½®ä¿¡åº¦ä¸‹ï¼Œä¸ä»…æœ€ä½³ç­”æ¡ˆç›¸åŒï¼Œä¸¤ç§æ–¹æ³•æç»˜çš„æ¦‚ç‡åˆ†å¸ƒéƒ½éå¸¸ç›¸ä¼¼ã€‚è¿‘ä¼¼æ–¹æ³• q ä¸ä»…çŒœå¯¹äº†å¯èƒ½æ€§æœ€å¤§çš„ tokenï¼Œ å¯¹å…¶ä»–å¯èƒ½æ€§çš„ä¼°è®¡ï¼Œä¹Ÿå’Œç²¾ç¡®æ–¹æ³• p çš„åˆ¤æ–­é«˜åº¦ä¸€è‡´ã€‚ 4. Experiments 4.1 Experimental Setup ç¡¬ä»¶ä¸ç¯å¢ƒ ğŸ–¥ï¸: æ‰€æœ‰å®éªŒå‡åœ¨å•å¼  NVIDIA A100 80GB GPU ä¸Šè¿›è¡Œï¼Œbatch size=1. è¯„æµ‹æ¨¡å‹ ğŸ§ : LLaDA å’Œ Dream. è¯„æµ‹åŸºå‡† ğŸ“Š: é‡‡ç”¨äº†å››ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æ•°æ®é›†ï¼šGSM8Kã€MATHã€HumanEval å’Œ MBPP. æ ¸å¿ƒæŒ‡æ ‡ â±ï¸: å‡†ç¡®ç‡ (Accuracy): è¡¡é‡æ¨¡å‹åœ¨å…·ä½“ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚ ååé‡ (Throughput): ä»¥ tokens/sec ä¸ºå•ä½ï¼Œåæ˜ ç«¯åˆ°ç«¯çš„çœŸå®è§£ç é€Ÿåº¦ã€‚ è¶…å‚æ•° âš™ï¸: ç¼“å­˜å—å¤§å°: åœ¨ 4 åˆ° 32 ä¹‹é—´è¿›è¡Œæ¢ç´¢ã€‚ ç½®ä¿¡åº¦é˜ˆå€¼: åœ¨ 0.5 åˆ° 1.0 ä¹‹é—´è¿›è¡Œæ¢ç´¢ã€‚ å®éªŒé»˜è®¤ä½¿ç”¨ PrefixCacheï¼Œå—å¤§å°ä¸º 32ï¼Œç½®ä¿¡åº¦é˜ˆå€¼ä¸º 0.9. 4.2 Main Results: Performance and Speed å®éªŒç»“æœè¡¨æ˜ï¼ŒFast-dLLM åœ¨å„ç§ä»»åŠ¡å’Œè®¾ç½®ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ï¼ŒåŒæ—¶å¯¹æ¨¡å‹å‡†ç¡®ç‡çš„å½±å“å¾®ä¹å…¶å¾® ã€‚\nåŠ é€Ÿæ•ˆæœ: å•ç‹¬å¼•å…¥ KV Cache æœºåˆ¶ï¼Œé€šå¸¸èƒ½å¸¦æ¥ 2x-3.6x çš„é€Ÿåº¦æå‡ã€‚ å½“ KV Cache å’Œå¹¶è¡Œè§£ç ä¸¤ç§ç­–ç•¥ç»“åˆä½¿ç”¨æ—¶ï¼Œæ€§èƒ½æå‡æ›´ä¸ºæ˜¾è‘—ã€‚åœ¨ LLaDA æ¨¡å‹ä¸Šï¼Œæœ€ é«˜å¯è¾¾ 11.0x çš„ååé‡æå‡ï¼›åœ¨ Dream æ¨¡å‹ä¸Šï¼Œæœ€é«˜å¯è¾¾ 7.8x çš„æå‡ ã€‚ æå°çš„ç²¾åº¦æŸå¤±: åœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŠ é€Ÿåæ¨¡å‹çš„å‡†ç¡®ç‡ä¸åŸå§‹åŸºçº¿æ¨¡å‹çš„å·®è·åŸºæœ¬ä¿æŒåœ¨ 1-2ä¸ªç™¾åˆ†ç‚¹ ä»¥å†…ï¼Œæœ‰æ—¶ç”šè‡³ç•¥æœ‰æé«˜ã€‚ å¯¹é•¿åºåˆ—æ›´å‹å¥½: å®éªŒè¿˜å‘ç°ï¼Œåœ¨å¤„ç†æ›´é•¿çš„æ–‡æœ¬åºåˆ—æ—¶ (ä¾‹å¦‚ few-shot åœºæ™¯æˆ–é•¿ä»£ç ç”Ÿæˆ)ï¼ŒFast-dLLM çš„åŠ é€Ÿæ•ˆæœæ›´ä¸ºæ˜æ˜¾ã€‚ ä¸‹è¡¨ä»¥ GSM8K (5-shot) ä»»åŠ¡ä¸ºä¾‹ï¼Œç›´è§‚å±•ç¤ºäº† Fast-dLLM (å³ +Cache+Parallel) ç›¸è¾ƒäº baseline æ¨¡å‹çš„æ€§èƒ½æå‡ã€‚\næ¨¡å‹ ç”Ÿæˆé•¿åº¦ é…ç½® å‡†ç¡®ç‡ (%) ååé‡ (tok/s) ç›¸å¯¹åŠ é€Ÿ LLaDA 256 Baseline 79.3 6.7 1x Fast-dLLM 78.5 54.4 8.1x 512 Baseline 77.5 3.2 1x Fast-dLLM 77.2 35.3 11.0x Dream 256 Baseline 75.0 9.1 1x Fast-dLLM 74.8 48.2 5.3x 512 Baseline 76.0 7.7 1x Fast-dLLM 74.0 42.9 5.6x 4.3 Ablations and Analysis ä¸ºäº†æ·±å…¥ç†è§£å„ä¸ªç»„ä»¶çš„è´¡çŒ®ï¼Œè®ºæ–‡è¿›è¡Œäº†ä¸€ç³»åˆ—è¯¦ç»†çš„æ¶ˆèå®éªŒã€‚\nè¾“å…¥ä¸ç”Ÿæˆé•¿åº¦çš„å½±å“:\nå®éªŒè¯æ˜ï¼Œæ›´é•¿çš„ä¸Šä¸‹æ–‡ (prefillï¼Œå¦‚ä» 5-shot å¢åŠ åˆ° 8-shot) å’Œæ›´é•¿çš„ç”Ÿæˆé•¿åº¦ï¼Œéƒ½èƒ½æ˜¾è‘—æ”¾å¤§åŠ é€Ÿæ•ˆæœã€‚ åœ¨ 8-shot å’Œ 1024 ç”Ÿæˆé•¿åº¦çš„è®¾ç½®ä¸‹ï¼ŒDualCache å®ç°äº† 27.6x ç«¯åˆ°ç«¯åŠ é€Ÿã€‚ PrefixCache vs. DualCache:\nDualCache é€šå¸¸æ¯”åªç¼“å­˜å‰ç¼€çš„ PrefixCache å®ç°æ›´é«˜çš„åŠ é€Ÿæ¯”ï¼Œå°¤å…¶æ˜¯åœ¨é•¿åºåˆ—ç”Ÿæˆä»»åŠ¡ä¸­ ã€‚ ç¼“å­˜å—å¤§å°çš„å½±å“:\nsmall block sizeï¼šå‡†ç¡®ç‡æœ€é«˜ï¼Œä½†å› é¢‘ç¹æ›´æ–°ç¼“å­˜å¯¼è‡´å¼€é”€è¾ƒå¤§ï¼Œé€Ÿåº¦æå‡æœ‰é™ ã€‚ small block sizeï¼šé€Ÿåº¦å¿«ï¼Œä½†å¯èƒ½å› ä¸Šä¸‹æ–‡ä¸åŒ¹é…å¯¼è‡´å‡†ç¡®ç‡ä¸‹é™ ã€‚ å®éªŒå‘ç°ï¼Œå—å¤§å°ä¸º 32 æ—¶åœ¨é€Ÿåº¦å’Œç²¾åº¦ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡ã€‚ Impact of Cache Block Size on Accuracy and Throughput\nåŠ¨æ€é˜ˆå€¼ vs. å›ºå®šæ­¥æ•°ç­–ç•¥: è®ºæ–‡æå‡ºçš„ ç½®ä¿¡åº¦æ„ŸçŸ¥å¹¶è¡Œè§£ç  ç­–ç•¥ï¼Œåœ¨æ€§èƒ½ä¸ŠæŒç»­ä¼˜äºæ¯æ­¥å›ºå®šè§£ç  K ä¸ª token çš„ baseline æ–¹æ³•ã€‚ åœ¨è¾¾åˆ°ç›¸ä¼¼ç”šè‡³æ›´é«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œè¯¥åŠ¨æ€ç­–ç•¥èƒ½å®ç°æ›´é«˜çš„å¹³å‡æ¯æ­¥è§£ç  token æ•°ï¼Œä»è€Œè·å¾—æ›´é«˜çš„ååé‡ã€‚ Threshold VS Fxied Step\n5. Related Work æœ¬ç« èŠ‚å›é¡¾äº†ä¸ Fast-dLLM ç›¸å…³çš„ä¸¤ä¸ªæ ¸å¿ƒé¢†åŸŸï¼šæ‰©æ•£è¯­è¨€æ¨¡å‹çš„å‘å±•ï¼Œä»¥åŠå¤§è¯­è¨€æ¨¡å‹çš„é€šç”¨åŠ é€ŸæŠ€æœ¯ã€‚\n5.1. Diffusion LLM æ‰©æ•£æ¨¡å‹ä½œä¸ºä¸€ç§å¼ºå¤§çš„ç”ŸæˆèŒƒå¼ï¼Œæœ€åˆåœ¨å›¾åƒå’ŒéŸ³é¢‘ç­‰è¿ç»­æ•°æ®é¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸï¼Œéšåå…¶å½±å“åŠ›æ‰©å±•åˆ°äº† NLP. ç‰¹åˆ«æ˜¯ç¦»æ•£æ‰©æ•£æ¨¡å‹çš„æœ€æ–°è¿›å±•ä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€ç§æ›¿ä»£è‡ªå›å½’ (AR) èŒƒå¼çš„å¯è¡Œæ–¹æ¡ˆ ã€‚\nç†è®ºåŸºç¡€çš„å‘å±•:\nç¦»æ•£æ•°æ®çš„æ‰©æ•£æ¨¡å‹æœ€æ—©ç”± [29, 11] æ¢ç´¢ ã€‚ D3PM æå‡ºäº†ä¸€ä¸ªæ›´é€šç”¨çš„æ¡†æ¶ï¼Œå°†å‰å‘åŠ å™ªè¿‡ç¨‹å»ºæ¨¡ä¸ºç¦»æ•£çŠ¶æ€é©¬å°”å¯å¤«é“¾ï¼Œå¹¶é€šè¿‡æœ€å¤§ ELBO æ¥å­¦ä¹ åå‘è¿‡ç¨‹ã€‚ CTMC å°† D3PM æ‰©å±•åˆ°è¿ç»­æ—¶é—´è®¾å®š ã€‚ SEDD é‡‡ç”¨äº†ä¸åŒçš„æ–¹æ³•ï¼Œé€šè¿‡å‚æ•°åŒ–è¾¹é™…ä¼¼ç„¶æ¯”æ¥å­¦ä¹ åå‘è¿‡ç¨‹ ã€‚ MDMs è¿‘æœŸå—åˆ°äº†å¹¿æ³›å…³æ³¨ï¼Œå…¶ä¸­ MDLM å’Œ RADD çš„ç ”ç©¶è¡¨æ˜ï¼ŒMDMs çš„ä¸åŒå‚æ•°åŒ–æ–¹æ³•æ˜¯ç­‰ä»·çš„ï¼Œå¹¶ä¸”å…¶è®­ç»ƒç›®æ ‡å¯ä»¥è¢«ç®€åŒ– ã€‚ ä¸é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç»“åˆ: ä¸€ä¸ªå…³é”®çš„çªç ´æ˜¯å°†ç¦»æ•£æ‰©æ•£ä¸ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹æ¶æ„ç›¸ç»“åˆ ã€‚\nDiffusion-NAT [40] å°†ç¦»æ•£æ‰©æ•£çš„å»å™ªè¿‡ç¨‹ä¸ BART çš„éè‡ªå›å½’è§£ç ç›¸ç»“åˆï¼Œé€šè¿‡è¿­ä»£å¼åœ°ä¼˜åŒ–è¢«æ©ç çš„ token ï¼Œå®ç°äº†æ¯”åŒç±»è‡ªå›å½’ Transformer å¿«20å€çš„ç”Ÿæˆé€Ÿåº¦ ã€‚ LLaDA [21]ã€DiffuLLaMA [7] å’Œ Dream [36] ç­‰æ¡†æ¶å°†æ‰©æ•£æ¨¡å‹æ‰©å±•åˆ°äº† 7B å‚æ•°çš„è§„æ¨¡ï¼Œé€šè¿‡åœ¨æ‰©æ•£æ—¶é—´æ­¥ä¸Šè¿›è¡Œé€’å½’å¼çš„ token é¢„æµ‹ï¼Œå±•ç°äº†ä¸ LLaMA3 ç­‰ä¸»æµè‡ªå›å½’æ¨¡å‹ç›¸åŒ¹æ•Œçš„æ€§èƒ½ ã€‚ 5.2. LLM Acceleration KV Cache ç”±äº LLaDA ç­‰æ‰©æ•£è¯­è¨€æ¨¡å‹é‡‡ç”¨çš„æ˜¯ full attentionï¼Œå°† KV ç¼“å­˜ç›´æ¥åº”ç”¨äºè¿™ç±»æ¨¡å‹å¹¶éæ˜“äº‹ã€‚ ä¸€ç¯‡ç›¸å…³çš„ç ”ç©¶ Block diffusion é€šè¿‡åˆ†å—ç”Ÿæˆ (block-by-block) çš„æ–¹å¼ï¼Œå…‹æœäº†å…ˆå‰æ‰©æ•£è¯­è¨€æ¨¡å‹çš„å±€é™ï¼Œä½¿å¾—ç¼“å­˜å’Œå¤ç”¨å…ˆå‰å·²è§£ç å—çš„é”®å’Œå€¼æˆä¸ºå¯èƒ½ ã€‚\nNon-Autoregressive Generation éè‡ªå›å½’ (NAR) ç”Ÿæˆæ ‡å¿—ç€ä¸€ç§æ ¹æœ¬æ€§çš„è½¬å˜ï¼Œå®ƒé€šè¿‡åŒæ—¶ç”Ÿæˆå¤šä¸ª token æ¥æ˜¾è‘—åŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚NAR æ–¹æ³•æœ€åˆè¢«ç”¨äºç¥ç»æœºå™¨ç¿»è¯‘ï¼Œç°å·²æ‰©å±•åˆ°è¯­æ³•çº é”™ã€æ–‡æœ¬æ‘˜è¦å’Œå¯¹è¯ç³»ç»Ÿç­‰å¤šç§ä»»åŠ¡ ã€‚ å°½ç®¡ NAR åœ¨é€Ÿåº¦ä¸Šä¼˜åŠ¿å·¨å¤§ï¼Œä½†å®ƒé€šå¸¸ä»¥ç‰ºç‰²ä¸€å®šçš„ç”Ÿæˆè´¨é‡ä¸ºä»£ä»·ã€‚æ‰©æ•£è¯­è¨€æ¨¡å‹æ˜¯ NAR é¢†åŸŸä¸€ä¸ªæ–°å…´çš„èŒƒå¼ï¼›ç„¶è€Œï¼Œå…ˆå‰çš„å·¥ä½œ (å¦‚ LLaDA) åœ¨å®è·µä¸­éš¾ä»¥å®ç°é¢„æœŸçš„åŠ é€Ÿï¼Œå› ä¸ºå¹¶è¡Œç”Ÿæˆä¼šå¯¼è‡´è¾“å‡ºè´¨é‡æ˜¾è‘—ä¸‹é™ã€‚\nWeakness è¿‘ä¼¼ç¼“å­˜çš„è¯¯å·®ç´¯ç§¯æ•ˆåº”ï¼šè®ºæ–‡è¯æ˜äº†åœ¨ç›¸é‚»æ­¥éª¤ä¸­ï¼ŒKVæ¿€æ´»å€¼çš„å·®å¼‚å¾ˆå° ã€‚ä½†éšç€ç”Ÿæˆå—çš„å¢å¤šï¼Œè¿™ç§â€œè¿‘ä¼¼â€å¸¦æ¥çš„å¾®å°è¯¯å·®æ˜¯å¦ä¼šç´¯ç§¯ï¼Œå¹¶åœ¨ç”Ÿæˆéå¸¸é•¿çš„æ–‡æœ¬ (å¦‚æ•°ä¸‡ token çš„å°è¯´) æ—¶å¯¼è‡´è¯­ä¹‰æ¼‚ç§»æˆ–ä¸€è‡´æ€§ä¸‹é™ï¼Ÿè®ºæ–‡çš„æœ€é•¿æµ‹è¯•åºåˆ—ä¸º1024 ï¼Œå¯¹äºæ›´é•¿çš„åºåˆ—ï¼Œå…¶é²æ£’æ€§æœ‰å¾…è¿›ä¸€æ­¥éªŒè¯ã€‚\nå¯¹æ¨¡å‹èƒ½åŠ›çš„ä¾èµ–ï¼šâ€œç½®ä¿¡åº¦æ„ŸçŸ¥è§£ç â€ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œéšå¼åœ°ä¾èµ–äºæ¨¡å‹æœ¬èº«å…·æœ‰è‰¯å¥½çš„â€œæ ¡å‡†åº¦â€ (calibration) ï¼Œå³æ¨¡å‹çš„ç½®ä¿¡åº¦èƒ½å¤ŸçœŸå®åæ˜ å…¶é¢„æµ‹çš„æ­£ç¡®æ€§ã€‚å¦‚æœæ¨¡å‹æœ¬èº«â€œè¿‡äºè‡ªä¿¡â€æˆ–â€œä¸å¤Ÿè‡ªä¿¡â€ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¯¥ç­–ç•¥æ•ˆæœä¸ä½³ã€‚è®ºæ–‡æ²¡æœ‰å¯¹æ‰€ç”¨æ¨¡å‹çš„æ ¡å‡†åº¦è¿›è¡Œåˆ†æã€‚ å®šç†ä¸€çš„ç†è®ºä¸å®è·µå·®è·ï¼šè®ºæ–‡å¦è¯šåœ°æŒ‡å‡ºäº†å®šç†ä¸€çš„å±€é™æ€§\nIn practice, while MDM may not strictly satisfy this property, its behavior typically offers a close approximation.\nç†è®ºè¯æ˜å‡è®¾äº†ä¸€ä¸ªâ€œç†æƒ³çš„â€è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œè€ŒçœŸå®æ¨¡å‹æ˜¯å¦ä»¥åŠåœ¨å¤šå¤§ç¨‹åº¦ä¸Šç¬¦åˆè¿™ä¸ªç†æƒ³å‡è®¾ï¼Œæ˜¯ä¸€ä¸ªéœ€è¦è¿›ä¸€æ­¥æ¢ç©¶çš„é—®é¢˜ã€‚ç†è®ºå’Œå®è·µä¹‹é—´çš„å·®è·å¯èƒ½åœ¨æŸäº›åˆé’»çš„ (adversarial) æˆ–åˆ†å¸ƒå¤– (Out-of-Distribution) çš„åœºæ™¯ä¸‹è¢«æ”¾å¤§ã€‚ è¶…å‚æ•°çš„æ•æ„Ÿæ€§ä¸è°ƒä¼˜æˆæœ¬ï¼šå°½ç®¡è®ºæ–‡åˆ†æäº†å—å¤§å°å’Œé˜ˆå€¼çš„å½±å“ï¼Œä½†å¹¶æœªæä¾›ä¸€å¥—ç³»ç»Ÿæ€§çš„æ–¹æ³•æ¥ä¸ºæ–°æ¨¡å‹æˆ–æ–°ä»»åŠ¡é€‰æ‹©æœ€ä½³è¶…å‚æ•°ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™å¯èƒ½æ„å‘³ç€éœ€è¦ä¸ºæ¯ä¸ªç‰¹å®šç”¨ä¾‹è¿›è¡Œæˆæœ¬ä¸è²çš„ç½‘æ ¼æœç´¢ (grid search) ï¼Œå¢åŠ äº†æ–¹æ³•çš„åº”ç”¨é—¨æ§›ã€‚ è¯„ä¼°ç»´åº¦çš„å±€é™æ€§ï¼šè®ºæ–‡ä¸»è¦ä½¿ç”¨äº†åŸºäºå‡†ç¡®ç‡çš„åŸºå‡†æµ‹è¯•ã€‚ä½†åœ¨å¼€æ”¾å¼ç”Ÿæˆã€å¯¹è¯ç­‰ä»»åŠ¡ä¸­ï¼Œè¯„ä¼°æŒ‡æ ‡ (å¦‚æµç•…åº¦ã€ä¸€è‡´æ€§ã€å¤šæ ·æ€§) æ›´ä¸ºå¤æ‚ã€‚Fast-dLLMæ˜¯å¦ä¼šåœ¨è¿™äº›â€œè½¯â€æŒ‡æ ‡ä¸Šå¼•å…¥ä¸æ˜“å¯Ÿè§‰çš„è´Ÿé¢å½±å“ï¼Œéœ€è¦æ›´å…¨é¢çš„è¯„ä¼°ã€‚\nSource Code åˆå§‹åŒ–:\nå‡½æ•°é¦–å…ˆåˆ›å»ºä¸€ä¸ªå¼ é‡ xï¼Œå…¶é•¿åº¦ä¸ºâ€œæç¤ºè¯é•¿åº¦ + å¾…ç”Ÿæˆé•¿åº¦â€ã€‚ æç¤ºè¯ (prompt) éƒ¨åˆ†è¢«å¡«å……åˆ° x çš„å¼€å¤´ï¼Œè€Œæ‰€æœ‰å¾…ç”Ÿæˆçš„ä½ç½®åˆ™è¢«åˆå§‹åŒ–ä¸ºç‰¹æ®Šçš„æ©ç æ ‡è®° [MASK] (mask_id) ã€‚ å°†æ€»ç”Ÿæˆä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå— (num_blocks) ï¼Œå¹¶ä¸ºæ¯ä¸ªå—åˆ†é…å›ºå®šçš„è§£ç æ­¥æ•° (steps) åˆ†å—ç”Ÿæˆ (å¤–å±‚å¾ªç¯):\nä»£ç ä»¥å—ä¸ºå•ä½è¿›è¡Œå¾ªç¯ï¼Œä¾æ¬¡ç”Ÿæˆæ¯ä¸ªæ–‡æœ¬å—ã€‚ å¤„ç†å•ä¸ªå— (å†…å±‚å¾ªç¯ä¸ç¼“å­˜æœºåˆ¶):\næ­¥éª¤ A: å…¨å±€ç¼“å­˜åˆå§‹åŒ– (ç¬¬ä¸€æ¬¡æ¨¡å‹è°ƒç”¨)\nåœ¨å¤„ç†ä¸€ä¸ªæ–°å—çš„å¼€å§‹ï¼Œå®ƒé¦–å…ˆå°†æ•´ä¸ªåºåˆ— x (åŒ…å«æç¤ºè¯ã€å·²ç”Ÿæˆçš„å—å’Œæ‰€æœ‰æœªæ¥å¾…ç”Ÿæˆçš„[MASK]å—) å®Œæ•´åœ°è¾“å…¥æ¨¡å‹ã€‚ è¿™æ¬¡è°ƒç”¨çš„ä¸»è¦ç›®çš„æ˜¯è®¡ç®—å¹¶å­˜å‚¨æ•´ä¸ªåºåˆ—çš„é”®å€¼å¯¹ç¼“å­˜ (past_key_values). è¿™æ˜¯ä¸€ä¸ªå…¨å±€ç¼“å­˜ã€‚ ç„¶åï¼Œæ¨¡å‹æ ¹æ®è¾“å‡ºçš„ logitsï¼Œä½¿ç”¨ get_transfer_index å‡½æ•°å†³å®šåœ¨å½“å‰å—ä¸­ï¼Œå“ªäº› [MASK] æ ‡è®°åº”è¯¥è¢«ä¼˜å…ˆæ›¿æ¢æ‰ (ä¾‹å¦‚ï¼ŒåŸºäºæœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹) ï¼Œå¹¶ç”¨é¢„æµ‹å‡ºçš„ token (token) è¿›è¡Œå¡«å……ã€‚è¿™ä¸ªè¿‡ç¨‹åªå‘ç”Ÿä¸€æ¬¡ã€‚ æ­¥éª¤ B: å—å†…è¿­ä»£ä¼˜åŒ– (ç¬¬äºŒæ¬¡åŠåç»­æ¨¡å‹è°ƒç”¨)\næ¥ä¸‹æ¥ï¼Œè¿›å…¥ä¸€ä¸ª while å¾ªç¯ï¼Œå¯¹å½“å‰å—è¿›è¡Œè¿­ä»£å¼åœ°â€œç²¾ç‚¼â€ï¼Œç›´åˆ°è¿™ä¸ªå—ä¸­æ‰€æœ‰çš„ [MASK] æ ‡è®°éƒ½è¢«å¡«æ»¡ã€‚ æ ¸å¿ƒä¼˜åŒ–ç‚¹ï¼šåœ¨è¿™æ¬¡åŠåç»­çš„æ¨¡å‹è°ƒç”¨ä¸­ï¼Œä¸å†éœ€è¦è¾“å…¥æ•´ä¸ªåºåˆ—ã€‚å®ƒåªå°†å½“å‰å—çš„å¼ é‡ (x[:, current_block_start:current_block_end]) ä½œä¸ºè¾“å…¥ï¼Œå¹¶é‡ç”¨æ­¥éª¤ A ä¸­ç”Ÿæˆçš„å…¨å±€ç¼“å­˜ past_key_valuesã€‚ è¿™å°±æ˜¯ dual cache: ä¸€ä¸ªä¸ºä¸Šä¸‹æ–‡ (æç¤ºè¯+ä¹‹å‰å—) å‡†å¤‡çš„ã€åŸºæœ¬ä¸å˜çš„é™æ€ç¼“å­˜ï¼Œå’Œä¸€ä¸ªä¸ºå½“å‰å—æœåŠ¡çš„ã€åŠ¨æ€æ›´æ–°çš„ç¼“å­˜ã€‚è¿™é¿å…äº†å¯¹ä¸Šä¸‹æ–‡éƒ¨åˆ†çš„é‡å¤è®¡ç®—ï¼Œæå¤§åœ°æå‡äº†æ•ˆç‡ã€‚ æ¨¡å‹ä¼šä¸ºå½“å‰å—ä¸­å‰©ä½™çš„ [MASK] ä½ç½®ç”Ÿæˆæ–°çš„é¢„æµ‹ï¼Œå¹¶æ ¹æ®ç­–ç•¥ç»§ç»­å¡«å……ã€‚ è¿™ä¸ªè¿­ä»£è¿‡ç¨‹ä¼šæŒç»­è¿›è¡Œï¼Œç›´åˆ°å½“å‰å—ä¸å†æœ‰ [MASK] æ ‡è®°ä¸ºæ­¢ã€‚ å®Œæˆä¸è¿”å›:\nå½“æ‰€æœ‰å—éƒ½å¤„ç†å®Œæ¯•åï¼Œå‡½æ•°è¿”å›æœ€ç»ˆç”Ÿæˆçš„å®Œæ•´åºåˆ— x å’Œæ€»çš„æ¨¡å‹å‰å‘ä¼ æ’­æ¬¡æ•° nfe (ä¸€ä¸ªè¡¡é‡è®¡ç®—æˆæœ¬çš„æŒ‡æ ‡) ã€‚ import torch @torch.no_grad() def generate_with_dual_cache(model, prompt, steps=128, gen_length=128, block_length=128, temperature=0., remasking=\u0026#39;low_confidence\u0026#39;, mask_id=126336, threshold=None): \u0026#39;\u0026#39;\u0026#39; Generates text using a non-autoregressive, block-wise decoding strategy with a dual-cache mechanism. Args: model: The mask predictor model. prompt: A tensor of shape (1, L) representing the input prompt. steps: Total number of sampling/refinement steps for the entire generation. gen_length: The desired length of the generated text. block_length: The size of each block to be generated in parallel. gen_length must be divisible by this. temperature: Sampling temperature for token selection. 0 means greedy decoding. remasking: The strategy for choosing which masks to fill (\u0026#39;low_confidence\u0026#39; or \u0026#39;random\u0026#39;). mask_id: The token ID for the [MASK] token. \u0026#39;\u0026#39;\u0026#39; # Create the full tensor \u0026#39;x\u0026#39; with the prompt and space for generation, initialized with the mask token. x = torch.full((1, prompt.shape[1] + gen_length), mask_id, dtype=torch.long).to(model.device) # Copy the prompt into the beginning of the tensor \u0026#39;x\u0026#39;. x[:, :prompt.shape[1]] = prompt.clone() # Ensure that the generation length can be evenly divided into blocks. assert gen_length % block_length == 0 num_blocks = gen_length // block_length # Distribute the total steps among the blocks. assert steps % num_blocks == 0 steps_per_block = steps // num_blocks # nfe: Number of Forward-pass Evaluations. A counter for computational cost. nfe = 0 # Outer loop: iterate through each block to be generated. for num_block in range(num_blocks): # Define the start and end positions of the current block within the full tensor \u0026#39;x\u0026#39;. current_block_start = prompt.shape[1] + num_block * block_length current_block_end = current_block_start + block_length # Find the indices of mask tokens within the current block. block_mask_index = (x[:, current_block_start:current_block_end] == mask_id) # Determine the number of tokens to fill at each refinement step for this block. num_transfer_tokens = get_num_transfer_tokens(block_mask_index, steps_per_block) # --- First Model Call: Initialize Global Cache --- # A single forward pass on the ENTIRE sequence (prompt + all masked blocks) to pre-calculate # the Key-Value cache for all tokens. This is the \u0026#34;global\u0026#34; cache. output = model(x, use_cache=True) past_key_values = output.past_key_values # Identify all mask tokens up to the end of the current block. mask_index = (x == mask_id) # Ignore masks that are in future blocks for this step\u0026#39;s prediction. mask_index[:, current_block_end:] = 0 # Select which tokens to predict and fill in this initial step for the current block. x0, transfer_index = get_transfer_index(output.logits, temperature, remasking, mask_index, x, num_transfer_tokens[:, 0] if threshold is None else None, threshold) # Update the tensor \u0026#39;x\u0026#39; by filling the selected mask positions with the predicted tokens. x[transfer_index] = x0[transfer_index] nfe += 1 # Increment the forward-pass counter. i = 1 # Counter for refinement steps within the block. # A boolean mask indicating the position of the current block, used to update the cache efficiently. replace_position = torch.zeros_like(x, dtype=torch.bool) replace_position[:, current_block_start:current_block_end] = 1 # --- Inner Loop: Iterative Refinement of the Current Block --- # This loop continues until all masks in the current block are filled. while True: nfe += 1 # Increment the forward-pass counter for each refinement step. # Find the remaining masks ONLY within the current block. mask_index_block = (x[:, current_block_start:current_block_end] == mask_id) # --- Efficient Model Call using Dual Cache --- # Instead of passing the whole sequence, only pass the CURRENT BLOCK\u0026#39;s tokens. # Reuse the \u0026#39;past_key_values\u0026#39; (global cache) computed earlier. The model internally # uses \u0026#39;replace_position\u0026#39; to update the cache only at the current block\u0026#39;s location. # This is the \u0026#34;dual cache\u0026#34; trick, avoiding re-computation for the prompt and previous blocks. logits = model(x[:, current_block_start:current_block_end], past_key_values=past_key_values, use_cache=True, replace_position=replace_position).logits # Select which of the remaining masks to fill in this refinement step. x0, transfer_index = get_transfer_index(logits, temperature, remasking, mask_index_block, x[:, current_block_start:current_block_end], num_transfer_tokens[:, i] if threshold is None else None, threshold) # Update the current block with the newly predicted tokens. x[:, current_block_start:current_block_end][transfer_index] = x0[transfer_index] # If there are no more masks in the current block, exit the refinement loop. if (x[:, current_block_start:current_block_end] == mask_id).sum() == 0: break i += 1 # Move to the next refinement step. # Return the fully generated sequence and the total number of model evaluations. return x, nfe ","permalink":"http://localhost:1313/blogs/fast-dllm/","summary":"Paper Reading of Fast-dLLM","title":"Fast-dLLM"},{"content":"Introduction LLM ä¸»è¦çš„æ€æƒ³æ˜¯ generative modeling çš„æ€æƒ³æ˜¯é€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ¥ä¼˜åŒ–æ¨¡å‹çš„åˆ†å¸ƒ $\\log p_\\theta(\\cdot)$ æ¥é€¼è¿‘æ•°æ®çš„åˆ†å¸ƒ $\\log p_{\\text{data}}(\\cdot)$ $$\r\\underbrace{\\max_\\theta\\mathbb{E}_{p_{\\text{data}}(x)}\\log p_\\theta(x)\\Leftrightarrow\\min_\\theta\\operatorname{KL}(p_{\\text{data}}(x)||p_\\theta(x)).}_{\\text{Generative modeling principles}} \\tag{1}\r$$å½“å‰ï¼Œå‡ ä¹æ‰€æœ‰æˆ‘ä»¬ç†ŸçŸ¥çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä»GPTç³»åˆ—åˆ°LLaMAç³»åˆ—ï¼Œéƒ½åŸºäºautoregressice modeling æ¥å®ç°ã€‚è¿™ç§èŒƒå¼çš„æ ¸å¿ƒæ˜¯ next-token prediction ï¼Œå³æ ¹æ®å·²ç»ç”Ÿæˆçš„æ–‡æœ¬åºåˆ—ï¼Œé€ toekn åœ°é¢„æµ‹ä¸‹ä¸€ä¸ªæœ€æœ‰å¯èƒ½å‡ºç°çš„ token.\n$$\r\\underbrace{p_\\theta(x)=p_\\theta(x^1)\\prod_{i=2}^Lp_\\theta(x^i\\mid x^1,\\ldots,x^{i-1})}_{\\text{Autoregressive formulation}} \\tag{2}\r$$è¿™ç§å•å‘ã€é¡ºåºçš„ç”Ÿæˆæ–¹å¼åœ¨å¤„ç†éœ€è¦åŒå‘æ¨ç†çš„ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œä¸€ä¸ªå…¸å‹çš„ä¾‹å­å°±æ˜¯ Reversal Curse â€”â€”æ¨¡å‹çŸ¥é“ A is Bï¼Œå´å¾€å¾€æ— æ³•æ¨æ–­å‡º B is A.\nLLM èƒ½åŠ›çš„æ ¸å¿ƒåŸºçŸ³æ˜¯ç”Ÿæˆå¼å»ºæ¨¡åŸç†æœ¬èº«ï¼Œå³é€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡è®©æ¨¡å‹å­¦ä¹ çœŸå®ä¸–ç•Œçš„æ•°æ®åˆ†å¸ƒ ï¼Œè€Œéè‡ªå›å½’è¿™ä¸€å…·ä½“çš„å®ç°å½¢å¼ã€‚\nIt is the generative modeling principles (i.e., Eq. (1)), rather than the autoregressive formulation (i.e., Eq. (2)) itself, that fundamentally underpin the essential properties of LLMs.\nå¤§è¯­è¨€æ¨¡å‹çš„å¯æ‰©å±•æ€§ (scalability) â€”â€”å³æ¨¡å‹è¶Šå¤§ã€æ•°æ®è¶Šå¤šã€æ•ˆæœè¶Šå¥½çš„ç‰¹æ€§â€”â€”å¹¶éè‡ªå›å½’æ¨¡å‹æ‰€ç‹¬æœ‰ ã€‚ç›¸åï¼Œè¿™ç§å¯æ‰©å±•æ€§æ¥æºäºæ›´åº•å±‚çš„ç”Ÿæˆå¼å»ºæ¨¡åŸç†ï¼Œè€Œè¿™äº›åŸç†æ°å¥½ä¿è¯äº†fisher consistency1\ninstruction-following å’Œ in-context learning2 å¹¶éè‡ªå›å½’æ¨¡å‹æ‰€ç‹¬æœ‰ï¼Œè€Œæ˜¯æ‰€æœ‰è®¾è®¡å¾—å½“çš„æ¡ä»¶ç”Ÿæˆæ¨¡å‹ (conditional generative models) åœ¨å¤„ç†ç»“æ„åŒ–è¯­è¨€ä»»åŠ¡æ—¶éƒ½åº”å…·å¤‡çš„å†…åœ¨å±æ€§ ã€‚\nå› æ­¤ä½œè€…æå‡ºäº†LLaDA (Large Language Diffusion with mAsking)ï¼Œä¸€ä¸ªä»é›¶å¼€å§‹è®­ç»ƒçš„ã€å‚æ•°é‡è¾¾åˆ° 8B çš„æ‰©æ•£è¯­è¨€æ¨¡å‹ã€‚\nZero\u0026amp;Few-Shot Benchmarks\nLLaDA ä½¿ç”¨äº† Masked Diffusion Model (MDM)ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†ç¦»æ•£éšæœºæ©è”½è¿‡ç¨‹ï¼Œå¹¶è®­ç»ƒäº†ä¸€ä¸ªæ©ç é¢„æµ‹å™¨æ¥è¿‘ä¼¼å…¶åå‘è¿‡ç¨‹ã€‚\n2 Approach A Conceptual Overview of LLaDA\n2.1 Probabilistic Formulation ä¸å…¬å¼(2)ä¸­çš„è‡ªå›å½’æ¨¡å‹ä¸åŒï¼ŒLLaDAé€šè¿‡å‰å‘è¿‡ç¨‹ (forward process) å’Œ åå‘è¿‡ç¨‹ (reverse process) æ¥å®šä¹‰æ¨¡å‹åˆ†å¸ƒ $p_{\\theta}(x_{0})$ã€‚\nForward Process é€æ­¥åœ°ã€ç‹¬ç«‹åœ° mask $x_{0}$ ä¸­çš„ tokenï¼Œç›´åˆ°åœ¨ $t=1$ æ—¶åºåˆ—è¢«å®Œå…¨ mask.\nç»™å®š $x_{0}$ æ—¶ $x_{t}$ çš„æ¡ä»¶åˆ†å¸ƒå¯ä»¥è¢«åˆ†è§£ä¸ºï¼š\n$$\rq_{t|0}(x_{t}|x_{0}) = \\prod_{i=1}^{L} q_{t|0}(x_{t}^{i}|x_{0}^{i})\r$$å¯¹äº $t \\in (0,1)$ï¼Œåºåˆ— $x_{t}$ æ˜¯éƒ¨åˆ†è¢«æ©ç çš„ï¼Œå…¶ä¸­æ¯ä¸ª token æœ‰ $t$ çš„æ¦‚ç‡è¢«maskï¼Œæˆ–æœ‰ $1-t$ çš„æ¦‚ç‡ä¿æŒä¸å˜ã€‚\n$$\rq_{t|0}(x_{t}^{i}|x_{0}^{i}) = \\begin{cases} 1-t, \u0026 x_{t}^{i} = x_{0}^{i} \\\\ t, \u0026 x_{t}^{i} = M \\end{cases}\r$$å…¶ä¸­ M è¡¨ç¤ºæ©ç  token. ç›´è§‚ä¸Šï¼Œæ¯ä¸ª token è¦ä¹ˆä¿æŒä¸å˜ï¼Œè¦ä¹ˆè¢«æ©ç ï¼Œè¢«æ©ç çš„æ¦‚ç‡éšç€ t ä» 0 åˆ° 1 çº¿æ€§å¢åŠ ã€‚åœ¨ $t=1$ æ—¶ï¼Œæ‰€æœ‰ token éƒ½è¢« mask. çº¿æ€§å˜åŒ–çš„è¢«æ©ç æ¦‚ç‡å’ŒåŸå…ˆæ‰©æ•£æ¨¡å‹çš„åŠ å™ªæµç¨‹ä¸ä¸€æ ·ï¼Œæ˜¯åŸºäºæ–‡æœ¬ä¿¡æ¯å’Œ token é•¿åº¦æˆæ­£æ¯”çš„å‡è®¾ã€‚\nReverse Process åå‘è¿‡ç¨‹åˆ™é€šè¿‡åœ¨ $t=1\\rightarrow 0$ ä»å®Œå…¨è¢«æ©ç çš„åºåˆ—ä¸­ç”Ÿæˆæ–°æ•°æ®ã€‚\nå¯¹äº $0 \\le s \u003c t \\le 1$ï¼Œåå‘è¿‡ç¨‹çš„æ¡ä»¶åˆ†å¸ƒåˆ†è§£ä¸ºï¼š\n$$\rq_{s|t}(x_{s}|x_{t}) = \\prod_{i=1}^{L} q_{s|t}(x_{s}^{i}|x_{t})\r$$å…¶ä¸­æ¯ä¸ª token çš„æ¡ä»¶åˆ†å¸ƒä¸ºï¼š\n$$\rq_{s|t}(x_{s}^{i}|x_{t}^{i}) = \\begin{cases} 1, \u0026 x_{t}^{i} \\ne M, x_{s}^{i} = x_{t}^{i} \\\\ \\frac{s}{t}, \u0026 x_{t}^{i} = M, x_{s}^{i} = M \\\\ \\frac{t-s}{t}q_{0|t}(x_{s}^{i}|x_{t}), \u0026 x_{t}^{i} = M, x_{s}^{i} \\ne M \\\\ 0, \u0026 \\text{otherwise} \\end{cases}\r$$éœ€è¦ä¼°è®¡çš„å…³é”®å‡½æ•°æ˜¯æ¡ä»¶åˆ†å¸ƒ $q_{0|t}(x_{s}^{i}|x_{t})$ï¼Œå®ƒåœ¨è¾“å…¥ $x_{t}$ ä¸­å¯¹åº”ä½ç½®è¢«æ©ç çš„æƒ…å†µä¸‹ï¼Œé¢„æµ‹å‡ºåŸå§‹çš„ token. ç±»ä¼¼äºè¿ç»­æ‰©æ•£æ¨¡å‹ä¸­çš„æ•°æ®é¢„æµ‹å½¢å¼ã€‚å¦‚ (Ou et al., 2024) æ‰€è¯æ˜ï¼Œå¯ä»¥æ¨å¯¼å‡ºä¸€ä¸ªç­‰ä»·ä½†æ— æ—¶é—´ä¾èµ–çš„å‚æ•°åŒ–å½¢å¼\n$$\rq_{0|t}(x_s^i|x_t)=p_{\\text{data}}(x_0^i|x_t^\\text{UM}),\\quad\\forall i\\text{ such that }x_t^i=\\mathbf{M}\r$$å…¶ä¸­ $x_{t}^{\\text{UM}}$ è¡¨ç¤º $x_{t}$ ä¸­æœªè¢«æ©ç  token çš„é›†åˆï¼Œå®ƒä¸åŸå§‹æ•°æ® $x_{0}$ ä¸­å¯¹åº”çš„ token ç›¸åŒï¼Œå› ä¸ºæœªæ©ç çš„ token ä»…ç”± $x_{0}$ å†³å®šä¸”ä¸æ—¶é—´ t æ— å…³ ã€‚ç›´è§‚ä¸Šï¼Œè¿™æ„å‘³ç€ä¼°è®¡æ•°æ®é¢„æµ‹å‡½æ•°ç­‰åŒäºä¼°è®¡åœ¨å¹²å‡€æ•°æ®ä¸Šçš„æ¡ä»¶åˆ†å¸ƒï¼Œè€Œåè€…æ˜¯æ—¶ä¸å˜çš„ã€‚å› æ­¤ï¼Œæ—¶é—´ t ä¸éœ€è¦ä½œä¸ºè¾“å…¥æä¾›ç»™å‚æ•°åŒ–æ¨¡å‹ ã€‚\nå°½ç®¡ MDM çš„æ¨å¯¼è¿‡ç¨‹ä¸ç®€å•ï¼Œä½†å…¶å®ç°æ˜¯ç›´æ¥çš„ã€‚æˆ‘ä»¬é¦–å…ˆå¼•å…¥æ©ç é¢„æµ‹å™¨ï¼Œä¸€ä¸ªå‚æ•°åŒ–æ¨¡å‹ $p_{\\theta}(\\cdot|x_{t})$ (ä¾‹å¦‚ä¸€ä¸ªæ²¡æœ‰å› æœæ©ç çš„ Transformer)ï¼Œå®ƒå°†ä»»æ„ t æ—¶åˆ»çš„ $x_{t}$ ä½œä¸ºè¾“å…¥ï¼Œå¹¶åŒæ—¶é¢„æµ‹æ‰€æœ‰è¢« mask çš„ token. ç„¶åï¼Œæˆ‘ä»¬å¦‚ä¸‹å®šä¹‰æ¨¡å‹åˆ†å¸ƒ $p_{\\theta}(x_{0})$ï¼šä»ä¸€ä¸ªè¢«å®Œå…¨ mask åºåˆ—çš„ $x_{1}$ å¼€å§‹ï¼Œä» $t=1$ åˆ° 0 æ¨¡æ‹Ÿä¸€ä¸ªç”± $p_{\\theta}(\\cdot|x_{t})$ å‚æ•°åŒ–çš„è¿‘ä¼¼åå‘è¿‡ç¨‹ã€‚åœ¨ $t=0$ æ—¶åˆ»æ¨å¯¼å‡ºçš„è¾¹ç¼˜åˆ†å¸ƒå³ä»£è¡¨äº†æ¨¡å‹åˆ†å¸ƒ $p_{\\theta}(x_{0})$ ã€‚\næ©ç é¢„æµ‹å™¨å°† $x_{t}$ ä½œä¸ºè¾“å…¥å¹¶åŒæ—¶é¢„æµ‹æ‰€æœ‰è¢«æ©ç çš„ token (è¡¨ç¤ºä¸º M). å®ƒé€šè¿‡ä¸€ä¸ªä»…åœ¨è¢«æ©ç  token ä¸Šè®¡ç®—çš„äº¤å‰ç†µæŸå¤±è¿›è¡Œè®­ç»ƒï¼š\n$$\r\\mathcal{L}(\\theta)\\triangleq-\\mathbb{E}_{t,x_{0},x_{t}}[\\frac{1}{t}\\sum_{i=1}^{L}I[x_{t}^{i}=M]log~p_{\\theta}(x_{0}^{i}|x_{t})], \\tag{3}\r$$å…¶ä¸­ï¼Œ$x_{0}$ ä»è®­ç»ƒæ•°æ®ä¸­é‡‡æ ·ï¼Œ$t$ ä»[0, 1]ä¸­å‡åŒ€é‡‡æ ·Notably, LLaDA employs a masking ratio that varies randomly between 0 and 1 while masked language models (Devlin, 2018) use a fixed ratio.\rï¼Œ$x_{t}$ ä»å‰å‘è¿‡ç¨‹ä¸­é‡‡æ ·ã€‚æŒ‡ç¤ºå‡½æ•° $I[\\cdot]$ ç¡®ä¿æŸå¤±ä»…é’ˆå¯¹è¢«æ©ç çš„ token è®¡ç®—ã€‚ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œä¾¿å¯ä»¥æ¨¡æ‹Ÿä¸€ä¸ªç”±è¯¥æ©ç é¢„æµ‹å™¨å‚æ•°åŒ–çš„åå‘è¿‡ç¨‹ï¼ˆè¯¦è§2.4èŠ‚ï¼‰ï¼Œå¹¶å°†æ¨¡å‹åˆ†å¸ƒ $p_{\\theta}(x_{0})$ å®šä¹‰ä¸ºè¯¥è¿‡ç¨‹çš„è¾¹ç¼˜åˆ†å¸ƒã€‚\nå…¬å¼(3)å·²è¢«è¯æ˜æ˜¯æ¨¡å‹åˆ†å¸ƒè´Ÿå¯¹æ•°ä¼¼ç„¶çš„ä¸Šç•Œ\n$$\r-\\mathbb{E}_{p_{\\text{data}}(x_{0})}\\left[\\log p_{\\theta}(x_{0})\\right]\\leq\\mathcal{L}(\\theta) \\tag{4}\r$$è¯¥æ–¹æ³•é€šè¿‡åœ¨æ­£å‘è¿‡ç¨‹ä¸­é€æ­¥å±è”½ token å¹¶åœ¨åå‘è¿‡ç¨‹ä¸­å­¦ä¹ æ¢å¤æ•°æ®åˆ†å¸ƒæ¥è®­ç»ƒç”Ÿæˆæ¨¡å‹ï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨ï¼ˆè¿‘ä¼¼ï¼‰æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ¡†æ¶ä¸‹ã€‚\nPretraining LLaDA 8B æ¨¡å‹åœ¨ä¸€ä¸ªåŒ…å« 2.3T tokens çš„é«˜è´¨é‡ã€å¤šæºæ•°æ®é›†ä¸Šä»é›¶å¼€å§‹è¿›è¡Œé¢„è®­ç»ƒã€‚è¯¥æ•°æ®é›†è¦†ç›–äº†é€šç”¨æ–‡æœ¬ã€ä»£ç ã€æ•°å­¦å’Œå¤šè¯­è¨€å†…å®¹ ã€‚\nè®­ç»ƒæ€»å…±æ¶ˆè€—äº† 0.13M H800 GPU hours. è®­ç»ƒåºåˆ—é•¿åº¦å›ºå®šä¸º4096. å…¶æ ¸å¿ƒè®­ç»ƒæ­¥éª¤æ˜¯ï¼šå¯¹æ¯ä¸ªåºåˆ—éšæœºé‡‡æ ·ä¸€ä¸ªæ©ç ç‡ tï¼Œå¹¶ç‹¬ç«‹åœ°ä»¥è¯¥æ¦‚ç‡æ©ç æ¯ä¸ª tokenï¼Œç„¶åè®©æ¨¡å‹å»é¢„æµ‹è¢«æ©ç çš„éƒ¨åˆ† ã€‚\næ¶æ„è°ƒæ•´ ç›¸è¾ƒäºLLaMA3 8Bï¼ŒLLaDA 8Båœ¨æ¶æ„ä¸Šåšäº†ä¸€äº›å¿…è¦è°ƒæ•´ï¼Œå¦‚ä½¿ç”¨æ ‡å‡†çš„ MHA è€Œé GQAï¼Œå¹¶ç›¸åº”åœ°è°ƒæ•´äº† FFN çš„ç»´åº¦ä»¥ä¿æŒæ¨¡å‹æ€»å‚æ•°é‡ç›¸å½“ ã€‚\nä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡ è®­ç»ƒä½¿ç”¨äº† AdamW ä¼˜åŒ–å™¨å’Œä¸€ä¸ªç‰¹æ®Šçš„ Warmup-Stable-Decay å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ã€‚æ•´ä¸ª8Bæ¨¡å‹çš„è®­ç»ƒå®éªŒåªæ‰§è¡Œäº†ä¸€æ¬¡ï¼Œæ²¡æœ‰è¿›è¡Œä»»ä½•è¶…å‚æ•°è°ƒä¼˜ã€‚\nOur ARM Baseline 1B LLaDA IB Our ARM Baseline 7B LLaDA 8B LLaMA3 8B Layers 22 22 28 32 32 Model dimension 2048 2048 4096 4096 4096 Attention heads 32 32 32 32 32 Vocabulary size 126,464 126,464 126,464 126.464 128,000 FFN dimension 5634 5634 13.440 12,288 14,336 Key/Value heads 4 4 8 32 8 Total parameters 1.49 B 1.49 B 6.83 B 8.02 B 8.03 B Non-embedding parameters 0.97 B 0.97 B 5.80 B 6.98 B 6.98 B Supervised Fine-Tuning æˆ‘ä»¬é€šè¿‡ä½¿ç”¨é…å¯¹æ•°æ® $(p_{0}, r_{0})$ è¿›è¡Œ ç›‘ç£å¾®è°ƒ (SFT) æ¥å¢å¼ºLLaDAéµå¾ªæŒ‡ä»¤çš„èƒ½åŠ›ï¼Œå…¶ä¸­ $p_{0}$ æ˜¯ promptï¼Œ$r_{0}$ è¡¨ç¤ºå“åº”(response). è¿™æ˜¯é’ˆå¯¹LLMæœ€ç®€å•ã€æœ€åŸºç¡€çš„ post-training æ–¹æ³•ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œè¿™è¦æ±‚æ¨¡å‹å¯¹æ¡ä»¶åˆ†å¸ƒ $p_{\\theta}(r_{0}|p_{0})$ï¼Œè€Œéé¢„è®­ç»ƒä¸­çš„ $p_{\\theta}(x_{0})$ è¿›è¡Œå»ºæ¨¡ã€‚\nå…¶å®ç°æ–¹å¼ä¸é¢„è®­ç»ƒç±»ä¼¼ã€‚å¦‚å›¾2(b)æ‰€ç¤ºï¼Œä¿æŒ prompt éƒ¨åˆ†ä¸å˜ï¼Œå¹¶åƒå¤„ç† $x_{0}$ ä¸€æ ·ï¼Œç‹¬ç«‹åœ° mask response ä¸­çš„ token. ç„¶åï¼Œå°†æç¤ºå’Œè¢«æ©ç çš„å“åº” $r_{t}$ ä¸€åŒé€å…¥é¢„è®­ç»ƒå¥½çš„æ©ç é¢„æµ‹å™¨ï¼Œä»¥è®¡ç®—ç”¨äº SFT çš„æŸå¤±\n$$\r-\\mathbb{E}_{t,p_{0},r_{0},r_{t}}[\\frac{1}{t}\\sum_{i=1}^{L^{\\prime}}I[r_{t}^{i}=M]log~p_{\\theta}(r_{0}^{i}|p_{0},r_{t})] \\tag{5}\r$$å…¶ä¸­ï¼Œ$L^{\\prime}$ è¡¨ç¤ºç¨åæŒ‡å®šçš„åŠ¨æ€é•¿åº¦ã€‚è¿™ç§æ–¹æ³•ä¸é¢„è®­ç»ƒæ˜¯å®Œå…¨å…¼å®¹çš„ã€‚æœ¬è´¨ä¸Šï¼Œå°† $p_{0}$ å’Œ $r_{0}$ æ‹¼æ¥èµ·æ¥å¯ä»¥è¢«è§†ä¸ºå¹²å‡€çš„é¢„è®­ç»ƒæ•°æ® $x_{0} $ï¼Œè€Œå°† $p_{0}$ å’Œ $r_{t}$ æ‹¼æ¥èµ·æ¥åˆ™å¯ä½œä¸ºå…¶è¢«æ©ç åçš„ç‰ˆæœ¬ $x_{t}$. è¿™ä¸ªè¿‡ç¨‹ä¸é¢„è®­ç»ƒå®Œå…¨ç›¸åŒï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äºæ‰€æœ‰è¢«æ©ç çš„ token æ°å¥½éƒ½å‡ºç°åœ¨ $r_{0}$ éƒ¨åˆ†ã€‚\nLLaDA 8B æ¨¡å‹åœ¨ä¸€ä¸ªåŒ…å« 4.5M å¯¹æ ·æœ¬çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº† SFT. ä¸é¢„è®­ç»ƒè¿‡ç¨‹ä¸€è‡´ï¼Œæ•°æ®å‡†å¤‡å’Œè®­ç»ƒéƒ½éµå¾ªäº†ç°æœ‰LLM (Chu et al., 2024; Yang et al., 2024) ä¸­ä½¿ç”¨çš„ SFT åè®®ï¼Œæ²¡æœ‰å¼•å…¥ä»»ä½•é¢å¤–çš„æŠ€æœ¯æ¥ä¼˜åŒ– LLaDA çš„æ€§èƒ½ã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬ä»£ç ã€æ•°å­¦ã€æŒ‡ä»¤éµå¾ªå’Œç»“æ„åŒ–æ•°æ®ç†è§£ã€‚æˆ‘ä»¬åœ¨æ¯ä¸ª mini-batch ä¸­çš„çŸ­æ ·æœ¬å¯¹æœ«å°¾é™„åŠ  EOS tokenï¼Œä»¥ç¡®ä¿æ‰€æœ‰æ•°æ®é•¿åº¦ç›¸ç­‰ã€‚åœ¨è®­ç»ƒæœŸé—´å°† EOSè§†ä¸ºä¸€ä¸ªæ™®é€š token ï¼Œå¹¶åœ¨é‡‡æ ·æ—¶å°†å…¶ç§»é™¤ï¼Œä½¿å¾—LLaDAèƒ½å¤Ÿè‡ªåŠ¨æ§åˆ¶å“åº”çš„é•¿åº¦ã€‚\næˆ‘ä»¬åœ¨SFTæ•°æ®ä¸Šè®­ç»ƒäº† 3 ä¸ª epochï¼Œå…¶è°ƒåº¦ç­–ç•¥ä¸é¢„è®­ç»ƒé˜¶æ®µç›¸ä¼¼ã€‚å­¦ä¹ ç‡åœ¨æœ€åˆ 50 æ¬¡è¿­ä»£ä¸­ä» 0 çº¿æ€§å¢åŠ åˆ° $2.5 \\times 10^{-5}$ï¼Œç„¶åä¿æŒä¸å˜ã€‚åœ¨æœ€å 10% çš„è¿­ä»£ä¸­ï¼Œå­¦ä¹ ç‡æ€§é™ä½åˆ° $2.5 \\times 10^{-6}$. æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æƒé‡è¡°å‡è®¾ç½®ä¸º 0.1ï¼Œå…¨å±€ batch size è®¾ç½®ä¸º 256ï¼Œæ¯ä¸ª GPU çš„æœ¬åœ° batch size è®¾ç½®ä¸º 2. SFTå®éªŒåªæ‰§è¡Œäº†ä¸€æ¬¡ï¼Œæ²¡æœ‰è¿›è¡Œä»»ä½•è¶…å‚æ•°è°ƒä¼˜ã€‚\nInference ä½œä¸ºä¸€ä¸ªç”Ÿæˆå¼æ¨¡å‹ï¼ŒLLaDAæ—¢èƒ½ é‡‡æ · (sampling) æ–°æ–‡æœ¬ï¼Œä¹Ÿèƒ½ è¯„ä¼° (evaluating) å€™é€‰æ–‡æœ¬çš„ä¼¼ç„¶ã€‚\nå…ˆä»é‡‡æ ·è¯´èµ·ã€‚å¦‚å›¾ 2(c) æ‰€ç¤ºï¼Œç»™å®šä¸€ä¸ª prompt $p_{0}$ï¼Œæˆ‘ä»¬é€šè¿‡ç¦»æ•£åŒ–åå‘è¿‡ç¨‹æ¥ä»æ¨¡å‹åˆ†å¸ƒ $p_{\\theta}(r_{0}|p_{0})$ ä¸­è¿›è¡Œé‡‡æ ·ï¼Œè¿™ä¸ªè¿‡ç¨‹ä»ä¸€ä¸ªè¢«å®Œå…¨æ©ç çš„ response å¼€å§‹ã€‚\næ€»çš„é‡‡æ ·æ­¥æ•°æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œä¸º LLaDA æä¾›äº†ä¸€ä¸ªåœ¨æ•ˆç‡å’Œæ ·æœ¬è´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼ˆè¯¦è§3.3èŠ‚åˆ†æï¼‰ã€‚æˆ‘ä»¬é»˜è®¤ä½¿ç”¨å‡åŒ€åˆ†å¸ƒçš„æ—¶é—´æ­¥ã€‚ æ­¤å¤–ï¼Œç”Ÿæˆé•¿åº¦ä¹Ÿè¢«è§†ä¸ºè¶…å‚æ•°ï¼Œå®ƒæŒ‡å®šäº†é‡‡æ ·è¿‡ç¨‹å¼€å§‹æ—¶å®Œå…¨è¢«æ©ç å¥å­çš„é•¿åº¦ã€‚å¦‚é™„å½•B.4æ‰€è¿°ï¼Œç”±äºé¢„è®­ç»ƒå’ŒSFTéƒ½æ˜¯åœ¨å¯å˜é•¿åº¦çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„ï¼Œæœ€ç»ˆç»“æœå¯¹è¿™ä¸ªé•¿åº¦è¶…å‚æ•°ä¸æ•æ„Ÿã€‚\nåœ¨ä¸€ä¸ªä»æ—¶é—´ $t \\in (0, 1]$ åˆ° $s \\in [0, t)$çš„ä¸­é—´æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°† $p_{0}$ å’Œ $r_{t}$ åŒæ—¶é€å…¥æ©ç é¢„æµ‹å™¨ï¼Œå¹¶ä¸€æ¬¡æ€§é¢„æµ‹æ‰€æœ‰è¢«æ©ç çš„ token. éšå remask $\\frac{s}{t}$ æ¯”ä¾‹çš„å·²é¢„æµ‹ token å¾—åˆ°$r_{s}$ï¼Œä»è€Œç¡®ä¿åå‘è¿‡ç¨‹çš„è½¬æ¢ä¸å‰å‘è¿‡ç¨‹ä¿æŒä¸€è‡´ï¼Œä»¥å®ç°å‡†ç¡®é‡‡æ ·ã€‚\nå— LLM é‡‡æ ·ä¸­é€€ç«æŠ€å·§çš„å¯å‘ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä¸¤ç§ç¡®å®šæ€§ä½†æœ‰æ•ˆçš„é‡æ©ç ç­–ç•¥ã€‚\nlow-confidence remasking: remask é‚£äº›åŸºäºé¢„æµ‹ç½®ä¿¡åº¦æœ€ä½çš„ $\\frac{s}{t}$ æ¯”ä¾‹çš„ token. semi-autoregressive remasking: å¯¹äºç»è¿‡ SFT çš„ LLaDA æ¨¡å‹ï¼Œå°†åºåˆ—åˆ†æˆå‡ ä¸ªå—ï¼Œå¹¶ä»å·¦åˆ°å³åœ°ç”Ÿæˆ. åœ¨æ¯ä¸ªå—å†…éƒ¨ï¼Œé‡‡ç”¨åå‘è¿‡ç¨‹è¿›è¡Œé‡‡æ ·ã€‚ A Conceptual Overview of the Semi-autoregressive Sampling\nå¯¹äºæ¡ä»¶ä¼¼ç„¶è¯„ä¼°ï¼Œæˆ‘ä»¬è‡ªç„¶å¯ä»¥åˆ©ç”¨å…¬å¼(5)ä¸­çš„ä¸Šç•Œã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°ä¸‹é¢è¿™ä¸ªç­‰ä»·å½¢å¼ï¼ˆå…¬å¼6ï¼‰è¡¨ç°å‡ºæ›´ä½çš„æ–¹å·®ï¼Œåœ¨è¯„ä¼°æ—¶æ›´ä¸ºç¨³å®šï¼š\n$$\r-\\mathbb{E}_{l,r_{0},r_{l}}[\\frac{L}{l}\\sum_{i=1}^{L}I[r_{l}^{i}=M]log~p_{\\theta}(r_{0}^{i}|p_{0},r_{l})] \\tag{6}\r$$å…¶ä¸­ï¼Œ$l$ ä» ${1, 2, ..., L}$ ä¸­å‡åŒ€é‡‡æ ·ï¼Œ$r_{l}$ æ˜¯é€šè¿‡ä» $r_{0}$ ä¸­ä¸æ”¾å›åœ°å‡åŒ€é‡‡æ · $l$ ä¸ªæ²¡è¢« mask çš„ token å¾—åˆ°çš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨äº† unsupervised classifier-free guidance.\nè™½ç„¶è¿™ä¸¤ä¸ªå½¢å¼çš„æœŸæœ›å€¼ç›¸åŒï¼Œä½†å®ƒä»¬çš„æ–¹å·®ä¸åŒã€‚ç›´è§‚ä¸Šï¼Œåœ¨å…¬å¼ (5) ä¸­ï¼Œæˆ‘ä»¬æœŸæœ› $x_{t}=[p_0,r_t]$ æœ‰ $t$ æ¯”ä¾‹çš„ token è¢«æ©ç ã€‚ç„¶è€Œï¼Œå‰å‘è¿‡ç¨‹çš„éšæœºæ€§å¸¸å¸¸ä¼šå¯¼è‡´åå·®ï¼Œå°¤å…¶å½“ $x_{t}$ åŒ…å«çš„ token å¾ˆå°‘æ—¶ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨å…¬å¼ (6) ä¸­ï¼Œ$r_{l}$ ä¸­è¢«æ©ç  token çš„æ¯”ä¾‹ $\\frac{l}{L}$ æ˜¯ç¡®å®šçš„ã€‚\nè™½ç„¶ç†è®ºåˆ†æå–å†³äºæ•°æ®åˆ†å¸ƒï¼Œä½†ç»éªŒç»“æœè¡¨æ˜ï¼Œå…¬å¼ (5) éœ€è¦è¶…è¿‡ 1000 æ¬¡è’™ç‰¹å¡æ´›ä¼°è®¡æ‰èƒ½å¾—åˆ°ç¨³å®šç»“æœï¼Œè€Œå…¬å¼ (6) ä»…éœ€ 128 æ¬¡ä¼°è®¡å³å¯è¾¾åˆ°ç¨³å®šã€‚\nAny-order autoregressive models (AO-ARM) é€šè¿‡å¯¹ L ä¸ªå˜é‡æ‰€æœ‰å¯èƒ½çš„æ’åˆ—é¡ºåºè¿›è¡Œè‡ªå›å½’æ¥æè¿°è”åˆåˆ†å¸ƒã€‚ä¸ºäº†å­¦ä¹ è¿™æ ·çš„åˆ†å¸ƒï¼ŒAO-ARM åˆ©ç”¨ä¸€ä¸ªæƒé‡å…±äº«çš„ç¥ç»ç½‘ç»œæ¥ä¸ºæ‰€æœ‰å•å˜é‡æ¡ä»¶æ¦‚ç‡å»ºæ¨¡ï¼Œå¹¶ä½¿ç”¨æ©ç  token æ¥è¡¨ç¤ºç¼ºå¤±çš„å˜é‡ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œæ¨¡å‹ä¼šæœ€å°åŒ–åœ¨æ‰€æœ‰é¡ºåºçš„å‡åŒ€åˆ†å¸ƒ $U_{\\pi}$ ä¸Šçš„æœŸæœ›è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼š\n$$\r-\\mathbb{E}_{x_{0},\\pi \\sim U_{\\pi}}[\\sum_{i=1}^{L}log~p_{\\theta}(x_{0}^{\\pi(i)}|x_{0}^{\\pi(","permalink":"http://localhost:1313/blogs/llada/","summary":"Paper Reading of LLaDA","title":"LLaDA"},{"content":"TestGraphCompute 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 int main(int argc, char **argv) { // 1. åˆå§‹åŒ–ä¸å‘½ä»¤è¡Œå‚æ•°å¤„ç† Timer timer(\u0026#34;TestGraphCompute\u0026#34;); mlir::registerAsmPrinterCLOptions(); mlir::registerMLIRContextCLOptions(); mlir::registerPassManagerCLOptions(); // è§£æå‘½ä»¤è¡Œå‚æ•° cl::ParseCommandLineOptions(argc, argv, \u0026#34;tx8be compiler\\n\u0026#34;); // 2. åˆå§‹åŒ– MLIR æ¨¡å—å’Œä¸Šä¸‹æ–‡ mlir::OwningOpRef\u0026lt;mlir::ModuleOp\u0026gt; module; mlir::MLIRContext context; // å®šä¹‰ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºä»å‘½ä»¤è¡Œé€‰é¡¹ä¸­æå– codegen_path å‚æ•° std::regex pattern(\u0026#34;codegen_path=([a-zA-Z0-9_]+)\u0026#34;); std::smatch matches; std::string cachePath = \u0026#34;codegen\u0026#34;; // é»˜è®¤æ–‡ä»¶å¤¹åå­— if (std::regex_search(optionstr, matches, pattern)) { // å¯»æ‰¾å‘½ä»¤è¡Œé€‰é¡¹ä¸­æ˜¯å¦æŒ‡å®š codegen_path cachePath = matches[1]; // 3. åŠ è½½ MLIR æ¨¡å— // å¦‚æœ cache ä¸º 2 æˆ– 4ï¼Œåˆ™ä»ç¼“å­˜è·¯å¾„åŠ è½½æ¨¡å—ï¼›å¦åˆ™ï¼Œä½¿ç”¨é»˜è®¤çš„ gModelFil gModelFile = (cache == 2 || cache == 4) ? cachePath + \u0026#34;/cache.mlir\u0026#34; : gModelFile; if (int error = getMLIRFromFile(module, context, gModelFile)) { return error; } // 4. é…ç½®æ¨¡å— auto mconfig = getModuleConfig(module.get()); if (optionstr.size() \u0026gt; 0) { mconfig.option += optionstr; } mconfig.constCache = cache; updateModuleConfig(module, context, mconfig); mconfig = getModuleConfig(module.get()); showModuleConfig(mconfig); // 5. å¤„ç†å¤šå¡ä¿¡æ¯ json_info_multi_card_t *multi_card_jinfo = nullptr; multi_card_jinfo = (cache == 2 || cache == 4) ? get_multi_card_info_from_file(cachePath + \u0026#34;/model_info.json\u0026#34;) : parseMultiCardModuleInfo(module, context); if (0) { dumpIR(module.get(), true); } // 6. è¯»å–å‚è€ƒè·¯å¾„ if (!fast_codegen) { // NOT fast_codegen std::vector\u0026lt;std::string\u0026gt; in_files = parseStringArgs(gInputBin, std::string(\u0026#34;,\u0026#34;)); std::vector\u0026lt;std::string\u0026gt; out_files = parseStringArgs(gOutputBin, std::string(\u0026#34;,\u0026#34;)); // å®šä¹‰ä¸€ä¸ª lambda å‡½æ•°ï¼Œç”¨äºä»æ–‡ä»¶ä¸­è¯»å–å‚è€ƒæ–‡ä»¶è·¯å¾„ã€‚ auto getRefFiles = [] (std::string gFile, std::vector\u0026lt;std::string\u0026gt; \u0026amp;files) { if (gFile.size() == 0) { return 0; } if (!llvm::sys::fs::exists(gFile)) { return 0; } std::ifstream gf(gFile); std::string text((std::istreambuf_iterator\u0026lt;char\u0026gt;(gf)), (std::istreambuf_iterator\u0026lt;char\u0026gt;())); files = parseStringArgs(text, std::string(\u0026#34;,\u0026#34;)); return 0; }; if ((gInputBin.size() == 0) \u0026amp;\u0026amp; (gInputFile.size() != 0)) { getRefFiles(gInputFile, in_files); getRefFiles(gOutputFile, out_files); } } // 7. computeGolden if (cache \u0026lt; 2) { for (int32_t i = 0; i \u0026lt; mconfig.tile.chip_num; i++) { // éå†èŠ¯ç‰‡æ•°é‡ï¼Œåˆ›å»ºå¯¹åº”çš„ç›®å½•ç»“æ„ // æ„é€ å¹¶åˆ›å»ºåˆ›å»ºç›® codegen/node_0_0/chip0/agent/data std::string path = \u0026#34;codegen/node_0_0/chip\u0026#34;; path += std::to_string(i) + \u0026#34;/agent/data\u0026#34;; createDir(path); } // è°ƒç”¨ computeGolden å‡½æ•°ï¼Œè®¡ç®—å‚è€ƒè¾“å‡ºä¿å­˜åˆ° codegenPath computeGolden(module, multi_card_jinfo, in_files, out_files, mconfig.codegenPath); } // è°ƒç”¨ moduleCompileCodegen å‡½æ•°ï¼Œå¯¹ MLIR æ¨¡å—è¿›è¡Œç¼–è¯‘å’Œä»£ç ç”Ÿæˆ int32_t ret = moduleCompileCodegen(module, context); ASSERT(ret == true); // 9. è·å–å†…å­˜å¤§å° // ä»æ¨¡å—ä¸­è·å–ç«‹å³æ•° (Immediate) å’Œå¸¸é‡å‚æ•°çš„ DDR å¤§å° uint64_t imm_size = module.get()-\u0026gt;hasAttr(tx8be::ModuleAttr::ImmDdrSize) ? module.get()-\u0026gt;getAttrOfType\u0026lt;mlir::IntegerAttr\u0026gt;(tx8be::ModuleAttr::ImmDdrSize).getInt() : 2147483648; uint64_t params_size = module.get()-\u0026gt;hasAttr(tx8be::ModuleAttr::ConstDdrSize) ? module.get()-\u0026gt;getAttrOfType\u0026lt;mlir::IntegerAttr\u0026gt;(tx8be::ModuleAttr::ConstDdrSize).getInt() : 0; // 10. æ›´æ–°æ¯ä¸ªèŠ¯ç‰‡çš„å†…å­˜å¤§å°ä¿¡æ¯ for (int32_t i = 0; i \u0026lt; mconfig.tile.chip_num; i++) { multi_card_jinfo-\u0026gt;chip_infos[i]-\u0026gt;imm_size = imm_size; multi_card_jinfo-\u0026gt;chip_infos[i]-\u0026gt;params_size.emplace_back(params_size); } // 11. ä¿å­˜å¤šå¡æ¨¡å‹ä¿¡æ¯ std::vector\u0026lt;int32_t\u0026gt; chipIds; if (module.get()-\u0026gt;hasAttr(tx8be::ModuleAttr::ChipIds)) { // è·å–èŠ¯ç‰‡ ID mlir::ArrayAttr chipIdsAttr = module.get()-\u0026gt;getAttrOfType\u0026lt;mlir::ArrayAttr\u0026gt;(tx8be::ModuleAttr::ChipIds); for (int i = 0; i \u0026lt; chipIdsAttr.size(); i++) { chipIds.push_back(chipIdsAttr[i].cast\u0026lt;mlir::IntegerAttr\u0026gt;().getInt()); } } // å¤šå¡æ¨¡å‹æ–‡ä»¶ä¿å­˜åˆ° codegenPath è·¯å¾„ä¸‹ saveMultiCardModelJson(multi_card_jinfo, mconfig.codegenPath, chipIds); // uint64_t ddrSize = getModelDDRSize(multi_card_jinfo); return 0; } } computeGolden è¾“å…¥å‚æ•°çš„æ¥æºï¼š\nmoduleï¼šåœ¨ main æ–‡ä»¶ä¸­ï¼Œé€šè¿‡ getMLIRFromFile å‡½æ•°ä»æ–‡ä»¶ä¸­åŠ è½½ MLIR æ¨¡å— multi_card_jinfoï¼šåœ¨ main æ–‡ä»¶ä¸­ï¼Œé€šè¿‡ get_multi_card_info_from_file æˆ– parseMultiCardModuleInfo ä» JSON æ–‡ä»¶æˆ– MLIR æ¨¡å—ä¸­æå–å¤šå¡ä¿¡æ¯ã€‚ in_files å’Œ out_filesï¼šåœ¨ main æ–‡ä»¶ä¸­ï¼Œé€šè¿‡ parseStringArgs æˆ– getRefFiles è§£æè¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚ mconfig.codegenPathï¼šåœ¨ main æ–‡ä»¶ä¸­ï¼Œé€šè¿‡å‘½ä»¤è¡Œé€‰é¡¹æˆ–é»˜è®¤å€¼è®¾ç½®ä»£ç ç”Ÿæˆè·¯å¾„ï¼Œå¹¶ä¼ é€’ç»™ computeGoldenã€‚ computeGolden å‡½æ•°ç”Ÿæˆçš„æ•°æ®ï¼ˆè¾“å…¥å’Œè¾“å‡ºçš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼‰å°†ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ mconfig.codegenPath.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 void computeGolden(mlir::OwningOpRef\u0026lt;mlir::ModuleOp\u0026gt; \u0026amp;module, json_info_multi_card_t *multi_card_jinfo, std::vector\u0026lt;std::string\u0026gt; \u0026amp;inFiles, std::vector\u0026lt;std::string\u0026gt; \u0026amp;outFiles, std::string file_path) { // å®šä¹‰å½¢çŠ¶ç±»å‹ï¼Œç”¨äºå­˜å‚¨å¤šç»´å¼ é‡çš„å½¢çŠ¶ä¿¡æ¯ using ShapeType = std::vector\u0026lt;std::vector\u0026lt;int64_t\u0026gt;\u0026gt;; // ç”¨äºå­˜å‚¨å¤šèŠ¯ç‰‡çš„è¾“å…¥å’Œè¾“å‡ºæ•°æ® std::vector\u0026lt;std::vector\u0026lt;int8_t *\u0026gt;\u0026gt; multiInputDdata; std::vector\u0026lt;std::vector\u0026lt;int8_t *\u0026gt;\u0026gt; multiOutputData; std::vector\u0026lt;std::thread\u0026gt; threads; uint32_t chip_num = multi_card_jinfo-\u0026gt;chip_num; // è·å–èŠ¯ç‰‡æ•°é‡ auto tile_info = get_tileinfo(module.get()); // ä» MLIR æ¨¡å—ä¸­æå– tile ä¿¡æ¯ std::vector\u0026lt;ShapeType\u0026gt; outShapes(chip_num); // å­˜å‚¨æ¯ä¸ªèŠ¯ç‰‡çš„è¾“å‡ºå½¢çŠ¶ä¿¡æ¯ for (int i = 0; i \u0026lt; chip_num; i++) { chip_info_t *chip_info = multi_card_jinfo-\u0026gt;chip_infos[i]; // åˆ†é…å½“å‰èŠ¯ç‰‡çš„è¾“å…¥å’Œè¾“å‡ºæ•°æ®æŒ‡é’ˆæ•°ç»„ std::vector\u0026lt;int8_t *\u0026gt; input_data(chip_info-\u0026gt;input_num); std::vector\u0026lt;int8_t *\u0026gt; output_data(chip_info-\u0026gt;output_num); // ç”¨äº OneDNN è®¡ç®—çš„è¾“å…¥å’Œè¾“å‡ºç¼“å†²åŒº std::vector\u0026lt;char *\u0026gt; computeInputs; std::vector\u0026lt;char *\u0026gt; computeOutputs; // å½“å‰èŠ¯ç‰‡çš„è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„ std::vector\u0026lt;std::string\u0026gt; chipInFiles; std::vector\u0026lt;std::string\u0026gt; chipOutFiles; parseInOutfile(inFiles, chipInFiles, i, chip_num, chip_info-\u0026gt;input_num); parseInOutfile(outFiles, chipOutFiles, i, chip_num, chip_info-\u0026gt;output_num); // ç”Ÿæˆå½“å‰èŠ¯ç‰‡çš„è¾“å…¥è¾“å‡ºæ•°æ® genInputs4SingleChip(computeInputs, input_data, chip_info, chipInFiles); genOutputs4SingleChip(computeOutputs, output_data, chip_info, chipOutFiles); // å¦‚æœè¾“å…¥æ–‡ä»¶ä¸ºç©ºï¼Œåˆ™ç”Ÿæˆéšæœºè¾“å…¥æ•°æ®å¹¶æ ¡æ­£ if (chipInFiles.size() == 0) { updateSpecialInputData(computeModuleRef, computeInputs, input_data, chip_info); } multiInputDdata.push_back(input_data); multiOutputData.push_back(output_data); if (outFiles.size() == 0) { threads.emplace_back(moduleComputeInterface, std::ref(computeModuleRef), std::ref(outShapes[i]), computeInputs, computeOutputs, i); } } // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆè®¡ç®— for (auto \u0026amp;thread : threads) { thread.join(); } // éå†æ¯ä¸ªèŠ¯ç‰‡ï¼Œä¿å­˜è¾“å…¥å’Œè¾“å‡ºæ•°æ® for (int32_t i = 0; i \u0026lt; chip_num; i++) { chip_info_t *chip_info = multi_card_jinfo-\u0026gt;chip_infos[i]; uint32_t node_id = get_node_id(i, tile_info); int32_t relative_chip_id = get_relative_chip_id(i, tile_info); // æ„é€ å½“å‰èŠ¯ç‰‡çš„æ•°æ®ä¿å­˜è·¯å¾„ file_path/node_x_y/chip_z/agent/data std::string data_path = file_path + \u0026#34;/node_\u0026#34; + std::to_string(node_id / tile_info.node_y) + \u0026#34;_\u0026#34; + std::to_string(node_id % tile_info.node_y) + \u0026#34;/chip\u0026#34; + std::to_string(relative_chip_id) + \u0026#34;/agent/data\u0026#34;; createDir(data_path); // binæ ¼å¼ä¿å­˜å½“å‰èŠ¯ç‰‡çš„è¾“å…¥æ•°æ® for (uint32_t j = 0; j \u0026lt; chip_info-\u0026gt;input_num; j++) { inout_tensor_info_t *tensor = chip_info-\u0026gt;input[j]; saveInOutTensor(tensor-\u0026gt;shape, tensor-\u0026gt;dim, tensor-\u0026gt;layout, tensor-\u0026gt;dtype, data_path + \u0026#34;/in\u0026#34; + std::to_string(j) + \u0026#34;.bin\u0026#34;, multiInputDdata[i][j]); } // binæ ¼å¼ä¿å­˜å½“å‰èŠ¯ç‰‡çš„è¾“å‡ºæ•°æ® out_j_ref.bin for (uint32_t j = 0; j \u0026lt; chip_info-\u0026gt;output_num; j++) { inout_tensor_info_t *tensor = chip_info-\u0026gt;output[j]; int32_t tensorShape[MAX_SHAPE_DIM]; // æ ¹æ® outShapes æˆ–åŸå§‹å½¢çŠ¶è®¡ç®—è¾“å‡ºå¼ é‡çš„å½¢çŠ¶ for (int idx = 0; idx \u0026lt; tensor-\u0026gt;dim; ++idx) { if (!outShapes[i].empty()) { tensorShape[idx] = outShapes[i][j][idx]; } else { tensorShape[idx] = tensor-\u0026gt;shape[idx]; } } // ä¿å­˜è¾“å‡ºæ•°æ® saveInOutTensor(tensorShape, tensor-\u0026gt;dim, tensor-\u0026gt;layout, tensor-\u0026gt;dtype, data_path + \u0026#34;/out\u0026#34; + std::to_string(j) + \u0026#34;_ref.bin\u0026#34;, multiOutputData[i][j]); } // é‡Šæ”¾å½“å‰èŠ¯ç‰‡çš„è¾“å…¥å’Œè¾“å‡ºæ•°æ®å†…å­˜ for (uint32_t j = 0; j \u0026lt; chip_info-\u0026gt;input_num; j++) { free(multiInputDdata[i][j]); } for (uint32_t j = 0; j \u0026lt; chip_info-\u0026gt;output_num; j++) { free(multiOutputData[i][j]); } } } run_code_gen_layer ä¸»è¦ç”¨äºè¿è¡Œä»£ç ç”Ÿæˆ (codegen) ç›¸å…³çš„ä»»åŠ¡ï¼Œä»¥ä¸‹æ˜¯å‡½æ•°çš„è¯¦ç»†åŠŸèƒ½è§£é‡Šï¼š\nè§£æå‚æ•°ï¼š æ¥å—è‡³å°‘ä¸¤ä¸ªå‚æ•°ï¼š$1 æ˜¯å¯æ‰§è¡Œæ–‡ä»¶çš„åç§°ï¼Œ$2 æ˜¯ç§å­æ–‡ä»¶ (seed file) å¦‚æœæœ‰æ›´å¤šå‚æ•° ($# \u0026gt; 2)ï¼Œåˆ™å°†é¢å¤–å‚æ•°å­˜å‚¨ä¸ºé…ç½®å‚æ•° (config_params) ä» config_params ä¸­æå– codegen_path (ä»£ç ç”Ÿæˆè¾“å‡ºè·¯å¾„) ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼ \u0026ldquo;codegen\u0026rdquo; åˆ‡æ¢å·¥ä½œç›®å½•ï¼š åˆ‡æ¢åˆ° ${BEMLIR_PROJECT_ROOT}/build/bin ç›®å½•ã€‚ åˆ é™¤æ—§çš„ codegen_path ç›®å½•ï¼Œç¡®ä¿ç¯å¢ƒå¹²å‡€ã€‚ æ‰§è¡Œå¯æ‰§è¡Œæ–‡ä»¶ï¼š ä½¿ç”¨ ${layer_cmd} (å³ ./$1) è¿è¡ŒæŒ‡å®šçš„å¯æ‰§è¡Œæ–‡ä»¶ï¼Œä¼ å…¥ç§å­æ–‡ä»¶å’Œé…ç½®å‚æ•°ã€‚ æ£€æŸ¥è¿”å›å€¼ï¼Œå¦‚æœå¤±è´¥ (ret != 0)ï¼Œåˆ™æ¢å¤ç›®å½•å¹¶è¿”å›é”™è¯¯ã€‚ å¤„ç†ç”Ÿæˆçš„ä»£ç ï¼š æ ¹æ®å‚æ•°ä¸­çš„ chip_num æˆ– static_shape åˆ¤æ–­ host_type. è°ƒç”¨ get_codegen_file å¤„ç†ç”Ÿæˆçš„ä»£ç æ–‡ä»¶ã€‚ è¿è¡Œ cmodel æµ‹è¯•: æ ¹æ®å‚æ•°ä¸­çš„ fast_codegen æˆ– not_run è®¾ç½® cmp_flag. è°ƒç”¨ run_on_cmodel åœ¨ cmodel ä¸Šè¿è¡Œç”Ÿæˆçš„ä»£ç ã€‚ æ£€æŸ¥è¿”å›å€¼ï¼Œå¤±è´¥åˆ™è¿”å›é”™è¯¯ã€‚ # å®šä¹‰ run_codegen_layer å‡½æ•°ï¼Œç”¨äºè¿è¡Œä»£ç ç”Ÿæˆå±‚æµ‹è¯•æµç¨‹ function run_codegen_layer() { # 1. æ‰“å°å¼€å§‹æ—¶é—´ï¼Œç”¨äºè°ƒè¯•å’Œæ€§èƒ½è¿½è¸ª echo -n \u0026#34;time==\u0026gt;\u0026gt;run_codegen_layer-start \u0026#34;; date; # 2. å‡½æ•°å‚æ•°è¯´æ˜ # $1: å¯æ‰§è¡Œæ–‡ä»¶åç§° # $2: ç§å­æ–‡ä»¶ (seed fileï¼‰ layer_cmd=\u0026#34;./$1\u0026#34; # åœ¨å½“å‰ç›®å½•ä¸‹æ‰§è¡Œçš„å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ seed_file=$2 # ç§å­æ–‡ä»¶æˆ–é…ç½®æ–‡ä»¶ config_params=\u0026#34;\u0026#34; # é…ç½®å‚æ•°ï¼Œé»˜è®¤ä¸ºç©º # é»˜è®¤ä»£ç ç”Ÿæˆè¾“å‡ºè·¯å¾„ codegen_path=\u0026#34;codegen\u0026#34; # 3. æ£€æŸ¥æ˜¯å¦æœ‰è¶…è¿‡2ä¸ªå‚æ•° if [ $# -gt 2 ]; then # æå–é™¤å‰ä¸¤ä¸ªå‚æ•°å¤–çš„æ‰€æœ‰å‚æ•°ä½œä¸ºé…ç½®å‚æ•° config_params=$* config_params=${config_params#*} # ç§»é™¤ç¬¬ä¸€ä¸ªå‚æ•° (å¯æ‰§è¡Œæ–‡ä»¶ï¼‰ config_params=${config_params#*} # ç§»é™¤ç¬¬äºŒä¸ªå‚æ•° (ç§å­æ–‡ä»¶ï¼‰ fi # 4. å¦‚æœé…ç½®å‚æ•°ä¸­åŒ…å« --codegen_pathï¼Œæå–å…¶å€¼ä½œä¸ºä»£ç ç”Ÿæˆè·¯å¾„ if [[ ${config_params} == *\u0026#34;--codegen_path=\u0026#34;* ]]; then # æå– --codegen_path= åé¢çš„å€¼ codegen_path=${config_params#*codegen_path=} # ç§»é™¤å¯èƒ½å­˜åœ¨çš„å¼•å·æˆ–å…¶ä»–å­—ç¬¦ codegen_path=${codegen_path%%\\\u0026#34;*} codegen_path=${codegen_path-*} codegen_path=${codegen_path*} fi # 5. åˆ‡æ¢åˆ° build/bin ç›®å½•æ‰§è¡Œå‘½ä»¤ pushd ${BEMLIR_PROJECT_ROOT}/build/bin # åˆ é™¤æ—§çš„ codegen_path ç›®å½•ï¼Œç¡®ä¿ç¯å¢ƒå¹²å‡€ rm -rf ${codegen_path} # æ‰§è¡Œå±‚å‘½ä»¤ï¼Œä¼ å…¥ç§å­æ–‡ä»¶å’Œé…ç½®å‚æ•° ${layer_cmd} ${seed_file} ${config_params} # æ•è·å‘½ä»¤çš„è¿”å›å€¼ ret=$? # å¦‚æœå‘½ä»¤æ‰§è¡Œå¤±è´¥ (è¿”å›ç é0ï¼‰ï¼Œæ¢å¤ç›®å½•å¹¶è¿”å›é”™è¯¯ if [[ ${ret} -ne 0 ]]; then popd echo ${ret} return ${ret} fi popd # æ¢å¤åŸå§‹ç›®å½• # 6. æ‰“å°ä»£ç ç”Ÿæˆå®Œæˆçš„æ—¶é—´ echo -n \u0026#34;time==\u0026gt;\u0026gt;run_codegen_layer-codegen=== \u0026#34;; date; # 7. æ ¹æ®å‚æ•°åˆ¤æ–­ä¸»æœºç±»å‹ host_type=0 # å¦‚æœå‚æ•°ä¸­åŒ…å« chip_num æˆ– static_shapeï¼Œåˆ™å°† host_type è®¾ä¸º 1 if [[ $* == *\u0026#34;chip_num\u0026#34;* ]] || [[ $* == *\u0026#34;static_shape\u0026#34;* ]]; then host_type=1 fi # 8. è°ƒç”¨ get_codegen_file å¤„ç†ç”Ÿæˆçš„ä»£ç æ–‡ä»¶ get_codegen_file ${codegen_path} ${host_type} # æ•è·è¿”å›å€¼ ret=$? # å¦‚æœå¤„ç†å¤±è´¥ï¼Œæ¢å¤ç›®å½•å¹¶è¿”å›é”™è¯¯ if [[ ${ret} -ne 0 ]]; then popd echo ${ret} return ${ret} fi # 9. åˆå§‹åŒ–æ¯”è¾ƒæ ‡å¿— cmp_flag=\u0026#34;\u0026#34; # å¦‚æœå‚æ•°ä¸­åŒ…å« fast_codegen æˆ– not_runï¼Œåˆ™è®¾ç½® cmp_flag ä¸º \u0026#34;not_run\u0026#34; if [[ $* == *\u0026#34;fast_codegen\u0026#34;* ]] || [[ $* == *\u0026#34;not_run\u0026#34;* ]]; then cmp_flag=\u0026#34;not_run\u0026#34; fi # 10. åœ¨ cmodel ä¸Šè¿è¡Œç”Ÿæˆçš„ä»£ç ï¼Œä¼ å…¥æ¯”è¾ƒæ ‡å¿— run_on_cmodel ${codegen_path} ${cmp_flag} # æ•è·è¿”å›å€¼ ret=$? # å¦‚æœè¿è¡Œå¤±è´¥ï¼Œæ¢å¤ç›®å½•å¹¶è¿”å›é”™è¯¯ if [[ ${ret} -ne 0 ]]; then popd echo ${ret} return ${ret} fi # 11. æ‰“å°ç»“æŸæ—¶é—´ echo -n \u0026#34;time==\u0026gt;\u0026gt;run codegen layer-end=== \u0026#34;; date; } get_codegen_file get_codegen_file ç”¨äºæ•´ç†ä»£ç ç”Ÿæˆçš„ç»“æœ (ä½äº ${BEMLIR_PROJECT_ROOT}/build/bin/${codegen_case})ï¼Œä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆç‰ˆæœ¬ä¿¡æ¯ (version.txt)ï¼Œå¹¶å°†ç”Ÿæˆçš„æ–‡ä»¶å¤åˆ¶åˆ°æµ‹è¯•ç›®å½• (${BEMLIR_PROJECT_ROOT}/external/tx8be-oplib/tests/test_codegen)ï¼Œæœ€åè°ƒç”¨ get_codegen_host å®Œæˆä¸»æœºç›¸å…³å¤„ç†ã€‚\n# Function to process and organize generated codegen files function get_codegen_file() { # Print all input arguments for debugging echo \u0026#34;$*\u0026#34; # Assign first argument as the codegen case name or path codegen_case=$1 # Second argument: 0 for host thread mode, 1 for host stream mode # Note: $2 is passed to get_codegen_host # Change to the codegen case directory under build/bin pushd \u0026#34;${BEMLIR_PROJECT_ROOT}/build/bin/${codegen_case}\u0026#34; # Find node directories matching node_[0-9]+_[0-9] pattern (e.g., node_123_4) node_dirs=$(find . -maxdepth 1 -type d -regex \u0026#39;.*/node_[0-9]+_[0-9]\u0026#39; -exec basename {} \\;) # Iterate through each node directory for dir in $node_dirs; do # Check if libTX8MLIRTransforms.a exists to determine version type if [ ! -e \u0026#34;${BEMLIR_PROJECT_ROOT}/lib/libTX8MLIRTransforms.a\u0026#34; ]; then # Write \u0026#39;tx8be-mlir\u0026#39; to version.txt if library is absent echo -e \u0026#34;tx8be-mlir\u0026#34; \u0026gt; \u0026#34;${dir}/version.txt\u0026#34; else # Write \u0026#39;tx8be-mlir-sdk\u0026#39; to version.txt if library is present echo -e \u0026#34;tx8be-mlir-sdk\u0026#34; \u0026gt; \u0026#34;${dir}/version.txt\u0026#34; fi # Append git status to version.txt to record repository state git status --porcelain \u0026gt;\u0026gt; \u0026#34;${dir}/version.txt\u0026#34; # Append last two git commits to version.txt for version history git log -2 \u0026gt;\u0026gt; \u0026#34;${dir}/version.txt\u0026#34; done popd # Change to the test_codegen directory pushd \u0026#34;${BEMLIR_PROJECT_ROOT}/external/tx8be-oplib/tests/test_codegen\u0026#34; # Remove existing codegen_case directory to ensure a clean state rm -rf \u0026#34;${codegen_case}\u0026#34; # Copy the codegen_case directory from build/bin cp -r \u0026#34;${BEMLIR_PROJECT_ROOT}/build/bin/${codegen_case}\u0026#34; . popd # Call get_codegen_host to process host-related tasks get_codegen_host \u0026#34;${codegen_case}\u0026#34; \u0026#34;$2\u0026#34; } get_codegen_host get_codegen_host ç”¨äºä¸º host ç¯å¢ƒå‡†å¤‡ä»£ç ç”Ÿæˆç”¨ä¾‹çš„æµ‹è¯•æ–‡ä»¶ã€‚å®ƒåœ¨æŒ‡å®šçš„æµ‹è¯•ç”¨ä¾‹ç›®å½•ä¸­å¤„ç† node \u0026amp; chip ç›¸å…³çš„æ–‡ä»¶ï¼Œå¤åˆ¶å¿…è¦çš„é…ç½®æ–‡ä»¶ã€æºä»£ç å’Œæ„å»ºè„šæœ¬ï¼Œå¹¶æ ¹æ® host_type é€‰æ‹©ä¸åŒçš„ä¸»æœºå®ç°æ–‡ä»¶ host_thread.cpp æˆ– host_stream.cpp.\nå‡½æ•°è¾“å…¥å‚æ•°ï¼š $1 (codegen_case): ä»£ç ç”Ÿæˆç”¨ä¾‹çš„åç§°æˆ–è·¯å¾„ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªç›®å½• (ä¾‹å¦‚ codegen0 æˆ– codegen1) ï¼Œè¡¨ç¤ºæµ‹è¯•ç”¨ä¾‹çš„æ ¹ç›®å½•ã€‚ $2 (host_type): ä¸»æœºæ‰§è¡Œæ¨¡å¼ï¼Œ0: host_thread.cppï¼Œ1: host_stream.cpp. åˆ‡æ¢åˆ° ${{OPLIB_PROJECT_ROOT}}/tests/test_codegen/${codegen_case} ç›®å½•: ä½¿ç”¨ find å‘½ä»¤æŸ¥æ‰¾ç¬¦åˆ node_[0-9]+_[0-9] æ¨¡å¼ (ä¾‹å¦‚ node_123_4) çš„å­ç›®å½•ï¼Œè¡¨ç¤ºä»£ç ç”Ÿæˆä¸­çš„èŠ‚ç‚¹ã€‚ å¯¹æ¯ä¸ª node_dir è¿½åŠ ç‰ˆæœ¬ä¿¡æ¯å’Œå¤åˆ¶ç›¸å…³æ–‡ä»¶ã€‚ å¤„ç† chip ç›®å½•: åœ¨æ¯ä¸ªèŠ‚ç‚¹ç›®å½•ä¸‹ï¼ŒæŸ¥æ‰¾ç¬¦åˆ chip[0-9]+ æ¨¡å¼ (ä¾‹å¦‚ chip0, chip1) çš„å­ç›®å½• ä¸ºæ¯ä¸ª dir å¤åˆ¶ Makefile_tile åˆ° ./${node_dir}/${dir}/Makefile. åœ¨ ./${node_dir}/${dir}/ ä¸‹åˆ›å»º 16 ä¸ªå­ç›®å½• (tiles0 - tiles15)ï¼Œå¹¶ä¸ºæ¯ä¸ªå­ç›®å½•å¤åˆ¶ Makefile_main åˆ° t iles$i/Makefile æ ¹æ® host_type å¤åˆ¶ host_thread.cpp æˆ– host_stream.cpp åˆ°å½“å‰ç›®å½•çš„ host.cpp. å¤åˆ¶ CMakeLists.txt å’Œ Makefile åˆ°å½“å‰ç›®å½•ã€‚ # Function to prepare host-related files for a codegen test case function get_codegen_host() { # Print all input arguments for debugging echo \u0026#34;$*\u0026#34; # Assign first argument as the codegen case name or path codegen_case=$1 # Assign second argument as host type (0: thread mode, 1: stream mode) host_type=$2 # Define relative path for test_codegen directory oplib_path=\u0026#34;tests/test_codegen\u0026#34; # Change to the test_codegen directory for the codegen case pushd \u0026#34;${{OPLIB_PROJECT_ROOT}}/tests/test_codegen/${codegen_case}\u0026#34; # Find node directories matching node_[0-9]+_[0-9] pattern (e.g., node_123_4) node_dirs=$(find . -maxdepth 1 -type d -regex \u0026#39;.*/node_[0-9]+_[0-9]\u0026#39; -exec basename {} \\;) for node_dir in $node_dirs; do # # Iterate through each node directory # Append oplib version info to version.txt echo -e \u0026#34;\\n\\ntx8be-oplib:\u0026#34; \u0026gt;\u0026gt; \u0026#34;${node_dir}/version.txt\u0026#34; # Append git status to version.txt to record repository state git status --porcelain \u0026gt;\u0026gt; \u0026#34;${node_dir}/version.txt\u0026#34; # Write last two git commits to version.txt for version history git log -2 \u0026gt;\u0026gt; \u0026#34;${node_dir}/version.txt\u0026#34; # Copy all stream-related files to node directory cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/stream*\u0026#34; \u0026#34;./${node_dir}/\u0026#34; # Copy CMakeLists_chip.txt as CMakeLists.txt for node cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/CMakeLists_chip.txt\u0026#34; \u0026#34;./${node_dir}/CMakeLists.txt\u0026#34; # Copy main_kcore.c to node directory cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/main_kcore.c\u0026#34; \u0026#34;./${node_dir}/\u0026#34; # Copy Makefile_chip as Makefile for node cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/Makefile_chip\u0026#34; \u0026#34;./${node_dir}/Makefile\u0026#34; # Find chip directories matching chip[0-9]+ pattern (e.g., chip0, chip1) chip_dirs=$(find \u0026#34;./${node_dir}\u0026#34; -maxdepth 1 -type d -regex \u0026#39;.*/chip[0-9]+\u0026#39; -exec basename {} \\;) # Iterate through each chip directory for dir in $chip_dirs; do # Copy Makefile_tile as Makefile for chip cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/Makefile_tile\u0026#34; \u0026#34;./${node_dir}/${dir}/Makefile\u0026#34; # Create Makefiles for 16 tiles (tiles0 to tiles15) for ((i=0; i\u0026lt;16; i++)); do dst_file=\u0026#34;./${node_dir}/${dir}/tiles${i}/Makefile\u0026#34; # Copy Makefile_main to each tile\u0026#39;s Makefile cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/Makefile_main\u0026#34; \u0026#34;$dst_file\u0026#34; done done done # Copy host implementation based on host_type if [ $host_type -eq 0 ]; then # Use thread-based host implementation cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/host_thread.cpp\u0026#34; \u0026#34;host.cpp\u0026#34; else # Use stream-based host implementation # Note: Fixed typo \u0026#39;$t{OPLIB_PROJECT_ROOT}\u0026#39; to \u0026#39;${{OPLIB_PROJECT_ROOT}}\u0026#39; cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/host_stream.cpp\u0026#34; \u0026#34;host.cpp\u0026#34; fi # Copy top-level CMakeLists.txt for test case cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/CMakeLists.txt\u0026#34; . # Copy top-level Makefile for test case cp \u0026#34;${{OPLIB_PROJECT_ROOT}}/tools/codegen/Makefile\u0026#34; . # Restore original directory popd } run_on_cmodel run_on_cmodel ç”¨äºåœ¨æŒ‡å®šçš„æµ‹è¯•ç”¨ä¾‹ç›®å½•ä¸­è¿è¡Œ cmodel ä»¿çœŸä»»åŠ¡ã€‚å‡½æ•°çš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ç¯å¢ƒè®¾ç½®ã€æ„å»ºã€æ‰§è¡Œä»¿çœŸè„šæœ¬æˆ–ç¨‹åºï¼Œå¹¶å¤„ç†é”™è¯¯ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†çš„åŠŸèƒ½è¯´æ˜ï¼š\nå‡½æ•°è¾“å…¥å‚æ•°ï¼š $1 (case_name): æ¥è‡ª run_codegen_layer çš„ codegen_pathï¼Œå¯èƒ½é™„åŠ  host_type. $2 (run_flag): è¿è¡Œæ ‡å¿—ï¼Œæ¥è‡ª run_codegen_layer çš„ cmp_flag ç”¨äºæ§åˆ¶ä»¿çœŸæ‰§è¡Œçš„æ–¹å¼ (ä¾‹å¦‚æ˜¯å¦è¿è¡Œæˆ–è¿è¡Œæ¨¡å¼) ã€‚ åˆ‡æ¢å·¥ä½œç›®å½•å¹¶æ‰§è¡Œ: åˆ‡æ¢åˆ°æµ‹è¯•ç”¨ä¾‹ç›®å½• ${{OPLIB_PROJECT_ROOT}}/tests/test_codegen/${case_name} è¿è¡Œ cmake .. -DUSING_RISCV=OFFï¼Œé…ç½®æ„å»ºç³»ç»Ÿï¼Œç¦ç”¨ RISCV æ”¯æŒã€‚ è¿è¡Œ make -j å¹¶åŠ¨æ€è®¾ç½®å¹¶è¡Œä»»åŠ¡æ•° (åŸºäº CPU æ ¸å¿ƒæ•°ï¼Œcat /proc/stat | grep cpu[0-9] -c) ä»¿çœŸæ‰§è¡Œ: æ ¹æ®å‚æ•°è¿è¡Œä»¿çœŸè„šæœ¬ (host_sim.sh) æˆ– host_sim. # Function to run a cmodel simulation for a given test case function run_on_cmodel() { # Assign first argument as the test case name case_name=$1 # Assign second argument as the run flag (controls execution mode) run_flag=$2 # Check if case_name is empty if [ -z \u0026#34;$case_name\u0026#34; ]; then echo \u0026#34;Error: case_name is empty\u0026#34; return 1 fi # Check if the test case directory exists if [ ! -d \u0026#34;${{OPLIB_PROJECT_ROOT}}/tests/test_codegen/${case_name}\u0026#34; ]; then echo \u0026#34;Can not find ${case_name}\u0026#34; return 1 fi # Change to the test case directory pushd \u0026#34;${{OPLIB_PROJECT_ROOT}}/tests/test_codegen/${case_name}\u0026#34; # FIXED DIR rm -rf build mkdir build cd build # Run cmake to configure the build, disabling RISCV support cmake .. -DUSING_RISCV=OFF # Run make with parallel jobs based on CPU core count make -j$(cat /proc/stat | grep cpu[0-9] -c) ret=$? # Capture the return code # If make fails, restore directory, print error, and exit if [[ $ret -ne 0 ]]; then popd echo $ret return $ret fi # Check if run_flag is empty if [ -z \u0026#34;$run_flag\u0026#34; ]; then if [ -e ../host_sim.sh ]; then # Check if host_sim.sh exists in the parent directory cp ../host_sim.sh . sh ./host_sim.sh ret=$? # Capture the return code # If script fails, restore directory, print error, and exit if [[ $ret -ne 0 ]]; then popd echo $ret return $ret fi else ./host_sim ../ # Run host_sim with parent directory as argument ret=$? # Capture the return code # If host_sim fails, restore directory, print error, and exit if [[ $ret -ne 0 ]]; then popd echo $ret return $ret fi fi # Check if run_flag is \u0026#34;0\u0026#34; or \u0026#34;1\u0026#34; elif [[ $run_flag == \u0026#34;0\u0026#34; ]] || [[ $run_flag == \u0026#34;1\u0026#34; ]]; then # Run host_sim with parent directory and run_flag ./host_sim ../ \u0026#34;$run_flag\u0026#34; ret=$? # Capture the return code # If host_sim fails, restore directory, print error, and exit if [[ $ret -ne 0 ]]; then popd echo $ret return $ret fi fi popd echo \u0026#34;${FUNCNAME[0]} $* passed\u0026#34; } run_codegen_case_soc_rtt run_codegen_case_soc_rtt ä½äº tx8-oplib/scripts/regression.shï¼Œå‡½æ•°ç”¨äºåœ¨ SOC ç¯å¢ƒä¸‹è¿è¡Œ RTT (Real-Time Transfer) æµ‹è¯•ã€‚å…¶ä¸»è¦æµç¨‹å¦‚ä¸‹ï¼š\nåˆå§‹åŒ–å’Œå‚æ•°è·å–ï¼š å‡½æ•°ä»å‘½ä»¤è¡Œå‚æ•°ä¸­è·å– case_name, copy_option, å’Œ multi_graph_enable. æ£€æŸ¥ case_name æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™è¾“å‡ºé”™è¯¯ä¿¡æ¯å¹¶è¿”å› 1. ç¯å¢ƒè®¾ç½®å’Œç›®å½•å¯¼èˆªï¼š å°†å·¥ä½œç›®å½•åˆ‡æ¢åˆ° ${OPLIB_PROJECT_ROOT}/tests/test_codegen/${case_name}. å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™è¾“å‡ºé”™è¯¯ä¿¡æ¯å¹¶è¿”å› 1ã€‚ æ„å»ºå’Œé…ç½®ï¼š æ‰§è¡Œ rm -rf ${case_name}_build æ¸…ç†ä¹‹å‰çš„æ„å»ºæ–‡ä»¶ã€‚ æ ¹æ® multi_graph_enable è®¾ç½® CONFIG_ARGSï¼Œå¦‚æœå¯ç”¨å¤šå›¾åˆ™è®¾ç½®ä¸º \u0026ldquo;-DMULTI_GRAPH=1\u0026rdquo;ï¼Œå¦åˆ™ä¸ºç©ºã€‚ è°ƒç”¨ cmake å‘½ä»¤ç”Ÿæˆæ„å»ºæ–‡ä»¶ï¼ŒæŒ‡å®šæ„å»ºç›®å½•ä¸º ${case_name}_buildï¼Œå¹¶æ ¹æ® copy_option è®¾ç½® COPY_RTT_FLAG. æ‰§è¡Œ make å‘½ä»¤è¿›è¡Œå®é™…æ„å»ºï¼Œç›®æ ‡åŒ…æ‹¬ all å’Œ chip_out. é”™è¯¯å¤„ç†å’Œé€€å‡ºï¼š æ¯æ¬¡å…³é”®æ­¥éª¤æ‰§è¡Œåï¼Œæ£€æŸ¥è¿”å›çŠ¶æ€ $retï¼Œå¦‚æœé 0ï¼Œåˆ™å¼¹å‡ºç›®å½•å¹¶è¿”å›é”™è¯¯ç ã€‚ æ„å»ºæˆåŠŸåè¾“å‡º ${FUNCNAME[0]} \u0026quot;passed\u0026quot; è¡¨ç¤ºé€šè¿‡ã€‚ æ¸…ç†å’Œè¿”å›: å‡½æ•°ç»“æŸæ—¶å¼¹å‡ºç›®å½•ï¼Œæ¢å¤åŸå§‹å·¥ä½œç›®å½•ã€‚ function run_codegen_case_soc_rtt() { echo \u0026#34;${FUNCNAME[0]} \u0026#39;start\u0026#39;\u0026#34; # è¾“å‡ºå‡½æ•°åå’Œ\u0026#34;start\u0026#34;è¡¨ç¤ºå¼€å§‹ case_name=$1 # è·å–ç”¨ä¾‹åç§° copy_option=$2 # è·å–å¤åˆ¶é€‰é¡¹ multi_graph_enable=$3 # è·å–å¤šå›¾å¯ç”¨æ ‡å¿— if [ -z \u0026#34;$case_name\u0026#34; ]; then # å¦‚æœç”¨ä¾‹åç§°ä¸ºç©º echo \u0026#34;case_name($case_name) not found \u0026#34; # è¾“å‡ºé”™è¯¯ä¿¡æ¯ return 1 # è¿”å›é”™è¯¯ç  1 fi case_dir=${OPLIB_PROJECT_ROOT}/tests/test_codegen/${case_name} # è®¾ç½®ç”¨ä¾‹ç›®å½• pushd ${case_dir} # åˆ‡æ¢åˆ°ç”¨ä¾‹ç›®å½• rm -rf ${case_name}_build # æ¸…ç†ä¹‹å‰çš„æ„å»ºæ–‡ä»¶ ret=$?; if [ [ $ret -ne 0 ]]; then popd; echo $ret; return $ret; fi # æ£€æŸ¥æ¸…ç†æ˜¯å¦æˆåŠŸ if [ -z \u0026#34;$multi_graph_enable\u0026#34; ]; then # å¦‚æœå¤šå›¾å¯ç”¨æ ‡å¿—ä¸ºç©º CONFIG_ARGS=\u0026#34;\u0026#34; # é…ç½®å‚æ•°ä¸ºç©º else # å¦åˆ™ CONFIG_ARGS=\u0026#34;-DMULTI_GRAPH=1\u0026#34; # è®¾ç½®å¤šå›¾é…ç½®å‚æ•° fi cmake -B \u0026#34;${case_name}_build\u0026#34; -DUSING_RISCV=ON -TX8FW_BASE=${OPLIB_PROJECT_ROOT}/release/riscv/tx8-yoc-rt-thread-smp ${CONFIG_ARGS} ; ret=$?; if [ [ $ret -ne 0 ]]; then popd; echo $ret; return $ret; fi # ç”Ÿæˆæ„å»ºæ–‡ä»¶ make -j -C \u0026#34;${case_name}_build\u0026#34; --target all chip_out ; ret=$?; if [ [ $ret -ne 0 ]]; then popd; echo $ret; return $ret; fi # æ‰§è¡Œæ„å»º popd # æ¢å¤åˆ°åŸå§‹ç›®å½• echo \u0026#34;${FUNCNAME[0]} \u0026#39;passed\u0026#39;\u0026#34; # è¾“å‡ºå‡½æ•°åå’Œ\u0026#34;passed\u0026#34;è¡¨ç¤ºé€šè¿‡ } export_tx8fw_to_env export_tx8fw_to_env å‡½æ•°çš„ä¸»è¦ç›®çš„æ˜¯è®¾ç½®ä¸ TX8FW ç›¸å…³çš„ç¯å¢ƒå˜é‡ï¼Œä»¥ä¾¿åç»­æ„å»ºæˆ–è¿è¡Œæ—¶ä½¿ç”¨ã€‚ä»¥ä¸‹æ˜¯å…¶æµç¨‹ï¼š\nè®¾ç½® SDK è·¯å¾„ï¼š å®šä¹‰ TX8FW çš„ SDK è·¯å¾„ soc_sdk_path ä¸º ${OPLIB_PROJECT_ROOT}/3rd_party/tx8-yoc-rt-thread-smp. æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨: æ£€æŸ¥è·¯å¾„ ${soc_sdk_path}/tool/tx8fw-xuantie-sdk æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶é€€å‡ºï¼ŒçŠ¶æ€ç ä¸º 1. å¯¼å‡ºç¯å¢ƒå˜é‡: æ‰“å°å¹¶è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ TX8FW_SDK_INSTALL_DIRï¼šæŒ‡å‘ ${soc_sdk_path}/tool/tx8fw-xuantie-sdkã€‚ TX8FW_TOOLCHAIN_VARIANTï¼šè®¾ç½®ä¸º cross-compileã€‚ æ¸…ç†ç›®å½•: ä½¿ç”¨ popd å‘½ä»¤æ¢å¤åˆ°ä¹‹å‰çš„ç›®å½•. function export_tx8fw_to_env() { soc_sdk_path=${OPLIB_PROJECT_ROOT}/3rd_party/tx8-yoc-rt-thread-smp # è®¾ç½® TX8FW SDK è·¯å¾„ pushd ${soc_sdk_path}/tool/tx8fw-xuantie-sdk # åˆ‡æ¢åˆ° TX8FW SDK å·¥å…·ç›®å½• if [ ! -d \u0026#34;xuantie-900-gcc-elf-newlib-x86_64-V2.8.0\u0026#34; ]; then # æ£€æŸ¥æŒ‡å®š SDK ç›®å½•æ˜¯å¦å­˜åœ¨ echo \u0026#34;${soc_sdk_path}/tool/tx8fw-xuantie-sdk didn\u0026#39;t exist\u0026#34; # å¦‚æœä¸å­˜åœ¨ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯ exit 1 # é€€å‡ºå¹¶è¿”å›çŠ¶æ€ç  1 fi echo \u0026#34;export TX8FW_SDK_INSTALL_DIR=${soc_sdk_path}/tool/tx8fw-xuantie-sdk\u0026#34; # æ‰“å°å¹¶è®¾ç½® TX8FW SDK å®‰è£…ç›®å½•ç¯å¢ƒå˜é‡ export TX8FW_SDK_INSTALL_DIR=${soc_sdk_path}/tool/tx8fw-xuantie-sdk # å¯¼å‡º TX8FW SDK å®‰è£…ç›®å½•ç¯å¢ƒå˜é‡ export TX8FW_TOOLCHAIN_VARIANT=cross-compile # å¯¼å‡ºå·¥å…·é“¾å˜ä½“ä¸º cross-compile popd # æ¢å¤åˆ°ä¹‹å‰çš„ç›®å½• } build_oplib_with_soc å‡½æ•° build_oplib_with_soc å‡½æ•°ç”¨äºæ„å»º OPLib å¹¶ç»“åˆç‰¹å®š SoC é…ç½®ã€‚ä»¥ä¸‹æ˜¯å…¶æµç¨‹ï¼š\næ‰“å°é¡¹ç›®æ ¹ç›®å½•ï¼š æ‰“å° OPLIB_PROJECT_ROOT ç¯å¢ƒå˜é‡ï¼Œç”¨äºè°ƒè¯•æˆ–æ—¥å¿—è®°å½•ã€‚\nåˆ‡æ¢ç›®å½•å’Œåˆå§‹åŒ–ï¼š ä½¿ç”¨ pushd åˆ‡æ¢åˆ° OPLIB_PROJECT_ROOT ç›®å½•ã€‚ å®šä¹‰å˜é‡ rm=rf build, mkdir=build å’Œ cd=buildï¼Œè¿™äº›å˜é‡å®é™…ä¸Šæ˜¯æ¨¡æ‹Ÿå‘½ä»¤ï¼ˆrm -rf buildã€mkdir build å’Œ cd buildï¼‰ã€‚ è®¾ç½®å¤åˆ¶æ ‡å¿—ï¼š æ£€æŸ¥ $1 (å³ copy_option) æ˜¯å¦ä¸º \u0026ldquo;NOT_COPY\u0026rdquo;ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™è®¾ç½® COPY_RTT_FLAG ä¸º --DRTT_HOST_COPY=OFFï¼Œå¦åˆ™ä¸ºç©ºã€‚ å¯¼å‡ºç¯å¢ƒå˜é‡å¹¶æ„å»ºï¼š è°ƒç”¨ export_tx8fw_to_env å‡½æ•°è®¾ç½® TX8FW ç›¸å…³ç¯å¢ƒå˜é‡ã€‚ è¿è¡Œ cmake å‘½ä»¤ï¼Œç”Ÿæˆæ„å»ºæ–‡ä»¶ï¼ŒæŒ‡å®šæ„å»ºé€‰é¡¹ -DUSING_RISCV=ON å’Œ TX8FW_BASEï¼Œå¹¶æ ¹æ® COPY_RTT_FLAG æ·»åŠ é¢å¤–å‚æ•°ã€‚ ä½¿ç”¨ make å‘½ä»¤æ‰§è¡Œæ„å»ºï¼Œç›®æ ‡åŒ…æ‹¬ grep epilog å’Œ c æ¸…ç†ç›®å½•: ä½¿ç”¨ popd å‘½ä»¤æ¢å¤åˆ°ä¹‹å‰çš„ç›®å½•. function build_oplib_with_soc() { echo ${OPLIB_PROJECT_ROOT} # æ‰“å° OPLib é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ pushd ${OPLIB_PROJECT_ROOT} # åˆ‡æ¢åˆ° OPLib é¡¹ç›®æ ¹ç›®å½• rm=rf build # å®šä¹‰æ¸…ç†æ„å»ºç›®å½•çš„å‘½ä»¤ mkdir=build # å®šä¹‰åˆ›å»ºæ„å»ºç›®å½•çš„å‘½ä»¤ cd=build # å®šä¹‰åˆ‡æ¢åˆ°æ„å»ºç›®å½•çš„å‘½ä»¤ COPY_RTT_FLAG=\u0026#34;\u0026#34; # åˆå§‹åŒ– RTT å¤åˆ¶æ ‡å¿— if [ \u0026#34;$1\u0026#34; == \u0026#34;NOT_COPY\u0026#34; ]; then # å¦‚æœä¼ å…¥çš„å¤åˆ¶é€‰é¡¹ä¸º NOT_COPY COPY_RTT_FLAG=\u0026#34;--DRTT_HOST_COPY=OFF\u0026#34; # è®¾ç½® RTT å¤åˆ¶æ ‡å¿—ä¸ºå…³é—­ fi export_tx8fw_to_env # è°ƒç”¨å‡½æ•°å¯¼å‡º TX8FW ç›¸å…³ç¯å¢ƒå˜é‡ cmake .. -DUSING_RISCV=ON -TX8FW_BASE=${OPLIB_PROJECT_ROOT}/release/riscv/tx8-yoc-rt-thread-smp ${COPY_RTT_FLAG} # ç”Ÿæˆæ„å»ºæ–‡ä»¶ï¼ŒæŒ‡å®š RISCV å’Œ TX8FW è·¯å¾„ ret=$?; if [ $ret -ne 0 ]; then popd; return $ret; fi # æ£€æŸ¥ cmake æ˜¯å¦æˆåŠŸï¼Œå¤±è´¥åˆ™è¿”å› make -j cat /proc/stat | grep epilog -c # æ‰§è¡Œæ„å»ºå¹¶æ£€æŸ¥ epilog ç›¸å…³ä¿¡æ¯ ret=$?; if [ $ret -ne 0 ]; then popd; return $ret; fi # æ£€æŸ¥ make æ˜¯å¦æˆåŠŸï¼Œå¤±è´¥åˆ™è¿”å› popd # æ¢å¤åˆ°ä¹‹å‰çš„ç›®å½• echo ${FUNCNAME[0]} \u0026#34;passed\u0026#34; # è¾“å‡ºå‡½æ•°åå’Œ\u0026#34;passed\u0026#34;è¡¨ç¤ºæ„å»ºæˆåŠŸ } run_on_soc_rtt run_on_soc_rttï¼Œç”¨äºåœ¨ç‰¹å®š SoC å’Œ RTT ç¯å¢ƒä¸‹è¿è¡Œæµ‹è¯•ç”¨ä¾‹ã€‚ä»¥ä¸‹æ˜¯å…¶ä¸»è¦æµç¨‹ï¼š\nåˆå§‹åŒ–å’Œå‚æ•°è·å–: å‡½æ•°ä»å‘½ä»¤è¡Œå‚æ•°ä¸­è·å– case_name, rtt_option å’Œ multi_graph_enable. æ£€æŸ¥ case_name æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™è¾“å‡ºé”™è¯¯ä¿¡æ¯å¹¶è¿”å› 1ã€‚ ç›®å½•åˆ‡æ¢å’Œæ¸…ç†: å°†å·¥ä½œç›®å½•åˆ‡æ¢åˆ° ${OPLIB_PROJECT_ROOT}/tests/test_codegen/${case_name}. æ‰§è¡Œ rm -rf ${case_name}_build æ¸…ç†ä¹‹å‰çš„æ„å»ºæ–‡ä»¶ã€‚ é…ç½®è®¾ç½®: æ ¹æ® multi_graph_enable è®¾ç½® CONFIG_ARGSï¼Œå¦‚æœå¯ç”¨å¤šå›¾åˆ™è®¾ç½®ä¸º \u0026ldquo;-DMULTI_GRAPH=1\u0026rdquo;ï¼Œå¦åˆ™ä¸ºç©ºã€‚ æ„å»ºå’Œè¿è¡Œï¼š ä½¿ç”¨ cmake ç”Ÿæˆæ„å»ºæ–‡ä»¶ï¼ŒæŒ‡å®šæ„å»ºç›®å½•ä¸º ${case_name}_buildï¼Œå¹¶è®¾ç½® -DUSING_RISCV=ON å’Œ -TX8FW_BASE è·¯å¾„ã€‚ ä½¿ç”¨ make å‘½ä»¤æ‰§è¡Œæ„å»ºï¼Œç›®æ ‡åŒ…æ‹¬ all å’Œ chip_out. æ¸…ç†å’Œè¿”å›: ä½¿ç”¨ popd æ¢å¤åˆ°åŸå§‹ç›®å½•ã€‚ function run_on_soc_rtt() { echo \u0026#34;${FUNCNAME[0]} \u0026#39;start\u0026#39;\u0026#34; # è¾“å‡ºå‡½æ•°åå’Œ\u0026#34;start\u0026#34;è¡¨ç¤ºå¼€å§‹ case_name=$1 # è·å–ç”¨ä¾‹åç§° rtt_option=$2 # è·å– RTT é€‰é¡¹ multi_graph_enable=$3 # è·å–å¤šå›¾å¯ç”¨æ ‡å¿— if [ -z \u0026#34;$case_name\u0026#34; ]; then # å¦‚æœç”¨ä¾‹åç§°ä¸ºç©º echo \u0026#34;case_name($case_name) not found \u0026#34; # è¾“å‡ºé”™è¯¯ä¿¡æ¯ return 1 # è¿”å›é”™è¯¯ç  1 fi case_dir=${OPLIB_PROJECT_ROOT}/tests/test_codegen/${case_name} # è®¾ç½®ç”¨ä¾‹ç›®å½• pushd ${case_dir} # åˆ‡æ¢åˆ°ç”¨ä¾‹ç›®å½• rm -rf ${case_name}_build # æ¸…ç†ä¹‹å‰çš„æ„å»ºæ–‡ä»¶ ret=$?; if [ [ $ret -ne 0 ]]; then popd; echo $ret; return $ret; fi # æ£€æŸ¥æ¸…ç†æ˜¯å¦æˆåŠŸï¼Œå¤±è´¥åˆ™è¿”å› if [ -z \u0026#34;$multi_graph_enable\u0026#34; ]; then # å¦‚æœå¤šå›¾å¯ç”¨æ ‡å¿—ä¸ºç©º CONFIG_ARGS=\u0026#34;\u0026#34; # é…ç½®å‚æ•°ä¸ºç©º else # å¦åˆ™ CONFIG_ARGS=\u0026#34;-DMULTI_GRAPH=1\u0026#34; # è®¾ç½®å¤šå›¾é…ç½®å‚æ•° fi cmake -B \u0026#34;${case_name}_build\u0026#34; -DUSING_RISCV=ON -TX8FW_BASE=${OPLIB_PROJECT_ROOT}/release/riscv/tx8-yoc-rt-thread-smp ${CONFIG_ARGS} ; ret=$?; if [ [ $ret -ne 0 ]]; then popd; echo $ret; return $ret; fi # ç”Ÿæˆæ„å»ºæ–‡ä»¶ï¼ŒæŒ‡å®š RISCV å’Œ TX8FW è·¯å¾„ make -C \u0026#34;${case_name}_build\u0026#34; --target all chip_out ; ret=$?; if [ [ $ret -ne 0 ]]; then popd; echo $ret; return $ret; fi # æ‰§è¡Œæ„å»ºï¼Œç›®æ ‡ä¸º all å’Œ chip_out popd # æ¢å¤åˆ°åŸå§‹ç›®å½• echo \u0026#34;${FUNCNAME[0]} \u0026#39;passed\u0026#39;\u0026#34; # è¾“å‡ºå‡½æ•°åå’Œ\u0026#34;passed\u0026#34;è¡¨ç¤ºé€šè¿‡ } ","permalink":"http://localhost:1313/blogs/tx8read/","summary":"tx8 regression","title":"Tx8read"},{"content":"Build Analytical Backend build.sh è„šæœ¬æ˜¯æ„å»ºè¿‡ç¨‹çš„é«˜çº§æ§åˆ¶å™¨ã€‚å…¶æ ¸å¿ƒèŒè´£æ˜¯è§£æç”¨æˆ·æ„å›¾ï¼Œæ‰§è¡Œé¢„æ„å»ºæ­¥éª¤ï¼Œå¹¶ä»¥æ­£ç¡®çš„å‚æ•°è°ƒç”¨åº•å±‚çš„ CMake å·¥å…·é“¾ã€‚\né€‰é¡¹è§£æ: è„šæœ¬é€šè¿‡ getopts å¤„ç†ä»¥ä¸‹å‘½ä»¤è¡Œæ ‡å¿—ï¼š\n-t \u0026lt;target\u0026gt;: æŒ‡å®šç¼–è¯‘ç›®æ ‡ã€‚æœ‰æ•ˆå€¼ä¸º all, congestion_unaware, congestion_awareã€‚æ­¤å€¼å°†ä½œä¸ºå˜é‡ä¼ é€’ç»™ CMakeã€‚ -l: è§¦å‘æ¸…ç† (cleanup) æµç¨‹ï¼Œåˆ é™¤æ‰€æœ‰æ„å»ºäº§ç‰©å¹¶ç»ˆæ­¢è„šæœ¬ã€‚ -d: å¯ç”¨è°ƒè¯• (Debug) æ¨¡å¼è¿›è¡Œç¼–è¯‘ã€‚ ç¯å¢ƒå‡†å¤‡ (setup, compile_chakra_et):\nsetup å‡½æ•°è´Ÿè´£åˆ›å»ºç”¨äºå­˜æ”¾ä¸­é—´æ–‡ä»¶å’Œæœ€ç»ˆäº§ç‰©çš„ build ç›®å½•ï¼Œç¡®ä¿æºç æ ‘çš„æ¸…æ´ã€‚åŒæ—¶ï¼Œå®ƒä¼šæ ¹æ®ç³»ç»Ÿæ ¸å¿ƒæ•°è®¾ç½®ä¸€ä¸ªä¸Šé™ä¸º 16 çš„å¹¶å‘ç¼–è¯‘çº¿ç¨‹æ•°ï¼Œä»¥ä¼˜åŒ–ç¼–è¯‘æ•ˆç‡ã€‚ compile_chakra_et å‡½æ•°è´Ÿè´£å¤„ç† et_def.proto è¿™ä¸€ Protobuf ä¾èµ–ã€‚å®ƒæ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨ï¼Œåˆ™è°ƒç”¨ protoc ç¼–è¯‘å™¨ç”Ÿæˆç›¸åº”çš„ C++ å’Œ Python æºç ã€‚ æ„å»ºæ‰§è¡Œ (compile_astrasim_analytical, compile_astrasim_analytical_as_debug):\nè¿™ä¸¤ä¸ªå‡½æ•°æ˜¯è„šæœ¬ä¸ CMake äº¤äº’çš„æ ¸å¿ƒã€‚å®ƒä»¬æ ¹æ®ç”¨æˆ·æ˜¯å¦æŒ‡å®š -d æ ‡å¿—ï¼Œå†³å®šæ˜¯æ‰§è¡Œæ ‡å‡† Release æ„å»ºè¿˜æ˜¯ Debug æ„å»ºã€‚å…³é”®åœ¨äºå®ƒä»¬ä¼šå°†ç”¨æˆ·æŒ‡å®šçš„ build_target ä½œä¸º -DBUILDTARGET å‚æ•°ä¼ é€’ç»™ CMakeã€‚ åå¤„ç† (create_symlink_*):\nç¼–è¯‘å®Œæˆåï¼Œcreate_symlink_congestion_unaware å’Œ create_symlink_congestion_aware ç­‰å‡½æ•°ä¼šä¸ºç”Ÿæˆçš„äºŒè¿›åˆ¶æ–‡ä»¶åˆ›å»ºç¬¦å·é“¾æ¥ã€‚æ­¤ä¸¾æ—¨åœ¨ç»´æŒå¯¹æ—§æ–‡ä»¶è·¯å¾„çš„å‘åå…¼å®¹æ€§ã€‚ CMakeLists.txt æ–‡ä»¶æ˜¯é¡¹ç›®çš„æ„å»ºè“å›¾ï¼Œå®ƒå‘ CMake é˜è¿°äº†é¡¹ç›®çš„ç»“æ„ã€ä¾èµ–å…³ç³»ä»¥åŠç¼–è¯‘è§„åˆ™ã€‚\nç¼–è¯‘ç¯å¢ƒè®¾å®š:\ncmake_minimum_required(VERSION 3.15): è§„å®šäº†è¿è¡Œæ­¤é…ç½®æ‰€éœ€çš„æœ€ä½ CMake ç‰ˆæœ¬ã€‚ set(CMAKE_CXX_STANDARD 17) å’Œ set(CMAKE_CXX_STANDARD_REQUIRED ON): å¼ºåˆ¶é¡¹ç›®å¿…é¡»åœ¨æ”¯æŒ C++17 æ ‡å‡†çš„ç¼–è¯‘ç¯å¢ƒä¸­æ„å»ºã€‚ ç¼–è¯‘æ ‡å¿— (Compiler Flags):\næ­¤æ–‡ä»¶ä¸ºä¸åŒçš„æ„å»ºç±»å‹ï¼ˆCMAKE_BUILD_TYPEï¼‰å®šä¹‰äº†ä¸åŒçš„ç¼–è¯‘å™¨æ ‡å¿—ã€‚ Release (é»˜è®¤æ¨¡å¼): set(CMAKE_CXX_FLAGS_RELEASE \u0026quot;-O3\u0026quot;) æŒ‡ç¤ºç¼–è¯‘å™¨è¿›è¡Œé«˜ç­‰çº§ä¼˜åŒ–ï¼Œä»¥è¿½æ±‚æœ€å¤§åŒ–ç¨‹åºæ€§èƒ½ã€‚ Debug: set(CMAKE_CXX_FLAGS_DEBUG \u0026quot;...\u0026quot;) åŒ…å«ä¸€ç³»åˆ—ç”¨äºè°ƒè¯•çš„æ ‡å¿—ï¼š -O0: å…³é—­æ‰€æœ‰ä¼˜åŒ–ï¼Œç¡®ä¿ç¼–è¯‘åçš„ä»£ç ä¸æºç è¡Œä¸ºä¸€è‡´ã€‚ -g: åœ¨å¯æ‰§è¡Œæ–‡ä»¶ä¸­åŒ…å«è°ƒè¯•ç¬¦å·ï¼Œè¿™æ˜¯ GDB ç­‰è°ƒè¯•å™¨å·¥ä½œçš„å‰æã€‚ -fsanitize=address,undefined,leak: å¯ç”¨ AddressSanitizerã€UndefinedBehaviorSanitizer å’Œ LeakSanitizerã€‚è¿™äº›æ˜¯å¼ºå¤§çš„è¿è¡Œæ—¶è¯Šæ–­å·¥å…·ï¼Œç”¨äºæ•è·å†…å­˜è®¿é—®é”™è¯¯ã€æœªå®šä¹‰è¡Œä¸ºåŠå†…å­˜æ³„æ¼ã€‚ é¡¹ç›®ç»“æ„ä¸ä¾èµ–:\nproject(AstraSim_Analytical): å£°æ˜é¡¹ç›®åç§°ã€‚ add_subdirectory(...): æ­¤æŒ‡ä»¤æ˜¯ç»„ç»‡é¡¹ç›®çš„å…³é”®ã€‚å®ƒå°† AstraSim æ ¸å¿ƒåº“ã€Analytical ç½‘ç»œåç«¯å’Œ AstraSim_Analytical å‰ç«¯ç­‰å¤šä¸ªå­æ¨¡å—çº³å…¥æ„å»ºè¿‡ç¨‹ã€‚ ç”¨æˆ·è‡ªå®šä¹‰é€‰é¡¹:\nset(BUILDTARGET \u0026quot;all\u0026quot; CACHE STRING ...): æ­¤è¡Œå®šä¹‰äº†ä¸€ä¸ªåä¸º BUILDTARGET çš„å¯ç¼“å­˜å˜é‡ã€‚è¿™ä½¿å¾—ç”¨æˆ·å¯ä»¥é€šè¿‡ cmake -D å‘½ä»¤ä»å¤–éƒ¨æ³¨å…¥è¯¥å˜é‡çš„å€¼ã€‚æ­¤å˜é‡éšåä¼šè¢«å­ç›®å½•ä¸­çš„ CMakeLists.txt æ–‡ä»¶ç”¨æ¥å®ç°æ¡ä»¶ç¼–è¯‘ã€‚ Build ns-3 Backend æ„å»ºå‘½ä»¤ä¸º ./build/astra_ns3/build.sh -cï¼Œä»–ä¼šæ‰§è¡Œè¯¥è„šæœ¬é‡Œçš„ compile å‡½æ•°\n1 2 3 4 5 6 function compile { cd \u0026#34;${NS3_DIR}\u0026#34; ./ns3 configure --enable-mpi ./ns3 build AstraSimNetwork -j 12 cd \u0026#34;${SCRIPT_DIR:?}\u0026#34; } ./ns3 configure --enable-mpi å‚æ•°è§£æ (parse_args): è„šæœ¬çš„ argparse æ¨¡å—ä¼šè¯†åˆ«å‡º configure å­å‘½ä»¤å’Œ --enable-mpi é€‰é¡¹ã€‚--enable-mpi æ˜¯ä¸€ä¸ªé¢„å®šä¹‰çš„\u0026quot;On-Off\u0026quot;é€‰é¡¹ï¼Œç”¨äºæ§åˆ¶ MPI (Message Passing Interface) åˆ†å¸ƒå¼ä»¿çœŸåŠŸèƒ½çš„æ”¯æŒã€‚ è¿›å…¥é…ç½®æ­¥éª¤ (configuration_step): ç”±äºæ£€æµ‹åˆ° configure å‘½ä»¤ï¼Œè„šæœ¬ä¼šè°ƒç”¨ configuration_step å‡½æ•°ã€‚ è°ƒç”¨ CMake (configure_cmake): configuration_step å‡½æ•°å†…éƒ¨ä¼šè°ƒç”¨ configure_cmake. è¿™ä¸ªå‡½æ•°æ˜¯ä¼šåŠ¨æ€åœ°æ„å»ºä¸€ä¸ª cmake å‘½ä»¤ã€‚ å®ƒä¼šæ£€æµ‹åˆ° --enable-mpi é€‰é¡¹ï¼Œå¹¶é€šè¿‡ on_off_condition å‡½æ•°å°†å…¶è½¬æ¢ä¸º CMake å˜é‡ -DNS3_MPI=ON. æœ€ç»ˆç»„è£…å‡ºçš„å‘½ä»¤ä¸ºä¸º cmake -S . -B cmake-cache -G \u0026quot;Unix Makefiles\u0026quot; -DCMAKE_BUILD_TYPE=default -DNS3_ASSERT=ON -DNS3_LOG=ON -DNS3_WARNINGS_AS_ERRORS=OFF -DNS3_MPI=ON --warn-uninitialized æ‰§è¡Œé…ç½®: è„šæœ¬é€šè¿‡ subprocess.run() æ‰§è¡Œè¿™æ¡ cmake å‘½ä»¤ ./ns3 build AstraSimNetwork -j 12 å‚æ•°è§£æ (parse_args): è„šæœ¬è¯†åˆ«å‡º build å­å‘½ä»¤ï¼Œç›®æ ‡ AstraSimNetworkï¼Œä»¥åŠå¹¶è¡Œä»»åŠ¡æ•° -j 12. å‰è€…ä¼šè¢«å­˜å…¥ args.build åˆ—è¡¨ï¼Œåè€…ä¼šè¢«å­˜å…¥ args.jobs. è¿›å…¥æ„å»ºæ­¥éª¤ (build_step): è„šæœ¬æ£€æµ‹åˆ° build å‘½ä»¤ï¼Œå¹¶è°ƒç”¨ build_step å‡½æ•°ã€‚ è°ƒç”¨ CMake æ„å»º (cmake_build): build_step å‡½æ•°ä¼šéå† args.build åˆ—è¡¨ä¸­çš„æ‰€æœ‰ç›®æ ‡ã€‚åœ¨è¿™é‡Œï¼Œå®ƒä¼šä¸º AstraSimNetwork è¿™ä¸ªç›®æ ‡è°ƒç”¨ cmake_build å‡½æ•°ã€‚ cmake_build å‡½æ•°ä¼šç»„è£…å‡ºä¸€æ¡ cmake --build å‘½ä»¤ã€‚ å°†ç›®æ ‡ AstraSimNetwork è½¬æ¢ä¸º --target AstraSimNetwork. å°†å¹¶è¡Œä»»åŠ¡æ•° 12 è½¬æ¢ä¸º -j 12. æœ€ç»ˆç»„è£…å‡ºçš„å‘½ä»¤ä¸º cmake --build cmake-cache --target AstraSimNetwork -j 12. Error When Building ns-3 call of overloaded â€˜format(\u0026hellip;)â€™ is ambiguous âŒ é—®é¢˜è¯Šæ–­ ğŸ©º é”™è¯¯ä¿¡æ¯ call of overloaded â€˜format(...)â€™ is ambiguous çš„æ„æ€æ˜¯ï¼Œç¼–è¯‘å™¨åœ¨ä½ çš„ä»£ç ä¸­é‡åˆ°äº†ä¸€ä¸ªåä¸º format çš„å‡½æ•°è°ƒç”¨ï¼Œä½†å®ƒæ‰¾åˆ°äº†å¤šä¸ªåŒåçš„ã€å¹¶ä¸”å‚æ•°ç±»å‹éƒ½èƒ½åŒ¹é…çš„ format å‡½æ•°å®šä¹‰ï¼Œå¯¼è‡´ç¼–è¯‘å™¨ä¸çŸ¥é“è¯¥é€‰æ‹©å“ªä¸€ä¸ªï¼Œå› æ­¤äº§ç”Ÿäº†â€œæ­§ä¹‰â€ï¼ˆambiguousï¼‰ã€‚\nè¿™ä¸ªæ­§ä¹‰çš„æ¥æºæ˜¯ï¼š\nstd::format (æ¥è‡ª C++20 æ ‡å‡†åº“): ä½ çš„é¡¹ç›®å¾ˆå¯èƒ½æ­£åœ¨ä½¿ç”¨æ”¯æŒ C++20 æˆ–æ›´é«˜ç‰ˆæœ¬çš„ç°ä»£ç¼–è¯‘å™¨ï¼ˆå¦‚ GCC 11+ï¼‰ã€‚C++20 æ ‡å‡†åº“å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ ¼å¼åŒ–å‡½æ•° std::formatã€‚ fmt::format (æ¥è‡ª {fmt} åº“): spdlog è¿™ä¸ªæ—¥å¿—åº“æ˜¯åŸºäºä¸€ä¸ªéå¸¸æµè¡Œçš„ç¬¬ä¸‰æ–¹æ ¼å¼åŒ–åº“ {fmt} æ„å»ºçš„ã€‚è¿™ä¸ªåº“ä¹Ÿæä¾›äº†ä¸€ä¸ªåŠŸèƒ½å‡ ä¹å®Œå…¨ç›¸åŒçš„ fmt::format å‡½æ•°ã€‚åœ¨ spdlog çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå®ƒé€šå¸¸å¯ä»¥ç›´æ¥ä»¥ format çš„å½¢å¼è¢«è°ƒç”¨ã€‚ å½“ä½ çš„ä»£ç ï¼ˆè¿™é‡Œæ˜¯ spdlog_setup çš„ä¸€éƒ¨åˆ†ï¼‰ç®€å•åœ°è°ƒç”¨ format(...) æ—¶ï¼Œå¦‚æœ C++20 çš„ \u0026lt;format\u0026gt; å¤´æ–‡ä»¶è¢«åŒ…å«ï¼Œç¼–è¯‘å™¨å°±ä¼šåŒæ—¶çœ‹åˆ° std::format å’Œ spdlog å†…éƒ¨çš„ fmt::formatã€‚ç”±äºä¸¤è€…éƒ½èƒ½å¤„ç†å­—ç¬¦ä¸²å­—é¢é‡ (const char[]) å’Œ std::stringï¼Œç¼–è¯‘å™¨æ— æ³•å†³å®šç”¨å“ªä¸ªï¼Œä»è€ŒæŠ¥é”™ã€‚\nå…³äº using fmt::format; ä¸ºä½•ä»ç„¶æ— æ•ˆçš„è§£é‡Š åŸå› æ˜¯ï¼Œé™¤äº†å¸¸è§„çš„å‘½åç©ºé—´æŸ¥æ‰¾è§„åˆ™ï¼ŒC++ è¿˜æœ‰ä¸€ä¸ªæ›´å¼ºå¤§çš„è§„åˆ™å«åšå‚æ•°ä¾èµ–æŸ¥æ‰¾ï¼ˆArgument-Dependent Lookup, ADLï¼‰ï¼Œæœ‰æ—¶ä¹Ÿè¢«ç§°ä¸º Koenig æŸ¥æ‰¾ã€‚\næˆ‘ä»¬æ¥æ¢³ç†ä¸€ä¸‹ç¼–è¯‘å™¨åœ¨çœ‹åˆ° format(...) è¿™è¡Œä»£ç æ—¶çš„â€œæ€è€ƒè¿‡ç¨‹â€ï¼š\nåœ¨å½“å‰ä½œç”¨åŸŸæŸ¥æ‰¾\nç¼–è¯‘å™¨çœ‹åˆ°äº†ä½ çš„ using fmt::format; å£°æ˜ã€‚å¾ˆå¥½ï¼Œå®ƒåœ¨å½“å‰ä½œç”¨åŸŸé‡Œæ‰¾åˆ°äº†ä¸€ä¸ªå«åš format çš„å‡½æ•°ï¼ˆä¹Ÿå°±æ˜¯ fmt::formatï¼‰ã€‚è¿™æˆä¸ºäº†å€™é€‰è€… Aã€‚\nå‚æ•°ä¾èµ–æŸ¥æ‰¾ (ADL) â€”â€” é—®é¢˜çš„æ ¹æº\næ¥ä¸‹æ¥ï¼Œç¼–è¯‘å™¨ä¼šæ£€æŸ¥ format(...) å‡½æ•°çš„æ‰€æœ‰å‚æ•°ç±»å‹ã€‚åœ¨ä½ çš„é”™è¯¯æ—¥å¿—é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°äº† const std::string\u0026amp; è¿™æ ·çš„å‚æ•°ã€‚\nADL è§„åˆ™è§„å®šï¼šå¦‚æœä¸€ä¸ªå‡½æ•°çš„å‚æ•°æ˜¯æŸä¸ªå‘½åç©ºé—´ N ä¸‹çš„ç±»å‹ï¼ˆæ¯”å¦‚ std::string æ˜¯ std å‘½åç©ºé—´ä¸‹çš„ï¼‰ï¼Œé‚£ä¹ˆç¼–è¯‘å™¨ä¹Ÿå¿…é¡»å»é‚£ä¸ªå‘½åç©ºé—´ N (è¿™é‡Œæ˜¯ std) é‡Œé¢å»æŸ¥æ‰¾åŒåçš„å‡½æ•°ã€‚ ç”±äº std::string æ˜¯ std å‘½åç©ºé—´çš„æˆå‘˜ï¼ŒADL è§„åˆ™è¢«è§¦å‘ï¼Œç¼–è¯‘å™¨è‡ªåŠ¨åœ°å» std å‘½åç©ºé—´é‡Œå¯»æ‰¾åä¸º format çš„å‡½æ•°ã€‚ å› ä¸ºä½ ä½¿ç”¨äº† C++20 ç¼–è¯‘å™¨ï¼Œå®ƒåœ¨ std å‘½åç©ºé—´é‡ŒæˆåŠŸæ‰¾åˆ°äº† std::formatã€‚è¿™æˆä¸ºäº†å€™é€‰è€… Bã€‚ äº§ç”Ÿæ­§ä¹‰\nç°åœ¨ç¼–è¯‘å™¨é™·å…¥äº†å›°å¢ƒã€‚å®ƒæ‰‹å¤´æœ‰ä¸¤ä¸ªåŒæ ·åŒ¹é…çš„å€™é€‰å‡½æ•°ï¼š\nå€™é€‰è€… A: fmt::format (é€šè¿‡ using å£°æ˜æ‰¾åˆ°) å€™é€‰è€… B: std::format (é€šè¿‡ ADL åœ¨å‚æ•°çš„å‘½åç©ºé—´é‡Œæ‰¾åˆ°) using å£°æ˜åªæ˜¯å°†ä¸€ä¸ªåå­—å¼•å…¥å½“å‰ä½œç”¨åŸŸï¼Œå®ƒå¹¶**æ²¡æœ‰è¶³å¤Ÿçš„â€œç‰¹æƒâ€**å»å‹åˆ¶ä¸€ä¸ªé€šè¿‡ ADL æ‰¾åˆ°çš„åŒæ ·ä¼˜ç§€çš„å€™é€‰è€…ã€‚å› ä¸ºä¸¤ä¸ªå‡½æ•°éƒ½èƒ½å®Œç¾å¤„ç†ä½ ä¼ å…¥çš„å‚æ•°ï¼Œç¼–è¯‘å™¨æ— æ³•åšå‡ºé€‰æ‹©ï¼Œæ‰€ä»¥å®ƒåªèƒ½æ”¾å¼ƒå¹¶æŠ¥å‘Šâ€œè°ƒç”¨æ˜¯æ¨¡ç³Šçš„ (ambiguous)â€ã€‚\nç»“è®ºä¸æœ€ç»ˆè§£å†³æ–¹æ¡ˆ âœ… è¿™ä¸ª C++ çš„ç‰¹æ€§æ„å‘³ç€ï¼Œåªè¦ä½ çš„å‡½æ•°å‚æ•°ä¸­åŒ…å«äº† std å‘½åç©ºé—´é‡Œçš„ç±»å‹ï¼ˆå¦‚ std::string, std::vector ç­‰ï¼‰ï¼ŒADL å°±æœ‰å¯èƒ½è¢«è§¦å‘ï¼Œä»è€ŒæŠŠ std é‡Œçš„å‡½æ•°ï¼ˆå¦‚ std::format, std::to_string ç­‰ï¼‰ä¹Ÿæ‹‰å…¥å€™é€‰åˆ—è¡¨ï¼Œé€ æˆæ„æƒ³ä¸åˆ°çš„å†²çªã€‚\nå› æ­¤ï¼Œå”¯ä¸€èƒ½ 100% æ¶ˆé™¤æ­§ä¹‰ã€è®©ç¼–è¯‘å™¨åˆ«æ— é€‰æ‹©çš„æ–¹æ³•ï¼Œå°±æ˜¯ä½¿ç”¨æ˜¾å¼çš„å‘½åç©ºé—´é™å®šï¼š\n1 2 3 // è¿™æ ·åšï¼Œæ˜¯åœ¨ç›´æ¥å‘Šè¯‰ç¼–è¯‘å™¨ï¼šâ€œåˆ«å»çŒœäº†ï¼Œæˆ‘å°±æ˜¯è¦è°ƒç”¨ fmt å‘½åç©ºé—´é‡Œçš„è¿™ä¸ª formatï¼â€ // è¿™ä¼šå®Œå…¨ç»•è¿‡ ADL å’Œå…¶ä»–æŸ¥æ‰¾è§„åˆ™ï¼Œç›´è¾¾ç›®æ ‡ã€‚ fmt::format(...); Runing Arguments æ‰§è¡Œä»¿çœŸéœ€è¦ä¼ é€’ä¸€äº›å‚æ•°ï¼Œå‘½ä»¤æ¨¡æ¿å¦‚ä¸‹\n1 2 3 4 5 {ASTRA_SIM_BIN} \\ --workload-configuration=${WORKLOAD_CONFIG} \\ --system-configuration=${SYSTEM_CONFIG} \\ --network-configuration=${NETWORK_CONFIG} \\ --remote-memory-configuration=${REMOTE_MEMORY_CONFIG} WORKLOAD_CONFIG astra-sim ä½¿ç”¨çš„æ˜¯ Chakra (Execution Trace) ä½œä¸º workload å±‚çš„è¾“å…¥ã€‚å°† chakra ä½œä¸º python package å®‰è£…åæœ‰å‡ ä¸ªå‘½ä»¤é€šè¿‡ pyproject.toml å¯¹åº”åˆ° pythonå‡½æ•°ã€‚\nExplanation of toml file pyproject.toml æ˜¯ä¸€ä¸ªæ ‡å‡†åŒ–çš„é…ç½®æ–‡ä»¶ï¼Œç”¨äºå®šä¹‰ Python é¡¹ç›®çš„å…ƒæ•°æ®ã€ä¾èµ–å…³ç³»ä»¥åŠæ„å»ºå’Œå¼€å‘å·¥å…·çš„é…ç½®ã€‚\n[build-system] æ„å»ºç³»ç»Ÿé…ç½®ï¼Œè¿™éƒ¨åˆ†å®šä¹‰äº†å¦‚ä½•æ„å»ºä½ çš„ Python åŒ…ã€‚ **requires**: åˆ—å‡ºäº†æ„å»ºé¡¹ç›®æœ¬èº«æ‰€å¿…éœ€çš„åŒ…ã€‚è¿™äº›æ˜¯æ„å»ºç¯å¢ƒçš„ä¾èµ–ï¼Œè€Œä¸æ˜¯ä½ ä»£ç è¿è¡Œæ—¶çš„ä¾èµ–ã€‚ setuptools, setuptools-grpc: è¡¨æ˜æ­¤é¡¹ç›®ä½¿ç”¨ setuptools ä½œä¸ºå…¶æ„å»ºå·¥å…·ï¼Œå¹¶éœ€è¦ setuptools-grpc æ’ä»¶ã€‚ **build-backend**: æŒ‡å®šäº†æ„å»ºå·¥å…·ä¸­å®é™…æ‰§è¡Œæ„å»ºè¿‡ç¨‹çš„ Python å¯¹è±¡ï¼ˆå…¥å£ç‚¹ï¼‰ã€‚ setuptools.build_meta: è¿™æ˜¯ setuptools æä¾›çš„æ ‡å‡†æ„å»ºåç«¯ã€‚ [project]ï¼šè¿™éƒ¨åˆ†åŒ…å«äº†é¡¹ç›®çš„åŸºæœ¬ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯ä¼šå±•ç¤ºåœ¨ PyPI (Python Package Index) ä¸Šã€‚ **name**: åŒ…çš„åç§°ï¼Œå³ pip install chakra ä¸­çš„ chakraã€‚ **requires-python**: è¿è¡Œæ­¤åŒ…æ‰€éœ€çš„æœ€ä½ Python ç‰ˆæœ¬ï¼Œè¿™é‡Œæ˜¯ 3.7 æˆ–æ›´é«˜ã€‚ **version**: å½“å‰åŒ…çš„ç‰ˆæœ¬å·ã€‚ **readme**: æŒ‡å‘ä¸€ä¸ªæ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶çš„å†…å®¹å°†ä½œä¸ºé¡¹ç›®åœ¨ PyPI ä¸Šçš„è¯¦ç»†æè¿°ã€‚ **license**: æŒ‡å‘åŒ…å«è®¸å¯è¯ä¿¡æ¯çš„æ–‡ä»¶ã€‚ **authors**ï¼šé¡¹ç›®çš„ä½œè€…ä¿¡æ¯ã€‚ **dependencies**: é¡¹ç›®è¿è¡Œæ—¶çš„ä¾èµ–é¡¹ã€‚å½“ç”¨æˆ· pip install chakra æ—¶ï¼Œè¿™äº›åŒ…ä¹Ÿä¼šè¢«ä¸€å¹¶å®‰è£…ã€‚ protobuf==5.*: éœ€è¦ç‰ˆæœ¬ä¸º 5.x çš„ protobuf åº“ã€‚ graphviz, networkx, pydot: å…¶ä»–æ ‡å‡†çš„ç¬¬ä¸‰æ–¹åº“ä¾èµ–ã€‚ HolisticTraceAnalysis @ git+...: è¿™æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ä¾èµ–ã€‚å®ƒç›´æ¥ä» GitHub ä»“åº“çš„ä¸€ä¸ªç‰¹å®š commit (d731cc...) æ¥å®‰è£…ã€‚è¿™ç¡®ä¿äº†é¡¹ç›®ä¾èµ–äºä¸€ä¸ªç¨³å®šä¸”ä¸ä¼šæ„å¤–å˜åŠ¨çš„ç‰ˆæœ¬ã€‚ [project.urls]ï¼šé¡¹ç›®ç›¸å…³é“¾æ¥ï¼Œè¿™äº›é“¾æ¥ä¼šæ˜¾ç¤ºåœ¨ PyPI é¡µé¢çš„ä¾§è¾¹æ ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯çš„å…¥å£ã€‚ **Homepage**, **Documentation**, **Repository**: åˆ†åˆ«æŒ‡å‘é¡¹ç›®ä¸»é¡µã€æ–‡æ¡£å’Œä»£ç ä»“åº“çš„ URLã€‚ [tool.setuptools]ï¼šè¿™éƒ¨åˆ†æ˜¯é’ˆå¯¹æ„å»ºå·¥å…· setuptools çš„è¯¦ç»†é…ç½®ã€‚ **package-dir**: å®šä¹‰äº† Python åŒ…åä¸å®é™…æºä»£ç ç›®å½•ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚ ä¾‹å¦‚ï¼Œ\u0026quot;chakra.src.converter\u0026quot; = \u0026quot;src/converter\u0026quot; è¡¨ç¤ºå½“ç”¨æˆ· import chakra.src.converter æ—¶ï¼ŒPython ä¼šä» src/converter/ ç›®å½•ä¸‹å¯»æ‰¾ä»£ç ã€‚è¿™ä½¿å¾—é¡¹ç›®å¯ä»¥ä½¿ç”¨ src å¸ƒå±€ã€‚ **package-data**: æŒ‡å®šéœ€è¦åŒ…å«åœ¨æœ€ç»ˆå‘å¸ƒåŒ…ä¸­çš„é Python æ–‡ä»¶ã€‚ \u0026quot;chakra.schema.protobuf\u0026quot; = [\u0026quot;et_def.proto\u0026quot;]: è¡¨ç¤ºéœ€è¦å°† et_def.proto è¿™ä¸ªæ–‡ä»¶æ‰“åŒ…åˆ° chakra.schema.protobuf è¿™ä¸ªåŒ…é‡Œã€‚ [project.scripts]ï¼šè¿™éƒ¨åˆ†å®šä¹‰äº†åœ¨å®‰è£…åŒ…æ—¶åº”åˆ›å»ºçš„å‘½ä»¤è¡Œå·¥å…·ã€‚ **chakra_converter = \u0026quot;chakra.src.converter.converter:main\u0026quot;**: è¿™è¡Œé…ç½®æ„å‘³ç€ï¼Œå½“ç”¨æˆ·å®‰è£…æ­¤åŒ…åï¼Œä»–ä»¬å¯ä»¥åœ¨ç»ˆç«¯ä¸­ç›´æ¥è¿è¡Œ chakra_converter å‘½ä»¤ã€‚æ‰§è¡Œæ­¤å‘½ä»¤æ—¶ï¼Œç³»ç»Ÿä¼šè°ƒç”¨ chakra.src.converter.converter æ¨¡å—ä¸­çš„ main å‡½æ•°ã€‚ [tool.ruff]ï¼šè¿™éƒ¨åˆ†æ˜¯ç”¨äºé…ç½® Ruff é«˜æ€§èƒ½ä»£ç æ£€æŸ¥ï¼ˆLinterï¼‰å’Œæ ¼å¼åŒ–ï¼ˆFormatterï¼‰å·¥å…·ã€‚ **target-version**, **line-length**, **exclude**: åŸºæœ¬é…ç½®ï¼Œå¦‚ç›®æ ‡ Python ç‰ˆæœ¬ã€æ¯è¡Œæœ€å¤§é•¿åº¦å’Œè¦æ’é™¤æ£€æŸ¥çš„æ–‡ä»¶ã€‚ **[tool.ruff.lint]**: Linter çš„å…·ä½“é…ç½®ã€‚ **select**: å¯ç”¨ä¸€ç³»åˆ—ä»£ç è§„åˆ™é›†ï¼ˆä¾‹å¦‚ D ä»£è¡¨æ–‡æ¡£å­—ç¬¦ä¸² pydocstyleï¼ŒI ä»£è¡¨å¯¼å…¥æ’åº isortï¼‰ã€‚ **ignore**: å…¨å±€ç¦ç”¨çš„ç‰¹å®šè§„åˆ™ã€‚æ³¨é‡Šä¸­è§£é‡Šäº†å¿½ç•¥å®ƒä»¬çš„åŸå› ï¼ˆä¾‹å¦‚ï¼Œè§„åˆ™å†²çªæˆ–å¾…åŠäº‹é¡¹ï¼‰ã€‚ **per-file-ignores**: é’ˆå¯¹ç‰¹å®šæ–‡ä»¶æˆ–ç›®å½•ç¦ç”¨è§„åˆ™ã€‚ä¾‹å¦‚ï¼Œ\u0026quot;**/tests/*\u0026quot; = [\u0026quot;D\u0026quot;] è¡¨ç¤ºåœ¨æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ä¸­éƒ½ç¦ç”¨æ–‡æ¡£å­—ç¬¦ä¸²æ£€æŸ¥ã€‚ **[tool.ruff.format]**: æ ¼å¼åŒ–å™¨çš„é…ç½®ï¼Œå¦‚ä½¿ç”¨ç©ºæ ¼ä½œä¸ºç¼©è¿›é£æ ¼ã€‚ [tool.pyright]ï¼šè¿™éƒ¨åˆ†é…ç½®äº† Pyrightï¼Œä¸€ä¸ªç”±å¾®è½¯å¼€å‘çš„é™æ€ç±»å‹æ£€æŸ¥å·¥å…·ã€‚ **typeCheckingMode**: ç±»å‹æ£€æŸ¥çš„ä¸¥æ ¼ç¨‹åº¦ï¼Œè¿™é‡Œæ˜¯ basicï¼ˆåŸºç¡€æ¨¡å¼ï¼‰ã€‚ **exclude**ï¼šåœ¨è¿›è¡Œç±»å‹æ£€æŸ¥æ—¶è¦å¿½ç•¥çš„æ–‡ä»¶å’Œç›®å½•ã€‚ **report...**ï¼šå…³é—­ç‰¹å®šçš„é”™è¯¯æˆ–è­¦å‘ŠæŠ¥å‘Šã€‚ [tool.vulture]ï¼šè¿™éƒ¨åˆ†é…ç½®äº† Vultureï¼Œä¸€ä¸ªç”¨äºå‘ç°é¡¹ç›®ä¸­æœªä½¿ç”¨ï¼ˆ\u0026ldquo;æ­»\u0026rdquo;ï¼‰ä»£ç çš„å·¥å…·ã€‚ **ignore_names**: è®© Vulture å¿½ç•¥æŸäº›ç‰¹å®šçš„å˜é‡åæˆ–å‡½æ•°åï¼Œå³ä½¿å®ƒä»¬çœ‹èµ·æ¥æœªä½¿ç”¨ã€‚ **min_confidence**: è®¾ç½®æŠ¥å‘Šé—®é¢˜çš„æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼ã€‚100 è¡¨ç¤ºåªæœ‰åœ¨ Vulture 100% ç¡®å®šä»£ç æ˜¯æ— ç”¨çš„æ—¶å€™æ‰ä¼šæŠ¥å‘Šï¼Œè¿™å¯ä»¥æœ‰æ•ˆå‡å°‘è¯¯æŠ¥ã€‚ 1 2 3 4 5 6 7 [project.scripts] chakra_converter = \u0026#34;chakra.src.converter.converter:main\u0026#34; chakra_generator = \u0026#34;chakra.src.generator.generator:main\u0026#34; chakra_jsonizer = \u0026#34;chakra.src.jsonizer.jsonizer:main\u0026#34; chakra_timeline_visualizer = \u0026#34;chakra.src.timeline_visualizer.timeline_visualizer:main\u0026#34; chakra_trace_link = \u0026#34;chakra.src.trace_link.trace_link:main\u0026#34; chakra_visualizer = \u0026#34;chakra.src.visualizer.visualizer:main\u0026#34; Generate Execution Trace ASTRA-sim çš„ ET å‘½åæ ¼å¼ä¸º {path prefix/trace name}.{npu_id}.et. Chakra ET çš„è·å–æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤º1ã€‚\nCollect ET from PyTorch PyTorch ET è´Ÿè´£ CPU ç®—å­ï¼Œå¹¶æ˜ç¡®è¡¨ç¤ºå®ƒä»¬ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚ Kineto Trace ç¼–ç  GPU ç®—å­åŠå…¶å¼€å§‹å’Œç»“æŸæ—¶é—´ã€‚ Merge Trace by chkra_trace_linkï¼šå°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ª PyTorch ET+. è¯¥æ ¼å¼æœ¬è´¨ä¸Šéµå¾ª PyTorch ET çš„æ¨¡å¼ï¼Œä½†åŒæ—¶ä¹Ÿç¼–ç äº† GPU æ“ä½œç¬¦åŠå…¶ä¾èµ–å…³ç³»ã€‚ Convert to Chakra ET by chakra_converter Overview of Trace Collection å…·ä½“çš„æ•™ç¨‹å’Œä¾‹å­å¯ä»¥åœ¨ Conversion Guide å’Œ Practical Example æ‰¾åˆ°ã€‚\nUsing ET Converter å¯ä»¥å°† astra-sim 1.0 çš„æ–‡æœ¬è¾“å…¥è½¬æ¢æˆ Chakra ET.\n1 2 3 4 5 6 7 cd ./extern/graph_frontend/chakra/ pip3 install . chakra_converter Text \\ --input ../../../examples/text_converter/text_workloads/Resnet50_DataParallel.txt \\ --output ../../../examples/text_converter/text_workloads/Resnet50_DataParallel \\ --num-npus 8 \\ --num-passes 1 workload æ–‡æœ¬æ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼Œå…¶ä¸­é€šä¿¡å¤§å°å•ä½æ˜¯å­—èŠ‚ï¼Œè®¡ç®—æ—¶é—´ä»¥å‘¨æœŸæ•°è¡¨ç¤ºã€‚\nç¬¬ä¸€è¡Œï¼š(DATA/HYBRID_TRANSFORMER/HYBRID_DLRM) è¯¥è¡ŒæŒ‡å®šè®­ç»ƒå¾ªç¯çš„å¹¶è¡ŒåŒ–ç±»å‹ã€‚DATA è¡¨ç¤ºçº¯æ•°æ®å¹¶è¡Œæ–¹æ³•ï¼ŒHYBRID_TRANSFORMER è¡¨ç¤ºä¸“ä¸º Transformer DNN ç½‘ç»œè®¾è®¡çš„æ··åˆå¹¶è¡Œæ–¹æ³•ï¼Œè€Œ HYBRID_DLRM è¡¨ç¤ºä¸“ä¸º DLRM DNN ç½‘ç»œä¼˜åŒ–çš„æ··åˆå¹¶è¡Œæ–¹æ³•ã€‚ ç¬¬äºŒè¡Œï¼š(int) è¯¥è¡Œè¡¨ç¤º DNN çš„å±‚æ•°ã€‚ åç»­è¡Œï¼šæ¯è¡Œæè¿°ä¸€å±‚ã€‚å±‚çš„æè¿°æ ¼å¼å¦‚ä¸‹ï¼š {(string: å±‚åç§°) (int: ä¿ç•™å˜é‡) (int: å‰å‘è®¡ç®—æ—¶é—´) (ALLREDUCE/ALLGATHER/ALLTOALL: å‰å‘é€šä¿¡ç±»å‹) (int: å‰å‘é€šä¿¡å¤§å°) (int: è¾“å…¥æ¢¯åº¦è®¡ç®—æ—¶é—´) (ALLREDUCE/ALLGATHER/ALLTOALL: è¾“å…¥æ¢¯åº¦é€šä¿¡ç±»å‹) (int: è¾“å…¥æ¢¯åº¦é€šä¿¡å¤§å°) (int: æƒé‡æ¢¯åº¦è®¡ç®—æ—¶é—´) (ALLREDUCE/ALLGATHER/ALLTOALL: æƒé‡æ¢¯åº¦é€šä¿¡ç±»å‹) (int: æƒé‡æ¢¯åº¦é€šä¿¡å¤§å°) (é›†åˆé€šä¿¡å®Œæˆåï¼Œæƒé‡/è¾“å…¥/è¾“å‡ºæ›´æ–°çš„å»¶è¿Ÿ)}` Note\næ¯ä¸€å±‚çš„å‚æ•°å†™è¦åœ¨åŒä¸€è¡Œï¼ï¼ï¼\nEnable Communicator Groups astra-sim 2.0 æ”¯æŒé€šä¿¡ç»„ã€‚å¯ä»¥é€šè¿‡æŒ‡å®š --comm-group-configuration JSON æ–‡ä»¶æ¥æŒ‡å®šï¼Œé»˜è®¤åªæœ‰ä¸€ä¸ªé€šä¿¡ç»„ã€‚\n{ // The first/second communicator group, with ID 0/1, includes GPU IDs from 0-3/4-7. // \u0026#34;0\u0026#34;: [0, 1, 2, 3], // \u0026#34;1\u0026#34;: [4, 5, 6, 7] \u0026#34;\u0026lt;communicator_group_id\u0026gt;\u0026#34; : [gpu_ids] } SYSTEM_CONFIG System Layer Workload å±‚ä¼šéå† Chakra ET ä¸­çš„èŠ‚ç‚¹ï¼Œå¹¶ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ‰€æŒ‡ä»£çš„æ“ä½œå‘å‡ºç›¸åº”çš„å‘½ä»¤ã€‚System å±‚æ¥æ”¶è¿™äº›å‘½ä»¤ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºé€‚åˆç½‘ç»œã€è®¡ç®—æˆ–å†…å­˜åç«¯çš„æ ¼å¼ï¼Œä»è€Œæ­£ç¡®æ¨¡æ‹Ÿæ“ä½œã€‚æ ¹æ®æ“ä½œçš„ç±»å‹ï¼Œç³»ç»Ÿå±‚çš„è¡Œä¸ºä¼šæœ‰æ‰€ä¸åŒï¼Œå…·ä½“å¦‚ä¸‹ï¼š\nè®¡ç®—æ“ä½œï¼šå‘è®¡ç®—åç«¯å‘å‡ºè°ƒç”¨ï¼Œä»¥æ¨¡æ‹Ÿæ“ä½œçš„æŒç»­æ—¶é—´ã€‚ å†…å­˜æ“ä½œï¼š å†…å­˜ é€šä¿¡æ“ä½œï¼šå°†é›†åˆé€šä¿¡åˆ†è§£ä¸ºç‚¹å¯¹ç‚¹çš„å‘é€å’Œæ¥æ”¶æ¶ˆæ¯ï¼Œå¹¶å‘ç½‘ç»œåç«¯å‘å‡ºâ€œå‘é€â€æˆ–â€œæ¥æ”¶â€è°ƒç”¨ï¼Œä»¥æ¨¡æ‹Ÿæ¶ˆæ¯çš„ä¼ è¾“è¿‡ç¨‹ã€‚ Collective Scheduler Collective Scheduler\næ¯ä¸ªé˜Ÿåˆ—éƒ½æœ‰è®¸å¤š StreamBaseline å¯¹è±¡ (å›¾ä¸­å³ä¸Šè§’)ï¼Œä»£è¡¨äº†æ•´ä¸ªé›†åˆé€šä¿¡çš„æµç¨‹ï¼Œphase_to_go æ˜¯ä¸€ä¸ªç”¨äºè¡¨ç¤ºè¿™äº›é˜¶æ®µçš„é˜Ÿåˆ—ï¼Œmy_current_phase æ˜¯æŒ‡å‘å½“å‰æ‰§è¡Œé˜¶æ®µçš„æŒ‡é’ˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 class StreamBaseline : public BaseStream { public: StreamBaseline(Sys* owner, DataSet* dataset, int stream_id, std::list\u0026lt;CollectivePhase\u0026gt; phases_to_go, int priority); // my_current_phase[CollectivePhase] is defined in BaseStream void init(); void call(EventType event, CallData* data); void consume(RecvPacketEventHandlerData* message); }; å¯¹äºæ¯ä¸ª stream proceed_to_next_vnet_baseline (astra-sim/system/Sys.cc) ç”¨äºæ¨è¿›é€šä¿¡é˜¶æ®µå¹¶ä¸”è´Ÿè´£åœ¨é˜Ÿåˆ—ä¹‹é—´ç§»åŠ¨ stream å¯¹è±¡ã€‚ä»¥ä¸‹å‡ ç§æƒ…å†µä¼šè°ƒç”¨è¯¥å‡½æ•°ï¼š\nstream ç¬¬ä¸€æ¬¡è¢«ç§»åŠ¨å‡º ready_list å¹¶ä¸”å°†è¢«æ’å…¥åˆ° active_streams. stream å®Œæˆäº†ä¸€ä¸ªé€šä¿¡é˜¶æ®µå¹¶ä¸”ç­‰å¾…ä¸‹ä¸€ä¸ªé˜¶æ®µã€‚ stream å®Œæˆäº†æ‰€æœ‰çš„é€šä¿¡é˜¶æ®µã€‚ (2-1) åˆ° (2-5) æè¿°äº†è¯¥å‡½æ•°çš„è¡Œä¸º\næŸ¥çœ‹å½“å‰æŒæœ‰ stream çš„é˜Ÿåˆ—: ä»é˜Ÿåˆ—ä¸­åˆ é™¤ StreamBaseline å¯¹è±¡ (æµçš„å®Œæˆé¡ºåºå¯èƒ½ä¸å®ƒä»¬å¼€å§‹æ‰§è¡Œçš„é¡ºåºä¸åŒ)ã€‚\nä¿®æ”¹ StreamBaseline å¯¹è±¡: å·²å®Œæˆçš„é›†åˆé€šä¿¡é˜¶æ®µä» phases_to_go ä¸­å¼¹å‡ºï¼Œmy_current_phase ç°åœ¨æŒ‡å‘ä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„é˜¶æ®µã€‚\nä½¿ç”¨ insert_stream å°† StreamBaseline å¯¹è±¡æ’å…¥åˆ°ä¸‹ä¸€ä¸ªé˜Ÿåˆ—ä¸­ã€‚\nè°ƒç”¨å‡½æ•° notify_stream_removed å‡½æ•°æŸ¥çœ‹å‰ä¸€ä¸ªé˜Ÿåˆ—çš„å¤´éƒ¨ã€‚ stream_pointer æŒ‡å‘é˜Ÿåˆ—ä¸­ç¬¬ä¸€ä¸ªæœªè¿è¡Œçš„ stream (æ ‡è®°ä¸ºè“è‰²)ã€‚è¯¥å‡½æ•°é€šè¿‡è°ƒç”¨ StreamBaseline::init() æ¥å¯åŠ¨ stream çš„ä¸‹ä¸€ä¸ªé˜¶æ®µçš„æ‰§è¡Œã€‚\nä½¿ç”¨ notify_stream_added è§¦å‘æ–°é˜Ÿåˆ—å¤´éƒ¨ stream çš„é€šä¿¡é˜¶æ®µæ‰§è¡Œã€‚\nåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œproceed_to_next_vnet_baseline ä¼šæ‰§è¡Œä¸Šè¿°æ­¥éª¤çš„ä¸€éƒ¨åˆ†ã€‚å…·ä½“å¦‚ä¸‹ï¼š\nåˆšä» ready_list ä¸­ç§»é™¤ï¼š\nproceed_to_next.. ä¼šåˆå§‹åŒ– stream (1-2)ï¼Œå°†å…¶æ’å…¥åˆ°ç¬¬ä¸€ä¸ªé˜Ÿåˆ—ä¸­ (1-3)ï¼Œå¹¶è§¦å‘è¯¥é˜Ÿåˆ—å¤´éƒ¨çš„æµæ‰§è¡Œã€‚\nstream å®Œæˆï¼š\nè¯¥å‡½æ•°ä¼šä»ä¹‹å‰çš„é˜Ÿåˆ—ä¸­åˆ é™¤ stream (3-1)ï¼Œå¹¶è§¦å‘ä¹‹å‰é˜Ÿåˆ—å¤´éƒ¨çš„ stream æ‰§è¡Œã€‚æ­¤å¤–ï¼ŒStreamBaseline å¯¹è±¡ä¼šè¢«åˆ é™¤ï¼Œå¹¶è°ƒç”¨ notify_stream_finishedï¼Œä»¥é€šçŸ¥ Sys å¯¹è±¡ stream å·²ç»ç»“æŸ (3-6)\nCollective Implementation Overview of Collective Implementation æ¨¡æ‹Ÿå™¨å°†é›†ä½“é€šä¿¡åˆ†è§£ä¸ºå‘é€å’Œæ¥æ”¶æ¶ˆæ¯çš„æ–¹å¼æœ‰ä¸¤ç§ã€‚ç›®å‰æœ€å¸¸ç”¨çš„æ–¹æ³•æ˜¯æ¨¡æ‹Ÿå™¨å®ç°ä¸€ç»„é¢„å®šä¹‰çš„å¸¸è§ç®—æ³• (ä¾‹å¦‚ Ringã€DoubleBinaryã€HalvingDoubling ç­‰)ã€‚è¿™ç§â€œåŸç”Ÿâ€å®ç°é€»è¾‘ä½äºæ¨¡æ‹Ÿå™¨çš„ä»£ç åº“ä¸­ï¼Œå…è®¸ç”¨æˆ·å¿«é€Ÿæ¢ç´¢ä¸€ç»„é¢„å®šä¹‰çš„ç®—æ³•ã€‚\nè‡ª 2024 å¹´ 8 æœˆä»¥æ¥ï¼ŒASTRA-sim æ”¯æŒäº†ä¸€ç§æ–°çš„é›†åˆé€šä¿¡ç®—æ³•è¡¨ç¤ºæ–¹å¼ã€‚System å±‚é€šè¿‡æš´éœ²ä¸€ä¸ªé›†ä½“ APIï¼Œå¯ä»¥æ¥æ”¶ä»»æ„é›†ä½“ç®—æ³•çš„å®šä¹‰ã€‚\nè¿™ä¸¤ç§æ–¹æ³•éƒ½æ˜¯å¯¹ CollectivePhase::Algorithm å¯¹è±¡çš„å®ç°ï¼Œè¯¥å¯¹è±¡æ˜¯ System å±‚ä¸­çš„è°ƒåº¦å•å…ƒ. generate_collective_phase ä¼šæ ¹æ®ä¸åŒçš„ç®—æ³•åœ¨åˆ›å»º CollectivePhase çš„æ—¶å€™ä¼ å…¥å¯¹åº”çš„ Algorithm.\nASTRA-Sim Native Implementation ç›¸å…³çš„å®ç°éƒ½ä½äºè¯¥æ–‡ä»¶å¤¹ä¸‹, naive å®ç°çš„é™åˆ¶æ˜¯å½“éœ€è¦æ¨¡æ‹Ÿä¸€ä¸ªæ–°çš„é›†åˆé€šä¿¡ç®—æ³•æ—¶ç®—æ³•ï¼Œå¿…é¡»å®ç°æ•´ä¸ªé›†åˆï¼Ÿéšç€ä¸è§„åˆ™é›†åˆé€šä¿¡ (å¦‚ TACOS(Topology Aware CollectiveS), MSCCLang(åŸºäº DSL)) ä¸­å·¥ä½œçš„å¢åŠ ï¼Œå¿«é€Ÿæ¨¡æ‹Ÿå’Œè¿­ä»£å„ç§ç®—æ³•çš„éœ€æ±‚å˜å¾—è¶Šæ¥è¶Šå¤šã€‚\nChakra Based Arbitrary Definition Through Collective API å› æ­¤ä¸€ä¸ªæ–°çš„ APæ¥æ¥å—ä»»ä½•é›†åˆé€šä¿¡ç®—æ³•çš„å®šä¹‰ï¼Œè€Œä¸å±€é™äºé¢„å®šä¹‰çš„è§„åˆ™é€šä¿¡æ¨¡å¼ã€‚å¯¹äºé€šä¿¡è¡¨ç¤ºï¼Œä½¿ç”¨ Chakra ET æ¨¡å¼ä½œä¸ºå•ç‹¬çš„å›¾ã€‚å°†é›†åˆé€šä¿¡ç®—æ³•è¡¨ç¤ºä¸ºChakra ET æ¨¡å¼ä¸­ COMM_SENDï¼ŒCOMM_RECV èŠ‚ç‚¹çš„å›¾ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒSystem å±‚ä¸æ˜¯å°†é›†åˆé€šä¿¡åˆ†è§£ä¸ºå‘é€å’Œæ¥æ”¶æ¶ˆæ¯ï¼Œè€Œæ˜¯ç®€å•åœ°éµå¾ª Chakra å›¾ä¸­å·²ç»è¡¨ç¤ºçš„åˆ†è§£ã€‚ç”±äºå·²ç»ä½¿ç”¨ Chakra ET æ¥è¡¨ç¤º workloadï¼Œä½¿ç”¨ Chakra ET æ¥é¢å¤–å®šä¹‰é›†åˆé€šä¿¡ç®—æ³•æä¾›äº†ä¸€ç§è½»æ¾ç®€å•çš„æ–¹å¼æ¥éå†æ•´ä¸ªå›¾ã€‚\nå¦‚ä¸Šå›¾æ‰€ç¤ºå½“ workload å±‚å‘å‡º AllReduce é›†ä½“æ“ä½œæ—¶ï¼ŒSystem å±‚ä¸ä¼šè¿è¡Œæ¨¡æ‹Ÿå™¨ä»£ç åº“ä¸­å·²æœ‰çš„åŸç”Ÿå®ç°é€»è¾‘ï¼Œè€Œæ˜¯ä¼šéå†é€šè¿‡ API æä¾›çš„ Chakra ETï¼Œè¯¥ ET è¡¨ç¤ºé›†åˆé€šä¿¡ç®—æ³•ã€‚éœ€è¦æ³¨æ„ workload Chakra å›¾å’Œé›†åˆé€šä¿¡ç®—æ³•çš„ Chakra å›¾æ˜¯è§£è€¦çš„ï¼Œå¹¶é€šè¿‡ä¸åŒçš„è¾“å…¥ç‚¹æä¾›ã€‚æœ€ç»ˆï¼Œasytra-sim æ¨¡æ‹Ÿå™¨ä¼šå°†é€šä¿¡èŠ‚ç‚¹æ›¿æ¢ä¸ºé›†ä½“å®ç°ã€‚\nInput Files for Collective API ASTRA-sim Native // ... \u0026#34;active-chunks-per-dimension\u0026#34;: 1, \u0026#34;all-reduce-implementation\u0026#34;: [\u0026#34;ring\u0026#34;], \u0026#34;all-gather-implementation\u0026#34;: [\u0026#34;ring\u0026#34;, \u0026#34;doubleBinaryTree\u0026#34;], \u0026#34;all-to-all-implementation\u0026#34;: [\u0026#34;ring\u0026#34;, \u0026#34;doubleBinaryTree\u0026#34;, \u0026#34;halvingDoubling\u0026#34;], // ... all-*-implementation æŒ‡å®šäº†æ¨¡æ‹Ÿå™¨å°†å¦‚ä½•å°†ç»™å®šçš„é›†åˆé€šä¿¡åˆ†è§£ä¸ºå‘é€å’Œæ¥æ”¶æ¶ˆæ¯ã€‚All-Gather æ“ä½œåˆ—è¡¨ä¸­çš„ä¸¤ä¸ªæ¡ç›®è¡¨ç¤ºæ¨¡æ‹Ÿå™¨å°†æŒ‰ä¸¤ä¸ªç»´åº¦åˆ†è§£ â€”â€”ç¬¬ä¸€ä¸ªç»´åº¦ä½¿ç”¨ Ring ç®—æ³•ï¼Œç¬¬äºŒä¸ªç»´åº¦ä½¿ç”¨ doubleBinaryTree ç®—æ³•ã€‚\nNative Implementation Requires That the Dimensions for Collective Algorithms Are Same Across All Collectives.\nWarning\nNative å®ç°è¦æ±‚æ‰€æœ‰é›†ä½“æ“ä½œçš„ç»´åº¦å¿…é¡»ç›¸åŒã€‚æ¢å¥è¯è¯´ï¼Œå¦‚æœä¸€ä¸ªé›†åˆé€šä¿¡ç®—æ³•è¢«å®šä¹‰ä¸ºäºŒç»´çš„ï¼Œé‚£ä¹ˆå…¶ä»–é›†åˆé€šä¿¡ç®—æ³•ä¹Ÿå¿…é¡»æ˜¯äºŒç»´æ“ä½œã€‚ä¸Šè¿°åªæ˜¯ä¸€ä¸ªä¾‹å­ã€‚\nCollective API // ... \u0026#34;active-chunks-per-dimension\u0026#34;: 1, \u0026#34;all-reduce-implementation-chakra\u0026#34;: [\u0026#34;/app/hoti2024/demo5/inputs/custom_ring\u0026#34;], // ... éœ€è¦æ³¨æ„è¿™é‡Œè¦ä½¿ç”¨ all-*-implementation-chakraï¼Œè€Œä¸æ˜¯ all-*-implementation. å¦å¤– Chakra ET æ–‡ä»¶ä¸ä¼ é€’ç»™ workload å±‚çš„æ–‡ä»¶æ˜¯ä¸åŒçš„ï¼Œæ¯ä¸€é¡¹çš„å€¼æ˜¯ Chakra ET æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œä¸åŒ…æ‹¬æœ€åçš„ {rank}.et å­—ç¬¦ä¸² (ç±»ä¼¼äº Workload å±‚è¾“å…¥)ã€‚æ­¤å¤–ï¼Œå³ä½¿æœ‰è®¸å¤šç»´åº¦ï¼Œåˆ—è¡¨ä¹Ÿåªæ¥å—ä¸€ä¸ªå€¼ã€‚è¿™æ˜¯å› ä¸ºè·¨ç»´åº¦é€šä¿¡çš„æ¦‚å¿µå·²ç»åŒ…å«åœ¨ ET ä¸­ã€‚\nCollective API\rå‚è€ƒè¯¥ä»“åº“å®ç°\rNetwork Backend Analytical Network Backend Analytical Network æ¨¡æ‹Ÿå™¨é€šè¿‡æ•°å­¦æ–¹ç¨‹æ¨¡æ‹Ÿæ‰€æœ‰ç½‘ç»œè¡Œä¸ºã€‚å› æ­¤ï¼Œè¯¥åç«¯æœ€é€‚åˆäºå¤§è§„æ¨¡åˆ†å¸ƒå¼å¹³å°çš„å»ºæ¨¡å’Œä»¿çœŸã€‚ç›®å‰æ”¯æŒä¸¤ç§åˆ†ææ¨¡å¼\ncongestion_unaware analytical network simulator congestion_aware analytical network simulator TTopology Analytical Network æ”¯æŒä¸‰ç§æ‹“æ‰‘ç»“æ„: Ring, FullConnected, Switch. å¹¶ä¸”å¯ä»¥å †å æ¥è¡¨ç¤ºå¤šç»´ç½‘ç»œã€‚\nBasic Network Building Block\ntopology: [ Ring, Switch ] # 2D topology topology: [ Ring, Ring, Ring ] # 3D topology Example of 2D \u0026amp; 3D Topologies\nNPUs Count æŒ‡å®šäº†æ¯ä¸ªç»´åº¦ä¸Šçš„è®¾å¤‡æ•°ç›®\nnpus_count: [ 5 ] # 5 NPUs npus_count: [ 4, 2 ] # 4 Ã— 2 = 8 NPUs npus_count: [ 4, 2, 2 ] # 4 Ã— 2 Ã— 2 = 16 NPUs NPUs Count Example\nBandwidth \u0026amp; Latency latency å®šä¹‰äº†æ¯æ¡å•å‘é“¾è·¯çš„å»¶è¿Ÿ (ns). bandwidth å®šä¹‰äº†æ¯æ¡å•å‘é“¾è·¯çš„å¸¦å®½ (GB/s).\nNote\n$1 GB = 2^{30} B$ and $1 s = 10^9 ns$\nns3 backend ä¸‹é¢æ˜¯ç”¨ ns3 åç«¯è¿›è¡Œæ–¹é’ˆçš„ä¸€ä¸ªæ‰§è¡Œå‘½ä»¤ã€‚è¿™é‡Œä½¿ç”¨äº† --network-backend å’Œ --logical-topology è¿™ä¸¤ä¸ªå‚æ•°ã€‚éœ€è¦è¯´æ˜çš„æ˜¯ï¼ŒAnalytical Backend ä¸­ä»…ä½¿ç”¨äº†--network-backend å‚æ•°ï¼Œè¿™æ˜¯å› ä¸ºåˆ†æå‹åç«¯çš„é€»è¾‘æ‹“æ‰‘ä¸ç‰©ç†æ‹“æ‰‘æ˜¯ç›¸åŒçš„ï¼Œè€Œ ns3 åˆ™å…è®¸æˆ‘ä»¬å°†é€»è¾‘æ‹“æ‰‘ä¸ç‰©ç†æ‹“æ‰‘åˆ†ç¦»ã€‚\n# {NS3_DIR} is the directory of the ns-3 backend. That is, \u0026#39;{ASTRA_SIM_ROOT_DIRECTORY}/extern/network_backend/ns-3\u0026#39; cd \u0026#34;${NS3_DIR}/build/scratch\u0026#34; ./ns3.42-AstraSimNetwork-default \\ --workload-configuration=\u0026#34;${SCRIPT_DIR:?}\u0026#34;/../../extern/graph_frontend/chakra/one_comm_coll_node_allgather \\ --system-configuration=\u0026#34;${SCRIPT_DIR:?}\u0026#34;/../../inputs/system/Switch.json \\ --network-configuration=\u0026#34;../../../ns-3/scratch/config/config.txt\u0026#34; \\ --remote-memory-configuration=\u0026#34;${SCRIPT_DIR:?}\u0026#34;/../../inputs/remote_memory/analytical/no_memory_expansion.json \\ --logical-topology-configuration=\u0026#34;${SCRIPT_DIR:?}\u0026#34;/../../inputs/network/ns3/sample_8nodes_1D.json \\ --comm-group-configuration=\\\u0026#34;empty\\\u0026#34; Overview of Trace Collection\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blogs/astra-sim/","summary":"source code reading of astra-sim","title":"astra-Sim"},{"content":"Origin of Transformer Transformer ç”±è°·æ­Œç ”äº 2017 å¹´åœ¨ä¸€ç¯‡åä¸º Attention is All You Need çš„è®ºæ–‡ä¸­æå‡ºã€‚ä¸ RNN çš„è¾“å…¥ä»…ä¸ºä¸€ä¸ª token ä¸åŒï¼ŒTransformer ä¸€æ¬¡æ€§å¯ä»¥è¾“å…¥ä¸€æ•´ä¸ªå®Œæ•´çš„åºåˆ—ã€‚æ€»ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒåŒ…å«ä¸€ä¸ª Encoder å’Œä¸€ä¸ª Decoder.\nTransformers Architecture\nEmbedding Embedding æ˜¯ä¸€ç§å°†ç¦»æ•£çš„ã€ç¨€ç–çš„è¾“å…¥ (å¦‚è¯è¯­ã€å­—ç¬¦ã€ç±»åˆ«æ ‡ç­¾\u0026hellip;) è½¬æ¢ä¸ºè¿ç»­çš„ã€å¯†é›†çš„å‘é‡è¡¨ç¤ºçš„æŠ€æœ¯ï¼Œæ ¸å¿ƒæ˜¯é€šè¿‡ä¸€ä¸ªæ˜ å°„å‡½æ•°å°†ç¦»æ•£çš„è¾“å…¥ç¬¦å· (å¦‚å•è¯) æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´å‘é‡ç©ºé—´ä¸­ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å« V ä¸ªå•è¯çš„ Vocabularyï¼Œç»´åº¦ä¸º dï¼Œé‚£ä¹ˆ Embedding Matrix å°†æ˜¯ä¸€ä¸ªå¤§å°ä¸º VÃ—d çš„çŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªå•è¯çš„å‘é‡è¡¨ç¤ºã€‚é€šè¿‡åµŒå…¥å±‚ï¼Œè¾“å…¥çš„è¯ç´¢å¼• (é€šå¸¸æ˜¯æ•´æ•°) å°±ä¼šè¢«æ˜ å°„åˆ°è¯¥çŸ©é˜µçš„å¯¹åº”è¡Œï¼Œä»è€Œå¾—åˆ°è¯çš„å‘é‡è¡¨ç¤ºã€‚å¸¸è§çš„é¢„è®­ç»ƒè¯åµŒå…¥æ–¹æ³•åŒ…æ‹¬ï¼š\nWord2Vecï¼šé€šè¿‡ä¸Šä¸‹æ–‡é¢„æµ‹è¯è¯­çš„æ–¹å¼å­¦ä¹ è¯å‘é‡ã€‚ GloVeï¼šé€šè¿‡ç»Ÿè®¡è¯å…±ç°ä¿¡æ¯æ¥å­¦ä¹ è¯å‘é‡ã€‚ FastTextï¼šè€ƒè™‘äº†å­è¯ä¿¡æ¯çš„è¯åµŒå…¥æ–¹æ³•ï¼Œèƒ½æ›´å¥½åœ°å¤„ç†è¯å½¢å˜åŒ–ã€‚ åœ¨ PyTorch å’Œ TensorFlow ç­‰æ¡†æ¶ä¸­ï¼Œé€šå¸¸æœ‰ä¸“é—¨çš„ Embedding å±‚ï¼ŒHugging Face ä¹Ÿæœ‰ tokenizer å°†å¥å­åˆ’åˆ†æˆå•è¯å¹¶è½¬æ¢æˆå¯¹åº”çš„ç´¢å¼•ï¼š\nPositional Encoding Positional Encoding ä½œç”¨æ˜¯ä¸ºè¾“å…¥çš„åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ æä¾›ä½ç½®ä¿¡æ¯ã€‚ç”±äº Transformer æ¶æ„å¹¶æ²¡æœ‰ä½¿ç”¨é€’å½’æˆ–å·ç§¯ç»“æ„ï¼Œæœ¬èº«æ— æ³•æ•æ‰è¾“å…¥åºåˆ—ä¸­å…ƒç´ çš„ç›¸å¯¹ä½ç½®å…³ç³»ï¼Œå› æ­¤éœ€è¦é€šè¿‡ä½ç½®ç¼–ç æ¥æ˜¾å¼åœ°å¼•å…¥è¿™äº›ä½ç½®ä¿¡æ¯ã€‚\nNote\nTransformer çš„ä¸»è¦ä¼˜åŠ¿æ˜¯é€šè¿‡ Self-Attention å¹¶è¡Œå¤„ç†åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œä½†æ˜¯è¿™ä¹Ÿæ„å‘³ç€å®ƒæ²¡æœ‰è‡ªå¸¦é¡ºåºæ„ŸçŸ¥èƒ½åŠ›ï¼Œå®ƒå¹¶ä¸ä¼šè‡ªåŠ¨çŸ¥é“ä¸€ä¸ªå•è¯æ˜¯åœ¨å¥å­çš„å¼€å¤´è¿˜æ˜¯ç»“å°¾ï¼Œå› æ­¤éœ€è¦é¢å¤–çš„æœºåˆ¶æ¥ç¼–ç æ¯ä¸ªå…ƒç´ åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚\nä½ç½®ç¼–ç  é€šè¿‡å°†æ¯ä¸ªå•è¯çš„ä½ç½®ä¿¡æ¯ (å³å®ƒåœ¨åºåˆ—ä¸­çš„ä½ç½®) ç¼–ç ä¸ºä¸€ä¸ªå‘é‡ï¼Œå¹¶å°†è¯¥å‘é‡æ·»åŠ åˆ°å•è¯çš„åµŒå…¥è¡¨ç¤ºä¸­ï¼Œä»è€Œè®©æ¨¡å‹èƒ½å¤Ÿæ„ŸçŸ¥æ¯ä¸ªå…ƒç´ çš„ç›¸å¯¹æˆ–ç»å¯¹ä½ç½®ã€‚\nç»å…¸çš„ Transformer ä½ç½®ç¼–ç ä½¿ç”¨ æ­£å¼¦å’Œä½™å¼¦å‡½æ•°çš„ç»„åˆï¼Œä¸ºæ¯ä¸ªä½ç½®ç”Ÿæˆçš„å‘é‡åœ¨ä¸åŒç»´åº¦ä¸Šå…·æœ‰ä¸åŒçš„å‘¨æœŸæ€§ï¼Œè¿™èƒ½å¤Ÿæ•æ‰åˆ°ä¸åŒçº§åˆ«çš„ç›¸å¯¹ä½ç½®å…³ç³»ã€‚å‡è®¾è¾“å…¥çš„åºåˆ—ä¸­æœ‰ N ä¸ªå•è¯ï¼Œæ¯ä¸ªå•è¯çš„åµŒå…¥ç»´åº¦ä¸º dï¼Œé‚£ä¹ˆ Positional Encodin(PE) çš„è®¡ç®—å…¬å¼å¦‚ä¸‹:\n$$\r\\begin{aligned}\r\u0026PE_{(pos,2i)}=\\sin\\left(\\frac{pos}{10000^{\\frac{2i}d}}\\right)\\\\\r\u0026PE_{(pos,2i+1)}=\\cos\\left(\\frac{pos}{10000^{\\frac{2i}d}}\\right)\r\\end{aligned}\r$$å…¶ä¸­ï¼š\npos æ˜¯å•è¯åœ¨åºåˆ—ä¸­çš„ä½ç½®ç´¢å¼• (ä½ç½®ä» 0 å¼€å§‹). i æ˜¯ä½ç½®ç¼–ç çš„ç»´åº¦ç´¢å¼•ï¼Œè¡¨ç¤ºè¯¥ä½ç½®ç¼–ç å‘é‡ä¸­çš„ç¬¬ i ä¸ªå…ƒç´ ã€‚ d æ˜¯ Embedding çš„ç»´åº¦ è¿™äº›ä½ç½®ç¼–ç ä¸å•è¯çš„è¯åµŒå…¥ (Word Embedding) ç›¸åŠ ï¼Œæœ€ç»ˆå½¢æˆè¾“å…¥æ¨¡å‹çš„å‘é‡è¡¨ç¤ºã€‚\n(Masked) Multi-Head Attention Multi-Head Attention (MHA) çš„ç›®çš„æ˜¯é€šè¿‡å¹¶è¡Œåœ°è®¡ç®—å¤šä¸ªæ³¨æ„åŠ›å¤´ (Attention Head)ï¼Œä»å¤šä¸ªå­ç©ºé—´ä¸­å­¦ä¹ è¾“å…¥åºåˆ—çš„ä¸åŒè¡¨ç¤ºã€‚ç»è¿‡ Word Embedding åçš„è¾“å…¥ X å½¢çŠ¶ä¸º Nxd. è®¡ç®—æ­¥éª¤å¦‚ä¸‹\né€šè¿‡å­¦ä¹ çš„å˜æ¢çŸ©é˜µå°† X æ˜ å°„åˆ°æŸ¥è¯¢ (Q)ã€é”® (K) å’Œå€¼ (V) ç©ºé—´ã€‚ $$\r\\begin{aligned}\u0026Q=XW^{Q}\\\\\u0026K=XW^{K}\\\\\u0026V=XW^{V}\\end{aligned}\r$$ å…¶ä¸­ $W^{Q},W^{K}\\in\\mathbb{R}d_{model}\\times d_{k},W^{Q},W^{V}\\in\\mathbb{R}d_{model}\\times d_{v}$\næ ¹æ® QKV è®¡ç®— Attention æ¯ä¸ªæŸ¥è¯¢å‘é‡ä¼šä¸æ‰€æœ‰é”®å‘é‡è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®— (ä¸€èˆ¬é‡‡ç”¨ scaled inner product)ï¼Œä»è€Œè·å¾—æƒé‡ï¼Œç„¶ååˆ©ç”¨è¿™äº›æƒé‡å¯¹æ‰€æœ‰å€¼å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œã€‚\n$$\r\\mathrm{Attention}(Q,K,V)=\\mathrm{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\r$$\nåœ¨å¤šå¤´æ³¨æ„åŠ›ä¸­ï¼Œä¸ºäº†å¢åŠ æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œé€šå¸¸å°† Qã€K å’Œ V é€šè¿‡å¤šä¸ªä¸åŒçš„çº¿æ€§å˜æ¢çŸ©é˜µè¿›è¡Œå¤šæ¬¡è®¡ç®—ï¼Œå¾—åˆ°å¤šä¸ªæ³¨æ„åŠ›å¤´ (Attention Heads). æ¯ä¸ªå¤´çš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ï¼Œä½†å®ƒä»¬çš„ç»“æœä¼šåœ¨æœ€åè¿›è¡Œæ‹¼æ¥å¹¶ç»è¿‡çº¿æ€§å˜æ¢ã€‚æœ€ç»ˆçš„ Multi-Head Attention å…¬å¼ä¸ºï¼š\n$$\r\\text{MultiHead}(Q,K,V)=\\text{Concat}(head_1,head_2,\\ldots,head_h)W^O\r$$\næ¯ä¸ªå¤´ $head_i$ è®¡ç®—å…¬å¼ä¸º\n$$\r\\text{MultiHead}(Q,K,V)=\\text{Concat}(head_1,head_2,\\ldots,head_h)W^O\r$$\nè¿™é‡Œçš„ $W^{Q}_{i},W^{K}_{i},W^{V}_{i}$ æ˜¯ä¸ºæ¯ä¸ªå¤´å­¦ä¹ åˆ°çš„ä¸åŒæƒé‡çŸ©é˜µï¼Œ$W^O$ æ˜¯è¾“å‡ºçš„çº¿æ€§å˜æ¢çŸ©é˜µã€‚\nMulti-Head Attention\nDecoder ä¸­çš„ Masked MHA ç¡®ä¿æ¨¡å‹åªèƒ½åœ¨è§£ç åºåˆ—çš„å½“å‰ä½ç½®åŠå…¶ä¹‹å‰çš„ä½ç½®ä¸Šæ“ä½œï¼Œè€Œä¸èƒ½ â€œçœ‹åˆ°â€ å°†è¦ç”Ÿæˆçš„æœªæ¥ä¿¡æ¯ã€‚ä¸æ ‡å‡†çš„ MHA ç›¸åŒï¼Œæ³¨æ„åŠ›åˆ†æ•° $\\mathrm{Attention Scores}=\\frac{QK^T}{\\sqrt{d_k}}$ æ˜¯é€šè¿‡ Q å’Œ K çš„ç‚¹ç§¯è®¡ç®—å¾—åˆ°çš„ã€‚è®¡ç®—å®Œæˆåæˆ‘ä»¬ç»™å…¶åŠ ä¸Šä¸€ä¸ªä¸‹ä¸‰è§’å…ƒç´  (åŒ…å«ä¸»å¯¹è§’çº¿) ä¸º 0ï¼Œä¸Šä¸‰è§’å…ƒç´ ä¸º â€”âˆ çš„ maskï¼Œè¿™æ ·æœªæ¥çš„ä¿¡æ¯ç»è¿‡ Softmax åçš„æƒé‡ä¸º 0ï¼Œè¢«å®Œå…¨å±è”½ã€‚\nGrouped Query Attentionï¼ˆGQAï¼‰\u0026amp; Multi-query Attention (MQA) GQA å°†å¤šä¸ª Q åˆ†æˆè‹¥å¹²ç»„ï¼Œæ¯ä¸€ç»„å…±äº«ç›¸åŒçš„æƒé‡çŸ©é˜µã€‚è¿™ä½¿å¾—æ¯ç»„æŸ¥è¯¢å¯ä»¥å…±åŒå¤„ç†åŒä¸€ä¸ª K å’Œ Vï¼Œé™ä½äº†è®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚ã€‚åœ¨ MHA ä¸­ï¼Œæ‰€æœ‰çš„å¤´å…±äº«ç›¸åŒçš„è¾“å…¥ Xï¼Œä½†ä½¿ç”¨ä¸åŒçš„æŠ•å½±çŸ©é˜µæ¥ç”Ÿæˆ K å’Œ V. GQA ä¸­ K å’Œ V é€šå¸¸æ˜¯å¯¹è¾“å…¥ X è¿›è¡Œä¸€æ¬¡æ€§çº¿æ€§å˜æ¢ï¼Œå¹¶åœ¨æ‰€æœ‰åŒä¸€åˆ†ç»„ä¸­çš„ Q å…±äº«ã€‚MQA æ›´ä¸ºæç«¯ï¼Œæ‰€æœ‰çš„ Q å…±äº«ä¸€ä¸ª K å’Œ V.\nOverview of MHA, GQA \u0026amp; MQA\nMulti-Head Cross Attention Multi-Head Cross Attention æ˜¯ Transformer Decoder ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒç»„ä»¶ã€‚ä¸ Self-Attention ä¸åŒï¼ŒCross Attention è´Ÿè´£å°†è§£ç å™¨çš„éšè—çŠ¶æ€ä¸ç¼–ç å™¨çš„è¾“å‡ºä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œäº¤äº’ï¼Œå…è®¸è§£ç å™¨çš„æ¯ä¸€ä¸ªè§£ç æ—¶é—´æ­¥çš„çŠ¶æ€ æŸ¥çœ‹æ•´ä¸ªç¼–ç å™¨çš„è¾“å‡ºã€‚æ¯ä¸ªè§£ç çš„æ—¶é—´æ­¥ tï¼ŒDecoder çš„éšè—çŠ¶æ€ä½œä¸º Qï¼ŒEncoder çš„è¾“å‡ºä½œä¸º K å’Œ Vï¼Œè®¡ç®—è¿‡ç¨‹ä¸ æ ‡å‡†çš„ Self-Attention ç›¸åŒã€‚\nEvolution Tree of Transformer åç»­çš„ç ”ç©¶é€æ¸æŠŠ Encoder å’Œ Decoder åˆ†ç¦»å¼€æ¥ï¼Œå½¢æˆ Encoder-Only å’Œ Decoder-Only çš„æ¨¡å‹ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º\nTransformer Evolution Tree\nFeed Forward Network FFN æ˜¯ä¸€ä¸ªä¸¤å±‚çš„å‰é¦ˆå…¨è¿æ¥ç½‘ç»œï¼Œä¸­é—´æœ‰ä¸€ä¸ªéçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚ç¬¬ä¸€å±‚å…¨è¿æ¥å°† $d_model$ æ˜ å°„åˆ° $4d_model$ ï¼Œç»è¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°åï¼Œç¬¬äºŒå±‚å…¨è¿æ¥å†é‡æ–°æ˜ å°„å› $d_model$.\nDecoder-Only Transformer Decoder-Only åˆ é™¤äº†åŸå…ˆ Transformer Encoder çš„éƒ¨åˆ†ä»¥åŠ Encoder å’Œ Decoder è¿›è¡Œ Cross Attention çš„éƒ¨åˆ†ã€‚å®ƒå…·æœ‰ä¸‰ä¸ªå¿…è¦çš„ç‰¹å¾:\nåœ¨ç»™å®šç¼–ç å™¨è¾“å…¥ä½œä¸ºä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹åŸºäºè¿„ä»Šä¸ºæ­¢ç”Ÿæˆçš„ token è‡ªåŠ¨å›å½’é¢„æµ‹ä¸‹ä¸€ä¸ªã€‚ åœ¨è¯„ä¼°å¯¹è¾“å…¥åºåˆ—çš„ Q æ—¶çœ‹ä¸åˆ°æœªæ¥å€¼ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»…è§£ç å™¨çš„æ¨¡å‹é€šå¸¸è¢«ç§°ä¸º Casual Language Model (CLM). è®­ç»ƒæ¨¡å‹ä»¥åœ¨ç»™å®šå½“å‰è¾“å…¥åºåˆ—çš„æƒ…å†µä¸‹é¢„æµ‹ä¸‹ä¸€ä¸ª token. è¿™ç§è®­ç»ƒæ–¹æ³•ä¸å›å½’ç›¸ç»“åˆï¼Œå…è®¸æ¨¡å‹è‡ªå›å½’ç”Ÿæˆä»»æ„é•¿ (æœ€é«˜è¾¾è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦) çš„åºåˆ—ã€‚ Decoder-only (left) and Encoder-only (right) Transformer Architectures\nLLaMA Transformer Architecture LLaMA Transformer ç»“æ„å¦‚ä¸‹ï¼Œä¸»è¦æœ‰ä»¥ä¸‹å˜åŒ–\nä½¿ç”¨ RoPE (Rotary Position Embedding) æ›¿ä»£ä¼ ç»Ÿçš„ä½ç½®ç¼–ç ã€‚ RMSNorm æ›¿ä»£ LayerNorm å¼•å…¥ Gated Linear Unit (GLU) Rotary Position Embedding ä¼ ç»Ÿçš„ Transformer æ¨¡å‹ä½¿ç”¨å¯å­¦ä¹ çš„ç»å¯¹ä½ç½®ç¼–ç  (å¦‚ sinusoidal position embedding)ï¼Œä½† RoPE é‡‡ç”¨äº†æ—‹è½¬çŸ©é˜µçš„æ€æƒ³ï¼Œå°†ä½ç½®ç¼–ç ä¸è¾“å…¥çš„ token è¡¨ç¤ºç›´æ¥ç»“åˆï¼Œè€Œä¸ä¾èµ–äºé¢å¤–çš„å¯å­¦ä¹ å‚æ•°ã€‚\nè¾“å…¥å‘é‡çš„æ—‹è½¬è§’åº¦ä¸º $\\theta(p,i)=p\\cdot10000^{-2i/d}$. p è¡¨ç¤ºä½ç½®ç´¢å¼•ï¼Œi è¡¨ç¤ºç»´åº¦ç´¢å¼•ï¼Œd ä¸ºå‘é‡çš„æ€»ç»´åº¦ã€‚å¯¹äºè¾“å…¥çš„ token å‘é‡ x ä¸­çš„æ¯ä¸€å¯¹å¶æ•°å’Œå¥‡æ•°ç»´åº¦ $(x_{2i},x_{2i+1})$ï¼Œæ—‹è½¬æ“ä½œå¯ä»¥ç”¨ 2D æ—‹è½¬çŸ©é˜µè¡¨ç¤ºä¸º\n$$\\begin{bmatrix}x_{2i}^{\\prime}\\\\x_{2i+1}^{\\prime}\\end{bmatrix}=\\begin{bmatrix}\\cos(\\theta)\u0026-\\sin(\\theta)\\\\\\sin(\\theta)\u0026\\cos(\\theta)\\end{bmatrix}\\cdot\\begin{bmatrix}x_{2i}\\\\x_{2i+1}\\end{bmatrix}$$\nå¯¹äºè¾“å…¥çš„ token å‘é‡ $\\mathbf{x}\\left[x_{0},x_{1},x_{2},x_{3},\\cdots,x_{d-1}\\right]$, RoPE å°†å…¶ä¸¤ä¸¤ä¸€ç»„é…å¯¹ï¼Œæ¯ä¸€ç»„éƒ½ä¼šä¸ä½ç½®ç›¸å…³çš„æ—‹è½¬è§’åº¦ Î¸ å¯¹åº”åœ°åº”ç”¨æ—‹è½¬æ“ä½œã€‚è¿™ä¸ªè¿‡ç¨‹çš„æœ¬è´¨æ˜¯å¯¹è¾“å…¥ token çš„è¡¨ç¤ºåšäº†æ—‹è½¬å˜æ¢ï¼Œä½¿å¾—è¿™äº›ç‰¹å¾ä¸ä»…ä¾èµ–äºè¾“å…¥çš„ç‰¹å¾ï¼Œè¿˜éšå«äº†è¯¥ token åœ¨åºåˆ—ä¸­çš„ä½ç½®ã€‚\nRoPE\nRMSNorm RMSNorm ç›¸å¯¹äº LayerNorm å»æ‰äº†å‡å€¼è®¡ç®—ï¼Œä»…åŸºäºè¾“å…¥çš„å‡æ–¹æ ¹è¿›è¡Œå½’ä¸€åŒ– $\\mathrm{RMSNorm}(\\mathbf{x})=\\frac{\\mathbf{x}}{\\mathrm{RMS}(\\mathbf{x})+\\epsilon}\\cdot\\gamma$\nå…¶ä¸­\n$\\mathrm{RMS}(\\mathbf{x})=\\sqrt{\\frac1d\\sum_{i=1}^dx_i^2}$ ä¸ºè¾“å…¥çš„å‡æ–¹æ ¹ã€‚ $\\gamma{:}$ ä¸ºå¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•°ã€‚ $\\epsilon{:}$ ä¸ºé˜²æ­¢é™¤ä»¥ 0 çš„å°æ•°ã€‚ SiLU SiLU (Sigmoid Linear Unit) æ˜¯ä¸€ç§æ¿€æ´»å‡½æ•°ï¼Œä¹Ÿç§°ä¸º Swishï¼Œå…¶å®šä¹‰ä¸ºè¾“å…¥ x å’Œ Sigmoid å‡½æ•°è¾“å‡ºçš„ä¹˜ç§¯ã€‚å…¶å®šä¹‰ä¸º $$\\mathrm{SiLU}(x)=x\\cdot\\sigma(x)$$ å…¶ä¸­ $\\sigma(x)=\\frac1{1+e^{-x}}$\nSiLU\n","permalink":"http://localhost:1313/blogs/transformerfamily/","summary":"Introduction of Transformer Family","title":"Transformer Family"},{"content":"ZeRO Zero ç”¨äºä¼˜åŒ–å†…å­˜ï¼Œæå¤§åœ°æé«˜äº†è®­ç»ƒé€Ÿåº¦ï¼ŒåŒæ—¶å¢åŠ äº†å¯ä»¥è®­ç»ƒçš„æ¨¡å‹å¤§å°ã€‚ZeRO æ¶ˆé™¤äº†æ•°æ®å’Œæ¨¡å‹å¹¶è¡Œè®­ç»ƒä¸­çš„å†…å­˜å†—ä½™ï¼ŒåŒæ—¶ä¿æŒäº†ä½é€šä¿¡é‡å’Œé«˜è®¡ç®—ç²’åº¦ï¼Œèƒ½å¤Ÿä»¥æŒç»­çš„é«˜æ•ˆç‡æŒ‰è®¾å¤‡æ•°é‡ç­‰æ¯”ä¾‹æ‰©å±•å¯è®­ç»ƒæ¨¡å‹çš„å¤§å°ã€‚\nIntroduction ZeRO é¦–å…ˆæ€»ç»“äº†ä¸‹å½“å‰å¹¶è¡Œæ–¹æ³•å­˜åœ¨çš„é—®é¢˜\nBasic DP: æ²¡æœ‰å‡å°‘æ¯ä¸ªè®¾å¤‡çš„å†…å­˜ï¼Œåœ¨ 32GB å†…å­˜çš„ GPU ä¸Šè®­ç»ƒè¶…è¿‡ 1.4B å‚æ•°çš„æ¨¡å‹ä¾¿ä¼š OOM. Model Parallelsim (MP): åˆ‡åˆ†äº†æ¯ä¸€å±‚çš„è®¡ç®—å’Œæ¿€æ´»åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œä½†å¼•å…¥äº†å¤§é‡çš„é€šä¿¡ (å‰å‘å’Œåå‘éƒ½éœ€è¦ 2xAll-Reduce)ï¼Œå› æ­¤æ‰©å±•æ€§å·®ï¼Œé€šå¸¸åªåœ¨ä¸€ä¸ªèŠ‚ç‚¹å†…çš„é«˜å¸¦å®½è¿æ¥çš„ GPU ä¸­è¿›è¡Œã€‚åœ¨ DGX-2 èŠ‚ç‚¹è®­ç»ƒ 40B å‚æ•°çš„æ¨¡å‹æ¯ä¸ª V100 GPU ä»…èƒ½è¾¾åˆ°ç¡¬ä»¶å³°å€¼çš„ 5% ç®—åŠ› (5T flops). æ¨¡å‹çŠ¶æ€é€šå¸¸å æ®äº†è®­ç»ƒæ—¶çš„å¤§éƒ¨åˆ†å†…å­˜ï¼Œä½† DP åœ¨æ‰€æœ‰æ•°æ®å¹¶è¡Œè¿›ç¨‹ä¸­ä¿å­˜ä¸€ä»½æ¨¡å‹çŠ¶æ€ï¼Œå¯¼è‡´å†—ä½™å†…å­˜æ¶ˆè€—ï¼›è€Œ MP å¯¹è¿™äº›çŠ¶æ€è¿›è¡Œåˆ‡åˆ†ä»¥è·å¾—é«˜å†…å­˜æ•ˆç‡ï¼Œä½†é€šå¸¸ä¼šå¯¼è‡´è¿‡äºç»†ç²’åº¦çš„è®¡ç®—å’Œæ˜‚è´µçš„é€šä¿¡ï¼Œæ‰©å±•æ•ˆç‡è¾ƒä½ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•éƒ½é™æ€åœ°ç»´æŠ¤æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹æ‰€éœ€çš„æ•´ä¸ªæ¨¡å‹çŠ¶æ€ã€‚\nZeRO-DP é€šè¿‡åœ¨æ•°æ®å¹¶è¡Œè¿‡ç¨‹ä¸­åˆ’åˆ†æ¨¡å‹çŠ¶æ€ (å‚æ•°ã€æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€) æ¶ˆé™¤äº†æ•°æ®å¹¶è¡Œè¿‡ç¨‹ä¸­çš„å†…å­˜å†—ä½™ã€‚\nç»“è®ºï¼šå¦‚ä¸‹å›¾æ‰€ç¤º ZeRO-DP æœ‰ä¸‰ä¸ªä¸»è¦çš„ä¼˜åŒ–é˜¶æ®µï¼Œå®ƒä»¬å¯¹åº”äºä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œå‚æ•°çš„åˆ’åˆ†ã€‚ å¯¹äºä½¿ç”¨ FP16 çš„æ¨¡å‹ï¼Œå†…å­˜å ç”¨åŒ…æ‹¬å‚æ•° (FP16)ã€æ¢¯åº¦ (FP16)ã€Adam ä¼˜åŒ–å™¨çŠ¶æ€ (åŠ¨é‡ (FP32)ï¼Œæ–¹å·® (FP32) ä»¥åŠæ›´æ–°åçš„å‚æ•° (FP32), å› æ­¤ K=12).\nä¼˜åŒ–å™¨çŠ¶æ€åˆ’åˆ† (Pos) â€”â€” å†…å­˜å‡å°‘ 4 å€ï¼Œéœ€è¦å¯¹æ¢¯åº¦è¿›è¡Œ reduce-scatterï¼Œç”¨å„è‡ªçš„ä¼˜åŒ–å™¨çŠ¶æ€æ›´æ–°æ¢¯åº¦åè¿›è¡Œ All-gather ä½¿æ‰€æœ‰è®¾å¤‡éƒ½æœ‰æœ€æ–°çš„æ¢¯åº¦ï¼Œé€šä¿¡é‡ä¸æ•°æ®å¹¶è¡Œæ€§ç›¸åŒ (å¯¹ Loss è¿›è¡Œä¸€æ¬¡ All-reduce). æ·»åŠ æ¢¯åº¦åˆ’åˆ† (Pos+g) \u0026ndash; å†…å­˜å‡å°‘ 8 å€ï¼Œæ¯ä¸ªè®¾å¤‡éœ€è¦å°†è‡ªå·±çš„æ¢¯åº¦ scatter åˆ°è´Ÿè´£æ›´æ–°é‚£éƒ¨åˆ†å‚æ•°çš„è®¾å¤‡ä¸Šï¼Œç„¶åä½¿ç”¨ Gather å°†å…¶ä»–è®¾å¤‡æ›´æ–°åçš„æ¨¡å‹å‚æ•°åŒæ­¥åˆ°è‡ªå·±ä¸Šé¢ï¼Œé€šä¿¡é‡ä¸æ•°æ®å¹¶è¡Œæ€§ç›¸åŒã€‚ æ·»åŠ å‚æ•°åˆ’åˆ† (Pos+g+p) \u0026ndash; å†…å­˜å‡å°‘ä¸æ•°æ®å¹¶è¡Œåº¦ Nd å‘ˆçº¿æ€§å…³ç³»ã€‚é€šä¿¡é‡å¢åŠ äº†50%ï¼Œå› ä¸ºåœ¨å‰å‘/åå‘ä¼ æ’­ä¸­éœ€è¦æ¯ä¸ªè®¾å¤‡éœ€è¦é¢å¤–å¹¿æ’­è‡ªå·±å­˜å‚¨çš„æ¨¡å‹å‚æ•° 2*(N-1)/N*Pï¼Œåå‘ä¼ æ’­æ—¶éœ€è¦å¯¹å‘é€æ¢¯åº¦åˆ°å¯¹åº”çš„è®¾å¤‡ä¸Š (N-1)/N*P. Memory Savings and Communication Volume for the 3-stage of ZeRO\næ¿€æ´»ã€ä¸´æ—¶ç¼“å†²åŒºå’Œä¸å¯ç”¨çš„å†…å­˜ç‰‡æ®µä¼šæˆä¸ºæ¬¡è¦å†…å­˜ç“¶é¢ˆã€‚ä½œè€…å¼€å‘äº† ZeRO-R ä¼˜åŒ–äº†è¿™ä¸‰ä¸ªå› ç´ åˆ†åˆ«æ¶ˆè€—çš„å‰©ä½™å†…å­˜ã€‚\nå¯¹äºæ¿€æ´» (åœ¨å‰å‘ä¼ æ’­ä¸­å­˜å‚¨ï¼Œåå‘ä¼ æ’­ä¸­ä½¿ç”¨)ï¼Œä»…ä»…ä½¿ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹æ˜¯ä¸å¤Ÿçš„ã€‚ZeRO-R é€šè¿‡æ¿€æ´»åˆ’åˆ†è¯†åˆ«å’Œåˆ é™¤ç°æœ‰ MP æ–¹æ³•ä¸­é‡å¤å­˜å‚¨çš„æ¿€æ´»ï¼Œå¹¶ä¸”åœ¨é€‚å½“æ—¶å€™å°†æ¿€æ´»å­˜å‚¨åœ¨ CPU ä¸­ã€‚ ZeRO-R å®šä¹‰äº†é€‚å½“å¤§å°çš„ä¸´æ—¶ç¼“å†²åŒºï¼Œä»¥å®ç°å†…å­˜å’Œè®¡ç®—æ•ˆç‡çš„å¹³è¡¡ã€‚ ç”±äºä¸åŒå¼ é‡çš„å¯¿å‘½å­˜åœ¨å·®å¼‚ï¼ŒZeRO-R æ ¹æ®å¼ é‡çš„ä¸åŒç”Ÿå‘½å‘¨æœŸä¸»åŠ¨ç®¡ç†å†…å­˜ï¼Œé˜²æ­¢å†…å­˜ç¢ç‰‡ã€‚ åœ¨æŸäº›æƒ…å†µä¸‹ï¼ŒMP ä»å¯ä»¥å’Œ ZeRO ä¸€èµ·ä½¿ç”¨ï¼šiï¼‰å½“ä¸ ZeRO-R ä¸€èµ·ä½¿ç”¨æ—¶ï¼ŒMP å¯ä»¥å‡å°‘è¶…å¤§æ¨¡å‹çš„æ¿€æ´»å†…å­˜å ç”¨ã€‚iiï¼‰å¯¹äºè¾ƒå°æ¨¡å‹ï¼Œå½“å•ç‹¬ä½¿ç”¨ DP çš„ batchsize å¤ªå¤§è€Œæ— æ³•å®ç°è‰¯å¥½çš„æ”¶æ•›æ—¶ï¼ŒMP ä¹Ÿå¯ä»¥å¸¦æ¥å¥½å¤„ã€‚\nWhere Did All the Memory Go? åœ¨æ¨¡å‹è®­ç»ƒæœŸé—´ï¼Œå¤§éƒ¨åˆ†å†…å­˜è¢«æ¨¡å‹çŠ¶æ€æ¶ˆè€— (ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œå‚æ•°). é™¤äº†è¿™äº›æ¨¡å‹çŠ¶æ€ä¹‹å¤–ï¼Œå‰©ä½™çš„å†…å­˜è¢«æ¿€æ´»ã€ä¸´æ—¶ç¼“å†²åŒºå’Œç¢ç‰‡å†…å­˜æ‰€æ¶ˆè€—ï¼Œç§°ä¹‹ä¸ºå‰©ä½™çŠ¶æ€ã€‚\nModel States: Optimizer States, Gradients and Parameters Adam ä¼˜åŒ–å™¨éœ€è¦å­˜å‚¨ä¸¤ä¸ªä¼˜åŒ–å™¨çŠ¶æ€ï¼šæ—¶é—´å¹³å‡åŠ¨é‡å’Œæ¢¯åº¦æ–¹å·®æ¥è®¡ç®—æ›´æ–°åçš„å‚æ•°ã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦æœ‰è¶³å¤Ÿçš„å†…å­˜æ¥å­˜å‚¨æ¢¯åº¦å’Œæƒé‡æœ¬èº«ã€‚\næ··åˆç²¾åº¦è®­ç»ƒ (Mixed-Precision Training) ä¸­å‚æ•°å’Œæ¿€æ´»ä»¥ fp16 æ ¼å¼å­˜å‚¨å¹¶ä¸”åœ¨å‰å‘å’Œåå‘ä¼ æ’­ä¸­ä¹Ÿä½¿ç”¨ fp16 æ ¼å¼çš„æƒé‡å’Œæ¿€æ´»ã€‚Adam ä¼˜åŒ–å™¨å­˜å‚¨ fp32 æ ¼å¼çš„å‚æ•°å‰¯æœ¬ã€åŠ¨é‡å’Œæ–¹å·®ä»¥ä¿è¯æ›´æ–°çš„ç²¾åº¦ã€‚\nå‡è®¾æ¨¡å‹å‚æ•°é‡ä¸º Ïˆï¼Œæ¨¡å‹å‚æ•°éœ€è¦å ç”¨ 2Ïˆ å­—èŠ‚çš„å†…å­˜ï¼Œåå‘ä¼ æ’­ä¸­äº§ç”Ÿçš„ fp16 æ¢¯åº¦éœ€è¦å ç”¨ 2Ïˆ å­—èŠ‚çš„å†…å­˜ã€‚Adam ä¼˜åŒ–å™¨å­˜å‚¨ fp32 æ ¼å¼çš„å‚æ•°å‰¯æœ¬ã€åŠ¨é‡å’Œæ–¹å·®æ¯ä¸ªéƒ½éœ€è¦å ç”¨ 4Ïˆ å­—èŠ‚çš„å†…å­˜ã€‚å› æ­¤è®­ç»ƒæ—¶æ€»å…±éœ€è¦ 16Ïˆ å­—èŠ‚çš„å†…å­˜ï¼Œä¸ºå­˜å‚¨æ¨¡å‹å‚æ•°çš„ 8x.\nResidual Memory Consumption åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¿€æ´»ä¼šå ç”¨å¤§é‡çš„å†…å­˜ã€‚åŸºäº transformer çš„æ¨¡å‹çš„æ¿€æ´»å†…å­˜å ç”¨ä¸å±‚æ•°Ã—éšè—ç»´åº¦Ã—åºåˆ—é•¿åº¦Ã—æ‰¹å¤§å°æˆæ­£æ¯”ã€‚å¯¹äºç±»ä¼¼ GPT-2çš„ç»“æ„ï¼Œæ€»æ¿€æ´»çº¦ä¸º 12Ã—éšè—äº®åº¦Ã—æ‰¹å¤§å°Ã—åºåˆ—é•¿åº¦Ã—å˜å±‚æ•° (QKV(h*3h) + O(h*h) + MLP(h*4h+4h*h)=12h*hï¼Œæ²¡æœ‰è€ƒè™‘ mask). æ¿€æ´»é‡è®¡ç®—å¯ä»¥ä»¥ 33% çš„é¢å¤–è®¡ç®—å¼€é”€ (ä¹‹å‰æ˜¯ä¸€æ¬¡å‰å‘ï¼Œä¸€æ¬¡åå‘ï¼Œåå‘å› ä¸ºéœ€è¦å¯¹è¾“å…¥å’Œå‚æ•°éƒ½è¿›è¡Œæ±‚å¯¼æ‰€ä»¥è®¡ç®—é‡æ˜¯å‰å‘çš„ä¸¤å€ï¼Œç°åœ¨å¤šäº†ä¸€æ¬¡å‰å‘) æ¢å–æ¥è¿‘åŸå…ˆæ¿€æ´»å¤§å°å¹³æ–¹çº§åˆ«çš„å†…å­˜å ç”¨ã€‚\nå¯¹äºå¤§å‹æ¨¡å‹ï¼Œç”¨äºå­˜å‚¨ä¸­é—´ç»“æœçš„ä¸´æ—¶ç¼“å†²åŒºä¼šæ¶ˆè€—å¤§é‡å†…å­˜ã€‚å¯¹æ¢¯åº¦è¿›è¡Œ All-Reduce æˆ–æ¢¯åº¦å½’ä¸€åŒ–è®¡ç®—ç­‰æ“ä½œå€¾å‘äºåœ¨æ“ä½œä¹‹å‰å°†æ‰€æœ‰æ¢¯åº¦èåˆåˆ°å•ä¸ªæ‰å¹³ç¼“å†²åŒºä¸­ï¼Œä»¥æé«˜ååé‡ã€‚\nç¢ç‰‡åŒ–å†…å­˜ä¼šå¯¼è‡´å³ä½¿æœ‰è¶³å¤Ÿçš„å†…å­˜ä½†æ²¡æœ‰è¶³å¤Ÿå¤§çš„è¿ç»­å—è¿›è¡Œåˆ†é…æ—¶çš„ OOMï¼Œä½œè€…è§‚å¯Ÿåˆ°æç«¯æƒ…å†µä¸‹åœ¨æœ‰ 30% å‰©ä½™å†…å­˜æ—¶ä¹Ÿä¼šäº§ç”Ÿ OOM.\nZeRO: Insight and Overview ZeROæœ‰ä¸¤ç»„ä¼˜åŒ–ï¼šZeRO-DP æ—¨åœ¨å‡å°‘æ¨¡å‹çŠ¶æ€çš„å†…å­˜å ç”¨ï¼›ZeRO-R æ—¨åœ¨å‡å°‘å‰©ä½™å†…å­˜æ¶ˆè€—ã€‚\nZeRO-DP åŸºäºä¸‰ä¸ªå…³é”®è§è§£ï¼š\nDP æ¯” MP å…·æœ‰æ›´å¥½çš„æ‰©å±•æ•ˆç‡ï¼Œå› ä¸º MP å‡å°‘äº†è®¡ç®—çš„ç²’åº¦ï¼ŒåŒæ—¶ä¹Ÿå¢åŠ äº†é€šä¿¡å¼€é”€ã€‚ DP å†…å­˜æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºæ¨¡å‹çŠ¶æ€è¢«åœ¨æ‰€æœ‰æ•°æ®å¹¶è¡Œè¿›ç¨‹ä¸­éƒ½å­˜æœ‰ä¸€ä»½ã€‚ DP å’Œ MP éƒ½ä¿ç•™äº†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æ‰€éœ€çš„æ‰€æœ‰æ¨¡å‹çŠ¶æ€ï¼Œä½†å¹¶éæ‰€æœ‰çŠ¶æ€åœ¨æ•´ä¸ªè®­ç»ƒæœŸé—´éƒ½éœ€è¦ã€‚ ZeRO-DP åˆ’åˆ†æ¨¡å‹çŠ¶æ€ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€é€šä¿¡è°ƒåº¦åˆ©ç”¨æ¨¡å‹çŠ¶æ€çš„å†…åœ¨çš„æš‚æ—¶æ€§ï¼ŒåŒæ—¶æœ€å°åŒ–é€šä¿¡é‡ã€‚\nZeRO-R åŸºäºä¸¤ä¸ªå…³é”®è§è§£ï¼š\nMP å¯¹æ¨¡å‹çŠ¶æ€è¿›è¡Œåˆ‡åˆ†ï¼Œä½†é€šå¸¸éœ€è¦é‡å¤å­˜å‚¨æ¿€æ´»ã€‚ å¯¹äºGPT-2æˆ–æ›´å¤§çš„æ¨¡å‹ï¼Œç®—æœ¯å¼ºåº¦ (æ¯æ¬¡è¿­ä»£è®¡ç®—é‡ä¸æ¿€æ´»æ£€æŸ¥ç‚¹æ•°é‡çš„æ¯”å€¼) éå¸¸å¤§ (â‰¥10K)ï¼Œå¹¶ä¸”éšç€éšè—ç»´æ•°çš„å¢åŠ è€Œçº¿æ€§å¢åŠ ï¼Œå³ä½¿åœ¨å¸¦å®½è¾ƒä½çš„æƒ…å†µä¸‹ï¼Œä¹Ÿå¯ä»¥éšè—æ¿€æ´»æ£€æŸ¥ç‚¹çš„æ•°æ®ç§»åŠ¨æˆæœ¬ã€‚ ZeRO é€šè¿‡è·¨ GPU åˆ’åˆ†æ¿€æ´»æ£€æŸ¥ç‚¹æ¥æ¶ˆé™¤ MP ä¸­çš„å†…å­˜å†—ä½™ï¼Œå¹¶æ ¹æ®éœ€è¦ä½¿ç”¨ All-Gather æ¥é‡å»ºï¼›ä½¿ç”¨æ’å®šå¤§å°çš„ç¼“å†²åŒºæ¥é¿å…ä¸´æ—¶ç¼“å†²åŒºéšç€æ¨¡å‹å¤§å°çš„å¢åŠ è€Œçˆ†ç‚¸ï¼›é€šè¿‡å°†æ¿€æ´»æ£€æŸ¥ç‚¹å’Œæ¢¯åº¦ç§»åŠ¨åˆ°é¢„åˆ†é…çš„è¿ç»­å†…å­˜ç¼“å†²åŒºæ¥æ‰§è¡ŒåŠ¨æ€å†…å­˜ç¢ç‰‡æ•´ç†ã€‚\nDeep Dive into ZeRO-DP ä¸‹è¡¨æ˜¾ç¤ºäº†é€æ¸åˆ‡åˆ† (1) ä¼˜åŒ–å™¨çŠ¶æ€ã€(2) æ¢¯åº¦å’Œ (3) å‚æ•°å†—ä½™åçš„å†…å­˜å ç”¨ã€‚ç§°ä¸ºZeRO-DPçš„ä¸‰ä¸ªä¼˜åŒ–é˜¶æ®µï¼šPosï¼Œ Pgå’ŒPpï¼Œå°†åœ¨ä¸‹é¢è¯¦ç»†è¯´æ˜ã€‚\nDP\r7.5B Model (GB)\r128B Model (GB)\r1T Model (GB)\rPos\rPos+g\rPos+g+p\rPos\rPos+g\rPos+g+p\rPos\rPos+g\rPos+g+p\r1\r120\r120\r120\r2048\r2048\r2048\r16000\r16000\r16000\r4\r52.5\r41.3\r30\r896\r704\r512\r7000\r5500\r4000\r16\r35.6\r21.6\r7.5\r608\r368\r128\r4750\r2875\r1000\r64\r31.4\r16.6\r1.88\r536\r284\r32\r4187\r2218\r250\r256\r30.4\r15.4\r0.47\r518\r263\r8\r4046\r2054\r62.5\r1024\r30.1\r15.1\r0.12\r513\r257\r2\r4011\r2013\r15.6\rPos: Optimizer State Partitioning è®¾ DP å¹¶è¡Œåº¦ä¸º Nd, æ¯ä¸ªæ•°æ®å¹¶è¡Œè¿›ç¨‹åªéœ€è¦å­˜å‚¨å’Œæ›´æ–°æ€»ä¼˜åŒ–å™¨çŠ¶æ€çš„ 1/Ndï¼Œç„¶ååªæ›´æ–°å‚æ•°çš„ 1/Nd. åœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤ç»“æŸæ—¶ï¼Œåœ¨æ•°æ®å¹¶è¡Œè¿›ç¨‹ä¸­æ‰§è¡Œä¸€æ¬¡ All-Gatherï¼Œä»¥è·å¾—æ‰€æœ‰æ•°æ®å¹¶è¡Œè¿‡ç¨‹ä¸­å®Œå…¨æ›´æ–°çš„å‚æ•°ã€‚è¿™ä½¿å¾—æ¯ä¸ªè®¾å¤‡ä¸Šä¿å­˜æ¨¡å‹çŠ¶æ€éœ€è¦çš„å†…å­˜ä» 4Ïˆ+KÏˆ å˜æˆ 4Ïˆ+KÏˆ/Ndï¼Œå½“ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ (K=12) å¹¶ä¸” Nd å¾ˆå¤§æ—¶ï¼Œå†…å­˜éœ€æ±‚å¯ä»¥é™ä½æ¥è¿‘ 4x.\nPg: Gradient Partitioning ç”±äºæ¯ä¸ªæ•°æ®å¹¶è¡Œè¿›ç¨‹åªç”¨æ›´æ–°è‡ªå·±è¢«åˆ†é…çš„å‚æ•°ï¼Œå› æ­¤ä»–ä¹Ÿåªéœ€è¦é‚£éƒ¨åˆ†å‚æ•° reduce åçš„æ¢¯åº¦ã€‚åªåœ¨è´Ÿè´£æ›´æ–°ç›¸åº”å‚æ•°çš„æ•°æ®å¹¶è¡Œè¿‡ç¨‹ä¸­è¿›è¡Œ reduce. å®Œæˆåå®ƒä»¬çš„å†…å­˜å¯ä»¥è¢«é‡Šæ”¾ã€‚è¿™ä½¿å¾—äº†æ¢¯åº¦æ‰€éœ€çš„å†…å­˜å ç”¨ä» 2Î¨ å­—èŠ‚å‡å°‘åˆ° 2Î¨/Nd. æ›´æ–°åçš„å‚æ•°å†è¢« scatter åˆ°å…¶ä»–è¿›ç¨‹ã€‚\né€šå¸¸ä¸ºäº†æ•ˆç‡ï¼Œå°†éœ€è¦ reduce çš„æ¢¯åº¦æŒ‰ç…§å‚æ•°çš„åˆ†åŒºåˆ’åˆ†æˆå¤šä¸ª bucketsï¼Œæ¯ä¸ª bucket å¯¹åº”ç‰¹å®šçš„ä¸€ç»„å‚æ•°ï¼Œå¯¹æ¯ä¸ª bucket è¿›è¡Œæ•´ä½“ reduce æ“ä½œï¼Œè€Œä¸æ˜¯å¯¹å•ä¸ªæ¢¯åº¦è¿›è¡Œæ“ä½œã€‚è¿›ä¸€æ­¥åˆ’åˆ†æ¢¯åº¦åï¼Œæ¯ä¸ªè®¾å¤‡ä¸Šä¿å­˜æ¨¡å‹çŠ¶æ€éœ€è¦çš„å†…å­˜è¿›ä¸€æ­¥å‡å°‘åˆ° 2Ïˆ+(K+2)Ïˆ/Nd\nè“è‰²ç®­å¤´ä¸²èµ·æ¥çš„ç™½è‰²é•¿æ–¹å½¢ä»£è¡¨çš„æ˜¯ Transformer Blockï¼Œè“è‰²çš„ç¬¬ä¸€è¡Œä»£è¡¨ FP16 å‚æ•°ï¼›æ©™è‰²çš„ç¬¬äºŒè¡Œä»£è¡¨ FP16 æ¢¯åº¦ï¼Œåå‘ä¼ æ’­æ—¶å°†ç”¨äºæ›´æ–°å‚æ•°ï¼›ç»¿è‰²çš„è¡Œä»£è¡¨ä¼˜åŒ–å™¨çŠ¶æ€ (FP32 çš„æ¢¯åº¦ï¼ŒåŠ¨é‡ï¼Œæ–¹å·®ï¼Œä»¥åŠæ›´æ–°åçš„å‚æ•°)ï¼Œå…¶ä¸­åœ¨è®¡ç®—å®Œ FP16 æ¢¯åº¦ä»¥åä¸å†éœ€è¦ä¿å­˜ FP32 å‚æ•°ã€‚åŒæ—¶ä¹Ÿéœ€è¦ buffer æ¥ä¿å­˜éƒ¨åˆ† transformer block çš„è¾“å‡ºæ¿€æ´»ã€‚\nPp: Parameter Partitioning æ›´è¿›ä¸€æ­¥æˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹å‚æ•°ä¹Ÿè¿›è¡Œåˆ’åˆ†ï¼Œå½“è®¾å¤‡æ‰€æ²¡æœ‰çš„å‚æ•°éœ€è¦è¿›è¡Œå‘å‰å’Œå‘åä¼ æ’­æ—¶ï¼Œé€šè¿‡å¹¿æ’­ä»å…¶ä»–çš„çš„æ•°æ®å¹¶è¡Œè¿›ç¨‹æ¥æ”¶ã€‚é€šè¿‡å‰é¢çš„åˆ†æå¯çŸ¥è¿™ä½¿å¾—é€šä¿¡é‡å˜ä¸ºåŸæ¥çš„ 1.5xï¼Œ ä½†ä½¿å¾—æ‰€æœ‰çš„æ¨¡å‹å‚æ•°éƒ½è¢«åˆ’åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œåªéœ€è¦ (4+K)/Nd å­—èŠ‚çš„å†…å­˜ã€‚\nExecution Steps of ZeRO3 Overview of Memory Consumption\næ¯ä¸ª GPU åªéœ€è¦ä¿å­˜è‡ªå·±éƒ¨åˆ†çš„ Pos+g+p. å‰å‘ä¼ æ’­æ—¶ä¿å­˜å¯¹åº”æ¨¡å‹å‚æ•°çš„ GPU éœ€è¦æŠŠå‚æ•°å¹¿æ’­åˆ°å…¶ä»– GPU ä¸­ï¼Œå…¶ä»– GPU ç”¨è‡ªå·±éƒ¨åˆ†çš„æ•°æ®å®Œæˆå‰å‘ä¼ æ’­åå°±å¯ä»¥åˆ é™¤è¿™éƒ¨åˆ†å‚æ•° (æœ€åä¸€éƒ¨åˆ†é™¤å¤–). (N-1)/N*P\nBroadcast of Model Parameters\nå‰å‘ä¼ æ’­å®Œæˆåï¼Œç¬¬ä¸€æ¬¡åå‘ä¼ æ’­å¯ä»¥åˆ©ç”¨æœ€åä¸€æ¬¡æ­£å‘ä¼ æ’­å·²ç»å¹¿æ’­äº†çš„æ¨¡å‹å‚æ•°ï¼Œæ¯ä¸ª GPU è®¡ç®—è‡ªå·±éƒ¨åˆ†çš„æ¢¯åº¦ï¼Œç„¶å Reduce åˆ°å­˜å‚¨å¯¹åº”æ¨¡å‹å‚æ•°çš„ GPU ä¸­ã€‚ä¹‹åå’Œå‰å‘ä¼ æ’­ä¸€æ ·ï¼Œæ¯ä¸ª GPU éƒ½éœ€è¦å¹¿æ’­è‡ªå·±çš„å‚æ•°ï¼Œç„¶åå…¶ä»– GPU ç”¨è‡ªå·±çš„æ•°æ®å®Œæˆæ¢¯åº¦è®¡ç®—ä»¥å Reduce åˆ°è‡ªå·±çš„æ¢¯åº¦ã€‚(N-1)/N*P + 1/N*G*(N-1)\nGradient Accumulation\nåå‘ä¼ æ’­ç»“æŸä»¥åï¼Œæ¯ä¸ª GPU ä½¿ç”¨ä¼˜åŒ–å™¨æ›´æ–°è‡ªå·±çš„ FP32 æ¨¡å‹å‚æ•°åè½¬æ¢æˆ FP16 æ ¼å¼ã€‚\nUpdate Parameters Locally\nDeep Dive into ZeRO-R Pa: Partitioned Activation Checkpointing ä¸€æ—¦è®¡ç®—äº†æ¨¡å‹çš„ä¸€å±‚çš„å‰å‘ä¼ æ’­ï¼Œè¾“å…¥æ¿€æ´»å°†åœ¨æ‰€æœ‰æ¨¡å‹å¹¶è¡Œè¿‡ç¨‹ä¸­è¿›è¡Œåˆ’åˆ†ï¼Œç›´åˆ°åœ¨åå‘ä¼ æ’­æœŸé—´å†æ¬¡éœ€è¦è¾“å…¥æ¿€æ´»ã€‚æ­¤æ—¶ï¼ŒZeRO ä½¿ç”¨ä¸€ä¸ª All-Gather æ“ä½œæ¥é‡æ–°å®ç°æ¿€æ´»çš„å¤åˆ¶å‰¯æœ¬ã€‚ç§°è¿™ä¸ªä¼˜åŒ–ä¸º Pa. å°† Pa ä¸æ¿€æ´»æ£€æŸ¥ç‚¹ç»“åˆï¼Œåªå­˜å‚¨åˆ†åŒºçš„æ¿€æ´»æ£€æŸ¥ç‚¹ï¼Œè¿™æ ·ä½¿å¾—æ¿€æ´»å ç”¨ç©ºé—´çš„å‡å°‘ä¸ MP å¹¶è¡Œåº¦æˆæ­£æ¯”ã€‚\nCB: Constant Size Buffers é€šä¿¡çš„æ•ˆç‡ä¸ä»…ä»…ä¸æ•°æ®é‡ç›¸å…³ï¼Œè¿˜å—åˆ°å›ºå®šå¯åŠ¨å¼€é”€å’Œå¸¦å®½åˆ©ç”¨ç‡çš„å½±å“ã€‚è¾ƒå¤§çš„è¾“å…¥æ›´å®¹æ˜“å……åˆ†åˆ©ç”¨ç¡¬ä»¶çš„å¸¦å®½å’Œä¼˜åŒ–æœºåˆ¶ï¼Œå› è€Œèƒ½æ˜¾è‘—æé«˜ All-Reduce æ“ä½œçš„æ•ˆç‡ã€‚å› æ­¤ç»å¸¸å°†éœ€è¦è¿›è¡Œé€šä¿¡çš„æ•°æ®åˆå¹¶åˆ°ä¸€ä¸ªç¼“å†²å™¨ã€‚ç„¶è€Œï¼Œåˆå¹¶ç¼“å†²åŒºçš„å†…å­˜å¼€é”€ä¸æ¨¡å‹å¤§å°æˆæ­£æ¯”ï¼Œæ¨¡å‹è¿‡å¤§æ—¶å®¹æ˜“ OOM. ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå½“æ¨¡å‹å¾ˆå¤§æ—¶ï¼Œç®€å•åœ°ä½¿ç”¨ä¸€ä¸ªæ€§èƒ½é«˜æ•ˆçš„å›ºå®šå¤§å°çš„åˆå¹¶ç¼“å†²åŒºã€‚\nMD: Memory Defragmentation å‰å‘ä¼ æ’­ä¸­åªéœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹çš„æ¿€æ´»è€Œä¸¢å¼ƒå…¶ä»–æ¿€æ´»ä¼šäº§ç”Ÿç¢ç‰‡åŒ–å†…å­˜ã€‚åŒæ ·çš„åå‘ä¼ æ’­ä¸­åªéœ€è¦ä¿å­˜å‚æ•°çš„æ¢¯åº¦è€Œä¸¢å¼ƒæ¿€æ´»çš„æ¢¯åº¦ä¹Ÿä¼šäº§ç”Ÿç¢ç‰‡åŒ–å†…å­˜ã€‚å†…å­˜ç¢ç‰‡å¯¼è‡´ä¸¤ä¸ªé—®é¢˜: (1) å³ä½¿æœ‰è¶³å¤Ÿçš„å¯ç”¨å†…å­˜ï¼Œç”±äºç¼ºä¹è¿ç»­å†…å­˜å¯¼è‡´ OOM. (2) ç”±äºå†…å­˜åˆ†é…å™¨èŠ±è´¹å¤§é‡æ—¶é—´æœç´¢è¿ç»­å†…å­˜å—ä»¥æ»¡è¶³å†…å­˜è¯·æ±‚è€Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚ZeRO é€šè¿‡ä¸ºæ¿€æ´»æ£€æŸ¥ç‚¹å’Œæ¢¯åº¦é¢„åˆ†é…è¿ç»­å†…å­˜å—ï¼Œå¹¶åœ¨å®ƒä»¬äº§ç”Ÿæ—¶å°†å®ƒä»¬å¤åˆ¶åˆ°é¢„åˆ†é…çš„å†…å­˜ä¸­ï¼Œä»è€Œå®æ—¶åœ°è¿›è¡Œå†…å­˜ç¢ç‰‡æ•´ç†ã€‚\nCommunication Analysis of ZeRO-DP ä½¿ç”¨ Pos å’Œ Pg æ—¶ï¼ŒZeRO-DP ä¸ä¼šäº§ç”Ÿé¢å¤–çš„é€šä¿¡ï¼ŒåŒæ—¶å¯ä»¥å‡å°‘é«˜è¾¾ 8 å€çš„å†…å­˜ã€‚ä½¿ç”¨ Pos+g+p æ—¶ï¼ŒZeRO-DP æœ€å¤šä¼šäº§ç”Ÿ 1.5 å€çš„é€šä¿¡ï¼ŒåŒæ—¶å‡å°‘å†…å­˜å ç”¨ä¸ºåŸæ¥çš„ 1/Nd.\nåœ¨æ•°æ®å¹¶è¡Œè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåœ¨è®¡ç®—ä¸‹ä¸€æ­¥çš„æ›´æ–°ä¹‹å‰ï¼Œåœ¨åå‘ä¼ æ’­ç»“æŸæ—¶å¯¹æ‰€æœ‰æ•°æ®å¹¶è¡Œè¿›ç¨‹çš„æ¢¯åº¦ä½¿ç”¨ All-Reduce è¿›è¡Œå¹³å‡ï¼Œå› æ­¤é€šä¿¡é‡ä¸º 2Ïˆ. ä½¿ç”¨ Pos+g æ—¶æ¯ä¸ªè®¾å¤‡éœ€è¦å°†è‡ªå·±çš„æ¢¯åº¦ scatter åˆ°è´Ÿè´£æ›´æ–°é‚£éƒ¨åˆ†å‚æ•°çš„è®¾å¤‡ä¸Šï¼Œç„¶åä½¿ç”¨ Gather å°†å…¶ä»–è®¾å¤‡æ›´æ–°åçš„æ¨¡å‹å‚æ•°åŒæ­¥åˆ°è‡ªå·±ä¸Šé¢ï¼Œæ€»é€šä¿¡é‡ä»ä¸º 2Ïˆï¼Œä¸æ•°æ®å¹¶è¡Œç›¸åŒã€‚ä½¿ç”¨ Pos+g+p æ—¶è´Ÿè´£è¯¥åˆ†åŒºçš„æ•°æ®å¹¶è¡Œè¿›ç¨‹å°†æƒé‡ brocast ç»™æ‰€æœ‰æ•°æ®å¹¶è¡Œè¿›ç¨‹ (å‰å‘åå‘å„ä¸€æ¬¡)ï¼Œæœ€åä»éœ€è¦ Gather å…¶ä»–è¿›ç¨‹ä¸Šæ›´æ–°å¥½çš„å‚æ•°ï¼Œå› æ­¤æ€»é€šä¿¡é‡ä¸º 3Ïˆ.\nCommunication Analysis of ZeRO-R åœ¨ä½¿ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹çš„ Megatron-LM ä¸­ï¼Œæ¯ä¸ª transformer block åœ¨å‰å‘ä¼ æ’­ä¸­æ‰§è¡Œ 2 æ¬¡å¤§å°ä¸º æ‰¹å¤§å°Ã—åºåˆ—é•¿åº¦Ã—éšè—ç»´åº¦çš„ All-Reduce æ“ä½œï¼Œåå‘ä¼ æ’­ä¸­æ‰§è¡Œ 2 æ¬¡åŒæ ·å¤§å°çš„ All-Reduce æ“ä½œï¼ŒåŒæ—¶æ¿€æ´»é‡è®¡ç®—ä¹Ÿéœ€è¦ 2 æ¬¡åŒæ ·å¤§å°çš„ All-Reduce æ“ä½œã€‚å› æ­¤æ¯ä¸ªå—çš„æ€»é€šä¿¡é‡ä¸º 12Ã—åºåˆ—é•¿åº¦Ã—éšè—ç»´åº¦ã€‚\nå½“ä½¿ç”¨ ZeRO-R åˆ’åˆ†æ¿€æ´»æ£€æŸ¥ç‚¹æ—¶ï¼Œåœ¨å¯¹æ¯ä¸ªæ¿€æ´»æ£€æŸ¥ç‚¹ä¸Šçš„åå‘ä¼ æ’­è¿›è¡Œå‰å‘é‡æ–°è®¡ç®—ä¹‹å‰ï¼Œéœ€è¦è¿›è¡Œé¢å¤–çš„ä¸€æ¬¡ All-Gather æ“ä½œã€‚å› æ­¤ï¼ŒPaçš„æ€»é€šä¿¡å¼€é”€ç›¸å¯¹äºåŸå…ˆ MP é€šä¿¡é‡å¢åŠ äº† 1/12ï¼Œä½†æ˜¯ä½¿å¾—æ¿€æ´»å†…å­˜å ç”¨å‡å°åˆ°åŸæ¥çš„ 1/MP_degree.\nå¦‚æœä½¿ç”¨äº† Pa+cpuï¼Œåˆ™åˆ†åŒºæ¿€æ´»æ£€æŸ¥ç‚¹å°†è¢«å­˜å‚¨åˆ° CPUï¼Œå¯¹æ¿€æ´»å†…å­˜éœ€æ±‚å‡å°‘åˆ°å‡ ä¹ä¸ºé›¶ï¼Œè€Œä»£ä»·æ˜¯ä¸ Pa ç›¸æ¯”ï¼Œéœ€è¦ä» CPU å’Œå†…å­˜ä¹‹é—´çš„æ•°æ®ç§»åŠ¨å¢åŠ äº† 2 å€ã€‚\nZeRO-Offload ZeRO-Offload é€šè¿‡å°†æ•°æ®å’Œè®¡ç®—ä¸‹æ”¾åˆ° CPU æ¥å®ç°å¤§å‹æ¨¡å‹è®­ç»ƒã€‚ä¸ºäº†ä¿æŒè®¡ç®—æ•ˆç‡ï¼Œå®ƒå°½å¯èƒ½å‡å°‘æ•°æ®åœ¨ GPU å’Œ CPU ä¹‹é—´çš„ç§»åŠ¨ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘ CPU çš„è®¡ç®—æ—¶é—´ï¼Œå¹¶æœ€å¤§é™åº¦åœ°èŠ‚çœ GPU ä¸Šçš„å†…å­˜ã€‚\nIntroduction PP, MP å’Œ ZeRO ç­‰å¹¶è¡ŒæŠ€æœ¯éƒ½éœ€è¦æœ‰è¶³å¤Ÿçš„ GPU è®¾å¤‡ï¼Œä½¿å¾—å®ƒä»¬çš„å†…å­˜ä¹‹å’Œèƒ½å¤Ÿå®¹çº³è®­ç»ƒæ‰€éœ€çš„æ¨¡å‹çŠ¶æ€çš„å­˜å‚¨ã€‚ç›®å‰åŸºäºæ³¨æ„åŠ›çš„å¤§æ¨¡å‹è®­ç»ƒçš„ä¸»è¦å†…å­˜ç“¶é¢ˆæ˜¯æ¨¡å‹çŠ¶æ€ï¼Œè€Œä¸æ˜¯æ¿€æ´»ã€‚ç°æœ‰çš„å¼‚æ„è®­ç»ƒåœ¨ä¸¤ä¸ªä¸»è¦æ–¹é¢å—åˆ°é™åˆ¶ï¼š(i) å‡ ä¹æ‰€æœ‰çš„è®­ç»ƒéƒ½åˆ©ç”¨ CPU å†…å­˜ï¼Œè€Œä¸æ˜¯ CPUç®—åŠ›ã€‚(ii) å®ƒä»¬ä¸»è¦æ˜¯ä¸ºå•ä¸ª GPU è®¾è®¡å’Œè¯„ä¼°çš„ã€‚\nZeRO-Offload ä¸ºäº†æé«˜è®¡ç®—æ•ˆç‡é‡‡å–çš„è®¾è®¡åŸåˆ™æœ‰ä¸‰æ¡ï¼š(i) å®ƒéœ€è¦çš„ CPU è®¡ç®—é‡ä¸ GPU ç›¸æ¯”å‡å°‘äº†å‡ ä¸ªæ•°é‡çº§ã€‚(ii) å®ƒæœ€å°åŒ–äº† CPU å’Œ GPU ä¹‹é—´çš„é€šä¿¡é‡ï¼Œé˜²æ­¢äº†é€šä¿¡æˆä¸ºç“¶é¢ˆã€‚(iii) å¯ä»¥è¯æ˜åœ¨å®ç°æœ€å°é€šä¿¡é‡çš„åŒæ—¶æœ€å¤§é™åº¦åœ°èŠ‚çœäº† GPU çš„å†…å­˜ã€‚\nZeRO-Offload å°†æ¢¯åº¦ï¼Œä¼˜åŒ–å™¨çŠ¶æ€å’Œä¼˜åŒ–å™¨è®¡ç®—å¸è½½åˆ° CPUï¼Œè€Œå°†å‚æ•°å’Œå‰å‘å’Œåå‘è®¡ç®—ä¿ç•™åœ¨ GPUä¸Šã€‚è¿™æ · CPU ä¸Šçš„è®¡ç®—é‡ä¸º O(M)ï¼Œè€Œ GPU ä¸Šçš„è®¡ç®—é‡åˆ™ä¸º O(MB)ï¼Œå…¶ä¸­ M å’Œ B åˆ†åˆ«ä¸ºæ¨¡å‹å¤§å°å’Œ batchsize. å› ä¸º CPU åªå¤„ç†æ¨¡å‹å‚æ•°çš„æ›´æ–°ï¼Œè€Œä¸å‚ä¸ä¸ batch size ç›¸å…³çš„æ¢¯åº¦æ±‚å¹³å‡çš„æ“ä½œã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œbatchsize è¾ƒå¤§ï¼Œå› æ­¤ CPU è®¡ç®—ä¸æ˜¯ç“¶é¢ˆã€‚ä½†æ˜¯å¯¹äºè¾ƒå°çš„ batchsizeï¼ŒCPU è®¡ç®—å¯èƒ½ä¼šæˆä¸ºç“¶é¢ˆã€‚\nUnique Optimal Offload Strategy ä¸ºäº†ç¡®å®šæœ€ä½³çš„å¸è½½ç­–ç•¥ï¼ŒZeRO-Offload å°† DL è®­ç»ƒå»ºæ¨¡ä¸ºå¦‚ä¸‹å›¾æ‰€ç¤ºçš„æ•°æ®æµï¼Œå¹¶æœ‰æ•ˆåœ°åœ¨ CPU å’Œ GPU è®¾å¤‡ä¹‹é—´è¿›è¡Œåˆ’åˆ†ã€‚GPU å’Œ CPU ä¹‹é—´çš„å¸è½½ç­–ç•¥å¯ä»¥ä½¿ç”¨è¯¥å›¾çš„äºŒåˆ†å›¾æ¥è¡¨ç¤ºï¼Œè¿™æ ·ä¸€ä¸ªåˆ†åŒºä¸­çš„è®¡ç®—èŠ‚ç‚¹å°†åœ¨æ‹¥æœ‰è¯¥åˆ†åŒºçš„è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œåˆ†åŒºä¸­çš„æ•°æ®èŠ‚ç‚¹ä¹Ÿå­˜å‚¨åœ¨æ‹¥æœ‰è¯¥åˆ†åŒºçš„è®¾å¤‡ä¸Šã€‚\nThe Dataflow of Fully Connected Neural Networks\nç”±äº CPU çš„ç®—åŠ›è¿œè¿œä½äº GPUï¼Œæ‰€ä»¥å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ (å®ƒä»¬çš„è®¡ç®—å¤æ‚åº¦éƒ½æ˜¯ O(MB)) å¿…é¡»åœ¨ GPUä¸Šå®Œæˆï¼Œè€Œå…¶ä½™å¤æ‚åº¦ä¸º O(M) çš„è®¡ç®— (å¦‚å½’ä¸€åŒ–è®¡ç®—ã€æƒé‡æ›´æ–°ç­‰) ä¼šè¢«å¸è½½åˆ° CPU ä¸Šã€‚\nCPU å†…å­˜å¸¦å®½ (100xGB) è‡³å°‘æ¯” CPU å’Œ GPU ä¹‹é—´çš„ PCIe å¸¦å®½ (10xGB) å¿«ä¸€ä¸ªæ•°é‡çº§ï¼Œè€Œ GPU å†…å­˜å¸¦å®½æ¯” CPU å†…å­˜å¸¦å®½ (TB) å¿«å¦ä¸€ä¸ªæ•°é‡çº§ã€‚æ•°æ®æµä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ç¯çš„ä¸€éƒ¨åˆ†ã€‚å› æ­¤ï¼Œå¯¹è¯¥å›¾è¿›è¡Œä»»ä½•åˆ’åˆ†éƒ½éœ€è¦åˆ‡å‰²è‡³å°‘ä¸¤æ¡è¾¹ï¼Œæ¯æ¡è¾¹çš„æƒå€¼è‡³å°‘ä¸º 2Mï¼Œä»è€Œæ€»é€šä¿¡é‡è‡³å°‘ 4M (é€šè¿‡ä»…å¸è½½éƒ¨åˆ†æ¨¡å‹çŠ¶æ€ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‡å°‘é€šä¿¡é‡). å› æ­¤ï¼Œä¸ºäº†å®ç°æœ€å°çš„é€šä¿¡é‡ï¼Œæ‰€æœ‰å¸è½½ç­–ç•¥å¿…é¡»ä½¿å¾—å…³äº fp32 æ¨¡å‹çŠ¶æ€æ“ä½œçš„ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ç›¸åŒã€‚fp16 å‚æ•°èŠ‚ç‚¹å¿…é¡»å’Œ FWD-BWD èŠ‚ç‚¹åœ¨ä¸€ä¸ªå­å›¾ä¸­ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„è¾¹æƒå€¼æ˜¯ 4M.\nä¸‹è¡¨æ˜¾ç¤ºäº†æœ€å°åŒ–é€šä¿¡é‡æƒ…å†µä¸‹çš„æ‰€æœ‰æœ‰æ•ˆåˆ†åŒºç­–ç•¥æ‰€èŠ‚çœçš„å†…å­˜ã€‚é€šè¿‡å°† fp16 æ¢¯åº¦å’Œ Update Super èŠ‚ç‚¹æ”¾åˆ° CPU å¯ä»¥å®ç° 8x çš„æœ€å¤§å†…å­˜èŠ‚çœã€‚\nFWD-BWD p16 g16 Update Memory Reduction gpu gpu gpu gpu 16M 1x (baseline) gpu gpu cpu gpu 14M 1.14x gpu gpu cpu cpu 4M 4x gpu cpu cpu cpu 2M 8x ç»¼ä¸Šæ‰€è¿° ZeRO-Offload åœ¨ CPU ä¸Šå­˜å‚¨æ‰€æœ‰ fp32 æ¨¡å‹çŠ¶æ€ä»¥åŠ fp16 æ¢¯åº¦ï¼Œå¹¶ä¸”è¿˜åœ¨ CPU ä¸Šè®¡ç®—æ›´æ–°åçš„å‚æ•°ã€‚fp16 çš„å‚æ•°ä¿å­˜åœ¨ GPU ä¸Šï¼Œå‰å‘å’Œåå‘è®¡ç®—ä¹Ÿåœ¨GPUä¸Šå®Œæˆã€‚\nZeRO-Offload Schedule åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆé€šè¿‡å‰å‘ä¼ æ’­è®¡ç®—æŸå¤±ã€‚ç”±äº fp16 å‚æ•°å·²ç»å­˜æ”¾åœ¨GPUä¸Šï¼Œå› æ­¤è¿™éƒ¨åˆ†è®¡ç®—ä¸éœ€è¦ä¸ CPU é€šä¿¡ã€‚åœ¨æŸå¤±çš„åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œä¸åŒè®¾å¤‡è®¡ç®—ä¸åŒå‚æ•°çš„æ¢¯åº¦ã€‚ZeRO-Offload å¯ä»¥åœ¨è®¡ç®—å®Œæ¯ä¸ªå‚æ•°åï¼Œå°†è¿™äº›æ¢¯åº¦å•ç‹¬æˆ–åˆ†ç»„ä¼ è¾“åˆ° CPU å†…å­˜ä¸­ã€‚ç”±äºæ¢¯åº¦æ˜¯é€å±‚ä¼ è¾“çš„ï¼Œå› æ­¤ GPU ä¸Šåªéœ€è¦å¾ˆå°çš„ç¼“å†²åŒºæ¥å­˜æ”¾æ¯ä¸€å±‚çš„æ¢¯åº¦ã€‚åœ¨åå‘ä¼ æ’­ä¹‹åï¼ŒZeRO-Offload ç›´æ¥åœ¨ CPU ä¸Šæ›´æ–° fp32 å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼‰ï¼Œå¹¶å°†æ›´æ–°åçš„ fp32 å‚æ•°ä» CPU å†…å­˜å¤åˆ¶åˆ° GPU å†…å­˜ä¸Šçš„ fp16 å‚æ•°ã€‚\nZeRO-Offload Training Process on a Single GPU\nåœ¨å¸è½½ä¹‹å‰è¿›è¡Œå¦‚ä¸Šä¸€èŠ‚æ‰€è¿°çš„åˆ’åˆ†çš„ä¸»è¦å¥½å¤„æ˜¯ï¼Œå¯¹äºå…·æœ‰è¶…è¿‡ 1 ä¸ª GPU çš„ç³»ç»Ÿï¼Œæ¯ä¸ªæ•°æ®å¹¶è¡Œè¿›ç¨‹åªè´Ÿè´£æ›´æ–°å‚æ•°çš„ä¸€ä¸ªå­é›†ã€‚æ‰€æœ‰æ•°æ®å¹¶è¡Œè¿›ç¨‹çš„ GPU åˆ° CPU çš„é€šä¿¡é‡æ€»å’Œä¿æŒä¸å˜ï¼ŒCPU èµ„æºå¯ä»¥å¹¶è¡Œä½¿ç”¨ï¼Œå…±åŒè®¡ç®—å•ä¸ªæƒé‡æ›´æ–°ã€‚ZeRO-Offload åœ¨ä¸åŒ GPU ä¹‹é—´åˆ’åˆ†æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¯ä¸ª GPU å°†å…¶æ‹¥æœ‰çš„éƒ¨åˆ†å¸è½½åˆ° CPU å†…å­˜ä¸­ï¼Œå¹¶åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­å°†å…¶ä¸€ç›´ä¿å­˜åœ¨é‚£é‡Œã€‚åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œåœ¨ GPUä¸Šä½¿ç”¨ reduce-scatter è®¡ç®—æ™®éå¤æ ¸ä¸€éæ¢¯åº¦ï¼Œæ¯ä¸ª GPU åªå°†å±äºå…¶é‚£ä¸€éƒ¨åˆ†çš„å¹³å‡æ¢¯åº¦å¸è½½åˆ° CPU å†…å­˜ä¸­ã€‚ç„¶åä¼˜åŒ–å™¨çŠ¶æ€å°†ç”±æ¯ä¸ªæ•°æ®å¹¶è¡Œè¿›ç¨‹ç›´æ¥åœ¨ CPU ä¸Šå¹¶è¡Œæ›´æ–°ã€‚æ›´æ–°åï¼Œå‚æ•°è¢«ç§»å› GPUï¼Œç„¶ååœ¨ GPU ä¸Šæ‰§è¡Œç±»ä¼¼äº ZeRO-2 çš„ All-Gather æ“ä½œæ¥è·å–æ‰€æœ‰æ›´æ–°åçš„å‚æ•°ã€‚\nZeRO-Offload Data Placement with Multiple GPUs\nOptimized CPU Execution ä½œè€…ä½¿ç”¨é«˜æ€§èƒ½è®¡ç®—æŠ€æœ¯å®ç°äº†ä¸€ä¸ªåŠ é€Ÿç‰ˆçš„ CPU Adam ä¼˜åŒ–å™¨ å¼€å‘äº†ä¸€ä¸ªä¸€æ­¥å»¶è¿Ÿå‚æ•°æ›´æ–°è®¡åˆ’ï¼Œå°† CPU å‚æ•°æ›´æ–°è®¡ç®—ä¸ GPU ä¸Šçš„å‰å‘å’Œåå‘è®¡ç®—é‡å ï¼Œéšè—äº† CPU æ‰§è¡Œæ—¶é—´ã€‚ Implementing the CPU Optimizer ä½œè€…ä½¿ç”¨ä¸‰çº§å¹¶è¡Œæ€§æ¥æé«˜ CPU ä¼˜åŒ–å™¨çš„æ€§èƒ½ã€‚\nSIMD çŸ¢é‡æŒ‡ä»¤ï¼Œå……åˆ†åˆ©ç”¨ CPU æ¶æ„çš„ç¡¬ä»¶å¹¶è¡Œæ€§ã€‚ å¾ªç¯å±•å¼€ï¼Œä¸€ç§æé«˜æŒ‡ä»¤çº§å¹¶è¡Œæ€§çš„æœ‰æ•ˆæŠ€æœ¯ï¼Œèƒ½æ›´å¥½åœ°åˆ©ç”¨å†…å­˜å¸¦å®½ã€‚ OMP å¤šçº¿ç¨‹ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¹¶è¡Œåˆ©ç”¨ CPU ä¸Šçš„å¤šä¸ªå†…æ ¸å’Œçº¿ç¨‹ã€‚ ç®—æ³•çš„è¾“å…¥ä¸º Î²â‚(åŠ¨é‡ç³»æ•°), Î²â‚‚(RMSProp çš„å¹³æ–¹æ¢¯åº¦è¡°å‡ç³»æ•°), Î±(å­¦ä¹ ç‡)ï¼Œä»¥åŠæ¢¯åº¦ï¼ŒåŠ¨é‡ï¼Œæ–¹å·®å’Œ fp32 å‚æ•°ä½œä¸ºè¾“å…¥ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨äº†ä¸€äº›ç‰¹å®šäºå®ç°çš„å‚æ•°ï¼Œå¦‚ simd_width å’Œ unroll_width. Adam ä¼˜åŒ–å™¨åˆ†åˆ«å‘é€æ›´æ–°çš„æ–¹å·®ã€åŠ¨é‡å’Œå‚æ•°çš„ fp16 å’Œ fp32 æ ¼å¼åˆ° GPU å’Œ CPU. é¦–å…ˆå°†æ•°æ®è¯»å…¥çŸ¢é‡å¯„å­˜å™¨ã€‚ç„¶åï¼Œä¸»å¾ªç¯ä¸­ä½¿ç”¨ Fused Multiplication Add çŸ¢é‡æ“ä½œã€‚å…¶ä»–æ“ä½œï¼Œå¦‚ä¹˜æ³•ã€é™¤æ³•å’Œå¹³æ–¹æ ¹ï¼Œä¹Ÿåœ¨çŸ¢é‡æ¨¡å¼ä¸‹è¿è¡Œã€‚ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œä½¿ç”¨ AVX512 simd æŒ‡ä»¤é›†å’ŒåŸºäºè‡ªåŠ¨è°ƒä¼˜ç»“æœçš„ unroll_width=8. é™¤äº† CPU-Adam ä¼˜åŒ–å™¨ä¹‹å¤–ï¼Œè¿˜ä»¥åˆ†å—çš„æ–¹å¼å®ç°äº† CPU åˆ° GPU çš„ fp16 å‚æ•°å¤åˆ¶ã€‚é€šè¿‡å¹¶è¡ŒåŒ– Adam è®¡ç®—å¹¶å°†å‚æ•°å¤åˆ¶åˆ° GPU æ¥é‡å  CPU å’Œ GPU çš„æ‰§è¡Œã€‚å½“åœ¨ CPU ä¸Šå¤„ç†å½“å‰æ•°æ®å—çš„ Adam è®¡ç®—æ—¶ï¼Œå°†å…ˆå‰å¤„ç†è¿‡çš„æ•°æ®å—çš„å‚æ•°å†™å› GPU.\nCPU-ADAM Optimizer\nOne-Step Delayed Parameter Update ä¸‹å›¾å±•ç¤ºäº† Delayed Parameter Update(DPU) çš„ ZeRO-Offload è®­ç»ƒçš„å·¥ä½œæµç¨‹ã€‚\nå‰ Nâˆ’1 æ­¥ä¸ä½¿ç”¨ DPU è¿›è¡Œè®­ç»ƒï¼Œé¿å…åœ¨æ¢¯åº¦å˜åŒ–è¿…é€Ÿçš„æ—©æœŸé˜¶æ®µç ´åè®­ç»ƒçš„ç¨³å®šæ€§ã€‚ åœ¨ç¬¬ N æ­¥ä¸­ï¼Œä» GPU è·å–æ¢¯åº¦ï¼Œä½†è·³è¿‡ CPU ä¼˜åŒ–æ­¥éª¤ï¼Œä¹Ÿä¸æ›´æ–° GPU ä¸Šçš„ fp16 å‚æ•°ã€‚ åœ¨ç¬¬ N+1 æ­¥ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¬¬ N æ­¥çš„æ¢¯åº¦è®¡ç®— CPU ä¸Šçš„å‚æ•°æ›´æ–°ï¼ŒåŒæ—¶ä½¿ç”¨ç¬¬ N-1 æ­¥æ›´æ–°çš„å‚æ•°å¹¶è¡Œè®¡ç®— GPU ä¸Šçš„å‰å‘å’Œåå‘ã€‚ Delayed Parameter Update During the Training Process\nZeRO-Infinity ZeRO-Infinity æ˜¯ä¸€ç§æ–°çš„å¼‚æ„ç³»ç»ŸæŠ€æœ¯ï¼Œå®ƒåˆ©ç”¨ GPU, CPU å’Œ NVMe å†…å­˜ï¼Œåœ¨æœ‰é™çš„èµ„æºä¸Šå®ç°å‰æ‰€æœªæœ‰çš„æ¨¡å‹æ‰©å±•ï¼Œå¹¶ä¸”ä¸éœ€è¦æ¨¡å‹ä»£ç é‡æ„ã€‚\nç›®å‰å¤§å‹æ¨¡å‹è®­ç»ƒæŠ€æœ¯ä¸­æœ€å…ˆè¿›çš„æ˜¯ä¸‰ç»´å¹¶è¡Œ (3D parallelism)ï¼Œå®ƒå°†æ¨¡å‹ï¼ˆå¼ é‡åˆ‡ç‰‡ï¼‰å’Œæµæ°´çº¿å¹¶è¡Œä¸æ•°æ®å¹¶è¡Œç›¸ç»“åˆã€‚ä½†æ˜¯ GPU å†…å­˜è·Ÿä¸ä¸Šæ¨¡å‹å¤§å°çš„å¢é•¿ã€‚\nZeRO-Infinity çš„ä¼˜åŠ¿å¦‚ä¸‹\né€šè¿‡åŒæ—¶åˆ©ç”¨ CPU å’Œ NVMe å†…å­˜ï¼Œåœ¨æœ‰é™çš„ GPU èµ„æºä¸Šæ”¯æŒå¤§æ¨¡å‹è®­ç»ƒã€‚ å¼•å…¥äº†ä¸€ç§ç§°ä¸º memory-centric tiling çš„ GPU å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œä»¥åº”å¯¹ GPU å†…å­˜æ— æ³•ä¸€æ¬¡æ”¾ä¸‹çš„è¶…å¤§ block æƒ…å†µã€‚ å¼•å…¥äº†ä¸€ç§ç§°ä½œ bandwidth-centric partitioning çš„æ•°æ®åˆ†åŒºç­–ç•¥ï¼Œç”¨äºåˆ©ç”¨æ‰€æœ‰è®¾å¤‡ä¸Šçš„å†…å­˜å¸¦å®½ï¼Œå¹¶å°†å…¶ä¸é‡å é€šä¿¡ä¸è®¡ç®—çš„æŠ€æœ¯ç»“åˆã€‚ MEMORY REQUIREMENTS Memory for Model States: åŸºäº Transformer çš„æ¨¡å‹ä¸­çš„å‚æ•°æ€»æ•°ä¸»è¦å–å†³äºéšè—ç»´åº¦ (hd) å’Œ Transformer å±‚æ•° (nl). Transformer block ä¸­çš„å‡ ä¹æ‰€æœ‰å‚æ•°éƒ½æ¥è‡ªå››ä¸ªçº¿æ€§å±‚ï¼Œå¤§å°åˆ†åˆ«ä¸ºï¼šQKV_Linear(nd,3nd), O_Linear(hd, hd),MLP(hd, 4hd)+(4hd, hd). å› æ­¤ä¸€ä¸ª Transformer block çš„å‚æ•°é‡çº¦ä¸º 12 x nl x (hd)Â²ï¼Œå› æ­¤å ç”¨çš„å†…å­˜å¤§å°ä¸º 192 x nl x (hd)Â² å­—èŠ‚ã€‚\nMemory for Residual States: å‰©ä½™çŠ¶æ€ä¸»è¦ç”±æ¿€æ´»å†…å­˜ç»„æˆï¼Œå®ƒå–å†³äºæ¨¡å‹æ¶æ„ã€æ‰¹å¤„ç†å¤§å° (bsz) å’Œåºåˆ—é•¿åº¦ (seq). å­˜å‚¨æ¿€æ´»æ£€æŸ¥ç‚¹æ‰€éœ€çš„å†…å­˜ä¼°è®¡ä¸º 2Ã—bszÃ—seqÃ—hdÃ—nl/ciï¼Œå…¶ä¸­ ci(checkpoint interval) æ˜¯ä¸¤ä¸ªæ¿€æ´»æ£€æŸ¥ç‚¹ä¹‹é—´çš„ Transformer block çš„æ•°é‡ã€‚\nModel State Working Memory (MSWM) æ˜¯åœ¨æ‰€æœ‰æ¨¡å‹çŠ¶æ€è¢«å¸è½½åˆ° CPU æˆ– NVMe ä¹‹åï¼Œåœ¨æ¨¡å‹ä¸­æœ€å¤§çš„å•ä¸ªç®—å­ä¸Šæ‰§è¡Œå‰å‘æˆ–åå‘ä¼ æ’­æ‰€éœ€çš„æœ€å° GPU å†…å­˜ã€‚å¯¹äºåŸºäº Transformer çš„æ¨¡å‹ï¼Œæœ€å¤§çš„ç®—å­æ˜¯å°†éšè—ç»´åº¦ä» hd è½¬æ¢ä¸º 4hd çš„çº¿æ€§å±‚ï¼Œå› æ­¤ fp32 æ ¼å¼ä¸‹éœ€è¦ 4xhdx4hd å­—èŠ‚çš„å†…å­˜ã€‚\nActivation Working Memory (AWM): æ˜¯åœ¨æ‰§è¡Œå®é™…çš„åå‘ä¼ æ’­ä¹‹å‰é‡æ–°è®¡ç®—æ¿€æ´»æ‰€éœ€çš„å†…å­˜ï¼Œå³ä¸¤ä¸ªè¿ç»­æ¿€æ´»æ£€æŸ¥ç‚¹ä¹‹é—´çš„æ¿€æ´»å¤§å° bsz Ã— seq Ã— ci Ã— (16 Ã— hd + 2 Ã— attn_heads Ã— seq) å­—èŠ‚ã€‚\nBANDWIDTH REQUIREMENTS å‡è®¾æ²¡æœ‰ä»»ä½•è®¡ç®—å’Œé€šä¿¡é‡å çš„å·¥ä½œè´Ÿè½½æ‰§è¡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å³°å€¼è®¡ç®—ååé‡ (peaktp)ï¼Œæ•°æ®ç§»åŠ¨å¸¦å®½ (bw) åŠå…¶ç®—æœ¯å¼ºåº¦ (ait) æ¥ä¼°è®¡è®­ç»ƒæ•ˆç‡ã€‚éœ€è¦æ³¨æ„ peaktp ä¸æ˜¯ç†è®ºä¸Šçš„ç¡¬ä»¶å³°å€¼ï¼Œè€Œæ˜¯åœ¨æ²¡æœ‰ä»»ä½•é€šä¿¡ç“¶é¢ˆçš„æƒ…å†µä¸‹å¯ä»¥è¾¾åˆ°çš„å³°å€¼ã€‚\nç®—æœ¯å¼ºåº¦ (AIT) æ˜¯æ€»è®¡ç®—é‡ä¸è®¡ç®—æ‰€éœ€æ•°æ®é‡ä¹‹æ¯”ã€‚å®ƒæè¿°äº†æ¯æ¬¡æ•°æ®ç§»åŠ¨çš„è®¡ç®—é‡ã€‚\ncompute_time = total_computation / peaktp ait = total_computation / total_data_movement communication_time = total_data_movement / bw = total_computation / (ait Ã— bw) efficiency = compute_time / (compute_time + communication_time) = ait x bw / (ait x bw + peaktp) Quantifying AIT in DL training Transformer block ä¸­ä¸€æ¬¡å‰å‘ä¼ æ’­ä¸­çš„è®¡ç®—é‡å¯ä»¥è¿‘ä¼¼ä¸ºè¾“å…¥ä¹˜ä»¥å‚æ•°å¤§å° 2 Ã— bsz Ã— seq Ã— params. åå‘ä¼ æ’­åˆ™ä¸ºå…¶ 2 å€ã€‚å¦‚æœä½¿ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹åˆ™è¿˜éœ€è¦ä¸€æ¬¡é¢å¤–çš„å‰å‘ä¼ æ’­ï¼Œå› æ­¤æ¯æ¬¡è¿­ä»£çš„æ€»è®¡ç®—é‡ä¸º computation_per_iter = 2 Ã— 4 Ã— bsz Ã— seq Ã— parameters = 2 Ã— 4 Ã— 12 Ã— bsz Ã— seq Ã— nl Ã— (hd)Â²\nAIT w.r.t. Parameters and Gradients: å‰å‘å’Œåå‘è¿‡ç¨‹ä¸­æ¨¡å‹å‚æ•°å¿…é¡»ä»å­˜å‚¨ä½ç½®ä½ç½®åŠ è½½åˆ° GPU å¯„å­˜å™¨å„æ¬¡ã€‚åœ¨ä½¿ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹çš„æƒ…å†µä¸‹ï¼Œè¿˜éœ€è¦åŠ è½½ä¸€æ¬¡ï¼Œä»¥ä¾¿åœ¨åå‘ä¼ æ’­æœŸé—´é‡æ–°è®¡ç®—ã€‚æ­¤å¤–ï¼Œæ¢¯åº¦å¿…é¡»ä» GPU å¯„å­˜å™¨å­˜å‚¨åˆ°å…¶æœ€ç»ˆä½ç½®è‡³å°‘ä¸€æ¬¡ã€‚å› æ­¤æ€»å…±è¦ç§»åŠ¨æ¨¡å‹å‚æ•° 4 æ¬¡ï¼Œæ€»è®¡ 2 x 4 x parameters å­—èŠ‚ã€‚å› æ­¤å…³äºå‚æ•°å’Œæ¢¯åº¦çš„è®¡ç®—å¼ºåº¦ä¸º seq x bsz.\nAIT w.r.t. Optimizer States: ä¼˜åŒ–å™¨çŠ¶æ€å¿…é¡»è‡³å°‘è¯»å–å’Œå†™å…¥ä¸€æ¬¡ã€‚æ‰€ä»¥æ€»çš„æ•°æ®ç§»åŠ¨æ˜¯ 2 Ã— optimizer_statesï¼Œæ€»è®¡ 2 Ã— 16 Ã— parameters å­—èŠ‚ã€‚å› æ­¤å…³äºä¼˜åŒ–å™¨çŠ¶æ€çš„è®¡ç®—å¼ºåº¦ä¸º seq x bsz / 4.\nAIT w.r.t. Activation Checkpoints: å‰å‘ä¼ æ’­æ—¶å¿…é¡»å°†æ¿€æ´»æ£€æŸ¥ç‚¹ä¿å­˜åˆ°å®ƒä»¬çš„æœ€ç»ˆä½ç½®ï¼Œç„¶ååœ¨åå‘ä¼ æ’­æœŸé—´åŠ è½½æ¿€æ´»æ£€æŸ¥ç‚¹ã€‚å› æ­¤æ€»æ•°æ®ç§»åŠ¨é‡ä¸º 4 Ã— nl/ci Ã— hd Ã— seq Ã— bsz å­—èŠ‚ã€‚å› æ­¤å…³äºæ¿€æ´»æ£€æŸ¥ç‚¹çš„è®¡ç®—å¼ºåº¦ä¸º 24 Ã— hd Ã— ci.\nBandwidth Requirements é€šè¿‡å‰é¢çš„åˆ†æå¯çŸ¥æ¨¡å‹çŠ¶æ€çš„è®¡ç®—å¼ºåº¦ä»…å–å†³äºæ‰¹å¤§å°å’Œåºåˆ—é•¿åº¦ï¼Œæ¿€æ´»æ£€æŸ¥ç‚¹çš„è®¡ç®—å¼ºåº¦ä»…å–å†³äºå­˜å‚¨é—´éš”å’Œæ¨¡å‹çš„éšè—ç»´åº¦å¤§å°ã€‚ä¸‹å›¾ a è¯´æ˜å½“ä¼ è¾“å‚æ•°å’Œæ¢¯åº¦çš„å¸¦å®½è¶…è¿‡ 70 GB/s æ—¶ï¼Œå³ä½¿æ˜¯æœ€å°çš„æ‰¹å¤„ç†å¤§å°ï¼Œä¹Ÿå¯ä»¥å®ç°è¶…è¿‡ 50% çš„æ•ˆç‡ã€‚å›¾ b è¯´æ˜ï¼Œä¼ è¾“ä¼˜åŒ–å™¨çŠ¶æ€éœ€è¦è¿‘ 4 å€çš„å¸¦å®½æ‰èƒ½è¾¾åˆ° 50% çš„æ•ˆç‡ã€‚å¹¶ä¸”ä¼˜åŒ–å™¨çŠ¶æ€æ›´æ–°éœ€è¦ç­‰å¾…æ‰€æœ‰å‰å‘å’Œåå‘ä¼ æ’­ç»“æŸï¼Œä¸èƒ½ä¸è®¡ç®—é‡å ã€‚å›¾ c è¯´æ˜ï¼Œå¯ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹åï¼Œå³ä½¿éšè—å¤§å°ä¸º2Kï¼Œ2 GB/s çš„å¸¦å®½ä¹Ÿèƒ½å¤Ÿä¿æŒ 50% ä»¥ä¸Šçš„æ•ˆç‡ã€‚\nImpact of Bandwidth on Efficiency with 70 TFlops of single GPU Peak Throughput\nZERO-INFINITY DESIGN OVERVIEW GPU é›†ç¾¤é‡‡ç”¨å¼‚æ„å†…å­˜å­˜å‚¨ï¼Œé™¤äº† GPU å†…å­˜è¿˜æ‹¥æœ‰ CPU å†…å­˜ä»¥åŠæ¯” GPU å†…å­˜å¤§ 50x, æ¯” CPU å†…å­˜å¤§è¿‘ 20x çš„å¤§è§„æ¨¡ NVMe å­˜å‚¨ã€‚ä¸‹å›¾ä¸º ZeRO-Infinity æ¶æ„ï¼Œæè¿°äº†ç¬¬ä¸€å±‚çš„åå‘ä¼ é€’çš„é€šä¿¡ã€‚å°†åˆ’åˆ†åçš„å‚æ•°ä»æ…¢é€Ÿå†…å­˜ç§»åŠ¨åˆ° GPUï¼Œç„¶å All-Gather ä»¥å½¢æˆå®Œæ•´çš„å±‚ã€‚åœ¨è®¡ç®—æ¢¯åº¦ä¹‹åï¼Œå‚æ•°è¢«èšåˆå’Œé‡æ–°åˆ’åˆ†ï¼Œç„¶åå¸è½½åˆ°æ…¢é€Ÿå†…å­˜ä¸­ã€‚å±‚ç”¨ä¸‹æ ‡è¡¨ç¤ºï¼ŒDP rank ç”¨ä¸Šæ ‡è¡¨ç¤ºã€‚\nA Snapshot of ZeRO-Infinity Training a Model with 2 Layers on 4 DP Ranks\nEfficiency w.r.t Parameter and Gradients: ç°æœ‰çš„å¼‚æ„è§£å†³æ–¹æ¡ˆ (ä¾‹å¦‚ ZeRO-Offload) è¦æ±‚å…ˆå°†å‚æ•°ä» CPU ç§»åŠ¨åˆ°æ‹¥æœ‰è¿™äº›å‚æ•°çš„ GPUï¼Œç„¶åå†è¿›è¡Œå¹¿æ’­ã€‚è¿™ç§æ–¹å¼éœ€è¦åœ¨æ¯ä¸ª GPU ä¸Šä½¿ç”¨è¶³å¤Ÿå¤§çš„ batchsizeï¼Œä»¥ç¡®ä¿é€šä¿¡èƒ½è¢«è®¡ç®—æ©ç›–ã€‚ä½†è¿™å¸¦æ¥äº†ä¸¤ä¸ªé—®é¢˜ï¼š\nå¯¹äºè¶…å¤§è§„æ¨¡æ¨¡å‹ï¼Œæ¿€æ´»çš„å†…å­˜å ç”¨ä¼šè¿‡å¤§ï¼Œç”šè‡³è¶…è¿‡ CPU çš„å†…å­˜å®¹é‡ã€‚ å½“æ‰©å±•åˆ°æ•°ç™¾ç”šè‡³ä¸Šåƒä¸ª GPU æ—¶ï¼Œä¸ºäº†å®ç°æœ‰æ•ˆçš„æ”¶æ•›ï¼Œå®é™…çš„ batchsize ä¼šå˜å¾—è¿‡å¤§ã€‚ Efficiency w.r.t Optimizer States: ä¸åœ¨å‰å‘å’Œåå‘ä¼ æ’­æœŸé—´å‚æ•°å’Œæ¢¯åº¦çš„äº§ç”Ÿæœ‰å…ˆåé¡ºåºä¸åŒï¼Œä¼˜åŒ–å™¨çŠ¶æ€å¯ä»¥åŒæ—¶æ›´æ–°ã€‚ZeRO-Infinity å»ºç«‹åœ¨ ZeRO-3 ä¹‹ä¸Šï¼Œå› æ­¤åœ¨å°†ä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ° CPU å†…å­˜æ—¶ï¼Œå®ƒè¿˜å¯ä»¥åˆ©ç”¨æ‰€æœ‰çš„ GPU å’Œ CPU å†…å­˜å¸¦å®½ä»¥åŠæ‰€æœ‰ CPU ç®—åŠ›ç”¨äºä¼˜åŒ–å™¨çŠ¶æ€æ›´æ–°ã€‚ç„¶è€Œï¼Œä½¿ç”¨ NVMe å¸è½½ï¼Œéœ€è¦å°†æ•°æ®ä» NVMe ä¼ å…¥åˆ° CPU å†…å­˜ä¸­ï¼Œå†ä» CPU å†…å­˜è¿”å›ã€‚ç”±äº CPU å†…å­˜æœ‰é™ï¼Œå¿…é¡»å°†æ•°æ®åˆ†å—ä» NVMe åŠ è½½åˆ° CPU å†…å­˜ï¼Œè¿›è¡Œè®¡ç®—åå†å†™å› NVMe.\nEfficiency w.r.t Activations: åœ¨ä¸€å° DGX-2 èŠ‚ç‚¹ä¸Šï¼Œæ¯ä¸ª GPU å¯ä»¥é€šè¿‡ PCIe æ¥å£ä»¥å¤§çº¦ 3 GB/s çš„é€Ÿåº¦å¹¶è¡Œè¯»å†™æ•°æ®åˆ° CPU å†…å­˜ã€‚è¿™ä½¿å¾—åœ¨éšè—å±‚å¤§å°ä¸º 8K æˆ–æ›´å¤§æ—¶ï¼Œå¯ä»¥å°†æ¿€æ´»æ£€æŸ¥ç‚¹å¸è½½åˆ° CPU å†…å­˜çš„åŒæ—¶ä¿æŒè¶…è¿‡ 80% çš„æ•ˆç‡ã€‚\nEFFICIENCY OPTIMIZATIONS Bandwidth-Centric Partitioning åœ¨ ZeRO-3 å’Œ ZeRO-Offload ä¸­æ¯å±‚çš„å‚æ•°ä¸ºå•ä¸ªæ•°æ®å¹¶è¡Œè¿›ç¨‹æ‹¥æœ‰ï¼Œåœ¨éœ€è¦æ—¶å°†å®ƒä»¬å¹¿æ’­ç»™å…¶ä»–è¿›ç¨‹ï¼ŒZeRO-Infinity åœ¨æ‰€æœ‰æ•°æ®å¹¶è¡Œè¿›ç¨‹ä¸­åˆ’åˆ†å•ä¸ªå‚æ•°ï¼Œå¹¶åœ¨éœ€è¦å‚æ•°æ—¶ä½¿ç”¨ All-Gather. ç›¸è¾ƒäºå¹¿æ’­åªç”¨åˆ°äº†å•ä¸ª PCIe é“¾è·¯å°†å‚æ•°ä»å­˜å‚¨ä½ç½®åŠ è½½åˆ° GPUï¼ŒAll-Gather åŒæ—¶ä½¿ç”¨æ‰€æœ‰çš„ PCIe é“¾è·¯ï¼Œæ¯æ¡é“¾è·¯ä¼ è¾“ 1/dp çš„å‚æ•°ã€‚\nOverlap Centric Design è®¿é—® NVMe å†…å­˜éœ€è¦ä¸‰ä¸ªæ­¥éª¤ï¼š(i) ä» NVMe è¯»å–æ•°æ®åˆ°CPUå†…å­˜ (nc-transfer). (ii) å°†æ•°æ®ä» CPU å†…å­˜å¤åˆ¶åˆ° GPU å†…å­˜ (cg-transfer). (iii) æ‰§è¡Œ All-Gather ä»¥åœ¨æ‰€æœ‰ GPU ä¸Šè·å¾—å®Œæ•´å‚æ•° (gg-transfer).\nZeRO-Infinity çš„é€šä¿¡é‡å æœ‰ä¸¤ä¸ªç»„ä»¶\nä¸€ä¸ª dynamic prefetcherï¼Œåœ¨æ¯æ¬¡è¿­ä»£æœŸé—´ï¼Œè·Ÿè¸ªå…¶åœ¨ç®—å­åºåˆ—ä¸­çš„ä½ç½®ï¼Œå¹¶é¢„å–æœªæ¥ç®—å­æ‰€éœ€çš„å‚æ•°ã€‚åœ¨æ‰§è¡Œç¬¬ i ä¸ªæ“ä½œç¬¦ä¹‹å‰ï¼Œprefetcher å¯ä»¥åˆ†åˆ«å¯¹ç¬¬ i+3ï¼Œç¬¬ i+2 å’Œç¬¬ i+1 ä¸ªç®—å­æ‰€éœ€çš„å‚æ•°è°ƒç”¨ nc, cg å’Œ gg-transfer. ä¸€ä¸ªé€šä¿¡å’Œå¸è½½é‡å æœºåˆ¶ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œæ¢¯åº¦æ‰€éœ€çš„æ•°æ®ç§»åŠ¨å’Œåå‘è®¡ç®—ã€‚å°†ç¬¬ i+1 ä¸ªç®—å­ä¸­å‚æ•°æ¢¯åº¦çš„ Reduce-Scatter ä¸ç¬¬ i ä¸ªç®—å­çš„è®¡ç®—é‡å ï¼ŒåŒæ—¶å°†ç¬¬ i+2 ä¸ªç®—å­ Reduce-Scatter åˆ’åˆ†çš„æ¢¯åº¦ä¼ è¾“ç»™ CPU æˆ– NVMe. ","permalink":"http://localhost:1313/blogs/zero/","summary":"Paper reading of ZeRO.","title":"ZeRO, ZeRO-Offload, ZeRO-Infinity"},{"content":"Parse Config Arguments ä¼šä»å‘½ä»¤è¡Œå‚æ•°ä¸­è·å–æœ‰å…³ Model, Runtime, Parallel Processing \u0026amp; Input æœ‰å…³çš„ä¿¡æ¯ã€‚å‰ä¸‰è€…è¢«åŒ…å«åœ¨ engine_config ä¸­ï¼Œè€Œæœ€åè€…åˆ™è¢«åŒ…å«åœ¨ input_config ä¸­ã€‚åœ¨ create_config() å‡½æ•°ä¸­ï¼Œä¼šåˆå§‹åŒ– _WORLD å…¨å±€å˜é‡ï¼Œå®ƒæ˜¯ä¸€ä¸ª GroupCoordinator å®ä¾‹ã€‚å¾ˆæ˜æ˜¾å®ƒåªæœ‰ä¸€ä¸ªåŒ…å«æ‰€æœ‰çš„è®¾å¤‡è¿›ç¨‹ç»„ã€‚ GroupCoordinator GroupCoordinator ç±»æ˜¯ä¸€ä¸ª PyTorch çš„è¿›ç¨‹ç»„å°è£…å™¨ï¼Œä¸»è¦ç”¨äºç®¡ç†ä¸€ç»„è¿›ç¨‹ä¹‹é—´çš„é€šä¿¡ã€‚å®ƒå¯ä»¥æ ¹æ®ä¸åŒçš„é€šä¿¡åç«¯ï¼ˆå¦‚ NCCLã€Glooã€MPI ç­‰ï¼‰æ¥åè°ƒè¿›ç¨‹ä¹‹é—´çš„æ“ä½œã€‚åŒ…å«ä»¥ä¸‹ä¿¡æ¯\nrank: å½“å‰è¿›ç¨‹çš„å…¨å±€ç´¢å¼•ï¼ˆå…¨å±€å”¯ä¸€ï¼‰ã€‚ ranks: ç»„å†…æ‰€æœ‰è¿›ç¨‹çš„å…¨å±€ç´¢å¼•åˆ—è¡¨ã€‚ world_size: ç»„çš„å¤§å°ï¼Œå³è¿›ç¨‹çš„æ•°é‡ len(ranks) local_rank: å½“å‰è¿›ç¨‹åœ¨æœ¬åœ°èŠ‚ç‚¹ä¸­çš„ç´¢å¼•ã€‚ rank_in_group: å½“å‰è¿›ç¨‹åœ¨ç»„å†…çš„ç´¢å¼•ã€‚ cpu_group: ç”¨äº CPU é€šä¿¡çš„è¿›ç¨‹ç»„ã€‚ device_group: ç”¨äºè®¾å¤‡ï¼ˆå¦‚ GPUï¼‰é€šä¿¡çš„è¿›ç¨‹ç»„ã€‚ 1 2 3 4 5 6 if we have a group of size 4 across two nodes: Process | Node | Rank | Local Rank | Rank in Group 0 | 0 | 0 | 0 | 0 1 | 0 | 1 | 1 | 1 2 | 1 | 2 | 0 | 2 3 | 1 | 3 | 1 | 3 __init__ æ–¹æ³•æ¥æ”¶ä»¥ä¸‹å‚æ•°ï¼š\ngroup_ranks: ä¸€ä¸ªåŒ…å«å¤šä¸ªè¿›ç¨‹ç´¢å¼•åˆ—è¡¨çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­åˆ—è¡¨è¡¨ç¤ºä¸€ä¸ªè¿›ç¨‹ç»„ã€‚ local_rank: å½“å‰è¿›ç¨‹çš„æœ¬åœ°ç´¢å¼•ã€‚ torch_distributed_backend: æŒ‡å®šç”¨äºé€šä¿¡çš„åç«¯ç±»å‹ (å¦‚ \u0026ldquo;gloo\u0026rdquo; æˆ– \u0026ldquo;nccl\u0026rdquo;). åˆå§‹åŒ–è¿‡ç¨‹ï¼š\nä½¿ç”¨ torch.distributed.get_rank() è·å–å½“å‰è¿›ç¨‹çš„å…¨å±€ç´¢å¼•ã€‚ éå†ä¼ å…¥çš„ group_ranks åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªå­åˆ—è¡¨åˆ›å»ºä¸€ä¸ªæ–°çš„è®¾å¤‡ç»„å’Œ CPU ç»„ã€‚ å¦‚æœå½“å‰è¿›ç¨‹çš„ç´¢å¼•åœ¨å½“å‰å­åˆ—è¡¨ä¸­ï¼Œåˆ™è®¾ç½®è¯¥è¿›ç¨‹çš„ç»„å†…ä¿¡æ¯ (åŒ…æ‹¬ ranksã€world_size å’Œ rank_in_group). ç¡®ä¿ CPU ç»„å’Œè®¾å¤‡ç»„éƒ½å·²æˆåŠŸåˆ›å»ºã€‚ æ ¹æ®æ˜¯å¦å¯ç”¨ CUDA è®¾ç½®å½“å‰è®¾å¤‡ä¸º GPU æˆ– CPU. 1 2 3 4 5 6 def main(): parser = FlexibleArgumentParser(description=\u0026#34;xFuser Arguments\u0026#34;) args = xFuserArgs.add_cli_args(parser).parse_args() # Add Command Line Interface (CLI) arguments engine_args = xFuserArgs.from_cli_args(args) # Extract CLI args and pass them to xFuserArgs Constructor engine_config, input_config = engine_args.create_config() # Init _WORLD. engine_config: model, run_time \u0026amp; parallel infos, input_config: input shape, prompt \u0026amp; sampler infos local_rank = get_world_group().local_rank å…³äºå¯ä»¥æ”¯æŒçš„å¹¶è¡Œç­–ç•¥å¦‚ä¸‹ï¼ŒåŒ…æ‹¬ Data Parallel, Sequence Parallel, Pipefusion Parallel \u0026amp; Tensor Parallel.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Parallel Processing Options: --use_cfg_parallel Use split batch in classifier_free_guidance. cfg_degree will be 2 if set --data_parallel_degree DATA_PARALLEL_DEGREE Data parallel degree. --ulysses_degree ULYSSES_DEGREE Ulysses sequence parallel degree. Used in attention layer. --ring_degree RING_DEGREE Ring sequence parallel degree. Used in attention layer. --pipefusion_parallel_degree PIPEFUSION_PARALLEL_DEGREE Pipefusion parallel degree. Indicates the number of pipeline stages. --num_pipeline_patch NUM_PIPELINE_PATCH Number of patches the feature map should be segmented in pipefusion parallel. --attn_layer_num_for_pp [ATTN_LAYER_NUM_FOR_PP ...] List representing the number of layers per stage of the pipeline in pipefusion parallel --tensor_parallel_degree TENSOR_PARALLEL_DEGREE Tensor parallel degree. --split_scheme SPLIT_SCHEME Split scheme for tensor parallel. ä» CLI è§£æçš„å‚æ•°åä¼šåœ¨ create_config() ä¸­ç»„æˆå¦‚ä¸‹çš„ ParallelConfig.\nDataParallelConfig: æ€»çš„å¹¶è¡Œåº¦ä¸º dp_degree * cfg_degree. dp_degree: ç›¸å½“äºå¯¹ batch ç»´åº¦è¿›è¡Œåˆ‡åˆ†ï¼Œ cfg_degree: Class-free Guidance(cfg) ç”¨äºæ§åˆ¶æ— æ¡ä»¶çš„å›¾ç‰‡ç”Ÿæˆ (è‹¥ä½¿ç”¨ç›¸å½“äº batchsize *= 2). SequenceParallelConfig: æ€»çš„å¹¶è¡Œåº¦ä¸º sp_degree = ulysses_degree * ring_degree ulysses_degree: ç”¨äºæ§åˆ¶ DeepSeed-Ulesses çš„åºåˆ—å¹¶è¡Œåº¦ã€‚ ring_degree: ç”¨äºæ§åˆ¶è®¡ç®— Ring Attention æ—¶å¯¹ Q K V æ²¿ç€ Sequence ç»´åº¦çš„åˆ‡åˆ†å—æ•°ã€‚ TensorParallelConfig: æ€»çš„å¹¶è¡Œåº¦ä¸º tp_degree. tp_degree: ç”¨äºæ§åˆ¶ 2D Tensor Parallel çš„å¹¶è¡Œåº¦ã€‚ split_scheme: ç”¨äºæ§åˆ¶å¼ é‡åˆ‡åˆ†æ–¹å¼. PipeFusionParallelConfig: æ€»çš„å¹¶è¡Œåº¦ä¸º pp_degree=num_pipeline_patch. pp_degree: ç”¨äºæ§åˆ¶ PipeFusion ä¸­æ¨¡å‹ Transoformer Blocks çš„åˆ‡åˆ†ä¸ªæ•°ã€‚ num_pipeline_patch: ç”¨äºæ§åˆ¶å¯¹ latent feature map çš„åˆ‡åˆ†å—æ•°. attn_layer_num_for_pp: æ˜¯ä¸€ä¸ª listï¼Œè¡¨ç¤º pp_degree é‡Œæ¯ä¸ª stage çš„ Transformer å±‚æ•°ã€‚ Warning\nå…³äº PipeFusionï¼ŒåŸæ–‡è¯´åˆ‡åˆ†çš„ patch æ•°å’Œ pipeline å¤§å°å¯ä»¥ä¸åŒï¼Œä½†è¿™é‡Œè¦æ±‚ len(attn_layer_num_for_pp)=pp_degree\nInfo\nè®¾å¤‡æ•°å¿…é¡»ç­‰äº dp_degree * cfg_degree * sp_degree * tp_degree * num_pipeline_patchï¼Œå¹¶ä¸” pp_degree å¿…é¡»å°äºç­‰äºè®¾å¤‡æ•°ã€‚ ulysses_degree å¿…é¡»è¦å¤§äºä¸”èƒ½è¢« attention çš„å¤´æ•°æ•´é™¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 parallel_config = ParallelConfig( dp_config=DataParallelConfig( dp_degree=self.data_parallel_degree, use_cfg_parallel=self.use_cfg_parallel, ), sp_config=SequenceParallelConfig( ulysses_degree=self.ulysses_degree, ring_degree=self.ring_degree, ), tp_config=TensorParallelConfig( tp_degree=self.tensor_parallel_degree, split_scheme=self.split_scheme, ), pp_config=PipeFusionParallelConfig( pp_degree=self.pipefusion_parallel_degree, num_pipeline_patch=self.num_pipeline_patch, attn_layer_num_for_pp=self.attn_layer_num_for_pp, ), ) Construct Pipeline è§£æå®Œé…ç½®å‚æ•°å¹¶æ„å»ºäº† engine_config åï¼Œä¸‹ä¸€æ­¥æ˜¯æ„å»ºæ¨¡å‹çš„ pipeline.\n1 2 3 4 5 6 pipe = xFuserPixArtAlphaPipeline.from_pretrained( # First construct a PixArtAlphaPipeline, then pass it and engine_config to xFuserPipelineBaseWrapper pretrained_model_name_or_path=engine_config.model_config.model, engine_config=engine_config, torch_dtype=torch.float16, ).to(f\u0026#34;cuda:{local_rank}\u0026#34;) pipe.prepare_run(input_config) xFuserPixArtAlphaPipeline ç»§æ‰¿è‡ª xFuserPipelineBaseWrapperï¼Œ_init_runtime_state å‡½æ•°ç»è¿‡ä¸€ç•ªè°ƒç”¨åä¼šä½¿ç”¨ initialize_model_parallel åˆå§‹åŒ– _RUNTIME æœ‰å…³æ¨¡å‹å‚æ•°çš„éƒ¨åˆ†å’Œæ¨¡å‹å¹¶è¡Œçš„å…¨å±€å˜é‡ _DP, _CFG, _PP, _SP, _TPï¼Œå®ƒæ˜¯ä¸€ä¸ª DiTRuntimeState (ç»§æ‰¿ RuntimeState) å®ä¾‹ï¼Œè®°å½•äº†æ¯ä¸ª Group åŒ…å«çš„è®¾å¤‡ç´¢å¼•ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜åŒ…æ‹¬ PipeFusionParallel ä¸­æœ‰å…³ patch ç´¢å¼•çš„å‚æ•° (åœ¨ç¨å pipeline æ‰§è¡Œçš„æ—¶å€™è®¡ç®—).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class xFuserPipelineBaseWrapper(xFuserBaseWrapper, metaclass=ABCMeta): def __init__( self, pipeline: DiffusionPipeline, engine_config: EngineConfig, ): self.module: DiffusionPipeline self._init_runtime_state(pipeline=pipeline, engine_config=engine_config) # backbone transformer = getattr(pipeline, \u0026#34;transformer\u0026#34;, None) unet = getattr(pipeline, \u0026#34;unet\u0026#34;, None) # vae vae = getattr(pipeline, \u0026#34;vae\u0026#34;, None) # scheduler scheduler = getattr(pipeline, \u0026#34;scheduler\u0026#34;, None) if transformer is not None: pipeline.transformer = self._convert_transformer_backbone(transformer) elif unet is not None: pipeline.unet = self._convert_unet_backbone(unet) if scheduler is not None: pipeline.scheduler = self._convert_scheduler(scheduler) super().__init__(module=pipeline) def _convert_transformer_backbone( self, transformer: nn.Module, ): #... logger.info(\u0026#34;Transformer backbone found, paralleling transformer...\u0026#34;) wrapper = **xFuserTransformerWrappersRegister.get_wrapper(transformer)** transformer = wrapper(transformer=transformer) return transformer initialize_model_parallel è¯¥å‡½æ•°ä¸­ä¼šåˆå§‹åŒ–ä¸€ä¸ª RankGeneratorï¼Œå®ƒæ¥æ”¶æ¯ä¸ªå¹¶è¡Œæ–¹æ³•çš„è®¾å¤‡ç»„å¤§å°å’Œå¹¶è¡Œåº¦å¤§å°é¡ºåºã€‚å…¶ä¸»è¦çš„æ–¹æ³•æ˜¯é€šè¿‡ generate_masked_orthogonal_rank_groups å‡½æ•°ç¡®å®šæ¯ä¸ªå¹¶è¡Œç»„ç”±åŒ…å«å“ªäº›è®¾å¤‡ï¼Œå…ˆæŠŠå¹¶è¡Œæ–¹æ³•æŒ‰ç…§å¹¶è¡Œåº¦ä»å°åˆ°å¤§æ’åˆ—æˆ tp-sp-pp-cfg-dp. å†æ ¹æ®è¦ç”Ÿæˆçš„å¹¶è¡Œç»„äº§ç”Ÿå¯¹åº”çš„ mask. å³å¦‚æœè¦ç”Ÿæˆ pp ç»„å¯¹åº”çš„ rankï¼Œé‚£ä¹ˆ mask = [0, 0, 1, 0, 0]\nè¯¥å‡½æ•°é¦–å…ˆä¼šç”Ÿæˆéœ€è¦ç”Ÿæˆçš„å¹¶è¡Œç»„çš„å¤§å°ç»„æˆçš„ masked_shape å’Œä¸éœ€è¦ç”Ÿæˆçš„ unmasked_shape. é¦–å…ˆè¦ç”¨ prefix_product è®¡ç®— global_strideï¼Œå³æ¯ä¸ªå¹¶è¡Œåº¦çš„è®¾å¤‡ç»„åŒ…å«å‡ ä¸ªè®¾å¤‡ã€‚å†æ ¹æ® mask å–å‡ºå¯¹åº”çš„ mask_stride å’Œ unmaskd_stride. group_size = mask_stride[-1] å³ä¸ºæœ€å¤§å¹¶è¡Œåº¦çš„ç»„åŒ…å«çš„è®¾å¤‡æ•°ã€‚num_of_group = num_of_device / mask_stride[-1] å³ä¸ºè¦ç”Ÿæˆå‡ ä¸ªå¹¶è¡Œåº¦æœ€å¤§çš„ç»„ã€‚å…ˆéå†è¦ç”Ÿæˆçš„æ¯ä¸ªè®¾å¤‡ç»„ï¼Œå¹¶ç”¨ decompose å‡½æ•°ç¡®å®šè¯¥è®¾å¤‡ç»„åœ¨ä¸éœ€è¦å¹¶è¡Œç»´åº¦ä¸Šçš„ç´¢å¼•ï¼›å†éå†è¯¥ç»„ä¸­çš„æ¯ä¸ªè®¾å¤‡çš„ lock rankï¼Œç¡®å®šè¯¥è®¾å¤‡åœ¨éœ€è¦å¹¶è¡Œç»´åº¦ä¸Šçš„ç´¢å¼•ï¼Œæœ€åç”¨ inner_product ç¡®å®šè¯¥è®¾å¤‡çš„ global rank.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def generate_masked_orthogonal_rank_groups( world_size: int, parallel_size: List[int], mask: List[bool] ) -\u0026gt; List[List[int]]: def prefix_product(a: List[int], init=1) -\u0026gt; List[int]: # Exclusive r = [init] for v in a: init = init * v r.append(init) return r def inner_product(a: List[int], b: List[int]) -\u0026gt; int: return sum([x * y for x, y in zip(a, b)]) def decompose(index, shape, stride=None): # index: ç¬¬å‡ ä¸ªå¹¶è¡Œç»„ # shape: å¹¶è¡Œç»„å¤§å°çš„ list \u0026#34;\u0026#34;\u0026#34; This function solve the math problem below: There is an equation: index = sum(idx[i] * stride[i]) And given the value of index, stride. Return the idx. This function will used to get the pp/dp/pp_rank from group_index and rank_in_group. \u0026#34;\u0026#34;\u0026#34; if stride is None: stride = prefix_product(shape) idx = [(index // d) % s for s, d in zip(shape, stride)] # è®¡ç®—åœ¨æ¯ä¸ªå¹¶è¡Œç»´åº¦ä¸Šçš„ç´¢å¼• # stride is a prefix_product result. And the value of stride[-1] # is not used. assert ( sum([x * y for x, y in zip(idx, stride[:-1])]) == index ), \u0026#34;idx {} with shape {} mismatch the return idx {}\u0026#34;.format(index, shape, idx) return idx masked_shape = [s for s, m in zip(parallel_size, mask) if m] # éœ€è¦é‡‡å–å¹¶è¡Œçš„ç»´åº¦ unmasked_shape = [s for s, m in zip(parallel_size, mask) if not m] # ä¸éœ€è¦çš„ global_stride = prefix_product(parallel_size) # exclusive å‰ç¼€ç§¯ è¡¨ç¤ºå¤§çš„å¹¶è¡Œç»´åº¦åŒ…æ‹¬å‡ ä¸ªè®¾å¤‡ masked_stride = [d for d, m in zip(global_stride, mask) if m] unmasked_stride = [d for d, m in zip(global_stride, mask) if not m] group_size = prefix_product(masked_shape)[-1] # æœ€å¤§çš„ä¸€ä¸ªå¹¶è¡Œç»´åº¦åŒ…æ‹¬å‡ ä¸ªè®¾å¤‡ num_of_group = world_size // group_size # åˆ†æˆå‡ ä¸ªå¤§ç»„ ranks = [] for group_index in range(num_of_group): # éå†æ¯ä¸ªè®¾å¤‡ç»„ # get indices from unmaksed for group_index. decomposed_group_idx = decompose(group_index, unmasked_shape) # å¾—åˆ°åœ¨ä¸éœ€è¦é‡‡å–å¹¶è¡Œçš„ç»´åº¦ä¸Šçš„ç´¢å¼• rank = [] for rank_in_group in range(group_size): # éå†è¯¥ç»„ä¸­çš„æ¯ä¸ªè®¾å¤‡ local rank # get indices from masked for rank_in_group. decomposed_rank_idx = decompose(rank_in_group, masked_shape) # å¾—åˆ°æœ€å¤§å¹¶è¡Œç»„çš„æ¯ä¸ªè®¾å¤‡åœ¨é‡‡å–å¹¶è¡Œçš„ç»´åº¦ä¸Šçš„ç´¢å¼• rank.append( // ç›¸åŠ å¾—åˆ°å…¨å±€rank inner_product(decomposed_rank_idx, masked_stride) + inner_product(decomposed_group_idx, unmasked_stride) ) ranks.append(rank) return ranks Hybrid Parallelsim Design xDiTæ”¯æŒå››ç§å¹¶è¡Œæ–¹å¼ï¼šPipeFusionã€Sequenceã€Data å’Œ CFG Parallelã€‚å…¶ä¸­ï¼ŒData å’Œ CFG Parallelåœ¨å›¾åƒé—´å¹¶è¡Œç›¸å¯¹ç®€å•ï¼Œè€Œ PipeFusionå’Œ Sequence åœ¨å›¾åƒå†…éƒ¨çš„ä¸åŒ Patch é—´å¹¶è¡Œåˆ™è¾ƒä¸ºå¤æ‚ã€‚èƒ½\nPipeFusion åˆ©ç”¨ Input Tempor Redundancyç‰¹ç‚¹ï¼Œä½¿ç”¨è¿‡æ—¶çš„ KVï¼ˆStale KVï¼‰è¿›è¡Œ Attention è®¡ç®—ï¼Œè¿™ä½¿å¾— PipeFusion æ— æ³•åƒå¤§å‹è¯­è¨€æ¨¡å‹é‚£æ ·è½»æ¾åœ°å®ç°å¹¶è¡Œç­–ç•¥çš„æ··åˆã€‚ä½¿ç”¨æ ‡å‡†çš„åºåˆ—å¹¶è¡Œæ¥å£ï¼Œå¦‚RingAttentionã€Ulyssesæˆ– USPï¼Œæ— æ³•æ»¡è¶³ SP ä¸PipeFusionæ··åˆå¹¶è¡Œçš„éœ€æ±‚ã€‚\næˆ‘ä»¬å¯¹è¿™ä¸ªé—®é¢˜å…·ä½“è¯´æ˜ï¼Œä¸‹å›¾å±•ç¤ºäº†pipe_degree=4ï¼Œsp_degree=2çš„æ··åˆå¹¶è¡Œæ–¹æ³•ã€‚è®¾ç½® num_pipeline_patch=4ï¼Œå›¾ç‰‡åˆ‡åˆ†ä¸º M=num_pipeline_patch*sp_degree=8 ä¸ª Patchï¼Œåˆ†åˆ«æ˜¯ P0~P7.\nStandard SP Attention çš„è¾“å…¥Qï¼ŒKï¼ŒV å’Œè¾“å‡º O éƒ½æ˜¯æ²¿ç€åºåˆ—ç»´åº¦åˆ‡åˆ†ï¼Œä¸”åˆ‡åˆ†æ–¹å¼ä¸€è‡´ã€‚å¦‚æœä¸åŒ rank çš„è¾“å…¥ patch æ²¡æœ‰é‡å ï¼Œæ¯ä¸ª micro step è®¡ç®—å‡º fresh KV æ›´æ–°çš„ä½ç½®åœ¨ä¸åŒ rank é—´ä¹Ÿæ²¡æœ‰é‡å ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œstandard SP çš„ KV Buffer ä¸­é»„è‰²éƒ¨åˆ†æ˜¯ SP0 rank=0 æ‹¥æœ‰çš„ fresh KVï¼Œç»¿è‰²éƒ¨åˆ†æ˜¯ SP1 rank=1 æ‹¥æœ‰çš„fresh KVï¼ŒäºŒè€…å¹¶ä¸ç›¸åŒã€‚åœ¨è¿™ä¸ª diffusion step å†…ï¼Œdevice=0 æ— æ³•æ‹¿åˆ° P1,3,5,7 çš„ fresh KV è¿›è¡Œè®¡ç®—ï¼Œä½†æ˜¯ PipeFusion åˆ™éœ€è¦åœ¨ä¸‹ä¸€ä¸ª diffusion step ä¸­ï¼Œæ‹¥æœ‰ä¸Šä¸€ä¸ªdiffusion step å…¨éƒ¨çš„ KV. standard SP åªæ‹¥æœ‰ 1/sp_degree çš„ fresh kv bufferï¼Œå› æ­¤æ— æ³•è·å¾—æ··åˆå¹¶è¡Œæ¨ç†æ­£ç¡®çš„ç»“æœã€‚\nxDiTä¸“é—¨å®šåˆ¶äº†åºåˆ—å¹¶è¡Œçš„å®ç°æ–¹å¼ï¼Œä»¥é€‚åº”è¿™ç§æ··åˆå¹¶è¡Œçš„éœ€æ±‚ã€‚xDiTä½¿ç”¨ xFuserLongContextAttention æŠŠSPçš„ä¸­é—´ç»“æœå­˜åœ¨ KV Buffer å†…ã€‚æ•ˆæœå¦‚ä¸‹å›¾ï¼Œæ¯ä¸ª micro-step SP æ‰§è¡Œå®Œæ¯•åï¼ŒSP Group å†…ä¸åŒ rank è®¾å¤‡çš„ fresh KVæ˜¯ replicate çš„ã€‚è¿™æ ·ä¸€ä¸ª diffusion step åï¼ŒSP Group æ‰€æœ‰è®¾å¤‡çš„ KV Buffer éƒ½æ›´æ–°æˆæœ€æ–°ï¼Œä¾›ä¸‹ä¸€ä¸ª Diffusion Step ä½¿ç”¨ã€‚\nNote\nå‡è®¾ä¸€å…±æœ‰ 16 ä¸ª GPUï¼Œç´¢å¼•è¡¨ç¤ºä¸º g0 \u0026hellip; g15ï¼Œå¹¶è¡Œæ–¹æ³•å’Œå¹¶è¡Œåº¦è®¾ç½®å¦‚ä¸‹\ndp_degree (2) * cfg_degree (2) * pp_degree (2) * sp_degree (2) = 16.\né‚£ä¹ˆä¸€å…±ä¼šåˆ›å»º 2 data parallel-groups, 8 CFG groups, 8 pipeline-parallel groups \u0026amp; 8 sequence-parallel groups:\n2 data-parallel groups: [g0, g1, g2, g3, g4, g5, g6, g7], [g8, g9, g10, g11, g12, g13, g14, g15] 8 CFG-parallel groups: [g0, g4], [g1, g5], [g2, g6], [g3, g7], [g8, g12], [g9, g13], [g10, g14], [g11, g15] 8 pipeline-parallel groups: [g0, g2], [g4, g6], [g8, g10], [g12, g14], [g1, g3], [g5, g7], [g9, g11], [g13, g15] 8 sequence-parallel groups: [g0, g1], [g2, g3], [g4, g5], [g6, g7], [g8, g9], [g10, g11], [g12, g13], [g14, g15] Convert Model _split_transformer_blocks ä¼šå¯¹ transformer block è¿›è¡Œåˆ†é…ï¼Œå¦‚æœ parallel_config æŒ‡å®šäº† attn_layer_num_for_ppï¼Œå³å­˜æœ‰æ¯ä¸ª pipeFusion çš„è®¾å¤‡è¢«åˆ†é…çš„ transformer block æ•°é‡çš„åˆ—è¡¨ï¼ŒæŒ‰å…¶è¿›è¡Œåˆ†é…ï¼›å¦åˆ™å¹³å‡åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def _split_transformer_blocks(self, transformer: nn.Module,): # omit # transformer layer split attn_layer_num_for_pp = ( # è·å–æ¯ä¸ª pipeFusion çš„è®¾å¤‡è¢«åˆ†é…çš„ transformer block æ•°é‡ get_runtime_state().parallel_config.pp_config.attn_layer_num_for_pp ) pp_rank = get_pipeline_parallel_rank() pp_world_size = get_pipeline_parallel_world_size() if attn_layer_num_for_pp is not None: if is_pipeline_first_stage(): transformer.transformer_blocks = transformer.transformer_blocks[ : attn_layer_num_for_pp[0]] else: transformer.transformer_blocks = transformer.transformer_blocks[sum(attn_layer_num_for_pp[: pp_rank - 1]) : sum(attn_layer_num_for_pp[:pp_rank])] else: # æ²¡æœ‰æŒ‡å®šåˆ™å¹³å‡åˆ† num_blocks_per_stage = (len(transformer.transformer_blocks) + pp_world_size - 1) // pp_world_size start_idx = pp_rank * num_blocks_per_stage end_idx = min((pp_rank + 1) * num_blocks_per_stage, len(transformer.transformer_blocks),) transformer.transformer_blocks = transformer.transformer_blocks[start_idx:end_idx] # position embedding if not is_pipeline_first_stage(): transformer.pos_embed = None if not is_pipeline_last_stage(): transformer.norm_out = None transformer.proj_out = None return transformer åŒæ—¶ä¹Ÿä¼š convert åŸå…ˆçš„ transformer backbone ä¸º xFuserPixArtTransformer2DWrapperï¼Œå…·ä½“è¡¨ç°ä¸ºåªæœ‰ pipeline çš„ç¬¬ä¸€é˜¶æ®µè¿›è¡Œ position embeddingï¼Œæœ€åä¸€é˜¶æ®µè¿›è¡Œ unpatchify å˜ä¸ºåŸæ¥çš„å›¾åƒå½¢çŠ¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @xFuserTransformerWrappersRegister.register(PixArtTransformer2DModel) class xFuserPixArtTransformer2DWrapper(xFuserTransformerBaseWrapper): def __init__( self, transformer: PixArtTransformer2DModel, ): super().__init__( transformer=transformer, submodule_classes_to_wrap=[nn.Conv2d, PatchEmbed], submodule_name_to_wrap=[\u0026#34;attn1\u0026#34;], ) @xFuserBaseWrapper.forward_check_condition def forward( self, hidden_states: torch.Tensor, encoder_hidden_states: Optional[torch.Tensor] = None, timestep: Optional[torch.LongTensor] = None, added_cond_kwargs: Dict[str, torch.Tensor] = None, cross_attention_kwargs: Dict[str, Any] = None, attention_mask: Optional[torch.Tensor] = None, encoder_attention_mask: Optional[torch.Tensor] = None, return_dict: bool = True, ): \u0026#39;\u0026#39;\u0026#39; ...... \u0026#39;\u0026#39;\u0026#39; height, width = self._get_patch_height_width() # * only pp rank 0 needs pos_embed (patchify) if is_pipeline_first_stage(): hidden_states = self.pos_embed(hidden_states) \u0026#39;\u0026#39;\u0026#39; ...... \u0026#39;\u0026#39;\u0026#39; if is_pipeline_last_stage(): \u0026#39;\u0026#39;\u0026#39; ...... \u0026#39;\u0026#39;\u0026#39; else: output = hidden_states if not return_dict: return (output,) return Transformer2DModelOutput(sample=output) Pipeline Execution åœ¨è¿›è¡Œ warm up åä¾¿ä¼šè¿›è¡Œæ¨¡å‹æ¨ç†å’Œé‡‡æ ·å™¨çš„å»å™ªè¿‡ç¨‹ã€‚æ¨¡å‹æ¨ç†é€šè¿‡è°ƒç”¨ pipeline çš„ __call__ æ–¹æ³•å®ç°ã€‚åœ¨åŸå…ˆ diffusers åŒ…ä¸­çš„ PixaeArtAlphaPipeline åŸºç¡€ä¸Šåšäº†ä¸€äº›ä¿®æ”¹ã€‚æˆ‘ä»¬ç›´æ¥çœ‹ä¿®æ”¹çš„éƒ¨åˆ†ã€‚\nget_runtime_state() è¿”å› _RUNTIME ï¼Œå†è°ƒç”¨ set_input_parameters æ–¹æ³•ï¼Œè®¾ç½®è¾“å…¥å‚æ•°å’Œè®¡ç®— PipeFusionParallel ä¸­æœ‰å…³ patch ç´¢å¼•çš„å‚æ•°ã€‚\n1 2 3 4 5 6 get_runtime_state().set_input_parameters( height=height, width=width, batch_size=batch_size, num_inference_steps=num_inference_steps, ) è¯¥å‡½æ•°ä¼šè®¡ç®—\npipeline parallel ä¸­æ¯ä¸ª patch çš„é«˜åº¦ï¼Œå¿…é¡»æ˜¯ patch_size * num_sp_patches çš„æ•´æ•°å€ã€‚ å°†æ¯ä¸ªæµæ°´çº¿é˜¶æ®µçš„ patch é«˜åº¦å‡åŒ€åœ°åˆ†é…ç»™ num_sp_patches ä¸ªåºåˆ—å¹¶è¡Œè®¾å¤‡ï¼Œè®¡ç®—æ¯ä¸ªè®¾å¤‡çš„ patch é«˜åº¦å’Œèµ·å§‹ç´¢å¼•ã€‚ ç„¶åä¼šå¯¹ prompt åµŒå…¥åçš„æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬åœ¨ cfg parallel ç»„ä¸­çš„è®¾å¤‡è¿›è¡Œåˆ†å‰², rank 0 è´Ÿæ ·æœ¬ï¼Œrank 1 æ­£æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 if do_classifier_free_guidance: (prompt_embeds, prompt_attention_mask,) = self._process_cfg_split_batch(negative_prompt_embeds, prompt_embeds, negative_prompt_attention_mask, prompt_attention_mask,) def _process_cfg_split_batch(self, concat_group_0_negative: torch.Tensor, concat_group_0: torch.Tensor, concat_group_1_negative: torch.Tensor, concat_group_1: torch.Tensor,): if get_classifier_free_guidance_world_size() == 1: concat_group_0 = torch.cat([concat_group_0_negative, concat_group_0], dim=0) concat_group_1 = torch.cat([concat_group_1_negative, concat_group_1], dim=0) elif get_classifier_free_guidance_rank() == 0: concat_group_0 = concat_group_0_negative concat_group_1 = concat_group_1_negative elif get_classifier_free_guidance_rank() == 1: concat_group_0 = concat_group_0 concat_group_1 = concat_group_1 else: raise ValueError(\u0026#34;Invalid classifier free guidance rank\u0026#34;) return concat_group_0, concat_group_1 Async Pipeline Initialize Pipeline é¦–å…ˆä¼šåˆå§‹åŒ– pipelineï¼Œrank 0 ä¼šæ¥æ”¶ warmup é˜¶æ®µçš„ latents ç„¶åæ²¿ç€ H ç»´åº¦è¿›è¡Œåˆ†å—ï¼Œrank -1 ä¹Ÿä¼šæ²¿ç€ H ç»´åº¦è¿›è¡Œåˆ†å—ã€‚ç„¶åä¸ºæ¯ä¸ª patch åˆ›å»ºæ¥æ”¶çš„ä»»åŠ¡ï¼Œæ³¨æ„ rank 0 ç¬¬ä¸€æ¬¡æ˜¯ä» warmup é˜¶æ®µæ¥æ”¶ latentsï¼Œæ‰€ä»¥ä»–çš„éœ€è¦æ¥æ”¶çš„ timestep å°‘ä¸€ä¸ªã€‚ patch_latents è¡¨ç¤ºå½“å‰è®¾å¤‡æ­£åœ¨å¤„ç†çš„ patch æ•°æ®ï¼Œå®ƒä¼šåœ¨æµæ°´çº¿çš„æ¯ä¸€é˜¶æ®µè¿›è¡Œå¤„ç†å’Œä¼ é€’ã€‚last_patch_latents åªåœ¨æµæ°´çº¿çš„æœ€åé˜¶æ®µè®¾å¤‡ä¸­ä½¿ç”¨ï¼Œç”¨æ¥å­˜å‚¨æ¯ä¸ª patch çš„æœ€ç»ˆè®¡ç®—ç»“æœã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 if len(timesteps) == 0: return latents num_pipeline_patch = get_runtime_state().num_pipeline_patch num_pipeline_warmup_steps = get_runtime_state().runtime_config.warmup_steps patch_latents = self._init_async_pipeline( num_timesteps=len(timesteps), latents=latents, num_pipeline_warmup_steps=num_pipeline_warmup_steps, ) last_patch_latents = ( # æ¯ä¸ª pipeline group æœ€åçš„è®¾å¤‡æ¥æ”¶æ‰€æœ‰çš„ patch [None for _ in range(num_pipeline_patch)] if (is_pipeline_last_stage()) else None ) def _init_async_pipeline( self, num_timesteps: int, latents: torch.Tensor, num_pipeline_warmup_steps: int, ): get_runtime_state().set_patched_mode(patch_mode=True) if is_pipeline_first_stage(): # get latents computed in warmup stage # ignore latents after the last timestep latents = (get_pp_group().pipeline_recv() if num_pipeline_warmup_steps \u0026gt; 0 else latents) patch_latents = list(latents.split(get_runtime_state().pp_patches_height, dim=2)) elif is_pipeline_last_stage(): patch_latents = list(latents.split(get_runtime_state().pp_patches_height, dim=2)) else: patch_latents = [None for _ in range(get_runtime_state().num_pipeline_patch)] recv_timesteps = (num_timesteps - 1 if is_pipeline_first_stage() else num_timesteps) # construct receive tasks for each patch for _ in range(recv_timesteps): for patch_idx in range(get_runtime_state().num_pipeline_patch): get_pp_group().add_pipeline_recv_task(patch_idx) return patch_latents Iterate Over Timesteps å¯¹äºæ¯ä¸ª timestepï¼ˆå³æ¯ä¸ªå»å™ªæ­¥éª¤ï¼‰ï¼Œä¼šå¯¹æ¯ä¸ª patch æ‰§è¡Œï¼š\nå¦‚æœå½“å‰è®¾å¤‡æ˜¯æµæ°´çº¿çš„æœ€åä¸€é˜¶æ®µ (is_pipeline_last_stage())ï¼Œå°†å½“å‰ patch çš„æ•°æ®ä¿å­˜åˆ° last_patch_latents ä¸­ã€‚ å¦‚æœä¸æ˜¯ç¬¬ä¸€é˜¶æ®µçš„ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ (i == 0)ï¼Œè°ƒç”¨ recv_next() æ¥å¼‚æ­¥æ¥æ”¶æ¥è‡ªä¸Šä¸€è®¾å¤‡çš„ patch æ•°æ®ï¼ˆéé˜»å¡æ“ä½œï¼Œé€šè¿‡ irecv å®Œæˆï¼‰ã€‚ å¯¹æ¯ä¸ª patch æ‰§è¡Œæ¨¡å‹çš„å‰å‘ä¼ æ’­ _backbone_forwardï¼Œæ ¹æ®å½“å‰æ—¶é—´æ­¥ t è¿›è¡Œæ¨ç†å’Œè®¡ç®—ã€‚ å¦‚æœå½“å‰è®¾å¤‡æ˜¯æœ€åä¸€é˜¶æ®µï¼Œè°ƒç”¨ _scheduler_step æ¥æ ¹æ®å™ªå£°è¿›è¡Œå»å™ªï¼Œå¹¶å°†æ•°æ®å‘é€ç»™ä¸‹ä¸€ä¸ªè®¾å¤‡ pipeline_isendã€‚ å¯¹äºéæœ€åé˜¶æ®µçš„è®¾å¤‡ï¼Œç»§ç»­å°†å½“å‰ patch çš„è®¡ç®—ç»“æœå‘é€åˆ°ä¸‹ä¸€è®¾å¤‡ã€‚ get_pp_group().pipeline_isend ç”¨äºå°†å½“å‰ patch å‘é€åˆ°ä¸‹ä¸€ä¸ªè®¾å¤‡ï¼Œä½¿ç”¨çš„æ˜¯ torch.distributed.isendï¼Œè¿™æ˜¯éé˜»å¡å‘é€ã€‚ get_pp_group().recv_next ä¼šå‡†å¤‡å¥½æ¥æ”¶æ¥è‡ªä¸Šä¸€ä¸ªè®¾å¤‡çš„æ•°æ®ï¼Œrecv_buffer ç”¨æ¥å­˜æ”¾æ¥æ”¶åˆ°çš„æ•°æ®ã€‚irecv å®ç°éé˜»å¡æ¥æ”¶ï¼Œå¯ä»¥åœ¨ç­‰å¾…æ•°æ®çš„åŒæ—¶è¿›è¡Œå…¶ä»–æ“ä½œã€‚\nWarning\nscheduler_step åªå¯¹å•ç‹¬çš„ patch è¿›è¡Œï¼ŒåŸå› æœªçŸ¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 first_async_recv = True for i, t in enumerate(timesteps): for patch_idx in range(num_pipeline_patch): if is_pipeline_last_stage(): last_patch_latents[patch_idx] = patch_latents[patch_idx] if is_pipeline_first_stage() and i == 0: pass else: if first_async_recv: get_pp_group().recv_next() first_async_recv = False patch_latents[patch_idx] = get_pp_group().get_pipeline_recv_data( idx=patch_idx ) patch_latents[patch_idx] = self._backbone_forward( latents=patch_latents[patch_idx], prompt_embeds=prompt_embeds, prompt_attention_mask=prompt_attention_mask, added_cond_kwargs=added_cond_kwargs, t=t, guidance_scale=guidance_scale, ) if is_pipeline_last_stage(): patch_latents[patch_idx] = self._scheduler_step( patch_latents[patch_idx], # pred noise last_patch_latents[patch_idx], # last timestep noise t, extra_step_kwargs, ) if i != len(timesteps) - 1: get_pp_group().pipeline_isend( patch_latents[patch_idx], segment_idx=patch_idx ) else: get_pp_group().pipeline_isend( patch_latents[patch_idx], segment_idx=patch_idx ) if is_pipeline_first_stage() and i == 0: pass else: if i == len(timesteps) - 1 and patch_idx == num_pipeline_patch - 1: pass else: get_pp_group().recv_next() get_runtime_state().next_patch() # switch to next: (self.pipeline_patch_idx + 1) % self.num_pipeline_patch if i == len(timesteps) - 1 or ( (i + num_pipeline_warmup_steps + 1) \u0026gt; num_warmup_steps and (i + num_pipeline_warmup_steps + 1) % self.scheduler.order == 0 ): progress_bar.update() assert callback is None, \u0026#34;callback not supported in async \u0026#34; \u0026#34;pipeline\u0026#34; if ( callback is not None and i + num_pipeline_warmup_steps % callback_steps == 0 ): step_idx = (i + num_pipeline_warmup_steps) // getattr( self.scheduler, \u0026#34;order\u0026#34;, 1 ) callback(step_idx, t, patch_latents[patch_idx]) Construct Final Latents timestep éå†å®Œæˆåï¼Œä»ç„¶æœ‰æœ€åçš„æ“ä½œè¦è¿›è¡Œï¼Œè¿™äº›æ“ä½œçš„ä¸»è¦ç›®çš„æ˜¯å°†æµæ°´çº¿å¹¶è¡Œä¸­å„ä¸ª patch çš„ç»“æœæ‹¼æ¥èµ·æ¥ï¼Œå½¢æˆå®Œæ•´çš„è¾“å‡ºç»“æœã€‚å°¤å…¶æ˜¯å¯¹äºæœ€åä¸€ä¸ªè®¾å¤‡ï¼Œè¿˜éœ€è¦å¤„ç† åºåˆ—å¹¶è¡Œï¼ˆsequence parallelismï¼‰ çš„åˆå¹¶æ“ä½œã€‚é€šè¿‡ all_gather æ“ä½œå°†æ¯ä¸ªè®¾å¤‡ä¸Šå¤„ç†çš„ patch ç»“æœæ”¶é›†èµ·æ¥ï¼Œç„¶åä»æ¯ä¸ªè®¾å¤‡çš„ sp_latents_list ä¸­ï¼Œæå–å‡ºå¯¹åº”äº pp_patch_idx çš„ patch æ•°æ®å¹¶å°†å®ƒä»¬æ‹¼æ¥èµ·æ¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 latents = None if is_pipeline_last_stage(): latents = torch.cat(patch_latents, dim=2) if get_sequence_parallel_world_size() \u0026gt; 1: sp_degree = get_sequence_parallel_world_size() sp_latents_list = get_sp_group().all_gather( latents, separate_tensors=True ) latents_list = [] for pp_patch_idx in range(get_runtime_state().num_pipeline_patch): latents_list += [ sp_latents_list[sp_patch_idx][ ..., get_runtime_state().pp_patches_start_idx_local[pp_patch_idx] : get_runtime_state().pp_patches_start_idx_local[pp_patch_idx + 1], :, ] for sp_patch_idx in range(sp_degree) ] latents = torch.cat(latents_list, dim=-2) return latents Decode Latents ä¸ºäº†é¿å… VAE ä¸­çš„ Decoder åœ¨å¯¹ 8192px åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œ conv2D çš„è¿‡ç¨‹ä¸­å‡ºç° OOM çš„é—®é¢˜ï¼Œ xDiT ä½¿ç”¨äº†åºåˆ—å¹¶è¡Œå’Œ patch å¹¶è¡Œçš„ PatchConv2d å’Œ PatchGroupNorm æ¥æ›¿æ¢æ‰åŸæœ‰ Decoder ä¸­çš„ UpDecoderBlock2D å¯¹åº”çš„å±‚ã€‚\nPatchGroupNorm PatchGroupNorm åœ¨ H ç»´åº¦ä¸Šåˆ’åˆ†ä¸ºå¤šä¸ª patchï¼Œæ¯ä¸ªè®¾å¤‡æ±‚è‡ªå·±æ‰€è´Ÿè´£çš„éƒ¨åˆ†å’Œã€‚ GroupNorm Principles å‡è®¾è¾“å…¥å¼ é‡ x çš„å½¢çŠ¶ä¸º [N, C, H, W]ï¼Œå…¶ä¸­ N è¡¨ç¤ºæ‰¹é‡å¤§å°ï¼ˆBatch Sizeï¼‰ï¼ŒC è¡¨ç¤ºé€šé“æ•°ï¼ˆChannelsï¼‰ï¼ŒH å’Œ W åˆ†åˆ«è¡¨ç¤ºé«˜åº¦å’Œå®½åº¦ã€‚åœ¨ GN ä¸­ï¼Œé€šé“æ•° C è¢«åˆ’åˆ†ä¸º G ç»„ï¼Œæ¯ä¸ªç»„åŒ…å« C/G ä¸ªé€šé“ã€‚è®¡ç®—æ¯ä¸ªç»„å†…å³ [C/G, H, W] ç»´åº¦ä¸Šçš„å‡å€¼å’Œæ–¹å·®ã€‚ç‰¹åˆ«çš„ G=1 æ—¶ï¼ŒGN é€€åŒ–ä¸º BNã€‚G=C æ—¶ï¼ŒGN é€€åŒ–ä¸º LNã€‚ è·å–é«˜åº¦ä¿¡æ¯ 1 2 3 4 5 6 7 class PatchGroupNorm(nn.Module): \u0026#39;\u0026#39;\u0026#39; def __init__(self, ...)\u0026#39;\u0026#39;\u0026#39; def forward(self, x: Tensor) -\u0026gt; Tensor: height = torch.tensor(x.shape[-2], dtype=torch.int64, device=x.device) dist.all_reduce(height) # æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„é«˜åº¦å¹¶æ±‡æ€»ã€‚æœ€ç»ˆæ¯ä¸ªè¿›ç¨‹çš„ height éƒ½å°†è¡¨ç¤ºå…¨å±€çš„é«˜åº¦å’Œã€‚ è®¡ç®—æ¯ä¸ªç»„çš„é€šé“æ•°é‡ä»¥åŠæ¯ä¸ªè¿›ç¨‹å†…çš„å…ƒç´ æ•°é‡ 1 2 3 channels_per_group = x.shape[1] // self.num_groups # æ¯ä¸ªç»„çš„é€šé“æ•°é‡ nelements_rank = channels_per_group * x.shape[-2] * x.shape[-1] # å½“å‰è¿›ç¨‹è´Ÿè´£çš„æ¯ä¸ªç»„ä¸­çš„å…ƒç´ æ€» nelements = channels_per_group * height * x.shape[-1] # æ‰€æœ‰è¿›ç¨‹çš„æ¯ä¸ªç»„ä¸­çš„å…ƒç´ æ€»æ•° è®¡ç®—æ¯ä¸ªç»„çš„å‡å€¼ 1 2 3 4 5 x = x.view(x.shape[0], self.num_groups, -1, x.shape[-2], x.shape[-1]) # [batch_size, num_groups, channels_per_group, height, width] group_sum = x.mean(dim=(2,3,4), dtype=torch.float32) # å¯¹æ¯ä¸ªç»„çš„æ‰€æœ‰å…ƒç´  (channels_per_group, height, width) æ±‚å¹³å‡ group_sum = group_sum * nelements_rank # åŠ æƒåçš„å±€éƒ¨å’Œ = å±€éƒ¨å‡å€¼ * å½“å‰è¿›ç¨‹çš„å…ƒç´ æ•°é‡ dist.all_reduce(group_sum) # æ”¶é›†å¹¶æ±‡æ€»æ‰€æœ‰è¿›ç¨‹çš„å±€éƒ¨å’Œï¼Œå¾—åˆ°å…¨å±€å’Œ E = (group_sum / nelements)[:, :, None, None, None].to(x.dtype) # è®¡ç®—å…¨å±€çš„å‡å€¼ E è®¡ç®—æ¯ä¸ªç»„çš„æ–¹å·® 1 2 3 4 5 6 # å’Œè®¡ç®—å‡å€¼åŒæ ·çš„æ“ä½œ group_var_sum = torch.empty((x.shape[0], self.num_groups), dtype=torch.float32, device=x.device) torch.var(x, dim=(2,3,4), out=group_var_sum) group_var_sum = group_var_sum * nelements_rank dist.all_reduce(group_var_sum) var = (group_var_sum / nelements)[:, :, None, None, None].to(x.dtype) å½’ä¸€åŒ–å¹¶ç¼©æ”¾ $y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$ 1 2 3 x = (x - E) / torch.sqrt(var + self.eps) x = x * self.weight[:, :, None, None, None] + self.bias[:, :, None, None, None] return x PatchConv2d PatchConv2d å°†æ½œåœ¨ç©ºé—´ä¸­çš„ç‰¹å¾æ˜ å°„åˆ†å‰²æˆå¤šä¸ª patchï¼Œè·¨ä¸åŒè®¾å¤‡è¿›è¡Œåºåˆ—å¹¶è¡Œ VAE è§£ç ã€‚è¿™ç§æŠ€æœ¯å°†ä¸­é—´æ¿€æ´»æ‰€éœ€çš„å³°å€¼å†…å­˜å‡å°‘åˆ° 1/Nï¼Œå…¶ä¸­ N æ˜¯æ‰€ä½¿ç”¨çš„è®¾å¤‡æ•°é‡ã€‚å¯¹äº VAE ä¸­çš„å·ç§¯ç®—å­ï¼Œéœ€è¦å¯¹å¦‚ä¸‹å›¾æ‰€ç¤ºçš„ halo åŒºåŸŸæ•°æ®è¿›è¡Œé€šä¿¡ã€‚\nPatch VAE Conv\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class PatchConv2d(nn.Conv2d): def __init__( self, in_channels: int, out_channels: int, kernel_size: _size_2_t, stride: _size_2_t = 1, padding: Union[str, _size_2_t] = 0, dilation: _size_2_t = 1, groups: int = 1, bias: bool = True, padding_mode: str = \u0026#39;zeros\u0026#39;, # TODO: refine this type device=None, dtype=None, block_size: Union[int, Tuple[int, int]] = 0 ) -\u0026gt; None: if isinstance(dilation, int): assert dilation == 1, \u0026#34;dilation is not supported in PatchConv2d\u0026#34; else: for i in dilation: assert i == 1, \u0026#34;dilation is not supported in PatchConv2d\u0026#34; self.block_size = block_size super().__init__( in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype) _conv_forward å‡½æ•°æ˜¯ PatchConv2d ç±»çš„æ ¸å¿ƒï¼Œå®ƒè´Ÿè´£åœ¨è¾“å…¥å¼ é‡ä¸Šæ‰§è¡Œå·ç§¯æ“ä½œï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ†å¸ƒå¼è®¡ç®—åœºæ™¯ä¸‹å¤„ç†è·¨è¿›ç¨‹çš„è¾“å…¥åˆ‡åˆ†ã€halo åŒºåŸŸçš„ä¼ é€’å’Œè®¡ç®—ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨çš„è¾…åŠ©å‡½æ•°çš„ç®€è¦åŠŸèƒ½è¯´æ˜\n_get_world_size_and_rank ï¼šè·å–å½“å‰åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„è¿›ç¨‹æ€»æ•° world_size å’Œå½“å‰è¿›ç¨‹çš„ç¼–å· rank _calc_patch_height_indexï¼šæ ¹æ®æ¯ä¸ªè¿›ç¨‹çš„è¾“å…¥é«˜åº¦ï¼Œè®¡ç®—æ‰€æœ‰è¿›ç¨‹çš„èµ·å§‹å’Œç»“æŸé«˜åº¦ç´¢å¼•ã€‚ _calc_halo_width_in_h_dimï¼šè®¡ç®—å½“å‰è¿›ç¨‹åœ¨ h ç»´åº¦ä¸Šæ‰€éœ€çš„ä¸Šæ–¹å’Œä¸‹æ–¹çš„ halo åŒºåŸŸå®½åº¦ã€‚ _calc_bottom_halo_widthï¼šè®¡ç®—å½“å‰è¿›ç¨‹ä»ä¸‹æ–¹ç›¸é‚»è¿›ç¨‹éœ€è¦æ¥æ”¶çš„ halo åŒºåŸŸçš„å®½åº¦ã€‚ _calc_top_halo_widthï¼šè®¡ç®—å½“å‰è¿›ç¨‹ä»ä¸Šæ–¹ç›¸é‚»è¿›ç¨‹éœ€è¦æ¥æ”¶çš„ halo åŒºåŸŸçš„å®½åº¦ã€‚ _adjust_padding_for_patchï¼šæ ¹æ®å½“å‰è¿›ç¨‹çš„ rank å’Œæ€»è¿›ç¨‹æ•°è°ƒæ•´è¾“å…¥æ•°æ®çš„å¡«å……æ–¹å¼ï¼Œé˜²æ­¢è¾¹ç•Œé‡å¤è®¡ç®—ã€‚ è·å–è¾“å…¥ä¿¡æ¯ä»¥åŠé€šä¿¡ç»„ä¿¡æ¯ 1 2 3 4 5 6 7 8 9 10 11 12 def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]): bs, channels, h, w = input.shape world_size, rank = self._get_world_size_and_rank() if (world_size == 1): # å¤„ç†éåˆ†å¸ƒå¼æƒ…å†µ if self.padding_mode != \u0026#39;zeros\u0026#39;: return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode), weight, bias, self.stride, _pair(0), self.dilation, self.groups) return F.conv2d(input, weight, bias, self.stride, self.padding, self.dilation, self.groups) è·å–è¾“å…¥çš„å…ƒæ•°æ® 1 2 3 4 patch_height_list = [torch.zeros(1, dtype=torch.int64, device=f\u0026#34;cuda:{rank}\u0026#34;) for _ in range(dist.get_world_size())] dist.all_gather(patch_height_list, torch.tensor([h], dtype=torch.int64, device=f\u0026#34;cuda:{rank}\u0026#34;)) # æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„è¾“å…¥é«˜åº¦ patch_height_index = self._calc_patch_height_index(patch_height_list) # è®¡ç®—æ¯ä¸ªè¿›ç¨‹å—çš„èµ·å§‹é«˜åº¦å’Œç»“æŸé«˜åº¦çš„ç´¢å¼• halo_width = self._calc_halo_width_in_h_dim(rank, patch_height_index, self.kernel_size[0], self.padding[0], self.stride[0]) # è®¡ç®—å½“å‰è¿›ç¨‹å—çš„ä¸Šä¸‹ halo åŒºåŸŸçš„å®½åº¦ è®¡ç®—ç›¸é‚»è¿›ç¨‹çš„ halo åŒºåŸŸ (ä¹Ÿå°±æ˜¯è‡ªå·±éœ€è¦æ¥å‘é€çš„éƒ¨åˆ†) é€šè¿‡è®¡ç®—å‰ä¸€ä¸ªè¿›ç¨‹çš„ bottom_halo_width å’Œåä¸€ä¸ªè¿›ç¨‹çš„ top_halo_width å¾—å‡ºè‡ªå·±éœ€è¦å‘é€çš„éƒ¨åˆ†\n1 2 3 4 5 6 7 prev_bottom_halo_width: int = 0 next_top_halo_width: int = 0 if rank != 0: prev_bottom_halo_width = self._calc_bottom_halo_width(rank - 1, patch_height_index, self.kernel_size[0], self.padding[0], self.stride[0]) if rank != world_size - 1: next_top_halo_width = self._calc_top_halo_width(rank + 1, patch_height_index, self.kernel_size[0], self.padding[0], self.stride[0]) next_top_halo_width = max(0, next_top_halo_width) è¿›è¡Œ halo åŒºåŸŸçš„å‘é€ä¸æ¥æ”¶ å¼‚æ­¥å‘é€ï¼ŒåŒæ­¥æ¥æ”¶\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 to_next = None to_prev = None top_halo_recv = None bottom_halo_recv = None if next_top_halo_width \u0026gt; 0: bottom_halo_send = input[:, :, -next_top_halo_width:, :].contiguous() to_next = dist.isend(bottom_halo_send, rank + 1) if halo_width[0] \u0026gt; 0: # not rank 0 top_halo_recv = torch.empty([bs, channels, halo_width[0], w], dtype=input.dtype, device=f\u0026#34;cuda:{rank}\u0026#34;) dist.recv(top_halo_recv, rank - 1) if prev_bottom_halo_width \u0026gt; 0: # not rank N-1 top_halo_send = input[:, :, :prev_bottom_halo_width, :].contiguous() to_prev = dist.isend(top_halo_send, rank - 1) if halo_width[1] \u0026gt; 0: bottom_halo_recv = torch.empty([bs, channels, halo_width[1], w], dtype=input.dtype, device=f\u0026#34;cuda:{rank}\u0026#34;) dist.recv(bottom_halo_recv, rank + 1) æ‹¼æ¥ halo åŒºåŸŸ 1 2 3 4 5 6 7 if halo_width[0] \u0026lt; 0: # Remove redundancy at the top of the input input = input[:, :, -halo_width[0]:, :] if top_halo_recv is not None: # concat the halo region to the input tensor input = torch.cat([top_halo_recv, input], dim=-2) if bottom_halo_recv is not None: input = torch.cat([input, bottom_halo_recv], dim=-2) ç­‰å¾…å‘é€å®Œæˆå†å¼€å§‹è®¡ç®— 1 2 3 4 if to_next is not None: to_next.wait() if to_prev is not None: to_prev.wait() è¿›è¡Œå·ç§¯å’Œåå¤„ç† ä¸ºäº†å‡å°‘ memory spike ä¸€æ¬¡è®¡ç®— block_size*block_size çš„åŒºåŸŸï¼Œå¹¶å°†ç»“æœæ‹¼æ¥èµ·æ¥\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 padding = self._adjust_padding_for_patch(self._reversed_padding_repeated_twice, rank=rank, world_size=world_size) if self.block_size == 0 or (h \u0026lt;= self.block_size and w \u0026lt;= self.block_size): if self.padding_mode != \u0026#39;zeros\u0026#39;: conv_res = F.conv2d(F.pad(input, padding, mode=self.padding_mode), weight, bias, self.stride, _pair(0), self.dilation, self.groups) else: conv_res = F.conv2d(input, weight, bias, self.stride, self.padding, self.dilation, self.groups) return conv_res else: if self.padding_mode != \u0026#34;zeros\u0026#34;: input = F.pad(input, padding, mode=self.padding_mode) elif self.padding != 0: input = F.pad(input, padding, mode=\u0026#34;constant\u0026#34;) _, _, h, w = input.shape num_chunks_in_h = (h + self.block_size - 1) // self.block_size # h ç»´åº¦çš„ block æ•°é‡ num_chunks_in_w = (w + self.block_size - 1) // self.block_size # w ... unit_chunk_size_h = h // num_chunks_in_h unit_chunk_size_w = w // num_chunks_in_w outputs = [] for idx_h in range(num_chunks_in_h): inner_output = [] for idx_w in range(num_chunks_in_w): start_w = idx_w * unit_chunk_size_w start_h = idx_h * unit_chunk_size_h end_w = (idx_w + 1) * unit_chunk_size_w end_h = (idx_h + 1) * unit_chunk_size_h # è®¡ç®—æ¯ä¸ªå—çš„å¼€å§‹å’Œç»“æŸç´¢å¼•ï¼Œè°ƒæ•´å—çš„è¾¹ç•Œ # ... # å¯¹å½“å‰å—æ‰§è¡Œå·ç§¯æ“ä½œ inner_output.append( F.conv2d( input[:, :, start_h:end_h, start_w:end_w], weight, bias, self.stride, 0, self.dilation, self.groups, ) ) outputs.append(torch.cat(inner_output, dim=-1)) return torch.cat(outputs, dim=-2) ","permalink":"http://localhost:1313/blogs/xdit/","summary":"This is a brief introduction to the xDiT Principle.","title":"xDiT Principle"},{"content":"Basic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from vllm import LLM, SamplingParams # Sample prompts. prompts = [ \u0026#34;Hello, my name is\u0026#34;, \u0026#34;The president of the United States is\u0026#34;, \u0026#34;The capital of France is\u0026#34;, \u0026#34;The future of AI is\u0026#34;, ] # Create a sampling params object. sampling_params = SamplingParams(temperature=0.8, top_p=0.95) # Create an LLM. llm = LLM(model=\u0026#34;facebook/opt-125m\u0026#34;) # Generate texts from the prompts. The output is a list of RequestOutput objects # that contain the prompt, generated text, and other information. outputs = llm.generate(prompts, sampling_params) # Print the outputs. for output in outputs: prompt = output.prompt generated_text = output.outputs[0].text print(f\u0026#34;Prompt: {prompt!r}, Generated text: {generated_text!r}\u0026#34;) Architecture VLLM Architecture Overview\nLLM: æœ€ä¸Šå±‚çš„ç±»ï¼Œæ„é€ å‡½æ•°ä¸­ä¼šæ ¹æ®ä¼ å…¥çš„å‚æ•°æ„å»º EngineArgs ç„¶ååˆ›å»º LLMEngine å¯¹è±¡ã€‚ LLMEngine: åŒ…å«ä¸€äº›ç»„ä»¶ InputPreprocessor, ExecutorBase è´Ÿè´£æ¨¡å‹æ¨ç†çš„æœ€ä¸Šå±‚çš„ç±» ExecutorBase ä¼šåˆå§‹åŒ– N ä¸ª WorkerWrapperBase (åŒ…è£…å®é™…çš„ workerï¼Œç±»æ¯”æˆ GPU) Worker: åœ¨ GPU ä¸Šæ‰§è¡Œ (ä¸€éƒ¨åˆ†) æ¨¡å‹æ¨ç†ã€‚æ¯ä¸ª worker ä¸ä¸€ä¸ª GPU ç›¸å…³è”ï¼Œè´Ÿè´£ç»´æŠ¤ KV Cache å¹¶åœ¨ GPU ä¸Šæ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚åœ¨åˆ†å¸ƒå¼æ¨ç†çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸ª worker è¢«åˆ†é…æ¨¡å‹çš„ä¸€éƒ¨åˆ†ã€‚ ModelRunner: æ‰§è¡Œæ¨¡å‹æ¨ç†å¹¶è´Ÿè´£é‡‡æ ·æ–° token. CacheEngine: è´Ÿè´£åˆå§‹åŒ–å’Œç®¡ç† GPU å’Œ CPU KV Cache. è¿˜æä¾›äº†å¯¹ KV Cache è¿›è¡Œæ“ä½œçš„æ–¹æ³•ã€‚é€šè¿‡ initialize_cache() åˆå§‹åŒ–ã€‚ Scheduler: è´Ÿè´£æ¨ç†æ—¶å€™å¯¹è¯·æ±‚çš„è°ƒåº¦ã€‚ç»„ä»¶åŒ…æ‹¬ä¸€ä¸ª BlockSpaceManager (KV Cache blocks ç®¡ç†çš„æ ¸å¿ƒç±») ä»¥åŠä¸‰ä¸ªé˜Ÿåˆ— waiting, running \u0026amp; swapped. LLMEngine Initialization InputPreprocessor: ä¸»è¦æ˜¯åœ¨ add_request() æ–¹æ³•ä¸­å°†è¾“å…¥çš„ prompt æ”¾å…¥ tokenizer è¿›è¡Œå¤„ç†ã€‚ InputRegistry: æ ¹æ®ç›®æ ‡æ¨¡å‹å¯¹ InputPreprocessor ä¹‹åçš„æ•°æ®è¿›è¡Œå¤„ç†ã€‚ Init Executor 1 2 3 4 5 6 7 8 9 class DistributedExecutorBase(ExecutorBase): \u0026#34;\u0026#34;\u0026#34;Abstract superclass of distributed executor implementations.\u0026#34;\u0026#34;\u0026#34; def __init__(self, *args, **kwargs): # This is non-None when the execute model loop is running # in the parallel workers. It\u0026#39;s a coroutine in the AsyncLLMEngine case. self.parallel_worker_tasks: Optional[Union[Any, Awaitable[Any]]] = None super().__init__(*args, **kwargs) ExecutorBase çš„æ„é€ å‡½æ•°ä¸­ä¼šè°ƒç”¨ self._init_executor() å¯¹åº”åˆ°å…·ä½“å­ç±»çš„å‡½æ•°ã€‚å¦‚æœé‡‡ç”¨ TP æˆ– PP çš„è¯ å¯¹åº”åˆ°çš„æ˜¯ RayDistributedExecutorï¼Œå¦åˆ™å¯¹åº”åˆ°çš„æ˜¯ UniProcExecutor. ä¸‹é¢ä»¥åè€…ä¸ºä¾‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class UniProcExecutor(ExecutorBase): uses_ray: bool = False def _init_executor(self) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;Initialize the worker and load the model. \u0026#34;\u0026#34;\u0026#34; self.driver_worker = WorkerWrapperBase(vllm_config=self.vllm_config, rpc_rank=0) distributed_init_method = get_distributed_init_method( get_ip(), get_open_port()) local_rank = 0 # set local rank as the device index if specified device_info = self.vllm_config.device_config.device.__str__().split( \u0026#34;:\u0026#34;) if len(device_info) \u0026gt; 1: local_rank = int(device_info[1]) rank = 0 kwargs = dict( vllm_config=self.vllm_config, local_rank=local_rank, rank=rank, distributed_init_method=distributed_init_method, is_driver_worker=(not self.parallel_config) or (rank % self.parallel_config.tensor_parallel_size == 0), ) self.collective_rpc(\u0026#34;init_worker\u0026#34;, args=([kwargs], )) self.collective_rpc(\u0026#34;init_device\u0026#34;) self.collective_rpc(\u0026#34;load_model\u0026#34;) def collective_rpc(self, method: Union[str, Callable], timeout: Optional[float] = None, args: Tuple = (), kwargs: Optional[Dict] = None) -\u0026gt; List[Any]: if kwargs is None: kwargs = {} answer = run_method(self.driver_worker, method, args, kwargs) # åˆå§‹åŒ– Worker return [answer] Executor: åˆå§‹åŒ–å…·ä½“çš„ç»§æ‰¿è‡ª ExecutorBase çš„å¯¹è±¡ï¼Œè¯¥å¯¹è±¡çš„åˆå§‹åŒ–è¿‡ç¨‹ä¸­ä¼šè°ƒç”¨ init_worker() åˆå§‹åŒ– Worker (è¢« WorkerWrapperBase åŒ…è£…)ï¼Œè°ƒç”¨ init_device() åˆå§‹åŒ–è®¾å¤‡ï¼Œå’Œè°ƒç”¨å…·ä½“ Worker å¯¹è±¡çš„ model_runner çš„ load_model() å°†æ¨¡å‹åŠ è½½åˆ°è®¾å¤‡ä¸Šã€‚ Worker: æ„é€ å‡½æ•°ä¸­ä¼šåˆå§‹åŒ– GPUModelRunnerBase å¯¹è±¡ï¼Œç¡®å®šè®¡ç®— attention ä½¿ç”¨çš„ backend è¿˜æœ‰ CUDAGraphRunner ç”¨äºå°†æ¨¡å‹çš„è®¡ç®—è¿‡ç¨‹è®°å½•ä¸ºä¸€ä¸ªé™æ€å›¾ï¼Œåœ¨åç»­çš„æ¨ç†ä¸­ï¼Œé€šè¿‡ç›´æ¥ replay è¿™ä¸ªé™æ€å›¾æ¥é¿å…åŠ¨æ€è°ƒåº¦å’Œé‡å¤çš„å†…æ ¸å¯åŠ¨å¼€é”€ã€‚ initialize_kv_caches LLMEngine æ„é€ å‡½æ•°åœ¨åˆå§‹åŒ– ExecutorBase åä¼šè°ƒç”¨ initialize_kv_caches() æ¥åˆå§‹åŒ– Worker ä¸­çš„ KV Cacheï¼Œæµç¨‹å¦‚ä¸‹:\nè¯¥å‡½æ•°ä¼šé¦–å…ˆé€šè¿‡ Worker.determine_num_available_blocks() ç¡®å®š GPU å’Œ CPU å¯ç”¨çš„ block æ•°é‡ã€‚åè€…åœ¨ memory_profiling ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œ profile_run() æ¨¡æ‹Ÿæ¨¡å‹åœ¨æœ€å¤§è´Ÿè½½ (max_num_batched_tokens å’Œ max_num_seqs) ä¸‹æ‰§è¡Œä¸€æ¬¡æ¨ç†ã€‚æµ‹é‡å†…å­˜ä½¿ç”¨å¹¶åˆ†è§£ä¸ºæƒé‡ã€æ¿€æ´»å¼ é‡å’Œé PyTorch éƒ¨åˆ†ã€‚ç•™ç»™ KV Cache çš„å†…å­˜å¤§å°ä¸º total_mem * max_utilization - weight_mem - act_mem - nontorch_mem. å†é™¤ä»¥æ¯ä¸€ä¸ª block èƒ½å­˜å‚¨çš„çš„ KV Cache å¤§å° cache_size = Cache_config.block_size * num_attention_layers * 2*num_heads*head_size å³å¯å¾—åˆ°æœ€å¤šèƒ½åˆ†é…å¤šå°‘ä¸ª GPU block. è€Œ CPU block æ•°é‡ç”±é¢„è®¾çš„ swap_size // cache_size æ‰€ç¡®å®šã€‚ ç¡®å®šäº† GPU å’Œ CPU çš„ block æ•°é‡åä¼šè°ƒç”¨ Worker.initialize_cache() æ–¹æ³•ï¼Œé‡Œé¢é¦–å…ˆä¼šè°ƒç”¨ Worker._init_cache_engine() æ ¹æ®ä¼ å…¥çš„ GPU block ä¸ªæ•°åˆå§‹åŒ– CacheEngine (åˆå§‹åŒ– attn_backendï¼Œè°ƒç”¨ CacheEngine._allocate_kv_cache() ä¸ºæ¨¡å‹çš„æ¯ä¸€å±‚ transformer å¼€è¾Ÿ CPU å’Œ GPU çš„ KV Cache å†…å­˜)ï¼Œç„¶åä¼šè°ƒç”¨ bind_kv_cache() å°† GPU KV Cache Tensor ç»‘å®šåˆ°å¯¹åº”çš„æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ï¼Œå®ƒç­›é€‰éœ€è¦ KV Cache çš„æ³¨æ„åŠ›å±‚ï¼ŒæŒ‰å±‚ç´¢å¼•æ’åºå¹¶å»é‡åä¸ºæ¯ä¸ªè®¾å¤‡ç»‘å®šå¯¹åº”çš„ Tensor. é¢„çƒ­ä¹‹åè¿›è¡Œ capture_model è®°å½•è®¡ç®—å›¾ã€‚ Init Scheduler æ„é€ å‡½æ•°ä¸­ä¼šåˆå§‹åŒ– BlockSpaceManager. é¦–å…ˆä¼šåˆ›å»ºä¸€ä¸ª CpuGpuBlockAllocatorï¼Œä¸º CPU å’Œ GPU å—ç»´æŠ¤å•ç‹¬çš„å†…å­˜æ± ï¼Œå¹¶å…è®¸åœ¨è¿™äº›å†…å­˜æ± ä¸­åˆ†é…ã€é‡Šæ”¾ã€åˆ†å‰å’Œäº¤æ¢å—ã€‚å®ƒä¼šä¸º CPU å’Œ GPU ä¸­çš„ blocks åˆ†åˆ«åˆ›å»ºä¸€ä¸ª BlockAlloctor. è¿˜ä¼šåˆå§‹åŒ–ä¸€ä¸ªç©ºçš„ Dict[SeqId, BlockTable]ï¼Œ è¡¨ç¤ºå¯¹åº” seq çš„ KV Cache æ‰€ä½¿ç”¨çš„ç‰©ç†å†…å­˜å—ã€‚è¿˜ä¼šåˆå§‹åŒ–ä¸€äº›è°ƒåº¦æ—¶æ‰€éœ€è¦çš„æ•°æ®ï¼Œåæ–‡å†è°ˆã€‚\nè¿˜ä¼šåˆå§‹åŒ– waiting(åŒ…å«æ–°çš„æˆ– preempted prefill è¯·æ±‚), running \u0026amp; swapped(è¢«æ¢å‡ºçš„ decoding è¯·æ±‚), å®ƒä»¬æ˜¯ Deque[SequenceGroup]ï¼Œå…¶ä¸­ SequenceGroup(SG) æ˜¯ä¸€ç»„ç”±åŒä¸€ä¸ª prompt ç”Ÿæˆçš„ Sequences å’Œå¯¹åº”çš„é‡‡æ ·å‚æ•°ã€‚\nSequenceGroupOutputProcessor: æŠ½è±¡åŸºç±»å€Ÿæ¥å£ï¼Œä¼šåˆ†ä¸º SingleStepOutputProcessor (æ”¯æŒ beam seaching) å’Œ MultiStepOutputProcessor (æ”¯æŒ speculatice decoding) LLM Generate _validate_and_add_requests é‡Œé¢ä¼šè°ƒç”¨ _add_request() ç»™ prompt åˆ†é… reqest_id åä¼šè°ƒç”¨ LLMEngine.add_request() å°†å…¶æ·»åŠ åˆ°è¯·æ±‚æ± ä¸­ï¼Œå¹¶å°†åœ¨è°ƒç”¨ LLMEngine.step() æ—¶ç”±è°ƒåº¦å™¨å¤„ç†ã€‚ç¡®åˆ‡çš„è°ƒåº¦ç­–ç•¥ç”±è°ƒåº¦ç¨‹åºç¡®å®šã€‚ä¸»è¦å°±æ˜¯è¿›è¡Œ tokenizeï¼Œç„¶åæ‰“åŒ…æˆ SG ååŠ å…¥ waiting.\n__run_engine è°ƒç”¨ generate æ—¶é¦–å…ˆä¼šå°† prompt åŒ…è£…æˆ SGï¼Œå®ƒæ˜¯åŒ…å«æŸä¸ª prompt ç”Ÿæˆçš„æ‰€æœ‰ Sequenceï¼Œä»¥åŠä¸€äº›å…¶ä»–åœ¨è°ƒåº¦æ—¶éœ€è¦çš„ä¿¡æ¯çš„ç»“æ„ã€‚Scheduler é‡Œé¢åŒ…å«ä¸‰ä¸ª Deque[SequenceGroup]: waiting, running \u0026amp; swapped. generate() \u0026ndash;\u0026gt; _run_engine() \u0026ndash;\u0026gt; step() \u0026ndash;\u0026gt; Scheduler.schedule() \u0026ndash;\u0026gt; Scheduler._schedule() Scheduler çš„ä¸€äº›æ“ä½œä¸ BlockManager æ¯æ¯ç›¸å…³ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢å…ˆç®€è¦è¯´æ˜é€»è¾‘ï¼Œæœ‰å…³å…¶å…·ä½“ç»“æ„å’Œæ“ä½œæµç¨‹åœ¨åæ–‡ä¸­è§£é‡Šã€‚\nstep æ‰§è¡Œä¸€æ¬¡ decoding è¿­ä»£å¹¶è¿”å›æ–°ç”Ÿæˆçš„ç»“æœã€‚ Overview of the step function ä¸»è¦æµç¨‹å¦‚ä¸‹\nè°ƒåº¦è¦åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­æ‰§è¡Œçš„ seq å’Œè¦äº¤æ¢å…¥/å‡º/å¤åˆ¶çš„ä»¤ç‰Œå—ã€‚æ ¹æ®è°ƒåº¦ç­–ç•¥ï¼ŒSequences å¯èƒ½è¢«æŠ¢å /é‡æ–°æ’åºã€‚ è°ƒç”¨åˆ†å¸ƒå¼æ‰§è¡Œå™¨æ¥æ‰§è¡Œæ¨¡å‹ã€‚ å¤„ç†æ¨¡å‹è¾“å‡ºã€‚ä¸»è¦åŒ…æ‹¬ï¼š decoding ç›¸å…³è¾“å‡ºï¼Œä½¿ç”¨ _beam_search ä¸å¦çš„æ¨¡å‹è¾“å‡ºæ›´æ–°è°ƒåº¦ seq ç»„å’Œé‡Šæ”¾å·²å®Œæˆçš„ seq ç»„ã€‚ è¯»å–ä¸Šä¸€æ¬¡è°ƒåº¦çš„å…ƒæ•°æ®å’Œè¾“å‡º å¦‚æœæ²¡æœ‰å‰©ä½™æ­¥éª¤ä¸”ï¼Œè°ƒç”¨ Scheduler.schedule() æ‰§è¡Œæ–°è°ƒåº¦ï¼Œç”Ÿæˆ seq ç»„å…ƒæ•°æ®ã€è°ƒåº¦è¾“å‡ºå’Œå¼‚æ­¥æ ‡å¿—ã€‚ è·å–å¹¶é‡ç½®å·²å®Œæˆè¯·æ±‚ IDï¼Œæ¸…ç†å†…å­˜ å¦‚æœä¸å…è®¸å¼‚æ­¥ä¸”æœ‰è¾“å‡ºé˜Ÿåˆ—ï¼Œå¤„ç†æ¨¡å‹è¾“å‡ºã€‚ ä» Cache è·å–ä¸Šä¸€æ¬¡è¿­ä»£çš„ sampled_token_idsï¼Œæ„é€  ExecuteModelRequest åè°ƒç”¨ Executor.execute_model() (æœ€åæ˜¯ç”± ModelRunner) æ‰§è¡Œæ¨¡å‹æ¨ç†ï¼Œè·å–è¾“å‡ºã€‚ _schedule_prefill() æ£€æŸ¥ budget æ˜¯å¦è€—å°½ å–å‡ºé˜Ÿåˆ—head éƒ¨çš„ SequenceGroup (prefill é˜¶æ®µ SequenceGroup åªæœ‰ä¸€ä¸ªåˆå§‹ prompt Sequence) è®¡ç®— uncached å’Œ cached çš„æ–° token æ•° è°ƒç”¨ BlockSpaceManager.can_allocate() æ£€æŸ¥æ˜¯å¦èƒ½åˆ†é…è¶³å¤Ÿå†…å­˜ã€‚ è‹¥èƒ½æ»¡è¶³ budgetï¼Œä» waiting ä¸­ç§»é™¤ SequenceGroup. è°ƒç”¨ _allocate_and_set_running() åˆ†é…å†…å­˜å¹¶è®¾ç½®ä¸º RUNNING çŠ¶æ€ã€‚ _schedule_running() å–å‡ºé˜Ÿåˆ—head éƒ¨ SequenceGroup å¹¶è®¡ç®—å…¶åŒ…å« seq çš„ #uncached_token. è¿™é‡Œä¸éœ€è¦ #cached_token å› ä¸ºè‹¥ä½¿ç”¨ chunked prefillï¼Œè¯¥ä¿¡æ¯å·²ç»åœ¨ç¬¬ä¸€æ¬¡ prefill æ—¶ä½¿ç”¨ï¼Œå¦‚æœä¸ä½¿ç”¨é‚£ä¹ˆä»–å°±æ˜¯è¿›è¡Œ decoding çš„ seq ï¼Œä¸éœ€è¦ç”¨åˆ°è¿™ä¸ªä¿¡æ¯ã€‚ ä» running ç§»é™¤è¯¥ SequenceGroup. å¾ªç¯è°ƒç”¨ Scheduler._can_append_slots() æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç©ºé—´å­˜å‚¨è¯¥ SequenceGroup çš„ KV Cacheï¼Œè‹¥ä¸èƒ½ï¼Œè¿›å…¥æŠ¢å é€»è¾‘ ä» budget ä¸­å‡å»å½“å‰ SequenceGroup çš„ token å’Œ seq æ•° è‹¥ running æœ‰å…¶ä»– SequenceGroupï¼ŒæŠ¢å æœ€ä½ä¼˜å…ˆçº§ï¼ˆé˜Ÿåˆ—å°¾éƒ¨ï¼‰çš„ï¼Œè‹¥è¯¥ SequenceGroup åªæœ‰ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„ Sequence åˆ™æŠ¢å æ¨¡å¼ä¸º RECOMPUTE åŠ å…¥åˆ° preemptedï¼Œå¦åˆ™ä¸º SWAP åŠ å…¥åˆ° swapped_out. åˆ†é… slot å¹¶æ›´æ–° blocks_to_copyï¼Œæ ¹æ®è¯¥ Sequence å¤„äº decoding(ç”Ÿæˆ 1 ä¸ª token çš„ KV Cache ) æˆ–è€… prefill(ç”Ÿæˆ #uncached_token çš„ KV Cache) åŠ å…¥åˆ° prefill_seq_group æˆ–è€… decode_seq_groupsï¼Œå¹¶æ›´æ–° budget. è¿”å› decode_seq_groupsï¼šå­˜å‚¨ decoding SequenceGroup. prefill_seq_groupsï¼šå­˜å‚¨åˆ†å— prefill SequenceGroup. preemptedï¼šè¢«æŠ¢å éœ€é‡æ–°è®¡ç®—çš„ SequenceGroup. swapped_outï¼šè¢«äº¤æ¢åˆ° CPU çš„ SequenceGroup. keys_to_swap_out å’Œ keys_to_copyï¼šå†…å­˜å—äº¤æ¢å’Œå¤åˆ¶çš„æ˜ å°„ _schedule_swapepd() å¾ªç¯éå† swapped é˜Ÿåˆ—ï¼Œå–å‡ºé˜Ÿåˆ—head éƒ¨çš„ SequenceGroupï¼Œè°ƒç”¨ BlockManager.can_swap_in() (å®é™…ä¸Šæ˜¯ SWAPPED çŠ¶æ€çš„ can_swap) è·å– SequenceGroup ä¸­å¤„äº SWAPPED çš„ Sequence ä¸ªæ•°å’Œ token ä¸ªæ•°ï¼Œæ˜¯å¦æ»¡è¶³é¢„ç®—ã€‚ è°ƒç”¨ _swap_in(å®é™…ä¸Šæ˜¯ BlockManager.swap_in()) æ‰§è¡Œäº¤æ¢ï¼Œæ›´æ–° blocks_to_swap_inï¼Œå°† Sequence çŠ¶æ€ç”± SWAPPED å˜ä¸º RUNNING. è°ƒç”¨ _append_slots ç»™è¢«æ¢å…¥çš„ Sequence åˆ†é… block. æ ¹æ® SequenceGroup çš„çŠ¶æ€æ·»åŠ åˆ°ä¸åŒé˜Ÿåˆ—ã€‚ è¿”å›blocks_to_swap_inï¼šè®°å½•éœ€è¦ä» CPU äº¤æ¢åˆ° GPU çš„å—æ˜ å°„ã€‚blocks_to_copyï¼šè®°å½•éœ€è¦å¤åˆ¶çš„å—æ˜ å°„ï¼ˆä¾‹å¦‚å†™æ—¶å¤åˆ¶ï¼‰ã€‚decode_seq_groups å’Œ prefill_seq_groupsï¼šåˆ†åˆ«å­˜å‚¨ decoding å’Œ prefill SequenceGroup. infeasible_seq_groupsï¼šå­˜å‚¨æ— æ³•è°ƒåº¦çš„ SequenceGroup. swapped_queueï¼šå¼•ç”¨äº¤æ¢é˜Ÿåˆ—ã€‚leftover_swappedï¼šæš‚å­˜æ— æ³•ç«‹å³è°ƒåº¦çš„ SequenceGroup. _schedule_chunked_prefill() ä¸»è¦æ€æƒ³æ˜¯: 1.å®‰æ’å°½å¯èƒ½å¤šçš„ decoding è¯·æ±‚ã€‚2.è°ƒåº¦æœªå®Œæˆçš„ prefill è¯·æ±‚ã€‚3.è°ƒåº¦äº¤æ¢è¯·æ±‚ã€‚4.å®‰æ’æ–°çš„ prefill è¯·æ±‚ã€‚\nåˆå§‹åŒ– budgetï¼Œé™åˆ¶æœ€å¤§æ‰¹å¤„ç† token æ•°å’Œ seq æ•°ã€‚ ä» running å’Œ waiting ç”Ÿæˆ PartialPrefillMetadata prefills: running å’Œ waiting ä¸­æœªå®Œæˆ prefill çš„ #SequenceGroup. long_prefills: running ä¸­éœ€è¦è¿›è¡Œ prefill çš„ token æ•°å¾ˆå¤šçš„ #SequenceGroup. waiting_long_prefills: waiting ä¸­éœ€è¦è¿›è¡Œä¸”èƒ½è¿›è¡Œçš„ (æœªè¶…è¿‡ ScheduleConfig é™åˆ¶) prefill çš„ token æ•°å¾ˆå¤šçš„ #SequenceGroup. è°ƒç”¨ _schedule_running. åœ¨ running è°ƒåº¦è¿”å›ä¸­æ— æ— æŠ¢å æˆ–äº¤æ¢æ—¶(è¯´æ˜æœ‰è¶³å¤Ÿç©ºé—´) æ‰§è¡Œ _schedule_swapped è°ƒç”¨ _schedule_prefills. æ›´æ–° waitingï¼Œæ·»åŠ  running è°ƒåº¦ä¸­è¿”å›çš„è¢«æŠ¢å çš„ seq running_scheduled.preempted. æŒ‰ä¼˜å…ˆçº§æ›´æ–° running. swapped_in.decode_seq_groupsï¼šäº¤æ¢å›æ¥çš„ decoding è¯·æ±‚ã€‚ swapped_in.prefill_seq_groupsï¼šäº¤æ¢å›æ¥çš„ prefill è¯·æ±‚ã€‚ running_scheduled.decode_seq_groupsï¼šè¿è¡Œä¸­çš„ decoding è¯·æ±‚ã€‚ running_scheduled.prefill_seq_groupsï¼ˆæŒ‰å®Œæˆé¡ºåºï¼‰ï¼šæœªå®Œæˆçš„åˆ†å— prefill ã€‚ä½¿ç”¨ _order_finishing_prefills_first ç¡®ä¿å³å°†å®Œæˆçš„ prefill ä¼˜å…ˆï¼Œä¾¿äºä¸‹ä¸€è½®è½¬ä¸º decoding. prefills.seq_groupsï¼šæ–° prefill è¯·æ±‚ã€‚ å°†è¿è¡Œé˜Ÿåˆ—ä¸­äº¤æ¢å‡ºå»çš„ running_scheduled.swapped_out æ·»åŠ åˆ° swapped. æŒ‰é¡ºåºç»„åˆæ‰€æœ‰è°ƒåº¦çš„ SequenceGroup: prefill ä¼˜å…ˆï¼ˆæ»¡è¶³æ³¨æ„åŠ›æœºåˆ¶å‡è®¾ï¼‰ï¼Œdecoding æ¬¡ä¹‹ã€‚ è°ƒæ•´ lookahead_slots æ•°é‡ã€‚è‹¥æ‰€æœ‰è¢«è°ƒåº¦çš„å‡ä¸º prefill ä¸”æœªå¯ç”¨å¤šæ­¥è°ƒåº¦ï¼Œè®¾ç½® num_lookahead_slots = 0(é¿å…æ¨æµ‹ decoding è·¯å¾„). å¦åˆ™ï¼Œä½¿ç”¨ running è®¡ç®—çš„ lookaheadh slots æ•°é‡ã€‚ _schedule_default å°½å¯èƒ½å¤šåœ°æ‰¹å¤„ç† prefill è¯·æ±‚ï¼Œç„¶åè°ƒåº¦ decoding è¯·æ±‚. åœ¨ GPU å†…å­˜å‹åŠ›ä¸‹ï¼Œéœ€è¦ preempt æˆ– swap out è¿è¡Œä¸­çš„ decoding è¯·æ±‚ã€‚\nswapped ä¸ºç©ºåˆ™è¿›è¡Œ _schedule_prefills. å¦‚æœæ²¡æœ‰è°ƒåº¦ä»»ä½• prefill è¯·æ±‚ï¼Œè°ƒç”¨ _schedule_running. å¦‚æœ running è°ƒåº¦ç»“æœä¸­æ²¡æœ‰å‘ç”ŸæŠ¢å æˆ–æ¢å‡ºæ—¶ (å¦åˆ™è¯´æ˜èµ„æºä¸å¤Ÿ)ï¼Œæ‰§è¡Œ _schedule_swapped. æ›´æ–° waiting, running \u0026amp; swapped ä¸‰ä¸ªé˜Ÿåˆ—ã€‚ After schedule è°ƒåº¦ç»“æœè¿”å›åï¼Œ\néå†è°ƒåº¦ç»“æœä¸­çš„ SequenceGroup éå†è¯¥ SequenceGroup ä¸­çŠ¶æ€ä¸º RUNNING çš„ Sequence. è·å–å…¶æ•°æ®ï¼Œå¯¹åº”çš„ BlockID åˆ—è¡¨ï¼Œå¹¶æ›´æ–°å…¶è®¿é—®æ—¶é—´ã€‚è‹¥ä½¿ç”¨ prefix_caching, åˆ™è°ƒç”¨ BlockManager.get_common_computed_block_ids() è·å–å…±äº«çš„å·²è®¡ç®—çš„éƒ¨åˆ†çš„ BlockID åˆ—è¡¨ã€‚ å¦‚æœè¯¥ SequenceGroup å¤„äº prefill é˜¶æ®µï¼Œåˆ™åˆ¤æ–­è¿™æ¬¡è°ƒåº¦åæ˜¯å¦èƒ½å®Œæˆ prefill. æ„é€ è¿”å›ç»“æœï¼Œæ ‡è®°æ‰€æœ‰è°ƒåº¦ SequenceGroup çš„ blocks ä¸ºå·²è®¡ç®—ã€‚ BlockSpaceManager ç”¨äºå°† SequenceGroup æ“ä½œæ˜ å°„åˆ°å…¶åŒ…å«çš„å¯¹åº”ç»„ä»¶çš„æ“ä½œã€‚\nCpuGpuBlockAlloctor: æ ¹æ®æ˜¯å¦é‡‡ç”¨ prefix caching åˆ†åˆ«ä¸º CPU å’Œ GPU åˆå§‹åŒ–ä¸€ä¸ª Alloctor PrefixCachingBlockAlloctor: åŸºäºå“ˆå¸Œå€¼ç»´æŠ¤ block çš„Cache)é‡ç”¨å…·æœ‰ç›¸åŒå“ˆå¸Œå€¼çš„ blockï¼Œä»¥é¿å…å†—ä½™çš„å†…å­˜åˆ†é…ã€‚ Dict[PrefixHash, BlockId] å°†ç”¨äº prefix caching blocks çš„å“ˆå¸Œå€¼ä¸å…¶ BlockID å¯¹åº”ã€‚ Dict[BlockId, BlockTracker] ä¸ºæ¯ä¸ªç‰©ç† block åˆå§‹åŒ–ä¸€ä¸ª BlockTracker. NaiveBlockAllocator ç”¨äºåˆ†é…ä¸ä½œä¸º prefix caching çš„ blocks. æœ‰ä¸€ä¸ª RefCounter è¡¨ç¤ºæŸä¸ªç‰©ç† block è¢«å¤šå°‘é€»è¾‘ block æŒ‡å‘ã€‚ Evictor é‡‡ç”¨ LRU ç­–ç•¥é©±é€å·²ç»Cache) blocks. CopyOnWriterTracker ç”¨äºå°†åŸå…ˆçš„ block ID æ˜ å°„åˆ°ç›®çš„ block ID. Dict[SeqId, BlockTable]: BlockTable ç”¨äºå°†å•ä¸ª seq çš„ KV Cache æ˜ å°„åˆ°ç‰©ç†å†…å­˜åˆ†é…ã€‚ä¼šåœ¨è°ƒç”¨ _allocate_sequence() æ—¶è¢«åˆå§‹åŒ–ã€‚åŒ…å«ä¸€ä¸ª BlockList (block åˆ—è¡¨å’Œä¸€ä¸ªè¡¨ç¤ºå¯¹åº” ID çš„ int åˆ—è¡¨) å’Œ BlockpaceManager çš„ BlockAllocator. ComputedBlocksTracker: ç»´æŠ¤ä¸€ä¸ª Dict[SeqId, List[int]] ( seq idåˆ° seq å—å“ˆå¸Œåˆ—è¡¨çš„æ˜ å°„)ã€‚Cache)ä¸ª seq çš„å®Œæ•´å— (å—å…¨éƒ¨è¢«å æ»¡) çš„å“ˆå¸Œå€¼ã€‚å½“ä¸€ä¸ª seq è¿›è¡Œ decoding æ—¶ï¼Œä¹Ÿç›¸åº”æ›´æ–° seq çš„å“ˆå¸Œå€¼ã€‚è¿˜æœ‰ä¸€ä¸ª Dict[int, int] ( seq idåˆ°å·²è®¡ç®— token æ•°çš„æ˜ å°„) can_allocate åœ¨ _schedule_prefills ä¸­è¢«è°ƒç”¨ã€‚\n1 2 3 def can_allocate(self, seq_group: SequenceGroup, num_lookahead_slots: int = 0) -\u0026gt; AllocStatus: å–å‡ºè¯¥ SequenceGroup ä¸­å¤„äº WAITING çŠ¶æ€çš„ç¬¬ä¸€ä¸ª Sequence (i.e. prompt). è°ƒç”¨ BlockTable.get_num_required_blocks() è®¡ç®—å­˜å‚¨ token å’Œ lookahead slots æ‰€éœ€çš„æœ€å° block æ•° (å‡è®¾æ—  prefix caching), i.e. cdiv(len(token_ids) + num_lookahead_slots, block_size). è°ƒç”¨ BlockAlloctor.get_num_free_blocks() è·å– GPU ä¸Šç©ºé—²çš„ block æ•° (é prefix_caching ä¸­çš„ç©ºé—²ä¸ªæ•° + å¯ä»¥è¢«é©±é€çš„ä¸ªæ•°). è¿”å›åˆ†é…çŠ¶æ€ NEVER: #total - #required \u0026lt; #watermark OK: #free - #required \u0026gt;= #watermark LATER: #free - #required \u0026lt; #watermark allocate 1 def allocate(self, seq_group: SequenceGroup) -\u0026gt; None: åœ¨ _schedule_prefills ä¸­æ­¥éª¤ 4 ä¸­è°ƒç”¨çš„ _allocate_and_set_running å†…éƒ¨è¢«è°ƒç”¨ã€‚\nå–å‡ºè¯¥ SequenceGroup ä¸­å¤„äº WAITING çŠ¶æ€çš„ç¬¬ä¸€ä¸ª Sequence (i.e. prompt). è°ƒç”¨ BlockManager._allocate_sequence() åˆ›å»ºä¸€ä¸ª BlockTableï¼Œåœ¨è·å– token_ids åˆ—è¡¨åè°ƒç”¨ BlockTable.allocate() ä¸ºè¯¥ Sequence åˆ†é… blocks. å°† token_ids æŒ‰ _block_size å¤§å°è¿›è¡Œåˆ†å—ã€‚æœ€åä¸€å—å¯èƒ½ä¸èƒ½å æ»¡ä¸€ä¸ª block. å¯¹äºèƒ½å¤Ÿå æ»¡ä¸€ä¸ª block çš„ token_ids åˆ†å—ï¼Œè°ƒç”¨ BlockAlloctor.allocate_immutable_block(). è¯¥å‡½æ•°ä¼˜å…ˆä»Cache)æŸ¥æ‰¾æ˜¯å¦å·²æœ‰ç›¸åŒå†…å®¹çš„å—ï¼Œè‹¥æœ‰åˆ™ç›´æ¥å¤ç”¨è¯¥å—å¹¶å¢åŠ å…¶å¼•ç”¨è®¡æ•°ï¼›å¦åˆ™è°ƒç”¨ BlockAlloctor.allocate_mutable_blocks() åˆ†é…ä¸€ä¸ªæ–°çš„ blockï¼Œå¹¶å°† token_ids æ·»åŠ åˆ°è¯¥ block ä¸­. è¯¥å‡½æ•°ä¼šå°è¯•ä»é prefix caching blocks ä¸­åˆ†é…ä¸€ä¸ª block_idï¼Œè‹¥æ²¡æ‰¾åˆ°åˆ™ä¼šé©±é€ä¸€ä¸ªã€‚ å¯¹äºæœ€åä¸€ä¸ªå¯èƒ½è¢«æ²¡å æ»¡çš„ block è°ƒç”¨ BlockAlloctor.allocate_mutable_blocks(). can_append_slots 1 2 def can_append_slots(self, seq_group: SequenceGroup, num_lookahead_slots: int) -\u0026gt; bool: ç¡®å®š GPU KV Cache ä¸­æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç©ºé—´æ¥ç»§ç»­ç”ŸæˆæŒ‡å®šçš„ SequenceGroup. ä¸Šå±‚æ¥å£ä¸º Scheduler._can_append_slots()ï¼Œåœ¨ _schedule_running ä¸­æ­¥éª¤ 2 ä¸­ç¡®å®šæ˜¯å¦éœ€è¦è¿›è¡ŒæŠ¢å æ—¶è¢«è°ƒç”¨ã€‚\néå†è¯¥ Sequence Group ä¸­å¤„äº RUNNING çŠ¶æ€çš„ Sequence å¯¹åº”çš„ BlockTable è°ƒç”¨ BlockTable.get_unseen_token_ids() è·å–è¯¥ Sequence è¿˜æœªè¢«Cache) token éƒ¨åˆ†ã€‚ è°ƒç”¨ BlockTable.get_num_blocks_touched_by_append_slots() è·å–Cache)ä½™éƒ¨åˆ†å’Œ lookahead éƒ¨åˆ†éœ€è¦å‡ ä¸ª block. è°ƒç”¨ BlockAlloctor.get_num_free_blocks() è·å– GPU ä¸Šç©ºé—²çš„ block æ•°. éœ€è¦ä¸ªæ•°å°äºç©ºé—²ä¸ªæ•°è¿”å› True. append_slots 1 2 3 4 5 def append_slots( self, seq: Sequence, num_lookahead_slots: int, ) -\u0026gt; List[Tuple[int, int]]: ä¸Šå±‚æ¥å£ä¸º Scheduler._append_slots(). åœ¨ _schedule_running ä¸­æ£€æŸ¥åˆ°æœ‰ç©ºé—´æ·»åŠ ï¼Œ_schedule_swapped ä¸­æœ‰ budget è¿›è¡Œæ¢å…¥ï¼Œ_schedule_prefills ä¸­å…è®¸è¿›è¡Œ chunked prefill æ—¶è¢«è°ƒç”¨ã€‚\nè°ƒç”¨ BlockTable.append_token_ids(). è¯¥æ–¹æ³•å°† tokens æ·»åŠ åˆ° BlockTable ä¸­çš„ç°æœ‰ block ä¸­ã€‚ä¼šè°ƒç”¨ BlockTable.ensure_num_empty_slots()ï¼Œ å®ƒæŸ¥çœ‹å½“å‰èƒ½å¤Ÿå®¹çº³å¤šå°‘ä¸ª token. å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ç©ºé—´ï¼Œåˆ™ä½¿ç”¨ BlockAlloctor.allocate_mutable_block() æ–¹æ³•åˆ†é…æ–° block. è°ƒç”¨ BlockAllocator.clear_copy_on_writes() è¿”å›ä¸€ä¸ªæ˜ å°„æº block ID åˆ°å½“å‰ COW çš„ç›®æ ‡ block ID çš„å…ƒç»„çš„åˆ—è¡¨. _can_swap 1 2 3 4 5 def _can_swap(self, seq_group: SequenceGroup, device: Device, status: SequenceStatus, num_lookahead_slots: int = 0) -\u0026gt; AllocStatus: æ ¹æ® status åŒºåˆ†ä¸Šå±‚æ¥å£: RUNNING/SWAPPED è¡¨ç¤ºéœ€è¦æŠŠè¯¥ SequenceGroup å¤„äº RUNNING/SWAPPED çŠ¶æ€çš„ Sequence å¯¹åº”çš„ blocks ä» GPU/CPU æ¢åˆ° CPU/GPU.\nè·å– SequenceGroup ä¸­ç¬¦åˆæŒ‡å®šçŠ¶æ€çš„ seq Sequenceï¼Œç„¶åæ ¹æ® SeqID è·å–å¯¹åº”çš„ BlockTable. è°ƒç”¨ BlockTable.get_num_blocks_touched_by_append_slots() è®¡ç®—æ·»åŠ æœªå­˜å‚¨ token åŠ ä¸Š lookahead_slots æ‰€éœ€çš„ block æ•°é‡ã€‚ è°ƒç”¨ BlockAlloctor.get_num_full_blocks_touched() è·å–å½“å‰æœ‰è¢«ä½¿ç”¨çš„ block æ•°é‡ã€‚ å¦‚æœæ€»å—æ•°å°äºè¢«ä½¿ç”¨çš„åŠ ä¸Šéœ€è¦çš„ block æ•°é‡ è¿”å› Never. å¦‚æœç©ºé—²å—å‡å» è¢«ä½¿ç”¨çš„åŠ ä¸Šéœ€è¦çš„ block æ•°é‡åä»å¤§äºç­‰äº watermark_blocksï¼Œè¿”å› OK. å¦åˆ™ä¸º LATER. swap_in è°ƒç”¨çš„æ˜¯ self.block_allocator.swap(blocks=blocks, src_device=Device.CPU, dst_device=Device.GPU)ï¼Œå³ blocks ä»åŸè®¾å¤‡çš„æ¢å‡ºï¼Œæ¢å…¥åˆ°ç›®çš„è®¾å¤‡ã€‚ è¿›ä¸€æ­¥åˆ™æ˜¯ BlockAlloctor.swap_in()ï¼Œè¯¥å‡½æ•°éå†ä¼ å…¥çš„ blocksï¼Œè‹¥å·²ç»è¢«å æ»¡è°ƒç”¨ BlockAlloctor.allocate_immutable_block(). å¦åˆ™è°ƒç”¨ BlockAlloctor.allocate_mutable_blocks() åˆ†é…ä¸€ä¸ªæ–°çš„ block åå°†åŸ blockçš„ token æ•°æ®è¿½åŠ åˆ°æ–° block.\nswap_out åŒä¸Šï¼Œæœ€ç»ˆè°ƒç”¨çš„æ˜¯ BlockAlloctor.swap_out(). è¯¥å‡½æ•°å¯¹ä¼ å…¥çš„æ¯ä¸ª block è°ƒç”¨ _free_block_idï¼Œé€ä¸ªå¤„ç†é‡Šæ”¾é€»è¾‘ã€‚è‹¥ block æœ‰å“ˆå¸Œå€¼ï¼Œrefcount -1ï¼Œè‹¥å‡å»åä¸º 0 åˆ™å°† block ä¿¡æ¯æ·»åŠ åˆ° evictor ä¸­ï¼Œä»è·Ÿè¸ªç³»ç»Ÿä¸­ç§»é™¤ï¼Œç„¶åè®¾ç½® BlockId ä¸º None. å¦åˆ™å°±ç›´æ¥è®¾ç½®ä¸º None. è‹¥æ— å“ˆå¸Œå€¼åˆ™é‡Šæ”¾ BlockIdï¼Œå‡å»å¯¹åº”çš„ refcountï¼Œä½†ä¿ç•™ block å¯¹è±¡æœ¬èº«.\nAttention XFormersImpl ä¸­ä½¿ç”¨äº† vllm è‡ªå·±å†™çš„ PagedAttention kernel.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class XFormersImpl(AttentionImpl[XFormersMetadata]): def __init__( self, num_heads: int, head_size: int, scale: float, num_kv_heads: int, alibi_slopes: Optional[List[float]], sliding_window: Optional[int], kv_cache_dtype: str, blocksparse_params: Optional[Dict[str, Any]] = None, logits_soft_cap: Optional[float] = None, attn_type: str = AttentionType.DECODER, ) -\u0026gt; None: å…¶ä¸­ attn_type åˆ†ä¸ºå››ç§ï¼Œä¸‹é¢æˆ‘ä»¬ä¸»è¦åˆ†æ DECODER çš„æƒ…å†µã€‚\nDECODER: ä½¿ç”¨ decoding å™¨çš„ self-attention block table æ¥Cache)KV(GPT). ENCODER: ä¸è¿›è¡Œ KV Cache)ç”¨äº Encoder-Decoder æ¨¡ç¼–ç å™¨åˆ†æ”¯ã€‚ç¼–ç å™¨é€šå¸¸ä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªè¾“å…¥ seq ã€‚ ENCODER-ONLY: ä¸è¿›è¡Œ KV Cache)BERT). ENCODER_DECODER: ç”¨äºç¼–ç å™¨- decoding å™¨æ¨¡å‹ä¸­çš„äº¤å‰æ³¨æ„åŠ›éƒ¨åˆ†ï¼Œå…¶ä¸­ KV seq é•¿åº¦ä¸ç¼–ç å™¨ seq é•¿åº¦ä¸€è‡´(T5). 1 2 3 4 5 6 7 8 9 10 def forward( self, layer: AttentionLayer, query: torch.Tensor, # [num_tokens, num_heads * head_size] key: Optional[torch.Tensor], # [num_tokens, num_kv_heads * head_size] value: Optional[torch.Tensor], # [num_tokens, num_kv_heads * head_size] kv_cache: torch.Tensor, # [2, num_blocks, block_size * num_kv_heads * head_size] attn_metadata: \u0026#34;XFormersMetadata\u0026#34;, output: Optional[torch.Tensor] = None, ) -\u0026gt; torch.Tensor: AttentionMetadata ç±»å®šä¹‰å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 @dataclass class AttentionMetadata: \u0026#34;\u0026#34;\u0026#34;Attention metadata for prefill and decode batched together.\u0026#34;\u0026#34;\u0026#34; num_prefills: int # prefill è¯·æ±‚çš„æ€»æ•° num_prefill_tokens: int # æ‰€æœ‰ prefill è¯·æ±‚ä¸­çš„ token æ€»æ•°ã€‚ num_decode_tokens: int # decodeing token çš„æ•°é‡ï¼Œç­‰åŒäº decoding è¯·æ±‚çš„æ•°é‡ slot_mapping: torch.Tensor # (num_tokens,)ï¼ŒæŒ‡å®šæ¯ä¸ªè¾“å…¥ token å­˜å‚¨åˆ° KV cache ä¸­çš„ slot ç´¢å¼• # block_idx = x // block_size, block_offset = x % block_size multi_modal_placeholder_index_maps: Optional[Dict[ str, MultiModalPlaceholderMap.IndexMap]] enable_kv_scales_calculation: bool forward æ–¹æ³•å¦‚ä¸‹ï¼Œç®€åŒ–äº†æˆäº† DECODER æƒ…å†µçš„é€»è¾‘ã€‚ ä¸»è¦æµç¨‹ä¸º\nè°ƒç”¨ PagedAttention.split_kv_cache åˆ†ç¦»å¹¶ reshape KV Cache å¼ é‡å è°ƒç”¨ PagedAttention.write_to_paged_cache` å†™å…¥å½“å‰ key å’Œ value åˆ°Cache)ã€‚ åˆ†ç¦» prefill å’Œ decoding çš„ tokenï¼Œåˆå§‹åŒ–è¾“å‡ºã€‚å¯¹äº prefill éƒ¨åˆ†æ ¹æ®æ˜¯å¦é‡‡ç”¨äº† prefix_caching è°ƒç”¨ self._run_memory_efficient_xformers_forward æˆ– PagedAttention.forward_prefix è®¡ç®—æ³¨æ„åŠ›ã€‚ è°ƒç”¨ get_seq_len_block_table_args è·å– decoding Sequence å¯¹åº”çš„ BlockTableåè°ƒç”¨ PagedAttention.forward_decode è®¡ç®—æ³¨æ„åŠ›ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def forward( self, layer: AttentionLayer, query: torch.Tensor, # [num_tokens, num_heads * head_size] key: torch.Tensor, # [num_tokens, num_kv_heads * head_size] value: torch.Tensor, # [num_tokens, num_kv_heads * head_size] kv_cache: torch.Tensor, # [2, num_blocks, block_size * num_kv_heads * head_size] attn_metadata: \u0026#34;XFormersMetadata\u0026#34;, output: Optional[torch.Tensor] = None, ) -\u0026gt; torch.Tensor: # å°† query é‡å¡‘ä¸º [num_tokens, num_heads, head_size] query = query.view(-1, self.num_heads, self.head_size) # key å’Œ value å¿…é¡»éç©ºï¼ˆè‡ªæ³¨æ„åŠ›è¦æ±‚ï¼‰ï¼Œé‡å¡‘ä¸º [num_tokens, num_kv_heads, head_size] key = key.view(-1, self.num_kv_heads, self.head_size) value = value.view(-1, self.num_kv_heads, self.head_size) # å¦‚æœ KV Cache)ç©ºï¼Œå¤„ç†Cache)è¾‘ if kv_cache.numel() \u0026gt; 0: # ä» kv_cache åˆ†ç¦»å‡º key_cache å’Œ value_cache # key_cache: [num_blocks, num_kv_heads, head_size/x, block_size, x] # value_cache: [num_blocks, num_kv_heads, head_size, block_size] key_cache, value_cache = PagedAttention.split_kv_cache( kv_cache, self.num_kv_heads, self.head_size) # æ›´æ–°è‡ªæ³¨æ„åŠ›çš„ KV Cache) # ä½¿ç”¨ attn_metadata.slot_mapping æŒ‡å®š token å­˜å‚¨ä½ç½® PagedAttention.write_to_paged_cache( key, value, key_cache, value_cache, attn_metadata.slot_mapping, self.kv_cache_dtype, layer._k_scale, layer._v_scale) # è·å– prefill å’Œ decoding é˜¶æ®µçš„ token æ•°é‡ (num_prefill_query_tokens, num_prefill_kv_tokens, num_decode_query_tokens) = \\ get_num_prefill_decode_query_kv_tokens(attn_metadata, AttentionType.DECODER) # åˆ›å»ºè¾“å‡ºå¼ é‡ä¸ query ç›¸åŒ output = torch.empty_like(query) # åˆ†ç¦» prefill å’Œ decoding çš„ QKV decode_query = query[num_prefill_query_tokens:] # query = query[:num_prefill_query_tokens] key = key[:num_prefill_kv_tokens] value = value[:num_prefill_kv_tokens] # å¤„ç† prefill é˜¶æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰ if prefill_meta := attn_metadata.prefill_metadata: if kv_cache.numel() == 0 or prefill_meta.block_tables.numel() == 0: # æ™®é€šæ³¨æ„åŠ›ï¼ˆæ— Cache)ç¼€ï¼‰ out = self._run_memory_efficient_xformers_forward( query, key, value, prefill_meta, attn_type=AttentionType.DECODER) output[:num_prefill_query_tokens] = out else: # å‰ç¼€Cache)æ„åŠ› out = PagedAttention.forward_prefix( query, key, value, self.kv_cache_dtype, key_cache, value_cache, prefill_meta.block_tables, prefill_meta.query_start_loc, prefill_meta.seq_lens_tensor, prefill_meta.max_query_len, self.alibi_slopes, self.sliding_window, layer._k_scale, layer._v_scale) output[:num_prefill_query_tokens] = out # å¤„ç† decoding é˜¶æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰ if decode_meta := attn_metadata.decode_metadata: # è·å– decoding æ‰€éœ€çš„ seq é•¿åº¦å’Œ BlockTable å‚æ•° seq_lens_arg, max_seq_len_arg, block_tables_arg = \\ get_seq_len_block_table_args(decode_meta, False, AttentionType.DECODER) # è¿è¡Œ decoding æ³¨æ„åŠ› output[num_prefill_query_tokens:] = PagedAttention.forward_decode( decode_query, key_cache, value_cache, block_tables_arg, seq_lens_arg, max_seq_len_arg, self.kv_cache_dtype, self.num_kv_heads, self.scale, self.alibi_slopes, layer._k_scale, layer._v_scale) # å°†è¾“å‡º reshape ä¸º [num_tokens, num_heads * head_size] return output.view(-1, self.num_heads * self.head_size) write_to_paged_cache è°ƒç”¨çš„æ˜¯å·²ç»æ³¨å†Œåˆ° torch.ops ä¸­çš„ CUDA å‡½æ•°ã€‚å…¶å¯¹åº”çš„ host å‡½æ•°ä¸ºæ¯ä¸ª token åˆ†é…ä¸€ä¸ª CUDA blockï¼Œæ¯ä¸ª CUDA block çš„çº¿ç¨‹æ•°è¢«é™åˆ¶åœ¨æœ€å¤š 512 ä¸ªã€‚ä¸»è¦çš„ kernel å‡½æ•°å¦‚ä¸‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 // scalar_t: è¾“å…¥ key å’Œ value çš„æ•°æ®ç±»å‹ï¼ˆå¦‚ floatã€halfï¼‰ // cache_t: Cache)key_cache å’Œ value_cache çš„æ•°æ®ç±»å‹ï¼ˆå¦‚ halfã€uint8_tï¼‰ // kv_dt: KV Cache) FP8 æ•°æ®ç±»å‹ï¼ˆå¦‚ kAuto æˆ–å…·ä½“ FP8 æ ¼å¼ï¼‰ template \u0026lt;typename scalar_t, typename cache_t, Fp8KVCacheDataType kv_dt\u0026gt; __global__ void reshape_and_cache_kernel( const scalar_t* __restrict__ key, // [num_tokens, num_heads, head_size] const scalar_t* __restrict__ value, // [num_tokens, num_heads, head_size] cache_t* __restrict__ key_cache, // [num_blocks, num_heads, head_size/x, block_size, x] cache_t* __restrict__ value_cache, // [num_blocks, num_heads, head_size, block_size] const int64_t* __restrict__ slot_mapping, // [num_tokens]ï¼ŒæŒ‡å®šæ¯ä¸ª token çš„Cache)ç½® const int key_stride, const int value_stride, // key å’Œ value åœ¨ token ç»´çš„æ­¥å¹… const int num_heads, const int head_size, // æ³¨æ„åŠ›head æ•°å’Œæ¯ä¸ªhead çš„ç»´åº¦ const int block_size, const int x, // Cache)å¤§å°å’Œ key_cache ä¸­ head_size çš„æ‹†åˆ†å› å­ const float* k_scale, const float* v_scale) // key å’Œ value çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ•°æ®ç±»å‹è½¬æ¢ const int64_t token_idx = blockIdx.x; // host å‡½æ•°å®šä¹‰ block ä¸ªæ•°ä¸ token ä¸ªæ•°ç›¸åŒ const int64_t slot_idx = slot_mapping[token_idx]; { // Cache Block const int64_t block_idx = slot_idx / block_size; // å—ç´¢å¼• const int64_t block_offset = slot_idx % block_size; // å—å†…åç§» const int n = num_heads * head_size; // æ¯ä¸ª token çš„ç»´åº¦æ•°ç›® // CUDA Block çº§åˆ«å¹¶è¡Œï¼Œæ¯ä¸ªçº¿ç¨‹å¤„ç†token çš„ä¸€ä¸ªç»´åº¦ for (int i = threadIdx.x; i \u0026lt; n; i += blockDim.x) { // è®¡ç®—è¾“å…¥ key å’Œ value çš„æºç´¢å¼• const int64_t src_key_idx = token_idx * key_stride + i; const int64_t src_value_idx = token_idx * value_stride + i; // è®¡ç®—å½“å‰å¤„ç†çš„head ç´¢å¼•å’Œhead å†…åç§» const int head_idx = i / head_size; // ç¬¬å‡ ä¸ªhead const int head_offset = i % head_size; // head å†…çš„ç¬¬å‡ ä¸ªå…ƒç´  // å°† head_offset æ‹†åˆ†ä¸º x_idx å’Œ x_offsetï¼ˆä»…ç”¨äº key_cacheï¼‰ const int x_idx = head_offset / x; // head_size/x ç»´çš„ç´¢å¼• const int x_offset = head_offset % x; // x ç»´çš„åç§» // è®¡ç®— key_cache çš„ç›®æ ‡ç´¢å¼•ï¼ŒæŒ‰ç»´åº¦é€æ­¥åç§» const int64_t tgt_key_idx = block_idx * num_heads * (head_size / x) * block_size * x + // å—åç§» head_idx * (head_size / x) * block_size * x + // head åç§» x_idx * block_size * x + // head_size/x åç§» block_offset * x + x_offset; // å—å†…å’Œ x åç§» // è®¡ç®— value_cache çš„ç›®æ ‡ç´¢å¼•ï¼ŒæŒ‰ç»´åº¦é€æ­¥åç§» const int64_t tgt_value_idx = block_idx * num_heads * head_size * block_size + // å—åç§» head_idx * head_size * block_size + // head åç§» head_offset * block_size + // head_size åç§» block_offset; // å—å†…åç§» // ä»è¾“å…¥å¼ é‡è¯»å–å½“å‰å…ƒç´  scalar_t tgt_key = key[src_key_idx]; scalar_t tgt_value = value[src_value_idx]; // æ ¹æ® kv_dt ç±»å‹å†³å®šå­˜å‚¨æ–¹å¼ if constexpr (kv_dt == Fp8KVCacheDataType::kAuto) { // å¦‚æœæ˜¯ kAutoï¼Œç›´æ¥å­˜å‚¨ï¼Œä¸è¿›è¡Œç±»å‹è½¬æ¢ key_cache[tgt_key_idx] = tgt_key; value_cache[tgt_value_idx] = tgt_value; } else { // å¦åˆ™ï¼Œä½¿ç”¨ scaled_convert è¿›è¡Œç±»å‹è½¬æ¢ï¼ˆå¦‚ FP8 é‡åŒ–ï¼‰ key_cache[tgt_key_idx] = fp8::scaled_convert\u0026lt;cache_t, scalar_t, kv_dt\u0026gt;(tgt_key, *k_scale); value_cache[tgt_value_idx] = fp8::scaled_convert\u0026lt;cache_t, scalar_t, kv_dt\u0026gt;(tgt_value, *v_scale); } } } _run_memory_efficient_xformers_forward ä¹ŸåŒæ ·ç®€åŒ–æˆ DECODER çš„é€»è¾‘çš„æƒ…å†µ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def _run_memory_efficient_xformers_forward( self, query: torch.Tensor, # [num_prefill_tokens, num_heads, head_size] key: torch.Tensor, # [num_prefill_tokens, num_kv_heads, head_size] value: torch.Tensor, # [num_prefill_tokens, num_kv_heads, head_size] attn_metadata: \u0026#34;XFormersMetadata\u0026#34;, ) -\u0026gt; torch.Tensor: original_query = query # ä¿å­˜åŸå§‹ queryï¼Œç”¨äºæœ€å reshape è¾“å‡º # å¤„ç† GQA/MQA if self.num_kv_heads != self.num_heads: # reshape Q to [num_prefill_tokens, num_kv_heads, num_queries_per_kv, head_size] query = query.view(query.shape[0], self.num_kv_heads, self.num_queries_per_kv, query.shape[-1]) # expand K to [num_prefill_tokens, num_kv_heads, num_queries_per_kv, head_size] key = key[:, :, None, :].expand(key.shape[0], self.num_kv_heads, self.num_queries_per_kv, key.shape[-1]) # expand V to [num_prefill_tokens, num_kv_heads, num_queries_per_kv, head_size] value = value[:, :, None, :].expand(value.shape[0], self.num_kv_heads, self.num_queries_per_kv, value.shape[-1]) # è·å–æˆ–è®¾ç½® attention bias attn_bias = _get_attn_bias(attn_metadata, AttentionType.DECODER) if attn_bias is None: assert attn_metadata.seq_lens is not None # ç¡®ä¿ seq é•¿åº¦ä¿¡æ¯å­˜åœ¨ if self.alibi_slopes is None: # åˆ›å»º causal mask attn_bias = BlockDiagonalCausalMask.from_seqlens( attn_metadata.seq_lens, device=query.device) if self.sliding_window is not None: # å¦‚æœæœ‰æ»‘åŠ¨çª—å£ï¼Œåº”ç”¨å±€éƒ¨æ³¨æ„åŠ› attn_bias = attn_bias.make_local_attention(self.sliding_window) attn_bias = [attn_bias] else: # ä½¿ç”¨ ALiBi åç½®ï¼ˆçº¿æ€§åç½®æ³¨æ„åŠ›ï¼‰ attn_bias = _make_alibi_bias(self.alibi_slopes, self.num_kv_heads, query.dtype, attn_metadata.seq_lens) _set_attn_bias(attn_metadata, attn_bias, AttentionType.DECODER) # æ‰§è¡Œ xFormers é«˜æ•ˆæ³¨æ„åŠ›è®¡ç®— if self.alibi_slopes is None: # ä¸º QKV æ·»åŠ  batch query = query.unsqueeze(0) key = key.unsqueeze(0) value = value.unsqueeze(0) out = xops.memory_efficient_attention_forward( query, key, value, attn_bias=attn_bias[0], p=0.0, scale=self.scale) else: # ALiBi æ¨¡å¼ç›´æ¥ä½¿ç”¨ attn_bias assert attn_metadata.seq_lens is not None output = torch.empty_like(original_query) start = 0 # xformers ä¸æ”¯æŒåœ¨è‡ªå®šä¹‰ bias çš„æƒ…å†µä¸‹æ¯ä¸ª seq çš„é•¿åº¦ä¸åŒ for i, seq_len in enumerate(attn_metadata.seq_lens): end = start + seq_len out = xops.memory_efficient_attention_forward( query[None, start:end], key[None, start:end], value[None, start:end], attn_bias=attn_bias[i], p=0.0, scale=self.scale) output[start:end].copy_(out.view_as(original_query[start:end])) start += seq_len # å°†è¾“å‡º reshape ä¸ºåŸå§‹ query return out.view_as(original_query) forward_prefix ä¸è€ƒè™‘ ALiBi çš„æƒ…å†µè°ƒç”¨çš„æ˜¯ triton ç¼–å†™çš„ _fwd_kernel() æ¯ä¸ªçº¿ç¨‹å—ç‹¬ç«‹å¤„ç†ä¸€ä¸ª Q çš„ä¸€éƒ¨åˆ†ï¼Œå¯¹ KV Cache å’Œ å½“å‰ KV åˆ†åˆ«é‡‡å– flash-attention çš„è®¡ç®—ç­–ç•¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 import triton import triton.language as tl @triton.jit def _fwd_kernel( # --- è¾“å…¥å¼ é‡ --- Q, # Query å¼ é‡: [total_seq_len, num_heads, head_dim] # total_seq_len æ˜¯æ‰€æœ‰ batch seq é•¿åº¦çš„æ€»å’Œï¼Œå½“å‰å—ä¸º [BLOCK_M, BLOCK_DMODEL_PADDED] K, # é”®å¼ é‡ï¼ˆå½“å‰è¾“å…¥ï¼‰: [total_seq_len, num_kv_heads, head_dim] V, # å€¼å¼ é‡ï¼ˆå½“å‰è¾“å…¥ï¼‰: [total_seq_len, num_kv_heads, head_dim] K_cache, # é”®Cache) [num_blocks, num_kv_heads, head_dim, block_size, x] # ç”¨äºå­˜å‚¨ä¸Šä¸‹æ–‡éƒ¨åˆ†çš„ K V_cache, # å€¼Cache) [num_blocks, num_kv_heads, head_dim, block_size] # ç”¨äºå­˜å‚¨ä¸Šä¸‹æ–‡éƒ¨åˆ†çš„ V B_Loc, # å—ç´¢å¼•è¡¨: [batch_size, max_seq_len // block_size] # è®°å½•æ¯ä¸ª batch ä¸­æ¯ä¸ªå—çš„å—ç¼–å· sm_scale, # softmax ç¼©æ”¾å› å­ï¼Œé€šå¸¸ä¸º 1/sqrt(head_dim) k_scale, # ç”¨äº FP8 ç²¾åº¦è½¬æ¢çš„ç¼©æ”¾å› å­ v_scale, # ç”¨äº FP8 ç²¾åº¦è½¬æ¢çš„ç¼©æ”¾å› å­ B_Start_Loc, # batch èµ·å§‹ä½ç½®: [batch_size + 1] # æ¯ä¸ª batch çš„å…¨å±€ seq èµ·å§‹ç´¢å¼•ï¼Œæœ€åä¸€ä¸ªå…ƒç´ æ˜¯æ€»é•¿åº¦ B_Seqlen, # batch seq é•¿åº¦: [batch_size] # æ¯ä¸ª batch çš„æ€» seq é•¿åº¦ï¼ˆä¸Šä¸‹æ–‡ + Query ï¼‰ block_size, # æ¯ä¸ªCache)çš„å¤§å° x, # K_cache çš„é¢å¤–ç»´åº¦åˆ†ç‰‡å› å­ï¼ˆé€šå¸¸ä¸º 1 æˆ–å°æ•´æ•°ï¼‰ Out, # è¾“å‡ºå¼ é‡: [total_seq_len, num_heads, head_dim] # å­˜å‚¨æ³¨æ„åŠ›è®¡ç®—ç»“æœ # --- æ­¥å¹…å‚æ•° --- stride_b_loc_b, # B_Loc çš„ batch æ­¥å¹… stride_b_loc_s, # B_Loc çš„ seq å—æ­¥å¹… stride_qbs, # Q çš„ batch / seq æ­¥å¹…ï¼Œé€šå¸¸ä¸º num_heads * head_dim stride_qh, # Q çš„head æ­¥å¹…ï¼Œé€šå¸¸ä¸º head_dim stride_qd, # Q çš„head_sizeæ­¥å¹…ï¼Œé€šå¸¸ä¸º 1 stride_kbs, # K çš„ batch / seq æ­¥å¹… stride_kh, # K çš„head æ­¥å¹… stride_kd, # K çš„head_sizeæ­¥å¹… stride_vbs, # V çš„ batch / seq æ­¥å¹… stride_vh, # V çš„head æ­¥å¹… stride_vd, # V çš„head_sizeæ­¥å¹… stride_obs, # Out çš„ batch / seq æ­¥å¹… stride_oh, # Out çš„head æ­¥å¹… stride_od, # Out çš„head_sizeæ­¥å¹… stride_k_cache_bs, # K_cache çš„å—æ­¥å¹… stride_k_cache_h, # K_cache çš„head æ­¥å¹… stride_k_cache_d, # K_cache çš„head_sizeæ­¥å¹… stride_k_cache_bl, # K_cache çš„å—å†…åç§»æ­¥å¹… stride_k_cache_x, # K_cache çš„é¢å¤–ç»´åº¦æ­¥å¹… stride_v_cache_bs, # V_cache çš„å—æ­¥å¹… stride_v_cache_h, # V_cache çš„head æ­¥å¹… stride_v_cache_d, # V_cache çš„head_sizeæ­¥å¹… stride_v_cache_bl, # V_cache çš„å—å†…åç§»æ­¥å¹… # --- è¶…å‚æ•° --- num_queries_per_kv: int, # æ¯ä¸ª KV head å¯¹åº”çš„ Query head æ•°é‡ IN_PRECISION: tl.constexpr, # è¾“å…¥ç²¾åº¦ï¼ˆä¾‹å¦‚ tl.float32ï¼‰ BLOCK_M: tl.constexpr, # Query å—å¤§å° BLOCK_DMODEL: tl.constexpr, # head ç»´åº¦å¤§å° BLOCK_DMODEL_PADDED: tl.constexpr, # head ç»´åº¦å¡«å……åˆ° 2 çš„å¹‚æ¬¡ BLOCK_N: tl.constexpr, # KV å—å¤§å° SLIDING_WINDOW: tl.constexpr, # æ»‘åŠ¨çª—å£å¤§å°ï¼Œ0 è¡¨ç¤ºæ— çª—å£ SKIP_DECODE: tl.constexpr, # æ˜¯å¦è·³è¿‡è§£ç ï¼ˆä»…å¤„ç†ä¸Šä¸‹æ–‡ï¼‰ ): # --- ç½‘æ ¼å®šä¹‰ --- # grid = (batch_size, num_heads, max_seq_len // BLOCK_M) cur_batch = tl.program_id(0) # å½“å‰ batch ç´¢å¼• cur_head = tl.program_id(1) # å½“å‰head ç´¢å¼• start_m = tl.program_id(2) # å½“å‰ Query å—ç´¢å¼• # --- è®¡ç®— KV head ç´¢å¼• --- cur_kv_head = cur_head // num_queries_per_kv # å½“å‰ KV head ç´¢å¼• # --- åŠ è½½ batch ä¿¡æ¯ --- cur_batch_seq_len = tl.load(B_Seqlen + cur_batch) # å½“å‰ batch æ€» seq é•¿åº¦ cur_batch_in_all_start_index = tl.load(B_Start_Loc + cur_batch) # å½“å‰ batch å…¨å±€èµ·å§‹ç´¢å¼• cur_batch_in_all_stop_index = tl.load(B_Start_Loc + cur_batch + 1) # ä¸‹ä¸€ batch èµ·å§‹ç´¢å¼• cur_batch_query_len = (cur_batch_in_all_stop_index - cur_batch_in_all_start_index) # å½“å‰ batch Query é•¿åº¦ cur_batch_ctx_len = cur_batch_seq_len - cur_batch_query_len # ä¸Šä¸‹æ–‡é•¿åº¦ # --- è®¡ç®— Query å—èµ·å§‹ä½ç½® --- block_start_loc = BLOCK_M * start_m # å½“å‰ Query å—çš„èµ·å§‹ä½ç½® # --- åˆå§‹åŒ–ç´¢å¼•èŒƒå›´ --- offs_n = tl.arange(0, BLOCK_N) # KV å—å†…åç§»: [0, BLOCK_N) offs_d = tl.arange(0, BLOCK_DMODEL_PADDED) # head_size åç§»: [0, BLOCK_DMODEL_PADDED) offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M) # Query å—å†…åç§»: [start_m * BLOCK_M, (start_m + 1) * BLOCK_M) # --- è®¡ç®— Q çš„åç§»é‡ --- # off_q: [BLOCK_M, BLOCK_DMODEL_PADDED] # å®šä½å½“å‰ Query å—åœ¨ Q å¼ é‡ä¸­çš„å†…å­˜åœ°å€ off_q = ( (cur_batch_in_all_start_index + offs_m[:, None]) * stride_qbs + # batch å’Œ seq åç§» cur_head * stride_qh + # head åç§» offs_d[None, :] * stride_qd # head_sizeåç§» ) # ç¤ºä¾‹: å‡è®¾ Q [100, 4, 64], stride_qbs=256, stride_qh=64, stride_qd=1 # cur_batch_in_all_start_index=20, cur_head=1, start_m=1, BLOCK_M=16 # offs_m=[16, 17, ..., 31], offs_d=[0, 1, ..., 63] # off_q[0, 0] = (20 + 16) * 256 + 1 * 64 + 0 * 1 = 9216 + 64 = 9280 # off_q[0, 1] = (20 + 16) * 256 + 1 * 64 + 1 * 1 = 9281 # --- åˆ›å»ºhead_sizeç»´åº¦æ©ç  --- dim_mask = tl.where(tl.arange(0, BLOCK_DMODEL_PADDED) \u0026lt; BLOCK_DMODEL, 1, 0).to(tl.int1) # [BLOCK_DMODEL_PADDED] # å±è”½å¡«å……éƒ¨åˆ†ï¼Œä¾‹å¦‚ BLOCK_DMODEL=64, BLOCK_DMODEL_PADDED=128ï¼Œåˆ™å 64 ä¸ªå€¼ä¸º 0 # --- åŠ è½½ Q æ•°æ® --- q = tl.load(Q + off_q, mask=dim_mask[None, :] \u0026amp; (offs_m[:, None] \u0026lt; cur_batch_query_len), other=0.0) # [BLOCK_M, BLOCK_DMODEL_PADDED] # åŠ è½½å½“å‰ Query å—ï¼Œæ©ç ç¡®ä¿ä¸åŠ è½½è¶…å‡º Query é•¿åº¦å’Œå¡«å……ç»´åº¦çš„æ•°æ® # --- åˆå§‹åŒ–online softmax å˜é‡ --- m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\u0026#34;inf\u0026#34;) # æœ€å¤§å€¼ l_i = tl.zeros([BLOCK_M], dtype=tl.float32) # å½’ä¸€åŒ–å› å­ acc = tl.zeros([BLOCK_M, BLOCK_DMODEL_PADDED], dtype=tl.float32) # æ³¨æ„åŠ›ç´¯åŠ  # --- è®¡ç®—ä¸Šä¸‹æ–‡æ³¨æ„åŠ›ï¼ˆQ å¯¹ KV Cache) --- for start_n in range(0, cur_batch_ctx_len, BLOCK_N): start_n = tl.multiple_of(start_n, BLOCK_N) # ç¡®ä¿ start_n æ˜¯ BLOCK_N çš„å€æ•° # --- åŠ è½½ Cache ç´¢å¼• --- bn = tl.load(B_Loc + cur_batch * stride_b_loc_b + ((start_n + offs_n) // block_size) * stride_b_loc_s, mask=(start_n + offs_n) \u0026lt; cur_batch_ctx_len, other=0) # [BLOCK_N] # bn æ˜¯å½“å‰ KV Cacheçš„å—ç¼–å· # ç¤ºä¾‹: B_Loc=[0, 1, 2, ...], cur_batch=0, start_n=16, block_size=16, offs_n=[0, 1, 2, 3] # bn = B_Loc[0, 1]ï¼ˆè‹¥ stride_b_loc_b=8, stride_b_loc_s=1ï¼Œåˆ™åœ°å€ä¸º 0*8 + 1*1 = 1ï¼‰ # --- è®¡ç®— K_cache åç§»é‡ --- # off_k: [BLOCK_DMODEL_PADDED, BLOCK_N] off_k = ( bn[None, :] * stride_k_cache_bs + # å—åç§» cur_kv_head * stride_k_cache_h + # head åç§» (offs_d[:, None] // x) * stride_k_cache_d + # head_sizeåç§»ï¼ˆåˆ†ç‰‡ï¼‰ ((start_n + offs_n[None, :]) % block_size) * stride_k_cache_bl + # å—å†…åç§» (offs_d[:, None] % x) * stride_k_cache_x # é¢å¤–ç»´åº¦åç§» ) # ç¤ºä¾‹: bn=[1], cur_kv_head=1, stride_k_cache_bs=4096, stride_k_cache_h=1024, stride_k_cache_d=16 # offs_d=[0, 1, ..., 63], start_n=16, offs_n=[0, 1, 2, 3], block_size=16, x=1 # off_k[0, 0] = 1*4096 + 1*1024 + (0//1)*16 + (16+0)%16*256 + (0%1)*1 = 4096 + 1024 = 5120 # --- åŠ è½½ K_cache æ•°æ® --- k_load = tl.load(K_cache + off_k, mask=dim_mask[:, None] \u0026amp; ((start_n + offs_n[None, :]) \u0026lt; cur_batch_ctx_len), other=0.0) # [BLOCK_DMODEL_PADDED, BLOCK_N] # å¤„ç† FP8 ç²¾åº¦ if k_load.dtype.is_fp8(): k = (k_load.to(tl.float32) * tl.load(k_scale)).to(q.dtype) else: k = k_load # --- è®¡ç®— QK æ³¨æ„åŠ›åˆ†æ•° --- qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32) qk = tl.dot(q, k, acc=qk, input_precision=IN_PRECISION) # [BLOCK_M, BLOCK_N] qk = tl.where((start_n + offs_n[None, :]) \u0026lt; cur_batch_ctx_len, qk, float(\u0026#34;-inf\u0026#34;)) qk *= sm_scale if SLIDING_WINDOW \u0026gt; 0: qk = tl.where((cur_batch_ctx_len + offs_m[:, None]) - (start_n + offs_n[None, :]) \u0026lt; SLIDING_WINDOW, qk, -10000) # --- online softmax æ›´æ–° --- m_ij = tl.max(qk, 1) # [BLOCK_M] p = tl.exp(qk - m_ij[:, None]) # [BLOCK_M, BLOCK_N] l_ij = tl.sum(p, 1) # [BLOCK_M] m_i_new = tl.maximum(m_i, m_ij) alpha = tl.exp(m_i - m_i_new) beta = tl.exp(m_ij - m_i_new) l_i_new = alpha * l_i + beta * l_ij # --- æ›´æ–°ç´¯åŠ å™¨ --- p_scale = beta / l_i_new p = p * p_scale[:, None] acc_scale = l_i / l_i_new * alpha acc = acc * acc_scale[:, None] # åŠ è½½ V_cache off_v = ( bn[:, None] * stride_v_cache_bs + cur_kv_head * stride_v_cache_h + offs_d[None, :] * stride_v_cache_d + (start_n + offs_n[:, None]) % block_size * stride_v_cache_bl ) v_load = tl.load(V_cache + off_v, mask=dim_mask[None, :] \u0026amp; ((start_n + offs_n[:, None]) \u0026lt; cur_batch_ctx_len), other=0.0) # [BLOCK_N, BLOCK_DMODEL_PADDED] if v_load.dtype.is_fp8(): v = (v_load.to(tl.float32) * tl.load(v_scale)).to(q.dtype) else: v = v_load p = p.to(v.dtype) acc = tl.dot(p, v, acc=acc, input_precision=IN_PRECISION) # æ›´æ–° m_i å’Œ l_i l_i = l_i_new m_i = m_i_new # --- è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼ˆQ å¯¹å½“å‰ K å’Œ Vï¼‰ --- # è®¡ç®— K å’Œ V çš„åˆå§‹åç§» off_k = (offs_n[None, :] * stride_kbs + cur_kv_head * stride_kh + offs_d[:, None] * stride_kd) # [BLOCK_DMODEL_PADDED, BLOCK_N] off_v = (offs_n[:, None] * stride_vbs + cur_kv_head * stride_vh + offs_d[None, :] * stride_vd) # [BLOCK_N, BLOCK_DMODEL_PADDED] k_ptrs = K + off_k # åˆå§‹æŒ‡é’ˆ v_ptrs = V + off_v # æ£€æŸ¥å½“å‰ Query å—æ˜¯å¦æœ‰æ•ˆ block_mask = tl.where(block_start_loc \u0026lt; cur_batch_query_len, 1, 0) # éå†å½“å‰è¾“å…¥çš„ K å’Œ V for start_n in range(0, block_mask * (start_m + 1) * BLOCK_M, BLOCK_N): start_n = tl.multiple_of(start_n, BLOCK_N) # --- åŠ è½½ K æ•°æ® --- # å…¨å±€åç§»: (cur_batch_in_all_start_index + start_n) * stride_kbs å®šä½ batch å’Œ seq å— # ç¤ºä¾‹: K [100, 4, 64], stride_kbs=256, cur_batch_in_all_start_index=20, start_n=8 # åŸºåœ°å€åç§» = (20 + 8) * 256 = 7168 # k_ptrs[0, 0] = K + 0 + 1*64 + 0*1 + 7168 = K + 7232 k = tl.load(k_ptrs + (cur_batch_in_all_start_index + start_n) * stride_kbs, mask=dim_mask[:, None] \u0026amp; ((start_n + offs_n[None, :]) \u0026lt; cur_batch_query_len), other=0.0) # [BLOCK_DMODEL_PADDED, BLOCK_N] # --- è®¡ç®— QK æ³¨æ„åŠ›åˆ†æ•° --- qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32) qk = tl.dot(q, k, acc=qk, input_precision=IN_PRECISION) qk *= sm_scale # åº”ç”¨å› æœæ©ç  qk = tl.where(offs_m[:, None] \u0026gt;= (start_n + offs_n[None, :]), qk, float(\u0026#34;-inf\u0026#34;)) if SLIDING_WINDOW \u0026gt; 0: qk = tl.where(offs_m[:, None] - (start_n + offs_n[None, :]) \u0026lt; SLIDING_WINDOW, qk, -10000) # --- online softmax æ›´æ–° --- m_ij = tl.max(qk, 1) p = tl.exp(qk - m_ij[:, None]) l_ij = tl.sum(p, 1) m_i_new = tl.maximum(m_i, m_ij) alpha = tl.exp(m_i - m_i_new) beta = tl.exp(m_ij - m_i_new) l_i_new = alpha * l_i + beta * l_ij # --- æ›´æ–°ç´¯åŠ å™¨ --- p_scale = beta / l_i_new p = p * p_scale[:, None] acc_scale = l_i / l_i_new * alpha acc = acc * acc_scale[:, None] v = tl.load(v_ptrs + (cur_batch_in_all_start_index + start_n) * stride_vbs, mask=dim_mask[None, :] \u0026amp; ((start_n + offs_n[:, None]) \u0026lt; cur_batch_query_len), other=0.0) # [BLOCK_N, BLOCK_DMODEL_PADDED] p = p.to(v.dtype) acc = tl.dot(p, v, acc=acc, input_precision=IN_PRECISION) # æ›´æ–° m_i å’Œ l_i l_i = l_i_new m_i = m_i_new # --- å­˜å‚¨è¾“å‡º --- off_o = ( (cur_batch_in_all_start_index + offs_m[:, None]) * stride_obs + cur_head * stride_oh + offs_d[None, :] * stride_od ) out_ptrs = Out + off_o tl.store(out_ptrs, acc, mask=dim_mask[None, :] \u0026amp; (offs_m[:, None] \u0026lt; cur_batch_query_len)) forward_decode è°ƒç”¨çš„æ˜¯ paged_atention_kernel gridDim = (num_heads, num_seqs, 1). decode çš„æ—¶å€™æ¯ä¸ª seq çš„ Query çš„ toekn æ•°ç›®éƒ½æ˜¯ 1ï¼Œ\ngridDim = (num_heads, num_seqs, 1): æ¯ä¸ªçº¿ç¨‹å—è´Ÿè´£ä¸€ä¸ª seq çš„ ä¸€ä¸ª headï¼Œå‡½æ•°å®šä¹‰å¦‚ä¸‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 template \u0026lt;typename scalar_t, typename cache_t, int HEAD_SIZE, int BLOCK_SIZE, // default 16 int NUM_THREADS /*=128*/, vllm::Fp8KVCacheDataType KV_DTYPE, bool IS_BLOCK_SPARSE, int PARTITION_SIZE = 0\u0026gt; // Zero means no partitioning. __device__ void paged_attention_kernel( float* __restrict__ exp_sums, // [num_seqs, num_heads, max_num_partitions] float* __restrict__ max_logits, // [num_seqs, num_heads, // max_num_partitions] scalar_t* __restrict__ out, // [num_seqs, num_heads, max_num_partitions, head_size] const scalar_t* __restrict__ q, // [num_seqs, num_heads, head_size] const cache_t* __restrict__ k_cache, // [num_blocks, num_kv_heads, head_size/x, block_size, x] const cache_t* __restrict__ v_cache, // [num_blocks, num_kv_heads, head_size, block_size] const int num_kv_heads, // [num_heads] const float scale, const int* __restrict__ block_tables, // [num_seqs, max_num_blocks_per_seq] const int* __restrict__ seq_lens, // [num_seqs] const int max_num_blocks_per_seq, const float* __restrict__ alibi_slopes, // [num_heads] // çŸ©é˜µæ¯ä¸€ç»´åº¦çš„ strideï¼Œä¾¿äºç§»åŠ¨æŒ‡é’ˆ const int q_stride, const int kv_block_stride, const int kv_head_stride, const float* k_scale, const float* v_scale, const int tp_rank, const int blocksparse_local_blocks, const int blocksparse_vert_stride, const int blocksparse_block_size, const int blocksparse_head_sliding_step) é¦–å…ˆå…ˆè®¡ç®—ä¸€ä¸‹å½“å‰çº¿ç¨‹å¯¹åº”çš„å„ç§å‚æ•°ï¼Œè¿™é‡Œæ ¹æ®æ¨¡æ¿å‡½æ•°å®šä¹‰ä¸ä½¿ç”¨ PARTITIONING.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // grid = (num_heads, num_seqs, 1) ä¸€ä¸ª thread block å¤„ç†ä¸€ä¸ª seq çš„ ä¸€ä¸ª head const int seq_idx = blockIdx.y; const int partition_idx = blockIdx.z; const int max_num_partitions = gridDim.z; // 1 const int seq_len = seq_lens[seq_idx]; // è¯¥ seq token æ•° // è®¡ç®—å—èŒƒå›´å’Œ token èŒƒå›´ const int num_seq_blocks = DIVIDE_ROUND_UP(seq_len, BLOCK_SIZE); // seq è¦åˆ†å‡ å—è¯»å– const int num_blocks_per_partition = num_seq_blocks; // åˆ†äº†å‡ å— const int start_block_idx = 0; // èµ·å§‹å—ç´¢å¼• const int end_block_idx = num_seq_blocks; // ç»“æŸå—ç´¢å¼• const int num_blocks = end_block_idx - start_block_idx; // å½“å‰åˆ†åŒºå—æ•° const int start_token_idx = start_block_idx * BLOCK_SIZE; // èµ·å§‹ token ç´¢å¼• const int end_token_idx = MIN(start_token_idx + num_blocks * BLOCK_SIZE, seq_len); // ç»“æŸ token ç´¢å¼• const int num_tokens = end_token_idx - start_token_idx; // å½“å‰åˆ†åŒº token æ•° // çº¿ç¨‹ç»„ç»‡å‚æ•° constexpr int THREAD_GROUP_SIZE = MAX(WARP_SIZE / BLOCK_SIZE, 1); // å‡ ä¸ª thread å¤„ç†ä¸€ä¸ª token 32/16=2 constexpr int NUM_THREAD_GROUPS = NUM_THREADS / THREAD_GROUP_SIZE; // ä¸€ä¸ª thread block è¢«åˆ†æˆå‡ ç»„ 128/2=64 constexpr int NUM_TOKENS_PER_THREAD_GROUP = DIVIDE_ROUND_UP(BLOCK_SIZE, WARP_SIZE); // æ¯çº¿ç¨‹å¤„ç†çš„ token æ•° 16/32=1 constexpr int NUM_WARPS = NUM_THREADS / WARP_SIZE; // warp ä¸ªæ•° 128/32=4 const int thread_idx = threadIdx.x; // çº¿ç¨‹ç´¢å¼• const int warp_idx = thread_idx / WARP_SIZE; // çº¿ç¨‹ä½äºç¬¬å‡ ä¸ª warp const int lane = thread_idx % WARP_SIZE; // çº¿ç¨‹æ˜¯è¯¥ warp ä¸­çš„ç¬¬å‡ ä¸ª const int head_idx = blockIdx.x; const int num_heads = gridDim.x; // è€ƒè™‘ GQA MQA const int num_queries_per_kv = num_heads / num_kv_heads; const int kv_head_idx = head_idx / num_queries_per_kv; const float alibi_slope = alibi_slopes == nullptr ? 0.f : alibi_slopes[head_idx]; å®šä¹‰ thread group ï¼Œä¿è¯å…¶ä¸€æ¬¡è®¿é—®çš„æ•°æ®ä¸º 16 Bytesï¼Œéœ€è¦è®¡ç®—å…¶ä¸­æ¯ä¸ª thread å¤„ç†å‡ ä¸ªå…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 // VEC_SIZE å³ä¸ºä¸€ä¸ª thread group ä¸­æ¯ä¸ªçº¿ç¨‹éœ€è¦å¤„ç†å…ƒç´ ä¸ªæ•°ï¼Œ constexpr int VEC_SIZE = MAX(16 / (THREAD_GROUP_SIZE * sizeof(scalar_t)), 1); // 16/2/2=4 using K_vec = typename Vec\u0026lt;scalar_t, VEC_SIZE\u0026gt;::Type; using Q_vec = typename Vec\u0026lt;scalar_t, VEC_SIZE\u0026gt;::Type; using Quant_vec = typename Vec\u0026lt;cache_t, VEC_SIZE\u0026gt;::Type; constexpr int NUM_ELEMS_PER_THREAD = HEAD_SIZE / THREAD_GROUP_SIZE; // æ¯ä¸ª thread å¤„ç†å‡ ä¸ªå…ƒç´  64/2=32 constexpr int NUM_VECS_PER_THREAD = NUM_ELEMS_PER_THREAD / VEC_SIZE; // è¿™å‡ ä¸ªå…ƒç´ ç›¸å½“äºå‡ ä¸ªå‘é‡ 32/4=8 // thread_idx = thread_group_idx * THREAD_GROUP_SIZE + thread_group_offset const int thread_group_idx = thread_idx / THREAD_GROUP_SIZE; // çº¿ç¨‹ä½äºç¬¬å‡ ä¸ª thread group const int thread_group_offset = thread_idx % THREAD_GROUP_SIZE; // çº¿ç¨‹æ˜¯è¯¥ thread group ä¸­ç¬¬å‡ ä¸ªçº¿ç¨‹ ä¸‹é¢å°† Q åŠ è½½è¿›å…±äº«å†…å­˜ã€‚ loadQ\n1 2 3 4 5 6 7 8 9 10 11 const scalar_t* q_ptr = q + seq_idx * q_stride + head_idx * HEAD_SIZE; __shared__ Q_vec q_vecs[THREAD_GROUP_SIZE][NUM_VECS_PER_THREAD]; // HEAD_SIZE * VEC_SIZE * sizeof(scalar_t) å¤§å° #pragma unroll for (int i = thread_group_idx; i \u0026lt; NUM_VECS_PER_THREAD; i += NUM_THREAD_GROUPS) { // NUM_ELEMS_PER_THREAD / VEC_SIZE // ä½¿å¾—æ¯ä¸ª thread group çš„çº¿ç¨‹è®¿é—®ç›¸é‚»çš„ vec const int vec_idx = thread_group_offset + i * THREAD_GROUP_SIZE; q_vecs[thread_group_offset][i] = *reinterpret_cast\u0026lt;const Q_vec*\u0026gt;(q_ptr + vec_idx * VEC_SIZE); } __syncthreads(); å‡è®¾å—ä¸ç¨€ç–å¹¶ä¸”æŠŠä¸é‡‡ç”¨é‡åŒ–ï¼ŒåŠ è½½ K å¹¶è®¡ç®— Q@K.T. æ ¸å¿ƒæ€æƒ³æ˜¯ä¸€ä¸ª thread group è®¿é—® 16 Bytes. ä¸€ä¸ª thread è®¿é—®ä¸€ä¸ª vecï¼Œä¸€ä¸ªå‘é‡åŒ…å«çš„å…ƒç´ ä¸ªæ•° VEC_SIZE = 16 / sizeof (scalar_t) / THREAD_GROUP_SIZE\n1st for å¾ªç¯ç¡®å®šçš„æ˜¯æ¯æ¬¡è¿­ä»£ä¸­æ¯ä¸ª warp å¤„ç†çš„æ˜¯å“ªä¸€ä¸ª blockï¼Œä¸€å…±è¦å¾ªç¯ num_seq_blocks / NUM_WARPS æ¬¡ 2nd for å¾ªç¯ç¡®å®šçš„æ˜¯è¯¥ warp ä¸­çš„æ¯ä¸ª thread group è®¿é—®çš„æ˜¯è¯¥ block çš„ç¬¬å‡ ä¸ª token. å³æ¯ä¸ªçº¿ç¨‹ç»„å¤„ç†ä¸€ä¸ª token. 3rd for å¾ªç¯ç¡®å®šçš„æ˜¯è¯¥ thread group ä¸­çš„æ¯ä¸ª thread è®¿é—®çš„æ˜¯ç¬¬å‡ ä¸ª vec. è¯¥å¾ªç¯ä½¿å¾—è¯¥ thread group é‡Œé¢çš„çº¿ç¨‹è¯»å–ä¸€ä¸ªå®Œæ•´çš„ headsize. ä¸€æ¬¡è¿­ä»£è¯»å–çš„å¤§å°ä¸º 16 Bytes. é¦–å…ˆå°† block_table æŒ‡é’ˆç§»åŠ¨åˆ°å­˜å‚¨è¯¥ kv cache çš„é¦–ä¸ª blockID å¤„ï¼Œå–å‡ºå®é™…çš„ç‰©ç†å— IDï¼Œç”¨åœ¨ç¬¬ä¸‰ä¸ª for å¾ªç¯ä¸­å°†æŒ‡é’ˆç§»åŠ¨åˆ°è¯¥ K cache block èµ·å§‹å¤„. ç”±äº k_cache çš„ shape æ˜¯ [num_blocks, num_kv_heads, head_size/x, block_size, x]ï¼Œåœ¨ç¬¬ä¸‰ä¸ª for å¾ªç¯ä¸­ k_ptr è¢«ç§»åŠ¨åˆ°äº†è¯¥ thread_group è¦è¯»å–çš„ block çš„ token çš„ head å¤„ã€‚vec_idx * VEC_SIZE å³ä¸º thread è¦è¯»å–çš„å…ƒç´ å¼€å§‹ä½ç½®ï¼Œ/x è¡¨ç¤ºå¯¹åº”çš„æ˜¯ç¬¬å‡ ä¸ª 16Bytes åˆ’åˆ†, offset1 ç§»åŠ¨çš„æ˜¯ dim3ï¼Œoffset2 ç§»åŠ¨çš„ åˆ™æ˜¯ dim4.\n3rd loop ç»“æŸåå·²ç»è¯»å–äº†ä¸€ä¸ª K cache çš„å®Œæ•´ head_size åˆ°å¯„å­˜å™¨ä¸­ï¼Œå› æ­¤ qk ä¸ºä¸€ä¸ª token çš„ä¸€ä¸ª head çš„ Score Matrix. æ ¹æ® token_idx ç”±æ¯ä¸ª thread group é‡Œçš„ ç¬¬ä¸€ä¸ªçº¿ç¨‹è´Ÿè´£å°†ç´¯åŠ å’Œåˆ° logits ä¸­å¹¶æ›´æ–° qk_maxã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 // Memory planning. extern __shared__ char shared_mem[]; // NOTE(woosuk): We use FP32 for the softmax logits for better accuracy. float* logits = reinterpret_cast\u0026lt;float*\u0026gt;(shared_mem); // Workspace for reduction. __shared__ float red_smem[2 * NUM_WARPS]; // å‰ä¸€åŠç”¨äºå­˜å‚¨ qk_max åä¸€åŠç”¨äºå­˜å‚¨ exp_sum // x == THREAD_GROUP_SIZE * VEC_SIZE // æ¯æ¬¡ thread group ä¸€æ¬¡å–çš„å…ƒç´ æ•°é‡ ä¿è¯ä¸º 16 bytes constexpr int x = 16 / sizeof(cache_t); float qk_max = -FLT_MAX; // æŒ‡é’ˆç§»åŠ¨åˆ°å½“å‰ seq å¯¹åº”çš„é¦–ä¸ª blockID const int* block_table = block_tables + seq_idx * max_num_blocks_per_seq; for (int block_idx = start_block_idx + warp_idx; block_idx \u0026lt; end_block_idx; block_idx += NUM_WARPS) { // æ¯ä¸ª warp å¤„ç†ä¸€ä¸ª block const int64_t physical_block_number = static_cast\u0026lt;int64_t\u0026gt;(block_table[block_idx]); // è¯¥ warp å½“å‰å¤„ç†çš„ block å¯¹åº”çš„ id // Load a key to registers. for (int i = 0; i \u0026lt; NUM_TOKENS_PER_THREAD_GROUP; i++) { // BLOCK_SIZE(16) / WARP_SIZE(32) = 1 const int physical_block_offset = (thread_group_idx + i * WARP_SIZE) % BLOCK_SIZE; // thread group å¤„ç†çš„æ˜¯è¯¥ block çš„ç¬¬å‡ ä¸ª token const int token_idx = block_idx * BLOCK_SIZE + physical_block_offset; // è¯¥ token æ˜¯è¯¥ seq çš„ç¬¬å‡ ä¸ª K_vec k_vecs[NUM_VECS_PER_THREAD]; #pragma unroll for (int j = 0; j \u0026lt; NUM_VECS_PER_THREAD; j++) { // NUM_ELEMS_PER_THREAD(32) / VEC_SIZE(4) = 8 const cache_t* k_ptr = k_cache + physical_block_number * kv_block_stride + // ç§»åŠ¨åˆ°è¯¥ block èµ·å§‹å¤„ kv_head_idx * kv_head_stride + // ç§»åŠ¨åˆ°å¯¹åº”çš„ head å¤„ physical_block_offset * x; // ç§»åŠ¨åˆ°å¯¹åº”çš„ token å¤„ const int vec_idx = thread_group_offset + j * THREAD_GROUP_SIZE; // è¯¥ thread è¦è¯»å– head_size åˆ’åˆ†æˆçš„ç¬¬å‡ ä¸ª vec const int offset1 = (vec_idx * VEC_SIZE) / x; // ç¬¬å‡ ä¸ª 16Bytes åˆ’åˆ† const int offset2 = (vec_idx * VEC_SIZE) % x; // åˆ’åˆ†çš„ç¬¬å‡ ä¸ªå…ƒç´  if constexpr (KV_DTYPE == Fp8KVCacheDataType::kAuto) { k_vecs[j] = *reinterpret_cast\u0026lt;const K_vec*\u0026gt;(k_ptr + offset1 * BLOCK_SIZE * x + offset2); } } // Compute dot product. // This includes a reduction across the threads in the same thread group. float qk = scale * Qk_dot\u0026lt;scalar_t, THREAD_GROUP_SIZE\u0026gt;::dot(q_vecs[thread_group_offset], k_vecs); // Add the ALiBi bias if slopes are given. qk += (alibi_slope != 0) ? alibi_slope * (token_idx - seq_len + 1) : 0; if (thread_group_offset == 0) { // æ¯ä¸ªçº¿ç¨‹ç»„çš„ç¬¬ä¸€ä¸ªçº¿ç¨‹è¿›è¡Œæ›´æ–° max // Store the partial reductions to shared memory. // NOTE(woosuk): It is required to zero out the masked logits. const bool mask = token_idx \u0026gt;= seq_len; logits[token_idx - start_token_idx] = mask ? 0.f : qk; // Update the max value. qk_max = mask ? qk_max : fmaxf(qk_max, qk); } } } load k \u0026amp; QK Mul\nä¸Šé¢è¿™ä¸€æ®µç»“æŸåä¸‹é¢æ¯ä¸ª warp å†… thread group ä¸­çš„ç¬¬ä¸€ä¸ªçº¿ç¨‹å·²ç»è®°å½•äº†è¯¥ group çš„ qk_max. ä¸‹ä¸€æ­¥åˆ™æ˜¯åœ¨ warp å†…è¿›è¡Œ qk_max å½’çº¦ï¼Œå­˜å‚¨åœ¨å…±äº«å†…å­˜ red_smem ä¸­ã€‚ ç”±äºä¸€ä¸ª warp å¤„ç†çš„æ˜¯ä¸€ä¸ª blockï¼Œç›¸å½“äºç°åœ¨ red_smem æ¯ä¸ªå…ƒç´ å­˜å‚¨äº†å¯¹åº” block å†…çš„ qk_max.\n1 2 3 4 5 6 7 8 #pragma unroll for (int mask = WARP_SIZE / 2; mask \u0026gt;= THREAD_GROUP_SIZE; mask /= 2) { qk_max = fmaxf(qk_max, VLLM_SHFL_XOR_SYNC(qk_max, mask)); } if (lane == 0) { red_smem[warp_idx] = qk_max; } __syncthreads(); ä¸‹ä¸€æ­¥åˆ™æ˜¯åœ¨ thread block å†…å¯¹æ‰€æœ‰ warp è¿›è¡Œè§„çº¦ï¼Œå¾—åˆ°è¯¥ seq æœ€åçš„ qk_max. ç„¶åå¹¿æ’­åˆ°æ‰€æœ‰çº¿ç¨‹ä¸­ã€‚ä¹‹åæ¯ä¸ªçº¿ç¨‹è®¡ç®— exp å­˜å…¥ logitsï¼Œæ¯ä¸ª warp å†…çš„ exp æ±‚å’Œç»“æœå­˜å‚¨åœ¨ red_smem çš„åä¸€åŠä¸­ã€‚æœ€ååˆ™æ˜¯è®¡ç®— softmax å­˜åˆ° logits.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 qk_max = lane \u0026lt; NUM_WARPS ? red_smem[lane] : -FLT_MAX; #pragma unroll for (int mask = NUM_WARPS / 2; mask \u0026gt;= 1; mask /= 2) { qk_max = fmaxf(qk_max, VLLM_SHFL_XOR_SYNC(qk_max, mask)); } // Broadcast the max qk value to all threads. qk_max = VLLM_SHFL_SYNC(qk_max, 0); // Get the sum of the exp values. float exp_sum = 0.f; for (int i = thread_idx; i \u0026lt; num_tokens; i += NUM_THREADS) { float val = __expf(logits[i] - qk_max); logits[i] = val; exp_sum += val; } exp_sum = block_sum\u0026lt;NUM_WARPS\u0026gt;(\u0026amp;red_smem[NUM_WARPS], exp_sum); // Compute softmax. const float inv_sum = __fdividef(1.f, exp_sum + 1e-6f); for (int i = thread_idx; i \u0026lt; num_tokens; i += NUM_THREADS) { logits[i] *= inv_sum; } __syncthreads(); åŠ è½½ v çš„é€»è¾‘ä¸ k ç›¸åŒï¼Œä½†æ²¡æœ‰ä½¿ç”¨ thread group æ¦‚å¿µï¼Œè€Œæ˜¯è®©ä¸€ä¸ª thread ä¸€æ¬¡åŠ è½½ 16 Bytes.\n","permalink":"http://localhost:1313/blogs/vllm/","summary":"vllm structure","title":"VLLM Sourse Code Reading"},{"content":"Github Card this is a github card\rBig Quote Basically, Iâ€™m not interested in doing research and I never have beenâ€¦ Iâ€™m interested in understanding, which is quite a different thing. And often to understand something you have to work it out yourself because no one else has done it. â€” David Blackwell\nMargin Note è¿™æ˜¯ä¸€æ®µæ­£å¸¸çš„æ–‡æœ¬ï¼Œæˆ‘ä»¬æ­£åœ¨è®¨è®ºä¸€ä¸ªéå¸¸é‡è¦çš„æ¦‚å¿µã€‚è¿™å°±æ˜¯bilibiliå¯¹é‚£ä¸ªé‡è¦æ¦‚å¿µçš„è§£é‡Šå’Œè¡¥å……è¯´æ˜ã€‚ä½ ç”šè‡³å¯ä»¥åœ¨è¿™é‡Œä½¿ç”¨ Markdown è¯­æ³•ï¼\rè¿™ä¸ªæ¦‚å¿µæºäºå¤å¸Œè…Šï¼Œå¯¹åä¸–å½±å“æ·±è¿œã€‚\nç»§ç»­ä½ çš„æ–‡ç« \u0026hellip; å¦ä¸€å¤„éœ€è¦æ³¨è§£çš„åœ°æ–¹ã€‚è¿™æ˜¯ç¬¬äºŒä¸ªæ—æ³¨ï¼Œå®ƒä¼šè‡ªåŠ¨å¯¹é½ï¼Œä¸ä¼šå’Œç¬¬ä¸€ä¸ªé‡å ã€‚\rVarious Notice å…³äºä»¥ä¸‹notice è¯·å‚è€ƒ hugo_notice\rWarning\nThis is a warning notice. Be warned!\nTip\nThis is a very good tip.\nInfo\nThis is a use info.\nNote\nThis is a note.\n","permalink":"http://localhost:1313/blogs/functiontest/","summary":"function test","title":"Functional Test of Hugo"},{"content":"CMake å…¥é—¨æ•™ç¨‹ï¼šä»é¡¹ç›®ç»“æ„åˆ°é“¾æ¥åº“\næ ¸å¿ƒç†å¿µï¼šæºç å¤–æ„å»º (Out-of-Source Builds) åœ¨å¼€å§‹ä¹‹å‰ï¼Œæœ€é‡è¦çš„ä¸€ç‚¹æ˜¯ç†è§£ CMake çš„æ ¸å¿ƒå“²å­¦ï¼šæºç å¤–æ„å»ºã€‚è¿™æ„å‘³ç€æ‰€æœ‰ç”±æ„å»ºè¿‡ç¨‹äº§ç”Ÿçš„æ–‡ä»¶ï¼ˆä¾‹å¦‚ Makefilesã€Visual Studio é¡¹ç›®æ–‡ä»¶ã€ç›®æ ‡æ–‡ä»¶ .oã€å¯æ‰§è¡Œæ–‡ä»¶ .exeã€åº“æ–‡ä»¶ .a æˆ– .soï¼‰éƒ½åº”è¯¥ä¸ä½ çš„æºä»£ç å®Œå…¨åˆ†ç¦»å¼€ã€‚è¿™æ ·åšæœ€å¤§çš„å¥½å¤„æ˜¯èƒ½ä¿æŒä½ çš„æºç ç›®å½•æ°¸è¿œå¹²å‡€æ•´æ´ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª build ç›®å½•æ¥å­˜æ”¾æ‰€æœ‰è¿™äº›ç”Ÿæˆçš„æ–‡ä»¶ã€‚\næ¨èçš„é¡¹ç›®ç›®å½•ç»“æ„ ğŸ“‚ ä¸€ä¸ªè‰¯å¥½ç»„ç»‡çš„ C++ é¡¹ç›®ç»“æ„ä¸ä»…æ¸…æ™°ï¼Œä¹Ÿè®© CMake çš„é…ç½®å·¥ä½œäº‹åŠåŠŸå€ã€‚è¿™æ˜¯ä¸€ä¸ªæ¨èçš„ã€å¯æ‰©å±•çš„ç›®å½•ç»“æ„ï¼šmy_project/\nâ”‚ â”œâ”€â”€ build/ # æ„å»ºç›®å½• (åˆå§‹ä¸ºç©ºï¼Œæ‰€æœ‰ç”Ÿæˆæ–‡ä»¶éƒ½åœ¨æ­¤) â”‚ â”œâ”€â”€ include/ # å­˜æ”¾é¡¹ç›®å…¨å±€å¤´æ–‡ä»¶ â”‚ â””â”€â”€ my_app/ â”‚ â””â”€â”€ my_lib.h â”‚ â”œâ”€â”€ src/ # å­˜æ”¾æ‰€æœ‰æºæ–‡ä»¶ (.cpp) â”‚ â”‚ â”‚ â”œâ”€â”€ main.cpp # ä¸»ç¨‹åºå…¥å£ â”‚ â”‚ â”‚ â””â”€â”€ my_lib/ # ä¸€ä¸ªç‹¬ç«‹çš„åº“æ¨¡å— â”‚ â”œâ”€â”€ CMakeLists.txt # è¿™ä¸ªåº“è‡ªå·±çš„ CMake é…ç½®æ–‡ä»¶ â”‚ â””â”€â”€ my_lib.cpp â”‚ â””â”€â”€ CMakeLists.txt # æ•´ä¸ªé¡¹ç›®çš„é¡¶å±‚ CMake é…ç½®æ–‡ä»¶ build/: è¿™ä¸ªç›®å½•ç”¨äºæ‰§è¡Œæ‰€æœ‰æ„å»ºå‘½ä»¤ï¼Œæºç ä¸ä¼šè¢«æ±¡æŸ“ã€‚include/: å­˜æ”¾å¯ä»¥è¢«é¡¹ç›®å†…å…¶ä»–éƒ¨åˆ†ï¼ˆæˆ–è¢«å…¶ä»–é¡¹ç›®ï¼‰å¼•ç”¨çš„å¤´æ–‡ä»¶ã€‚æŒ‰æ¨¡å—ç»„ç»‡å¯ä»¥é¿å…å¤´æ–‡ä»¶åå†²çªã€‚src/: å­˜æ”¾æ‰€æœ‰ .cpp æºæ–‡ä»¶ã€‚ src/my_lib/: å°†é¡¹ç›®æŒ‰åŠŸèƒ½æ¨¡å—åŒ–æ˜¯ä¸€ç§å¥½ä¹ æƒ¯ã€‚æ¯ä¸ªæ¨¡å—ï¼ˆæ¯”å¦‚ä¸€ä¸ªåº“ï¼‰å¯ä»¥æœ‰è‡ªå·±çš„ CMakeLists.txt æ–‡ä»¶ï¼Œè´Ÿè´£ç®¡ç†è‡ªèº«çš„ç¼–è¯‘ã€‚ CMakeLists.txt (é¡¶å±‚): è¿™æ˜¯æ•´ä¸ªé¡¹ç›®çš„å…¥å£ï¼Œè´Ÿè´£è®¾ç½®å…¨å±€é…ç½®ã€æ‰¾åˆ°å¹¶æ„å»ºæ‰€æœ‰å­æ¨¡å—ï¼Œæœ€åç”Ÿæˆä¸»ç¨‹åºã€‚ ç¼–å†™å„å±‚çº§çš„ CMakeLists.txt ğŸ“æˆ‘ä»¬å°†é‡‡ç”¨â€œè‡ªä¸‹è€Œä¸Šâ€çš„æ–¹å¼æ¥ç¼–å†™é…ç½®æ–‡ä»¶ï¼Œå…ˆä»åº•å±‚çš„åº“å¼€å§‹ï¼Œå†åˆ°é¡¶å±‚çš„é¡¹ç›®ã€‚ ç¬¬ 1 æ­¥: åº“çš„ CMakeLists.txt (src/my_lib/CMakeLists.txt )è¿™ä¸ªæ–‡ä»¶åªè´Ÿè´£ä¸€ä»¶äº‹ï¼šå°† my_lib.cpp å’Œç›¸å…³çš„å¤´æ–‡ä»¶ç¼–è¯‘æˆä¸€ä¸ªåº“ã€‚# æ–‡ä»¶ä½ç½®: src/my_lib/CMakeLists.txt\n# ä½¿ç”¨ add_library å‘½ä»¤åˆ›å»ºä¸€ä¸ªåº“ã€‚ # è¯­æ³•: add_library(\u0026lt;åº“åç§°\u0026gt; [STATIC | SHARED] \u0026lt;æºæ–‡ä»¶...\u0026gt;) # # \u0026lt;åº“åç§°\u0026gt;: æˆ‘ä»¬ç§°ä¹‹ä¸º my_libï¼Œè¿™æ˜¯å…¶ä»–éƒ¨åˆ†é“¾æ¥æ­¤åº“æ—¶ä½¿ç”¨çš„åå­—ã€‚ # STATIC: ç”Ÿæˆé™æ€é“¾æ¥åº“ (.a, .lib)ã€‚ # SHARED: ç”ŸæˆåŠ¨æ€/å…±äº«é“¾æ¥åº“ (.so, .dll)ã€‚ # å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤æ˜¯ STATICã€‚ # \u0026lt;æºæ–‡ä»¶\u0026gt;: ç”¨äºç¼–è¯‘è¿™ä¸ªåº“çš„æºæ–‡ä»¶åˆ—è¡¨ã€‚ add_library(my_lib STATIC my_lib.cpp) # ä¸ºè¿™ä¸ªåº“ç›®æ ‡æŒ‡å®šå®ƒéœ€è¦åŒ…å«çš„å¤´æ–‡ä»¶ç›®å½•ã€‚ # è¯­æ³•: target_include_directories(\u0026lt;ç›®æ ‡\u0026gt; \u0026lt;PUBLIC|PRIVATE|INTERFACE\u0026gt; \u0026lt;è·¯å¾„...\u0026gt;) # # \u0026lt;ç›®æ ‡\u0026gt;: å°±æ˜¯æˆ‘ä»¬ä¸Šé¢ç”¨ add_library åˆ›å»ºçš„ my_libã€‚ # PUBLIC: è¡¨ç¤ºæ­¤å¤´æ–‡ä»¶è·¯å¾„ä¸ä»… my_lib è‡ªå·±éœ€è¦ï¼Œä»»ä½•é“¾æ¥äº† my_lib çš„ç›®æ ‡ä¹Ÿéœ€è¦ã€‚ # è¿™æ˜¯æœ€å…³é”®çš„è®¾ç½®ï¼Œå®ƒå®ç°äº†ä¾èµ–çš„è‡ªåŠ¨ä¼ é€’ã€‚ # PRIVATE: è¡¨ç¤ºæ­¤å¤´æ–‡ä»¶è·¯å¾„åªæœ‰ my_lib å†…éƒ¨ç¼–è¯‘æ—¶éœ€è¦ï¼Œä¸ä¼šä¼ é€’ç»™é“¾æ¥å®ƒçš„ç›®æ ‡ã€‚ # INTERFACE:è¡¨ç¤ºæ­¤å¤´æ–‡ä»¶è·¯å¾„åªæœ‰é“¾æ¥å®ƒçš„ç›®æ ‡éœ€è¦ï¼Œmy_lib è‡ªå·±ç¼–è¯‘æ—¶ä¸éœ€è¦ã€‚ target_include_directories(my_lib PUBLIC # ${PROJECT_SOURCE_DIR} æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„å†…ç½®å˜é‡ï¼ŒæŒ‡å‘é¡¶å±‚ CMakeLists.txt æ‰€åœ¨çš„ç›®å½•ã€‚ # æˆ‘ä»¬å°†é¡¹ç›®çš„å…¨å±€ include ç›®å½•æš´éœ²å‡ºå»ã€‚ ${PROJECT_SOURCE_DIR}/include ) add_library() å®šä¹‰äº†ä¸€ä¸ªç¼–è¯‘ç›®æ ‡â€”â€”ä¸€ä¸ªåº“ã€‚ target_include_directories() ä¸ºè¿™ä¸ªç›®æ ‡æŒ‡å®šäº†å¤´æ–‡ä»¶æœç´¢è·¯å¾„ã€‚ä½¿ç”¨ PUBLIC å…³é”®å­—è‡³å…³é‡è¦ä½¿å¾—ä»»ä½•é“¾æ¥åˆ° my_lib çš„ç¨‹åºéƒ½èƒ½è‡ªåŠ¨æ‰¾åˆ° my_lib.hï¼Œæ— éœ€åœ¨é“¾æ¥æ–¹å†æ¬¡æ‰‹åŠ¨æ·»åŠ å¤´æ–‡ä»¶è·¯å¾„ã€‚ ç¬¬ 2 æ­¥: é¡¶å±‚çš„ CMakeLists.txt è¿™ä¸ªæ–‡ä»¶æ˜¯æ•´ä¸ªé¡¹ç›®çš„æ€»æŒ‡æŒ¥ï¼Œè´Ÿè´£è®¾ç½®å…¨å±€é…ç½®ã€è°ƒç”¨å­æ¨¡å—ï¼Œå¹¶ç”Ÿæˆæœ€ç»ˆçš„å¯æ‰§è¡Œæ–‡ä»¶ã€‚\n# æ–‡ä»¶ä½ç½®: my_project/CMakeLists.txt # 1. æŒ‡å®š CMake çš„æœ€ä½ç‰ˆæœ¬è¦æ±‚ã€‚è¿™æ˜¯æ¯ä¸ªé¡¶å±‚æ–‡ä»¶éƒ½åº”è¯¥æœ‰çš„ç¬¬ä¸€è¡Œã€‚ cmake_minimum_required(VERSION 3.10) # 2. å®šä¹‰é¡¹ç›®ä¿¡æ¯ã€‚ # è¯­æ³•: project(\u0026lt;é¡¹ç›®åç§°\u0026gt; VERSION \u0026lt;ç‰ˆæœ¬å·\u0026gt; LANGUAGES \u0026lt;è¯­è¨€\u0026gt;) # è¿™ä¼šåˆ›å»ºä¸€äº›æœ‰ç”¨çš„å˜é‡ï¼Œæ¯”å¦‚ PROJECT_NAME, PROJECT_SOURCE_DIRã€‚ project(MyApp VERSION 1.0 LANGUAGES CXX) # 3. è®¾ç½® C++ æ ‡å‡† (è¿™æ˜¯ç°ä»£ CMake æ¨èçš„æ–¹å¼)ã€‚ set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_CXX_EXTENSIONS OFF) # 4. æ‰“å°ä¸€æ¡æ¶ˆæ¯ï¼Œæ–¹ä¾¿è°ƒè¯•æ—¶æŸ¥çœ‹å˜é‡å€¼ (å¯é€‰)ã€‚ message(STATUS \u0026#34;Project source directory is: ${PROJECT_SOURCE_DIR}\u0026#34;) # 5. æ·»åŠ å­ç›®å½•ã€‚ # è¿™ä¸ªå‘½ä»¤ä¼šå‘Šè¯‰ CMake å»å¤„ç† src/my_lib ç›®å½•ä¸‹çš„ CMakeLists.txt æ–‡ä»¶ã€‚ # å½“æ‰§è¡Œåˆ°è¿™é‡Œæ—¶ï¼Œä¸Šé¢å®šä¹‰çš„ my_lib åº“ç›®æ ‡å°±ä¼šè¢«åˆ›å»ºå‡ºæ¥ã€‚ add_subdirectory(src/my_lib) # 6. æ·»åŠ å¯æ‰§è¡Œæ–‡ä»¶ã€‚ # è¯­æ³•: add_executable(\u0026lt;å¯æ‰§è¡Œæ–‡ä»¶å\u0026gt; \u0026lt;æºæ–‡ä»¶...\u0026gt;) # æˆ‘ä»¬å°†ä¸»ç¨‹åºå‘½åä¸º appï¼Œå®ƒç”± src/main.cpp ç¼–è¯‘è€Œæ¥ã€‚ add_executable(app src/main.cpp) # 7. é“¾æ¥åº“ï¼è¿™æ˜¯å°†æ‰€æœ‰éƒ¨åˆ†ç»„åˆåœ¨ä¸€èµ·çš„å…³é”®æ­¥éª¤ã€‚ # è¯­æ³•: target_link_libraries(\u0026lt;ç›®æ ‡\u0026gt; \u0026lt;PUBLIC|PRIVATE|INTERFACE\u0026gt; \u0026lt;è¦é“¾æ¥çš„åº“...\u0026gt;) # # \u0026lt;ç›®æ ‡\u0026gt;: æˆ‘ä»¬è¦é“¾æ¥çš„ç›®æ ‡ï¼Œå³ appã€‚ # PRIVATE: è¡¨ç¤º app çš„ç¼–è¯‘éœ€è¦ my_libï¼Œä½†è¿™ä¸ªä¾èµ–å…³ç³»ä¸ä¼šç»§ç»­ä¼ é€’ã€‚ # å¯¹äºå¯æ‰§è¡Œæ–‡ä»¶ï¼Œé€šå¸¸ä½¿ç”¨ PRIVATEã€‚ # \u0026lt;è¦é“¾æ¥çš„åº“\u0026gt;: æˆ‘ä»¬åœ¨å­ç›®å½•ä¸­å®šä¹‰çš„åº“ç›®æ ‡ my_libã€‚ target_link_libraries(app PRIVATE my_lib) add_subdirectory() ä½¿å¾—é¡¶å±‚æ–‡ä»¶ä¿æŒç®€æ´ï¼Œåªè´Ÿè´£â€œæŒ‡æŒ¥â€ï¼Œå…·ä½“å®ç°åˆ™äº¤ç»™å„ä¸ªå­æ¨¡å—ã€‚ target_link_libraries() è´Ÿè´£å°†ä¸åŒçš„ç¼–è¯‘ç›®æ ‡ï¼ˆåº“å’Œå¯æ‰§è¡Œæ–‡ä»¶ï¼‰é“¾æ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆä¾èµ–å…³ç³»ã€‚ å¦‚ä½•æ„å»ºé¡¹ç›® ğŸš€ ç°åœ¨å·²ç»å†™å¥½äº†æ‰€æœ‰çš„ CMakeLists.txt æ–‡ä»¶ï¼Œå¯ä»¥å¼€å§‹æ„å»ºäº†ã€‚æ•´ä¸ªè¿‡ç¨‹éƒ½åœ¨ç»ˆç«¯ä¸­å®Œæˆã€‚ # 1. ç¡®ä¿ä½ ä½äºé¡¹ç›®çš„æ ¹ç›®å½• (my_project) cd path/to/my_project # 2. åˆ›å»ºå¹¶è¿›å…¥æˆ‘ä»¬è§„åˆ’å¥½çš„ build ç›®å½• mkdir build cd build # 3. è¿è¡Œ CMake æ¥ç”Ÿæˆæ„å»ºç³»ç»Ÿã€‚ # \u0026#39;..\u0026#39; æŒ‡å‘ä¸Šä¸€çº§ç›®å½•ï¼Œä¹Ÿå°±æ˜¯ my_project/ æ ¹ç›®å½•ï¼ŒCMake ä¼šåœ¨é‚£é‡Œå¯»æ‰¾é¡¶å±‚çš„ CMakeLists.txtã€‚ # -DCMAKE_BUILD_TYPE=Debug æŒ‡å®šäº†æ„å»ºç±»å‹ä¸º Debugï¼Œä¼šåŒ…å«è°ƒè¯•ä¿¡æ¯ã€‚ cmake -DCMAKE_BUILD_TYPE=Debug .. # CMake ä¼šæ‰«æä½ çš„ç³»ç»Ÿï¼Œæ‰¾åˆ° C++ ç¼–è¯‘å™¨ï¼Œç„¶åæ ¹æ® CMakeLists.txt çš„å†…å®¹ # ç”Ÿæˆç‰¹å®šå¹³å°çš„æ„å»ºæ–‡ä»¶ï¼ˆåœ¨ Linux/macOS ä¸Šæ˜¯ Makefileï¼Œåœ¨ Windows ä¸Šæ˜¯ Visual Studio sln æ–‡ä»¶ï¼‰ã€‚ # 4. ç¼–è¯‘é¡¹ç›® # è¿™ä¸ªå‘½ä»¤ä¼šè°ƒç”¨åº•å±‚çš„æ„å»ºå·¥å…·ï¼ˆå¦‚ make æˆ– msbuildï¼‰æ¥æ‰§è¡ŒçœŸæ­£çš„ç¼–è¯‘å’Œé“¾æ¥å·¥ä½œã€‚ # \u0026#39;--build .\u0026#39; æ˜¯ä¸€ä¸ªå¹³å°æ— å…³çš„å‘½ä»¤ï¼Œå‘Šè¯‰ CMake åœ¨å½“å‰ç›®å½•æ‰§è¡Œæ„å»ºã€‚ cmake --build . # æˆ–è€…åœ¨ Linux/macOS ä¸Šï¼Œä½ å¯ä»¥ç›´æ¥è¿è¡Œ: # make # ç¼–è¯‘å®Œæˆåï¼Œä½ ä¼šåœ¨ build ç›®å½•ï¼ˆæˆ–å…¶å­ç›®å½•ï¼‰ä¸‹æ‰¾åˆ°ä½ çš„å¯æ‰§è¡Œæ–‡ä»¶ `app` å’Œåº“æ–‡ä»¶ `libmy_lib.a`ã€‚ ","permalink":"http://localhost:1313/blogs/productivity/simple_cmake/","summary":"A Simple Cmake Example","title":"A Simple Cmake Example"},{"content":"What Can git rebase Do rebase çš„å­—é¢æ„æ€æ˜¯â€œå˜åŸºâ€â€”â€”ä¹Ÿå°±æ˜¯æ”¹å˜ä¸€ä¸ªåˆ†æ”¯çš„â€œåŸºç¡€â€æäº¤ç‚¹ã€‚å®ƒçš„ä¸»è¦ç›®æ ‡æ˜¯ï¼šå°†ä¸€ç³»åˆ—çš„æäº¤ä»¥æ›´æ•´æ´ã€çº¿æ€§çš„æ–¹å¼åº”ç”¨åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šï¼Œä»è€Œåˆ›é€ ä¸€ä¸ªå¹²å‡€ã€æ²¡æœ‰å¤šä½™åˆå¹¶è®°å½•çš„é¡¹ç›®å†å²ã€‚\nå‡è®¾ä½ çš„é¡¹ç›®å†å²æ˜¯è¿™æ ·çš„ï¼šä½ åœ¨ main åˆ†æ”¯ä¸Šåˆ‡å‡ºäº†ä¸€ä¸ª feature åˆ†æ”¯ï¼Œä¹‹å main åˆ†æ”¯å’Œä½ è‡ªå·±çš„ feature åˆ†æ”¯éƒ½æœ‰äº†æ–°çš„ commits.\n1 2 3 A---B---C \u0026lt;-- feature / D---E---F---G \u0026lt;-- main å¦‚æœä½ åœ¨ feature åˆ†æ”¯ä¸Šè¿è¡Œ git rebase mainï¼ŒGit ä¼šåšä¸€ä»¶éå¸¸ç¥å¥‡çš„äº‹ï¼š\nGit ä¼šæš‚æ—¶â€œæ”¶èµ·â€ feature åˆ†æ”¯ä¸Šçš„æ‰€æœ‰æäº¤ (A, B, C). å°† feature åˆ†æ”¯çš„èµ·ç‚¹ç§»åŠ¨åˆ° main åˆ†æ”¯çš„æœ€æ–°æäº¤ G ä¸Šã€‚ æŠŠåˆšæ‰æ”¶èµ·çš„æäº¤ (A, B, C) ä¾æ¬¡é‡æ–°åº”ç”¨åˆ°æ–°çš„èµ·ç‚¹ä¸Šï¼Œå½¢æˆæ–°çš„æäº¤ A\u0026rsquo;, B\u0026rsquo;, C' 1 2 3 A\u0026#39;--B\u0026#39;--C\u0026#39; \u0026lt;-- feature / D---E---F---G \u0026lt;-- main A\u0026rsquo; å’Œ A çš„å†…å®¹è™½ç„¶ä¸€æ ·ï¼Œä½†å®ƒä»¬çš„ Commit ID æ˜¯ä¸åŒçš„ï¼Œå› ä¸ºå®ƒä»¬çš„çˆ¶æäº¤å˜äº†ã€‚rebase ç›¸å½“äºé‡å†™äº†å†å²ã€‚\nç°åœ¨ï¼Œå†åˆ‡æ¢å› main åˆ†æ”¯ï¼Œæ‰§è¡Œ git merge featureï¼Œç”±äº main åˆ†æ”¯çš„æ‰€æœ‰å†å²ç°åœ¨æ˜¯ feature åˆ†æ”¯å†å²çš„å­é›†ï¼ŒGit åªä¼šè¿›è¡Œä¸€æ¬¡ Fast-forward åˆå¹¶ï¼Œä¸ä¼šäº§ç”Ÿæ–°çš„åˆå¹¶æäº¤ã€‚æœ€ç»ˆç»“æœå¦‚ä¸‹\n1 D---E---F---G---A\u0026#39;--B\u0026#39;--C\u0026#39; \u0026lt;-- main, feature æœ€ç»ˆçš„é¡¹ç›®å†å²æ˜¯ä¸€æ¡å®Œç¾çš„ç›´çº¿ï¼Œéå¸¸æ¸…æ™°ï¼Œå°±åƒæ‰€æœ‰å¼€å‘éƒ½æ˜¯æŒ‰é¡ºåºå‘ç”Ÿçš„ä¸€æ ·ã€‚rebase é‡å†™äº†å†å²ï¼ŒæŠ¹å»äº†åˆ†æ”¯å¼€å‘çš„â€œå¹¶è¡Œâ€ç—•è¿¹ã€‚\nCompared to merge è¦ç†è§£ rebaseï¼Œæœ€å¥½çš„æ–¹æ³•å°±æ˜¯å’Œ merge å¯¹æ¯”ã€‚å¦‚æœåœ¨ main åˆ†æ”¯ä¸Šè¿è¡Œ git merge featureï¼Œç»“æœä¼šæ˜¯è¿™æ ·\n1 2 3 A---B---C / \\ D---E---F---G---H \u0026lt;-- main (H æ˜¯ä¸€ä¸ªåˆå¹¶æäº¤) merge åšçš„äº‹æƒ…æ˜¯ï¼š\næ‰¾åˆ°ä¸¤ä¸ªåˆ†æ”¯çš„å…±åŒç¥–å…ˆ E. å°†ä¸¤ä¸ªåˆ†æ”¯çš„ä¿®æ”¹æ•´åˆèµ·æ¥ï¼Œåˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ Merge Commitï¼Œä¹Ÿå°±æ˜¯ H. è¯¥æäº¤æœ‰ä¸¤ä¸ªçˆ¶æäº¤ç‚¹ C å’Œ G. merge å®Œå…¨å…¨ä¿ç•™äº†å†å²çš„çœŸå®æ€§ã€‚å®ƒæ¸…æ¥šåœ°è®°å½•äº†â€œåœ¨æŸä¸ªæ—¶é—´ç‚¹ï¼Œæˆ‘ä»¬æŠŠä¸€ä¸ªåˆ†æ”¯åˆå¹¶äº†è¿›æ¥â€ã€‚ä½†å¦‚æœé¡¹ç›®é¢‘ç¹åˆå¹¶ï¼Œå†å²è®°å½•ä¼šå……æ»¡å¤§é‡çš„åˆå¹¶æäº¤ï¼Œå½¢æˆä¸€ä¸ªå¤æ‚çš„â€œè±å½¢â€æˆ–â€œæ„å¤§åˆ©é¢æ¡â€å¼çš„ç½‘çŠ¶ç»“æ„ï¼Œéš¾ä»¥é˜…è¯»ã€‚\nHow to use rebase å‡è®¾ä½ æ­£åœ¨ feature-login åˆ†æ”¯ä¸Šå¼€å‘ï¼ŒåŒæ—¶ä¸»åˆ†æ”¯ main ä¹Ÿæœ‰äº†æ–°çš„æ›´æ–°ã€‚\nç¡®ä¿ main åˆ†æ”¯å¤„äºæœ€æ–°çš„çŠ¶æ€ 1 2 git checkout main git pull origin main åˆ‡æ¢åˆ°ä½ æ­£åœ¨å¼€å‘çš„åˆ†æ”¯ git checkout feature-login æŠŠ main åˆ†æ”¯ä¸Šçš„æœ€æ–°ä¿®æ”¹ rebase åˆ°ä½ å½“å‰çš„ feature-login åˆ†æ”¯ä¸Š git rebase main è§£å†³å†²çª (å¦‚æœæœ‰çš„è¯). å› ä¸º rebase æ˜¯é€ä¸ªåº”ç”¨æäº¤ï¼Œæ‰€ä»¥å¯èƒ½ä¼šåœ¨æŸä¸ªæäº¤åº”ç”¨æ—¶å‘ç”Ÿå†²çªã€‚æ­¤æ—¶ï¼Œrebase ä¼šæš‚åœã€‚ æ‰“å¼€å†²çªæ–‡ä»¶ï¼Œæ‰‹åŠ¨è§£å†³å†²çªï¼ˆå’Œ merge å†²çªä¸€æ ·ï¼‰ã€‚ è§£å†³åï¼Œä½¿ç”¨ git add \u0026lt;filename\u0026gt; å°†æ–‡ä»¶æ ‡è®°ä¸ºå·²è§£å†³ã€‚ ç„¶åï¼Œç»§ç»­ rebase è¿‡ç¨‹ git rebase --continue å¦‚æœä¸­é€”æƒ³æ”¾å¼ƒï¼Œå¯ä»¥å›åˆ° rebase å¼€å§‹å‰çš„çŠ¶æ€ git rebase --abort åˆå¹¶åˆ°ä¸»åˆ†æ”¯ rebase æˆåŠŸåï¼Œä½ çš„ feature-login åˆ†æ”¯å°±å·²ç»åŒ…å«äº† main çš„æ‰€æœ‰æ›´æ–°ï¼Œå¹¶ä¸”ä½ çš„æäº¤éƒ½åœ¨æœ€å‰é¢ã€‚ç°åœ¨å¯ä»¥è¿›è¡Œä¸€æ¬¡å¹²å‡€çš„å¿«è¿›åˆå¹¶ã€‚ 1 2 git checkout main git merge feature-login When NOT to Use rebase **æ°¸è¿œä¸è¦å¯¹ä¸€ä¸ªå·²ç»æ¨é€åˆ° remoteï¼Œå¹¶ä¸”å¯èƒ½è¢«å›¢é˜Ÿå…¶ä»–äººä½¿ç”¨çš„å…¬å…±åˆ†æ”¯ (å¦‚ main, develop)è¿›è¡Œ rebaseï¼**å› ä¸º rebase ä¼šé‡å†™å†å²ã€‚å¦‚æœä½  rebase äº†ä¸€ä¸ªå…¬å…±åˆ†æ”¯å¹¶å¼ºåˆ¶æ¨é€ (git push --force)ï¼Œé‚£ä¹ˆæ‰€æœ‰å›¢é˜Ÿæˆå‘˜çš„æœ¬åœ°å†å²è®°å½•éƒ½å°†ä¸è¿œç¨‹çš„â€œæ–°å†å²â€äº§ç”Ÿä¸¥é‡åˆ†æ­§ã€‚\næ­£ç¡®ç”¨æ³•æ˜¯åªåœ¨ä½ è‡ªå·±çš„ã€è¿˜æœªä¸ä»–äººåˆ†äº«çš„æœ¬åœ°åˆ†æ”¯ä¸Šä½¿ç”¨ rebaseï¼Œç”¨æ¥æ•´ç†ä½ è‡ªå·±çš„æäº¤è®°å½•ï¼Œä»¥ä¾¿åœ¨åˆå¹¶åˆ°å…¬å…±åˆ†æ”¯å‰æœ‰ä¸€ä¸ªå¹²å‡€çš„å†å²ã€‚\nAdvanced Use git rebase -i git rebase -i å…è®¸ä½ åœ¨ rebase çš„è¿‡ç¨‹ä¸­ï¼Œå¯¹ä½ çš„æäº¤è¿›è¡Œç¼–è¾‘ã€åˆå¹¶ã€æ‹†åˆ†æˆ–åˆ é™¤ã€‚è¿™å¸¸ç”¨äºåœ¨åˆå¹¶åˆ° main åˆ†æ”¯å‰ï¼Œå°†è‡ªå·±æœ¬åœ°å‡Œä¹±çš„æäº¤ï¼ˆå¦‚ \u0026ldquo;ä¿®å¤æ‹¼å†™é”™è¯¯\u0026rdquo;, \u0026ldquo;ä¸´æ—¶æäº¤\u0026rdquo;, \u0026ldquo;åˆæ”¹äº†ä¸€ç‚¹\u0026rdquo;ï¼‰æ•´ç†æˆå‡ ä¸ªæœ‰æ„ä¹‰çš„æäº¤ã€‚\nå‡è®¾ä½ çš„ feature-login åˆ†æ”¯æœ‰ 3 ä¸ªå‡Œä¹±çš„æäº¤ï¼Œä½ æƒ³æŠŠå®ƒä»¬åˆå¹¶æˆä¸€ä¸ªã€‚\nå¯åŠ¨äº¤äº’å¼ rebase git rebase -i HEAD~3. å…¶ä¸­ HEAD~3 è¡¨ç¤ºä»å½“å‰æäº¤ (HEAD) å¾€å‰æ•° 3 ä¸ªæäº¤ã€‚ ç¼–è¾‘ Rebase è„šæœ¬ Git ä¼šæ‰“å¼€ä¸€ä¸ªæ–‡æœ¬ç¼–è¾‘å™¨ï¼Œåˆ—å‡ºè¿™ 3 ä¸ªæäº¤ï¼š 1 2 3 pick a31ab34 complete login UI pick 58c34bb fix a button bug pick 948f2cb add backend verify logic åœ¨æ–‡ä»¶ä¸‹æ–¹ä¼šæœ‰æŒ‡ä»¤è¯´æ˜ã€‚ä½ å¯ä»¥ä¿®æ”¹æ¯ä¸€è¡Œå‰é¢çš„ pick å‘½ä»¤ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬æƒ³æŠŠåä¸¤ä¸ªæäº¤åˆå¹¶åˆ°ç¬¬ä¸€ä¸ªé‡Œé¢ï¼š\n1 2 3 pick a31ab34 complete login UI squash 58c34bb fix a button bug squash 948f2cb add backend verify logic ä¿å­˜å¹¶é€€å‡ºç¼–è¾‘å™¨ Git ä¼šå¼€å§‹åˆå¹¶æäº¤ï¼Œå¹¶å¼¹å‡ºå¦ä¸€ä¸ªç¼–è¾‘å™¨ï¼Œè®©ä½ ä¸ºè¿™ä¸ªåˆå¹¶åçš„æ–°æäº¤ç¼–å†™ä¸€ä¸ªæ–°çš„ commit message. æ•´ç†å¥½åä¿å­˜é€€å‡ºã€‚ç°åœ¨å†ç”¨ git log æŸ¥çœ‹ï¼Œä½ ä¼šå‘ç°åŸæ¥ 3 ä¸ªå‡Œä¹±çš„æäº¤å·²ç»å˜æˆäº†ä¸€ä¸ªå¹²å‡€ã€å®Œæ•´çš„æäº¤ã€‚ ","permalink":"http://localhost:1313/blogs/productivity/git-rebase-flow/","summary":"Use of git rebase","title":"How to Use git rebase"},{"content":"åœ¨ All2All é€šä¿¡ä¸­ï¼Œæ¯ä¸ªè®¾å¤‡ç»™å…¶ä»–è®¾å¤‡å‘é€å¤§å°ä¸º m çš„ä¸åŒçš„æ¶ˆæ¯ã€‚æ­¤æ“ä½œç›¸å½“äºä½¿ç”¨ä¸€ç»´æ•°ç»„åˆ†åŒºå¯¹åˆ†å¸ƒåœ¨ p ä¸ªè¿›ç¨‹ä¸­çš„äºŒç»´æ•°æ®æ•°ç»„è¿›è¡Œè½¬ç½®ï¼Œå› æ­¤ä¹Ÿè¢«ç§°ä½œå…¨äº¤æ¢ (total exchange)\nRing / Bidirectional Linear Array çº¿æ€§æ•°ç»„æ‹“æ‰‘ç»“æ„çš„ All2All é€šä¿¡ä¸­ï¼Œæ¯ä¸ªè®¾å¤‡éœ€è¦å‘é€ p-1 ä»½å¤§å°ä¸º m çš„æ•°æ®ã€‚ç”¨ {i,j} è¡¨ç¤ºæ¶ˆæ¯éœ€è¦ä»è®¾å¤‡ i å‘é€åˆ°è®¾å¤‡ j. é¦–å…ˆï¼Œæ¯ä¸ªèŠ‚ç‚¹å°†æ‰€æœ‰è¦å‘é€çš„æ•°æ®ä½œä¸ºä¸€ä¸ªå¤§å°ä¸º m(p-1) çš„åˆå¹¶æ¶ˆæ¯å‘é€ç»™å®ƒé‚»å±… (å‡è®¾æ‰€æœ‰è®¾å¤‡é€šä¿¡æ–¹å‘ç›¸åŒ)ã€‚å½“é‚»å±…æ”¶åˆ°è¿™ä¸ªæ¶ˆæ¯åæå–ä»–æ‰€éœ€è¦çš„é‚£ä¸€éƒ¨åˆ†ï¼Œå‘é€å‰©ä¸‹çš„å¤§å°ä¸º m(p-2). æ¯ä¸ªè®¾å¤‡ä¸€å…±å‘é€ p-1 æ¬¡ï¼Œæ¯æ¬¡è¦å‘é€çš„æ¶ˆæ¯å¤§å°å‡å°‘ m.\nç”±æ­¤å¯ä»¥å¾—å‡ºåœ¨ p ä¸ªè®¾å¤‡ç»„æˆçš„çº¿æ€§æ•°ç»„æ‹“æ‰‘ä¸Šè¿›è¡Œ All2All æ¯ä¸ªè®¾å¤‡éœ€è¦å‘ç›¸é‚»è®¾å¤‡é€šä¿¡ p-1 æ¬¡ï¼Œç¬¬ i æ¬¡é€šä¿¡çš„æ¶ˆæ¯å¤§å°ä¸º m(p-i). å¦‚æœå‘ä¸¤ä¸ªæ–¹å‘éƒ½è¿›è¡Œå‘é€ï¼Œé‚£ä¹ˆæ¯ä¸ªæ–¹å‘éƒ½åªç”¨å‘é€åŸå…ˆä¸€åŠçš„æ•°æ®ã€‚\n$$\r\\begin{aligned}T_{ring}\u0026=\\quad\\sum_{i=1}^{p-1}(t_{s}+t_{w}m(p-i))\\\\\u0026=\\quad t_{s}(p-1)+\\sum_{i=1}^{p-1}it_{w}m\\\\\u0026=\\quad(t_{s}+t_{w}mp/2)(p-1).\\end{aligned}\r$$ç¯çŠ¶ç½‘ç»œä¸­æ¯ä»½æ¶ˆæ¯çš„å¹³å‡ä¼ è¾“è·³æ•°æ˜¯ $\\frac{\\sum_{d=1}^{p-1}i}{p-1} = p/2$ï¼Œå› æ­¤ p ä¸ªèŠ‚ç‚¹æ€»å…±çš„é€šä¿¡é‡ä¹‹å’Œä¸º $p\\times m(p-1)\\times\\frac p2$ ç¯çŠ¶ç½‘ç»œä¸­æ€»çš„é“¾è·¯æ•°ç›®ä¸º p. å› æ­¤è´Ÿè½½å¹³å‡çš„æƒ…å†µä¸‹ï¼Œæœ€å°‘éœ€è¦çš„æ—¶é—´ä¸º $\\frac{m(p-1)\\times\\frac p2\\times p}p = m(p-1)\\frac p2$ ï¼Œå› æ­¤ç®—æ³•æ—¶é—´ä¸ºæœ€ä¼˜çš„ã€‚\nè·³æ•°ä¸º d çš„æ¶ˆæ¯æ•°é‡å¯¹åº”äºç›¸è· d çš„èŠ‚ç‚¹å¯¹ (i, j)ï¼Œå…¶ä¸­ |i-j|=d\n(0, d),(1, d+1), \\ldots,(p-1-d, p-1)ï¼Œå³ i ä» 0 åˆ° p-1-d, j=i+d ï¼Œå…±æœ‰ p-d å¯¹ã€‚ (d, 0),(d+1,1), \\ldots,(p-1, p-1-d)ï¼Œå³ i ä» d åˆ° p-1, ~ j=i-d ï¼Œä¹Ÿæœ‰ p-d å¯¹ã€‚ æ€»å…±æœ‰ 2(p-d) æ¡æ¶ˆæ¯çš„è·³æ•°ä¸º d æ€»è·³æ•°\n$$\r\\begin{aligned}\r\\text { æ€»è·³æ•° } \u0026 =\\sum_{d=1}^{p-1} d \\times 2(p-d) \\\\\r\u0026 =2 \\sum_{d=1}^{p-1} d(p-d)=2\\left(p \\sum_{d=1}^{p-1} d-\\sum_{d=1}^{p-1} d^{2}\\right) \\\\\r\u0026 = p \\cdot \\frac{(p-1) p}{2}-\\frac{(p-1) p(2 p-1)}{6} \\\\\r\u0026 = =\\frac{(p-1) p(p+1)}{6}\r\\end{aligned}\r$$å› æ­¤å¹³å‡è·³æ•° =$\\frac{\\text { æ€»è·³æ•° }}{\\text { æ€»æ¶ˆæ¯æ•° }}=\\frac{\\frac{(p-1) p(p+1)}{3}}{p(p-1)}=\\frac{p+1}{3}$\nMesh è‹¥ p ä¸ªè®¾å¤‡ç»„æˆå¤§å°ä¸º $\\sqrt{p} \\times \\sqrt{p}$ çš„ mesh è¿›è¡Œ All2All é€šä¿¡ï¼Œæ¯ä¸ªè®¾å¤‡é¦–å…ˆå°†å…¶ p ä¸ªæ•°æ®æŒ‰ç…§ç›®çš„è®¾å¤‡çš„åˆ—è¿›è¡Œåˆ†ç»„ï¼Œå³åˆ†æˆ $\\sqrt{p}$ ç»„ï¼Œæ¯ç»„åŒ…å«å¤§å°ä¸º $m\\sqrt{p}$ çš„æ¶ˆæ¯ã€‚å‡è®¾ 3x3 çš„ meshï¼Œåˆ™ç¬¬ä¸€ç»„æ¶ˆæ¯çš„ç›®çš„èŠ‚ç‚¹ä¸º {0,3,6}ï¼Œç¬¬äºŒç»„æ¶ˆæ¯çš„ç›®çš„èŠ‚ç‚¹ä¸º {1,4,7}ï¼Œç¬¬ä¸‰ç»„æ¶ˆæ¯çš„ç›®çš„èŠ‚ç‚¹ä¸º {2,5,8}\né¦–å…ˆåŒæ—¶åˆ†åˆ«åœ¨æ¯ä¸€è¡Œä¸­è¿›è¡Œ All2All é€šä¿¡ï¼Œæ¯ä¸€ä»½æ•°æ®å¤§å°ä¸º $m\\sqrt{p}$. é€šä¿¡ç»“æŸåæ¯ä¸ªè®¾å¤‡æ‹¥æœ‰çš„æ˜¯è¯¥è¡Œç›®çš„è®¾å¤‡ä¸ºæ‰€åœ¨åˆ—çš„æ‰€æœ‰æ•°æ®ã€‚ç„¶åå°†æ•°æ®æŒ‰ç…§ç›®çš„è®¾å¤‡æ‰€åœ¨çš„è¡Œè¿›è¡Œåˆ†ç»„ã€‚å³è®¾å¤‡ {0,3,6} ç¬¬ä¸€ç»„æ¶ˆæ¯çš„ç›®çš„èŠ‚ç‚¹ä¸º 0ï¼Œç¬¬äºŒç»„æ¶ˆæ¯çš„ç›®çš„èŠ‚ç‚¹ä¸º 3ï¼Œç¬¬ä¸‰ç»„æ¶ˆæ¯çš„ç›®çš„èŠ‚ç‚¹ä¸º 6. ç„¶ååŒæ—¶åˆ†åˆ«åœ¨æ¯ä¸€åˆ—ä¸­è¿›è¡Œ All2All é€šä¿¡ã€‚\næˆ‘ä»¬åªéœ€è¦å°† Linear Array æ‹“æ‰‘ç»“æ„ä¸­çš„å…¬å¼çš„ p æ¢æˆ $\\sqrt{p}$ ï¼Œm æ¢æˆ $m\\sqrt{p}$ï¼Œå†ä¹˜ä»¥ 2 å°±å¾—åˆ°åœ¨ mesh ä¸Šè¿›è¡Œ All2All çš„æ—¶é—´\n$$\rT_{mesh}=(2t_{s}+t_{w}mp)(\\sqrt{p}-1).\r$$Hypercube è¶…ç«‹æ–¹ä½“æ‹“æ‰‘åœ¨æ¯ä¸ªç»´åº¦ä¸Šéƒ½æœ‰ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œä¸€å…±æœ‰ $\\log{p}$ ä¸ªç»´åº¦ã€‚åœ¨ä¸€å…±æœ‰ p ä¸ªèŠ‚ç‚¹è¶…ç«‹æ–¹ä½“ä¸­ï¼Œåœ¨æŸä¸ªç»´åº¦ $d$ ä¸Šï¼Œè¶…ç«‹æ–¹ä½“å¯ä»¥è¢«åˆ’åˆ†ä¸ºä¸¤ä¸ªÂ (nâˆ’1) ç»´çš„å­ç«‹æ–¹ä½“ï¼Œè¿™ä¸¤ä¸ªå­ç«‹æ–¹ä½“é€šè¿‡ç»´åº¦ d ä¸Šçš„ p/2 æ¡é“¾è·¯ç›¸è¿ã€‚\nåœ¨ All2All é€šä¿¡çš„ä»»ä½•é˜¶æ®µï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½æŒæœ‰ $p$ ä¸ªå¤§å°ä¸º $m$ çš„æ•°æ®åŒ…ã€‚å½“åœ¨ç‰¹å®šç»´åº¦ä¸Šé€šä¿¡æ—¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹å‘é€ $p/2$ ä¸ªæ•°æ®åŒ… (åˆå¹¶ä¸ºä¸€æ¡æ¶ˆæ¯)ã€‚è¿™äº›æ•°æ®åŒ…çš„ç›®çš„åœ°æ˜¯ç”±å½“å‰ç»´åº¦çš„é“¾è·¯è¿æ¥çš„å¦ä¸€ä¸ªå­ç«‹æ–¹ä½“åŒ…å«çš„èŠ‚ç‚¹ã€‚åœ¨ä¸Šè¿°è¿‡ç¨‹ä¸­ï¼ŒèŠ‚ç‚¹å¿…é¡»åœ¨æ¯ä¸ª $\\log{p}$ é€šä¿¡æ­¥éª¤ä¹‹å‰åœ¨æœ¬åœ°é‡æ–°æ’åˆ—æ¶ˆæ¯ã€‚\n$\\log{p}$ æ­¥ä¸­çš„æ¯ä¸€æ­¥ï¼Œæ¯ä¸ªè®¾å¤‡æ²¿å½“å‰ç»´åº¦çš„åŒå‘é“¾è·¯äº¤æ¢å¤§å°ä¸º mp/2 çš„æ•°æ®ã€‚å› æ­¤åœ¨ hypercube ä¸Šè¿›è¡Œ All2All çš„æ—¶é—´ä¸º\n$$\rT_{hcube}=(t_{s}+t_{w}mp/2)\\log p.\r$$å€¼å¾—æ³¨æ„çš„æ˜¯ä¸ ring å’Œ mesh ç®—æ³•ä¸åŒï¼Œè¶…ç«‹æ–¹ä½“ç®—æ³•ä¸æ˜¯æœ€ä¼˜çš„ã€‚æ¯ä¸ªè®¾å¤‡å‘é€å’Œæ¥æ”¶å¤§å°ä¸º m(p- 1) çš„æ•°æ®ï¼Œè¶…ç«‹æ–¹ä½“ä¸Šä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„å¹³å‡è·ç¦»ä¸º $\\log{p}/2$ . å› æ­¤ï¼Œç½‘ç»œä¸Šçš„æ€»æ•°æ®æµé‡ä¸º $p\\times m(p - 1)\\times(\\log{p})/2$. æ¯ä¸ªè¶…ç«‹æ–¹ä½“ä¸€å…±æœ‰ $p\\log{p}/2$ æ¡åŒå‘é“¾è·¯ï¼Œå¦‚æœæµé‡èƒ½å¤Ÿè¢«å¹³åˆ†ï¼Œåˆ™é€šä¿¡ç”¨æ—¶ä¸‹ç•Œåº”è¯¥ä¸º\n$$\r\\begin{aligned}T_{min}\u0026=\\frac{t_{w}pm(p-1)(\\log p)/2}{(p\\log p)/2}\\\\\u0026=t_{w}m(p-1).\\end{aligned}\r$$Optimal Algorithm in Hypercube åœ¨è¶…ç«‹æ–¹ä½“ä¸Šï¼Œæ‰§è¡Œ All2All çš„æœ€ä½³æ–¹æ³•æ˜¯è®©æ¯ä¸€å¯¹èŠ‚ç‚¹å½¼æ­¤ç›´æ¥é€šä¿¡ã€‚å› æ­¤ï¼Œæ¯ä¸ªèŠ‚ç‚¹åªéœ€æ‰§è¡Œ p-1 æ¬¡é€šä¿¡ï¼Œæ¯æ¬¡ä¸ä¸åŒè®¾å¤‡äº¤æ¢å¤§å°ä¸º m çš„æ•°æ®ã€‚è®¾å¤‡å¿…é¡»åœ¨æ¯æ¬¡é€šä¿¡ä¸­é€‰æ‹©ä¸ä¼šå‡ºç°æ‹¥å¡çš„é€šä¿¡å¯¹è±¡ã€‚åœ¨ç¬¬ j æ¬¡é€šä¿¡ä¸­ï¼ŒèŠ‚ç‚¹ i ä¸èŠ‚ç‚¹ $i \\oplus j$ äº¤æ¢æ•°æ®ã€‚åœ¨è¶…ç«‹æ–¹ä½“ä¸Šï¼Œä»èŠ‚ç‚¹ i åˆ°èŠ‚ç‚¹ j çš„æ¶ˆæ¯å¿…é¡»ç»è¿‡è‡³å°‘ l æ¡é“¾è·¯ï¼Œå…¶ä¸­ l æ˜¯ i å’Œ j ä¹‹é—´çš„æ±‰æ˜è·ç¦» (å³ $i \\oplus j$ çš„äºŒè¿›åˆ¶è¡¨ç¤ºä¸­çš„éé›¶æ¯”ç‰¹æ•°). æˆ‘ä»¬é€šè¿‡ E-cube è·¯ç”±æ¥é€‰æ‹©è·¯å¾„ï¼š\nå°†å½“å‰èŠ‚ç‚¹åœ°å€ C ä¸ç›®æ ‡èŠ‚ç‚¹åœ°å€ D è¿›è¡Œ XOR æ“ä½œï¼Œå¾—åˆ° $R=C\\oplus D$. æ‰¾åˆ° R çš„æœ€ä½æœ‰æ•ˆéé›¶ä½ï¼Œå†³å®šä¸‹ä¸€æ­¥è·³è½¬çš„ç»´åº¦ã€‚ æ²¿é€‰å®šç»´åº¦è·³è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ›´æ–°å½“å‰èŠ‚ç‚¹åœ°å€ã€‚ é‡å¤ä¸Šè¿°æ­¥éª¤ï¼Œç›´åˆ° R=0ï¼Œ å³åˆ°è¾¾ç›®æ ‡èŠ‚ç‚¹ã€‚ å¯¹äºèŠ‚ç‚¹iå’ŒèŠ‚ç‚¹jä¹‹é—´çš„æ¶ˆæ¯ä¼ è¾“ï¼Œè¯¥ç®—æ³•ä¿è¯æ¯ä¸€æ­¥çš„é€šä¿¡æ—¶é—´ä¸º t_s + t_wmï¼Œå› ä¸ºåœ¨èŠ‚ç‚¹ i å’ŒèŠ‚ç‚¹ j ä¹‹é—´çš„é“¾è·¯ä¸Šæ²¿ç€åŒä¸€æ–¹å‘ä¼ æ’­çš„ä»»ä½•å…¶ä»–æ¶ˆæ¯éƒ½ä¸å­˜åœ¨ç«äº‰ï¼Œåˆ‡æ¯ä¸€æ­¥åªåˆ‡æ¢ä¸€ä¸ªç»´åº¦ï¼Œé€šä¿¡è·ç¦»ä¸º 1. æ•´ä¸ª All2All çš„æ€»é€šä¿¡æ—¶é—´ä¸º $$T_{xor}=(t_{s}+t_{w}m)(p-1).$$Bruck Algorithm in Full-connected Network Bruckæ˜¯ä¸€ç§å­˜å‚¨-è½¬å‘ (store-and-forward) ç®—æ³•ï¼Œéœ€è¦ log(P) æ¬¡é€šä¿¡æ­¥éª¤ã€‚è¿™æ„å‘³ç€å‘é€ç¼“å†²åŒº S å’Œæ¥æ”¶ç¼“å†²åŒº R éƒ½ç”¨äºåœ¨ä¸­é—´é€šä¿¡è½®æ¬¡ä¸­å‘é€ã€æ¥æ”¶å’Œå­˜å‚¨æ•°æ®ã€‚å› ä¸ºæŸäº›æ¥æ”¶åˆ°çš„æ•°æ®å—å¿…é¡»åœ¨åç»­é€šä¿¡æ­¥éª¤ä¸­ä½¿ç”¨ã€‚è¿™ç§å­˜å‚¨-è½¬å‘çš„ç‰¹æ€§å¯¹é€šä¿¡è½®æ¬¡çš„é¡ºåºæå‡ºäº†çº¦æŸã€‚ä¸çº¿æ€§æ­¥éª¤å®ç°ä¸åŒï¼ŒBruck å¿…é¡»ä¿æŒæ˜ç¡®çš„é€šä¿¡é¡ºåºï¼Œå…¶ä¸­ç¬¬ i+1 æ¬¡è¿­ä»£å¿…é¡»åœ¨ç¬¬ i æ¬¡è¿­ä»£ä¹‹åç‰©ç†æ—¶é—´ä¸Šå‘ç”Ÿã€‚ Bruck\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 Algorithm 2 NCCL Bruck algorithm P â† total number of processes. for i âˆˆ [0, P] do R[i] = S[(p+i) % P] // S and R are send and receive buffers, and p is rank id of each process; end for allocate temporary buffer T with SC Ã— (P+1) / 2 elements; // SC is number of elements per data-block. for k = 1; k \u0026lt; P; k \u0026lt;\u0026lt;= 1 do allocate send indexes array SB with (P+1) / 2 integers; number of send data-blocks NB â† 0; for i âˆˆ [k, P] do if i \u0026amp; k then SB[NB] â† i; copy R[i] into T[NB]; NB â† NB + 1; end if sendproc â† (p + k) % P; recvproc â† (p - k + P) % P; ncclGroupStart() send data in T to sendproc; receive data from recvproc into S; ncclGroupEnd() for i âˆˆ [0, SB] do copy T[i] into R[SB[i]]; end for end for for i âˆˆ [0, P] do R[i] = R[(p - i + P) % P] // final rotation; end for end for line(2-4): å°†æ¯ä¸ªè®¾å¤‡å‘é€ç¼“å†²åŒº S ä¸­çš„æ•°æ®æŒ‰ç…§ rank åç§»é‡æ–°æ’åˆ—æ‹·è´åˆ°æ¥æ”¶ç¼“å†²åŒº R ä¸­ã€‚ line(5): ä¸ºé€šä¿¡é˜¶æ®µå‡†å¤‡ä¸€ä¸ªä¸´æ—¶ç¼“å†²åŒº T line(6): é€šä¿¡æ­¥å¼€å§‹ k ä»¥æŒ‡æ•°æ–¹å¼å¢é•¿ (1, 2, 4, \u0026hellip;)ï¼Œæ€»å…±æ‰§è¡Œ logP æ¬¡è¿­ä»£ line(7-14): ç”¨ç´¢å¼•æ•°ç»„ SBï¼Œè®°å½•éœ€è¦å‘é€çš„æ•°æ®å—ä½ç½®ã€‚éå† k~P-1 åŒé€šè¿‡å¯¹ i\u0026amp;k åˆ¤æ–­å“ªäº›æ•°æ®å—éœ€è¦åœ¨æ­¤è½®å‘é€. (è‹¥ P æ˜¯ 2 çš„æŒ‡æ•°å¹‚ï¼Œå› ä¸º k æ˜¯ 2 çš„æŒ‡æ•°å¹‚ï¼Œå› æ­¤åªæœ‰ä¸€ä½ä¸º 1ï¼Œé‚£ä¹ˆå°±æ˜¯æ¯è½®å‘é€ p/2 ä¸ªæ•°æ®å—) å°†æ¥æ”¶ç¼“å†²åŒº R ä¸­æ»¡è¶³æ¡ä»¶çš„æ•°æ®æ‹·è´åˆ°ä¸´æ—¶ç¼“å†²åŒº Tï¼Œå¹¶è®°å½•ç´¢å¼•ã€‚ line(15-16): ç¡®å®šè¦æ¥æ”¶å’Œå‘é€çš„ç›®æ ‡ã€‚ line(17-20): è¿›è¡Œé€šä¿¡æ“ä½œï¼Œå°†æ•°æ®å‘é€åˆ°ç›®æ ‡çš„å‘é€ç¼“å†²åŒºã€‚ line(21-23): æ›´æ–°æ¥æ”¶ç¼“å†²åŒºã€‚ line(25-27): åå‘è°ƒæ•´æ¥æ”¶ç¼“å†²åŒºæ•°æ®çš„ä½ç½®ã€‚ æ€»å…± log(p) æ­¥éª¤æ¯æ­¥å‘é€ m æ¶ˆæ¯ã€‚\nTree-based Tree\né‡‡ç”¨å…ˆåœ¨è¡Œä¸Šè¿›è¡Œ All-gather, å†åœ¨åˆ—ä¸Šè¿›è¡Œ Scatter. ä¹Ÿéœ€è¦ log(p) æ­¥ï¼Œå…¶ä¸­ gather é˜¶æ®µç¬¬ä¸€æ­¥é€šä¿¡é‡ä¸º m(p-1)ï¼Œä¸€å…±è¿›è¡Œ 0.5log(p) æ­¥æ¯ä¸€æ­¥é€šä¿¡é‡ç¿»å€ï¼Œè·³æ•°ä¹Ÿç¿»å€ï¼›scatteré˜¶æ®µåˆ™æ˜¯ç›¸åï¼Œå› æ­¤ä¸¤æ­¥çš„é€šä¿¡æ—¶é—´ç›¸åŒæ€»å…± t_s*log(p) + m(p-1)^2/3\n","permalink":"http://localhost:1313/blogs/all2allcommcost/","summary":"Introduction of Transformer Family","title":"All2All Communication Cost"},{"content":"MLIR çš„ä¸»è¦åŸåˆ™ä¹‹ä¸€æ˜¯é€æ­¥ä¸‹é™ï¼Œå³å­˜åœ¨è®¸å¤šçº§åˆ«çš„ IR ç²’åº¦ï¼Œå¹¶ä¸”é€æ­¥ä¸‹é™ IR çš„ä¸åŒéƒ¨åˆ†ï¼Œä»…åœ¨ä¸å†å¯¹ä¼˜åŒ–æœ‰ç”¨æ—¶ä¸¢å¼ƒä¿¡æ¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œå°†å®Œæˆå…¶ä¸­çš„ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨æ‰€è°“çš„æ–¹è¨€è½¬æ¢åŸºç¡€è®¾æ–½å°†å¤šæ–¹è¨€ lowering ä¸ºæ ‡å‡†MLIRæ–¹è¨€çš„ç»„åˆã€‚\nThe Type Obstacle å¦‚æœä¸æ˜¯é’ˆå¯¹ç±»å‹ï¼Œæ–¹è¨€è½¬æ¢ (lowering) æœ¬è´¨ä¸Šä¸æ™®é€š pass ç›¸åŒï¼šç¼–å†™ä¸€äº›é‡å†™æ¨¡å¼å¹¶å°†å…¶åº”ç”¨äº IR. å¯¹äºæ¯ä¸ªéœ€è¦ lowering çš„ OP ï¼Œé€šå¸¸ä¼šæœ‰ä¸€ä¸ªé‡å†™æ¨¡å¼ã€‚\nç±»å‹ä½¿è¿™ä¸ªé—®é¢˜å˜å¾—æ›´åŠ å¤æ‚ï¼Œæˆ‘å°†é€šè¿‡polyçš„ç¤ºä¾‹æ¥æ¼”ç¤ºè¿™ä¸ªé—®é¢˜ã€‚\npoly.add å¯¹ä¸¤ä¸ªå¤šé¡¹å¼è¿›è¡Œç›¸åŠ å¹¶è¿”å›ç»“æœå¤šé¡¹å¼ã€‚æˆ‘ä»¬æƒ³ lowering polyã€‚ä¾‹å¦‚ï¼Œæ·»åŠ åˆ° arith.addi ç®—æœ¯è¿ç®—çš„çŸ¢é‡åŒ–å¾ªç¯ä¸­ã€‚ä½† arith å¹¶ä¸çŸ¥é“ poly.poly ç±»å‹çš„å­˜åœ¨ã€‚\nå¦‚æœå¿…é¡»ä½¿æ‰©å±• arith ä»¥äº†è§£polyï¼Œéœ€è¦å¯¹ arith è¿›è¡Œä¸Šæ¸¸æ›´æ”¹ã€‚æ·»åŠ  op çš„ operands ä»¥å…è®¸å®ç°æŸç§æ¥å£çš„ç±»å‹ï¼Œä¾‹å¦‚ integer-like æˆ– containers of integer-like.\næ‰€ä»¥ï¼Œé™¤äº† lowering opï¼Œè¿˜éœ€è¦ lowering poly. poly\u0026lt;N\u0026gt; å˜æˆå¼ é‡ \u0026lt;Nxi32\u0026gt;. è¿™å°±æ˜¯ç±»å‹éšœç¢å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚ä¸€æ—¦æ›´æ”¹äº†ç‰¹å®šå€¼çš„ç±»å‹ï¼Œä¾‹å¦‚ï¼Œåœ¨ lowering ç”Ÿæˆè¯¥å€¼ä½œä¸ºè¾“å‡ºçš„ OP æ—¶ï¼Œé‚£ä¹ˆè¯¥å€¼çš„æ‰€æœ‰ä¸‹æ¸¸ç”¨æˆ·ä»ç„¶æœŸæœ›ä½¿ç”¨æ—§ç±»å‹ï¼Œå¹¶ä¸”åœ¨ lowering å®ƒä»¬ä¹‹å‰åœ¨æŠ€æœ¯ä¸Šæ˜¯æ— æ•ˆçš„ã€‚åœ¨æ¯æ¬¡ä¼ é€’ä¹‹é—´ï¼ŒMLIRè¿è¡ŒéªŒè¯å™¨ä»¥ç¡®ä¿IRæœ‰æ•ˆï¼Œå› æ­¤å¦‚æœæ²¡æœ‰ä¸€äº›ç‰¹æ®Šå¤„ç†ï¼Œè¿™æ„å‘³ç€éœ€è¦åœ¨ä¸€æ¬¡ä¼ é€’ä¸­è½¬æ¢æ‰€æœ‰ç±»å‹å’Œ OP ï¼Œå¦åˆ™è¿™äº›éªŒè¯å™¨å°†å¤±è´¥ã€‚ä½†æ˜¯ç”¨æ ‡å‡†é‡å†™è§„åˆ™ç®¡ç†æ‰€æœ‰è¿™äº›å°†æ˜¯å›°éš¾çš„ï¼šå¯¹äºæ¯ä¸ªé‡å†™è§„åˆ™ï¼Œæ‚¨éƒ½å¿…é¡»ä¸æ–­æ£€æŸ¥å‚æ•°å’Œç»“æœæ˜¯å¦å·²ç»è½¬æ¢ã€‚\nä¾‹å¦‚åœ¨ lowering ä¸€ä¸ªç”Ÿæˆè¯¥å€¼ä½œä¸ºè¾“å‡ºçš„ OP æ—¶ï¼Œæ‰€æœ‰ä¾èµ–è¯¥å€¼çš„ä¸‹æ¸¸ç”¨æˆ·ä»ç„¶æœŸæœ›æ—§çš„ç±»å‹ï¼Œå› æ­¤åœ¨æŠ€æœ¯ä¸Šè¿™äº›ä¸‹æ¸¸ç”¨æˆ·åœ¨æœªè¢« lowering ä¹‹å‰æ˜¯æ— æ•ˆçš„ã€‚MLIR åœ¨æ¯æ¬¡è½¬æ¢ (pass) ä¹‹é—´è¿è¡ŒéªŒè¯å™¨ä»¥ç¡®ä¿ä¸­é—´è¡¨ç¤º (IR) æ˜¯æœ‰æ•ˆçš„ï¼Œå› æ­¤å¦‚æœæ²¡æœ‰ç‰¹æ®Šå¤„ç†ï¼Œè¿™æ„å‘³ç€æ‰€æœ‰ç±»å‹å’Œ OP å¿…é¡»åœ¨ä¸€ä¸ªè½¬æ¢ä¸­å…¨éƒ¨è½¬æ¢ï¼Œå¦åˆ™éªŒè¯å™¨ä¼šå¤±è´¥ã€‚ä½†æ˜¯ï¼Œä½¿ç”¨æ ‡å‡†çš„é‡å†™è§„åˆ™æ¥ç®¡ç†è¿™ä¸€åˆ‡ä¼šå¾ˆå›°éš¾ï¼šå¯¹äºæ¯ä¸ª OP é‡å†™è§„åˆ™ï¼Œä½ éœ€è¦ä¸æ–­åœ°æ£€æŸ¥å‚æ•°å’Œç»“æœæ˜¯å¦å·²ç»è½¬æ¢ã€‚\nMLIR é€šè¿‡ä¸€ä¸ªå›´ç»•æ ‡å‡†è½¬æ¢çš„åŒ…è£…å™¨æ¥å¤„ç†è¿™ç§æƒ…å†µï¼Œè¿™ä¸ªåŒ…è£…å™¨è¢«ç§°ä¸ºæ–¹è¨€è½¬æ¢æ¡†æ¶(dialect conversion framework). ä½¿ç”¨è¿™ä¸ªæ¡†æ¶éœ€è¦ç”¨æˆ·ç»§æ‰¿ä¸åŒçš„ç±»æ¥å®ç°æ™®é€šçš„é‡å†™ï¼Œè®¾ç½®ä¸€äº›é¢å¤–çš„å…ƒæ•°æ®ï¼Œå¹¶ä»¥ç‰¹å®šçš„æ–¹å¼ å°†ç±»å‹è½¬æ¢ä¸ OP è½¬æ¢åˆ†å¼€ï¼Œæˆ‘ä»¬ç¨åä¼šçœ‹åˆ°å…·ä½“æ–¹å¼ã€‚ä½†ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼Œè¿™ä¸ªæ¡†æ¶é€šè¿‡ä»¥æŸç§æ’åºé¡ºåº lowering OP ã€åŒæ—¶è½¬æ¢ç±»å‹ï¼Œå¹¶è®© OP è½¬æ¢å™¨èƒ½å¤Ÿè®¿é—®æ¯ä¸ª OP çš„åŸå§‹ç±»å‹ä»¥åŠåœ¨ OP è¢«æ¡†æ¶è®¿é—®æ—¶çš„è¿›è¡Œä¸­çš„è½¬æ¢ç±»å‹ã€‚æ¯ä¸ªåŸºäº OP çš„é‡å†™æ¨¡å¼éƒ½æœŸæœ›åœ¨è®¿é—®åä½¿è¯¥ OP çš„ç±»å‹åˆæ³•ï¼Œä½†ä¸éœ€è¦æ‹…å¿ƒä¸‹æ¸¸ OP.\nModes of Conversion å½“å¯¹ä¸€ç»„ OP è¿›è¡Œè½¬æ¢æ—¶ï¼Œæœ‰å‡ ç§ä¸åŒçš„è½¬æ¢æ¨¡å¼å¯ä¾›é€‰æ‹©ï¼š\nPartial Conversion ä½¿å°½å¯èƒ½å¤šçš„å¯¹ç›®æ ‡çš„æ“ä½œåˆæ³•åŒ–ï¼Œä½†å°†å…è®¸æœªæ˜¾å¼æ ‡è®°ä¸ºâ€œéæ³•â€çš„é¢„å…ˆå­˜åœ¨çš„æ“ä½œä¿æŒæœªè½¬æ¢ã€‚è¿™å…è®¸åœ¨å­˜åœ¨æœªçŸ¥æ“ä½œçš„æƒ…å†µä¸‹éƒ¨åˆ†é™ä½è¾“å…¥ã€‚ å¯ä»¥é€šè¿‡ applyPartialConversion è¿›è¡Œéƒ¨åˆ†è½¬æ¢ã€‚ Full Conversion ä½¿æ‰€æœ‰è¾“å…¥æ“ä½œåˆæ³•åŒ–ï¼Œå¹¶ä¸”åªæœ‰å½“æ‰€æœ‰æ“ä½œéƒ½æ­£ç¡®åœ°åˆæ³•åŒ–åˆ°ç»™å®šçš„è½¬æ¢ç›®æ ‡æ—¶æ‰æˆåŠŸã€‚è¿™ç¡®ä¿äº†åœ¨è½¬æ¢è¿‡ç¨‹ä¹‹ååªå­˜åœ¨å·²çŸ¥çš„æ“ä½œã€‚ å¯ä»¥é€šè¿‡ applyFullConversion è¿›è¡Œå®Œæ•´è½¬æ¢ã€‚ Analysis Conversion å¦‚æœè¦åº”ç”¨è½¬æ¢ï¼ŒAnalysis Conversion å°†åˆ†æå“ªäº›æ“ä½œå¯¹ç»™å®šçš„è½¬æ¢ç›®æ ‡æ˜¯åˆæ³•çš„ã€‚è¿™æ˜¯é€šè¿‡æ‰§è¡Œ \u0026lsquo;Partial\u0026rsquo; Conversion å¹¶è®°å½•å“ªäº›æ“ä½œå¦‚æœæˆåŠŸå°†è¢«æˆåŠŸè½¬æ¢æ¥å®Œæˆçš„ã€‚æ³¨æ„ï¼Œæ²¡æœ‰ rewrites æˆ–è½¬æ¢å®é™…åº”ç”¨äºè¾“å…¥æ“ä½œã€‚ å¯ä»¥é€šè¿‡ a pplyAnalysisConversion åº”ç”¨åˆ†æè½¬æ¢ã€‚ Conversion Target è½¬æ¢ç›®æ ‡æ˜¯åœ¨è½¬æ¢è¿‡ç¨‹ä¸­è¢«è®¤ä¸ºæ˜¯åˆæ³•çš„å†…å®¹çš„æ­£å¼å®šä¹‰ã€‚è½¬æ¢æ¡†æ¶ç”Ÿæˆçš„æœ€ç»ˆæ“ä½œå¿…é¡»åœ¨converontargetä¸Šæ ‡è®°ä¸ºåˆæ³•ï¼Œè¿™æ ·é‡å†™æ‰èƒ½æˆåŠŸã€‚æ ¹æ®è½¬æ¢æ¨¡å¼çš„ä¸åŒï¼Œç°æœ‰æ“ä½œä¸ä¸€å®šæ€»æ˜¯åˆæ³•çš„ã€‚æ“ä½œå’Œæ–¹è¨€å¯ä»¥æ ‡è®°ä¸ºä¸‹åˆ—ä»»ä½•è§„å®šçš„åˆæ³•æ€§è¡Œä¸ºï¼š\nLegal: è¡¨æ˜ç»™å®šæ“ä½œçš„æ¯ä¸ªå®ä¾‹éƒ½æ˜¯åˆæ³•çš„ï¼Œå³å±æ€§ã€æ“ä½œæ•°ã€ç±»å‹ç­‰çš„ä»»ä½•ç»„åˆéƒ½æ˜¯æœ‰æ•ˆçš„ã€‚ Dynamic: æ­¤æ“ä½œè¡¨ç¤ºç»™å®šæ“ä½œçš„æŸäº›å®ä¾‹æ˜¯åˆæ³•çš„ã€‚è¿™å…è®¸å®šä¹‰å¾®è°ƒçº¦æŸï¼Œä¾‹å¦‚ï¼Œarith.addi ä»…åœ¨æ“ä½œ32ä½æ•´æ•°æ—¶åˆ- Illegal: æ­¤æ“ä½œè¡¨ç¤ºç»™å®šæ“ä½œçš„å®ä¾‹ä¸åˆæ³•ã€‚ä¸ºä½¿è½¬æ¢æˆåŠŸï¼Œå¿…é¡»å§‹ç»ˆè½¬æ¢æ ‡è®°ä¸ºâ€œéæ³•â€çš„æ“ä½œã€‚æ­¤æ“ä½œè¿˜å…è®¸æœ‰é€‰æ‹©åœ°å°†ç‰¹å®šæ“ä½œæ ‡è®°ä¸ºéæ³•ï¼Œå¦åˆ™å°†æ˜¯åˆæ³•çš„æ–¹è¨€ã€‚ æœªæ˜ç¡®æ ‡è®°ä¸ºåˆæ³•æˆ–éæ³•çš„æ“ä½œå’Œæ–¹è¨€ä¸ä¸Šè¿°ï¼ˆâ€œæœªçŸ¥â€æ“ä½œï¼‰åˆ†å¼€ï¼Œå¹¶è¢«åŒºåˆ«å¯¹å¾…ï¼Œä¾‹å¦‚ï¼Œå‡ºäºä¸Šè¿°éƒ¨åˆ†è½¬æ¢çš„ç›®çš„ã€‚\næœ€åï¼Œæ–¹è¨€è½¬æ¢æ¡†æ¶ä¼šè·Ÿè¸ªä»»ä½•æœªè§£å†³çš„ç±»å‹å†²çªã€‚å¦‚æœåœ¨è½¬æ¢ç»“æŸæ—¶ä»å­˜åœ¨ç±»å‹å†²çªï¼Œä¼šå‘ç”Ÿä»¥ä¸‹ä¸¤ç§æƒ…å†µä¹‹ä¸€ã€‚è½¬æ¢æ¡†æ¶å…è®¸ç”¨æˆ·å¯é€‰åœ°å®ç°ä¸€ä¸ªç§°ä¸ºç±»å‹ç‰©åŒ–å™¨ (type materializer) çš„åŠŸèƒ½ï¼Œå®ƒä¼šæ’å…¥æ–°çš„ä¸­é—´ OP æ¥è§£å†³ç±»å‹å†²çªã€‚å› æ­¤ï¼Œç¬¬ä¸€ç§å¯èƒ½æ˜¯æ–¹è¨€è½¬æ¢æ¡†æ¶ä½¿ç”¨ä½ çš„ç±»å‹ç‰©åŒ–å™¨é’©å­æ¥ä¿®è¡¥ IRï¼Œè½¬æ¢æˆåŠŸç»“æŸã€‚å¦‚æœè¿™äº›é’©å­å¤±è´¥ï¼Œæˆ–è€…ä½ æ²¡æœ‰å®šä¹‰ä»»ä½•é’©å­ï¼Œé‚£ä¹ˆè½¬æ¢ä¼šå¤±è´¥ã€‚\nè¿™ç§åŸºç¡€è®¾æ–½çš„å¤æ‚æ€§éƒ¨åˆ†è¿˜ä¸ä¸Šæ¸¸ MLIR ä¸­ä¸€ä¸ªæ›´å›°éš¾çš„ lowering æµæ°´çº¿æœ‰å…³ï¼šç¼“å†²åŒºåŒ–æµæ°´çº¿ (bufferization pipeline). è¿™ä¸ªæµæ°´çº¿æœ¬è´¨ä¸Šå°†ä½¿ç”¨ value semantics çš„æ“ä½œçš„ IR è½¬æ¢ä¸ºä½¿ç”¨ pointer semantics çš„ä¸­é—´è¡¨ç¤ºã€‚ä¾‹å¦‚ï¼Œå¼ é‡ç±»å‹ (tensor type) åŠå…¶ç›¸å…³æ“ä½œå…·æœ‰ value semanticsï¼Œè¿™æ„å‘³ç€æ¯ä¸ªæ“ä½œåœ¨è¯­ä¹‰ä¸Šéƒ½ä¼šç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„å¼ é‡ä½œä¸ºè¾“å‡ºï¼Œå¹¶ä¸”æ‰€æœ‰æ“ä½œéƒ½æ˜¯ pure çš„ (æœ‰ä¸€äº›ä¾‹å¤–æƒ…å†µ) ã€‚å¦ä¸€æ–¹é¢ï¼Œ memref å…·æœ‰ pointer semanticsï¼Œæ„å‘³ç€å®ƒæ›´æ¥è¿‘äºå¯¹ç‰©ç†ç¡¬ä»¶çš„å»ºæ¨¡ï¼Œéœ€è¦æ˜¾å¼çš„å†…å­˜åˆ†é…ï¼Œå¹¶æ”¯æŒå¯¹å†…å­˜ä½ç½®è¿›è¡Œå˜åŠ¨çš„æ“ä½œã€‚\nç”±äºç¼“å†²åŒºåŒ–è¿‡ç¨‹å¤æ‚ï¼Œå®ƒè¢«æ‹†åˆ†ä¸º sub-passesï¼Œåˆ†åˆ«å¤„ç†ä¸ä¸Šæ¸¸ MLIR å„ç›¸å…³æ–¹è¨€ç‰¹å®šçš„ç¼“å†²åŒºåŒ–é—®é¢˜ (å‚è§æ–‡æ¡£ï¼Œä¾‹å¦‚ arith-bufferizeã€func-bufferize ç­‰) ã€‚æ¯ä¸ªç¼“å†²åŒºåŒ–è½¬æ¢éƒ½ä¼šäº§ç”Ÿä¸€äº›å†…éƒ¨æ— æ³•è§£å†³çš„ç±»å‹å†²çªï¼Œè¿™äº›å†²çªéœ€è¦è‡ªå®šä¹‰çš„ç±»å‹ç‰©åŒ– (type materializations) æ¥è§£å†³ã€‚ä¸ºäº†åœ¨æ‰€æœ‰ç›¸å…³æ–¹è¨€ä¸­å¤„ç†è¿™äº›é—®é¢˜ï¼ŒMLIR å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªä¸“é—¨çš„æ–¹è¨€ï¼Œç§°ä¸ºç¼“å†²åŒºåŒ–æ–¹è¨€ (bufferization dialect) ï¼Œç”¨æ¥å­˜æ”¾ä¸­é—´æ“ä½œã€‚ä½ ä¼šæ³¨æ„åˆ°åƒ to_memref å’Œ to_tensor è¿™æ ·çš„æ“ä½œï¼Œå®ƒä»¬æ‰®æ¼”äº†è¿™ä¸€è§’è‰²ã€‚ç„¶åè¿˜æœ‰ä¸€ä¸ªæœ€ç»ˆç¼“å†²åŒºåŒ–è½¬æ¢ (finalizing-bufferize pass) ï¼Œå…¶ä½œç”¨æ˜¯æ¸…ç†ä»»ä½•æ®‹ç•™çš„ç¼“å†²åŒºåŒ–æˆ–ç‰©åŒ–æ“ä½œã€‚\nLowering Poly with Type Materializations è·Ÿä¹‹å‰å†™ Pass tablegen çš„æ—¶å€™å¤§åŒå°å¼‚ï¼Œä¸»è¦æ˜¯éœ€è¦å®šä¹‰ dependent dialects. Lowering å¿…é¡»ä»¥è¿™ç§æ–¹å¼ä¾èµ–äºåŒ…å«å°†åˆ›å»ºçš„æ“ä½œæˆ–ç±»å‹çš„ä»»ä½•æ–¹è¨€ï¼Œä»¥ç¡®ä¿ MLIR åœ¨å°è¯•è¿è¡Œ pass ä¹‹å‰åŠ è½½è¿™äº›æ–¹è¨€ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // include/Conversion/PolyToStandard/PolyToStandard.td #ifndef LIB_CONVERSION_POLYTOSTANDARD_POLYTOSTANDARD_TD_ #define LIB_CONVERSION_POLYTOSTANDARD_POLYTOSTANDARD_TD_ include \u0026#34;mlir/Pass/PassBase.td\u0026#34; def PolyToStandard : Pass\u0026lt;\u0026#34;poly-to-standard\u0026#34;\u0026gt; { let summary = \u0026#34;Lower `poly` to standard MLIR dialects.\u0026#34;; let description = [{ This pass lowers the `poly` dialect to standard MLIR, a mixture of affine, tensor, and arith. }]; let dependentDialects = [ \u0026#34;mlir::arith::ArithDialect\u0026#34;, \u0026#34;mlir::tutorial::poly::PolyDialect\u0026#34;, \u0026#34;mlir::tensor::TensorDialect\u0026#34;, ]; } #endif // LIB_CONVERSION_POLYTOSTANDARD_POLYTOSTANDARD_TD_ ä¸‹ä¸€æ­¥éœ€è¦å®šä¹‰ ConversionTargetï¼Œå‘Šè¯‰ MLIR å“ªäº› OP éœ€è¦è¿›è¡Œ loweringï¼Œå¯ä»¥å®šä¹‰æ•´ä¸ªéœ€è¦ä¸‹é™çš„ dialect ä¸º illegalï¼Œç¡®ä¿åœ¨è½¬æ¢å®Œæˆåæ²¡æœ‰è¯¥ dialect. è¿™é‡Œä½¿ç”¨ applyPartialConversion è€Œä¸æ˜¯ applyFullConversion çš„åŸå› æ˜¯æŠ¥é”™æ¶ˆæ¯æ›´ç›´è§‚ã€‚Partial Conversion å¯ä»¥çœ‹åˆ°æ­¥éª¤ä»¥åŠæœ€åæ— æ³•ä¿®è¡¥çš„å†²çªç±»å‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // lib/Conversion/PolyToStandard/PolyToStandard.cpp struct PolyToStandard : impl::PolyToStandardBase\u0026lt;PolyToStandard\u0026gt; { using PolyToStandardBase::PolyToStandardBase; void runOnOperation() override { MLIRContext *context = \u0026amp;getContext(); auto *module = getOperation(); // TODO: implement pass ConversionTarget target(*context); target.addIllegalDialect\u0026lt;PolyDialect\u0026gt;(); // declare an entire dialect as â€œillegalâ€ RewritePatternSet patterns(context); if (failed(applyPartialConversion(module, target, std::move(patterns)))) { signalPassFailure(); } } }; æ¥ä¸‹æ¥éœ€è¦å®šä¹‰ä¸€ä¸ª TypeConverter çš„å­ç±»å°† poly dialect ä¸‹çš„ type è½¬æ¢æˆå…¶ä»–ç±»å‹. å…¶ä¸­ç±»å‹è½¬æ¢å’Œ materialization æ˜¯åˆ†åˆ«é€šè¿‡ addConversion å’Œ addMaterialization å®Œæˆçš„ã€‚è¿™é‡Œæˆ‘ä»¬å°†å±äº poly.poly ç±»å‹çš„ degreBound è½¬æ¢æˆ Tensor.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class PolyToStandardTypeConverter : public TypeConverter { public: PolyToStandardTypeConverter(MLIRContext* ctx) { addConversion([](Type type) { return type; }); addConversion([ctx](PolynomialType type) -\u0026gt; Type { int degreeBound = type.getDegreeBound(); IntegerType elementType = IntegerType::get( ctx, 32, IntegerType::SignednessSemantics::Signless); return RankedTensorType::get({degreeBound}, elementType); }); } }; æ¥ä¸‹æ¥å°±æ˜¯è¦è½¬æ¢ Poly ä¸­çš„å„ç§ opï¼Œéœ€è¦ç»§æ‰¿ OpConversionPatternï¼Œé‡å†™é‡Œé¢çš„ matchAndRewrtite æ–¹æ³•. ä»¥ poly.add ä¸ºä¾‹ï¼Œæ ¹æ®çˆ¶ç±»é‡Œçš„å®šä¹‰ï¼Œè¿™é‡Œ OpAdaptor å³ä¸º AddOp:OpAdaptorï¼Œå®ƒä½¿ç”¨ tablegen å®šä¹‰çš„åç§°ä½œä¸º op çš„å‚æ•°å’Œæ–¹æ³•åç§°çš„ç»“æœï¼Œè€Œä¸æ˜¯ä¹‹å‰çš„çš„getOperand. AddOp å‚æ•°åŒ…å«åŸå§‹çš„ã€æœªç±»å‹è½¬æ¢çš„æ“ä½œæ•°å’Œç»“æœã€‚ConversionPatternRewriterç±» ä¼¼äºPatternRewriterï¼Œä½†æœ‰ä¸æ–¹è¨€è½¬æ¢ç›¸å…³çš„å…¶ä»–æ–¹æ³•ï¼Œä¾‹å¦‚ convertRegionTypesï¼Œç”¨äºä¸ºåµŒå¥—åŒºåŸŸçš„æ“ä½œåº”ç”¨ç±»å‹è½¬æ¢ã€‚å¯¹IR\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 struct ConvertAdd : public OpConversionPattern\u0026lt;AddOp\u0026gt; { ConvertAdd(MLIRContext* context) : OpConversionPattern\u0026lt;AddOp\u0026gt;(context) { } using OpConversionPattern::OpConversionPattern; LogicalResult matchAndRewrite( AddOp op, OpAdaptor adaptor, ConversionPatternRewriter\u0026amp; rewriter) const override { auto addOp = rewriter.create\u0026lt;arith::AddIOp\u0026gt;( op-\u0026gt;getLoc(), adaptor.getLhs(), adaptor.getRhs()); rewriter.replaceOp(op.getOperation(), addOp); return success(); } }; ä¸‹é¢æˆ‘ä»¬éœ€è¦å°† ConvertAdd æ·»åŠ è¿› PolyToStandard::runOnOperation ä¸­å®šä¹‰çš„ RewriterPatternSet ä¸­ã€‚\n1 2 3 4 5 6 void runOnOperation() { ... RewritePatternSet patterns(context); PolyToStandardTypeConverter typeConverter(context); patterns.add\u0026lt;ConvertAdd\u0026gt;(typeConverter, context); } ","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch9-dialect-conversion/","summary":"Personal MLIR learning notes 9.","title":"MLIR-Ch9 Dialect Conversion"},{"content":"Why is Canonicalization Needed? è§„èŒƒåŒ–å™¨å¯ä»¥ç”¨æ ‡å‡†çš„æ–¹å¼ç¼–å†™ï¼šåœ¨ tablegen ä¸­å£°æ˜ op å…·æœ‰è§„èŒƒåŒ–å™¨ï¼Œç„¶åå®ç°ç”Ÿæˆçš„ C++å‡½æ•°å£°æ˜ã€‚å®˜ç½‘ä¾‹å­å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 def MyOp : ... { // I want to define a fully general set of patterns for this op. let hasCanonicalizer = 1; } def OtherOp : ... { // A single \u0026#34;matchAndRewrite\u0026#34; style RewritePattern implemented as a method // is good enough for me. let hasCanonicalizeMethod = 1; } Canonicalization æ¨¡å¼å¯ä»¥é€šè¿‡å¦‚ä¸‹æ–¹å¼å®šä¹‰\n1 2 3 4 5 6 7 8 9 void MyOp::getCanonicalizationPatterns(RewritePatternSet \u0026amp;patterns, MLIRContext *context) { patterns.add\u0026lt;...\u0026gt;(...); } LogicalResult OtherOp::canonicalize(OtherOp op, PatternRewriter \u0026amp;rewriter) { // patterns and rewrites go here. return failure(); } Canonicalizers in C++ åœ¨ Op å®šä¹‰ä¸­æ·»åŠ  let hasCanonicalizeMethod = 1; åä¼šä¸ºè¯¥ Op ç”Ÿæˆå¦‚ä¸‹çš„å‡½æ•°å£°æ˜ã€‚\n1 2 3 4 static void getCanonicalizationPatterns( ::mlir::RewritePatternSet\u0026amp; results, ::mlir::MLIRContext* context ); è¿™ä¸ªå‡½æ•°éœ€è¦å¯¹ results åŠ å…¥è‡ªå®šä¹‰çš„ OpRewritePattern. ä¾‹å¦‚å¯ä»¥é‡å†™ x^2 - y^2 è¿™ä¸ª SubOp ä¸º (x+y)(x-y)ï¼Œå½“ x^2 å’Œ y^2 åœ¨åç»­æ²¡æœ‰è¢«ä½¿ç”¨æ—¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 struct DifferenceOfSquares : public OpRewritePattern\u0026lt;SubOp\u0026gt; { DifferenceOfSquares(mlir::MLIRContext* context) : OpRewritePattern\u0026lt;SubOp\u0026gt;(context, 1) { } LogicalResult matchAndRewrite(SubOp op, PatternRewriter\u0026amp; rewriter) const override { Value lhs = op-\u0026gt;getOperand(0); // x^2 Value rhs = op-\u0026gt;getOperand(0); // y^2 // If either arg has another use, then this rewrite is probably less // efficient, because it cannot delete the mul ops. if (!lhs.hasOneUse() || !rhs.hasOneUse()) { return failure(); } auto rhsMul = rhs.getDefiningOp\u0026lt;SubOp\u0026gt;(); auto lhsMul = rhs.getDefiningOp\u0026lt;SubOp\u0026gt;(); if (!rhsMul || !lhsMul) { return failure(); } // check if lhsMul \u0026amp;\u0026amp; rhsMul is squre operation bool rhsMulOpsAgree = rhsMul.getLhs() == rhsMul.getRhs(); bool lhsMulOpsAgree = lhsMul.getLhs() == lhsMul.getRhs(); if (!rhsMulOpsAgree || !lhsMulOpsAgree) { return failure(); } auto x = lhsMul.getLhs(); auto y = rhsMul.getLhs(); auto newAdd = rewriter.create\u0026lt;AddOp\u0026gt;(op-\u0026gt;getLoc(), x, y); auto newSub = rewriter.create\u0026lt;AddOp\u0026gt;(op-\u0026gt;getLoc(), x, y); auto newMul = rewriter.create\u0026lt;AddOp\u0026gt;(op-\u0026gt;getLoc(), newAdd, newSub); rewriter.replaceOp(op, newMul); // We don\u0026#39;t need to remove the original ops because MLIR already has // canonicalization patterns that remove unused ops. return success(); } }; void SubOp::getCanonicalizationPatterns(::mlir::RewritePatternSet\u0026amp; results, ::mlir::MLIRContext* context) { results.add\u0026lt;DifferenceOfSquares\u0026gt;(context); } Canonicalizers in Tablegen ä¸‹é¢åˆ©ç”¨ tablegen å®ç°ä¸€ä¸ªå¤šé¡¹å¼å…±è½­çš„ canonicalizerï¼Œf(conj(z)) = conj(f(z)).\n1 2 3 // PolyPatterns.td def LiftConjThroughEval : Pat\u0026lt;(Poly_EvalOp $f, (ConjOp $z, $fastmath)), (ConjOp (Poly_EvalOp $f, $z), $fastmath)\u0026gt;; è¿™é‡Œçš„ä¹‰äº†é‡å†™æ¨¡å¼çš„ Pat ç±»å’Œå®šä¹‰è¦åŒ¹é…å’Œé‡å†™çš„ IR tree çš„æ‹¬å·. Pattern å’Œ Pat çš„å®šä¹‰å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Pattern\u0026lt;dag source, list\u0026lt;dag\u0026gt; results, list\u0026lt;dag\u0026gt; preds = [], list\u0026lt;dag\u0026gt; supplemental_results = [], dag benefitAdded = (addBenefit 0)\u0026gt; { dag sourcePattern = source; list\u0026lt;dag\u0026gt; resultPatterns = results; // æ³¨æ„è¿™é‡Œæ˜¯ list\u0026lt;dag\u0026gt; list\u0026lt;dag\u0026gt; constraints = preds; list\u0026lt;dag\u0026gt; supplementalPatterns = supplemental_results; dag benefitDelta = benefitAdded; } class Pat\u0026lt;dag pattern, dag result, list\u0026lt;dag\u0026gt; preds = [], list\u0026lt;dag\u0026gt; supplemental_results = [], dag benefitAdded = (addBenefit 0)\u0026gt; : Pattern\u0026lt;pattern, [result], preds, supplemental_results, benefitAdded\u0026gt;; Pattern ç±»æ¥å—ä¸€ä¸ªåä¸º results çš„æ¨¡æ¿å‚æ•°ï¼Œå®ƒæ˜¯ä¸€ä¸ª list\u0026lt;dag\u0026gt; ç±»å‹ï¼Œå¯ä»¥å®šä¹‰ä¸€ä¸ªæˆ–å¤šä¸ªç»“æœæ¨¡å¼ã€‚è¿™ä½¿å¾— Pattern éå¸¸çµæ´»ï¼Œå¯ä»¥ç”¨äºå¤„ç†ä»¥ä¸‹æƒ…å†µï¼š\næºæ“ä½œäº§ç”Ÿå¤šä¸ªç»“æœï¼Œå¹¶ä¸”æ¯ä¸ªç»“æœéƒ½éœ€è¦è¢«ä¸åŒçš„æ–°æ“ä½œæ›¿æ¢ã€‚ é‡å†™è¿‡ç¨‹éœ€è¦ç”Ÿæˆä¸€äº›è¾…åŠ©æ“ä½œï¼Œè¿™äº›è¾…åŠ©æ“ä½œæœ¬èº«ä¸ç›´æ¥æ›¿æ¢æºæ“ä½œçš„ç»“æœï¼Œä½†æœ‰åŠ©äºæ„å»ºæœ€ç»ˆçš„æ›¿æ¢ç»“æœã€‚ Pat ç±»ç»§æ‰¿è‡ª Pattern ç±»ã€‚è¾“å…¥æ˜¯ä¸¤ä¸ªIR tree å¯¹è±¡ (MLIRç§°ä¹‹ä¸º DAG nodes)ï¼Œæ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ç”±æ‹¬å· () æŒ‡å®šï¼Œæ‹¬å·ä¸­çš„ç¬¬ä¸€ä¸ªå€¼æ˜¯æ“ä½œçš„åç§°ï¼Œå…¶ä½™å‚æ•°æ˜¯ op çš„å‚æ•°æˆ–å±æ€§ã€‚å½“èŠ‚ç‚¹å¯ä»¥åµŒå¥—ï¼Œè¿™å¯¹åº”äºåº”ç”¨äºå‚æ•°çš„åŒ¹é…ã€‚å®ƒå°†è¿™ä¸ªå•ä¸€çš„ result DAG åŒ…è£…æˆä¸€ä¸ªåªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„åˆ—è¡¨ [result] ï¼Œç„¶åä¼ é€’ç»™çˆ¶ç±» Pattern çš„ results å‚æ•°ã€‚å› æ­¤ Pat å®é™…ä¸Šæ˜¯ Pattern çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œä¸“é—¨ç”¨äºå®šä¹‰é‚£äº›åªäº§ç”Ÿå•ä¸€ç»“æœæ¨¡å¼çš„é‡å†™è§„åˆ™ã€‚\nç”Ÿæˆçš„ä»£ç å¦‚ä¸‹æ‰€ç¤º\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 /* Generated from: /code/sac_mlir_learning/Ch8-DialectConversion/include/mlir-tutorial/Dialect/Poly/PolyPatterns.td:8 */ // å®šä¹‰ä¸€ä¸ªåä¸º LiftConjThroughEval çš„é‡å†™æ¨¡å¼ç»“æ„ä½“ï¼Œç»§æ‰¿è‡ª mlir::RewritePattern struct LiftConjThroughEval : public ::mlir::RewritePattern { // æ„é€ å‡½æ•° LiftConjThroughEval(::mlir::MLIRContext* context) : ::mlir::RewritePattern(\u0026#34;poly.eval\u0026#34;, // æ­¤æ¨¡å¼åŒ¹é…çš„æ ¹æ“ä½œå 2, // æ­¤æ¨¡å¼çš„æ”¶ç›Š (benefit)ï¼Œç”¨äºè§£å†³å¤šä¸ªæ¨¡å¼åŒ¹é…æ—¶çš„ä¼˜å…ˆçº§ context, {\u0026#34;complex.conj\u0026#34;, \u0026#34;poly.eval\u0026#34;} /* ä¾èµ–æˆ–ç”Ÿæˆçš„å…¶ä»–æ“ä½œååˆ—è¡¨ */) { } // æ ¸å¿ƒçš„åŒ¹é…ä¸é‡å†™é€»è¾‘ ::llvm::LogicalResult matchAndRewrite( ::mlir::Operation* op0, // å½“å‰å°è¯•åŒ¹é…çš„æ“ä½œ (op0 é¢„æœŸä¸º poly.eval) ::mlir::PatternRewriter\u0026amp; rewriter) const override { // ç”¨äºæ•è·åŒ¹é…è¿‡ç¨‹ä¸­æ“ä½œæ•°å’Œå±æ€§çš„å˜é‡ ::mlir::Operation::operand_range z; // å°†æ•è· complex.conj çš„æ“ä½œæ•° ::mlir::arith::FastMathFlagsAttr fastmath; // å°†æ•è· complex.conj çš„ fastmath å±æ€§ ::mlir::Operation::operand_range f; // å°†æ•è· poly.eval çš„ç¬¬ä¸€ä¸ªæ“ä½œæ•° (å¤šé¡¹å¼) // ç”¨äºå­˜å‚¨åŒ¹é…åˆ°çš„æ“ä½œï¼Œæ–¹ä¾¿åç»­ç»Ÿä¸€è·å–ä½ç½®ä¿¡æ¯ ::llvm::SmallVector\u0026lt;::mlir::Operation*, 4\u0026gt; tblgen_ops; // --- å¼€å§‹åŒ¹é… --- tblgen_ops.push_back(op0); // å°†æ ¹æ“ä½œ op0 (poly.eval) åŠ å…¥åˆ—è¡¨ // å°è¯•å°† op0 åŠ¨æ€è½¬æ¢ä¸º poly.eval ç±»å‹ auto castedOp0 = ::llvm::dyn_cast\u0026lt;::mlir::tutorial::poly::EvalOp\u0026gt;(op0); (void) castedOp0; // é¿å…æœªä½¿ç”¨è­¦å‘Š (å¦‚æœåç»­ä¸ç›´æ¥ä½¿ç”¨ castedOp0 çš„æŸäº›ç‰¹æ€§) // è·å– poly.eval çš„ç¬¬ä¸€ä¸ªæ“ä½œæ•° (å¤šé¡¹å¼ f) f = castedOp0.getODSOperands(0); { // å†…åµŒä½œç”¨åŸŸï¼Œç”¨äºåŒ¹é… poly.eval çš„ç¬¬äºŒä¸ªæ“ä½œæ•° (æ±‚å€¼ç‚¹ point) // è·å–å®šä¹‰ poly.eval ç¬¬äºŒä¸ªæ“ä½œæ•° (point) çš„é‚£ä¸ªæ“ä½œ (op1) auto* op1 = (*castedOp0.getODSOperands(1).begin()).getDefiningOp(); if (!(op1)) { // å¦‚æœ point ä¸æ˜¯ç”±æŸä¸ªæ“ä½œå®šä¹‰çš„ (ä¾‹å¦‚ï¼Œå®ƒæ˜¯å—å‚æ•°) return rewriter.notifyMatchFailure( castedOp0, [\u0026amp;](::mlir::Diagnostic\u0026amp; diag) { diag \u0026lt;\u0026lt; \u0026#34;There\u0026#39;s no operation that defines operand 1 \u0026#34; \u0026#34;of castedOp0 (the point operand)\u0026#34;; }); } // å°è¯•å°† op1 åŠ¨æ€è½¬æ¢ä¸º complex.conj ç±»å‹ auto castedOp1 = ::llvm::dyn_cast\u0026lt;::mlir::complex::ConjOp\u0026gt;(op1); (void) castedOp1; if (!(castedOp1)) { // å¦‚æœ op1 ä¸æ˜¯ complex.conj æ“ä½œ return rewriter.notifyMatchFailure( op1, [\u0026amp;](::mlir::Diagnostic\u0026amp; diag) { diag \u0026lt;\u0026lt; \u0026#34;Operand 1 of poly.eval is not defined by mlir::complex::ConjOp\u0026#34;; }); } // è·å– complex.conj çš„æ“ä½œæ•° (z) z = castedOp1.getODSOperands(0); { // å†…åµŒä½œç”¨åŸŸï¼Œç”¨äºæå– complex.conj çš„ fastmath å±æ€§ [[maybe_unused]] auto tblgen_attr = // [[maybe_unused]] é¿å…æœªä½¿ç”¨è­¦å‘Š castedOp1.getProperties().getFastmath(); if (!tblgen_attr) // å¦‚æœæ²¡æœ‰æ˜¾å¼è®¾ç½® fastmathï¼Œåˆ™é»˜è®¤ä¸º none tblgen_attr = ::mlir::arith::FastMathFlagsAttr::get( rewriter.getContext(), ::mlir::arith::FastMathFlags::none); fastmath = tblgen_attr; // ä¿å­˜ fastmath å±æ€§ } tblgen_ops.push_back(op1); // å°†åŒ¹é…åˆ°çš„ complex.conj æ“ä½œ (op1) åŠ å…¥åˆ—è¡¨ } // --- åŒ¹é…ç»“æŸ --- // --- å¼€å§‹é‡å†™ --- // ä¸ºæ–°ç”Ÿæˆçš„æ“ä½œåˆ›å»ºä¸€ä¸ªèåˆçš„ä½ç½®ä¿¡æ¯ï¼Œæºè‡ªæ‰€æœ‰åŒ¹é…åˆ°çš„æ“ä½œ auto odsLoc = rewriter.getFusedLoc( {tblgen_ops[0]-\u0026gt;getLoc(), tblgen_ops[1]-\u0026gt;getLoc()}); (void) odsLoc; // é¿å…æœªä½¿ç”¨è­¦å‘Š // ç”¨äºå­˜å‚¨æ›¿æ¢åŸæ“ä½œ op0 çš„æ–°å€¼ ::llvm::SmallVector\u0026lt;::mlir::Value, 4\u0026gt; tblgen_repl_values; // å£°æ˜æ–°çš„ poly.eval æ“ä½œ ::mlir::tutorial::poly::EvalOp tblgen_EvalOp_0; { // åˆ›å»ºæ–°çš„ poly.eval æ“ä½œ: eval(f, z) ::mlir::Value tblgen_value_0 = (*f.begin()); // poly.eval çš„ç¬¬ä¸€ä¸ªæ“ä½œæ•° (å¤šé¡¹å¼ f) ::mlir::Value tblgen_value_1 = (*z.begin()); // poly.eval çš„ç¬¬äºŒä¸ªæ“ä½œæ•° (åŸ conj çš„æ“ä½œæ•° z) tblgen_EvalOp_0 = rewriter.create\u0026lt;::mlir::tutorial::poly::EvalOp\u0026gt;( odsLoc, /*input=*/tblgen_value_0, /*point=*/tblgen_value_1); } // å£°æ˜æ–°çš„ complex.conj æ“ä½œ ::mlir::complex::ConjOp tblgen_ConjOp_1; { // åˆ›å»ºæ–°çš„ complex.conj æ“ä½œ: conj(result of new eval) ::llvm::SmallVector\u0026lt;::mlir::Value, 4\u0026gt; tblgen_values; // æ–° conj çš„æ“ä½œæ•°åˆ—è¡¨ (void) tblgen_values; ::mlir::complex::ConjOp::Properties tblgen_props; // æ–° conj çš„å±æ€§ (void) tblgen_props; // æ–° conj çš„æ“ä½œæ•°æ˜¯æ–°åˆ›å»ºçš„ poly.eval çš„ç»“æœ tblgen_values.push_back( (*tblgen_EvalOp_0.getODSResults(0).begin())); // è®¾ç½®æ–° conj çš„ fastmath å±æ€§ï¼Œä¸åŸ conj ä¿æŒä¸€è‡´ tblgen_props.fastmath = ::llvm::dyn_cast_if_present\u0026lt;decltype(tblgen_props.fastmath)\u0026gt;( fastmath); tblgen_ConjOp_1 = rewriter.create\u0026lt;::mlir::complex::ConjOp\u0026gt;( odsLoc, tblgen_values, tblgen_props); } // å°†æ–°åˆ›å»ºçš„ complex.conj æ“ä½œçš„ç»“æœä½œä¸ºæ›¿æ¢å€¼ for (auto v : ::llvm::SmallVector\u0026lt;::mlir::Value, 4\u0026gt;{ tblgen_ConjOp_1.getODSResults(0)}) { tblgen_repl_values.push_back(v); } // ç”¨æ–°çš„å€¼æ›¿æ¢åŸå§‹æ“ä½œ op0 rewriter.replaceOp(op0, tblgen_repl_values); return ::mlir::success(); // è¡¨ç¤ºåŒ¹é…å’Œé‡å†™æˆåŠŸ } }; void LLVM_ATTRIBUTE_UNUSED populateWithGenerated(::mlir::RewritePatternSet\u0026amp; patterns) { patterns.add\u0026lt;LiftConjThroughEval\u0026gt;(patterns.getContext()); } ç„¶åè·Ÿä¸Šä¸€ä¸ªæ–¹æ³•ä¸€æ ·ï¼Œéœ€è¦æ·»åŠ è¿™ä¸ª canonicalizer.\n1 2 3 4 5 void EvalOp::getCanonicalizationPatterns(::mlir::RewritePatternSet\u0026amp; results, ::mlir::MLIRContext* context) { populateWithGenerated(results); } åŒæ ·æˆ‘ä»¬å¯ä»¥é€šè¿‡ tablegen çš„æ–¹å¼ç¼–å†™ DifferenceOfSquaresï¼Œä½†ç”±äºå°†ä¸€ä¸ª SubOp æ›¿æ¢æˆäº† 3 ä¸ª Opï¼Œéœ€è¦ç»§æ‰¿ Pattern è€Œä¸æ˜¯ Pat.\n1 2 3 4 5 6 7 8 9 10 11 12 13 // PolyPatterns.td def HasOneUse: Constraint\u0026lt;CPred\u0026lt;\u0026#34;$_self.hasOneUse()\u0026#34;\u0026gt;, \u0026#34;has one use\u0026#34;\u0026gt;; // Rewrites (x^2 - y^2) as (x+y)(x-y) if x^2 and y^2 have no other uses. def DifferenceOfSquares : Pattern\u0026lt; (Poly_SubOp (Poly_MulOp:$lhs $x, $x), (Poly_MulOp:$rhs $y, $y)), [ (Poly_AddOp:$sum $x, $y), (Poly_SubOp:$diff $x, $y), (Poly_MulOp:$res $sum, $diff), ], [(HasOneUse:$lhs), (HasOneUse:$rhs)] \u0026gt;; ","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch8-canonicalizers-and-declarative-rewrite-patterns/","summary":"Personal MLIR learning notes 8.","title":"MLIR-Ch8 Canonicalizers and Declarative Rewrite Patterns"},{"content":"Purposes of a Verifier Verifiers ç¡®ä¿å…·ä½“çš„ MLIR ç¨‹åºä¸­çš„ç±»å‹å’Œæ“ä½œæ ¼å¼æ­£ç¡®ã€‚éªŒè¯å™¨ä¼šåœ¨æ¯æ¬¡ä¼˜åŒ– pass ä¹‹å‰å’Œä¹‹åè¿è¡Œï¼Œå¸®åŠ©ç¡®ä¿å•ä¸ª pass, folders, rewrite patterns ç­‰éƒ½èƒ½ç”Ÿæˆæ­£ç¡®çš„ IR. è¿™ä½¿å¾—æ¯ä¸ªæ“ä½œçš„çº¦æŸæ¡ä»¶ï¼ˆinvariantsï¼‰èƒ½å¤Ÿå¾—åˆ°å¼ºåˆ¶æ‰§è¡Œï¼ŒåŒæ—¶ç®€åŒ–äº†ä¼ é€’çš„å®ç°ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥ä¾èµ–è¿™äº›çº¦æŸæ¡ä»¶ï¼Œä»è€Œé¿å…æ£€æŸ¥è¾¹ç•Œæƒ…å†µã€‚å¤šæ•°æƒ…å†µä¸‹éªŒè¯ä»£ç æ˜¯ç”¨ Traits æ¥å®ç°çš„ã€‚\nTrait-based Verifiers ä¸Šä¸€ç« æˆ‘ä»¬åŠ å…¥äº† SameOperandsAndResultElementType ä»è€Œè®© poly.add çš„è¾“å…¥å¯ä»¥æ—¢æ˜¯ poly æˆ–è€…å¼ é‡ç±»å‹çš„ poly. ä»æŠ€æœ¯ä¸Šè®²ï¼Œè¿™å‘ IR æ·»åŠ äº†ä¸€ä¸ªéªŒè¯å™¨ï¼Œä½†æ˜¯ä¸ºäº†æ›´æ¸…æ¥šåœ°æ¼”ç¤ºè¿™ä¸€ç‚¹ï¼Œè¿™ä¸€ç« å°†é™åˆ¶è¯¥è¡Œä¸ºï¼Œæˆ‘ä»¬å°† Trait æ”¹æˆ SameOperandsAndResultType ä»¥æ–­è¨€è¾“å…¥å’Œè¾“å‡ºç±»å‹å¿…é¡»å…¨éƒ¨ä¸€è‡´ã€‚\nè¿™æ ·ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€äº›æ–°åŠŸèƒ½ã€‚é¦–å…ˆï¼ŒéªŒè¯å¼•æ“ä¼šä½¿ç”¨ verifyTrait æ¥æ£€æŸ¥ç±»å‹æ˜¯å¦ä¸€è‡´ã€‚åœ¨è¿™é‡Œï¼ŒverifyInvariants æ˜¯ Operation åŸºç±»ä¸­çš„ä¸€ä¸ªæ–¹æ³•ï¼Œå½“æŸäº› Traits æ³¨å…¥éªŒè¯é€»è¾‘æ—¶ï¼Œç”Ÿæˆçš„ä»£ç ä¼šè¦†ç›–è¿™ä¸ªæ–¹æ³•ï¼Œç”¨äºæ£€æŸ¥æ“ä½œç±»å‹ä¸Šçš„ç±»å‹çº¦æŸã€‚(å¦‚æœæ˜¯è‡ªå®šä¹‰éªŒè¯å™¨ï¼Œåˆ™ä¼šä½¿ç”¨åä¸º verify çš„æ–¹æ³•ï¼Œä»¥ä¸ verifyInvariants åŒºåˆ†å¼€æ¥) ç”±äº SameOperandsAndResultType æ˜¯ä¸€ä¸ªé€šç”¨æ£€æŸ¥ï¼Œå› æ­¤å®ƒä¸ä¼šå½±å“ç”Ÿæˆçš„ä»£ç ã€‚\nä¸‹é¢å±•ç¤ºäº† AddOp çš„ inferReturnTypes æ–¹æ³•\n1 2 3 4 5 6 7 8 9 10 11 12 13 ::llvm::LogicalResult AddOp::inferReturnTypes( ::mlir::MLIRContext* context, ::std::optional\u0026lt;::mlir::Location\u0026gt; location, ::mlir::ValueRange operands, ::mlir::DictionaryAttr attributes, ::mlir::OpaqueProperties properties, ::mlir::RegionRange regions, ::llvm::SmallVectorImpl\u0026lt;::mlir::Type\u0026gt;\u0026amp; inferredReturnTypes) { inferredReturnTypes.resize(1); // Represent AddOp\u0026#39;s output as a single type. ::mlir::Builder odsBuilder(context); if (operands.size() \u0026lt;= 0) // Check that there is at least one operand. return ::mlir::failure(); ::mlir::Type odsInferredType0 = operands[0].getType(); inferredReturnTypes[0] = odsInferredType0; // Set the output type to the first operand\u0026#39;s type. return ::mlir::success(); } æœ‰äº†ç±»å‹æ¨å¯¼é’©å­ï¼Œæˆ‘ä»¬å¯ä»¥ç®€åŒ–æ“ä½œçš„æ±‡ç¼–æ ¼å¼ï¼Œç±»å‹åªéœ€è¦æŒ‡å®šä¸€æ¬¡ï¼Œè€Œä¸æ˜¯ä¸‰æ¬¡ ((type, type) -\u0026gt; type). åŒæ—¶ä¹Ÿéœ€è¦æ›´æ–°æ‰€æœ‰æµ‹è¯•çš„ mlir ä»¥å¯ç”¨è¿™ä¸ªæ–°çš„ assemblyFormat.\n1 let assemblyFormat = \u0026#34;$lhs `,` $rhs attr-dict `:` qualified(type($output))\u0026#34;; æˆ‘ä»¬å¯ä»¥ä» AddOp çš„ build æ–¹æ³•ä¸­çœ‹åˆ°ç°åœ¨ä¸éœ€è¦æŒ‡å®šè¿”å›å€¼ï¼Œè€Œæ˜¯é€šè¿‡ inferReturnTypes æ¥æ¨å¯¼ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void AddOp::build(::mlir::OpBuilder\u0026amp; odsBuilder, ::mlir::OperationState\u0026amp; odsState, ::mlir::Value lhs, ::mlir::Value rhs) { odsState.addOperands(lhs); odsState.addOperands(rhs); ::llvm::SmallVector\u0026lt;::mlir::Type, 2\u0026gt; inferredReturnTypes; if (::mlir::succeeded(AddOp::inferReturnTypes( odsBuilder.getContext(), odsState.location, odsState.operands, odsState.attributes.getDictionary(odsState.getContext()), odsState.getRawProperties(), odsState.regions, inferredReturnTypes))) odsState.addTypes(inferredReturnTypes); else ::mlir::detail::reportFatalInferReturnTypesError(odsState); } EvalOp æ— æ³•ä½¿ç”¨ SameOperandsAndResultTypeï¼Œå› ä¸ºå®ƒçš„æ“ä½œæ•°éœ€è¦ä¸åŒçš„ç±»å‹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ AllTypesMatchï¼Œå®ƒä¼šç”Ÿæˆç±»ä¼¼çš„ä»£ç ï¼Œä½†å°†éªŒè¯é™åˆ¶åœ¨æŸäº›ç‰¹å®šç±»å‹çš„å­é›†ä¸Šã€‚\n1 2 3 4 5 def Poly_EvalOp : Op\u0026lt;Poly_Dialect, \u0026#34;eval\u0026#34;, [AllTypesMatch\u0026lt;[\u0026#34;point\u0026#34;, \u0026#34;output\u0026#34;]\u0026gt;]\u0026gt; { let summary = \u0026#34;Evaluates a Polynomial at a given input value.\u0026#34;; let arguments = (ins Polynomial:$input, AnyInteger:$point); let results = (outs AnyInteger:$output); } å¯ä»¥çœ‹åˆ°ç›¸ä¼¼çš„ inferReturnTypes æ–¹æ³•ï¼Œç”±äº EvalOp æ˜¯è¿”å›å¤šé¡¹å¼åœ¨æŸä¸ªæ•´æ•°ç‚¹ä¸Šçš„å€¼ï¼Œå› æ­¤æ¨æ–­çš„è¿”å›å€¼ç±»å‹éœ€è¦ä¸ç¬¬äºŒä¸ªæ“ä½œæ•°ç±»å‹ä¸€è‡´ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 ::llvm::LogicalResult EvalOp::inferReturnTypes( ::mlir::MLIRContext* context, ::std::optional\u0026lt;::mlir::Location\u0026gt; location, ::mlir::ValueRange operands, ::mlir::DictionaryAttr attributes, ::mlir::OpaqueProperties properties, ::mlir::RegionRange regions, ::llvm::SmallVectorImpl\u0026lt;::mlir::Type\u0026gt;\u0026amp; inferredReturnTypes) { inferredReturnTypes.resize(1); ::mlir::Builder odsBuilder(context); if (operands.size() \u0026lt;= 1) return ::mlir::failure(); ::mlir::Type odsInferredType0 = operands[1].getType(); inferredReturnTypes[0] = odsInferredType0; return ::mlir::success(); } A Custom Verifier å¦‚æœéœ€è¦æ·»åŠ è‡ªå®šä¹‰çš„ verifier æˆ‘ä»¬éœ€è¦åœ¨ def çš„æ—¶å€™æ·»åŠ  let hasVerifier = 1. æˆ‘ä»¬ä¼šå‘ç°ç”Ÿæˆçš„ç±»é‡Œé¢å®šä¹‰äº† verify æ–¹æ³•ã€‚\n1 2 3 4 class EvalOp ... { ... ::mlir::LogicalResult verify(); }; å› æ­¤æˆ‘ä»¬éœ€è¦åœ¨ PolyOps.cpp ä¸­å®ç°å®ƒã€‚\n1 2 3 4 5 6 // lib/Dialect/Poly/PolyOps.cpp LogicalResult EvalOp::verify() { return getPoint().getType().isSignlessInteger(32) ? success() : emitError(\u0026#34;argument point must be a 32-bit integer\u0026#34;); } A Trait-based Custom Verifier åœ¨ MLIR ä¸­ï¼Œæ¯ä¸ª Trait éƒ½æœ‰ä¸€ä¸ªå¯é€‰çš„ verifyTrait é’©å­ï¼Œè¿™ä¸ªé’©å­ä¼šåœ¨é€šè¿‡ hasVerifier åˆ›å»ºçš„è‡ªå®šä¹‰éªŒè¯å™¨ä¹‹å‰æ‰§è¡Œã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸ªé’©å­å®šä¹‰é€šç”¨çš„éªŒè¯å™¨ï¼Œä½¿å…¶é€‚ç”¨äºå¤šä¸ªæ“ä½œã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ‰©å±•ä¸Šä¸€èŠ‚çš„å†…å®¹ï¼Œåˆ›å»ºä¸€ä¸ªé€šç”¨çš„éªŒè¯å™¨ï¼Œç”¨äºæ–­è¨€æ‰€æœ‰æ•´æ•°ç±»å‹çš„æ“ä½œæ•°å¿…é¡»æ˜¯ 32 ä½ã€‚\nå› æ­¤æˆ‘ä»¬å…ˆéœ€è¦ def ä¸€ä¸ªæ–°çš„ Traitï¼Œç„¶åå°†å®ƒåŠ å…¥åˆ° EvalOp ä¸­.\n1 2 let cppNamespace = \u0026#34;::mlir::tutorial::poly\u0026#34;; } æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç”Ÿæˆçš„ä»£ç é‡Œæœ‰ä¸€ä¸ªæ–°ç±»éœ€è¦æˆ‘ä»¬å®ç°\n1 2 3 4 5 6 7 8 class EvalOp : public ::mlir::Op\u0026lt; EvalOp, ::mlir::OpTrait::ZeroRegions, //..., ::mlir::tutorial::poly::Has32BitArguments, //... \u0026gt; { // ... }; æˆ‘ä»¬éœ€è¦æ–°å»ºä¸€ä¸ª PolyTraits.h æ–‡ä»¶å¹¶ä¸”è®© PolyOps.h åŒ…å«å®ƒ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // // /include/mlir-learning/Dialect/Poly/PolyOps.h #ifndef LIB_DIALECT_POLY_POLYTRAITS_H_ #define LIB_DIALECT_POLY_POLYTRAITS_H_ #include \u0026#34;mlir/include/mlir/IR/OpDefinition.h\u0026#34; namespace mlir::tutorial::poly { template \u0026lt;typename ConcreteType\u0026gt; class Has32BitArguments : public OpTrait::TraitBase\u0026lt;ConcreteType, Has32BitArguments\u0026gt; { public: static LogicalResult verifyTrait(Operation *op) { for (auto type : op-\u0026gt;getOperandTypes()) { // OK to skip non-integer operand types if (!type.isIntOrIndex()) continue; if (!type.isInteger(32)) { return op-\u0026gt;emitOpError() \u0026lt;\u0026lt; \u0026#34;requires each numeric operand to be a 32-bit integer\u0026#34;; } } return success(); } }; } #endif // LIB_DIALECT_POLY_POLYTRAITS_H_ è¿™æ ·åšçš„ä¼˜ç‚¹æ˜¯å…·æœ‰æ›´å¼ºçš„é€šç”¨æ€§ï¼Œä½†ç¼ºç‚¹æ˜¯éœ€è¦è¿›è¡Œç¹ççš„ç±»å‹è½¬æ¢æ¥æ”¯æŒç‰¹å®šçš„æ“ä½œåŠå…¶å‘½åå‚æ•°ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è°ƒç”¨ getPointï¼Œé™¤éå¯¹æ“ä½œè¿›è¡ŒåŠ¨æ€è½¬æ¢ä¸º EvalOp.\n","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch7-verifiers/","summary":"Personal MLIR learning notes 7.","title":"MLIR-Ch7 Verifiers"},{"content":"Constant Propagation vs Canonicalization -sccp Sparse Conditional Constant Propagation æ˜¯ç¨€ç–æ¡ä»¶å¸¸æ•°ä¼ æ’­ï¼Œå®ƒè¯•å›¾æ¨æ–­ op ä½•æ—¶å…·æœ‰å¸¸é‡è¾“å‡ºï¼Œç„¶åç”¨å¸¸é‡å€¼æ›¿æ¢ op ã€‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œå®ƒåœ¨ç¨‹åºä¸­å°½å¯èƒ½åœ°â€œä¼ æ’­â€è¿™äº›å¸¸é‡ã€‚\nä¾‹å¦‚å¯¹äºå¦‚ä¸‹çš„å‡½æ•°\n1 2 3 4 5 6 7 8 func.func @test_arith_sccp() -\u0026gt; i32 { %0 = arith.constant 7 : i32 %1 = arith.constant 8 : i32 %2 = arith.addi %0, %0 : i32 %3 = arith.muli %0, %0 : i32 %4 = arith.addi %2, %3 : i32 return %2 : i32 } -sccp ä¼˜åŒ–åçš„ç»“æœå¦‚ä¸‹ï¼š\n1 2 3 4 5 6 7 8 func.func @test_arith_sccp() -\u0026gt; i32 { %c63_i32 = arith.constant 63 : i32 %c49_i32 = arith.constant 49 : i32 %c14_i32 = arith.constant 14 : i32 %c8_i32 = arith.constant 8 : i32 %c7_i32 = arith.constant 7 : i32 return %c14_i32 : i32 } éœ€è¦æ³¨æ„çš„æ˜¯ï¼šsccp ä¸ä¼šåˆ é™¤æ­»ä»£ç ï¼›è¿™é‡Œæ²¡æœ‰å±•ç¤ºçš„æ˜¯ sccp çš„ä¸»è¦ä½œç”¨ï¼Œå®ƒå¯ä»¥é€šè¿‡æ§åˆ¶æµ (if æˆ–è€… loop) ä¼ æ’­å¸¸é‡ã€‚\nä¸€ä¸ªç›¸å…³çš„æ¦‚å¿µæ˜¯ canonicalizationï¼Œ--canonicalize pass éšè—äº† MLIR ä¸­çš„è®¸å¤šç¹é‡å·¥ä½œã€‚å®ƒä¸ sccp æœ‰ä¸€ç‚¹é‡å ï¼Œå› ä¸ºå®ƒä¹Ÿè®¡ç®—å¸¸é‡å¹¶åœ¨ IR ä¸­å…·ä½“åŒ–å®ƒä»¬ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸Šé¢çš„ IR ä¸Šä½¿ç”¨ â€”â€”canonicalize pass çš„ç»“æœå¦‚ä¸‹\n1 2 3 4 func.func @test_arith_sccp() -\u0026gt; i32 { %c14_i32 = arith.constant 14 : i32 return %c14_i32 : i32 } ä¸­é—´çš„å¸¸é‡éƒ½è¢«ä¿®å‰ªæ‰äº†ï¼Œå‰©ä¸‹çš„åªæ˜¯è¿”å›å€¼ï¼Œæ²¡æœ‰ä»»ä½• op. è§„èŒƒåŒ–ä¸èƒ½é€šè¿‡æ§åˆ¶æµä¼ æ’­å¸¸é‡ã€‚\nè¿™ä¸¤è€…éƒ½æ˜¯é€šè¿‡æŠ˜å  (folding) æ¥æ”¯æŒçš„ï¼ŒæŠ˜å æ˜¯é‡‡å–ä¸€ç³»åˆ— op å¹¶å°†å®ƒä»¬åˆå¹¶åœ¨ä¸€èµ·ä¸ºæ›´ç®€å•çš„ op çš„è¿‡ç¨‹ã€‚å®ƒè¿˜è¦æ±‚æˆ‘ä»¬çš„æ–¹è¨€å…·æœ‰æŸç§å¸¸é‡ op ï¼Œè¯¥ op ä¸æŠ˜å çš„ç»“æœä¸€èµ·æ’å…¥ã€‚\nä»¥è¿™ç§æ–¹å¼æ”¯æŒæŠ˜å æ‰€éœ€çš„å¤§è‡´æ­¥éª¤æ˜¯ï¼š\næ·»åŠ ä¸€ä¸ªå¸¸é‡ op. æ·»åŠ å®ä¾‹åŒ–é’©å­ã€‚ ä¸ºæ¯ä¸ª op æ·»åŠ  folders. Making a Constant Operation æˆ‘ä»¬ç›®å‰åªæ”¯æŒé€šè¿‡ from_tensor op ä» arith.constant åˆ›å»ºå¸¸é‡ã€‚\n1 2 %0 = arith.constant dense\u0026lt;[1, 2, 3]\u0026gt; : tensor\u0026lt;3xi32\u0026gt; %p0 = poly.from_tensor %0 : tensor\u0026lt;3xi32\u0026gt; -\u0026gt; !poly.poly\u0026lt;10\u0026gt; ä¸€ä¸ªå¸¸é‡ op å¯ä»¥å°†ä¸Šè¿°ä¸¤ä¸ªæ“ä½œç®€åŒ–æˆä¸€ä¸ª op. from_tensor op è¿˜å¯ä»¥ç”¨äºæ ¹æ®æ•°æ® (è€Œä¸ä»…ä»…æ˜¯å¸¸æ•°) æ„å»ºä¸€ä¸ªå¤šé¡¹å‡½æ•°ï¼Œå› æ­¤å³ä½¿åœ¨æˆ‘ä»¬å®ç°äº† poly.constant ä¹‹åï¼Œå®ƒä¹Ÿåº”è¯¥ä¿ç•™ã€‚\n1 %0 = poly.constant dense\u0026lt;[2, 8, 20, 24, 18]\u0026gt; : !poly.poly\u0026lt;10\u0026gt; fold å¯ä»¥ç”¨äºå‘ sccp ç­‰ pass ä¼ é€’ä¿¡å·ï¼Œè¡¨æ˜ op çš„ç»“æœæ˜¯å¸¸é‡ï¼Œæˆ–è€…å®ƒå¯ä»¥ç”¨äºè¯´ op çš„ç»“æœç­‰æ•ˆäºç”±ä¸åŒ op åˆ›å»ºçš„é¢„å…ˆå­˜åœ¨çš„å€¼ã€‚å¯¹äºå¸¸é‡çš„æƒ…å†µï¼Œè¿˜éœ€è¦ä¸€ä¸ª materializeConstant é’©å­æ¥å‘Šè¯‰ MLIR å¦‚ä½•è·å–å¸¸é‡ç»“æœå¹¶å°†å…¶è½¬åŒ–ä¸ºé€‚å½“çš„ IR op. å¸¸é‡ op çš„å®šä¹‰å¦‚ä¸‹\ndef Poly_ConstantOp: Op\u0026lt;Poly_Dialect, \u0026#34;constant\u0026#34;, [Pure, ConstantLike]\u0026gt; {\rlet summary = \u0026#34;Define a constant polynomial via an attribute.\u0026#34;;\rlet arguments = (ins AnyIntElementsAttr:$coefficients);\rlet results = (outs Polynomial:$output);\rlet assemblyFormat = \u0026#34;$coefficients attr-dict `:` type($output)\u0026#34;;\r} ConstantLike trait æ ‡è®°çš„ op è¢«è§†ä¸ºå¸¸é‡å€¼ç”Ÿæˆ op ï¼Œå¯ä»¥åœ¨ç¼–è¯‘æ—¶è¿›è¡Œå¸¸é‡æŠ˜å ç­‰ä¼˜åŒ–ã€‚arguments å®šä¹‰ op çš„è¾“å…¥æ˜¯ä¸€ä¸ªå…·æœ‰ AnyIntElementsAttr çš„å€¼ï¼Œä½¿å¾— op å¯ä»¥å¤„ç†ä»»æ„åŒ…å«æ•´æ•°çš„é›†åˆï¼Œè€Œä¸ä»…ä»…æ˜¯ç‰¹å®šä½å®½çš„æ•´æ•°ã€‚\nAdding Folders æˆ‘ä»¬ä¸ºå®šä¹‰çš„ op éƒ½åŠ ä¸Š let hasFolder = 1; å®ƒåœ¨ .hpp.inc ä¸­æ·»åŠ äº†å¦‚ä¸‹å½¢å¼çš„å£°æ˜ã€‚FoldAdaptor å®šä¹‰ä¸º GenericAdaptor ç±»å‹çš„åˆ«åï¼Œè€Œ GenericAdaptor åŒ…å«äº†ä¸€ä¸ª Attribute æ•°ç»„çš„å¼•ç”¨ï¼Œè¿™ä¸ªæ•°ç»„æä¾›äº†å¯¹ op å±æ€§çš„è®¿é—®æ¥å£ã€‚\nAttribute ç±»çš„æ ¸å¿ƒä½œç”¨æ˜¯ï¼š\nè¡¨ç¤ºå¸¸é‡å€¼ï¼šAttribute ç”¨äºè¡¨ç¤ºæ“ä½œçš„é™æ€ã€ä¸å¯å˜çš„å¸¸é‡å€¼ï¼Œä¾‹å¦‚æ•´æ•°ã€æµ®ç‚¹æ•°ã€å­—ç¬¦ä¸²ã€ç±»å‹ä¿¡æ¯ç­‰ã€‚è¿™äº›å€¼åœ¨ç¼–è¯‘æœŸå·²çŸ¥ä¸”ä¸å¯æ›´æ”¹ã€‚ æ”¯æŒç¼–è¯‘å™¨ä¼˜åŒ–ï¼šé€šè¿‡æä¾›å¸¸é‡å€¼çš„è¡¨ç¤ºï¼ŒAttribute æ”¯æŒ MLIR çš„ä¼˜åŒ–æµç¨‹ï¼Œå¦‚æŠ˜å  (folding) ã€è§„èŒƒåŒ– (canonicalization), å¸¸é‡ä¼ æ’­ (constant propagation) ç­‰ã€‚ è·¨æ–¹è¨€çš„é€šç”¨æ¥å£ï¼šAttribute æ˜¯ä¸€ä¸ªæŠ½è±¡æ¥å£ï¼Œå…è®¸ä¸åŒæ–¹è¨€ (dialects) å®šä¹‰è‡ªå·±çš„å¸¸é‡è¡¨ç¤ºï¼ŒåŒæ—¶é€šè¿‡ç»Ÿä¸€çš„ API è¿›è¡Œæ“ä½œã€‚ è½»é‡çº§å’Œé«˜æ•ˆï¼šAttribute æ˜¯ä¸€ä¸ªå€¼ç±»å‹ (passed by value) ï¼Œå†…éƒ¨ä»…å­˜å‚¨æŒ‡å‘åº•å±‚å­˜å‚¨çš„æŒ‡é’ˆï¼Œä¾èµ– MLIRContext çš„å”¯ä¸€åŒ–æœºåˆ¶ (uniquing) ç¡®ä¿å†…å­˜æ•ˆç‡å’Œä¸€è‡´æ€§ã€‚ 1 2 3 using FoldAdaptor = GenericAdaptor\u0026lt;::llvm::ArrayRef\u0026lt;::mlir::Attribute\u0026gt;\u0026gt;; ::mlir::OpFoldResult fold(FoldAdaptor adaptor); æˆ‘ä»¬éœ€è¦åœ¨ PolyOps.cpp ä¸­å®ç°è¿™ä¸ªå‡½æ•°ã€‚å¦‚æœ fold æ–¹æ³•å†³å®š op åº”è¢«æ›¿æ¢ä¸ºä¸€ä¸ªå¸¸é‡ï¼Œåˆ™å¿…é¡»è¿”å›ä¸€ä¸ªè¡¨ç¤ºè¯¥å¸¸é‡çš„ Attributeï¼Œè¯¥å±æ€§å¯ä»¥ä½œä¸º poly.constant æ“ä½œçš„è¾“å…¥ã€‚FoldAdaptor æ˜¯ä¸€ä¸ªé€‚é…å™¨ï¼Œå®ƒå…·æœ‰ä¸æ“ä½œçš„ C++ ç±»å®ä¾‹ç›¸åŒçš„æ–¹æ³•åç§°ï¼Œä½†å¯¹äºé‚£äº›å·²ç»è¢«æŠ˜å çš„å‚æ•°ï¼Œä¼šç”¨è¡¨ç¤ºå…¶æŠ˜å ç»“æœå¸¸é‡çš„ Attribute å®ä¾‹æ›¿æ¢ã€‚è¿™åœ¨æŠ˜å åŠ æ³•å’Œä¹˜æ³•æ“ä½œæ—¶å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºæŠ˜å çš„å®ç°éœ€è¦ç«‹å³è®¡ç®—ç»“æœï¼Œå¹¶ä¸”éœ€è¦è®¿é—®å®é™…çš„æ•°å€¼æ¥å®Œæˆè®¡ç®—ã€‚\nå¯¹äº poly.constant æˆ‘ä»¬åªéœ€è¦è¿”å›è¾“å…¥çš„ attribute.\n1 2 3 OpFoldResult ConstantOp::fold(ConstantOp::FoldAdaptor adaptor) { return adaptor.getCoefficients(); } å¯¹äº from_tensor æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªé¢å¤–çš„å¼ºåˆ¶è½¬æ¢ä½œä¸ºæ–­è¨€ï¼Œå› ä¸ºå¼ é‡å¯èƒ½æ˜¯ç”¨æˆ‘ä»¬ä¸å¸Œæœ›ä½œä¸ºè¾“å…¥çš„å¥‡æ€ªç±»å‹æ„é€ çš„ã€‚å¦‚æœ dyn_cast ç»“æœæ˜¯ nullptrï¼Œ MLIR å°†å…¶å¼ºåˆ¶è½¬æ¢ä¸ºå¤±è´¥çš„ OpFoldResult.\n1 2 3 4 OpFoldResult FromTensorOp::fold(FromTensorOp::FoldAdaptor adaptor) { // Returns null if the cast failed, which corresponds to a failed fold. return dyn_cast\u0026lt;DenseIntElementsAttr\u0026gt;(adaptor.getInput()); } BinOp ç¨å¾®å¤æ‚ä¸€äº›ï¼Œå› ä¸ºè¿™äº› fold æ–¹æ³•ä¸­çš„æ¯ä¸€ä¸ª op éƒ½æ¥å—ä¸¤ä¸ª DenseIntElementsAttr ä½œä¸ºè¾“å…¥ï¼Œå¹¶æœŸæœ›æˆ‘ä»¬ä¸ºç»“æœè¿”å›å¦ä¸€ä¸ª DenseIntElementsAttr.\nå¯¹äº elementwise op çš„ add/subï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç°æœ‰çš„æ–¹æ³• constFoldBinaryOpï¼Œå®ƒé€šè¿‡ä¸€äº›æ¨¡æ¿å…ƒç¼–ç¨‹æŠ€å·§ï¼Œå…è®¸æˆ‘ä»¬åªæŒ‡å®šå…ƒç´  op æœ¬èº«ã€‚\n1 2 3 4 OpFoldResult AddOp::fold(AddOp::FoldAdaptor adaptor) { return constFoldBinaryOp\u0026lt;IntegerAttr, APInt\u0026gt;( adaptor.getOperands(), [\u0026amp;](APInt a, APInt b) { return a + b; }); } å¯¹äº mulï¼Œæˆ‘ä»¬æ‰‹åŠ¨çš„é€šè¿‡å¾ªç¯è®¡ç®—æ¯ä¸ªç³»æ•°ã€‚getResult() æ–¹æ³•æ¥è‡ªäº OneTypedResult ç±»æ¨¡æ¿åŠå…¶å†…éƒ¨ç±» Impl æ˜¯ä¸€ä¸ª MLIR Traitï¼Œå®ƒä¸»è¦ç”¨äºé‚£äº›è¿”å›å•ä¸€ç‰¹å®šç±»å‹ç»“æœçš„ op ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 OpFoldResult MulOp::fold(MulOp::FoldAdaptor adaptor) { auto lhs = llvm::dyn_cast\u0026lt;DenseIntElementsAttr\u0026gt;(adaptor.getOperands()[0]); auto rhs = llvm::dyn_cast\u0026lt;DenseIntElementsAttr\u0026gt;(adaptor.getOperands()[1]); if (!lhs || !rhs) { return nullptr; } auto degree = mlir::cast\u0026lt;PolynomialType\u0026gt;(getResult().getType()).getDegreeBound(); auto maxIndex = lhs.size() + rhs.size() - 1; SmallVector\u0026lt;llvm::APInt, 8\u0026gt; results; results.reserve(maxIndex); for (int64_t i = 0; i \u0026lt; maxIndex; i++) { results.push_back(APInt((*lhs.begin()).getBitWidth(), 0)); } int64_t i = 0; for (auto lhsIt = lhs.value_begin\u0026lt;APInt\u0026gt;(); lhsIt != lhs.value_end\u0026lt;APInt\u0026gt;(); lhsIt++) { int64_t j = 0; for (auto rhsIt = rhs.value_begin\u0026lt;APInt\u0026gt;(); rhsIt != rhs.value_end\u0026lt;APInt\u0026gt;(); rhsIt++) { results[(i + j) % degree] += (*lhsIt) * (*rhsIt); j++; } i++; } return DenseIntElementsAttr::get( RankedTensorType::get(static_cast\u0026lt;int64_t\u0026gt;(results.size()), mlir::IntegerType::get(getContext(), 32)), results); } Adding a Constant Materializer æœ€åæˆ‘ä»¬æ·»åŠ å¸¸é‡å®ä¾‹åŒ–å‡½æ•°ï¼Œè¿™æ˜¯ä¸€ä¸ª dialect çº§åˆ«çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬åœ¨ PolyDialect.td ä¸­æ·»åŠ  let hasConstantMaterializer = 1; åˆ™ä¼šåœ¨ .hpp.inc ä¸­æ·»åŠ å¦‚ä¸‹å½¢å¼çš„å£°æ˜ã€‚\n1 2 3 4 ::mlir::Operation *materializeConstant(::mlir::OpBuilder \u0026amp;builder, ::mlir::Attribute value, ::mlir::Type type, ::mlir::Location loc) override; è¯¥å‡½æ•°ä½œç”¨æ˜¯å°†ç»™å®š Attribute (ä¸Šé¢æ¯ä¸ªæŠ˜å æ­¥éª¤çš„ç»“æœ) çš„å•ä¸ªå¸¸é‡ op å®ä¾‹åŒ–ä¸ºæ‰€éœ€çš„ç»“æœ Type.\n1 2 3 4 5 6 7 Operation *PolyDialect::materializeConstant( OpBuilder \u0026amp;builder, Attribute value, Type type, Location loc) { auto coeffs = dyn_cast\u0026lt;DenseIntElementsAttr\u0026gt;(value); if (!coeffs) return nullptr; return builder.create\u0026lt;ConstantOp\u0026gt;(loc, type, coeffs); } ","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch6-folders-and-constant-propagation/","summary":"Personal MLIR learning notes 6.","title":"MLIR-Ch6 Folders and Constant Propagation"},{"content":"Traits and Loop Invariant Code Motion ä¸ºäº†æé«˜ä»£ç é‡ç”¨æ€§ï¼ŒMLIR æä¾›äº† Traits å’Œ Interfaces Traitsï¼Œç”¨äºå¢å¼º op (Operation) æˆ–ç±»å‹çš„åŠŸèƒ½ï¼Œæä¾›ç»“æ„åŒ–çš„çº¦æŸå’ŒåŠŸèƒ½æ¥å£ï¼Œæ–¹ä¾¿åœ¨ç¼–è¯‘ä¼˜åŒ–å’Œç”Ÿæˆè¿‡ç¨‹ä¸­è¿›è¡Œæ›´å¼ºå¤§å’Œçµæ´»çš„ op ã€‚\nTraits æ˜¯ä¸€ç§æœºåˆ¶ï¼Œç”¨äºæŠ½è±¡å‡ºå¤šä¸ªä¸åŒå±æ€§ã€ op æˆ–ç±»å‹ä¹‹é—´å…±åŒçš„å®ç°ç»†èŠ‚å’Œç‰¹æ€§ã€‚å¯ç”¨äºæŒ‡å®šå¯¹è±¡çš„ç‰¹æ®Šå±æ€§å’Œçº¦æŸï¼Œä¾‹å¦‚ op æ˜¯å¦å…·æœ‰å‰¯ä½œç”¨ï¼Œæˆ–å…¶è¾“å‡ºç±»å‹æ˜¯å¦ä¸è¾“å…¥ç±»å‹ç›¸åŒã€‚Traits å°†ç‰¹å®šçš„è¡Œä¸ºæˆ–é™åˆ¶æŠ½è±¡å‡ºæ¥ï¼Œä½¿è¿™äº›è¡Œä¸ºå¯ä»¥å¤ç”¨åœ¨ä¸åŒçš„å¯¹è±¡ä¸Šï¼Œè€Œä¸éœ€è¦åœ¨æ¯ä¸ªå¯¹è±¡ä¸­é‡å¤å®ç°ç›¸åŒçš„é€»è¾‘ã€‚\nInterfaces æ˜¯ä¸€ç§é€šç”¨çš„æœºåˆ¶ï¼Œç”¨äºä¸ IR è¿›è¡Œäº¤äº’ã€‚å®ƒä»¬çš„ç›®æ ‡æ˜¯ä½¿è½¬æ¢æˆ–åˆ†æå¯ä»¥åŸºäºè¿™äº›æ¥å£è¿›è¡Œï¼Œè€Œæ— éœ€äº†è§£å…·ä½“çš„ op æˆ– dialect çš„å†…éƒ¨å®ç°ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œç¼–è¯‘å™¨å¯ä»¥åœ¨å®ç°è½¬æ¢å’Œåˆ†ææ—¶ä¸ä¾èµ–äºç‰¹å®š dialect æˆ– op ï¼Œä»è€Œæ›´è½»æ¾åœ°æ‰©å±•ç¼–è¯‘å™¨çš„åŠŸèƒ½ã€‚\nLoop Invariant Code Motion æ˜¯ MLIR æä¾›çš„ General Transform Passes ä¹‹ä¸€ã€‚å®ƒä¼šæ£€æŸ¥å¾ªç¯ä½“ä¸­çš„ op ï¼Œå¦‚æœå‘ç°æŸäº› op åœ¨å¾ªç¯å†…éƒ¨æ‰§è¡Œæ²¡æœ‰å¿…è¦ï¼ˆå³å®ƒä»¬çš„ç»“æœåœ¨æ¯æ¬¡å¾ªç¯ä¸­ä¿æŒä¸å˜ï¼‰ï¼Œå°±ä¼šå°†è¿™äº› op ç§»å‡ºå¾ªç¯ä½“ã€‚è¿™å¯ä»¥å‡å°‘å¾ªç¯ä¸­çš„é‡å¤è®¡ç®—ï¼Œæé«˜æ•ˆç‡ã€‚\nè¦è®©æŸä¸ªè‡ªå®šä¹‰ op å¯ä»¥è¢«è¿™ç§ pass è¯†åˆ«å¹¶ç§»å‡ºå¾ªç¯ä½“ï¼Œéœ€è¦æ·»åŠ ä¸¤ä¸ªå…³é”®çš„ Traits æ¥è¡¨æ˜è¯¥ op åœ¨å¾ªç¯å¤–æ‰§è¡Œæ˜¯å®‰å…¨çš„ï¼š\nNoMemoryEffect: æ˜¯ MemoryEffect çš„ä¸€ä¸ª empty å®ç°ï¼Œè¡¨ç¤ºè¯¥ op ä¸ä¼šäº§ç”Ÿä»»ä½•ä¸å†…å­˜å†™å…¥ç›¸å…³çš„å‰¯ä½œç”¨ã€‚ AlwaysSpeculatable: æ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ª Traits çš„ åˆ—è¡¨ï¼Œå‘Šè¯‰ç¼–è¯‘å™¨è¯¥ op å¯ä»¥åœ¨ä¸å½±å“ç¨‹åºé€»è¾‘çš„å‰æä¸‹ï¼Œå°†å…¶æå‰è®¡ç®—æˆ–ç§»åŠ¨åˆ°å…¶ä»–ä½ç½®ã€‚ åœ¨ MLIR ä¸­ï¼ŒLoop Invariant Code Motion (LICM) ä¼šå°†å…·æœ‰ NoMemoryEffect å’Œ AlwaysSpeculatable è¿™ä¸¤ä¸ª Traits çš„ op ç§»åŠ¨åˆ°å¾ªç¯ä½“å¤–éƒ¨ï¼Œä½†å‰ææ˜¯è¯¥ op çš„ operands åœ¨æ•´ä¸ªå¾ªç¯ä½“ä¸­ä¿æŒä¸å˜ã€‚è¿™æ ·å¯ä»¥é¿å…å¾ªç¯å†…éƒ¨çš„é‡å¤è®¡ç®—ï¼Œä»è€Œä¼˜åŒ–ä»£ç æ‰§è¡Œæ•ˆç‡ã€‚MLIR æä¾›äº†ä¸€ä¸ªæ–¹ä¾¿çš„ç»„åˆ Trait Pureï¼Œå®ƒåŒ…å«äº† NoMemoryEffect å’Œ AlwaysSpeculatable è¿™ä¸¤ä¸ª Traits. å› æ­¤ï¼Œç›´æ¥æ·»åŠ  Pure Trait åˆ° op çš„å®šä¹‰ä¸­å°±èƒ½è®©ç¼–è¯‘å™¨è‡ªåŠ¨è¯†åˆ«å®ƒä¸ºå¯ç§»åŠ¨åˆ°å¾ªç¯å¤–éƒ¨çš„ op ã€‚\nTypeOrContainer æ˜¯ä¸€ä¸ªç”¨äºå¤„ç† op è¾“å…¥å’Œè¾“å‡ºç±»å‹çš„æœºåˆ¶ï¼Œå®ƒå¯ä»¥åŒ¹é…å•ä¸ªç±»å‹ (å¦‚ f32 æˆ– i32) ä»¥åŠå®¹å™¨ç±»å‹(å¦‚ vector\u0026lt;f32\u0026gt; æˆ– tensor\u0026lt;i32\u0026gt;)ï¼Œä½¿å¾—ä¸€ä¸ª op å¯ä»¥è¢«è®¾è®¡ä¸ºåŒæ—¶æ”¯æŒæ ‡é‡ç±»å‹å’Œé›†åˆç±»å‹ã€‚\ninclude \u0026#34;mlir/Interfaces/SideEffectInterfaces.td\u0026#34;\rdef PolyOrContainer: TypeOrContainer\u0026lt;Polynomial, \u0026#34;poly-or-container\u0026#34;\u0026gt;;\rclass Poly_BinOp\u0026lt;string mnemonic\u0026gt;: Op\u0026lt;Poly_Dialect, mnemonic, [Pure]\u0026gt; {\rlet arguments = (ins PolyOrContainer:$lhs, PolyOrContainer:$rhs);\rlet results = (outs PolyOrContainer:$output);\rlet assemblyFormat = \u0026#34;$lhs `,` $rhs attr-dict `:` `(` type($lhs) `,` type($rhs) `)` `-\u0026gt;` type($output)\u0026#34;;\r} åŠ å…¥ Pure trait åç”Ÿæˆçš„ .hpp.inc ä¸­å…³äº op çš„å®šä¹‰ç»§æ‰¿äº†æ–°çš„å†…å®¹\n1 2 3 4 5 6 7 8 9 10 11 class AddOp : public ::mlir::Op\u0026lt; AddOp, ::mlir::OpTrait::ZeroRegions, ::mlir::OpTrait::OneResult, ::mlir::OpTrait::OneTypedResult\u0026lt;::mlir::tutorial::poly::PolynomialType\u0026gt;::Impl, ::mlir::OpTrait::ZeroSuccessors, ::mlir::OpTrait::NOperands\u0026lt;2\u0026gt;::Impl, ::mlir::OpTrait::OpInvariants, ::mlir::ConditionallySpeculatable::Trait, // \u0026lt;-- new ::mlir::OpTrait::AlwaysSpeculatableImplTrait, // \u0026lt;-- new ::mlir::MemoryEffectOpInterface::Trait\u0026gt; // \u0026lt;--- new NoMemoryEffect interface åˆ™åœ¨ç”Ÿæˆçš„ .cpp.inc ä¸­æ·»åŠ äº†ä¸€ä¸ªç®€å•çš„å‡½æ•°\n1 2 3 4 5 void AddOp::getEffects( ::llvm::SmallVectorImpl\u0026lt; ::mlir::SideEffects::EffectInstance\u0026lt;::mlir::MemoryEffects::Effect\u0026gt;\u0026gt;\u0026amp; effects) { } æˆ‘ä»¬å¯ä»¥å†™ä¸€ä¸ª .mlir æ¥æµ‹è¯• %2 çš„è®¡ç®—æ˜¯å¦èƒ½ä¼˜åŒ–åˆ°å¾ªç¯å¤–ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // RUN: build/Ch4-UsingTraits/tools/ch4-tutorial-opt %s --loop-invariant-code-motion \u0026gt; %t // RUN: FileCheck %s \u0026lt; %t module { // CHECK-LABEL: func.func @test_loop_invariant_code_motion func.func @test_loop_invariant_code_motion() -\u0026gt; !poly.poly\u0026lt;10\u0026gt; { %0 = arith.constant dense\u0026lt;[1,2,3]\u0026gt; : tensor\u0026lt;3xi32\u0026gt; %p0 = poly.from_tensor %0 : tensor\u0026lt;3xi32\u0026gt; -\u0026gt; !poly.poly\u0026lt;10\u0026gt; %1 = arith.constant dense\u0026lt;[9,8,16]\u0026gt; : tensor\u0026lt;3xi32\u0026gt; %p1 = poly.from_tensor %0 : tensor\u0026lt;3xi32\u0026gt; -\u0026gt; !poly.poly\u0026lt;10\u0026gt; // CHECK: poly.mul // CHECK: affine.for %ret_val = affine.for %i = 0 to 100 iter_args(%sum_iter = %p0) -\u0026gt; !poly.poly\u0026lt;10\u0026gt; { // The polt.mul should be hoisted out of the loop. // CHECK-NOT: poly.mul %2 = poly.mul %p0, %p1 : (!poly.poly\u0026lt;10\u0026gt;, !poly.poly\u0026lt;10\u0026gt;) -\u0026gt; !poly.poly\u0026lt;10\u0026gt; %sum_next = poly.add %sum_iter, %2 : (!poly.poly\u0026lt;10\u0026gt;, !poly.poly\u0026lt;10\u0026gt;) -\u0026gt; !poly.poly\u0026lt;10\u0026gt; affine.yield %sum_next : !poly.poly\u0026lt;10\u0026gt; } return %ret_val: !poly.poly\u0026lt;10\u0026gt; } } Passes Already Handled by Pure ç»™æŸä¸ª op åŠ ä¸Š Pure Trait åï¼Œä¸‹åˆ— Pass å°±ä¼šè‡ªåŠ¨è¯†åˆ«å¹¶ä¼˜åŒ–è¯¥ op ï¼š\n--control-flow-sink: å°†åªåœ¨æ¡ä»¶è¯­å¥çš„æŸä¸€ä¸ªåˆ†æ”¯ä¸­ä½¿ç”¨çš„ op ç§»åŠ¨åˆ°å¯¹åº”çš„åˆ†æ”¯ä¸­ï¼Œä»¥å‡å°‘æ— æ•ˆä»£ç çš„æ‰§è¡Œã€‚éœ€è¦ op æ— å†…å­˜å‰¯ä½œç”¨ (memory-effect free)ï¼Œé€šå¸¸å¯ä»¥é€šè¿‡ Pure Trait æ¥æ»¡è¶³ã€‚ --cse (Constant Subexpression Elimination): å¸¸é‡å­è¡¨è¾¾å¼æ¶ˆé™¤ã€‚å½“æŸäº›é‡å¤çš„è®¡ç®—ç»“æœå·²ç»å­˜åœ¨æ—¶ï¼Œæ¶ˆé™¤ä¸å¿…è¦çš„é‡å¤è®¡ç®—ï¼Œæé«˜æ•ˆç‡ã€‚éœ€è¦ op æ²¡æœ‰å†…å­˜å‰¯ä½œç”¨ï¼ˆmemory-effect freeï¼‰ï¼Œå› æ­¤ Pure Trait ä¹Ÿå¯ä»¥æ»¡è¶³è¿™ä¸€è¦æ±‚ã€‚ --inline: å°†å‡½æ•°è°ƒç”¨â€œå†…è”â€åˆ°è°ƒç”¨ä½ç½®ï¼Œä»¥å‡å°‘å‡½æ•°è°ƒç”¨çš„å¼€é”€ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿™å¯ä»¥å‡å°‘è°ƒç”¨æ ˆçš„æ·±åº¦æˆ–ä¼˜åŒ–ä»£ç æ‰§è¡Œçš„æ€§èƒ½ã€‚ --mem2reg: å°†å†…å­˜ä¸­çš„å­˜å‚¨/åŠ è½½ op è½¬æ¢ä¸ºå¯¹å®é™…å€¼çš„ç›´æ¥ä½¿ç”¨ï¼Œä»è€Œå‡å°‘å†…å­˜è®¿é—®ï¼Œæé«˜è¿è¡Œæ•ˆç‡ã€‚ --remove-dead-values: ç§»é™¤æœªä½¿ç”¨çš„å‡½æ•°å‚æ•°æˆ–è¿”å›å€¼ï¼Œä»¥å‡å°‘ä¸å¿…è¦çš„æ•°æ®ä¼ é€’æˆ–å†…å­˜å ç”¨ã€‚ --sroa (Scalar Replacement of Aggregates): å°†èšåˆç±»å‹ï¼ˆä¾‹å¦‚æ•°ç»„æˆ–ç»“æ„ä½“ï¼‰æ‹†åˆ†ä¸ºæ ‡é‡å€¼ï¼Œé€šå¸¸ä¼šå¯¹å†…å­˜å¸ƒå±€è¿›è¡Œé‡æ’ï¼Œä»¥ä¾¿æ›´å¥½åœ°åˆ©ç”¨å†…å­˜ã€‚ --symbol-dce (Symbol Dead Code Elimination): æ¶ˆé™¤ä¸å†ä½¿ç”¨çš„ç§æœ‰å‡½æ•° (æ­»ä»£ç )ï¼Œå‡å°‘ä¸å¿…è¦çš„ä»£ç é‡ã€‚ Elementwise Mappings æœ‰å››ç§ traits å¯ä»¥æŠŠæ ‡é‡è¿ç®—æ‰©å±•åˆ°å¼ é‡è¿ç®—æˆ–è€…åè¿‡æ¥\nElemntwise: æ ‡è®°é€å…ƒç´ çš„ op ï¼Œä»…é€‚ç”¨äºå‘é‡æˆ–å¼ é‡ï¼Œä¸å…è®¸å¹¿æ’­ã€‚\nå¦‚æœä»»ä½•ç»“æœæ˜¯å‘é‡æˆ–å¼ é‡ï¼Œè‡³å°‘æœ‰ä¸€ä¸ª operand å¿…é¡»æ˜¯å‘é‡æˆ–å¼ é‡ã€‚ å¦‚æœä»»ä½• operand æ˜¯å‘é‡æˆ–å¼ é‡ï¼Œè‡³å°‘æœ‰ä¸€ä¸ªç»“æœå¹¶ä¸”æ‰€æœ‰ç»“æœå¿…é¡»æ˜¯å‘é‡æˆ–å¼ é‡ã€‚ æ‰€æœ‰ operand å’Œç»“æœçš„å‘é‡æˆ–å¼ é‡ç±»å‹å¿…é¡»å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ã€‚å½¢çŠ¶å¯ä»¥æ˜¯åŠ¨æ€çš„ï¼Œä½†å¯¹äºä¸åŒ¹é…çš„å½¢çŠ¶ï¼Œè¡Œä¸ºæ˜¯æœªå®šä¹‰çš„ã€‚ è¯¥ op å¿…é¡»åœ¨ operand å’Œç»“æœä¸Šé€å…ƒç´ è¿›è¡Œï¼Œå³åœ¨å•å…ƒç´ å‘é‡æˆ–å¼ é‡ä¸Šåº”ç”¨æ—¶ï¼Œæ¯ä¸ªå…ƒç´ çš„ç»“æœåº”ç›¸åŒã€‚ Scalarizable: æ ‡è®°å’ŒéªŒè¯æŸäº›æ“ä½œæ˜¯å¦å¯ä»¥è¢«ç³»ç»Ÿæ€§åœ°æ ‡é‡åŒ–ï¼Œå³å°†å…¶åŸºäºå‘é‡æˆ–å¼ é‡çš„æ“ä½œè½¬åŒ–ä¸ºåŸºäºæ ‡é‡çš„æ“ä½œã€‚åªè¦æ“ä½œæ˜¯ Elementwise çš„ï¼ŒScalarizable å°±å¯ä»¥ä½¿ç”¨ã€‚\n%tensor_select = \u0026#34;arith.select\u0026#34;(%pred_tensor, %true_val, %false_val) : (tensor\u0026lt;?xi1\u0026gt;, tensor\u0026lt;?xf32\u0026gt;, tensor\u0026lt;?xf32\u0026gt;) -\u0026gt; tensor\u0026lt;?xf32\u0026gt; // Can be scalarized to %scalar_select = \u0026#34;arith.select\u0026#34;(%pred, %true_val_scalar, %false_val_scalar) : (i1, f32, f32) -\u0026gt; f32 Vectorizable: æä¾›äº†ä¸ Scalarizable ç›¸åçš„ op ã€‚æ‰€æœ‰çš„æ ‡é‡ operand å’Œç»“æœå°†è¢«æ›¿æ¢ä¸ºç›¸åº”çš„å‘é‡ç±»å‹ã€‚å³ï¼Œè¯¥ op è¡¨ç¤ºåŒæ—¶ä½œç”¨äºå¤šä¸ªå…ƒç´ ã€‚å…è®¸é€šè¿‡å¹¿æ’­å°†æ ‡é‡æå‡ä¸ºå‘é‡ï¼Œå†è¿›è¡Œå‘é‡åŒ–æ“ä½œã€‚\nTensorizable: æä¾›äº†ä¸ Scalarizable ç›¸åçš„ op ï¼Œå…è®¸åœ¨å¼ é‡å’Œæ ‡é‡ä¹‹é—´è¿›è¡Œæ¨ç†ã€‚å…è®¸é€šè¿‡å¹¿æ’­å°†æ ‡é‡æå‡ä¸ºå¼ é‡ï¼Œä»¥ä¾¿åœ¨å¼ é‡ op ä¸­ä¿æŒä¸€è‡´çš„ op ç»“æ„ã€‚\n%scalar = \u0026#34;arith.addf\u0026#34;(%a, %b) : (f32, f32) -\u0026gt; f32 // Can be tensorized to %tensor = \u0026#34;arith.addf\u0026#34;(%a, %b) : (tensor\u0026lt;?xf32\u0026gt;, tensor\u0026lt;?xf32\u0026gt;) -\u0026gt; tensor\u0026lt;?xf32\u0026gt; // Also supports broadcasting %scalar_pred = \u0026#34;arith.select\u0026#34;(%pred, %true_val, %false_val) : (i1, tensor\u0026lt;?xf32\u0026gt;, tensor\u0026lt;?xf32\u0026gt;) -\u0026gt; tensor\u0026lt;?xf32\u0026gt; // Can be tensorized to %tensor_pred = \u0026#34;arith.select\u0026#34;(%pred, %true_val, %false_val) : (tensor\u0026lt;?xi1\u0026gt;, tensor\u0026lt;?xf32\u0026gt;, tensor\u0026lt;?xf32\u0026gt;) -\u0026gt; tensor\u0026lt;?xf32\u0026gt; ElementwiseMappable Trait åŒ…å«äº†ä»¥ä¸Šæ‰€æœ‰çš„ Traits. æˆ‘ä»¬å¯ä»¥ä¿®æ”¹ Poly_BinOp å®šä¹‰å¦‚ä¸‹ï¼š\n// PolyOps.td\rdef PolyOrContainer : TypeOrContainer\u0026lt;Polynomial, \u0026#34;poly-or-container\u0026#34;\u0026gt;;\rclass Poly_BinOp\u0026lt;string mnemonic\u0026gt; : Op\u0026lt;Poly_Dialect, mnemonic, [Pure, ElementwiseMappable]\u0026gt; {\rlet arguments = (ins PolyOrContainer:$lhs, PolyOrContainer:$rhs);\rlet results = (outs PolyOrContainer:$output);\r...\r} æ·»åŠ è¿™ä¸ª Trait åï¼Œç”Ÿæˆçš„ .cpp.inc æ–‡ä»¶å®šä¹‰äº†è®¸å¤šæ£€æŸ¥ op æ•°ç±»å‹çš„å‡½æ•°ï¼Œä¸‹é¢æ˜¯å…¶ä¸­ä¸€ä¸ªï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 static ::llvm::LogicalResult __mlir_ods_local_type_constraint_PolyOps1( ::mlir::Operation* op, ::mlir::Type type, ::llvm::StringRef valueKind, unsigned valueIndex) { if (!(((::llvm::isa\u0026lt;::mlir::tutorial::poly::PolynomialType\u0026gt;(type))) || (((type.hasTrait\u0026lt;::mlir::ValueSemantics\u0026gt;())) \u0026amp;\u0026amp; ([](::mlir::Type elementType) { return (::llvm::isa\u0026lt;::mlir::tutorial::poly::PolynomialType\u0026gt;( elementType)); }(::llvm::cast\u0026lt;::mlir::ShapedType\u0026gt;(type).getElementType()))))) { return op-\u0026gt;emitOpError(valueKind) \u0026lt;\u0026lt; \u0026#34; #\u0026#34; \u0026lt;\u0026lt; valueIndex \u0026lt;\u0026lt; \u0026#34; must be poly-or-container, but got \u0026#34; \u0026lt;\u0026lt; type; } return ::mlir::success(); } è¯¥å‡½æ•°é¦–å…ˆæ£€æŸ¥ type æ˜¯å¦ä¸º PolynomialTypeï¼›å¦‚æœä¸æ˜¯ï¼Œåˆ™è¿›ä¸€æ­¥æ£€æŸ¥å®ƒæ˜¯å¦å…·æœ‰ ValueSemantics Traitï¼Œå¹¶ä¸”æ˜¯ä¸€ä¸ª ShapedTypeï¼ˆå³å®¹å™¨ç±»å‹ï¼Œå¦‚ vector æˆ– tensorï¼‰ï¼Œå…¶ä¸­åŒ…å«çš„å…ƒç´ ç±»å‹æ˜¯ PolynomialType.\n","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch5-using-traits/","summary":"Personal MLIR learning notes 5.","title":"MLIR-Ch5 Using Traits"},{"content":"Sketching Out a Dseign TableGen ä¹Ÿå¯ä»¥ç”¨æ¥å®šä¹‰ dialect. æœ¬æ–‡å°†å®šä¹‰ä¸€ä¸ªå•æœªçŸ¥æ•°å¤šé¡¹å¼è¿ç®—çš„ dialectï¼Œç³»æ•°ç”¨ uint32_t ç±»å‹è¡¨ç¤ºã€‚ï¼Œå¹¶æä¾›é€šè¿‡ä»æ ‡å‡† MLIR ç±»å‹æŒ‡å®šå¤šé¡¹å¼ç³»æ•°æ¥å®šä¹‰å¤šé¡¹å¼çš„æ“ä½œï¼Œæå–å…³äºå¤šé¡¹å¼çš„æ•°æ®ä»¥å°†ç»“æœå­˜å‚¨åœ¨æ ‡å‡†MLIRç±»å‹ä¸­ï¼Œä»¥åŠå¯¹å¤šé¡¹å¼è¿›è¡Œç®—æœ¯è¿ç®—ã€‚\nAn Empty Dialect æˆ‘ä»¬é¦–å…ˆç”¨ TableGen å®šä¹‰ä¸€ä¸ªç©ºçš„ dialect. å®ƒå’Œä¸Šä¸€ç« å®šä¹‰ Pass æ²¡ä»€ä¹ˆä¸åŒï¼Œåªä¸è¿‡ include çš„æ˜¯ DialectBase.td æ–‡ä»¶ã€‚åŒæ—¶ä¹Ÿå®šä¹‰äº†å‘½åç©ºé—´ä¸º ::mlir::tutorial::poly.\n1 2 3 4 5 6 7 8 9 10 11 12 include \u0026#34;mlir/IR/DialectBase.td\u0026#34; def Poly_Dialect : Dialect { let name = \u0026#34;poly\u0026#34;; let summary = \u0026#34;A dialect for polynomial math\u0026#34;; let description = [{ The poly dialect defines types and operations for single-variable polynomials over integers. }]; let cppNamespace = \u0026#34;::mlir::tutorial::poly\u0026#34;; } æˆ‘ä»¬éœ€è¦åœ¨ include ç›®å½•ä¸‹çš„ CMakeLists.txt æ–‡ä»¶ä¸­æ·»åŠ \n1 2 3 4 5 set(TARGET_NAME \u0026#34;${PROJECT_TARGET_PREFIX}-Dialect-PolyDialect-IncGen\u0026#34;) set(LLVM_TARGET_DEFINITIONS mlir-learning/Dialect/Poly/PolyDialect.td) mlir_tablegen(mlir-learning/Dialect/Poly/PolyDialect.hpp.inc --gen-dialect-decls) mlir_tablegen(mlir-learning/Dialect/Poly/PolyDialect.cpp.inc --gen-dialect-defs) add_public_tablegen_target(${TARGET_NAME}) ç„¶ååœ¨ tutorial-opt.cpp ä¸­æ³¨å†Œæ‰€æœ‰ mlir è‡ªå¸¦çš„æ‰€æœ‰ dialect åè¿›è¡Œæ„å»ºï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ç”Ÿæˆçš„ .hpp.inc å’Œ.cpp.inc æ–‡ä»¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 namespace mlir { namespace tutorial { class PolyDialect : public ::mlir::Dialect { explicit PolyDialect(::mlir::MLIRContext *context); void initialize(); friend class ::mlir::MLIRContext; public: ~PolyDialect() override; static constexpr ::llvm::StringLiteral getDialectNamespace() { return ::llvm::StringLiteral(\u0026#34;poly\u0026#34;); } }; } // namespace tutorial } // namespace mlir MLIR_DECLARE_EXPLICIT_TYPE_ID(::mlir::tutorial::PolyDialect) ç¼–è¯‘å™¨ä¼šæŠ¥é”™ï¼Œå› ä¸º inc ä¸ä¼šåŒ…å« Dialect ç­‰ç±»æ‰€åœ¨çš„å¤´æ–‡ä»¶ã€‚è¿™éœ€è¦æˆ‘ä»¬è‡ªå·±åœ¨ PolyDialect.h æ–‡ä»¶ä¸­è¿›è¡Œ includeï¼Œè¿™æ · å½“é‡æ–°æ„å»ºçš„æ—¶å€™è¯¥æ–‡ä»¶æ³¨å…¥å˜ä¸ä¼šæŠ¥é”™\n1 2 3 4 5 6 7 8 9 // include/mlir-learning/Dialect/Poly/PolyDialect.h #ifndef LIB_DIALECT_POLY_POLYDIALECT_H #define LIB_DIALECT_POLY_POLYDIALECT_H #include \u0026#34;mlir/IR/DialectImplementation.h\u0026#34; // include mannually #include \u0026#34;mlir-learning/Dialect/Poly/PolyDialect.hpp.inc\u0026#34; #endif ç”Ÿæˆçš„ .cpp.inc å¦‚ä¸‹ï¼Œä»–åªåŒ…å«äº†è¯¥ç±»åŸºæœ¬çš„æ„é€ å‡½æ•°å’Œææ„å‡½æ•°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 MLIR_DEFINE_EXPLICIT_TYPE_ID(::mlir::tutorial::poly::PolyDialect) namespace mlir { namespace tutorial { namespace poly { PolyDialect::PolyDialect(::mlir::MLIRContext *context) : ::mlir::Dialect(getDialectNamespace(), context, ::mlir::TypeID::get\u0026lt;PolyDialect\u0026gt;()) { initialize(); } PolyDialect::~PolyDialect() = default; } // namespace poly } // namespace tutorial } // namespace mlir ç„¶åæˆ‘ä»¬å¯ä»¥åœ¨ tutorial-opt.cpp ä¸­æ³¨å†Œè¯¥ dialect.\n1 2 3 4 5 6 7 8 9 10 11 12 /* other includes */ #include \u0026#34;mlir-learning/Dialect/Poly/PolyDialect.h\u0026#34; int main(int argc, char** argv) { // Register all built-in MLIR dialects mlir::DialectRegistry registry; // Register our Dialect registry.insert\u0026lt;mlir::tutorial::poly::PolyDialect\u0026gt;(); mlir::registerAllDialects(registry); return mlir::asMainReturnCode( mlir::MlirOptMain(argc, argv, \u0026#34;Tutorial Pass Driver\u0026#34;, registry)); } Adding a Trival Type ä¸‹é¢æˆ‘ä»¬éœ€è¦å®šä¹‰è‡ªå·±çš„ poly.poly ç±»å‹.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // poly_types.td #ifndef LIB_DIALECT_POLY_POLYTYPES_TD_ #define LIB_DIALECT_POLY_POLYTYPES_TD_ include \u0026#34;mlir-learning/Dialect/Poly/PolyDialect.td\u0026#34; include \u0026#34;mlir/IR/AttrTypeBase.td\u0026#34; // a base class for all types in the dialect class Poly_Type\u0026lt;string name, string typeMnemonic\u0026gt; : TypeDef\u0026lt;Poly_Dialect, name\u0026gt; { let mnemonic = typeMnemonic; } def Polynomial: Poly_Type\u0026lt;\u0026#34;Polynomial\u0026#34;, \u0026#34;poly\u0026#34;\u0026gt; { let summary = \u0026#34;A polynomial with u32 coefficients\u0026#34;; let description = [{ A type for polynomials with integer coefficients in a single-variable polynomial ring. }]; } #endif åœ¨ MLIR çš„ TableGen æ–‡ä»¶ä¸­ï¼Œclass å’Œ def çš„ç”¨æ³•å’Œå«ä¹‰æœ‰æ‰€ä¸åŒ\nclass ç”¨äºå®šä¹‰ä¸€ä¸ªæ¨¡æ¿æˆ–åŸºç±»ï¼Œå¯ä»¥è¢«å…¶ä»–ç±»å‹æˆ–å®šä¹‰ç»§æ‰¿å’Œé‡ç”¨ã€‚å®ƒæœ¬èº«ä¸ä¼šåˆ›å»ºå®é™…çš„å¯¹è±¡æˆ–å…·ä½“ç±»å‹ï¼Œå®ƒåªæ˜¯ä¸€ç§ç»“æ„ï¼Œå¯ä»¥åŒ…å«å‚æ•°å’Œé»˜è®¤å±æ€§ã€‚å…¶ä»–å®šä¹‰å¯ä»¥é€šè¿‡ç»§æ‰¿è¯¥ç±»æ¥è·å¾—å…¶åŠŸèƒ½ã€‚ def ç”¨äºåˆ›å»ºä¸€ä¸ªå…·ä½“çš„å®ä¾‹ï¼Œæ¯”å¦‚ä¸€ä¸ªç±»å‹ã€æ“ä½œæˆ–å±æ€§ã€‚å®ƒä¼šå°†æ‰€å®šä¹‰çš„å†…å®¹åº”ç”¨åˆ° TableGen ä¸­ï¼Œä½¿å…¶æˆä¸ºå¯ç”¨çš„å…·ä½“ç±»å‹æˆ–åŠŸèƒ½ã€‚ è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªåä¸º Poly_Type çš„ç±»ï¼Œå‚æ•°ä¸º nameï¼ˆç±»å‹çš„åç§°ï¼‰å’Œ typeMnemonicï¼ˆç±»å‹çš„ç®€å†™æˆ–åŠ©è®°ç¬¦ï¼‰ã€‚è¿™ä¸ªç±»ç»§æ‰¿è‡ª TypeDef\u0026lt;Poly_Dialect, name\u0026gt;. ç„¶å def ç‰¹å®šçš„å¤šé¡¹å¼ç±»å‹ Polynomialï¼Œç»§æ‰¿è‡ª Poly_Type.\nåœ¨ MLIR çš„ TableGen ä¸­ï¼ŒTypeDef æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ªç±»ï¼Œå®ƒæ¥å—æ¨¡æ¿å‚æ•°ï¼Œç”¨äºæŒ‡å®šè¯¥ç±»å‹æ‰€å±çš„ dialect å’Œåç§°å­—æ®µã€‚å…¶ä½œç”¨åŒ…æ‹¬å°†ç”Ÿæˆçš„C++ç±»ä¸è¯¥ dialect çš„å‘½åç©ºé—´ç›¸å…³è”ã€‚\nç”Ÿæˆçš„ .hpp.inc æ–‡ä»¶å¦‚ä¸‹ã€‚ç”Ÿæˆçš„ç±» PolynomialType å°±æ˜¯åœ¨æˆ‘ä»¬çš„ TableGen æ–‡ä»¶ä¸­å®šä¹‰çš„ Polynomial ç±»å‹åé¢åŠ ä¸Šäº† Type.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #ifdef GET_TYPEDEF_CLASSES #undef GET_TYPEDEF_CLASSES namespace mlir { class AsmParser; class AsmPrinter; } // namespace mlir namespace mlir { namespace tutorial { namespace poly { class PolynomialType; class PolynomialType : public ::mlir::Type::TypeBase\u0026lt;PolynomialType, ::mlir::Type, ::mlir::TypeStorage\u0026gt; { public: using Base::Base; static constexpr ::llvm::StringLiteral name = \u0026#34;poly.poly\u0026#34;; static constexpr ::llvm::StringLiteral dialectName = \u0026#34;poly\u0026#34;; static constexpr ::llvm::StringLiteral getMnemonic() { return {\u0026#34;poly\u0026#34;}; } }; } // namespace poly } // namespace tutorial } // namespace mlir MLIR_DECLARE_EXPLICIT_TYPE_ID(::mlir::tutorial::poly::PolynomialType) #endif // GET_TYPEDEF_CLASSES ç”Ÿæˆçš„ .cpp.inc æ–‡ä»¶å¦‚ä¸‹ã€‚TableGen è¯•å›¾ä¸º dialect ä¸­çš„ PolynomialType è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª ç±»å‹è§£æå™¨ (type parser) å’Œç±»å‹æ‰“å°å™¨ (type printer). ä¸è¿‡æ­¤æ—¶è¿™äº›åŠŸèƒ½è¿˜ä¸å¯ç”¨ï¼Œæ„å»ºé¡¹ç›®æ—¶ä¼šçœ‹åˆ°ä¸€äº›ç¼–è¯‘è­¦å‘Šã€‚\nä»£ç ä¸­ä½¿ç”¨äº† å¤´æ–‡ä»¶ä¿æŠ¤ (header guards) æ¥å°† cpp æ–‡ä»¶åˆ†éš”ä¸ºä¸¤ä¸ªå—ä¿æŠ¤çš„éƒ¨åˆ†ã€‚è¿™æ ·å¯ä»¥åˆ†åˆ«ç®¡ç†ç±»å‹å£°æ˜å’Œå‡½æ•°å®ç°ã€‚\nGET_TYPEDEF_LIST åªåŒ…å«ç±»åçš„é€—å·åˆ†éš”åˆ—è¡¨ã€‚åŸå› åœ¨äº PolyDialect.cpp æ–‡ä»¶éœ€è¦è´Ÿè´£å°†ç±»å‹æ³¨å†Œåˆ° dialect ä¸­ï¼Œè€Œè¯¥æ³¨å†Œè¿‡ç¨‹é€šè¿‡åœ¨æ–¹è¨€åˆå§‹åŒ–å‡½æ•°ä¸­å°†è¿™äº› C++ ç±»åä½œä¸ºæ¨¡æ¿å‚æ•°æ¥å®ç°ã€‚æ¢å¥è¯è¯´ï¼ŒGET_TYPEDEF_LIST æä¾›äº†ä¸€ç§ç®€åŒ–æœºåˆ¶ï¼Œä½¿å¾— PolyDialect.cpp å¯ä»¥è‡ªåŠ¨è·å–æ‰€æœ‰ç±»åç§°åˆ—è¡¨ï¼Œä¾¿äºç»Ÿä¸€æ³¨å†Œï¼Œè€Œä¸éœ€è¦æ‰‹åŠ¨æ·»åŠ æ¯ä¸€ä¸ªç±»å‹ã€‚\ngeneratedTypeParser å‡½æ•°æ˜¯ä¸º PolynomialType å®šä¹‰çš„è§£æå™¨ã€‚å½“è§£æå™¨é‡åˆ° PolynomialType çš„åŠ©è®°ç¬¦ï¼ˆpolyï¼‰æ—¶ï¼Œä¼šå°† PolynomialType ç±»å‹å®ä¾‹åŒ–ã€‚KeywordSwitch ä½¿ç”¨ getMnemonic() æ¥åŒ¹é… PolynomialType çš„åŠ©è®°ç¬¦ï¼ˆpolyï¼‰ã€‚å¦‚æœåŒ¹é…æˆåŠŸï¼Œåˆ™è°ƒç”¨ PolynomialType::get() æ¥è·å–ç±»å‹å®ä¾‹ã€‚Default å­å¥åœ¨åŠ©è®°ç¬¦ä¸åŒ¹é…æ—¶æ‰§è¡Œï¼Œè®°å½•æœªçŸ¥çš„åŠ©è®°ç¬¦ï¼Œå¹¶è¿”å› std::nullopt è¡¨ç¤ºè§£æå¤±è´¥ã€‚ generatedTypePrinter å‡½æ•°ä¸º PolynomialType æä¾›äº†æ‰“å°åŠŸèƒ½ã€‚å½“ç±»å‹ä¸º PolynomialType æ—¶ï¼Œæ‰“å°å…¶åŠ©è®°ç¬¦ï¼ˆpolyï¼‰ï¼Œå¦åˆ™è¿”å›å¤±è´¥ã€‚TypeSwitch ç”¨äºæ£€æŸ¥ def ç±»å‹æ˜¯å¦æ˜¯ PolynomialTypeã€‚å¦‚æœæ˜¯ï¼Œæ‰“å°åŠ©è®°ç¬¦ï¼›å¦åˆ™è¿”å›å¤±è´¥ï¼Œè¡¨ç¤ºè¯¥ç±»å‹ä¸å±äºæ­¤æ–¹è¨€ã€‚ PolyDialect::parseType å’Œ PolyDialect::printType ä½œä¸ºæ–¹è¨€æ¥å£è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°ï¼Œä»è€Œå®ç°ç±»å‹çš„è§£æå’Œæ‰“å°åŠŸèƒ½ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 #ifdef GET_TYPEDEF_LIST #undef GET_TYPEDEF_LIST ::mlir::tutorial::poly::PolynomialType #endif // GET_TYPEDEF_LIST #ifdef GET_TYPEDEF_CLASSES #undef GET_TYPEDEF_CLASSES static ::mlir::OptionalParseResult generatedTypeParser(::mlir::AsmParser \u0026amp;parser, ::llvm::StringRef *mnemonic, ::mlir::Type \u0026amp;value) { return ::mlir::AsmParser::KeywordSwitch\u0026lt;::mlir::OptionalParseResult\u0026gt;(parser) .Case(::mlir::tutorial::poly::PolynomialType::getMnemonic(), [\u0026amp;](llvm::StringRef, llvm::SMLoc) { value = ::mlir::tutorial::poly::PolynomialType::get(parser.getContext()); return ::mlir::success(!!value); }) .Default([\u0026amp;](llvm::StringRef keyword, llvm::SMLoc) { *mnemonic = keyword; return std::nullopt; }); } static ::llvm::LogicalResult generatedTypePrinter(::mlir::Type def, ::mlir::AsmPrinter \u0026amp;printer) { return ::llvm::TypeSwitch\u0026lt;::mlir::Type, ::llvm::LogicalResult\u0026gt;(def) .Case\u0026lt;::mlir::tutorial::poly::PolynomialType\u0026gt;([\u0026amp;](auto t) { printer \u0026lt;\u0026lt; ::mlir::tutorial::poly::PolynomialType::getMnemonic(); return ::mlir::success(); }) .Default([](auto) { return ::mlir::failure(); }); } namespace mlir { namespace tutorial { namespace poly { } // namespace poly } // namespace tutorial } // namespace mlir MLIR_DEFINE_EXPLICIT_TYPE_ID(::mlir::tutorial::poly::PolynomialType) namespace mlir { namespace tutorial { namespace poly { /// Parse a type registered to this dialect. ::mlir::Type PolyDialect::parseType(::mlir::DialectAsmParser \u0026amp;parser) const { ::llvm::SMLoc typeLoc = parser.getCurrentLocation(); ::llvm::StringRef mnemonic; ::mlir::Type genType; auto parseResult = generatedTypeParser(parser, \u0026amp;mnemonic, genType); if (parseResult.has_value()) return genType; parser.emitError(typeLoc) \u0026lt;\u0026lt; \u0026#34;unknown type `\u0026#34; \u0026lt;\u0026lt; mnemonic \u0026lt;\u0026lt; \u0026#34;` in dialect `\u0026#34; \u0026lt;\u0026lt; getNamespace() \u0026lt;\u0026lt; \u0026#34;`\u0026#34;; return {}; } /// Print a type registered to this dialect. void PolyDialect::printType(::mlir::Type type, ::mlir::DialectAsmPrinter \u0026amp;printer) const { if (::mlir::succeeded(generatedTypePrinter(type, printer))) return; } } // namespace poly } // namespace tutorial } // namespace mlir #endif // GET_TYPEDEF_CLASSES åœ¨è®¾ç½® C++ æ¥å£ä»¥ä½¿ç”¨ TableGen æ–‡ä»¶æ—¶ï¼Œé€šå¸¸ä¼šæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ¥ç»„ç»‡ä»£ç æ–‡ä»¶å’ŒåŒ…å«å…³ç³»ã€‚\nPolyTypes.h æ˜¯å”¯ä¸€è¢«å…è®¸åŒ…å« PolyTypes.h.inc çš„æ–‡ä»¶ã€‚ PolyTypes.cpp.inc æ–‡ä»¶åŒ…å«äº† TableGen ä¸º PolyDialect ä¸­çš„ç±»å‹ç”Ÿæˆçš„å®ç°ã€‚æˆ‘ä»¬éœ€è¦åœ¨ PolyDialect.cpp ä¸­å°†å…¶åŒ…å«è¿›å»ï¼Œä»¥ç¡®ä¿æ‰€æœ‰å®ç°éƒ½èƒ½åœ¨è¯¥æ–¹è¨€çš„ä¸»æ–‡ä»¶ä¸­ä½¿ç”¨ã€‚ PolyTypes.cpp æ–‡ä»¶åº”è¯¥åŒ…å« PolyTypes.hï¼Œä»¥ä¾¿è®¿é—®ç±»å‹å£°æ˜ï¼Œå¹¶åœ¨è¯¥æ–‡ä»¶ä¸­å®ç°æ‰€æœ‰éœ€è¦çš„é¢å¤–åŠŸèƒ½ã€‚ ./Ch3-DefiningANewDialect/\râ”œâ”€â”€ CMakeLists.txt\râ”œâ”€â”€ include\râ”‚ â”œâ”€â”€ CMakeLists.txt\râ”‚ â””â”€â”€ mlir-tutorial\râ”‚ â””â”€â”€ Dialect\râ”‚ â””â”€â”€ Poly\râ”‚ â”œâ”€â”€ PolyDialect.hpp\râ”‚ â”œâ”€â”€ PolyDialect.td\râ”‚ â”œâ”€â”€ PolyOps.hpp\râ”‚ â”œâ”€â”€ PolyOps.td\râ”‚ â”œâ”€â”€ PolyTypes.hpp\râ”‚ â””â”€â”€ PolyTypes.td\râ”œâ”€â”€ lib\râ”‚ â”œâ”€â”€ CMakeLists.txt\râ”‚ â””â”€â”€ Dialect\râ”‚ â””â”€â”€ Poly\râ”‚ â””â”€â”€ PolyDialect.cpp ä¸ºäº†è®©ç±»å‹è§£æå™¨å’Œæ‰“å°å™¨èƒ½å¤Ÿæ­£ç¡®ç¼–è¯‘å’Œè¿è¡Œï¼Œéœ€è¦æœ€ååœ¨æ–¹è¨€çš„ TableGen æ–‡ä»¶ä¸­æ·»åŠ  let useDefaultTypePrinterParser = 1;ï¼Œè¿™ä¸ªæŒ‡ä»¤å‘Šè¯‰ TableGen ä½¿ç”¨é»˜è®¤çš„ç±»å‹è§£æå’Œæ‰“å°å™¨ã€‚å½“è¿™ä¸ªé€‰é¡¹å¯ç”¨åï¼ŒTableGen ä¼šç”Ÿæˆç›¸åº”çš„è§£æå’Œæ‰“å°ä»£ç ï¼Œå¹¶å°†è¿™äº›å®ç°ä½œä¸º PolyDialect ç±»çš„æˆå‘˜å‡½æ•°ã€‚\n1 2 3 4 5 6 /// Parse a type registered to this dialect. ::mlir::Type parseType(::mlir::DialectAsmParser \u0026amp;parser) const override; /// Print a type registered to this dialect. void printType(::mlir::Type type, ::mlir::DialectAsmPrinter \u0026amp;os) const override; æˆ‘ä»¬å¯ä»¥å†™ä¸€ä¸ª .mlir æ¥æµ‹è¯•å±æ€§æ˜¯æ˜¯å¦è·å–æ­£ç¡®ã€‚åœ¨ MLIR ä¸­è‡ªå®šä¹‰çš„ dialect å‰éƒ½éœ€è¦åŠ ä¸Š !.\n1 2 3 4 5 // CHECK-LABEL: test_type_syntax func.func @test_type_syntax(%arg0: !poly.poly\u0026lt;10\u0026gt;) -\u0026gt; !poly.poly\u0026lt;10\u0026gt; { // CHECK: poly.poly return %arg0: !poly.poly\u0026lt;10\u0026gt; } Add a Poly Type Parameter æˆ‘ä»¬éœ€è¦ä¸ºå¤šé¡¹å¼ç±»å‹æ·»åŠ ä¸€ä¸ªå±æ€§ï¼Œè¡¨ç¤ºå®ƒçš„æ¬¡æ•°ä¸Šé™ã€‚\n// include/mlir-tutorial/Dialect/Poly/PolyTypes.td\rlet parameters = (ins \u0026#34;int\u0026#34;:$degreeBound);\rlet assemblyFormat = \u0026#34;`\u0026lt;` $degreeBound `\u0026gt;`\u0026#34;; ç¬¬ä¸€è¡Œå®šä¹‰äº†ç±»å‹çš„ä¸€ä¸ªå‚æ•° degreeBoundï¼Œç±»å‹ä¸º int. è¡¨ç¤ºåœ¨å®ä¾‹åŒ–è¯¥ç±»å‹æ—¶ï¼Œç”¨æˆ·å¯ä»¥æŒ‡å®šä¸€ä¸ªæ•´æ•°å€¼ä½œä¸ºç±»å‹çš„å‚æ•°ã€‚parameters ä¸­çš„ (ins \u0026quot;int\u0026quot;:$degreeBound) æŒ‡å®šäº†è¾“å…¥å‚æ•°çš„ç±»å‹å’Œåç§°ï¼Œå…¶ä¸­ int æ˜¯æ•°æ®ç±»å‹ï¼Œ$degreeBound æ˜¯å‚æ•°çš„å ä½ç¬¦ã€‚assemblyFormat ç”¨äºå®šä¹‰è¯¥ç±»å‹åœ¨ MLIR æ–‡æœ¬æ ¼å¼ä¸­çš„æ‰“å°å’Œè§£ææ ¼å¼ã€‚\u0026quot;\u0026lt;\u0026quot; $degreeBound \u0026quot;\u0026gt;\u0026quot; è¡¨ç¤ºè¯¥ç±»å‹çš„å‚æ•°ä¼šç”¨å°–æ‹¬å·åŒ…è£¹ã€‚ç¬¬äºŒè¡Œæ˜¯å¿…éœ€çš„ï¼Œå› ä¸ºç°åœ¨ä¸€ä¸ª Poly ç±»å‹æœ‰äº†è¿™ä¸ªå…³è”çš„æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦èƒ½å¤Ÿå°†å®ƒæ‰“å°å‡ºæ¥å¹¶ä»æ–‡æœ¬ IR è¡¨ç¤ºä¸­è§£æå®ƒã€‚\nåŠ ä¸Šè¿™ä¸¤è¡Œä»£ç åè¿›è¡Œ build ä¼šå‘ç°å¤šäº†ä¸€äº›æ–°çš„å†…å®¹ã€‚\nPolynomialType æœ‰ä¸€ä¸ªæ–°çš„ int getDegreeBound() æ–¹æ³•ï¼Œä»¥åŠä¸€ä¸ªé™æ€ get å·¥å‚æ–¹æ³•ã€‚ parse å’Œ print å‡çº§ä¸ºæ–°æ ¼å¼ã€‚ æœ‰ä¸€ä¸ªåä¸º typestorage çš„æ–°ç±»ï¼Œå®ƒåŒ…å« int å½¢å‚ï¼Œå¹¶éšè—åœ¨å†…éƒ¨ç»†èŠ‚åç§°ç©ºé—´ä¸­ã€‚ MLIRä¼šè‡ªåŠ¨ç”Ÿæˆç®€å•ç±»å‹çš„ storage ç±»ï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦å¤æ‚çš„å†…å­˜ç®¡ç†ã€‚å¦‚æœå‚æ•°æ›´å¤æ‚ï¼Œå°±éœ€è¦å¼€å‘è€…æ‰‹åŠ¨ç¼–å†™ storage ç±»æ¥å®šä¹‰æ„é€ ã€ææ„å’Œå…¶ä»–è¯­ä¹‰ã€‚å¤æ‚çš„ storage ç±»éœ€è¦å®ç°æ›´å¤šç»†èŠ‚ï¼Œä»¥ç¡®ä¿ç±»å‹èƒ½å¤Ÿåœ¨ MLIR çš„ dialect ç³»ç»Ÿä¸­é¡ºåˆ©è¿è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // include/mlir-learning/Dialect/Poly/PolyTypes.hpp.inc static ::mlir::Type parse(::mlir::AsmParser \u0026amp;odsParser); void print(::mlir::AsmPrinter \u0026amp;odsPrinter) const; int getDegreeBound() const; // include/mlir-learning/Dialect/Poly/PolyTypes.cpp.inc struct PolynomialTypeStorage : public ::mlir::TypeStorage { /* lots of code */ }; PolynomialType PolynomialType::get(::mlir::MLIRContext *context, int degreeBound) { return Base::get(context, std::move(degreeBound)); } ::mlir::Type PolynomialType::parse(::mlir::AsmParser \u0026amp;odsParser) { /* code to parse the type */ } void PolynomialType::print(::mlir::AsmPrinter \u0026amp;odsPrinter) const { ::mlir::Builder odsBuilder(getContext()); odsPrinter \u0026lt;\u0026lt; \u0026#34;\u0026lt;\u0026#34;; odsPrinter.printStrippedAttrOrType(getDegreeBound()); odsPrinter \u0026lt;\u0026lt; \u0026#34;\u0026gt;\u0026#34;; } int PolynomialType::getDegreeBound() const { return getImpl()-\u0026gt;degreeBound; } Adding Some Simple Operations ä¸‹é¢æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç®€å•çš„å¤šé¡¹å¼åŠ æ³•æ“ä½œ\n// include/mlir-tutorial/Dialect/Poly/PolyOps.td\rinclude \u0026#34;PolyDialect.td\u0026#34;\rinclude \u0026#34;PolyTypes.td\u0026#34;\rdef Poly_AddOp : Op\u0026lt;Poly_Dialect, \u0026#34;add\u0026#34;\u0026gt; {\rlet summary = \u0026#34;Addition operation between polynomials.\u0026#34;;\rlet arguments = (ins Polynomial:$lhs, Polynomial:$rhs);\rlet results = (outs Polynomial:$output);\rlet assemblyFormat = \u0026#34;$lhs `,` $rhs attr-dict `:` `(` type($lhs) `,` type($rhs) `)` `-\u0026gt;` type($output)\u0026#34;;\r} å’Œåˆšæ‰å®šä¹‰ types éå¸¸ç›¸è¿‘ï¼Œä½†åŸºç±»æ˜¯ Opï¼Œarguments å¯¹åº”äºæ“ä½œçš„è¾“å…¥ï¼ŒassemblyFormat æ›´å¤æ‚ã€‚ç”Ÿæˆçš„ .hpp.inc å’Œ .cpp.inc éå¸¸å¤æ‚ã€‚æˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸€ä¸ª .mlir æ¥æµ‹è¯•ã€‚\n1 2 3 4 5 6 // CHECK-LABEL: test_add_syntax func.func @test_add_syntax(%arg0: !poly.poly\u0026lt;10\u0026gt;, %arg1: !poly.poly\u0026lt;10\u0026gt;) -\u0026gt; !poly.poly\u0026lt;10\u0026gt; { // CHECK: poly.add %0 = poly.add %arg0, %arg1 : (!poly.poly\u0026lt;10\u0026gt;, !poly.poly\u0026lt;10\u0026gt;) -\u0026gt; !poly.poly\u0026lt;10\u0026gt; return %0 : !poly.poly\u0026lt;10\u0026gt; } ç”Ÿæˆçš„ä»£ç å®šä¹‰äº†ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\nAdaptor Classes:\nAddOpGenericAdaptorBase å’Œ AddOpAdaptor: æä¾›äº†ä¾¿æ·çš„æ–¹å¼æ¥è®¿é—®æ“ä½œçš„æ“ä½œæ•° (operands) å’Œå±æ€§ (attributes)ã€‚å®ƒä»¬åœ¨ç¼–å†™è½¬æ¢å’Œé‡å†™æ¨¡å¼æ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚ Properties Handling:\nè¯¸å¦‚ setPropertiesFromAttr , getPropertiesAsAttr , computePropertiesHash ç­‰å‡½æ•°æ˜¯ MLIR æ“ä½œå±æ€§ç³»ç»Ÿçš„æ¥å£ã€‚è™½ç„¶åœ¨è¿™ä¸ªç‰¹å®šçš„ AddOp å®ç°ä¸­ï¼Œæœ‰äº›å‡½æ•°å¯èƒ½æ˜¯ç©ºå®ç°æˆ–è¿”å›é»˜è®¤å€¼ï¼Œä½†å®ƒä»¬æ˜¯æ“ä½œå®šä¹‰ç»“æ„çš„ä¸€éƒ¨åˆ†ã€‚ Builder Methods:\nå¤šä¸ªé‡è½½çš„ AddOp::build é™æ€æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•ç”¨äºåœ¨ä»£ç ä¸­ä»¥ç¼–ç¨‹æ–¹å¼åˆ›å»º AddOp çš„å®ä¾‹ã€‚ Verification:\nAddOp::verifyInvariantsImpl() å’Œ AddOp::verifyInvariants() : è¿™äº›æ–¹æ³•ç”¨äºæ£€æŸ¥ä¸€ä¸ª AddOp å®ä¾‹æ˜¯å¦ç¬¦åˆå…¶å®šä¹‰ã€‚ä¾‹å¦‚ï¼Œå®ƒä»¬ä¼šéªŒè¯æ“ä½œæ•°çš„æ•°é‡å’Œç±»å‹æ˜¯å¦æ­£ç¡®ï¼Œç»“æœç±»å‹æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚ä»£ç ä¸­è°ƒç”¨äº†åƒ __mlir_ods_local_type_constraint_PolyOps2 è¿™æ ·çš„è¾…åŠ©å‡½æ•°æ¥è¿›è¡Œç±»å‹çº¦æŸæ£€æŸ¥ã€‚ Assembly Format Parsing and Printing:\nAddOp::parse(::mlir::OpAsmParser\u0026amp; parser, ::mlir::OperationState\u0026amp; result) : è¿™ä¸ªæ–¹æ³•å®šä¹‰äº†å¦‚ä½•ä» MLIR çš„æ–‡æœ¬æ±‡ç¼–æ ¼å¼ä¸­è§£æå‡º AddOp ã€‚å½“ MLIR å·¥å…·è¯»å– .mlir æ–‡ä»¶æ—¶ï¼Œä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚ AddOp::print(::mlir::OpAsmPrinter\u0026amp; _odsPrinter) : è¿™ä¸ªæ–¹æ³•å®šä¹‰äº†å¦‚ä½•å°† AddOp å®ä¾‹æ‰“å°æˆ MLIR çš„æ–‡æœ¬æ±‡ç¼–æ ¼å¼ã€‚ Type ID Definition:\nMLIR_DEFINE_EXPLICIT_TYPE_ID(::mlir::tutorial::poly::AddOp) : è¿™ä¸ªå®ç”¨äº MLIR çš„è¿è¡Œæ—¶ç±»å‹ä¿¡æ¯ (RTTI) ç³»ç»Ÿï¼Œä¸º AddOp ç±»å‹ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„æ ‡è¯†ç¬¦ã€‚ ","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch4-defining-a-new-dialect/","summary":"Personal MLIR learning notes 4.","title":"MLIR-Ch4 Defining a New Dialect"},{"content":"What is Tablegen? TableGen æ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆä»£ç å’Œæè¿°ç»“æ„çš„ DSL å’Œå·¥å…·ï¼Œæœ€åˆç”± LLVM å¼€å‘ï¼Œåæ¥è¢« MLIR ç»§æ‰¿å¹¶æ‰©å±•ã€‚å®ƒä¸»è¦ç”¨äºä»¥å£°æ˜å¼çš„æ–¹å¼å®šä¹‰å’Œç”Ÿæˆ MLIR çš„å„ç§ç»„ä»¶ï¼Œä¾‹å¦‚ Dialectsã€Operationsã€Attributesã€Types å’Œ Passesï¼Œä»è€Œå‡å°‘æ‰‹åŠ¨ç¼–å†™é‡å¤æ€§ C++ ä»£ç çš„å·¥ä½œé‡ã€‚\nmlir-tablegen å¹¶æ²¡æœ‰æ¸…æ¥šåœ°å‘Šè¯‰ä½ å“ªäº›å‡½æ•°æ²¡æœ‰å®ç°ï¼Œä¹Ÿæ²¡æœ‰è§£é‡Šå¿…é¡»ç¼–å†™çš„å‡½æ•°ã€‚ç¡®å®šç¼ºå¤±å†…å®¹çš„ä¸»è¦æ–¹æ³•æ˜¯å°è¯•ç”¨ä¸€äº›ä½¿ç”¨å®ƒçš„ä»£ç æ¥æ„å»ºç”Ÿæˆçš„ä»£ç ï¼Œç„¶åç­›é€‰æ•°ç™¾è¡Œ c++ ç¼–è¯‘å™¨é”™è¯¯ï¼Œè¿™åè¿‡æ¥åˆéœ€è¦äº†è§£ç”Ÿæˆä»£ç ä¸­çš„å„ç§æ¨¡æ¿æ“ä½œã€‚ç”Ÿæˆçš„ä»£ç å°†ä½¿ç”¨å¿…é¡»çŸ¥é“çš„ç¬¦å·ï¼Œä»¥ä¾¿åœ¨æ­£ç¡®çš„ä½ç½®å¯¼å…¥æˆ–æå‰å£°æ˜ï¼Œå¹¶ä¸”å®ƒè¦æ±‚ç®¡ç†ç”Ÿæˆçš„ä»£ç æ‰€åœ¨çš„åç§°ç©ºé—´ã€‚\nTablegen Files and the mlir-tblgen Binary TableGen å…è®¸ä½ å®šä¹‰å˜é‡ï¼Œå¹¶ä¸”è¿™äº›å˜é‡å¯ä»¥åœ¨å¤šä¸ªå®šä¹‰ä¸­é‡å¤ä½¿ç”¨ã€‚\nTableGenå…è®¸ä½ åœ¨å®šä¹‰ä¸­åµŒå…¥C++ä»£ç ç‰‡æ®µã€‚è¿™äº›ä»£ç ç‰‡æ®µä¼šè¢«æ’å…¥åˆ°TableGenç”Ÿæˆçš„C++ç±»ä¸­ï¼Œå¹¶ä¸”è¿™äº›C++ä»£ç ç‰‡æ®µå¯ä»¥è®¿é—®å‰é¢å®šä¹‰çš„å˜é‡ã€‚è¿™ä½¿å¾—TableGenèƒ½å¤Ÿç”Ÿæˆé«˜åº¦å®šåˆ¶åŒ–çš„C++ä»£ç ã€‚å¦‚æœéœ€è¦ä¸ºä½ çš„ pass ç¼–å†™ç‰¹æ®Šçš„æ„é€ å‡½æ•°ï¼Œå°±å¯ä»¥åœ¨ PassBase.tdä¸­ç”¨ TableGen çš„è¯­æ³•å†™ä¸‹ç›¸åº”çš„ C++ ä»£ç ã€‚\nä¸‹é¢ç»™å‡ºäº†ä¸€ä¸ªä»¥ tablegen è¯­æ³•é‡å†™ä¸Šä¸€ç« çš„ AffineFullUnroll pass çš„ä¾‹å­\n1 2 3 4 5 6 7 8 9 10 // mlir-learning/Transform/Affine/Pass.td include \u0026#34;mlir/Pass/PassBase.td\u0026#34; def AffineFullUnroll : Pass\u0026lt;\u0026#34;affine-full-unroll\u0026#34;\u0026gt; { let summary = \u0026#34;Fully unroll all affine loops\u0026#34;; let description = [{ Fully unroll all affine loops. (could add more docs here like code examples) }]; let dependentDialects = [\u0026#34;mlir::affine::AffineDialect\u0026#34;]; } TableGen æ‹¥æœ‰ç±»ä¼¼çš„ç±»å’Œç»§æ‰¿çš„æ¦‚å¿µã€‚: Pass\u0026lt;...\u0026gt; è¡¨ç¤ºä¸€ä¸ªç±»ç»§æ‰¿è‡ª PassBase.td æ–‡ä»¶ä¸­å®šä¹‰çš„ Pass åŸºç±»\ndef ç”¨äºå®šä¹‰ä¸€ä¸ªå…·ä½“å®ä¾‹ï¼Œå®ƒä¼šç”Ÿæˆå¯¹åº”çš„ C++ ä»£ç ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œä½¿ç”¨ def å®šä¹‰çš„ç±»å®ä¾‹ä¼šè¢« TableGen å¤„ç†ï¼Œæœ€ç»ˆè½¬æ¢æˆå®é™…çš„ä»£ç ï¼Œè€Œä»…ä»…ä½¿ç”¨ class å®šä¹‰çš„ç±»åˆ™ä¸ä¼šç›´æ¥ç”Ÿæˆä»£ç ï¼Œåªä½œä¸ºæ¨¡æ¿æˆ–åŸºç±»å­˜åœ¨ã€‚\nä¸Šé¢ä»£ç è¯´æ˜ TableGen å…è®¸å®šä¹‰å­—ç¬¦ä¸²å˜é‡å’Œåˆ—è¡¨ã€‚ TableGen è¿˜æœ‰ä¸€ä¸ªé‡è¦åŠŸèƒ½ï¼šå®ƒå…è®¸å®šä¹‰å˜é‡å¹¶åœ¨å¤šä¸ªå®šä¹‰ä¸­å¤ç”¨è¿™äº›å˜é‡ï¼Œè¿˜å¯ä»¥å®šä¹‰ C++ ä»£ç ç‰‡æ®µï¼Œå¹¶å°†è¿™äº›ç‰‡æ®µæ’å…¥åˆ°ç”Ÿæˆçš„ç±»ä¸­ã€‚ è¿™äº› C++ ä»£ç ç‰‡æ®µå¯ä»¥ä½¿ç”¨å‰é¢å®šä¹‰çš„å˜é‡ã€‚ä¾‹å¦‚ PassBase.td ç±»å®šä¹‰äº†ä¸€ä¸ªä»£ç æ„é€ å‡½æ•°å˜é‡ã€‚ å¦‚æœéœ€è¦ä¸ºä½ çš„ Pass ç±»ç¼–å†™ç‰¹æ®Šçš„æ„é€ å‡½æ•°ï¼Œå¯ä»¥åœ¨ PassBase.td ä¸­ç¼–å†™ç›¸åº”çš„ C++ ä»£ç ã€‚ è¿™æ„å‘³ç€ TableGen ä¸ä»…ä»…æ˜¯ç®€å•çš„æ–‡æœ¬æ›¿æ¢ï¼Œå®ƒèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ä»£ç ç”Ÿæˆé€»è¾‘ï¼ŒåŒ…æ‹¬å˜é‡çš„è·¨å®šä¹‰ä½¿ç”¨å’Œ C++ ä»£ç çš„åµŒå…¥ã€‚\nå’Œä¸Šä¸€ç« ä¸åŒçš„æ˜¯ï¼Œè¿™æ¬¡æˆ‘ä»¬ä¹Ÿéœ€è¦åœ¨ include ç›®å½•ä¸‹å†™ä¸€ä¸ª CMakeLists.txt\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 set(TARGET_NAME \u0026#34;${PROJECT_TARGET_PREFIX}-Transform-Affine-Passes-IncGen\u0026#34;) set(LLVM_TARGET_DEFINITIONS mlir-learning/Transform/Affine/Pass.td) mlir_tablegen(mlir-learning/Transform/Affine/Pass.h.inc -gen-pass-decls -name=Affine) mlir_tablegen(mlir-learning/Transform/Affine/Pass.md -gen-pass-doc) add_public_tablegen_target(${TARGET_NAME}) set( ALL_TABLEGEN_TARGETS ${PROJECT_TARGET_PREFIX}-Transform-Affine-Passes-IncGen #${PROJECT_TARGET_PREFIX}-Transform-Arith-Passes-IncGen ) # Add the generated files to a global property, so they can be used in the library set_property( GLOBAL PROPERTY ${PROJECT_TARGET_PREFIX}-TABLEGEN-TARGETS ${ALL_TABLEGEN_TARGETS} ) set(LLVM_TARGET_DEFINITIONS mlir-learning/Transform/Affine/Pass.td): è¿™è¡Œä»£ç è®¾ç½®äº† TableGen çš„è¾“å…¥æ–‡ä»¶ã€‚ mlir_tablegen(mlir-learning/Transform/Affine/Pass.h.inc -gen-pass-decls -name=Affine): è¿™è¡Œè°ƒç”¨äº† mlir_tablegen å‘½ä»¤ï¼Œå®ƒå°† Pass.td æ–‡ä»¶ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆä¸€ä¸ªåä¸º Pass.h.inc çš„å¤´æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å« Pass çš„å£°æ˜ (-gen-pass-decls)ï¼Œå¹¶ä¸”å‘½åç©ºé—´ä¸º Affine (-name=Affine). mlir_tablegen(mlir-learning/Transform/Affine/Pass.md -gen-pass-doc): è¿™è¡ŒåŒæ ·è°ƒç”¨ mlir_tablegenï¼Œç”Ÿæˆä¸€ä¸ªåä¸º Pass.md çš„æ–‡ä»¶ï¼ŒåŒ…å« Pass çš„æ–‡æ¡£ä¿¡æ¯ (-gen-pass-doc). add_public_tablegen_target(${TARGET_NAME}): è¿™è¡Œä»£ç å°† TableGen ç”Ÿæˆçš„ç›®æ ‡æ·»åŠ åˆ° CMake é¡¹ç›®ä¸­ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªå…¬å…±ç›®æ ‡ï¼Œå…¶ä»–éƒ¨åˆ†å¯ä»¥ä¾èµ–å®ƒã€‚ set(ALL_TABLEGEN_TARGETS ...): è¿™è¡Œä»£ç å®šä¹‰äº†ä¸€ä¸ªåˆ—è¡¨ ALL_TABLEGEN_TARGETSï¼ŒåŒ…å«æ‰€æœ‰ TableGen ç”Ÿæˆçš„ç›®æ ‡ã€‚ set_property(GLOBAL PROPERTY ...): è¿™è¡Œä»£ç å°†æ‰€æœ‰ TableGen ç”Ÿæˆçš„ç›®æ ‡æ·»åŠ åˆ°å…¨å±€å±æ€§ ${PROJECT_TARGET_PREFIX}-TABLEGEN-TARGETS} ä¸­ã€‚ ä½¿å¾—æ„å»ºç³»ç»Ÿèƒ½å¤Ÿè·Ÿè¸ªå’Œç®¡ç†æ‰€æœ‰ç”± TableGen ç”Ÿæˆçš„æ–‡ä»¶ï¼Œç¡®ä¿å®ƒä»¬è¢«æ­£ç¡®åœ°åŒ…å«åœ¨åº“æˆ–å¯æ‰§è¡Œæ–‡ä»¶ä¸­ã€‚ .inc Files æˆ‘ä»¬åŒæ ·åˆ›å»ºå’Œä¸Šä¸€ç« ç›¸åŒçš„æ–‡ä»¶ (å¯ä»¥å…ˆä¸å†™)ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ç”±äº TableGen ç”Ÿæˆçš„ .inc æ–‡ä»¶ä½äºæ„å»ºç›®å½•ä¸‹ï¼Œåœ¨ lib çš„ CMakeLists.txt ä¸­æˆ‘ä»¬éœ€è¦åœ¨ target_include_directories å‘½ä»¤ä¸­åŠ å…¥ ${CMAKE_OUTPUT_DIR}/include\nä¸‹é¢æˆ‘ä»¬æ¥é€æ®µçœ‹ç”Ÿæˆçš„ .inc æ–‡ä»¶\nå¤´éƒ¨ä¿æŠ¤å’Œæ¡ä»¶ç¼–è¯‘ 1 2 3 4 5 6 7 //===----------------------------------------------------------------------===// // AffineFullUnroll //===----------------------------------------------------------------------===// #ifdef GEN_PASS_DECL_AFFINEFULLUNROLL std::unique_ptr\u0026lt;::mlir::Pass\u0026gt; createAffineFullUnroll(); #undef GEN_PASS_DECL_AFFINEFULLUNROLL #endif // GEN_PASS_DECL_AFFINEFULLUNROLL è¿™éƒ¨åˆ†ä»£ç ä½¿ç”¨äº†é¢„å¤„ç†å® GEN_PASS_DECL_AFFINEFULLUNROLLã€‚ å¦‚æœè¿™ä¸ªå®è¢«å®šä¹‰ï¼Œåˆ™ç¼–è¯‘å™¨ä¼šç”Ÿæˆ createAffineFullUnroll() å‡½æ•°çš„å£°æ˜ã€‚\nPass çš„å®ç° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #ifdef GEN_PASS_DEF_AFFINEFULLUNROLL namespace impl { std::unique_ptr\u0026lt;::mlir::Pass\u0026gt; createAffineFullUnroll(); } // namespace impl namespace impl { template \u0026lt;typename DerivedT\u0026gt; class AffineFullUnrollBase : public ::mlir::OperationPass\u0026lt;\u0026gt; { // ... (Pass çš„æ–¹æ³•å®šä¹‰) ... }; } // namespace impl std::unique_ptr\u0026lt;::mlir::Pass\u0026gt; createAffineFullUnroll() { return impl::createAffineFullUnroll(); } #undef GEN_PASS_DEF_AFFINEFULLUNROLL #endif // GEN_PASS_DEF_AFFINEFULLUNROLL è¿™éƒ¨åˆ†æ˜¯ Pass çš„ä¸»è¦å®ç°ã€‚å®ƒä½¿ç”¨äº† GEN_PASS_DEF_AFFINEFULLUNROLL å®æ¥æ§åˆ¶ç¼–è¯‘ã€‚å¦‚æœè¯¥å®è¢«å®šä¹‰ï¼Œåˆ™ç¼–è¯‘å™¨ä¼šç¼–è¯‘ AffineFullUnrollBase ç±»ä»¥åŠ createAffineFullUnroll å‡½æ•°ã€‚\nAffineFullUnrollBase æ˜¯ä¸€ä¸ªåŸºç±»æ¨¡æ¿ï¼Œä½¿ç”¨ CRTP (Curiously Recurring Template Pattern) æŠ€æœ¯ï¼Œå…è®¸æ´¾ç”Ÿç±»é€šè¿‡ DerivedT è·å–è‡ªèº«çš„ç±»å‹ä¿¡æ¯ã€‚ è¿™æ˜¯ä¸€ç§å¸¸è§çš„ C++ è®¾è®¡æ¨¡å¼ï¼Œç”¨äºå®ç°é™æ€å¤šæ€ã€‚å®ƒå®šä¹‰äº† Pass çš„åŸºæœ¬ä¿¡æ¯ï¼Œä¾‹å¦‚åç§°ã€æè¿°ã€å‘½ä»¤è¡Œå‚æ•°ã€ä¾èµ–çš„ Dialect (è¿™é‡Œæ˜¯ mlir::affine::AffineDialect). createAffineFullUnroll å‡½æ•°è´Ÿè´£åˆ›å»º AffineFullUnroll Pass çš„å®ä¾‹ã€‚ å®ƒä½¿ç”¨äº† impl å‘½åç©ºé—´ï¼Œè¿™æ˜¯ä¸€ç§å¸¸è§çš„ C++ ä»£ç ç»„ç»‡æ–¹å¼ï¼Œç”¨äºéšè—å®ç°ç»†èŠ‚ã€‚ Pass æ³¨å†Œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #ifdef GEN_PASS_REGISTRATION //===----------------------------------------------------------------------===// // AffineFullUnroll Registration //===----------------------------------------------------------------------===// inline void registerAffineFullUnroll() { ::mlir::registerPass([]() -\u0026gt; std::unique_ptr\u0026lt;::mlir::Pass\u0026gt; { return createAffineFullUnroll(); }); } // Old registration code, kept for temporary backwards compatibility. inline void registerAffineFullUnrollPass() { ::mlir::registerPass([]() -\u0026gt; std::unique_ptr\u0026lt;::mlir::Pass\u0026gt; { return createAffineFullUnroll(); }); } //===----------------------------------------------------------------------===// // Affine Registration //===----------------------------------------------------------------------===// inline void registerAffinePasses() { registerAffineFullUnroll(); } #undef GEN_PASS_REGISTRATION #endif // GEN_PASS_REGISTRATION Complete .hpp \u0026amp; .cpp TableGenæ ¹æ® .tdæ–‡ä»¶ç”ŸæˆPassçš„ä»£ç ï¼Œç”Ÿæˆçš„ä»£ç åŒ…å«æ³¨å†Œå‡½æ•°ï¼Œè¿™äº›æ³¨å†Œå‡½æ•°æœ€ç»ˆä¼šè¢«è°ƒç”¨ï¼Œå°†Passæ³¨å†Œåˆ°MLIRç³»ç»Ÿä¸­ã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡å†™ä¸€ä¸ª Passes.hæ–‡ä»¶é›†ä¸­ç®¡ç†æ‰€æœ‰Passçš„æ³¨å†Œï¼Œç®€åŒ–æ„å»ºè¿‡ç¨‹ã€‚\n1 2 3 4 5 6 7 // include/mlir-learning/Transform/Affine/Pass.h #include \u0026#34;mlir-learning/Transform/Affine/AffineFullUnroll.h\u0026#34; namespace mlir::tutorial { #define GEN_PASS_REGISTRION #include \u0026#34;mlir-learning/Transform/Affine/Pass.h.inc\u0026#34; } ç„¶åå†å¯¹åº”çš„ AffineFullUnroll.hpp ä¸­å®šä¹‰ GEN_PASS_DECL_AFFINEFULLUNROLL å®ï¼Œä»¥å®ç°åˆ›å»º Pass å‡½æ•°çš„å£°æ˜ã€‚\n1 2 3 4 5 6 7 8 9 #pragma once #include \u0026#34;mlir/Pass/Pass.h\u0026#34; namespace mlir::tutorial { #define GEN_PASS_DECL_AFFINEFULLUNROLL #include \u0026#34;mlir-learning/Transform/Affine/Pass.h.inc\u0026#34; } // namespace mlir::tutorial åŒæ ·åœ¨ cpp ä¸­éœ€è¦å®šä¹‰ GEN_PASS_DEF_AFFINEFULLUNROLL å®ï¼Œç„¶åå†™ä½ å¯¹åº”çš„å®ç° (ä¸ä¸Šä¸€ç« ç›¸åŒ). é—®é¢˜æ˜¯ä»…ä»…æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç å¹¶ä¸èƒ½ç›´æ¥çœ‹å‡ºè¿˜éœ€è¦å®ç°å“ªäº›å‡½æ•°ï¼Œéœ€è¦é€šè¿‡å…¶ä»–æ–¹æ³•æ¥ç¡®å®šã€‚\nç¼–è¯‘å¹¶æŸ¥çœ‹ç¼–è¯‘å™¨é”™è¯¯ä¿¡æ¯: æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯å°è¯•ç¼–è¯‘ä»£ç ã€‚ç¼–è¯‘å™¨ä¼šæŒ‡å‡ºå“ªäº›å‡½æ•°æ²¡æœ‰å®ç°ï¼Œä»è€Œå‘Šè¯‰ä½ éœ€è¦å®ç°å“ªäº›å‡½æ•°ã€‚ ä¸åŸºç±»è¿›è¡Œæ¯”è¾ƒ: å¯ä»¥å°†ç”Ÿæˆçš„ä»£ç ä¸åŸºç±»ï¼ˆOperationPasså’Œ Passï¼‰è¿›è¡Œæ¯”è¾ƒã€‚é€šè¿‡æ¯”è¾ƒï¼Œå¯ä»¥å‘ç°å”¯ä¸€éœ€è¦å®ç°çš„å‡½æ•°æ˜¯ runOnOperation()ã€‚ è¿™éœ€è¦ä½ ç†Ÿæ‚‰MLIR Passçš„ç»§æ‰¿ç»“æ„å’Œå„ä¸ªå‡½æ•°çš„ä½œç”¨ã€‚ è§‚å¯Ÿç¼ºå¤±çš„å‡½æ•°: å¦‚æœä¹‹å‰å·²ç»ä»åŸå§‹APIæ‰‹åŠ¨å®ç°è¿‡ç±»ä¼¼çš„Passï¼Œå¯ä»¥è§‚å¯Ÿç”Ÿæˆçš„ä»£ç ä¸­å“ªäº›å‡½æ•°å·²ç»å­˜åœ¨ï¼ˆä¾‹å¦‚ getArgumentï¼‰ï¼Œå“ªäº›å‡½æ•°ç¼ºå¤±ï¼ˆä¾‹å¦‚ runOnOperationï¼‰ã€‚ é€šè¿‡å¯¹æ¯”ï¼Œå¯ä»¥ç¡®å®šè¿˜éœ€è¦å®ç°å“ªäº›å‡½æ•°ã€‚ å…·ä½“çš„å®ç°ä¸ä¸Šä¸€ç« ç›¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬è¦ç»§æ‰¿ .inc æ–‡ä»¶ä¸­ç”Ÿæˆçš„ç±»\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #include \u0026#34;mlir-learning/Transform/Affine/AffineFullUnroll.h\u0026#34; #include \u0026#34;mlir/Dialect/Affine/IR/AffineOps.h\u0026#34; #include \u0026#34;mlir/Dialect/Affine/LoopUtils.h\u0026#34; #include \u0026#34;mlir/Pass/Pass.h\u0026#34; namespace mlir::tutorial { #define GEN_PASS_DEF_AFFINEFULLUNROLL #include \u0026#34;mlir-learning/Transform/Affine/Pass.h.inc\u0026#34; using mlir::affine::AffineForOp; using mlir::affine::loopUnrollFull; class AffineFullUnroll : public impl::AffineFullUnrollBase\u0026lt;AffineFullUnroll\u0026gt; { public: using AffineFullUnrollBase::AffineFullUnrollBase; void runOnOperation() override { getOperation()-\u0026gt;walk([\u0026amp;](AffineForOp op) { if (failed(loopUnrollFull(op))) { op.emitError(\u0026#34;unrolling failed\u0026#34;); signalPassFailure(); } }); } }; } // namespace mlir::tutorial æœ€ååœ¨ tutorial.cpp ä¸­ä½¿ç”¨ .inc æ–‡ä»¶ç”Ÿæˆçš„ registerAffinePasses\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026#34;mlir/IR/DialectRegistry.h\u0026#34; #include \u0026#34;mlir/InitAllDialects.h\u0026#34; #include \u0026#34;mlir/Pass/PassManager.h\u0026#34; #include \u0026#34;mlir/Pass/PassRegistry.h\u0026#34; #include \u0026#34;mlir/Tools/mlir-opt/MlirOptMain.h\u0026#34; #include \u0026#34;mlir-learning/Transform/Affine/Pass.h\u0026#34; int main(int argc, char** argv) { // Register all built-in MLIR dialects mlir::DialectRegistry registry; mlir::registerAllDialects(registry); mlir::tutorial::registerAffinePasses(); return mlir::asMainReturnCode( mlir::MlirOptMain(argc, argv, \u0026#34;Tutorial Pass Driver\u0026#34;, registry)); } ","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch3-using-tablegen-for-passes/","summary":"Personal MLIR learning notes 3.","title":"MLIR-Ch3 Using Tablegen for Passes"},{"content":"Tutorial-opt and Project Organization ç¼–è¯‘å™¨å¯èƒ½å°† mlir-opt ä½œä¸ºå­ä¾‹ç¨‹åœ¨å‰ç«¯ (c++ -\u0026gt; æŸäº›MLIRæ–¹è¨€) å’Œåç«¯ (MLIR çš„ LLVM æ–¹è¨€ -\u0026gt; LLVM -\u0026gt; æœºå™¨ç ) ä¹‹é—´è¿è¡Œã€‚ (æˆ‘å°†å®ƒå‘½åä¸º tutorial-opt).\nå…¸å‹çš„ MLIR ä»£ç åº“å°†ä»£ç åˆ†æˆå…·æœ‰å¤§è‡´ç›¸åŒå±‚æ¬¡ç»“æ„çš„ç›®å½•ï¼š\ninclude/ ç›®å½•ç”¨äºå­˜æ”¾å¤´æ–‡ä»¶å’Œtablegen æ–‡ä»¶ï¼Œ lib/ ç›®å½•ç”¨äºå­˜æ”¾å®ç°ä»£ç ã€‚å¯èƒ½ä¼šæœ‰ Transform/ å­ç›®å½•ç”¨äºå­˜å‚¨åœ¨æ–¹è¨€ä¸­è½¬æ¢ä»£ç çš„ passï¼ŒConversion/ å­ç›®å½•ç”¨äºåœ¨æ–¹è¨€ä¹‹é—´è½¬æ¢çš„ pass ï¼ŒAnalysis/ å­ç›®å½•ç”¨äºåˆ†æ passï¼Œç­‰ç­‰ã€‚è¿™äº›ç›®å½•ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯èƒ½æœ‰å®ƒä»¬æ‰€æ“ä½œçš„ç‰¹å®šæ–¹è¨€çš„å­ç›®å½•ã€‚ test/ ç”¨äºå­˜æ”¾éœ€è¦æµ‹è¯•çš„ mlir æ–‡ä»¶ã€‚ tools/ å­˜æ”¾ç”¨äºæ³¨å†Œ pass çš„ä¸»æ–‡ä»¶ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ./Ch1-WritingOurFirstPass/ â”œâ”€â”€ CMakeLists.txt â”œâ”€â”€ include â”‚ â””â”€â”€ mlir-tutorial â”œâ”€â”€ lib â”‚ â”œâ”€â”€ CMakeLists.txt â”‚ â””â”€â”€ Transform â”œâ”€â”€ tests â”‚ â”œâ”€â”€ Output â”‚ â”œâ”€â”€ affine_loop_unroll.mlir â”‚ â”œâ”€â”€ lit.cfg.py â”‚ â””â”€â”€ mul_to_add.mlir â””â”€â”€ tools â”œâ”€â”€ CMakeLists.txt â””â”€â”€ tutorial-opt.cpp å°½ç®¡ MLIR æä¾›äº†è®¸å¤šå®šä¹‰å¾ªç¯å’Œæ§åˆ¶æµçš„æœºåˆ¶ï¼Œæœ€é«˜çº§çš„æ˜¯ affine dialect. å®ƒè¢«è®¾è®¡ç”¨æ¥è¿›è¡Œå¤šé¢ä½“å¾ªç¯åˆ†æ (polyhedral loop analysis).\nPolyhedral Loop Analysis å¤šé¢ä½“å¾ªç¯åˆ†æçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ç¨‹åºä¸­çš„å¾ªç¯å’Œæ•°ç»„è®¿é—®æŠ½è±¡ä¸ºæ•°å­¦å½¢å¼ï¼Œä½¿å¾—å¯ä»¥åº”ç”¨å‡ ä½•å˜æ¢æ¥ä¼˜åŒ–ä»£ç ã€‚è¿™ç§æ•°å­¦å½¢å¼é€šå¸¸è¡¨ç¤ºä¸º æ•´æ•°çº¿æ€§ä¸ç­‰å¼çš„é›†åˆ ï¼Œè¿™äº›ä¸ç­‰å¼å®šä¹‰äº†å¾ªç¯è¿­ä»£ç©ºé—´å’Œæ•°ç»„è®¿é—®çš„èŒƒå›´ã€‚\nè¿­ä»£ç©ºé—´ï¼ˆIteration Spaceï¼‰ ï¼šç¨‹åºä¸­çš„å¾ªç¯åµŒå¥—å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªå¤šç»´çš„è¿­ä»£ç©ºé—´ã€‚ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ªåŒå±‚åµŒå¥—å¾ªç¯ï¼š 1 2 3 4 5 for (i = 0; i \u0026lt; N; i++) { for (j = 0; j \u0026lt; M; j++) { A[i][j] = A[i][j] + 1; } } è¿™é‡Œçš„è¿­ä»£ç©ºé—´æ˜¯äºŒç»´çš„ï¼Œç”± (i, j) æ„æˆã€‚\nè®¿é—®å…³ç³»ï¼ˆAccess Relationsï¼‰ ï¼šæ¯ä¸ªæ•°ç»„çš„è®¿é—®æ¨¡å¼ï¼ˆä¾‹å¦‚ A[i][j]ï¼‰ä¹Ÿå¯ä»¥è¢«è¡¨ç¤ºä¸ºå‡ ä½•å…³ç³»ã€‚è¿™ç§å…³ç³»å®šä¹‰äº†å“ªäº›è¿­ä»£å˜é‡è®¿é—®å“ªäº›æ•°ç»„å…ƒç´ ã€‚ å¤šé¢ä½“è¡¨ç¤ºï¼ˆPolyhedral Representationï¼‰ ï¼šåœ¨å¤šé¢ä½“å¾ªç¯åˆ†æä¸­ï¼Œå¾ªç¯çš„è¿­ä»£ç©ºé—´å’Œæ•°ç»„è®¿é—®æ¨¡å¼å¯ä»¥ç”¨æ•´æ•°çº¿æ€§ä¸ç­‰å¼æ¥è¡¨ç¤ºï¼Œä»è€Œå½¢æˆä¸€ä¸ªå¤šé¢ä½“ã€‚ä¾‹å¦‚ï¼Œ0\u0026lt;=i\u0026lt;N å’Œ 0\u0026lt;=j\u0026lt;M æ˜¯ä¸¤ä¸ªç®€å•çš„çº¿æ€§ä¸ç­‰å¼ï¼Œå®ƒä»¬è¡¨ç¤ºå¾ªç¯çš„è¾¹ç•Œã€‚ ä¸€ä¸ªç®€å•çš„å¯¹æ•°ç»„æ±‚å’Œçš„å‡½æ•°å¦‚ä¸‹: affine.for å®šä¹‰ä¸€ä¸ªå¾ªç¯ï¼Œè¿­ä»£å˜é‡ä¸º %iï¼ŒèŒƒå›´ [0,4)ï¼Œå³å¾ªç¯ 4 æ¬¡ã€‚ iter_args(%sum_iter = %sum_0) è¡¨ç¤ºå¾ªç¯ç»´æŠ¤ä¸€ä¸ªè¿­ä»£å˜é‡ %sum_iterï¼Œåˆå§‹å€¼ä¸º %sum_0.\n1 2 3 4 5 6 7 8 9 func.func @sum_buffer(%buffer: memref\u0026lt;4xi32\u0026gt;) -\u0026gt; i32 { %sum_0 = arigh.constant 0 : i32 %sum = affine.for %i = 0 to 4 iter_args(%sum_iter = %sum_0) -\u0026gt; (i32) { %t = affine.load %buffer[%i] : memref\u0026lt;4xi32\u0026gt; %sum_next = arith.addi %sum_iter, %t : i32 affine.yield %sum_next : i32 } return %sum: i32 } MLIR é«˜çº§ç»“æ„ åŸºäºå›¾æ•°æ®ç»“æ„ï¼Œå…¶èŠ‚ç‚¹ç§°ä¸º Operationsï¼Œè¾¹ç§°ä¸º Valuesã€‚æ¯ä¸ª Value éƒ½æ˜¯ä¸€ä¸ª Operation æˆ– Block Argument çš„ç»“æœï¼Œå¹¶å…·æœ‰ç”±ç±»å‹ç³»ç»Ÿå®šä¹‰çš„ Value Typeã€‚Operations åŒ…å«åœ¨ Blocks ä¸­ï¼ŒBlocks åŒ…å«åœ¨ Regions ä¸­ã€‚Operations åœ¨å…¶æ‰€åœ¨çš„ Block ä¸­æ˜¯æœ‰åºçš„ï¼ŒBlocks åœ¨å…¶æ‰€åœ¨çš„ Region ä¸­ä¹Ÿæ˜¯æœ‰åºçš„ï¼Œå°½ç®¡è¿™ç§é¡ºåºåœ¨ç‰¹å®šç±»å‹çš„ Region ä¸­å¯èƒ½å…·æœ‰æˆ–ä¸å…·æœ‰è¯­ä¹‰æ„ä¹‰ã€‚Operations è¿˜å¯ä»¥åŒ…å« Regionsï¼Œä»è€Œèƒ½å¤Ÿè¡¨ç¤ºå±‚æ¬¡åŒ–çš„ç»“æ„ã€‚\nOperations å¯ä»¥è¡¨ç¤ºå¤šç§ä¸åŒçš„æ¦‚å¿µï¼Œä»é«˜çº§æ¦‚å¿µå¦‚å‡½æ•°å®šä¹‰ã€å‡½æ•°è°ƒç”¨ã€ç¼“å†²åŒºåˆ†é…ã€ç¼“å†²åŒºçš„è§†å›¾æˆ–åˆ‡ç‰‡ã€è¿›ç¨‹åˆ›å»ºï¼Œåˆ°ä½çº§æ¦‚å¿µå¦‚ç›®æ ‡æ— å…³çš„ç®—æœ¯è¿ç®—ã€ç›®æ ‡ç‰¹å®šçš„æŒ‡ä»¤ã€é…ç½®å¯„å­˜å™¨å’Œé€»è¾‘é—¨ã€‚è¿™äº›ä¸åŒçš„æ¦‚å¿µåœ¨ MLIR ä¸­ç”±ä¸åŒçš„ Operations è¡¨ç¤ºï¼Œå¹¶ä¸” MLIR ä¸­å¯ç”¨çš„ Operations é›†å¯ä»¥ä»»æ„æ‰©å±•ã€‚\nMLIR è¿˜æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºå¯¹ Operations è¿›è¡Œè½¬æ¢ï¼Œä½¿ç”¨ç†Ÿæ‚‰çš„ç¼–è¯‘å™¨ Passes æ¦‚å¿µã€‚åœ¨ä»»æ„ Operations é›†ä¸Šå¯ç”¨ä»»æ„ Passes é›†ä¼šå¸¦æ¥æ˜¾è‘—çš„æ‰©å±•æ€§æŒ‘æˆ˜ï¼Œå› ä¸ºæ¯ä¸ªè½¬æ¢å¯èƒ½éœ€è¦è€ƒè™‘ä»»ä½• Operation çš„è¯­ä¹‰ã€‚MLIR é€šè¿‡å…è®¸ä½¿ç”¨ Traits å’Œ Interfaces æŠ½è±¡åœ°æè¿° Operation çš„è¯­ä¹‰æ¥è§£å†³è¿™ç§å¤æ‚æ€§ï¼Œä»è€Œä½¿è½¬æ¢èƒ½å¤Ÿæ›´é€šç”¨åœ°æ“ä½œ Operationsã€‚Traits é€šå¸¸æè¿°å¯¹æœ‰æ•ˆ IR çš„éªŒè¯çº¦æŸï¼Œèƒ½å¤Ÿæ•è·å’Œæ£€æŸ¥å¤æ‚çš„ä¸å˜æ€§ã€‚ï¼ˆå‚è§ Op vs Operationï¼‰\nMLIR çš„è¡¨ç¤ºåŸºäº SSA çš„ IRï¼Œä¾‹å¦‚ LLVM core IRï¼Œé€šè¿‡é€‚å½“é€‰æ‹© Operation ç±»å‹æ¥å®šä¹‰ Modulesã€Functionsã€Branchesã€Memory Allocationï¼Œä»¥åŠéªŒè¯çº¦æŸä»¥ç¡®ä¿ SSA Dominance å±æ€§ã€‚MLIR åŒ…å«ä¸€ç»„ Dialectsï¼Œå®šä¹‰äº†æ­¤ç±»ç»“æ„ã€‚\nAffine Full Unroll Pass MLIR æä¾›äº†ä¸€ä¸ªæ–¹æ³• loopUnrollFull æ¥è¿›è¡Œå¾ªç¯å±•å¼€ï¼Œå› æ­¤æˆ‘ä»¬çš„ pass å°†æ˜¯å¯¹è¿™ä¸ªå‡½æ•°è°ƒç”¨çš„ä¸€ä¸ªåŒ…è£…ï¼Œç›´æ¥è°ƒç”¨ C++ API å®ç°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // include/mlir-learning/Transform/Affine/AffineFullUnroll.h class AffineFullUnrollPass : public PassWrapper\u0026lt;AffineFullUnrollPass, OperationPass\u0026lt;mlir::FuncOp\u0026gt;\u0026gt; { private: void runOnOperation() override; StringRef getArgument() const final {return \u0026#34;affine-full-unroll\u0026#34;;} StringRef getDescription() const final { return \u0026#34;Perform full unrolling of all affine.for loops\u0026#34;; } }; // lib/Transform/Affine/AffineFullUnroll.cpp using mlir::affine::AffineForOp; using mlir::affine::loopUnrollFull; void AffineFullUnrollPass::runOnOperation() { getOperation().walk( [\u0026amp;](AffineForOp op) { if (failed(loopUnrollFull(op))) { op.emitError(\u0026#34;unrolling failed\u0026#34;); signalPassFailure(); } }); } è¯¥ç±»çš„å®šä¹‰ä½¿ç”¨äº†å¥‡å¼‚é€’å½’æ¨¡æ¿æ¨¡å¼ (Curiously Recurring Template Pattern, CRTP). PassWrapper æ˜¯ MLIR æ¡†æ¶ä¸­çš„ä¸€ä¸ªæ¨¡æ¿ç±»ï¼Œä¸ºå®šä¹‰çš„ Pass æä¾›é€šç”¨åŠŸèƒ½ (å¦‚ç±»å‹æ£€æŸ¥ã€åç§°è·å–ã€å…‹éš†)ã€‚å¼€å‘è€…åªéœ€ä¸“æ³¨äº Pass çš„æ ¸å¿ƒé€»è¾‘ï¼ˆå¦‚ runOnOperationï¼‰ï¼Œè€Œæ— éœ€æ‰‹åŠ¨å®ç°ç±»å‹æ ‡è¯†ã€å…‹éš†ç­‰è¾…åŠ©åŠŸèƒ½ã€‚\nrunOnOperation ä¸­è°ƒç”¨äº† getOperation æ–¹æ³•ï¼Œå®ƒæ˜¯ MLIR ä¸­ Pass ç±»æä¾›çš„ä¸€ä¸ªæ–¹æ³•ï¼Œè¿”å›å½“å‰æ“ Operation. walk æ–¹æ³•æ˜¯ MLIR æä¾›çš„ä¸€ä¸ªéå†æ–¹æ³•ï¼Œç”¨æ¥éå†æ“ä½œæ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ã€‚å®ƒä¼šé€’å½’åœ°éå†æ“ä½œæ ‘ä¸­çš„æ‰€æœ‰å­æ“ä½œï¼Œå¹¶å¯¹æ¯ä¸ªæ“ä½œåº”ç”¨ä¼ å…¥çš„å›è°ƒå‡½æ•° (lambda func). å½“è¿è¡Œè¿™ä¸ª Pass æ—¶ï¼Œå®ƒä¼šåœ¨æ¯ä¸€ä¸ª AffineForOp ç±»å‹çš„æ“ä½œä¸Šæ‰§è¡Œ runOnOperation å‡½æ•°ã€‚ getArgument æ–¹æ³•è¿”å› Pass çš„å‘½ä»¤è¡Œå‚æ•°ã€‚è¿™ä¸ªè¿”å›å€¼ affine-full-unroll è¡¨ç¤ºè¿™ä¸ª Pass çš„åç§°ï¼Œå¯ä»¥åœ¨è¿è¡Œæ—¶é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ˜¯å¦å¯ç”¨è¯¥ Pass. getDescription æ–¹æ³•ä¼šåœ¨è°ƒç”¨åƒ mlir-opt è¿™æ ·çš„å·¥å…·æ—¶è‹¥æœ‰ --help å‚æ•°åˆ™è¿”å› Pass çš„æè¿°ä¿¡æ¯ã€‚ Callback Function å›è°ƒå‡½æ•° (Callback Function) æ˜¯ä¸€ç§é€šè¿‡å°†å‡½æ•°ä½œä¸ºå‚æ•°ä¼ é€’ç»™å¦ä¸€ä¸ªå‡½æ•°ï¼Œæ¥å®ç°æŸäº›ç‰¹å®šæ“ä½œçš„æœºåˆ¶ã€‚å›è°ƒå‡½æ•°é€šå¸¸åœ¨æŸä¸ªäº‹ä»¶å‘ç”Ÿæˆ–æŸä¸ªç‰¹å®šæ¡ä»¶æ»¡è¶³æ—¶è¢«è°ƒç”¨ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå›è°ƒå‡½æ•°å°±æ˜¯è¢«è°ƒç”¨çš„å‡½æ•°ï¼Œå®ƒä¼šåœ¨ç‰¹å®šçš„æ—¶æœºè¢«æ‰§è¡Œã€‚\nåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ŒinvokeCallback å‡½æ•°æ¥æ”¶åˆ° printMessage å‡½æ•°çš„åœ°å€ï¼Œå¹¶åœ¨ main å‡½æ•°ä¸­è°ƒç”¨å®ƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;iostream\u0026gt; // å›è°ƒå‡½æ•°çš„å®šä¹‰ void printMessage() { std::cout \u0026lt;\u0026lt; \u0026#34;Hello, World!\u0026#34; \u0026lt;\u0026lt; std::endl; } // æ¥å—å›è°ƒå‡½æ•°ä½œä¸ºå‚æ•°çš„å‡½æ•° void invokeCallback(void (*callback)()) { // è°ƒç”¨å›è°ƒå‡½æ•° callback(); } int main() { // å°†å›è°ƒå‡½æ•°ä¼ é€’ç»™å¦ä¸€ä¸ªå‡½æ•° invokeCallback(printMessage); return 0; } åœ¨ç°ä»£ C++ ä¸­ï¼Œå›è°ƒå‡½æ•°é€šå¸¸é€šè¿‡ lambda è¡¨è¾¾å¼ä¼ é€’ã€‚ä¸‹é¢çš„ä¾‹å­ä¸­ invokeCallback å‡½æ•°æ¥å—ä¸€ä¸ª std::function\u0026lt;void()\u0026gt; ç±»å‹çš„å›è°ƒå‡½æ•°å‚æ•°ã€‚åœ¨ main å‡½æ•°ä¸­ï¼Œä¼ å…¥äº†ä¸€ä¸ª Lambda è¡¨è¾¾å¼ä½œä¸ºå›è°ƒå‡½æ•°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; void invokeCallback(std::function\u0026lt;void()\u0026gt; callback) { callback(); } int main() { // ä½¿ç”¨ Lambda è¡¨è¾¾å¼ä½œä¸ºå›è°ƒå‡½æ•° invokeCallback([](){ std::cout \u0026lt;\u0026lt; \u0026#34;Hello from Lambda!\u0026#34; \u0026lt;\u0026lt; std::endl; }); return 0; } Registering the Pass æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦åœ¨ tutorial.cpp ä¸­æ³¨å†Œè¿™ä¸ª Passã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026#34;mlir-learning/Transform/Affine/AffineFullUnroll.h\u0026#34; #include \u0026#34;mlir/InitAllDialects.h\u0026#34; #include \u0026#34;mlir/Pass/PassManager.h\u0026#34; #include \u0026#34;mlir/Pass/PassRegistry.h\u0026#34; #include \u0026#34;mlir/Tools/mlir-opt/MlirOptMain.h\u0026#34; int main(int argc, char** argv) { mlir::DialectRegistry registry; mlir::registerAllDialects(registry); mlir::PassRegistration\u0026lt;mlir::tutorial::AffineFullUnrollPass\u0026gt;(); return mlir::asMainReturnCode( mlir::MlirOptMain(argc, argv, \u0026#34;Tutorial Pass Driver\u0026#34;, registry)); } mlir::registerAllDialects(registry); ä¼šè°ƒç”¨ MLIR åº“çš„å‡½æ•°ï¼Œå°†æ‰€æœ‰å¯ç”¨çš„æ–¹è¨€æ³¨å†Œåˆ° registry ä¸­ã€‚æ–¹è¨€æ˜¯ MLIR ä¸­ç”¨æ¥å®šä¹‰å„ç§ä¸­é—´è¡¨ç¤ºçš„æŠ½è±¡ï¼Œå¯ä»¥ç†è§£ä¸ºä¸åŒç±»å‹çš„ IR. mlir::PassRegistration\u0026lt;mlir::tutorial::AffineFullUnrollPass\u0026gt;(); å°†è‡ªå®šä¹‰çš„ AffineFullUnrollPass æ³¨å†Œåˆ° MLIR çš„ Pass ç³»ç»Ÿä¸­ã€‚ MlirOptMain æ˜¯ MLIR æä¾›çš„ä¸€ä¸ªå‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶æ‰§è¡Œç›¸åº”çš„ Pass. argc å’Œ argvï¼šæ¥è‡ªå‘½ä»¤è¡Œçš„å‚æ•°ã€‚ \u0026ldquo;Tutorial Pass Driver\u0026rdquo;ï¼šè¿™æ˜¯ä¸€ä¸ªç¨‹åºæè¿°å­—ç¬¦ä¸²ï¼Œé€šå¸¸æ˜¯ç»™ç”¨æˆ·çš„ä¿¡æ¯ã€‚ registryï¼šä¹‹å‰åˆ›å»ºçš„ DialectRegistryï¼Œå®ƒåŒ…å«äº†æ‰€æœ‰å·²æ³¨å†Œçš„æ–¹è¨€ã€‚ mlir::asMainReturnCode(...) å°† MlirOptMain çš„è¿”å›å€¼è½¬æ¢ä¸ºæ ‡å‡†çš„é€€å‡ºä»£ç  (0 è¡¨ç¤ºæˆåŠŸï¼Œéé›¶å€¼è¡¨ç¤ºå¤±è´¥). Test the Pass æˆ‘ä»¬å†™ä¸€ä¸ª .mlir æ¥æµ‹è¯•æˆ‘ä»¬çš„ Passï¼Œè¿™æ˜¯ä¸€ä¸ªå¯¹æ•°ç»„è¿›è¡Œç´¯åŠ çš„å‡½æ•°ã€‚FileCheck æ£€æŸ¥ç»è¿‡ Pass åå‡½æ•°ä¸­ä¸ä¼šå­˜åœ¨ affine.for æŒ‡ä»¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 // RUN: /leaning/build/chapter2/tools/02-tutorial-opt %s --affine-full-unroll \u0026gt; %t // RUN: FileCheck %s \u0026lt; %t func.func @test_single_nested_loop(%buffer: memref\u0026lt;4xi32\u0026gt;) -\u0026gt; (i32) { %sum_0 = arith.constant 0 : i32 // CHECK-NOT: affine.for %sum = affine.for %i = 0 to 4 iter_args(%sum_iter = %sum_0) -\u0026gt; i32 { %t = affine.load %buffer[%i] : memref\u0026lt;4xi32\u0026gt; %sum_next = arith.addi %sum_iter, %t : i32 affine.yield %sum_next : i32 } return %sum : i32 } ç»è¿‡ä¼˜åŒ–åçš„å‡½æ•°å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #map = affine_map\u0026lt;(d0) -\u0026gt; (d0 + 1)\u0026gt; #map1 = affine_map\u0026lt;(d0) -\u0026gt; (d0 + 2)\u0026gt; #map2 = affine_map\u0026lt;(d0) -\u0026gt; (d0 + 3)\u0026gt; module { func.func @test_single_nested_loop(%arg0: memref\u0026lt;4xi32\u0026gt;) -\u0026gt; i32 { %c0 = arith.constant 0 : index %c0_i32 = arith.constant 0 : i32 %0 = affine.load %arg0[%c0] : memref\u0026lt;4xi32\u0026gt; %1 = arith.addi %c0_i32, %0 : i32 %2 = affine.apply #map(%c0) %3 = affine.load %arg0[%2] : memref\u0026lt;4xi32\u0026gt; %4 = arith.addi %1, %3 : i32 %5 = affine.apply #map1(%c0) %6 = affine.load %arg0[%5] : memref\u0026lt;4xi32\u0026gt; %7 = arith.addi %4, %6 : i32 %8 = affine.apply #map2(%c0) %9 = affine.load %arg0[%8] : memref\u0026lt;4xi32\u0026gt; %10 = arith.addi %7, %9 : i32 return %10 : i32 } } A Rewrite Pattern Version å½“æƒ³è¦å¯¹ä¸€ä¸ªç»™å®šçš„ IR å­ç»“æ„é‡å¤åº”ç”¨ç›¸åŒçš„å˜æ¢å­é›†ï¼Œç›´åˆ°è¯¥å­ç»“æ„è¢«å®Œå…¨å»é™¤æ—¶ï¼Œéœ€è¦å†™ä¸€ä¸ªé‡å†™æ¨¡å¼å¼•æ“ã€‚é‡å†™æ¨¡å¼æ˜¯ OpRewritePattern çš„å­ç±»ï¼Œå®ƒæœ‰ä¸€ä¸ªåä¸º matchAndRewrite çš„æ–¹æ³•æ¥æ‰§è¡Œè½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // chapter2/lib/Transform/Affine/AffineFullUnroll.cpp struct AffineFullUnrollPattern : public mlir::OpRewritePattern\u0026lt;AffineForOp\u0026gt; { AffineFullUnrollPattern(mlir::MLIRContext* context) : mlir::OpRewritePattern\u0026lt;AffineForOp\u0026gt;(context, 1) { } // ä¸€èˆ¬åœ¨ OpRewritePattern ä¸­ï¼ŒIR çš„æ›´æ”¹è¦é€šè¿‡ PatternRewriter // PatternRewriter å¤„ç† OpRewritePatternä¸­å‘ç”Ÿçš„çªå˜çš„åŸå­æ€§ LogicalResult matchAndRewrite(AffineForOp op, PatternRewriter\u0026amp; rewriter) const override{ return loopUnrollFull(op); } }; AffineFullUnrollPattern ç»§æ‰¿è‡ª OpRewritePattern\u0026lt;AffineForOp\u0026gt;ï¼ŒOpRewritePattern æ˜¯ MLIR ä¸­ç”¨äºå¯¹ç‰¹å®šæ“ä½œç±»å‹ (åœ¨è¿™é‡Œæ˜¯ AffineForOp) è¿›è¡Œæ¨¡å¼åŒ¹é…å’Œé‡å†™çš„åŸºç±»ã€‚æ¨¡æ¿å‚æ•° AffineForOp è¡¨ç¤ºæˆ‘ä»¬è¦ä¸º AffineForOp è¿™ä¸ªæ“ä½œåˆ›å»ºä¸€ä¸ªæ¨¡å¼ã€‚ æ„é€ å‡½æ•°åˆå§‹åŒ–äº†åŸºç±» OpRewritePattern\u0026lt;AffineForOp\u0026gt;ï¼Œå¹¶ä¼ é€’äº†ä¸¤ä¸ªå‚æ•° contextï¼šMLIRContext æ˜¯ MLIR çš„ä¸Šä¸‹æ–‡ï¼Œä¿å­˜ç€æ‰€æœ‰çš„æ“ä½œã€æ–¹è¨€å’Œç±»å‹ç­‰ä¿¡æ¯ã€‚åœ¨è¿™é‡Œï¼Œcontext ç”¨æ¥åˆå§‹åŒ–æ¨¡å¼å¯¹è±¡ã€‚ benefit æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ¨¡å¼åŒ¹é…ä¼˜å…ˆçº§çš„æ•´æ•°å€¼ï¼Œä¼˜å…ˆçº§è¶Šé«˜çš„æ¨¡å¼è¶Šå…ˆåº”ç”¨ã€‚ matchAndRewrite æ˜¯åœ¨ MLIR ä¸­è¿›è¡Œæ¨¡å¼é‡å†™çš„æ ¸å¿ƒæ–¹æ³•ã€‚å®ƒçš„ç›®çš„æ˜¯ï¼šæ£€æŸ¥æŸä¸ªæ“ä½œæ˜¯å¦ç¬¦åˆå½“å‰æ¨¡å¼çš„è¦æ±‚ã€‚å¦‚æœæ“ä½œåŒ¹é…æ¨¡å¼ï¼Œåˆ™æ‰§è¡Œé‡å†™æ“ä½œï¼Œé€šå¸¸ä¼šç”¨æ–°çš„ IR æ›¿æ¢åŸæ¥çš„ IRã€‚ AffineForOp op è¡¨ç¤ºè¦è¿›è¡Œæ¨¡å¼åŒ¹é…çš„ AffineForOp æ“ä½œã€‚ PatternRewriter \u0026amp;rewriter æ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆæ–°çš„ MLIR æ“ä½œçš„å·¥å…·ï¼Œå®ƒå¯ä»¥ä¿®æ”¹ IR. æˆ‘ä»¬åŒæ ·è¦åƒä¸Šä¸€èŠ‚ä¸€æ ·åœ¨å¤´æ–‡ä»¶ä¸­å£°æ˜ä¸€ä¸ª AffineFullUnrollPassAsPatternRewrite ç±»ï¼Œç„¶åå®ç°å…¶ runOnOperation æ–¹æ³•ã€‚\n1 2 3 4 5 6 // chapter2/lib/Transform/Affine/AffineFullUnroll.cpp void AffineFullUnrollPassAsPatternRewrite::runOnOperation() { mlir::RewritePatternSet patterns(\u0026amp;getContext()); patterns.add\u0026lt;AffineFullUnrollPattern\u0026gt;(\u0026amp;getContext()); (void) applyPatternsGreedily(getOperation(), std::move(patterns)); } RewritePatternSet æ˜¯ MLIR ä¸­ä¸€ä¸ªå®¹å™¨ï¼Œç”¨äºå­˜å‚¨å¤šä¸ª Rewrite Pattern. æ¯ä¸ªæ¨¡å¼éƒ½æ˜¯é’ˆå¯¹æŸç§ç‰¹å®šæ“ä½œè¿›è¡Œçš„ä¼˜åŒ–è§„åˆ™ã€‚RewritePatternSet ä¼šæŠŠæ‰€æœ‰è¿™äº›è§„åˆ™èšåˆåœ¨ä¸€èµ·ï¼Œæ–¹ä¾¿åœ¨åç»­çš„æ­¥éª¤ä¸­æ‰¹é‡åº”ç”¨ã€‚ ç„¶åé€šè¿‡ patterns.add\u0026lt;AffineFullUnrollPattern\u0026gt;ï¼Œå°†ä¸€ä¸ª Rewrite Pattern (è¿™é‡Œæ˜¯ä¸Šé¢å®šä¹‰çš„ AffineFullUnrollPattern) æ·»åŠ åˆ° patterns é›†åˆä¸­ã€‚ applyPatternsGreedilyæ˜¯ MLIR æä¾›çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå°†å®šä¹‰çš„æ¨¡å¼åº”ç”¨åˆ°ç»™å®šçš„æ“ä½œ (getOperation()) ä¸Šã€‚è¿™ä¸ªå‡½æ•°ä½¿ç”¨è´ªå¿ƒç­–ç•¥ï¼Œåœ¨ä¸€æ¬¡éå†ä¸­å°½å¯èƒ½å¤šåœ°åº”ç”¨æ¨¡å¼ï¼Œç›´åˆ°æ— æ³•å†åº”ç”¨ä¸ºæ­¢ã€‚ std::move std::move æ˜¯ C++11 å¼•å…¥çš„ä¸€ä¸ªæ ‡å‡†åº“å‡½æ•°ï¼Œå®ƒçš„ä¸»è¦ä½œç”¨æ˜¯å°†ä¸€ä¸ªå¯¹è±¡è½¬æ¢ä¸ºå³å€¼å¼•ç”¨ï¼Œä»¥ä¾¿å¯ç”¨ç§»åŠ¨è¯­ä¹‰ (Move Semantics). ç®€å•æ¥è¯´ï¼Œstd::move æœ¬èº«å¹¶ä¸å®é™…ç§»åŠ¨å¯¹è±¡ï¼Œè€Œæ˜¯ä¸ºå¯¹è±¡æä¾›ä¸€ä¸ªæŒ‡ç¤ºï¼Œå‘Šè¯‰ç¼–è¯‘å™¨è¯¥å¯¹è±¡å¯ä»¥è¢«ç§»åŠ¨è€Œä¸æ˜¯å¤åˆ¶ã€‚\nåœ¨ C++ ä¸­ï¼Œæœ‰ä¸¤ç§ä¸»è¦çš„å€¼ç±»åˆ«:\nå·¦å€¼ (Lvalue) ï¼šè¡¨ç¤ºå¯ä»¥å–åœ°å€çš„å¯¹è±¡ï¼Œå¯ä»¥ç†è§£ä¸ºæ‹¥æœ‰æŒä¹…ç”Ÿå‘½å‘¨æœŸçš„å¯¹è±¡ã€‚å®ƒé€šå¸¸æ˜¯å˜é‡ã€æ•°ç»„å…ƒç´ ã€å¯¹è±¡æˆå‘˜ç­‰ã€‚ å³å€¼ (Rvalue) ï¼šè¡¨ç¤ºä¸´æ—¶å¯¹è±¡ã€éæŒä¹…ç”Ÿå‘½å‘¨æœŸçš„å¯¹è±¡ï¼Œé€šå¸¸æ˜¯è¿”å›å€¼ã€å­—é¢å¸¸é‡ç­‰ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;utility\u0026gt; // std::move class MyClass { public: MyClass() { std::cout \u0026lt;\u0026lt; \u0026#34;Constructor\\n\u0026#34;; } MyClass(const MyClass\u0026amp; other) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy Constructor\\n\u0026#34;; } MyClass(MyClass\u0026amp;\u0026amp; other) noexcept { std::cout \u0026lt;\u0026lt; \u0026#34;Move Constructor\\n\u0026#34;; } MyClass\u0026amp; operator=(const MyClass\u0026amp; other) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy Assignment\\n\u0026#34;; return *this; } MyClass\u0026amp; operator=(MyClass\u0026amp;\u0026amp; other) noexcept { std::cout \u0026lt;\u0026lt; \u0026#34;Move Assignment\\n\u0026#34;; return *this; } }; int main() { MyClass obj1; // Constructor MyClass obj2 = std::move(obj1); // Move Constructor MyClass obj3; obj3 = std::move(obj2); // Move Assignment } A proper greedy RewritePattern æ¥ä¸‹æ¥å†™ä¸€ä¸ªç”¨é‡å†™æ¨¡å¼å®šä¹‰çš„ MulToAddPassï¼Œå®ƒä¼šå°† y=C*x å½¢å¼çš„ä¹˜æ³•è½¬æ¢ä¸º y=C/2*x+C/2*x å½¢å¼çš„åŠ æ³•å½“ C æ˜¯å¶æ•°ã€‚å¦åˆ™è½¬æ¢æˆ y=1+(C-1)/2*x+(C-1)/2*x å½¢å¼çš„åŠ æ³•ã€‚\nPowerOfTwoExpand è·å–äº† rhs çš„å®šä¹‰æ“ä½œï¼ˆrhs.getDefiningOp\u0026lt;arith::ConstantIntOp\u0026gt;()ï¼‰ï¼Œä»¥ç¡®ä¿å³æ“ä½œæ•°æ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚ å¦‚æœå³æ“ä½œæ•°çš„å€¼æ˜¯ 2 çš„å¹‚ï¼Œå³ (value \u0026amp; (value - 1)) == 0ï¼Œåˆ™è¿›è¡Œä¼˜åŒ–ã€‚ å°† value é™¤ä»¥ 2 ç„¶åç”Ÿæˆæ–°çš„å¸¸æ•° newConstantã€‚ è®¡ç®—æ–°çš„ä¹˜æ³• lhs * newConstantï¼Œå¹¶å°†å…¶åŠ å€ï¼ˆé€šè¿‡ AddIOp æ¥å®ç° lhs * valueï¼‰ã€‚ æœ€ç»ˆç”¨æ–°çš„åŠ æ³•æ›¿ä»£åŸæ¥çš„ä¹˜æ³•ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 struct PowerOfTwoExpand : public OpRewritePattern\u0026lt;MulIOp\u0026gt; { PowerOfTwoExpand(MLIRContext* context) : OpRewritePattern\u0026lt;MulIOp\u0026gt;(context, 2) { } LogicalResult matchAndRewrite(MulIOp op, PatternRewriter\u0026amp; rewriter) const override { // Value represents an instance of an SSA value in the MLIR system Value lhs = op-\u0026gt;getOperand(0); Value rhs = op-\u0026gt;getOperand(1); auto rhsDefiningOp = rhs.getDefiningOp\u0026lt;arith::ConstantIntOp\u0026gt;(); if (!rhsDefiningOp) { return failure(); } int64_t value = rhsDefiningOp.value(); bool is_power_of_two = (value \u0026amp; (value - 1)) == 0; if (!is_power_of_two) { return failure(); } auto newConstant = rewriter.create\u0026lt;ConstantOp\u0026gt;( rhsDefiningOp-\u0026gt;getLoc(), rewriter.getIntegerAttr(rhs.getType(), value / 2)); auto newMul = rewriter.create\u0026lt;MulIOp\u0026gt;(op-\u0026gt;getLoc(), lhs, newConstant); auto newAdd = rewriter.create\u0026lt;AddIOp\u0026gt;(op-\u0026gt;getLoc(), newMul, newMul); rewriter.replaceOp(op, newAdd); rewriter.eraseOp(rhsDefiningOp); return success(); } }; PeelFromMul è¿™ä¸ª Pass çš„ç›®æ ‡æ˜¯å°†ä¸€ä¸ªå¸¸æ•°ä¹˜æ³•è½¬åŒ–ä¸ºåŠ æ³•å½¢å¼ï¼Œé€‚ç”¨äºå¸¸æ•°å€¼ rhs ä¸ä¸º 2 çš„å¹‚æ—¶ã€‚\nå°† rhs å‡å» 1ï¼Œç„¶åç”Ÿæˆä¸€ä¸ªæ–°çš„å¸¸æ•° newConstantï¼ˆå³ value - 1ï¼‰ã€‚ ç”¨ lhs * newConstant è¿›è¡Œè®¡ç®—ï¼Œå¹¶å°†ç»“æœåŠ ä¸Š lhsï¼ˆå³ lhs * value è½¬åŒ–ä¸º (lhs * (value - 1)) + lhsï¼‰ã€‚ æœ€ç»ˆç”¨æ–°çš„åŠ æ³•æ›¿ä»£åŸæ¥çš„ä¹˜æ³•ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 struct PeelFromMul : public OpRewritePattern\u0026lt;MulIOp\u0026gt; { PeelFromMul(MLIRContext* context) : OpRewritePattern\u0026lt;MulIOp\u0026gt;(context, 1) { } LogicalResult matchAndRewrtite(MulIOp op, PatternRewriter\u0026amp; rewriter) const { Value lhs = op-\u0026gt;getOperand(0); Value rhs = op-\u0026gt;getOperand(1); auto rhsDefiningOp = rhs.getDefiningOp\u0026lt;arith::ConstantIntOp\u0026gt;(); if (!rhsDefiningOp) { return failure(); } int64_t value = rhsDefiningOp.value(); // Beacause PowerOfTwoExpand has higher benefit, // value must not be power of 2 auto newConstant = rewriter.create\u0026lt;ConstantOp\u0026gt;( rhsDefiningOp-\u0026gt;getLoc(), rewriter.getIntegerAttr(rhs.getType(), value - 1)); auto newMul = rewriter.create\u0026lt;MulIOp\u0026gt;(op.getLoc(), lhs, newConstant); auto newAdd = rewriter.create\u0026lt;AddIOp\u0026gt;(op.getLoc(), newMul, lhs); rewriter.replaceOp(op, newAdd); rewriter.eraseOp(rhsDefiningOp); return success(); } }; Add the Pass ä¹‹åæˆ‘ä»¬åŒæ ·åœ¨ runOnOperation æ–¹æ³•ä¸­æ³¨å†Œ PowerOfTwoExpand å’Œ PeelFromMul ä¸¤ä¸ªæ¨¡å¼ã€‚\n1 2 3 4 5 6 void MulToAddPass::runOnOperation() { mlir::RewritePatternSet patterns(\u0026amp;getContext()); patterns.add\u0026lt;PowerOfTwoExpand\u0026gt;(\u0026amp;getContext()); patterns.add\u0026lt;PeelFromMul\u0026gt;(\u0026amp;getContext()); (void) applyPatternsAndFoldGreedily(getOperation(), std::move(patterns)); } Lit, FileCheck LLVM å’Œ MLIR ä½¿ç”¨çš„æ˜¯åŒä¸€ä¸ªæµ‹è¯•æ¡†æ¶ï¼Œåˆ†ä¸ºä¸¤ä¸ªæµ‹è¯•æ­¥éª¤ã€‚\nlit (LLVM Integratesd Tester) è´Ÿè´£å‘ç°ã€ç»„ç»‡å’Œè¿è¡Œæµ‹è¯•ï¼Œå¹¶æŠ¥å‘Šæµ‹è¯•ç»“æœã€‚æµ‹è¯•æ–‡ä»¶ä¸­é€šå¸¸åŒ…å« RUN: æŒ‡ä»¤ï¼Œå‘Šè¯‰ lit å¦‚ä½•è¿è¡Œæµ‹è¯•ã€‚ FileCheck é€šè¿‡æ¨¡å¼åŒ¹é…çš„æ–¹å¼ï¼ŒéªŒè¯è¾“å‡ºæ˜¯å¦åŒ…å«ç‰¹å®šçš„å­—ç¬¦ä¸²æˆ–ç»“æ„ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # lit.cfg.py # CMD: llvm-lit -v path/to/test_files import os from os import path as osp from lit.formats import ShTest config.name = \u0026#34;MLIR-LEARN\u0026#34; config.test_format = ShTest() config.suffixes = [\u0026#34;.mlir\u0026#34;] current_path = os.getcwd() tool_path = \u0026#34;path/to/build/opt_executable\u0026#34; config.environment[\u0026#34;PATH\u0026#34;] = ( osp.join(current_path, tool_path) + \u0026#34;:\u0026#34; + os.environ[\u0026#34;PATH\u0026#34;] ) Test the Pass æˆ‘ä»¬åŒæ ·åˆ›å»ºä¸€ä¸ª .mlir æ–‡ä»¶æ¥æµ‹è¯•æˆ‘ä»¬çš„ Pass. æˆ‘ä»¬å¸Œæœ› Pass èƒ½å¤Ÿå°†é€’å½’åœ°å°†ä¹˜æ³•è½¬åŒ–ä¸ºåŠ æ³•å½¢å¼ï¼Œ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // RUN: /leaning/build/chapter2/tools/02-tutorial-opt %s --mul-to-add \u0026gt; %t // RUN: FileCheck %s \u0026lt; %t func.func @just_power_of_two(%arg0: i32) -\u0026gt; i32 { %0 = arith.constant 8: i32 %1 = arith.muli %arg0, %0: i32 func.return %1: i32 } // CHECK-LABEL: func.func @just_power_of_two( // CHECK-SAME: %[[ARG:.*]]: i32 // CHECK-SAME: ) -\u0026gt; i32 { // CHECK: %[[SUM_0:.*]] = arith.addi %[[ARG]], %[[ARG]] // CHECK: %[[SUM_1:.*]] = arith.addi %[[SUM_0]], %[[SUM_0]] // CHECK: %[[SUM_2:.*]] = arith.addi %[[SUM_1]], %[[SUM_1]] // CHECK: return %[[SUM_2]] : i32 // CHECK: } func.func @power_of_two_plus_one(%arg: i32) -\u0026gt; i32 { %0 = arith.constant 9 : i32 %1 = arith.muli %arg, %0 : i32 func.return %1 : i32 } // CHECK-LABEL: func.func @power_of_two_plus_one( // CHECK-SAME: %[[ARG:.*]]: i32 // CHECK-SAME: ) -\u0026gt; i32 { // CHECK: %[[SUM_0:.*]] = arith.addi %[[ARG]], %[[ARG]] // CHECK: %[[SUM_1:.*]] = arith.addi %[[SUM_0]], %[[SUM_0]] // CHECK: %[[SUM_2:.*]] = arith.addi %[[SUM_1]], %[[SUM_1]] // CHECK: %[[SUM_3:.*]] = arith.addi %[[SUM_2]], %[[ARG]] // CHECK: return %[[SUM_3]] : i32 // CHECK: } ç»è¿‡ä¼˜åŒ–åçš„ä»£ç å¦‚ä¸‹ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 module { func.func @just_power_of_two(%arg0: i32) -\u0026gt; i32 { %0 = arith.addi %arg0, %arg0 : i32 %1 = arith.addi %0, %0 : i32 %2 = arith.addi %1, %1 : i32 return %2 : i32 } func.func @power_of_two_plus_one(%arg0: i32) -\u0026gt; i32 { %0 = arith.addi %arg0, %arg0 : i32 %1 = arith.addi %0, %0 : i32 %2 = arith.addi %1, %1 : i32 %3 = arith.addi %2, %arg0 : i32 return %3 : i32 } } Summary ä½¿ç”¨æ¨¡å¼é‡å†™å¼•æ“é€šå¸¸æ¯”ç¼–å†™éå†ASTçš„ä»£ç æ›´å®¹æ˜“ã€‚ä¸éœ€è¦å¤§å‹ case/switch è¯­å¥æ¥å¤„ç† IR ä¸­å¯èƒ½å‡ºç°çš„æ‰€æœ‰å†…å®¹ã€‚å› æ­¤å¯ä»¥å•ç‹¬ç¼–å†™æ¨¡å¼ï¼Œå¹¶ç›¸ä¿¡å¼•æ“ä¼šé€‚å½“åœ°ç»„åˆå®ƒä»¬ã€‚\n","permalink":"http://localhost:1313/blogs/courselearning/mlir/mlir-ch2-writing-our-first-pass/","summary":"Personal MLIR learning notes 2.","title":"MLIR-Ch2 Writing Our First Pass"},{"content":"Abstract DistriFusion å°†æ¨¡å‹è¾“å…¥åˆ†å‰²æˆå¤šä¸ª patch ååˆ†é…ç»™ GPUã€‚ä½†æ˜¯ç›´æ¥å®ç°è¿™æ ·çš„ç®—æ³•ä¼šç ´å patch ä¹‹é—´çš„äº¤äº’å¹¶å¤±å»ä¿çœŸåº¦ï¼Œè€ŒåŒæ­¥ GPU ä¹‹é—´çš„æ¿€æ´»å°†äº§ç”Ÿå·¨å¤§çš„é€šä¿¡å¼€é”€ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å›°å¢ƒï¼Œæ ¹æ®è§‚å¯Ÿåˆ°çš„ç›¸é‚»æ‰©æ•£æ­¥è¾“å…¥ä¹‹é—´çš„é«˜åº¦ç›¸ä¼¼æ€§æå‡ºäº† displaced patch parallelismï¼Œè¯¥æ–¹æ³•é€šè¿‡é‡ç”¨å‰ä¸€ä¸ªæ—¶é—´æ­¥éª¤ä¸­é¢„å…ˆè®¡ç®—çš„ feature map æ¥åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§ï¼Œä¸ºå½“å‰æ­¥æä¾› context. è¯¥æ–¹æ³•æ”¯æŒå¼‚æ­¥é€šä¿¡ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—å®ç°æµæ°´çº¿åŒ–ã€‚\nIntroduction Original, Navie Patch \u0026amp; DistriFusion\nåŠ é€Ÿæ‰©æ•£æ¨¡å‹æ¨ç†ä¸»è¦é›†ä¸­åœ¨ä¸¤ç§æ–¹æ³•ä¸Šï¼šå‡å°‘é‡‡æ ·æ­¥éª¤å’Œä¼˜åŒ–ç½‘ç»œæ¨ç†ã€‚éšç€è®¡ç®—èµ„æºçš„å¿«é€Ÿå¢é•¿ï¼Œåˆ©ç”¨å¤šä¸ª GPU æ¥åŠ é€Ÿæ¨ç†æ˜¯å¾ˆæœ‰å¸å¼•åŠ›çš„ã€‚ä¾‹å¦‚åœ¨ NLP ä¸­ï¼Œ LLM å·²ç»æˆåŠŸåœ°åˆ©ç”¨äº† GPU ä¹‹é—´çš„å¼ é‡å¹¶è¡Œæ€§ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†å»¶è¿Ÿã€‚ç„¶è€Œï¼Œå¯¹äºæ‰©æ•£æ¨¡å‹ï¼Œç”±äºæ¿€æ´»å°ºå¯¸å¤§ï¼Œå¼ é‡å¹¶è¡Œè¿™æ ·çš„æŠ€æœ¯ä¸å¤ªé€‚åˆæ‰©æ•£æ¨¡å‹ã€‚å¤šä¸ª GPU é€šå¸¸åªç”¨äº batch æ¨ç†ï¼Œå½“ç”Ÿæˆå•ä¸ªå›¾åƒæ—¶ï¼Œé€šå¸¸åªæ¶‰åŠä¸€ä¸ªGPU.\nTechniques like tensor parallelism are less suitable for diffusion models due to the large activation size, as communication costs outweigh savings from distributed computation.\nè‡ªç„¶è€Œç„¶çš„ä¸€ç§æ–¹æ³•æ˜¯å°†å›¾åƒåˆ†æˆå‡ ä¸ª patch ååˆ†é…ç»™ä¸åŒçš„è®¾å¤‡è¿›è¡Œç”Ÿæˆã€‚ç”±äºå„ä¸ª patch ä¹‹é—´ç¼ºä¹ç›¸äº’ä½œç”¨ï¼Œå®ƒåœ¨æ¯ä¸ª patch çš„è¾¹ç•Œå¤„éƒ½æœ‰ä¸€ä¸ªæ¸…æ™°å¯è§çš„åˆ†ç•Œçº¿ã€‚\nDistriFusion ä¹Ÿæ˜¯åŸºäº patch parallelism. å…³é”®åœ¨äºæ‰©æ•£æ¨¡å‹ä¸­ç›¸é‚»å»å™ªæ­¥éª¤çš„è¾“å…¥æ˜¯ç›¸ä¼¼çš„ï¼Œå› æ­¤ï¼Œåªåœ¨ç¬¬ä¸€æ­¥é‡‡ç”¨åŒæ­¥é€šä¿¡ã€‚åç»­æ­¥éª¤é‡ç”¨å‰ä¸€æ­¥ä¸­é¢„å…ˆè®¡ç®—çš„æ¿€æ´»ï¼Œä¸ºå½“å‰æ­¥éª¤æä¾›å…¨å±€ä¸Šä¸‹æ–‡å’Œ patch äº¤äº’ã€‚é€šè¿‡å¼‚æ­¥é€šä¿¡æœ‰æ•ˆåœ°éšè—äº†è®¡ç®—ä¸­çš„é€šä¿¡å¼€é”€ã€‚å¹¶ä¸”è¿˜ç¨€ç–åœ°åœ¨æŒ‡å®šçš„åŒºåŸŸä¸Šè¿›è¡Œå·ç§¯å’Œæ³¨æ„åŠ›è®¡ç®—ï¼Œä»è€ŒæŒ‰æ¯”ä¾‹å‡å°‘æ¯ä¸ªè®¾å¤‡çš„è®¡ç®—é‡ã€‚\nMethod Displaced Patch Parallelism. åœ¨é¢„æµ‹ $\\epsilon_{\\theta}(\\mathbf{x}_{t})$ æ—¶ (å¿½ç•¥æ¡ä»¶ c å’Œæ—¶é—´æ­¥ t çš„è¾“å…¥) ï¼Œé¦–å…ˆå°† $\\mathbf{x}_{t}$ åˆ†å‰²æˆå¤šä¸ª patch $\\mathbf{x}_t^{(1)},\\mathbf{x}_t^{(2)},\\ldots,\\mathbf{x}_t^{(N)}$ ï¼Œå¯¹äºæ¯ä¸€å±‚ l å’Œè®¾å¤‡ iï¼Œåœ¨è·å¾—è¾“å…¥æ¿€æ´» patch $\\mathbf{A}_{t}^{l,(i)}$ åå¼‚æ­¥å¤„ç†ä¸¤ä¸ªæ“ä½œï¼šé¦–å…ˆï¼Œå¯¹äºè®¾å¤‡iï¼Œ æ¿€æ´» $\\mathbf{A}_{t}^{l,(i)}$ é¦–å…ˆ scatter åˆ°ä¸Šä¸€æ­¥æ—§çš„æ¿€æ´» $\\mathbf{A}_{t+1}^{l}$ ä¸­ã€‚ç„¶åå°†æ­¤åˆ†æ•£æ“ä½œçš„è¾“å‡ºé€å…¥ç¨€ç–ç®—å­ Fl (çº¿æ€§ã€å·ç§¯æˆ–æ³¨æ„å±‚)ï¼Œè¯¥ç®—å­ä¸“é—¨å¯¹æ–°åŒºåŸŸæ‰§è¡Œè®¡ç®—å¹¶äº§ç”Ÿç›¸åº”çš„è¾“å‡ºã€‚åŒæ—¶ï¼Œå¯¹ $\\mathbf{A}_{t}^{l,(i)}$ æ‰§è¡Œ AllGather æ“ä½œï¼Œä¸ºä¸‹ä¸€æ­¥çš„å…¨å°ºå¯¸æ¿€æ´» $\\mathbf{A}_{t}^{l}$ åšå‡†å¤‡ã€‚\nOverview of DistriFusion\næˆ‘ä»¬å¯¹é™¤ç¬¬ä¸€å±‚ (é‡‡ç”¨åŒæ­¥é€šä¿¡è·å¾—å…¶ä»–è®¾å¤‡ä¸Šçš„è¾“å…¥) å¤–çš„æ¯ä¸€å±‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ã€‚ç„¶åå°†æœ€ç»ˆè¾“å‡º Gather åœ¨ä¸€èµ·ä»¥è¿‘ä¼¼ $\\epsilon_{\\theta}(\\mathbf{x}_{t})$ï¼Œç”¨äºè®¡ç®— $\\mathbf{x}_{t-1}$\nTimeline Visualization on Each Device\nSparse Operations å¯¹äºæ¯ä¸€å±‚ lï¼Œå¦‚æœåŸå§‹ç®—å­ Fl æ˜¯ä¸€ä¸ªå·ç§¯å±‚ã€çº¿æ€§å±‚æˆ–äº¤å‰æ³¨æ„å±‚ï¼Œè°ƒæ•´ä½¿å…¶ä¸“é—¨ä½œç”¨äºæ–°æ¿€æ´»çš„åŒºåŸŸã€‚è¿™å¯ä»¥é€šè¿‡ä» scatter è¾“å‡ºä¸­æå–æœ€æ–°éƒ¨åˆ†å¹¶å°†å…¶è¾“å…¥åˆ° Fl ä¸­æ¥å®ç°ã€‚å¯¹äº self-attentionï¼Œå°†å…¶è½¬æ¢ä¸º cross-attentionï¼Œä»…åœ¨è®¾å¤‡ä¸Šä¿ç•™æ¥è‡ªæ–°æ¿€æ´»çš„ Qï¼Œè€Œ KV ä»ç„¶åŒ…å«æ•´ä¸ªç‰¹å¾å›¾ã€‚\nCorrected Asynchronous GroupNorm ä»…å¯¹æ–° patch è¿›è¡Œå½’ä¸€åŒ–æˆ–é‡ç”¨æ—§ç‰¹å¾éƒ½ä¼šé™ä½å›¾åƒè´¨é‡ã€‚åŒæ­¥ AllGather æ‰€æœ‰å‡å€¼å’Œæ–¹å·®å°†äº§ç”Ÿç›¸å½“å¤§çš„å¼€é”€ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å›°å¢ƒï¼ŒDistriFusion åœ¨é™ˆæ—§çš„ç»Ÿè®¡æ•°æ®ä¸­å¼•å…¥äº†ä¸€ä¸ªæ ¡æ­£é¡¹ã€‚è®¡ç®—å…¬å¼å¦‚ä¸‹\n$$\r\\mathbb{E}[\\mathbf{A}_t]\\approx\\underbrace{\\mathbb{E}[\\mathbf{A}_{t+1}]}_{\\text{stale global mean}}+\\underbrace{\\mathbb{E}[\\mathbf{A}_t^{(i)}]-\\mathbb{E}[\\mathbf{A}_{t+1}^{(i)}]}_{\\text{correction}}\r$$åŒæ ·å¯¹äºŒé˜¶çŸ© $\\mathbb{E}[\\mathbf{A}^2_t]$ ä¹Ÿé‡‡ç”¨è¿™ç§è®¡ç®—æ–¹å¼ï¼Œç„¶åé€šè¿‡ $\\mathbb{E}[\\mathbf{A}^2_t] - \\mathbb{E}[\\mathbf{A}_t]^2$ æ¥è®¡ç®—æ–¹å·®ã€‚å¯¹äºæ–¹å·®ç»“æœä¸ºè´Ÿçš„éƒ¨åˆ†ï¼Œå°†ä½¿ç”¨æ–°é²œ patch çš„å±€éƒ¨æ–¹å·®ä»£æ›¿ã€‚\nCode Implementation Distrifusion ä¸­ä¸»è¦å°±æ˜¯å°† UNet2DConditionModel ä¸­çš„ Conv2d, Attention å’Œ GroupNorm æ›¿æ¢æˆå¯¹åº”çš„ patch å®ç°çš„ç½‘ç»œç»“æ„ DistriUNetPP. è¿™é‡Œç»§æ‰¿çš„ BaseModel ç±»ä¸ºé›†æˆäº† PatchParallelismCommManager ç±» (ä»‹ç»è§åæ–‡) çš„ç½‘ç»œã€‚\nUNet2DConditionModel\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class DistriUNetPP(BaseModel): # for Patch Parallelism def __init__(self, model: UNet2DConditionModel, distri_config: DistriConfig): assert isinstance(model, UNet2DConditionModel) if distri_config.world_size \u0026gt; 1 and distri_config.n_device_per_batch \u0026gt; 1: for name, module in model.named_modules(): if isinstance(module, BaseModule): continue \u0026#39;\u0026#39;\u0026#39; Substitute Conv2d, Attention, GroupNorm with DistriConv2dPP, DistriSelfAttentionPP, DistriCrossAttentionPP, DistriGroupNorm \u0026#39;\u0026#39;\u0026#39; for subname, submodule in module.named_children(): if isinstance(submodule, nn.Conv2d): kernel_size = submodule.kernel_size if kernel_size == (1, 1) or kernel_size == 1: continue wrapped_submodule = DistriConv2dPP( submodule, distri_config, is_first_layer=subname == \u0026#34;conv_in\u0026#34; ) setattr(module, subname, wrapped_submodule) elif isinstance(submodule, Attention): if subname == \u0026#34;attn1\u0026#34;: # self attention wrapped_submodule = DistriSelfAttentionPP(submodule, distri_config) else: # cross attention assert subname == \u0026#34;attn2\u0026#34; wrapped_submodule = DistriCrossAttentionPP(submodule, distri_config) setattr(module, subname, wrapped_submodule) elif isinstance(submodule, nn.GroupNorm): wrapped_submodule = DistriGroupNorm(submodule, distri_config) setattr(module, subname, wrapped_submodule) super(DistriUNetPP, self).__init__(model, distri_config) PatchParallelismCommManager PatchParallelismCommManager ç±»ä¸»è¦å¤„ç†å¼‚æ­¥é€šä¿¡çš„éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class PatchParallelismCommManager: def __init__(self, distri_config: DistriConfig): self.distri_config = distri_config self.torch_dtype = None self.numel = 0 # å·²ç»æ³¨å†Œçš„å¼ é‡çš„ç´¯è®¡æ€»å…ƒç´ æ•°é‡ self.numel_dict = {} # è®°å½•æ¯ä¸ª layer_type æ‰€æ³¨å†Œçš„å¼ é‡çš„ç´¯è®¡å…ƒç´ æ•°é‡ self.buffer_list = None # åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šå­˜å‚¨æ‰€æœ‰æ³¨å†Œå¼ é‡çš„æ•°æ®ï¼Œé€šä¿¡æ‰€ç”¨çš„ buffer self.starts = [] # è®°å½•æ¯ä¸ªæ³¨å†Œå¼ é‡çš„èµ·å§‹ä½ç½® (åœ¨ buffer_list ä¸­çš„èµ·å§‹ç´¢å¼•) self.ends = [] # ç»“æŸ ç»“æŸ self.shapes = [] # è®°å½•æ¯ä¸ªæ³¨å†Œå¼ é‡çš„ shape self.idx_queue = [] # éœ€è¦è¿›è¡Œé€šä¿¡çš„å¼ é‡ç´¢å¼•çš„é˜Ÿåˆ— self.handles = None # å­˜å‚¨æ¯ä¸ªè®¾å¤‡é€šä¿¡æ“ä½œçš„å¥æŸ„çš„ list, ç”¨äºæ£€æŸ¥é€šä¿¡æ˜¯å¦å®Œæˆ æˆå‘˜å‡½æ•°åŠŸèƒ½ä»‹ç»å¦‚ä¸‹\nregister_tensor(self, shape: tuple[int, ...] or list[int], torch_dtype: torch.dtype, layer_type: str = None) -\u0026gt; int: ç”¨äºæ³¨å†Œå¼ é‡çš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹ï¼ŒåŒæ—¶è®¡ç®—å¹¶è®°å½•å¼ é‡åœ¨ç¼“å†²åŒºä¸­çš„èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®ã€‚\nå¦‚æœå°šæœªæŒ‡å®š torch_dtypeï¼Œåˆ™å°†ä¼ å…¥çš„ torch_dtype è®¾ä¸ºç±»æˆå‘˜çš„é»˜è®¤æ•°æ®ç±»å‹ã€‚ è®¡ç®—ä¼ å…¥å¼ é‡å½¢çŠ¶çš„æ€»å…ƒç´ æ•° numelï¼Œå¹¶æ›´æ–° startsã€ends å’Œ shapes åˆ—è¡¨ã€‚ å¦‚æœæŒ‡å®šäº† layer_typeï¼Œæ›´æ–° numel_dict ä¸­è¯¥å±‚ç±»å‹å¯¹åº”çš„å…ƒç´ æ•°ç›®ã€‚ create_buffer(self) : æ¯ä¸ªè®¾å¤‡ä¸Šä¸ºæ‰€æœ‰æ³¨å†Œçš„å¼ é‡åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç¼“å†²åŒºã€‚\nä¸ºæ¯ä¸ªè®¾å¤‡åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º (numel,) çš„å¼ é‡ï¼Œå¹¶å°†å…¶æ”¾å…¥ buffer_list ä¸­ã€‚ è¾“å‡ºåœ¨å„è®¾å¤‡ä¸Šåˆ›å»ºçš„ç¼“å†²åŒºæ€»å‚æ•°é‡ã€‚ get_buffer_list(self, idx: int) -\u0026gt; list[torch.Tensor]: è¿”å›æ¯ä¸ªè®¾å¤‡ä¸Šå¯¹åº”äºæŒ‡å®šç´¢å¼• idx çš„ç¼“å†²åŒºå¼ é‡ã€‚\næ ¹æ® starts å’Œ ends ä¿¡æ¯ï¼Œä» buffer_list ä¸­æå–æŒ‡å®šç´¢å¼• idx çš„å¼ é‡ç‰‡æ®µå¹¶è°ƒæ•´å…¶å½¢çŠ¶ã€‚ communicate(self): è°ƒç”¨ dist.all_gather å°†ç¼“å†²åŒºä¸­çš„å¼ é‡åœ¨ä¸åŒè®¾å¤‡é—´è¿›è¡Œå¹¿æ’­ã€‚\nç¡®å®šå½“å‰éœ€è¦é€šä¿¡çš„å¼ é‡èŒƒå›´ (æ ¹æ® idx_queue ä¸­çš„ç´¢å¼•). è°ƒç”¨ dist.all_gather åœ¨è®¾å¤‡ç»„å†…è¿›è¡Œå¼‚æ­¥å¹¿æ’­é€šä¿¡ï¼Œå¹¶å°†å¥æŸ„å­˜å‚¨åœ¨ handles ä¸­ã€‚ enqueue(self, idx: int, tensor: torch.Tensor): å°†æŒ‡å®šç´¢å¼• idx å¤„çš„å¼ é‡æ•°æ®å¤åˆ¶åˆ° buffer_list ä¸­ï¼Œå¹¶å°†ç´¢å¼•æ·»åŠ åˆ°é€šä¿¡é˜Ÿåˆ— idx_queueã€‚\nå¦‚æœé€šä¿¡é˜Ÿåˆ—ä¸ä¸ºç©ºä¸”ç´¢å¼•ä¸º 0ï¼Œåˆ™å…ˆæ‰§è¡Œä¸€æ¬¡é€šä¿¡æ“ä½œã€‚ å°†å¼ é‡æ•°æ®å¤åˆ¶åˆ° buffer_list ä¸­çš„å¯¹åº”ä½ç½®ã€‚ å½“é€šä¿¡é˜Ÿåˆ—é•¿åº¦è¾¾åˆ° distri_config ä¸­è®¾å®šçš„é€šä¿¡æ£€æŸ¥ç‚¹å€¼æ—¶ï¼Œè¿›è¡Œé€šä¿¡ã€‚ clear(self): æ‰§è¡Œä¸€æ¬¡æ‰€æœ‰å¾…é€šä¿¡å¼ é‡çš„é€šä¿¡ï¼Œå¹¶ç­‰å¾…æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆã€‚\nå¦‚æœé€šä¿¡é˜Ÿåˆ—ä¸ä¸ºç©ºï¼Œåˆ™è¿›è¡Œé€šä¿¡æ“ä½œã€‚ éå†æ‰€æœ‰å¥æŸ„ï¼Œç­‰å¾…æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆåï¼Œå°†å¥æŸ„è®¾ä¸º None. DistriConv2dPP DistriConv2dPP è®¡ç®—è‡ªå·±è´Ÿè´£ patch éƒ¨åˆ†çš„å·ç§¯ï¼Œéœ€è¦é€šä¿¡å…¶ä»–è®¾å¤‡éœ€è¦è‡ªå·±è´Ÿè´£ patch çš„ä¸Šä¸‹ padding éƒ¨åˆ†ã€‚\n__init__ï¼šæ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–æˆå‘˜å˜é‡ï¼Œè®¾ç½®æ˜¯å¦ä¸ºç¬¬ä¸€å±‚å·ç§¯ã€‚ naive_forwardï¼šæ‰§è¡Œæ ‡å‡†çš„å‰å‘ä¼ æ’­ï¼Œä¸è¿›è¡Œä»»ä½•åˆ‡ç‰‡æ“ä½œã€‚è¿™æ˜¯å•ä¸ªè®¾å¤‡å¤„ç†æ—¶çš„æ™®é€šå·ç§¯æ“ä½œã€‚ sliced_forwardï¼šå¤„ç†è¾“å…¥å¼ é‡çš„åˆ‡ç‰‡æ“ä½œã€‚æ ¹æ®å½“å‰è®¾å¤‡ç´¢å¼• (split_idx) è®¡ç®—è¾“å…¥å¼ é‡åœ¨é«˜åº¦æ–¹å‘çš„èµ·å§‹å’Œç»“æŸä½ç½®ï¼Œå¹¶åœ¨å¿…è¦æ—¶ä¸ºåˆ‡ç‰‡åçš„å¼ é‡æ·»åŠ  padding åè¿›è¡Œå·ç§¯æ“ä½œã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class DistriConv2dPP(BaseModule): def __init__(self, module: nn.Conv2d, distri_config: DistriConfig, is_first_layer: bool = False): super(DistriConv2dPP, self).__init__(module, distri_config) self.is_first_layer = is_first_layer def naive_forward(self, x: torch.Tensor) -\u0026gt; torch.Tensor: # x: [B, C, H, W] output = self.module(x) return output def sliced_forward(self, x: torch.Tensor) -\u0026gt; torch.Tensor: \u0026#39;\u0026#39;\u0026#39;...\u0026#39;\u0026#39;\u0026#39; def forward(self, x: torch.Tensor, *args, **kwargs) -\u0026gt; torch.Tensor: distri_config = self.distri_config # ç­‰å¾…ä¸Šä¸€æ­¥é€šä¿¡å®Œæˆ if self.comm_manager is not None and self.comm_manager.handles is not None and self.idx is not None: if self.comm_manager.handles[self.idx] is not None: self.comm_manager.handles[self.idx].wait() self.comm_manager.handles[self.idx] = None boundary_size = self.module.padding[0] if self.buffer_list is None: # buffer_list å­˜å‚¨çš„æ˜¯æ¯ä¸ª devive è¿›è¡Œå·ç§¯æ‰€éœ€è¦çš„å…¶ä»– devive çš„æ•°æ® if self.comm_manager.buffer_list is None: self.idx = self.comm_manager.register_tensor( shape=[2, x.shape[0], x.shape[1], boundary_size, x.shape[3]], torch_dtype=x.dtype, layer_type=\u0026#34;conv2d\u0026#34;, ) else: self.buffer_list = self.comm_manager.get_buffer_list(self.idx) def create_padded_x(): \u0026#39;\u0026#39;\u0026#39;æ‹¼æ¥æ¥æ”¶åˆ°çš„æ•°æ®\u0026#39;\u0026#39;\u0026#39; if distri_config.split_idx() == 0: # rank 0 concat_x = torch.cat([x, self.buffer_list[distri_config.split_idx() + 1][0]], dim=2) padded_x = F.pad(concat_x, [0, 0, boundary_size, 0], mode=\u0026#34;constant\u0026#34;) elif distri_config.split_idx() == distri_config.n_device_per_batch - 1: # rank n-1 concat_x = torch.cat([self.buffer_list[distri_config.split_idx() - 1][1], x], dim=2) padded_x = F.pad(concat_x, [0, 0, 0, boundary_size], mode=\u0026#34;constant\u0026#34;) else: # other ranks padded_x = torch.cat( [ self.buffer_list[distri_config.split_idx() - 1][1], x, self.buffer_list[distri_config.split_idx() + 1][0], ], dim=2, ) return padded_x # æå–å½“å‰è¾“å…¥å¼ é‡éœ€è¦å‘é€ç»™å…¶ä»–è®¾å¤‡çš„éƒ¨åˆ† boundary = torch.stack([x[:, :, :boundary_size, :], x[:, :, -boundary_size:, :]], dim=0) # ç›´æ¥ç”¨ä¸Šä¸€æ­¥çš„ buffer æ‹¼æ¥ padded_x = create_padded_x() output = F.conv2d( padded_x, self.module.weight, self.module.bias, stride=self.module.stride[0], padding=(0, self.module.padding[1]), ) if distri_config.mode != \u0026#34;no_sync\u0026#34;: self.comm_manager.enqueue(self.idx, boundary) # æ’å…¥è‡ªå·±è¦å‘é€çš„æ•°æ® self.counter += 1 return output DistriSelfAttentionPP DistriSelfAttentionPP åªè´Ÿè´£è®¡ç®—è‡ªå·± patch çš„è¾“å‡ºï¼Œéœ€è¦å®Œæ•´çš„ KVï¼Œå°† self attention è¿ç®—å˜æˆ cross-attention è®¡ç®—ã€‚éœ€è¦é€šä¿¡è‡ªå·±çš„ KV.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class DistriSelfAttentionPP(DistriAttentionPP): def __init__(self, module: Attention, distri_config: DistriConfig): super(DistriSelfAttentionPP, self).__init__(module, distri_config) def _forward(self, hidden_states: torch.FloatTensor, scale: float = 1.0): attn = self.module # è·å– Attention æ¨¡å— distri_config = self.distri_config residual = hidden_states # æ®‹å·®è¿æ¥ batch_size, sequence_length, _ = hidden_states.shape args = () if USE_PEFT_BACKEND else (scale,) query = attn.to_q(hidden_states, *args) # Q Projection encoder_hidden_states = hidden_states kv = self.to_kv(encoder_hidden_states) # KV Projection if self.buffer_list is None: # å¦‚æœç¼“å†²åŒºæœªåˆ›å»º full_kv = torch.cat([kv for _ in range(distri_config.n_device_per_batch)], dim=1) new_buffer_list = [buffer for buffer in self.buffer_list] new_buffer_list[distri_config.split_idx()] = kv full_kv = torch.cat(new_buffer_list, dim=1) if distri_config.mode != \u0026#34;no_sync\u0026#34;: self.comm_manager.enqueue(self.idx, kv) # å°† full_kv åˆ†å‰²ä¸º key å’Œ value key, value = torch.split(full_kv, full_kv.shape[-1] // 2, dim=-1) inner_dim = key.shape[-1] head_dim = inner_dim // attn.heads # multi-head attention query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2) key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2) value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2) hidden_states = F.scaled_dot_product_attention(query, key, value, dropout_p=0.0, is_causal=False) hidden_states = hidden_states.transpose(1, 2).reshape(batch_size, -1, attn.heads * head_dim) hidden_states = hidden_states.to(query.dtype) hidden_states = attn.to_out[0](hidden_states, *args) # O Projection hidden_states = attn.to_out[1](hidden_states) # Dropout if attn.residual_connection: hidden_states = hidden_states + residual hidden_states = hidden_states / attn.rescale_output_factor return hidden_states DistriGroupNorm DistriGroupNorm æ ¹æ®ä¸Šä¸€æ­¥å…¨ç‰¹å¾å›¾çš„ä»¥åŠå½“å‰æ­¥ patch çš„å‡å€¼å’ŒäºŒé˜¶çŸ©è¿‘ä¼¼å½“å‰æ­¥çš„å…¨ç‰¹å¾å›¾å‡å€¼å’Œæ–¹å·®ã€‚éœ€è¦é€šä¿¡ patch å‡å€¼å’ŒäºŒé˜¶çŸ©ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class DistriGroupNorm(BaseModule): def __init__(self, module: nn.GroupNorm, distri_config: DistriConfig): assert isinstance(module, nn.GroupNorm) super(DistriGroupNorm, self).__init__(module, distri_config) def forward(self, x: torch.Tensor) -\u0026gt; torch.Tensor: module = self.module distri_config = self.distri_config if self.comm_manager is not None and self.comm_manager.handles is not None and self.idx is not None: if self.comm_manager.handles[self.idx] is not None: self.comm_manager.handles[self.idx].wait() self.comm_manager.handles[self.idx] = None assert x.ndim == 4 n, c, h, w = x.shape num_groups = module.num_groups group_size = c // num_groups if self.buffer_list is None: if self.comm_manager.buffer_list is None: n, c, h, w = x.shape self.idx = self.comm_manager.register_tensor( # register for E[x], E[x^2] shape=[2, n, num_groups, 1, 1, 1], torch_dtype=x.dtype, layer_type=\u0026#34;gn\u0026#34; ) else: self.buffer_list = self.comm_manager.get_buffer_list(self.idx) x = x.view([n, num_groups, group_size, h, w]) # è®¡ç®— patch å‡å€¼å’ŒäºŒé˜¶çŸ© x_mean = x.mean(dim=[2, 3, 4], keepdim=True) # [1, num_groups, 1, 1, 1] x2_mean = (x**2).mean(dim=[2, 3, 4], keepdim=True) # [1, num_groups, 1, 1, 1] slice_mean = torch.stack([x_mean, x2_mean], dim=0) if self.buffer_list is None: full_mean = slice_mean else: # Equation 2 in the paper E[A_t] = E[A_(t+1)] + (E[A^i_t] - E[A^i_(t+1)]), same for E[A^2_t] correction = slice_mean - self.buffer_list[distri_config.split_idx()] full_mean = sum(self.buffer_list) / distri_config.n_device_per_batch + correction self.comm_manager.enqueue(self.idx, slice_mean) full_x_mean, full_x2_mean = full_mean[0], full_mean[1] var = full_x2_mean - full_x_mean**2 # è®¡ç®—æ–¹å·® slice_x_mean, slice_x2_mean = slice_mean[0], slice_mean[1] slice_var = slice_x2_mean - slice_x_mean**2 var = torch.where(var \u0026lt; 0, slice_var, var) # Correct negative variance num_elements = group_size * h * w var = var * (num_elements / (num_elements - 1)) std = (var + module.eps).sqrt() output = (x - full_x_mean) / std output = output.view([n, c, h, w]) # scale and shift if module.affine: output = output * module.weight.view([1, -1, 1, 1]) output = output + module.bias.view([1, -1, 1, 1]) self.counter += 1 return output ","permalink":"http://localhost:1313/blogs/distrifusion/","summary":"Paper reading about DistriFusion.","title":"DistriFusion"},{"content":"DeepSpeed-Ulysses Core Design System Design åŸç†å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå‡è®¾è®¾å¤‡æ•° P ç­‰äºå¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•° hc. è¾“å…¥ x[N,d] è¢«åˆ‡åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Š [N/p, d]ï¼Œä¹‹åè¿›è¡Œ QKV Projectionï¼Œéšåå°† K è¿›è¡Œè½¬ç½®åè¿›è¡Œä¸€æ¬¡ all-to-all é€šä¿¡ï¼Œè¿™æ ·æ¯ä¸ªè®¾å¤‡ä¸Šå°±æœ‰ Q[N, d/P], K[d/P, N], V[N, d/P], å†æ‰§è¡Œæ ‡å‡†çš„ attention è®¡ç®— $Outputcontext=Softmax((QK^T)/\\sqrt{d})V$. å†è¿›è¡Œä¸€æ¬¡ all-to-all é€šä¿¡ä½¿å¾—æ¯ä¸ªè®¾å¤‡ä¸Šæœ‰ [N, d/P] ç»“æœå†è¿›è¡Œåç»­æ“ä½œã€‚\nDeepSpeed Sequence Parallelism (DeepSpeed-Ulysses) Design\nCommunication Analysis åœ¨é‡‡ç”¨èŠ‚ç‚¹å†… NVSwitch äº’è¿å’ŒèŠ‚ç‚¹é—´ fat tree IB æ‹“æ‰‘çš„é›†ç¾¤ä¸­ï¼Œå¯¹äºæ€»æ¶ˆæ¯å¤§å°ä¸º M çš„ all-to-all é€šä¿¡ï¼Œæ¯æ¡é“¾è·¯é€šè¿‡ P ä¸ª gpu ä¼ è¾“çš„é€šä¿¡é‡ä¸º M/Pã€‚å¯¹äºéšè—å±‚å¤§å°ä¸º hã€åºåˆ—é•¿åº¦ä¸º Nã€å¹¶è¡Œåº¦ä¸º P çš„ transform æ¨¡å‹ï¼ŒDS-Sequence å¯¹æ³¨æ„åŠ›è®¡ç®—å‰æ€»æ¶ˆæ¯å¤§å°ä¸º 3Nh çš„ QKV Projection æ‰§è¡Œ all-to-all é€šä¿¡ï¼Œå¯¹æ¯ä¸ª transformer block çš„è¾“å‡ºæ‰§è¡Œ all-to-all é€šä¿¡ï¼Œå¤§å°ä¸º Nh. å› æ­¤ï¼ŒDeepSpeed åºåˆ—ä¸‹æ¯æ¡é“¾è·¯çš„æ€»é€šä¿¡é‡ä¸º 4Nh/P (æˆ–å¤æ‚åº¦ä¸º O(N/P)). ä¹Ÿå°±æ˜¯è¯´å½“ N å’Œ P æŒ‰æ¯”ä¾‹å¢åŠ æ—¶ï¼Œè¯¥é€šä¿¡é‡æ˜¯æ’å®šçš„ã€‚\nComparison of Other Works Comparison of DS-Ulysses to Other Sequence Parallelism Methods\nColAI-SP å‘æ˜äº† Ring-Attentionï¼ŒQ å­˜å‚¨åœ¨æœ¬åœ° è€Œ KV ä»¥ç¯å½¢æ–¹å¼ä¼ è¾“ä»¥è®¡ç®—å…¨å±€æ³¨æ„åŠ›ï¼Œå¯¼è‡´é€šä¿¡å¤æ‚åº¦ä¸æ¶ˆæ¯å¤§å° M å‘ˆçº¿æ€§å…³ç³»ã€‚ Megatron-LM åºåˆ—å¹¶è¡Œæ–¹æ³•ä¸ Megatron å¼ é‡å¹¶è¡Œç´§å¯†é›†æˆã€‚Megatron-LM æ²¿ç€åºåˆ—ç»´åº¦åˆ’åˆ†åºåˆ—ï¼Œå¹¶åº”ç”¨ all gather å’Œ reduce scatter æ¥èšåˆ QKV æ³¨æ„åŠ›è®¡ç®—çš„æŠ•å½±ã€‚å¹¶è¡Œé€šä¿¡é‡éšæ¶ˆæ¯å¤§å° M çº¿æ€§å¢åŠ ã€‚ DeepSpeed-Ulysses é€šè¿‡å¢åŠ ä¸åºåˆ—é•¿åº¦æˆæ¯”ä¾‹çš„è®¾å¤‡æ•°æ¥ä¿æŒé€šä¿¡é‡æ’å®šã€‚åŒæ—¶å°† Zero3 æ‰©å±•åˆ°æ•°æ®å¹¶è¡Œå’Œåºåˆ—å¹¶è¡Œçš„ç»„åˆã€‚ZeRO è·¨åºåˆ—å’Œæ•°æ®å¹¶è¡Œç»„åˆ’åˆ†æ¨¡å‹çŠ¶æ€ï¼Œå¹¶åœ¨éœ€è¦æ—¶ä½¿ç”¨ allgather æ”¶é›†æ¯ä¸ª rank çš„éƒ¨åˆ†ã€‚ General and Attention Agnostic Solution DeepSpeed-Ulysses çš„ä¼˜åŠ¿åœ¨äºä¸€ç§ä»¥æ³¨æ„åŠ›ä¸ºä¸­å¿ƒçš„åºåˆ—å¹¶è¡Œè®¾è®¡ã€‚åœ¨æ³¨æ„åŠ›è®¡ç®—æ˜¯ N/P åˆ’åˆ†çš„åºåˆ—å¹¶è¡Œä¹‹å‰ï¼Œæ³¨æ„åŠ›è®¡ç®—æ˜¯å¤´å¹¶è¡Œï¼Œæ¯ä¸ªå¤´çš„æ³¨æ„åŠ›éƒ½æ˜¯å®Œæ•´çš„ï¼Œä½†åªæœ‰è¾ƒå°‘çš„å¤´ï¼Œå› æ­¤æ³¨æ„åŠ›è®¡ç®—å¯ä»¥è¢«ä»»ä½•ç±»å‹çš„æ³¨æ„æœºåˆ¶æ‰€å–ä»£ï¼Œä¾‹å¦‚ dense attention å’Œå„ç§å½¢å¼çš„ sparse attention.\n","permalink":"http://localhost:1313/blogs/deepspeedulysses/","summary":"Paper reading of Deepseed Ulysses.","title":"DeepSpeedUlysses"},{"content":"Abstract æœ¬æ–‡å±•ç¤ºäº†å¦‚ä½•å°†å¼ é‡ã€æµæ°´çº¿å’Œæ•°æ®å¹¶è¡Œæ€§ç»„åˆèµ·æ¥ä»¥æ‰©å±•åˆ°æ•°åƒä¸ªgpuã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„äº¤é”™æµæ°´çº¿è°ƒåº¦ï¼Œå¯ä»¥åœ¨å†…å­˜å ç”¨ä¸ç°æœ‰æ–¹æ³•ç›¸å½“çš„åŒæ—¶å°†ååé‡æé«˜ 10%.\nTrend of Sizes of SOTA NLP Models\nIntroduction å¼ é‡ï¼ˆå±‚å†…ï¼‰æ¨¡å‹å¹¶è¡Œå¯¹äºè¾ƒå¤§çš„æ¨¡å‹ä¼šå´©æºƒã€‚è¾ƒå¤§çš„æ¨¡å‹åœ¨å¤šä¸ªå¤š GPU æœåŠ¡å™¨ä¸Šè¿›è¡Œåˆ‡åˆ†ä¼šå¯¼è‡´ä¸¤ä¸ªé—®é¢˜ï¼š\nå¼ é‡å¹¶è¡Œæ‰€éœ€çš„ all-reduce é€šä¿¡éœ€è¦é€šè¿‡æœåŠ¡å™¨é—´é“¾è·¯è¿›è¡Œï¼Œè¿™æ¯”å¤š GPU æœåŠ¡å™¨å†…å¯ç”¨çš„é«˜å¸¦å®½ NVLink è¦æ…¢ é«˜åº¦æ¨¡å‹å¹¶è¡Œä¼šäº§ç”Ÿå°è§„æ¨¡çš„çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ï¼Œä»è€Œå¯èƒ½é™ä½ GPU åˆ©ç”¨ç‡ã€‚ æµæ°´çº¿æ¨¡å‹å¹¶è¡ŒåŒ–æ˜¯æŒ‡æ¨¡å‹çš„å„å±‚åœ¨å¤šä¸ª GPU ä¸Šè¿›è¡Œæ¡å¸¦åŒ–å¤„ç†ã€‚batch è¢«æ‹†åˆ†æˆæ›´å°çš„ microbatch ï¼Œå¹¶åœ¨è¿™äº› microbatch ä¹‹é—´æµæ°´çº¿æ‰§è¡Œã€‚æ— è®ºè¿›åº¦å¦‚ä½•ï¼Œä¸ºäº†ä¿æŒä¸¥æ ¼çš„ä¼˜åŒ–å™¨è¯­ä¹‰ï¼Œä¼˜åŒ–å™¨æ­¥éª¤éœ€è¦è·¨è®¾å¤‡åŒæ­¥ï¼Œä»è€Œåœ¨æ¯ä¸ª batch ç»“æŸæ—¶è¿›è¡Œæµæ°´çº¿åˆ·æ–° (pipeline flush)ï¼Œå…è®¸ microbatch å®Œæˆæ‰§è¡Œ (ä¸å†æ³¨å…¥æ–°çš„ microbatch). microbatch æ•°é‡ä¸æµæ°´çº¿çº§æ•°çš„æ¯”ä¾‹è¶Šå¤§ï¼Œæµæ°´çº¿åˆ·æ–°æ‰€èŠ±è´¹çš„æ—¶é—´å°±è¶Šå°‘ã€‚\næˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ç»“åˆæµæ°´çº¿ã€å¼ é‡å’Œæ•°æ®å¹¶è¡Œæ€§ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºPTD-P. é…ç½®åˆ†å¸ƒå¼è®­ç»ƒçš„æŒ‡å¯¼åŸåˆ™å¦‚ä¸‹:\nä¸åŒå½¢å¼çš„å¹¶è¡Œæ€§ä»¥ä¸åŒçš„æ–¹å¼ç›¸äº’ä½œç”¨: å¹¶è¡Œç­–ç•¥å¯¹é€šä¿¡é‡ã€æ‰§è¡Œå†…æ ¸çš„è®¡ç®—æ•ˆç‡ä»¥åŠç”±äºæµæ°´çº¿å†²æ´— (æµæ°´çº¿æ°”æ³¡) è€ŒèŠ±è´¹çš„ç­‰å¾…è®¡ç®—çš„ç©ºé—²æ—¶é—´æœ‰å½±å“ã€‚ ç”¨äºæµæ°´çº¿å¹¶è¡Œæ€§çš„è°ƒåº¦å¯¹é€šä¿¡é‡ã€æµæ°´çº¿æ°”æ³¡å¤§å°å’Œç”¨äºå­˜å‚¨æ¿€æ´»çš„å†…å­˜æœ‰å½±å“ã€‚ è¶…å‚æ•° (å¦‚ microbatch å¤§å°) çš„å€¼ä¼šå½±å“å†…å­˜å ç”¨ã€åœ¨å·¥ä½œçº¿ç¨‹ä¸Šæ‰§è¡Œçš„å†…æ ¸çš„ç®—æœ¯æ•ˆç‡å’Œæµæ°´çº¿æ°”æ³¡å¤§å°ã€‚ éšç€è§„æ¨¡æ‰©å±•åˆ†å¸ƒå¼è®­ç»ƒæ˜¯é€šä¿¡å¯†é›†å‹çš„ã€‚ä½¿ç”¨è¾ƒæ…¢çš„èŠ‚ç‚¹é—´äº’è¿æˆ–æ›´å¯†é›†çš„é€šä¿¡åˆ†åŒºä¼šå½±å“æ‰©å±•æ€§èƒ½ã€‚ Model Parallelism æœ¬èŠ‚ä¸­å°†è®¨è®ºæœ‰åŠ©äºä¸é€‚åˆå•ä¸ª GPU å†…å­˜çš„å¤§æ¨¡å‹çš„å¹¶è¡Œè®­ç»ƒæ–¹æ³•ã€‚æˆ‘ä»¬å°†æµæ°´çº¿æ¨¡å‹å¹¶è¡Œå’Œå¼ é‡æ¨¡å‹å¹¶è¡Œ (å¦‚å›¾ 2 æ‰€ç¤ºçš„ç»„åˆ) ä¸æ•°æ®å¹¶è¡Œç»“åˆèµ·æ¥ï¼Œç®€ç§°ä¸ºPTD-P.\nCombination of Tensor and Pipeline Model Parallelism (MP)\nData Parallelism ä½¿ç”¨æ•°æ®å¹¶è¡Œæ—¶ï¼Œæ¯ä¸ª worker éƒ½æœ‰ä¸€ä¸ªå®Œæ•´æ¨¡å‹çš„å‰¯æœ¬ï¼Œè¾“å…¥æ•°æ®é›†è¢«åˆ†ç‰‡ï¼Œ worker å®šæœŸæ±‡æ€»ä»–ä»¬çš„æ¢¯åº¦ï¼Œä»¥ç¡®ä¿æ‰€æœ‰ worker çœ‹åˆ°ä¸€ä¸ªä¸€è‡´çš„æƒé‡ç‰ˆæœ¬ã€‚\nPipeline Parallelism é€šè¿‡æµæ°´çº¿å¹¶è¡Œï¼Œæ¨¡å‹çš„å±‚è¢«åˆ†æ•£åˆ°å¤šä¸ªè®¾å¤‡ä¸Šã€‚ä¸€ä¸ª batch è¢«åˆ†æˆæ›´å°çš„ microbatch. åœ¨ microbatch ä¹‹é—´è¿›è¡Œæµæ°´çº¿æ‰§è¡Œã€‚ä¸ºäº†å‡†ç¡®åœ°ä¿æŒä¼˜åŒ–å™¨è¯­ä¹‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†å®šæœŸçš„æµæ°´çº¿åˆ·æ–°ï¼Œä»¥ä¾¿åœ¨è®¾å¤‡ä¹‹é—´åŒæ­¥ä¼˜åŒ–å™¨æ­¥éª¤ã€‚åœ¨æ¯ä¸ª batch å¤„ç†çš„å¼€å§‹å’Œç»“æŸæ—¶ï¼Œè®¾å¤‡éƒ½æ˜¯ç©ºé—²çš„ã€‚æˆ‘ä»¬ç§°è¿™æ®µç©ºé—²æ—¶é—´ä¸ºæµæ°´çº¿æ°”æ³¡ (pipeline bubble).\nDefault Schedule GPipe æå‡ºäº†ä¸€ä¸ªè°ƒåº¦æ–¹æ¡ˆï¼Œå¦‚å›¾ 3 æ‰€ç¤º (å‡è®¾åå‘ä¼ æ’­çš„æ—¶é—´æ˜¯å‰å‘ä¼ æ’­çš„ä¸¤å€ï¼Œç®¡é“è°ƒåº¦çš„æ•ˆç‡å¹¶ä¸å–å†³äºè¿™ä¸ªå› ç´ )ï¼Œé¦–å…ˆæ‰§è¡Œä¸€ä¸ª batch ä¸­æ‰€æœ‰ microbatch çš„å‰å‘ä¼ æ’­ï¼Œç„¶åæ‰§è¡Œæ‰€æœ‰ microbatch çš„åå‘ä¼ æ’­ã€‚è®¾ GPipe æµæ°´çº¿æ°”æ³¡çš„å¤§å°ä¸º t_pbï¼Œmicrobatch çš„æ•°é‡ä¸º mï¼Œæµæ°´çº¿é˜¶æ®µæ•°é‡ (ç”¨äºæµæ°´çº¿å¹¶è¡Œçš„è®¾å¤‡æ•°é‡) è¡¨ç¤ºä¸º pï¼Œæ¯æ¬¡è¿­ä»£çš„ç†æƒ³æ—¶é—´è¡¨ç¤ºä¸º t_id (å‡è®¾ç†æƒ³ç¼©æ”¾)ï¼Œæ‰§è¡Œå•ä¸ª microbatch çš„å‘å‰å’Œåå‘ä¼ æ’­çš„æ—¶é—´è¡¨ç¤ºä¸º t_f å’Œ t_b. åœ¨è¯¥è°ƒåº¦ä¸­ï¼Œæµæ°´çº¿æ°”æ³¡ç”±æ‰¹å¤„ç†å¼€å§‹æ—¶çš„ pâˆ’1 ä¸ªå‰å‘ä¼ æ’­å’Œ pâˆ’1 ä¸ªåå‘ä¼ æ’­ç»„æˆã€‚åˆ™æµæ°´çº¿æ°”æ³¡æ€»æ—¶é—´ä¸º t_pb=(pâˆ’1)Â·(t_f+t_b). batch çš„ç†æƒ³æ‰§è¡Œæ—¶é—´ä¸º t_id=mÂ·(t_f+t_b)ã€‚å› æ­¤ï¼Œåœ¨æµæ°´çº¿æ°”æ³¡ä¸­èŠ±è´¹ä¸ç†æƒ³è®¡ç®—æ—¶é—´çš„æ¯”ä¾‹ä¸º:\næµæ°´çº¿æ°”æ³¡å æ¯” = t_pb / t_id = (pâˆ’1) / m.\nä¸ºäº†ä½¿æµæ°´çº¿æ°”æ³¡å æ¯”å°ï¼Œæˆ‘ä»¬éœ€è¦ m è¿œå¤§äº p. ç„¶è€Œ m éå¸¸å¤§æ—¶è¿™ç§æ–¹æ³•çš„å†…å­˜å ç”¨å¾ˆé«˜ï¼Œå› ä¸ºå®ƒéœ€è¦åœ¨è®­ç»ƒä¸€æ¬¡è¿­ä»£æ—¶é—´å†…ä¸ºæ‰€æœ‰ m ä¸ª microbatch ä¿å­˜ä¸­é—´æ¿€æ´».\nGPipe Pipeline Schedule\nSchedule with Interleaved Stages ä¸ºäº†ç¼©å°æµæ°´çº¿æ°”æ³¡çš„å¤§å°ï¼Œæ¯ä¸ªè®¾å¤‡éƒ½å¯ä»¥å¯¹å¤šä¸ªå±‚çš„å­é›†ï¼ˆç§°ä¸ºæ¨¡å‹å—ï¼‰è¿›è¡Œè®¡ç®—ï¼Œæµæ°´çº¿ä¸­çš„æ¯ä¸ªè®¾å¤‡éƒ½è¢«åˆ†é…äº†å¤šä¸ªæµæ°´çº¿é˜¶æ®µï¼ˆä¸ä¹‹å‰ç›¸æ¯”ï¼Œæ¯ä¸ªæµæ°´çº¿é˜¶æ®µçš„è®¡ç®—é‡æ›´å°‘ï¼‰ï¼Œè€Œä¸æ˜¯å•ä¸ªè¿ç»­çš„å±‚ã€‚\nAn Example ä¾‹å¦‚ï¼Œå¦‚æœæ¯ä¸ªè®¾å¤‡ä¹‹å‰è¢«åˆ†é… 4 å±‚ (å³è®¾å¤‡ 1 æœ‰ 1 - 4 å±‚ï¼Œè®¾å¤‡ 2 æœ‰ 5 - 8å±‚\u0026hellip;)ï¼Œæˆ‘ä»¬å¯ä»¥è®©æ¯ä¸ªè®¾å¤‡ä¸ºä¸¤ä¸ªæ¨¡å‹å—æ‰§è¡Œè®¡ç®— (æ¯ä¸ªæ¨¡å‹å—è¢«åˆ†é… 2 å±‚)ï¼Œå³è®¾å¤‡ 1 æœ‰ 1ã€2ã€9ã€10 å±‚; è®¾å¤‡ 2 å…·æœ‰ç¬¬3ã€4ã€11ã€12å±‚\u0026hellip; å’Œä¸Šä¸€å°èŠ‚ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œå®Œæ‰€æœ‰ microbatch çš„å‰å‘ä¼ æ’­ç„¶åæ‰§è¡Œæ‰€æœ‰åå‘ä¼ æ’­ (all-forward, all-backward)ï¼Œä½†è¿™å°†å ç”¨å¤§é‡å†…å­˜ (ä¸ m æˆæ­£æ¯”). å› æ­¤å¦‚å›¾ 4 æ‰€ç¤ºï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé€‚é…äºä¹‹å‰çš„å†…å­˜é«˜æ•ˆ 1F1B çš„äº¤é”™è°ƒåº¦ã€‚å®ƒè¦æ±‚ microbatch æ•°é‡æ˜¯æµæ°´çº¿å¹¶è¡Œåº¦ (æµæ°´çº¿ä¸­çš„è®¾å¤‡æ•°é‡) çš„æ•´æ•°å€ã€‚\nå¦‚æœæ¯ä¸ªè®¾å¤‡éƒ½æœ‰ v ä¸ªé˜¶æ®µ (æ¨¡å‹å—)ï¼Œé‚£ä¹ˆæ¯ä¸ªé˜¶æ®µ microbatch çš„å‰å‘å’Œåå‘ä¼ æ’­çš„æ—¶é—´åˆ†åˆ«ä¸º t_f/v å’Œ t_b/v. æµæ°´çº¿æ°”æ³¡æ—¶é—´å› æ­¤å‡å°‘åˆ° ğ‘¡^int_pb=(pâˆ’1)Â·(tf+tb)/vï¼Œ\næµæ°´çº¿æ°”æ³¡å æ¯”ä¸º ğ‘¡^int_pb / t_id = (pâˆ’1) / (mÂ·v).\nè¿™æ„å‘³ç€è¯¥è°ƒåº¦å‡å°‘æ°”æ³¡æ—¶é—´åˆ°åŸå…ˆçš„ 1/vï¼Œä½†è¯¥è®¡åˆ’éœ€è¦é¢å¤–çš„é€šä¿¡ï¼Œå› æ­¤é€šä¿¡é‡ä¹Ÿä¸ºåŸæ¥çš„ v å€ã€‚\nDefault and Interleaved 1F1B Pipeline Schedules\nTensor Model Parallelism è¯¦æƒ…è§ Megatron-LM.\nBlocks of Transformer Model Partitioned with Tensor Model Parallelsim\nPerformance Analysis of Parallelization Configurations é¦–å…ˆå®šä¹‰ä¸‹ç¬¦å·å«ä¹‰\n(p,t,d): å¹¶è¡ŒåŒ–ç»´åº¦ã€‚p è¡¨ç¤ºæµæ°´çº¿æ¨¡å‹å¹¶è¡Œå¤§å°ï¼Œt è¡¨ç¤ºå¼ é‡æ¨¡å‹å¹¶è¡Œå¤§å°ï¼Œd è¡¨ç¤ºæ•°æ®å¹¶è¡Œå¤§å°ã€‚ n: GPU æ•°é‡ï¼Œè¦æ±‚ ptd=n. B: å…¨å±€æ‰¹å¤§å° (ä½œä¸ºè¾“å…¥æä¾›) b: microbatch å¤§å°ã€‚ m = B/(db): ä¸€ä¸ª batch ä¸­æ¯ä¸ªæµæ°´çº¿ä¸­çš„ microbatch çš„æ•°é‡ã€‚ Tensor and Pipeline Model Parallelism å¦‚å‰æ‰€è¿°ï¼Œä½¿ç”¨å¸¦æœ‰å‘¨æœŸæ€§å†²æ´—çš„æµæ°´çº¿å¹¶è¡Œä¼šäº§ç”Ÿå¤§å°ä¸º (pâˆ’1)/m çš„æµæ°´çº¿æ°”æ³¡. å›ºå®š d=1ï¼Œåˆ™ tp=nï¼Œæ°”æ³¡å¤§å°å¯ä»¥ç”¨ t è¡¨ç¤ºä¸º\n(pâˆ’1)/m=(n/t-1)/m.\nGPU ä¹‹é—´çš„é€šä¿¡é‡ä¹Ÿå— p å’Œ t å¤§å°çš„å½±å“ã€‚æµæ°´çº¿æ¨¡å‹å¹¶è¡Œçš„ç‰¹ç‚¹æ˜¯æ›´ä¾¿å®œçš„ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œæ¯ä¸ª microbatch çš„æ¯å¯¹è¿ç»­è®¾å¤‡ä¹‹é—´ (å‰å‘æˆ–åå‘ä¼ é€’) éœ€è¦æ‰§è¡Œçš„é€šä¿¡æ€»é‡ä¸º bsh. å¼ é‡æ¨¡å‹å¹¶è¡Œåˆ™ä½¿ç”¨ all-reduce é€šä¿¡ï¼Œæ€»å¤§å°ä¸º bsh çš„å¼ é‡éœ€è¦åœ¨æ¯å±‚çš„å‰å‘å’Œåå‘ä¼ é€’ä¸­ï¼Œåœ¨ t ä¸ªæ¨¡å‹å‰¯æœ¬ä¹‹é—´è¿›è¡Œä¸¤æ¬¡ all-reduceï¼Œå› æ­¤æ¯ä¸ª microbatch æ¯å±‚æ¯ä¸ªè®¾å¤‡çš„æ€»é€šä¿¡é‡ä¸º 4bsh(t-1)/t. æ¯ä¸ªè®¾å¤‡é€šå¸¸æœ‰å¤šä¸ªå±‚ï¼Œåˆ™æ¯ä¸ªè®¾å¤‡ä¸Šæ¯ä¸ª microbatch çš„å¼ é‡å¹¶è¡Œé€šä¿¡æ€»é‡ä¸º l^stage4bsh(t-1)/t, å…¶ä¸­ l^stage ä¸ºæµæ°´çº¿é˜¶æ®µçš„å±‚æ•°ã€‚\nTip\nå¯ç¤º 1: å½“ t å¤§äºå•ä¸ªèŠ‚ç‚¹ä¸­çš„ GPU æ•°é‡æ—¶ï¼Œåœ¨è¾ƒæ…¢çš„èŠ‚ç‚¹é—´é“¾è·¯ä¸Šæ‰§è¡Œå¼ é‡æ¨¡å‹å¹¶è¡Œçš„å¼€é”€éå¸¸å¤§ã€‚åœ¨è€ƒè™‘ä¸åŒå½¢å¼çš„æ¨¡å‹å¹¶è¡Œæ—¶ï¼Œä½¿ç”¨ g-GPU æœåŠ¡å™¨æ—¶å¼ é‡æ¨¡å‹å¹¶è¡Œåº¦ä¸€èˆ¬ä¸º g (all-reduce é€šä¿¡é‡å¤§ï¼ŒNVLink å¸¦å®½é«˜)ï¼Œç„¶åå¯ä»¥ä½¿ç”¨æµæ°´çº¿æ¨¡å‹å¹¶è¡Œæ¥æ‰©å±•åˆ°è·¨æœåŠ¡å™¨çš„æ›´å¤§æ¨¡å‹ (P2P é€šä¿¡é‡å°ï¼ŒPCIe å¸¦å®½ä½).\nData and Model Parallelism ç®¡é“æ¨¡å‹å¹¶è¡Œæ€§ã€‚è®¾ t=1ï¼Œæ¯ä¸ªç®¡é“çš„ microbatches æ•°é‡ m=ğµ/(db)=b\u0026rsquo;/d, b\u0026rsquo;:=B/b. è®¾ GPU æ€»æ•°ä¸º n ï¼Œæµæ°´çº¿é˜¶æ®µæ•°ä¸º p=n/dï¼Œæ°”æ³¡å¤§å°ä¸º\n(pâˆ’1)/m=(n/d-1)/(b\u0026rsquo;/d)=(n-d)/b'\nç®¡é“æ°”æ³¡éšç€ d å˜å¤§è€Œå˜å°ã€‚å¦‚æœæ•°æ®å¹¶è¡Œæ‰€éœ€çš„ all-reduce é€šä¿¡ä¸ä¼šéšç€ d çš„å˜å¤§è€Œæ€¥å‰§å¢åŠ ï¼Œé‚£ä¹ˆæ€»ä½“ååé‡å°†ä¼šå¢åŠ ï¼Œå› ä¸ºåŸºäºç¯çš„å®ç°çš„é€šä¿¡æ—¶é—´éšç€ d çš„å˜åŒ–ä¸º (dâˆ’1)/d=1âˆ’1/d.åŒæ ·å¯¹äºç»™å®šçš„å¹¶è¡Œé…ç½®ï¼Œéšç€æ‰¹é‡å¤§å°çš„å¢åŠ ï¼Œb\u0026rsquo; = B/b å¢åŠ ï¼Œå› æ­¤ååé‡ä¸Šå‡ã€‚åŒæ—¶æ•°æ®å¹¶è¡Œæ‰€éœ€çš„ all-reduce é€šä¿¡é¢‘ç‡ä¹Ÿä¸‹é™ï¼Œè¿›ä¸€æ­¥æé«˜äº†ååé‡ã€‚\nFraction of Time Spent Idling due to Pipeline Flush\nåœ¨å¼ é‡æ¨¡å‹å¹¶è¡Œä¸‹ï¼Œæ¯ä¸ª microbatch éƒ½éœ€è¦è¿›è¡Œ all-reduce é€šä¿¡ï¼Œè¿™åœ¨å¤š GPU æœåŠ¡å™¨ä¸Šå¼€é”€å¾ˆå¤§ï¼›è€Œæ•°æ®å¹¶è¡Œåªéœ€è¦åœ¨æ¯ä¸ª batch ä¸­æ‰§è¡Œä¸€æ¬¡çš„ all-reduceé€šä¿¡ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¼ é‡æ¨¡å‹å¹¶è¡Œï¼Œæ¯ä¸ªè®¾å¤‡è®¡ç®—æ¯å±‚çš„ä¸€éƒ¨åˆ†ï¼Œå› æ­¤å¯¹äºä¸å¤Ÿå¤§çš„å±‚ï¼Œ GPU å¯èƒ½æ— æ³•ä»¥å³°å€¼æ•ˆç‡æ‰§è¡Œè¿™äº›å­çŸ©é˜µè®¡ç®—ã€‚\nTip\nå¯ç¤º 2ï¼šåœ¨ä½¿ç”¨æ•°æ®å’Œæ¨¡å‹å¹¶è¡Œæ—¶ï¼Œåº”ä½¿ç”¨ M=tp çš„æ€»æ¨¡å‹å¹¶è¡Œå¤§å°ï¼Œä»¥ä¾¿æ¨¡å‹å‚æ•°å’Œä¸­é—´æ•°æ®æ»¡è¶³ GPU å†…å­˜é™åˆ¶ï¼›æ•°æ®å¹¶è¡Œå¯ç”¨äºå°†è®­ç»ƒæ‰©å±•åˆ°æ›´å¤š GPU.\nMicrobatch Size ç»™å®šå‡½æ•° t_f(b) å’Œ t_b(b)ï¼Œå°† microbatch å¤§å°æ˜ å°„ä¸ºå•ä¸ª microbatch çš„å‰å‘å’Œåå‘è®¡ç®—æ—¶é—´ï¼Œè®¡ç®—ä¸€ä¸ª batch æ‰€èŠ±è´¹çš„æ€»æ—¶é—´ (å¿½ç•¥é€šä¿¡æˆæœ¬) ä¸º\n(b\u0026rsquo;/b+p-1)Â·(t_f(b)+t_b(b)).\nmicrobatch å¤§å°å› æ­¤æ—¢å½±å“è¿ç®—çš„ç®—æœ¯å¼ºåº¦ï¼Œä¹Ÿå½±å“ç®¡é“æ°”æ³¡å¤§å°ã€‚\nPer-GPU Throughput versus Microbatch Size for a GPT Model\nBehavior of Throughput for the same GPT Model\nTip\nå¯ç¤º 3ï¼šæœ€ä½³ microbatch å¤§å° b å–å†³äºæ¨¡å‹çš„ååé‡å’Œå†…å­˜å ç”¨ç‰¹å¾ï¼Œä»¥åŠæµæ°´çº¿æ·±åº¦ pã€æ•°æ®å¹¶è¡Œå¤§å° d å’Œæ‰¹é‡å¤§å° B.\nActivation Recomputation æ¿€æ´»é‡è®¡ç®—é€šè¿‡åœ¨å‘åä¼ é€’ä¹‹å‰è¿è¡Œç¬¬äºŒæ¬¡æ­£å‘ä¼ æ’­ (å¹¶ä¸”ä»…å­˜å‚¨ç»™å®šæµæ°´çº¿é˜¶æ®µçš„è¾“å…¥æ¿€æ´»)ï¼Œæ¥æƒè¡¡æ‰€æ‰§è¡Œçš„è®¡ç®—æ“ä½œæ•°é‡çš„å¢åŠ å¯¹é¢å¤–å†…å­˜å ç”¨çš„å½±å“ã€‚è®¾ A^input ä¸ºä¸€å±‚çš„è¾“å…¥æ¿€æ´»çš„å¤§å°ï¼ŒA^intermediate ä¸ºæ¯å±‚çš„ä¸­é—´æ¿€æ´»çš„å¤§å°ï¼Œä¸€ä¸ªæ¨¡å‹é˜¶æ®µæœ‰ l å±‚ï¼Œ æ¿€æ´»ä¿å­˜ç‚¹çš„æ•°é‡ä¸º cï¼Œé‚£ä¹ˆæ€»å†…å­˜å ç”¨ä¸º cÂ·A^input + l/cÂ·A^intermediate. å› æ­¤å– c = \\sqrt(lÂ·A^inputÂ·A^intermediate) æ—¶å†…å­˜å ç”¨æœ€å°ã€‚\nImplementation Communication Optimizations ä½¿ç”¨æµæ°´çº¿å¹¶è¡Œæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨æ­£å‘å’Œåå‘å¹¶è¡Œå‘é€å’Œæ¥æ”¶å¼ é‡ã€‚æ¯å° DGX A100 éƒ½é…å¤‡äº† 8 ä¸ª InfiniBandï¼ˆIBï¼‰ç½‘å¡ã€‚ç„¶è€Œå‘é€å’Œæ¥æ”¶éƒ½æ˜¯ç‚¹å¯¹ç‚¹çš„ï¼Œåªå‘ç”Ÿåœ¨ä¸¤å°æœåŠ¡å™¨ä¸Šçš„ä¸€å¯¹ GPU ä¹‹é—´ï¼Œå› æ­¤å¾ˆéš¾å……åˆ†åˆ©ç”¨æ‰€æœ‰ç½‘å¡ã€‚å¯¹äºæµæ°´çº¿å†…çš„å•æ¬¡é€šä¿¡ï¼Œæ¯ä¸ª transformer å±‚çš„è¾“å‡ºéƒ½ä¼šåœ¨å¼ é‡å¹¶è¡Œçš„è®¾å¤‡ä¸­å¤åˆ¶ã€‚ä¸ºäº†å‡å°‘è¿™ç§å†—ä½™ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å‘é€ç«¯å°†å¼ é‡åˆ†å‰²æˆå¤§å°ç›¸ç­‰çš„å—ï¼Œç„¶åä½¿ç”¨æ¯ä¸ª rank è‡ªå·±çš„ InfiniBand å‘é€. åœ¨æ¥æ”¶ç«¯é€šè¿‡æ¯” InfiniBand äº’è¿å¿«å¾—å¤šçš„ NVLink æ‰§è¡Œ all-gatherï¼Œé‡æ–°ç»„è£…æ•´ä¸ªå¼ é‡ã€‚é€šè¿‡ scatter-gather é€šä¿¡ä¼˜åŒ–ï¼Œå°†æ¯å¯¹è¿ç»­æµæ°´çº¿é˜¶æ®µä¹‹é—´éœ€è¦æ‰§è¡Œçš„é€šä¿¡æ€»é‡å‡å°‘ä¸º bsh/t.\nComputation Optimizations å°†æ•°æ®å¸ƒå±€ä» (b,s,a,h) æ›´æ”¹ä¸º (s,b,a,h). å…¶æ¬¡ï¼Œä½¿ç”¨ PyTorch JIT ä¸ºä¸€ç³»åˆ—å…ƒç´ æ“ä½œ (bias+GeLU å’Œ bias+dropout+add) ç”Ÿæˆèåˆç®—å­ã€‚\nEvaluation åœ¨ Selene è¶…çº§è®¡ç®—æœºä¸Šä»¥æ··åˆç²¾åº¦è¿è¡Œã€‚æ¯ä¸ªé›†ç¾¤èŠ‚ç‚¹æœ‰\n8 ä¸ª NVIDIA 80GB A100 GPUï¼Œé€šè¿‡ NVLink å’Œ NVSwitch äº’è¿ã€‚ 8 ä¸ª NVIDIA Mellanox 200Gbps HDR Infiniband HCA ç”¨äºåº”ç”¨ç¨‹åºé€šä¿¡ é¢å¤–æœ‰ 2 ä¸ª HCA ç”¨äºä¸“ç”¨å­˜å‚¨ã€‚ èŠ‚ç‚¹ä»¥ä¸‰çº§ (leaf, spine, core) èƒ–æ ‘æ‹“æ‰‘ç»“æ„è¿æ¥ï¼Œä¸€å…±æœ‰ 850ä¸ªäº¤æ¢æœºã€‚é›†ç¾¤ä½¿ç”¨ all-NVME å…±äº«å¹¶è¡Œæ–‡ä»¶ç³»ç»Ÿè¿›è¡Œé«˜æ€§èƒ½æ•°æ®è®¿é—®å’Œå­˜å‚¨ã€‚16 ä½ç²¾åº¦çš„ A100 GPU çš„å³°å€¼è®¾å¤‡ååé‡ä¸º 312 teraFLOP/s. QKV å˜æ¢çš„çº¿æ€§å±‚æƒé‡å‚æ•°é‡å‡ä¸º h^2, attention åçš„çº¿æ€§å±‚æƒé‡å‚æ•°é‡ä¸º h^2, ä¸¤å±‚å‰é¦ˆç½‘ç»œæ¯ä¸ªçº¿æ€§å±‚çš„æƒé‡å‚æ•°é‡ä¸º 4h^2ï¼Œå› æ­¤æ¯ä¸€ä¸ª transformer block çš„æ‰€æœ‰çº¿æ€§å±‚çš„å‚æ•°é‡ä¸º 12h^2. è¯åµŒå…¥çš„å‚æ•°é‡ä¸º Vhï¼Œä½ç½®ç¼–ç çš„å‚æ•°é‡ä¸º sh.\nä¸€ä¸ª $A_{m\\times k}\\times X_{k\\times n}$ çŸ©é˜µä¹˜æ³•éœ€è¦ 2mkn FLOPs( 2 æ˜¯å› ä¸ºä¹˜æ³•å’ŒåŠ æ³•). transformer block åŒ…å«ä¸€ä¸ªæ³¨æ„åŠ›å—å’Œä¸€ä¸ªä¸¤å±‚å‰é¦ˆç½‘ç»œç»„æˆã€‚å¯¹äºæ³¨æ„åŠ›å—ï¼Œä¸»è¦çš„ FLOP æ¥æºäº QKV è½¬æ¢ (6Bsh^2 æ¬¡æ“ä½œ)ã€æ³¨æ„åŠ›çŸ©é˜µè®¡ç®— (2Bhs^2 æ¬¡æ“ä½œ)ã€æ³¨æ„åŠ›ä¹˜ Value (2Bhs^2 æ¬¡æ“ä½œ) å’Œ attention åçš„çº¿æ€§å±‚ (2Bsh^2 æ¬¡æ“ä½œ). å‰é¦ˆç½‘ç»œå°†éšè—ç»´åº¦æ”¾å¤§åˆ° 4hï¼Œç„¶åå†å‡å°åˆ° 1hï¼Œéœ€è¦ 16Bsh^2 æ¬¡æ“ä½œã€‚å°†è¿™äº›åŠ åœ¨ä¸€èµ·ï¼Œæ¯ä¸ª transformer block ä¸€å…±æœ‰ 24Bsh^2+4Bhs^2 FLOPs. åå‘ä¼ æ’­éœ€è¦ä¸¤å€çš„è®¡ç®—é‡ï¼Œå› ä¸ºéœ€è¦è®¡ç®—å…³äºè¾“å…¥å¼ é‡å’Œæƒé‡å¼ é‡çš„æ¢¯åº¦ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æ¿€æ´»é‡è®¡ç®—éœ€è¦åœ¨åå‘ä¼ æ’­ä¹‹å‰è¿›è¡Œé¢å¤–çš„æ­£å‘ä¼ æ’­ã€‚å› æ­¤ï¼Œæ¯ä¸€å±‚çš„æ€»è®¡ç®—é‡ä¸º FLOPs ä¸º 4*(24Bsh^2+4Bhs^2).\nè®¡ç®—é‡å¦ä¸€æ–¹é¢æ¥æºäº head çš„ logit å±‚ï¼Œå®ƒå°†ç»´åº¦çš„ç‰¹å¾ h è½¬æ¢ä¸ºè¯æ±‡è¡¨ç»´åº¦çš„ç‰¹å¾ V. è¯¥æ“ä½œæ‰€éœ€çš„è®¡ç®—é‡ä¸ºæ­£å‘ä¼ æ’­çš„ 2BshV å’Œåå‘ä¼ æ’­çš„ 4BshVï¼Œæ€»å…± 6BshV FLOPs.\nResult Pipeline-parallel å¹¶è¡Œåº¦å¢åŠ é™ä½ GPU çš„è®¡ç®—æ•ˆç‡ï¼Œå› ä¸º bubble å˜å¤šäº†ã€‚ Batchsize çš„å¢å¤§å¯ä»¥å‡å°‘ pipeline-parallel å¹¶è¡Œåº¦å¤§å°å¸¦æ¥çš„å½±å“ã€‚\nBatch sizeå¢åŠ æœ‰åŠ©äºæé«˜GPUçš„è®¡ç®—æ•ˆç‡ã€‚ Interleaved schedules èƒ½æ˜¾è‘—æé«˜GPUçš„è®¡ç®—æ•ˆç‡ã€‚\nä¸ä½¿ç”¨æ¿€æ´»é‡è®¡ç®—çš„è¯å•ä½æ—¶é—´å†…çš„è®­ç»ƒçš„ååæ˜¯è¦é«˜äºä½¿ç”¨é‡è®¡ç®—çš„ï¼Œå› ä¸ºé‡è®¡ç®—åœ¨åå‘ä¼ æ’­ä¸­å¼•å…¥é¢å¤–çš„è®¡ç®—é‡ã€‚ ç”±äºé‡è®¡ç®—å¯ä»¥èŠ‚çœæ˜¾å­˜ï¼Œbatchsize å¯ä»¥ç›¸åº”æé«˜ä¸å°‘ã€‚ç”±äº batchsize çš„æé«˜ï¼Œè®­ç»ƒååé‡ä¹Ÿå¾—åˆ°äº†æé«˜ï¼Œä»è€Œè¾¾åˆ°äº†ä¼˜åŒ–çš„æ•ˆæœã€‚\n","permalink":"http://localhost:1313/blogs/efficient-large-scale-language-model-training-on-gpu-clusters/","summary":"Paper reading about Efficient Large-Scale Language Model Training on GPU Clusters.","title":"Efficient Large-Scale Language Model Training on GPU"},{"content":"Abstract æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦æ–°çš„ç¼–è¯‘å™¨æˆ–æ›´æ”¹åº“ï¼Œä¸æµæ°´çº¿æ¨¡å‹å¹¶è¡Œ (pipeline model parallelism) æ­£äº¤äº’è¡¥ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡åœ¨åŸç”Ÿ PyTorch ä¸­æ’å…¥ä¸€äº›é€šä¿¡æ“ä½œæ¥å®ç°ã€‚ä¸ºäº†é˜è¿°æˆ‘ä»¬çš„æ–¹æ³•ï¼Œä½¿ç”¨ 512 ä¸ª GPU å°†åŸºäº transformer çš„æ¨¡å‹æ‰©å±•åˆ° 83 äº¿ä¸ªå‚æ•°ã€‚ä¸å¯ä¿æŒ 39 TeraFLOPs (å³°å€¼ FLOPs çš„ 30%) çš„å¼ºå¤§å• GPU åŸºå‡†ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨æ•´ä¸ªåº”ç”¨ä¸­ä¿æŒäº† 15.1 PetaFLOPsï¼Œæ‰©å±•æ•ˆç‡é«˜è¾¾ 76%.\nIntroduction éšç€ LLM å˜å¾—è¶Šæ¥è¶Šå¤§ï¼Œå®ƒä»¬ä¼šè¶…å‡ºç°ä»£å¤„ç†å™¨çš„å†…å­˜é™åˆ¶ï¼Œå¹¶éœ€è¦å¦‚æ¿€æ´»æ£€æŸ¥ç‚¹ (activation checkpoint) ç­‰é¢å¤–çš„å†…å­˜ç®¡ç†æŠ€æœ¯ã€‚å¹¿æ³›ä½¿ç”¨çš„ä¼˜åŒ–ç®—æ³• (å¦‚ADAM) éœ€è¦æ¯ä¸ªå‚æ•°é¢å¤–çš„å†…å­˜æ¥å­˜å‚¨åŠ¨é‡å’Œå…¶ä»–ä¼˜åŒ–å™¨çŠ¶æ€ã€‚è¿™å‡å°‘äº†å¯ä»¥æœ‰æ•ˆè®­ç»ƒçš„æ¨¡å‹çš„å¤§å°ã€‚æ¨¡å‹å¹¶è¡Œæ€§çš„å‡ ç§æ–¹æ³•å…‹æœäº†è¿™ä¸€é™åˆ¶ï¼Œå®ƒä»¬å¯¹æ¨¡å‹è¿›è¡Œåˆ†åŒºï¼Œä½¿æƒé‡åŠå…¶ç›¸å…³çš„ä¼˜åŒ–å™¨çŠ¶æ€ä¸éœ€è¦å¹¶å‘åœ°é©»ç•™åœ¨å¤„ç†å™¨ä¸Šã€‚\nActivation Checkpoint åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå‰å‘ä¼ æ’­ä¼šè®¡ç®—å¹¶å­˜å‚¨æ¯ä¸€å±‚çš„æ¿€æ´»å€¼ï¼Œè¿™äº›æ¿€æ´»å€¼åœ¨åå‘ä¼ æ’­æ—¶è¢«ç”¨æ¥è®¡ç®—æ¢¯åº¦ã€‚ç„¶è€Œï¼Œå¯¹äºæ·±åº¦å¾ˆå¤§çš„æ¨¡å‹å› ä¸ºéœ€è¦å­˜å‚¨å¤§é‡çš„æ¿€æ´»å€¼ï¼Œå¯èƒ½ä¼šå¯¼è‡´å†…å­˜æº¢å‡ºã€‚æ¿€æ´»æ£€æŸ¥ç‚¹æŠ€æœ¯é€šè¿‡åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­åªå­˜å‚¨ä¸€éƒ¨åˆ†çš„æ¿€æ´»å€¼æ¥è§£å†³å†…å­˜å ç”¨é—®é¢˜ï¼Œå¦‚æœåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­éœ€è¦æ²¡æœ‰å­˜å‚¨çš„æ¿€æ´»å€¼å°±è¿›è¡Œé‡æ–°è®¡ç®—ã€‚ ä¸ºäº†è¯æ˜æ–¹æ³•çš„å¯æ‰©å±•æ€§ï¼Œé€šè¿‡åœ¨å•ä¸ªè‹±ä¼Ÿè¾¾ V100 32GB GPU ä¸Šè®­ç»ƒä¸€ä¸ªåŒ…å« 12 äº¿ä¸ªå‚æ•°çš„æ¨¡å‹æ¥å»ºç«‹åŸºå‡†ã€‚è®­ç»ƒè¯¥æ¨¡å‹å¯ç»´æŒ 39 TeraFLOPs çš„ç®—åŠ›ï¼Œæ˜¯åœ¨ DGX-2H æœåŠ¡å™¨ä¸­é…ç½®çš„å•ä¸ª GPU ç†è®ºå³°å€¼ FLOPS çš„ 30%. åœ¨ 512 ä¸ª GPU ä¸Šå°†æ¨¡å‹æ‰©å±•åˆ° 83 äº¿ä¸ªå‚æ•°ï¼Œå¹¶é‡‡ç”¨ 8 è·¯æ¨¡å‹å¹¶è¡Œï¼Œåœ¨æ•´ä¸ªåº”ç”¨ä¸­å®ç°äº†é«˜è¾¾ 15.1 PetaFLOPs çš„æŒç»­è¿è¡Œé€Ÿåº¦ã€‚ä¸å• GPU æƒ…å†µç›¸æ¯”ï¼Œæ‰©å±•æ•ˆç‡æé«˜äº† 76%. ä¸‹å›¾å±•ç¤ºäº†æ›´è¯¦ç»†çš„æ‰©å±•ç»“æœã€‚\nModel (blue) and model\u0026#43;data (green) parallel FLOPS\nBackground \u0026amp; Chanllenges Neural Language Model Pretraining æ—©æœŸçš„é¢„è®­ç»ƒå’Œä¼ é€’è¯­è¨€ç¥ç»è¡¨ç¤ºçš„ä¾‹å­è¡¨æ˜ï¼Œä¸ä»å¤´å¼€å§‹å­¦ä¹ çš„è¯åµŒå…¥è¡¨ç›¸æ¯”ï¼Œé¢„è®­ç»ƒçš„è¯åµŒå…¥è¡¨æ”¹å–„äº†ä¸‹æ¸¸ä»»åŠ¡çš„ç»“æœã€‚ç›®å‰çš„æŠ€æœ¯æ°´å¹³å·²ç»ä»ä¼ è¾“å•è¯åµŒå…¥è¡¨å‘å±•åˆ°ä¼ è¾“æ•´ä¸ªæ•°åäº¿å‚æ•°çš„è¯­è¨€æ¨¡å‹ã€‚è¿™ç§æ–¹æ³•çš„è¿›æ­¥è¦æ±‚ç¡¬ä»¶ã€ç³»ç»ŸæŠ€æœ¯å’Œæ¡†æ¶èƒ½å¤Ÿé«˜æ•ˆåœ°å¤§è§„æ¨¡è¿è¡Œã€‚\nTransformer Language Models and Multi-Head Attention ä¸‹å›¾å±•ç¤ºäº†ä½¿ç”¨çš„ transformer æ¨¡å‹çš„ç¤ºæ„å›¾ã€‚æœ€è¿‘åˆ©ç”¨ transformer è¿›è¡Œè¯­è¨€å»ºæ¨¡çš„å·¥ä½œï¼Œå¦‚ BERT å’Œ GPT-2 æ ¹æ®éœ€è¦åˆ†åˆ«åªä½¿ç”¨ç¼–ç å™¨å’Œè§£ç å™¨ã€‚\nGPT-2 å’Œ BERT éƒ½å¯¹å¤šå¤´æ³¨æ„å’Œ FFN çš„è¾“å…¥ä½¿ç”¨ GeLU éçº¿æ€§å’Œå±‚å½’ä¸€åŒ–ï¼Œè€ŒåŸå§‹ transformer ä½¿ç”¨ ReLU éçº¿æ€§å¹¶å¯¹è¾“å‡ºè¿›è¡Œå±‚å½’ä¸€åŒ–ã€‚\nTransformer Architecture\nData and Model Parallelism in Deep Learning å°†æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒæ‰©å±•åˆ°å¤šç¡¬ä»¶åŠ é€Ÿå™¨æœ‰ä¸¤ç§èŒƒå¼:\nData Parallelism (DP): å°† batch æ‹†åˆ†åˆ°å¤šä¸ª worker Model Parallelism (MP): å°†æ¨¡å‹çš„å†…å­˜ä½¿ç”¨å’Œè®¡ç®—åˆ†å¸ƒåœ¨å¤šä¸ª worker ä¸­ã€‚ Pipeline Parallelism (PP): ä¸€ç»„æ“ä½œåœ¨ä¸€ä¸ªè®¾å¤‡ä¸Šæ‰§è¡Œï¼Œç„¶åå°†è¾“å‡ºä¼ é€’åˆ°æµæ°´çº¿ä¸­çš„ä¸‹ä¸€ä¸ªè®¾å¤‡æ‰§è¡Œå¦ä¸€ç»„æ“ä½œã€‚ Distributed Tensor Computation: å°†å¼ é‡è¿ç®—åˆ†å‰²åˆ°å¤šä¸ªè®¾å¤‡ä¸Šï¼Œä»¥åŠ é€Ÿè®¡ç®—æˆ–å¢åŠ æ¨¡å‹å¤§å°ã€‚ ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯æœ‰ä¸€ä¸ªåŸºæœ¬çš„é™åˆ¶: æ¨¡å‹æƒé‡å¿…é¡»èƒ½åŠ è½½è¿› worker. æˆ‘ä»¬çš„æ–¹æ³•æ˜¯åˆ©ç”¨æ¨¡å‹å¹¶è¡Œæ€§åœ¨å¤šä¸ªåŠ é€Ÿå™¨ä¹‹é—´åˆ†å‰²æ¨¡å‹ã€‚\nModel Parallel Transformers æˆ‘ä»¬åˆ©ç”¨ transformer ç½‘ç»œçš„ç»“æ„ (self-attention å’Œ FFN (2*MLP) ç»„æˆ)ï¼Œé€šè¿‡æ·»åŠ ä¸€äº›åŒæ­¥åŸè¯­ï¼Œåˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„å¹¶è¡Œè®¡ç®—æ¨¡å‹ã€‚ä¸‹é¢åˆ†åˆ«é˜è¿°å¯¹ FFN å’Œ self-attention çš„å¹¶è¡ŒåŒ–ã€‚\nFFN ç¬¬ä¸€ä¸ª MLP ç”±ä¸€ä¸ª GEMMï¼Œåè·Ÿä¸€ä¸ª GeLU éçº¿æ€§ç»„æˆ:\n$$\rY=\\text{GeLU}(XA)\r$$å¹¶è¡ŒåŒ– GEMM çš„ä¸€ç§é€‰æ‹©æ˜¯å°†æƒé‡çŸ©é˜µ A æ²¿ç€è¡Œåˆ‡åˆ†ï¼Œå¹¶å°† X æ²¿ç€å…¶åˆ—åˆ‡åˆ†:\n$$\rX=[X_1,X_2], A=\\begin{bmatrix}A_1\\\\A_2\\end{bmatrix}\r$$\rRow Split of Weight\nå¯ä»¥å¾—å‡º $Y = X_1A_1+X_2A_2$. ç”±äº GeLU æ˜¯éçº¿æ€§å‡½æ•°ï¼Œå› æ­¤è¿™ç§æ–¹æ³•éœ€è¦åœ¨ GeLU å‡½æ•°ä¹‹å‰è¿›è¡ŒåŒæ­¥ã€‚\nå¦ä¸€ä¸ªé€‰æ‹©æ˜¯æ²¿ç€åˆ—åˆ‡åˆ† $A=\\begin{bmatrix}A_1,A_2\\end{bmatrix}$. è¿™æ ·å¯ä»¥è®© GeLU ç‹¬ç«‹åœ°åº”ç”¨äºæ¯ä¸ª GEMM çš„è¾“å‡º\n$[Y_1, Y_2]=\\begin{bmatrix}\\text{GeLU}(XA_1),\\text{GeLU}(XA_2)\\end{bmatrix}$.\nColumn Split of Weight\nè¿™ç§åˆ‡åˆ†æ–¹å¼çš„ä¼˜ç‚¹æ˜¯ä¸éœ€è¦è¿›è¡ŒåŒæ­¥æ“ä½œã€‚\nå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä»¥åˆ—å¹¶è¡Œæ–¹å¼åˆ‡åˆ†ç¬¬ä¸€ä¸ª GEMMï¼Œå¹¶æ²¿ç€è¡Œåˆ‡åˆ†ç¬¬äºŒä¸ªGEMMã€‚ç„¶åï¼Œåœ¨å°†è¾“å‡ºä¼ é€’ç»™ dropout å±‚ä¹‹å‰ï¼Œç¬¬äºŒä¸ªGEMM çš„è¾“å‡ºåœ¨ GPU ä¹‹é—´è¿›è¡Œ all-reduce æ“ä½œã€‚è¿™ç§æ–¹æ³•å°† FFN ä¸­çš„ä¸¤ä¸ª GEMM æ‹†åˆ†åˆ°å¤šä¸ª GPU ä¸Šæ‰§è¡Œï¼Œå¹¶ä¸”åªéœ€è¦åœ¨æ­£å‘ä¼ æ’­ (g æ“ä½œç¬¦) å’Œåå‘ä¼ æ’­ (f æ“ä½œç¬¦) ä¸­åˆ†åˆ«æ‰§è¡Œä¸€æ¬¡ all-reduce æ“ä½œã€‚\nParallelism of MLP\nå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æ“ä½œä¸­æœ¬èº«å­˜åœ¨çš„å¹¶è¡Œæ€§ï¼Œä»¥åˆ—å¹¶è¡Œçš„æ–¹å¼åˆ’åˆ†ä¸ QKV ç›¸å…³çš„ GEMMï¼Œä»¥ä¾¿æ¯ä¸ªæ³¨æ„åŠ›å¤´å¯¹åº”çš„çŸ©é˜µä¹˜æ³•åœ¨ä¸€ä¸ª GPU ä¸Šç‹¬ç«‹å®Œæˆã€‚è¾“å‡ºçº¿æ€§å±‚çš„ GEMM æ²¿ç€å…¶è¡Œå¹¶è¡ŒåŒ–ï¼Œå¹¶ç›´æ¥è·å–å¹¶è¡Œ attention çš„è¾“å‡ºã€‚\nParallelism of Self-Attention\nå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¿™ä½¿èƒ½å¤Ÿä»…åœ¨æ­£å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ä¸­åˆ†åˆ«ä¸­ä½¿ç”¨ä¸¤ä¸ª all-reduce æ“ä½œæ‰§è¡Œ transformer ä¸­æ‰€æœ‰çš„ GEMM.\nParallelism of Transformer Layer\nåŸºäº transformer çš„è¯­è¨€æ¨¡å‹çš„è¾“å‡ºåµŒå…¥ç»´åº¦ä¸ºéšè—å±‚å¤§å° (H) ä¹˜ä»¥è¯æ±‡è¡¨å¤§å° (v). æˆ‘ä»¬æ²¿ç€è¯æ±‡è¡¨ç»´åº¦ $E = \\begin{bmatrix}E_1,E_2\\end{bmatrix}$ å¹¶è¡ŒåŒ–æƒé‡çŸ©é˜µã€‚æ¯ä¸€å—ç°åœ¨åªåŒ…å«åµŒå…¥è¡¨çš„ä¸€éƒ¨åˆ†ï¼Œè¾“å…¥åµŒå…¥åéœ€è¦ä¸€ä¸ª all-reduce (g ç®—å­).\nå¯¹äºè¾“å‡ºåµŒå…¥ï¼Œä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡å¹¶è¡Œ $\\mathrm{GEMM} [Y_{1},Y_{2}]=[XE_{1},XE_{2}]$ æ¥è·å¾— logitsï¼Œå¹¶å¯¹ç»“æœ all-gather åé€å…¥äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œall-gather é€šä¿¡é‡ä¸º bsv ä¸ªå…ƒç´  (b æ˜¯æ‰¹å¤„ç†å¤§å°ï¼Œs æ˜¯åºåˆ—é•¿åº¦). ä¸ºäº†å‡å°é€šä¿¡è§„æ¨¡ï¼Œæˆ‘ä»¬å°†è¾“å‡ºä¸äº¤å‰ç†µæŸå¤±èåˆï¼Œè¿™æ ·é€šä¿¡é‡é™ä¸º bs.\næˆ‘ä»¬åœ¨æ¯ä¸ª GPU ä¸Šç»´æŠ¤å±‚å½’ä¸€åŒ–å‚æ•°çš„å‰¯æœ¬ï¼Œå¹¶åœ¨å°†è¿™äº›å¼ é‡ä½œä¸ºè¾“å…¥é€åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹å¹¶è¡ŒåŒºåŸŸä¹‹å‰ï¼Œåœ¨æœ¬åœ°è¾“å‡ºä¸Šè¿›è¡Œ dropout å’Œæ®‹å·®è¿æ¥ã€‚ä¸ºäº†ä¼˜åŒ–æ¨¡å‹ï¼Œæˆ‘ä»¬å…è®¸æ¯ä¸ªæ¨¡å‹å¹¶è¡Œ worker ä¼˜åŒ–è‡ªå·±çš„ä¸€ç»„å‚æ•°ã€‚å› ä¸ºæ‰€æœ‰çš„å€¼è¦ä¹ˆæ˜¯æœ¬åœ°çš„ï¼Œè¦ä¹ˆæ˜¯åœ¨ GPUä¸Š é‡å¤çš„ï¼Œæ‰€ä»¥åœ¨è¿™ä¸ªå…¬å¼ä¸­ä¸éœ€è¦é€šä¿¡æ›´æ–°çš„å‚æ•°å€¼ã€‚\n","permalink":"http://localhost:1313/blogs/megatronlm/","summary":"Paper reading about Megatron-LM","title":"Megatron-LM"},{"content":"Background å¦‚ä»Š LLM çš„ token é•¿åº¦æ˜¾è‘—å¢åŠ ï¼Œä» GPT-3.5 çš„ 16k åˆ° Claude 2 çš„ 200kï¼Œç°åœ¨ Gemini 1.5 Pro ç”šè‡³æœ‰ 1M çš„ token é•¿åº¦ã€‚å¦‚æ­¤é•¿çš„ token åœ¨è®¡ç®— attention æ—¶å¯¹æ˜¾å­˜çš„éœ€æ±‚éå¸¸å¤§ã€‚Ring Attention ä¾¿æ˜¯ä¸ºäº†å¹¶è¡Œè®¡ç®— attention è€Œæå‡ºçš„ä¸€ç§æ–¹æ³•1ã€‚\nRing Attention å’Œ Flash Attention å¯ä»¥åŒæ—¶ä½¿ç”¨ã€‚\nAttention and Memory è¦è®¡ç®— attentionï¼Œ æˆ‘ä»¬éœ€è¦ä¸‰ä¸ªå¤§å°ä¸º (s, d) çš„çŸ©é˜µï¼šQ (query)ã€K (key)ã€V (value)ï¼Œå…¶ä¸­ s ä¸ºåºåˆ—é•¿åº¦ï¼Œd ä¸ºæ¨¡å‹ç»´åº¦ã€‚attention çš„è®¡ç®—å…¬å¼ä¸º\n$$\rAttention(Q, K, V) = softmax(QK^T / \\sqrt{d})V\r$$å¿½ç•¥ sqrt(d) é¡¹ï¼Œæˆ‘ä»¬è®° Score Matrix ä¸º S = QK^T / \\sqrt{d}ï¼Œç„¶åå¯¹ S è¿›è¡Œ softmax å½’ä¸€åŒ–ï¼Œå¾—åˆ° Attention Matrix. å¯ä»¥å‘ç°å®ƒä»¬å ç”¨æ˜¾å­˜å¤§å°æ˜¯ O(s*s) æ•°é‡çº§ã€‚å³ä½¿ä½¿ç”¨ Flash Attentionï¼Œæ˜¾å­˜å ç”¨é‡ä¹Ÿæ˜¯ O(s) æ•°é‡çº§ã€‚\nAttention Compute Process\næˆ‘ä»¬å¸Œæœ›å¦‚æœåœ¨ N ä¸ªè®¾å¤‡ä¸Šå¹¶è¡Œè®¡ç®— attentionï¼Œæ¯ä¸ªè®¾å¤‡çš„æ˜¾å­˜å ç”¨é‡ä¸ºæ•´ä¸ªçš„ 1/N, å› æ­¤å°±éœ€è¦å¯¹ Qã€Kã€V çš„ sequence é•¿åº¦è¿›è¡Œåˆ‡åˆ†ã€‚ä½†æ˜¯å¦‚æœå¾—åˆ°çš„æœ€ç»ˆ attention çŸ©é˜µéœ€è¦åœ¨è®¾å¤‡é—´è¿›è¡Œé›†åˆé€šä¿¡ç»„è£…æ¯ä¸ªçš„è®¡ç®—ç»“æœï¼Œé€šä¿¡é‡ä¹Ÿå’Œ sequence é•¿åº¦æˆæ­£æ¯”ã€‚Ring Attention æå‡ºäº†ä¸€ä¸ªå·§å¦™çš„è§£å†³æ–¹æ¡ˆï¼šåœ¨è®¾å¤‡ä¹‹é—´è¿›è¡Œè½®è½¬ï¼Œå¹¶è¡ŒåŒ–æ‰€æœ‰è®¡ç®—è€Œä¸”å®Œå…¨éšè—é€šä¿¡çš„å¼€é”€ã€‚\nWe will rotate between devices to parallelize all computation and hide the communication overhead completely.\nSplitting the Query å‡è®¾æˆ‘ä»¬æœ‰ N ä¸ªè®¾å¤‡ï¼Œæˆ‘ä»¬å°† Q æ²¿ç€ sequence ç»´åº¦åˆ‡åˆ†ä¸º N ä»½ï¼Œæ¯ä»½å¤§å°ä¸º (s/N, d). ç”±äºè®¡ç®— Score å’Œ Attention éœ€è¦å®Œæ•´çš„ K å’Œ Vï¼Œè¿™æ ·å®ƒä»¬ä¹Ÿè¢«åˆ‡åˆ†æˆ N ä»½ï¼Œæ¯ä»½å¤§å°ä¸º (s/N, d). è®¡ç®—ç¤ºæ„å›¾å¦‚ä¸‹ã€‚\nSplit Q\nSplitting the Key and Value å¯¹ K å’Œ V çš„åˆ‡åˆ†å¹¶ä¸èƒ½åƒ Q é‚£æ ·ç›´æ¥ã€‚å› ä¸º softmax çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼Œè¦å¾—åˆ°åˆ†æ¯çš„å€¼æ„å‘³ç€æˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸€è¡Œè¿›è¡Œè®¡ç®—ã€‚\n$$\rsoftmax(s_i) = \\frac{\\exp(s_i)}{\\sum_{j=i}^d{\\exp(s_j)}}\r$$å¦‚æœæˆ‘ä»¬èƒ½å¯¹ K å’Œ V è¿›è¡Œåˆ‡åˆ†å¹¶æ­£ç¡®è®¡ç®— softmaxï¼Œé‚£ä¹ˆè®¡ç®—è¿‡ç¨‹å¯ä»¥ç”±ä¸‹å›¾æ‰€ç¤ºçš„é‚£æ ·å®Œæˆ (å¿½ç•¥ softmax). å¤–å¾ªç¯éå† Q çš„æ‰€æœ‰åˆ†å—ï¼Œå†…å¾ªç¯éå† K å’Œ V çš„æ‰€æœ‰åˆ†å—ï¼Œä¸€æ¬¡è®¡ç®—ä¸€éƒ¨åˆ†çš„ attention. Ring Attention ç¤ºæ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼Œé¡¾åæ€ä¹‰æ‰€æœ‰è®¾å¤‡ç»„æˆä¸€ä¸ªç¯çŠ¶ï¼Œæ¯ä¸ªè®¾å¤‡å­˜å‚¨ Q çš„ä¸€éƒ¨åˆ†ï¼Œæ¯æ¬¡è¿­ä»£è¿‡ç¨‹ä¼šä¼ é€’ K å’Œ V åˆ°ä¸‹ä¸€ä¸ªè®¾å¤‡ï¼Œæœ€ç»ˆæ¯ä¸ªè®¾å¤‡å°†å¾—åˆ°è®¡ç®—è‡ªå·± Q éƒ¨åˆ†çš„ attention çŸ©é˜µæ‰€éœ€è¦çš„ K å’Œ V. æ¯ä¸ªè®¾å¤‡è¢«åˆ†é… Q çš„ä¸€éƒ¨åˆ† (å³ä¸€ä¸ªå¤–å±‚å¾ªç¯ç´¢å¼•)ï¼Œå¹¶è¿­ä»£è®¡ç®—æ¯ä¸ª K å’Œ V çš„åˆ†å— (å†…å¾ªç¯)ã€‚æ¯ä¸ªè®¾å¤‡åªéœ€è¦è·Ÿè¸ªå½¢çŠ¶ä¸º (s/N, s/N) çš„ç´¯ç§¯å’Œ A_jã€‚\nAttention Parallel Computation\nOnline Softmax åœ¨å†…å¾ªç¯çš„æ¯æ¬¡è¿­ä»£ä¸­æˆ‘ä»¬å¯ä»¥æ›´æ–°éƒ¨åˆ†å’Œä¸º $l^j = l^{j-1} + \\sum_{k_t\\in K_j}{\\exp(Q_ik_t^T)}$. åœ¨å†…å¾ªç¯ç»“æŸåæˆ‘ä»¬å°±å¯ä»¥è·å¾—æ¯ä¸€è¡Œçš„æŒ‡æ•°å’Œã€‚å½’ä¸€åŒ–å’Œä¸ V çš„ç›¸ä¹˜é¡ºåºä¸ä¼šå½±å“ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å…ˆç´¯åŠ æ€»å’Œï¼Œå¹¶åœ¨æ‰€æœ‰å…¶ä»–è®¡ç®—å®Œæˆåå†æ‰§è¡Œå®é™…çš„å½’ä¸€åŒ–æ“ä½œã€‚\nå› æ­¤ï¼Œè®¾å¤‡ i é™¤äº†è®¡ç®—å½“å‰çš„ç´¯è®¡å’Œ $A^j = A^{j-1} + \\exp(Q_i K_j^T) V_j$ å¤–ï¼Œè¿˜éœ€è¦åœ¨å†…å¾ªç¯æ¯æ¬¡è¿­ä»£ä¸­æ›´æ–°éƒ¨åˆ†å’Œ $l^j \\in \\mathbb{R}^{B_q}$ ï¼Œå…¶ä¸­ $B_q$ ä¸º Q çš„åˆ†å—å¤§å°ã€‚\nSafe softmax ç”±äºæŒ‡æ•°è¿ç®—ç»å¸¸å®¹æ˜“å‡ºç°æº¢å‡ºï¼Œæˆ‘ä»¬é€šå¸¸å‡å» max(s_i) åè¿›è¡ŒæŒ‡æ•°è¿ç®—ï¼Œå…¬å¼å¦‚ä¸‹ï¼Œè¿™æ ·å¹¶ä¸ä¼šå½±å“ç»“æœã€‚\n$$\r\\mathrm{softmax}(s_{1:N})=\\frac{\\exp(s_{1:N})}{\\sum_i\\exp(s_i)}\\cdot\\frac{\\exp(-s_{max})}{\\exp(-s_{max})}=\\frac{\\exp(s_{1:N}-s_{max})}{\\sum_i\\exp(s_i-s_{max})}\r$$æ‰€ä»¥æˆ‘ä»¬åœ¨å†…å¾ªç¯æ¯æ¬¡è¿­ä»£ä¸­éœ€è¦å…ˆæ›´æ–°å½“å‰çš„æœ€å¤§å€¼ $m^{j+1}=\\max(m^j,\\max(Q_iK_{j+1}^T))$ï¼Œç„¶åæ›´æ–°ä¹‹å‰è¿­ä»£çš„è®¡ç®—ç»“æœ A_j å’Œ éƒ¨åˆ†å’Œ l_j. æœ€åå†è®¡ç®—æœ¬æ¬¡è¿­ä»£çš„ç»“æœã€‚\n$$\rA^{j+1}=A^j\\cdot\\exp(m^j-m^{j+1})+\\exp(Q_iK_{j+1}^T-m^{j+1})\\cdot V_j\r$$æ›´æ–°éƒ¨åˆ†å’Œ\n$$\rl^{j+1}=l^j\\cdot\\exp(m^j-m^{j+1})+\\exp(Q_iK_{j+1}^T-m^{j+1})\r$$Putting it Together Ring Attention è®¡ç®—æ­¥éª¤å¦‚ä¸‹ï¼š\næ²¿ç€ Q çš„ sequence é•¿åº¦æ‹†åˆ†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„å¤–å¾ªç¯ã€‚ åº”ç”¨ Online Safe Softmaxï¼Œä»¥ä¾¿æ²¿ç€ K å’Œ V çš„sequence é•¿åº¦æ‹†åˆ†ï¼Œä»è€Œåœ¨å†…å±‚å¾ªç¯ä¸­ç´¯ç§¯è®¡ç®—æ³¨æ„åŠ›ã€‚ è¿™ç§å¹¶è¡ŒåŒ–çš„æ–¹å¼æ˜¯é€šè¿‡å°†æ¯ä¸ªè®¾å¤‡åˆ†é…ä¸€ä¸ª Q_i å—æ¥å®ç°çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å°† Q æ‹†åˆ†ä¸º N ä¸ªç›¸ç­‰çš„éƒ¨åˆ† (B_Q=N). æ¯ä¸ªè®¾å¤‡å°†åˆ†åˆ«è®¡ç®—å®ƒçš„è¾“å‡ºå— $\\text{Output}(Qi,K,V)= \\text{softmax}(Q_i K^T)V ï¼Œé€šè¿‡åœ¨ K å’Œ V å—ä¸Šæ‰§è¡Œå†…å¾ªç¯æ¥è¿­ä»£è®¡ç®—ã€‚éš¾ç‚¹æŒ‘æˆ˜åœ¨äºè®¾å¤‡æ— æ³•ä¸€æ¬¡å­˜å‚¨å®Œæ•´çš„ K å’Œ V çŸ©é˜µã€‚\nå¦‚æœæˆ‘ä»¬æœ‰ 4 ä¸ª GPUï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†æŠŠæ¯ä¸ªè®¾å¤‡çš„ Q æŒ‰åºåˆ—ç»´åº¦åˆ†æˆ 4 ä¸ªå—ï¼ŒK å’Œ V è¢«åˆ†å‰²æˆ B_K=B_Q=N ä¸ªå—ï¼Œå¹¶å¯¹è®¾å¤‡è¿›è¡Œåˆå§‹åŒ–ï¼Œä½¿æ¯ä¸ªè®¾å¤‡éƒ½æŒæœ‰ä¸€ä¸ª Qi å—ã€ ä¸€ä¸ª Kj å—å’Œ ä¸€ä¸ª Vj å—ã€‚ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾è®¾å¤‡ i åœ¨å¼€å§‹æ—¶æŒæœ‰ Qi, Ki å’Œ Vj å—ã€‚åœ¨è®¾å¤‡è®¡ç®—å®Œä¸å…¶å½“å‰ vj kj ç›¸å¯¹åº”çš„ä¸€ä¸ªå†…å¾ªç¯æ­¥éª¤åï¼Œæ¯ä¸ªè®¾å¤‡éƒ½éœ€è¦æ¥æ”¶ä¸‹ä¸€ä¸ª Key å’Œ Value å—ï¼Œä»¥ç»§ç»­å†…å¾ªç¯ã€‚ æˆ‘ä»¬å°† N ä¸ªè®¾å¤‡å›´æˆä¸€ä¸ªç¯ï¼Œå…¶ä¸­è®¾å¤‡ i å¯ä»¥å‘è®¾å¤‡ i+1 ä»¥æ­¤ç±»æ¨ï¼Œå¦‚å›¾æ‰€ç¤ºï¼š\nKV-overlap\nå¦‚æœåœ¨è®¾å¤‡ i ä¸Šè®¡ç®—å†…å¾ªç¯çš„ä¸€ä¸ªæ­¥éª¤ Qi,Vj,Kj çš„è¿™æ®µæ—¶é—´å†…ï¼Œè®¾å¤‡ i è¿˜èƒ½å‘è®¾å¤‡ i+1 å‘é€å…¶å½“å‰ Kj Vjï¼Œå¹¶åŒæ—¶ä»è®¾å¤‡ i-1 æ¥æ”¶ V_j-1,K_j-1ï¼Œé‚£ä¹ˆåªè¦å‘é€å’Œæ¥æ”¶å¯†é’¥å’Œå€¼å—çš„æ—¶é—´ä½äºè®¡ç®—æ—¶é—´ï¼Œé‚£ä¹ˆå‘é€å’Œæ¥æ”¶ Key å’Œ Value å—çš„å»¶è¿Ÿå°±ä¼šéšè—åœ¨æ‰§è¡Œå®é™…è®¡ç®—æ—¶é—´ä¹‹å†…ã€‚ä¸€ä¸ªä¾‹å­å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\nKV-rotate\nMemory and Arithmetic Complexity ä»¥æ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨çš„ bfloat16 æ•°æ®ç±»å‹ä¸ºä¾‹ã€‚GPU æˆ– TPU ç­‰å¹¶è¡Œå¤„ç†åŠ é€Ÿå™¨é€šå¸¸ä»¥ FLOP:=F æ¥è¡¡é‡ï¼Œå³è®¾å¤‡ç†è®ºä¸Šæ¯ç§’å¯æ‰§è¡Œçš„æµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚æˆ‘ä»¬å‡è®¾ç¡¬ä»¶è¢«å®Œå…¨åˆ©ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾ä¸åŒè®¾å¤‡ä¹‹é—´çš„è¿æ¥å¸¦å®½ä¸º:=B (Bytes/sec).\nå†…å­˜å¤æ‚åº¦: ä¸ºäº†åŒæ—¶è¿›è¡Œæ¥æ”¶å‘é€å’Œè®¡ç®—ï¼Œæˆ‘ä»¬éœ€è¦æœ‰ç”¨äºæ¥æ”¶æ–° KV å—çš„å¯„å­˜å™¨å™¨ã€‚å­˜å‚¨å½“å‰ KV å€¼å—éœ€è¦ 2dc æµ®ç‚¹æ•°æˆ– 4dc å­—èŠ‚ã€‚ç”¨äºæ¥æ”¶æ–°çš„ KV å—çš„å†…å­˜å¤§å°ä¹Ÿæ˜¯ 2dc æµ®ç‚¹æ•°æˆ– 4dc å­—èŠ‚ã€‚å‡è®¾è®¡ç®—æœ¬èº«ä¸éœ€è¦æ›´å¤šå†…å­˜ (åˆ©ç”¨ Flash Attention æˆ– Blockwise Attention)ï¼Œè®¡ç®—å½“å‰æ­¥éª¤çš„è¾“å‡ºéœ€è¦ dc ä¸ªæµ®ç‚¹æ•°æˆ– 2dc å­—èŠ‚ã€‚æ­¤å¤–ï¼Œæ¯ä¸ªè®¾å¤‡è¿˜éœ€è¦å­˜å‚¨å…¶ Qi å—ï¼Œè¿™ä¹Ÿéœ€è¦ dc ä¸ªæµ®ç‚¹æ•°æˆ– 2dc å­—èŠ‚ã€‚æ€»å…±éœ€è¦ 6dc ä¸ªæµ®ç‚¹æˆ– 12dc å­—èŠ‚ã€‚\nNote\nRing Attention ä¸ Flash Attention æ˜¯æ­£äº¤çš„ï¼Œå¯ä»¥ä¸€èµ·ä½¿ç”¨ (Flash Attention å®é™…ä¸Šç”¨äº Ring Attention çš„å†…å¾ªç¯). Flash Attention ç›®æ ‡æ˜¯ä¸å°†æ•´ä¸ª Score Matrix åŠ è½½åˆ°å…¨å±€å†…å­˜ä¸­ï¼Œä»è€Œåœ¨åºåˆ—é•¿åº¦ä¸Šè·å¾—çº¿æ€§å†…å­˜å¤æ‚åº¦ã€‚Ring Attention å°† åŸå§‹æ³¨æ„åŠ›æ–¹æ³•å’Œ Flash Attention çš„å†…å­˜å¤æ‚åº¦è‡³å°‘é™ä½äº† N å€ï¼Œä½¿ç”¨ N ä¸ªè®¾å¤‡çš„å†…å­˜å¤æ‚åº¦è‡³å°‘é™ä½ N å€ï¼Œå› ä¸ºå®ƒå°†æ‰€æœ‰çŸ©é˜µéƒ½æ‹†åˆ†ä¸ºè‡³å°‘ N ä¸ªæˆ–æ›´å¤šéƒ¨åˆ† (å°† QKV åˆ†åˆ«åˆ†æˆ N ä»½ï¼Œå¹¶å°† Score Matrix åˆ†æˆ N^2 åˆ†). æ— è®ºå†…å­˜å¤æ‚åº¦æ˜¯ç”± QKVï¼Œè¿˜æ˜¯ç”± Score Matrix ä¸»å¯¼ï¼ŒRing Attention éƒ½èƒ½å°†å†…å­˜æˆæœ¬é™ä½è‡³å°‘ N å€ã€‚\né€šä¿¡å¼€é”€: åœ¨å†…å¾ªç¯æ¯ä¸€æ­¥ä¸­ï¼Œæ¯ä¸ªè®¾å¤‡éœ€è¦é€šè¿‡å¸¦å®½ä¸º B çš„ä¿¡é“å‘ä¸‹ä¸€ä¸ªè®¾å¤‡å‘é€ 2â‹…c_Qâ‹…d æµ®ç‚¹æ•°ã€‚æ¯ä¸ª bf16 å¤§å°ä¸º 2å­—èŠ‚ï¼Œå› æ­¤ï¼Œæ‰€éœ€çš„æ—¶é—´çº¦ä¸º 4â‹…câ‹…d/B.\nè¿ç®—å¼ºåº¦ï¼š ä¸€ä¸ªå†…å¾ªç¯æ­¥éª¤ï¼Œè®¡ç®—å±€éƒ¨æ³¨æ„åŠ›éœ€è¦ 2â‹…dâ‹…c^2 æ¬¡æµ®ç‚¹è®¡ç®—ï¼Œè®¡ç®— softmaxï¼Œå½’ä¸€åŒ–å‘é‡å’Œæœ€å¤§å€¼å‘é‡éœ€è¦ 2â‹…câ‹…d æ¬¡æµ®ç‚¹è®¡ç®—ï¼Œè®¡ç®—å±€éƒ¨æ³¨æ„åŠ›ä¸ Vj å—çš„ä¹˜ç§¯éœ€ 2â‹…dâ‹…c^2 æ¬¡æµ®ç‚¹è®¡ç®—ã€‚å› æ­¤ï¼Œæ€»è®¡ç®—æ‰€éœ€æ—¶é—´â‰ˆ4â‹…dâ‹…c^2/F.\nä¸ºäº†é‡å é€šä¿¡å’Œè®¡ç®— (éšè—é€šä¿¡å¼€é”€)ï¼Œæˆ‘ä»¬éœ€è¦ KV å—çš„ä¼ è¾“æ—¶é—´å°äºç­‰äºè®¡ç®—æœ¬åœ° QKV æ‰€éœ€çš„æ—¶é—´ï¼š\n$$\r4\\cdot c\\cdot d/B\\leq4\\cdot d\\cdot c^2/F\\iff B\\geq F/c\\iff s/N\\geq F/B $$Futher Optimization Ring Attention çš„ä¸€ä¸ªåº”ç”¨æ˜¯ç”¨äºå› æœ Transformal æ¨¡å‹æ—¶ï¼ŒåŠ ä¸Šä¸‰è§’å½¢æ©ç ç”¨äºæ³¨æ„åŠ›è®¡ç®—ã€‚è¿™æ„å‘³ç€æœ‰äº› GPU ä¸éœ€è¦å¯¹æ•´ä¸ªåºåˆ—è¿›è¡Œè®¡ç®—ï¼Œå¯¼è‡´å®ƒä»¬å¤§éƒ¨åˆ†æ—¶é—´å¤„äºé—²ç½®çŠ¶æ€ã€‚ä½œä¸º Ring Attention çš„æ‰©å±•ï¼ŒStripe Attention è§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œå¹¶æä¾›äº†ä¸€ç§åˆ†é…è®¡ç®—æ›´å‡åŒ€çš„æ–¹æ¡ˆï¼Œä»è€Œä½¿ Ring Attention çš„è®¡ç®—é€Ÿåº¦æ›´å¿«ã€‚\né™¤äº† Ring Attention å’Œ Flash Attention ç­‰ä½¿æ ‡å‡† Transformer æ¶æ„èƒ½æœ‰æ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦çš„æŠ€æœ¯å¤–ï¼Œäººä»¬è¿˜å°è¯•ä½¿ç”¨ Mamba ç­‰å…·æœ‰çº¿æ€§æ³¨æ„åŠ›çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ç­‰æ¨¡å‹æ¶æ„ã€‚\nReferences https://coconut-mode.com/posts/ring-attention/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blogs/ringattention/","summary":"This is a brief introduction to the Ring Attention Principle.","title":"Ring Attention Principle"},{"content":"15 Graph Traversal å›¾æ˜¯ä¸€ç§è¡¨ç¤ºå®ä½“ä¹‹é—´å…³ç³»çš„æ•°æ®ç»“æ„ã€‚æ‰€æ¶‰åŠçš„å®ä½“è¡¨ç¤ºä¸ºé¡¶ç‚¹ï¼Œå…³ç³»è¡¨ç¤ºä¸ºè¾¹ã€‚å›¾çš„éå†æ˜¯æŒ‡ä»ä¸€ä¸ªé¡¶ç‚¹å‡ºå‘ï¼Œä¾æ¬¡è®¿é—®å›¾ä¸­æ‰€æœ‰ä¸ä¹‹ç›¸é‚»çš„é¡¶ç‚¹ï¼Œç›´åˆ°æ‰€æœ‰é¡¶ç‚¹éƒ½è¢«è®¿é—®è¿‡ä¸ºæ­¢ã€‚\n15.1 Background ä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ªæœ‰å‘çš„ç®€å•å›¾çš„ä¾‹å­ã€‚æˆ‘ä»¬ä¸ºæ¯ä¸ªé¡¶ç‚¹åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•°å­—ï¼Œç§°ä¸ºé¡¶ç‚¹ç¼–å· (vertex id).\nA Simple Graph Example with 9 Vertices and 15 Directional Edges\nå›¾çš„ç›´è§‚è¡¨ç¤ºæ˜¯é‚»æ¥çŸ©é˜µ (adjacency matrix). å¦‚æœå­˜åœ¨ä¸€æ¡ä»æºé¡¶ç‚¹ i åˆ°ç›®çš„é¡¶ç‚¹ j çš„è¾¹ï¼Œåˆ™é‚»æ¥çŸ©é˜µå…ƒç´  a[i][j] çš„å€¼ä¸º 1ï¼Œå¦åˆ™ä¸º 0. ä¸‹å›¾å±•ç¤ºäº†å¯¹åº”çš„é‚»æ¥çŸ©é˜µã€‚\nAdjacent Matrix Representation of the Example Graph\nç¨€ç–è¿æ¥çš„å›¾å¯ä»¥ç”¨ç¨€ç–çŸ©é˜µè¡¨ç¤ºï¼Œä¸‹å›¾å±•ç¤ºäº†ç”¨ä¸‰ç§ä¸åŒå­˜å‚¨æ ¼å¼çš„é‚»æ¥çŸ©é˜µ: CSR, CSC å’Œ COO. æˆ‘ä»¬å°†è¡Œä¸‹æ ‡å’ŒæŒ‡é’ˆæ•°ç»„åˆ†åˆ«ç§°ä¸º src å’Œ srcPtrs æ•°ç»„ï¼Œåˆ—ä¸‹æ ‡å’ŒæŒ‡é’ˆæ•°ç»„åˆ†åˆ«ç§°ä¸º dst å’Œ dstPtrs æ•°ç»„ã€‚åœ¨å›¾çš„ CSR è¡¨ç¤ºä¸­ï¼Œæ¯ä¸ªæºé¡¶ç‚¹æŒ‡é’ˆ(srcPtrs) ç»™å‡ºé¡¶ç‚¹å‡ºè¾¹çš„èµ·å§‹ä½ç½®ã€‚åœ¨å›¾çš„ CSC è¡¨ç¤ºä¸­ï¼Œæ¯ä¸ªç›®çš„é¡¶ç‚¹æŒ‡é’ˆ (dstPtrs) ç»™å‡ºé¡¶ç‚¹å…¥è¾¹çš„èµ·å§‹ä½ç½®ã€‚åœ¨å›¾çš„ COO è¡¨ç¤ºä¸­ï¼Œsrc å’Œ dst æ•°ç»„åˆ†åˆ«å­˜å‚¨æºé¡¶ç‚¹å’Œç›®çš„é¡¶ç‚¹çš„ç¼–å·ã€‚\nThree Sparse Matrix Representations of the Adjacency Matrix\n15.2 Breadth-first Search (BFS) BFS é€šå¸¸ç”¨äºæ‰¾åˆ°ä»å›¾çš„ä¸€ä¸ªé¡¶ç‚¹åˆ°å¦ä¸€ä¸ªé¡¶ç‚¹æ‰€éœ€éå†çš„æœ€çŸ­è¾¹æ•°ã€‚ä¸€ç§æ–¹æ³•æ˜¯ï¼Œç»™å®šä¸€ä¸ªè¢«ç§°ä¸ºæ ¹çš„é¡¶ç‚¹ï¼Œç”¨ä»æ ¹åˆ°æŸä¸ªé¡¶ç‚¹æ‰€éœ€è¦éå†çš„æœ€å°è¾¹æ•°æ¥æ ‡è®°æ¯ä¸ªé¡¶ç‚¹ã€‚\nä¸‹å›¾(A)å±•ç¤ºç¤ºäº†ä»¥é¡¶ç‚¹ 0 ä¸ºæ ¹çš„ BFS ç»“æœã€‚å¦‚æœå¦ä¸€ä¸ªé¡¶ç‚¹ä½œä¸ºæ ¹ï¼ŒBFS çš„ç»“æœå°†å®Œå…¨ä¸åŒã€‚ä¸‹å›¾(B)æ˜¯ä¸ºä»¥é¡¶ç‚¹ 2 ä¸ºæ ¹çš„ BFS çš„ç»“æœã€‚å¯ä»¥å°† BFS çš„æ ‡è®°æ“ä½œçœ‹ä½œæ˜¯æ„å»ºä¸€ä¸ªæœç´¢æ ¹èŠ‚ç‚¹çš„ BFS æ ‘ã€‚æ ‘ç”±æ‰€æœ‰æ ‡è®°çš„é¡¶ç‚¹å’Œåœ¨æœç´¢è¿‡ç¨‹ä¸­ä»ä¸€ä¸ªé¡¶ç‚¹åˆ°ä¸‹ä¸€ä¸ªé¡¶ç‚¹çš„éå†çš„è¾¹ç»„æˆã€‚\n(A and B) Two Examples of BFS Results for Two Different Root Vertices\nä¸‹å›¾å±•ç¤ºäº† BFS åœ¨è®¡ç®—æœºè¾…åŠ©è®¾è®¡ (Computer-Aided Design, CAD) ä¸­çš„ä¸€ä¸ªé‡è¦åº”ç”¨ã€‚è¿·å®«è·¯ç”± (maze routing) å°†èŠ¯ç‰‡è¡¨ç¤ºä¸ºå›¾ã€‚è·¯ç”±å—æ˜¯é¡¶ç‚¹ã€‚ä»é¡¶ç‚¹ i åˆ°é¡¶ç‚¹ j çš„è¾¹è¡¨ç¤ºå¯ä»¥å°†ä¸€æ¡çº¿ä»å— i å»¶ä¼¸åˆ°å— j.\nMaze Routing in Integrated Circuits\n15.3 Vertex-centric Parallelization of BFS ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å¹¶è¡Œå®ç°å°†çº¿ç¨‹åˆ†é…ç»™é¡¶ç‚¹ï¼Œå¹¶è®©æ¯ä¸ªçº¿ç¨‹å¯¹å…¶é¡¶ç‚¹æ‰§è¡Œæ“ä½œï¼Œè¿™é€šå¸¸æ¶‰åŠè¿­ä»£è¯¥é¡¶ç‚¹çš„é‚»å±…ã€‚å½“å¤„ç†ä¸åŒå±‚çº§çš„è¿­ä»£æ—¶ï¼Œå¹¶è¡Œå®ç°éµå¾ªç›¸åŒçš„ç­–ç•¥ã€‚ä¸ºæ¯ä¸€å±‚è°ƒç”¨ä¸€ä¸ªå•ç‹¬çš„å†…æ ¸çš„åŸå› æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦ç­‰å¾…å‰ä¸€å±‚çš„æ‰€æœ‰é¡¶ç‚¹éƒ½è¢«æ ‡è®°ï¼Œç„¶åå†ç»§ç»­æ ‡è®°ä¸‹ä¸€å±‚çš„é¡¶ç‚¹ã€‚ä¸‹é¢å®ç°äº†ä¸€ä¸ª BFS å†…æ ¸ï¼Œæ ¹æ®å‰ä¸€ä¸ªå±‚çº§çš„é¡¶ç‚¹æ ‡ç­¾æ¥æ ‡è®°å±äºè¯¥å±‚çº§çš„æ‰€æœ‰é¡¶ç‚¹ã€‚è¯¥å†…æ ¸å°†æ¯ä¸ªçº¿ç¨‹åˆ†é…ç»™ä¸€ä¸ªé¡¶ç‚¹ï¼Œæ£€æŸ¥å…¶é¡¶ç‚¹æ˜¯å¦å±äºå‰ä¸€å±‚ã€‚å¦‚æœæ˜¯ï¼Œçº¿ç¨‹å°†éå†å‡ºè¾¹ï¼Œå°†æ‰€æœ‰æœªè®¿é—®çš„é‚»å±…æ ‡è®°ä¸ºå±äºå½“å‰çº§åˆ«ã€‚è¿™ç§ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å®ç°é€šå¸¸è¢«ç§°ä¸ºè‡ªé¡¶å‘ä¸‹æˆ– push å®ç°ï¼Œå› ä¸ºå…¶éœ€è¦è®¿é—®ç»™å®šæºé¡¶ç‚¹çš„å‡ºè¾¹ã€‚å¤šä¸ªçº¿ç¨‹å¯ä»¥å°†è¯¥æ ‡å¿—èµ‹å€¼ä¸º 1ï¼Œä»£ç ä»ç„¶å¯ä»¥æ­£ç¡®æ‰§è¡Œã€‚è¿™ä¸ªæ€§è´¨ç§°ä¸ºå¹‚ç­‰æ€§ (idempotence).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct CSRGRAPH { int numVertices; int* scrPtrs; // Strating outgoing edge index of each vertex int* dstList; // Destination vertex index of each edge }; __global__ void bfs_kernel_csr(CSRGRAPH graph, unsigned int* level, unsigned int* visited, unsigned int currLevel) { unsigned vertexId = blockIdx.x * blockDim.x + threadIdx.x; if (vertexId \u0026lt; graph.numVertices) { if (level[vertexId] == currLevel - 1) { for (int i = graph.scrPtrs[vertexId]; i \u0026lt; graph.scrPtrs[vertexId + 1]; i++) { unsigned int neighbor = graph.dstList[i]; if (level[neighbor] == 0xFFFFFFFF) { // unvisited neighbor level[neighbor] = currLevel; visited[neighbor] = 1; *visited = 1; // flag to indicate whether reached the end of the graph } } } } } ä¸‹å›¾å±•ç¤ºäº†è¯¥å†…æ ¸å¦‚ä½•æ‰§è¡Œä»ç¬¬ 1 å±‚ (currLevel-1) åˆ°ç¬¬ 2 å±‚ (currLevel) çš„éå†ã€‚\nExample of a Vertex-centric Push BFS Traversal from Level 1 to Level 2\nç¬¬äºŒä¸ªä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å¹¶è¡Œå®ç°å°†æ¯ä¸ªçº¿ç¨‹åˆ†é…ç»™ä¸€ä¸ªé¡¶ç‚¹ï¼Œè¿­ä»£é¡¶ç‚¹çš„å…¥è¾¹ã€‚æ¯ä¸ªçº¿ç¨‹é¦–å…ˆæ£€æŸ¥å…¶é¡¶ç‚¹æ˜¯å¦å·²è¢«è®¿é—®ã€‚å¦‚æœæ²¡è¢«è®¿é—®ï¼Œçº¿ç¨‹å°†éå†å…¥è¾¹ï¼Œå¦‚æœçº¿ç¨‹æ‰¾åˆ°ä¸€ä¸ªå±äºå‰ä¸€å±‚çš„é‚»å±…ï¼Œçº¿ç¨‹å°†æŠŠå®ƒçš„é¡¶ç‚¹æ ‡è®°ä¸ºå±äºå½“å‰å±‚ã€‚è¿™ç§ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å®ç°é€šå¸¸è¢«ç§°ä¸ºè‡ªåº•å‘ä¸Šæˆ– pull å®ç°ã€‚å®ç°è¦æ±‚èƒ½è®¿é—®ç»™å®šç›®æ ‡é¡¶ç‚¹çš„å…¥è¾¹ï¼Œå› æ­¤è¦é‡‡ç”¨ CSC è¡¨ç¤ºã€‚ ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„ pull å®ç°çš„å†…æ ¸ä»£ç å¦‚ä¸‹ï¼Œå¯¹äºä¸€ä¸ªçº¿ç¨‹æ¥è¯´ï¼Œè¦ç¡®å®šå®ƒçš„é¡¶ç‚¹å¤„äºå½“å‰å±‚ï¼Œåªéœ€è¦è¯¥é¡¶ç‚¹æœ‰ä¸€ä¸ªé‚»å±…så±äºå‰ä¸€å±‚ä¸­å°±è¶³å¤Ÿäº†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct CSCGRAPH { int numVertices; int* dstPtrs; // Starting incoming edge index of each vertex int* scrList; // Source vertex index of each edge }; __global__ void bfs_kernel_csc(CSCGRAPH graph, unsigned int* level, unsigned int* visited, unsigned int currLevel) { unsigned vertexId = blockIdx.x * blockDim.x + threadIdx.x; if (vertexId \u0026lt; graph.numVertices) { if (level[vertexId] == 0xFFFFFFF) { // loop through its incoming edges if not visited for (int i = graph.dstPtrs[vertexId]; i \u0026lt; graph.dstPtrs[vertexId + 1]; i++) { unsigned int neighbor = graph.scrList[i]; if (level[neighbor] == currLevel - 1) { level[vertexId] = currLevel; *visited = 1; // flag to indicate whether reached the end of the graph break; // Only need 1 neighbor in previous level to identify the vetex is currLevel } } } } } ä¸‹å›¾å±•ç¤ºäº†è¿™ä¸ªå†…æ ¸å¦‚ä½•æ‰§è¡Œä»ç¬¬ 1 å±‚åˆ°ç¬¬ 2 å±‚çš„éå†ã€‚\nExample of a Vertex-centric Pull (bottom-up) Traversal from Level 1 to Level 2\nåœ¨æ¯”è¾ƒæ¨å’Œæ‹‰ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å¹¶è¡Œå®ç°æ—¶ï¼Œéœ€è¦è€ƒè™‘ä¸¤ä¸ªå¯¹æ€§èƒ½æœ‰é‡è¦å½±å“çš„å…³é”®å·®å¼‚ã€‚\nåœ¨ push å®ç°ä¸­ï¼Œçº¿ç¨‹åœ¨å…¶é¡¶ç‚¹çš„å¾ªç¯éå†æ‰€æœ‰é‚»å±…ï¼›è€Œåœ¨ pull å®ç°ä¸­ï¼Œçº¿ç¨‹å¯èƒ½ä¼šæå‰è·³å‡ºå¾ªç¯ã€‚ åœ¨ push å®ç°ä¸­ï¼Œåªæœ‰è¢«æ ‡è®°ä¸ºå‰ä¸€å±‚çš„é¡¶ç‚¹çš„çº¿ç¨‹åœ¨éå†å…¶é‚»å±…åˆ—è¡¨ï¼›è€Œåœ¨ pull å®ç°ä¸­ï¼Œä»»ä½•è¢«æ ‡è®°ä¸ºæœªè®¿é—®é¡¶ç‚¹çš„çº¿ç¨‹ä¼šéå†å…¶é‚»å±…åˆ—è¡¨ã€‚ åŸºäºä¸¤ç§å®ç°çš„å·®å¼‚ï¼Œå¸¸è§çš„ä¼˜åŒ–æ–¹æ³•æ˜¯å¯¹ä½å±‚çº§ä½¿ç”¨ push å®ç°ï¼Œç„¶åå¯¹è¾ƒé«˜å±‚çº§ä½¿ç”¨ pull å®ç°ã€‚è¿™ç§æ–¹æ³•é€šå¸¸è¢«ç§°ä¸ºæ–¹å‘ä¼˜åŒ– (directional optimization) å®ç°ã€‚é€‰æ‹©ä½•æ—¶åˆ‡æ¢é€šå¸¸å–å†³äºå›¾çš„ç±»å‹ã€‚ä½åº¦å›¾é€šå¸¸æœ‰å¾ˆå¤šå±‚ï¼›é«˜åº¦å›¾ä¸­ï¼Œä»ä»»ä½•é¡¶ç‚¹åˆ°ä»»ä½•å…¶ä»–é¡¶ç‚¹åªéœ€è¦å¾ˆå°‘çš„å±‚ã€‚å› æ­¤å¯¹äºé«˜åº¦å›¾æ¥è¯´ä» push å®ç°åˆ‡æ¢åˆ° pull å®ç°é€šå¸¸æ¯”ä½åº¦å›¾è¦æ—©å¾—å¤šã€‚ å¦‚æœè¦ä½¿ç”¨æ–¹å‘ä¼˜åŒ–çš„å®ç°ï¼Œåˆ™å›¾çš„ CSR å’Œ CSC è¡¨ç¤ºéƒ½éœ€è¦å‚¨å­˜ã€‚ä½†å¯¹äºæ— å‘å›¾æ¥è¯´ï¼Œå…¶é‚»æ¥çŸ©é˜µæ˜¯å¯¹ç§°çš„ï¼Œå› æ­¤ CSR å’Œ CSC è¡¨ç¤ºæ˜¯ç›¸åŒçš„çš„ï¼Œåªéœ€è¦å­˜å‚¨å…¶ä¸­ä¸€ä¸ªï¼Œå°±å¯ä»¥è¢«ä¸¤ä¸ªå®ç°ä½¿ç”¨ã€‚ 15.4 Edge-centric Parallelization of BFS åœ¨è¿™ä¸ªå®ç°ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹è¢«åˆ†é…åˆ°ä¸€æ¡è¾¹ã€‚å®ƒæ£€æŸ¥è¾¹çš„æºé¡¶ç‚¹æ˜¯å¦å±äºå‰ä¸€å±‚ä»¥åŠè¾¹çš„ç›®æ ‡é¡¶ç‚¹æ˜¯å¦æœªè¢«è®¿é—®ã€‚ ä»¥è¾¹ä¸ºä¸­å¿ƒçš„å¹¶è¡Œå®ç°çš„å†…æ ¸ä»£ç å¦‚ä¸‹ã€‚æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ COO src æ•°ç»„æ‰¾åˆ°å…¶è¾¹ç¼˜çš„æºé¡¶ç‚¹ï¼Œå¹¶æ£€æŸ¥é¡¶ç‚¹æ˜¯å¦å±äºå‰ä¸€çº§ã€‚é€šè¿‡æ­¤æ£€æŸ¥çš„çº¿ç¨‹å°†ä½¿ç”¨ COO dst æ•°ç»„ç¡®å®šè¾¹çš„ç›®çš„é¡¶ç‚¹ï¼Œå¹¶æ£€æŸ¥å…¶æ˜¯å¦æœªè¢«è®¿é—®è¿‡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct COOGRAPH { int numVertices; int numEdges; int* srcList; // Source vertex index of each edge int* dstList; // Destination vertex index of each edge }; __global__ void bfs_kernel_coo(COOGRAPH graph, unsigned int* level, unsigned int* visited, unsigned int currLevel) { unsigned edgeId = blockIdx.x * blockDim.x + threadIdx.x; if (edgeId \u0026lt; graph.numEdges) { unsigned int src = graph.srcList[edgeId]; if (level[src] == currLevel - 1) { unsigned int neighbor = graph.dstList[edgeId]; if (level[neighbor] == 0xFFFFFFFF) { // unvisited neighbor level[neighbor] = currLevel; visited[neighbor] = 1; *visited = 1; // flag to indicate whether reached the end of the graph } } } } ä¸‹å›¾å±•ç¤ºäº†è¯¥å†…æ ¸å¦‚ä½•æ‰§è¡Œä»ä»ç¬¬ 1 å±‚åˆ°ç¬¬ 2 å±‚çš„éå†ã€‚\nExample of an Edge-centric Traversal from Level 1 to Level 2\nä¸ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å¹¶è¡Œå®ç°ç›¸æ¯”ï¼Œä»¥è¾¹ä¸ºä¸­å¿ƒçš„å¹¶è¡Œå®ç°çš„ä¼˜ç‚¹å¦‚ä¸‹\næœ‰æ›´å¤šçš„å¹¶è¡Œæ€§ã€‚åœ¨ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å®ç°ä¸­ï¼Œå¦‚æœé¡¶ç‚¹çš„æ•°é‡å¾ˆå°‘ï¼Œå¯èƒ½ä¸ä¼šå¯åŠ¨è¶³å¤Ÿçš„çº¿ç¨‹æ¥å®Œå…¨å ç”¨è®¾å¤‡ã€‚å› ä¸ºä¸€ä¸ªå›¾é€šå¸¸æœ‰æ¯”é¡¶ç‚¹æ›´å¤šçš„è¾¹ï¼Œä»¥è¾¹ä¸ºä¸­å¿ƒçš„å®ç°å¯ä»¥å¯åŠ¨æ›´å¤šçš„çº¿ç¨‹ã€‚ å…·æœ‰è¾ƒå°çš„è´Ÿè½½ä¸å¹³è¡¡å’Œæ§åˆ¶å‘æ•£ã€‚åœ¨ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å®ç°ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹è¿­ä»£ä¸åŒæ•°é‡çš„è¾¹ã€‚ç›¸åï¼Œåœ¨ä»¥è¾¹ä¸ºä¸­å¿ƒçš„å®ç°ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹åªéå†ä¸€ä¸ªè¾¹ã€‚ ä»¥è¾¹ä¸ºä¸­å¿ƒçš„å®ç°çš„ç¼ºç‚¹å¦‚ä¸‹ éœ€è¦æ£€æŸ¥å›¾ä¸­çš„æ¯æ¡è¾¹ã€‚ç›¸åï¼Œä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å®ç°ä¸­ï¼Œå¦‚æœç¡®å®šé¡¶ç‚¹ä¸å½“å‰å±‚çº§æ— å…³ï¼Œåˆ™ä¼šè·³è¿‡æ•´ä¸ªè¾¹åˆ—è¡¨ã€‚ ä½¿ç”¨ COO æ ¼å¼å­˜å‚¨å›¾ï¼Œä¸ä»¥é¡¶ç‚¹ä¸ºä¸­å¿ƒçš„å®ç°ä½¿ç”¨çš„ CSR å’Œ CSC ç›¸æ¯”ï¼Œå®ƒéœ€è¦æ›´å¤šçš„å­˜å‚¨ç©ºé—´æ¥å­˜å‚¨è¾¹ã€‚ 15.5 Improving efficiency with frontiers åœ¨å‰ä¸¤èŠ‚ä¸­çš„æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬ä¼šæ£€æŸ¥æ¯ä¸ªé¡¶ç‚¹æˆ–æ¯æ¡è¾¹æ˜¯å¦å±å’Œå½“å‰å±‚æœ‰å…³ã€‚è¿™ç§ç­–ç•¥çš„ä¼˜ç‚¹æ˜¯å†…æ ¸æ˜¯é«˜åº¦å¹¶è¡Œçš„ï¼Œå¹¶ä¸”ä¸éœ€è¦è·¨çº¿ç¨‹è¿›è¡Œä»»ä½•åŒæ­¥ã€‚ç¼ºç‚¹æ˜¯å¯åŠ¨äº†è®¸å¤šä¸å¿…è¦çš„çº¿ç¨‹ï¼Œå¹¶æ‰§è¡Œäº†å¤§é‡æ— ç”¨çš„å·¥ä½œã€‚æˆ‘ä»¬å¯ä»¥è®©å¤„ç†å‰ä¸€å±‚é¡¶ç‚¹çš„çº¿ç¨‹å°†å®ƒä»¬è®¿é—®çš„é¡¶ç‚¹ä½œä¸º frontier. å› æ­¤ï¼Œå¯¹äºå½“å‰å±‚çº§ï¼Œåªéœ€è¦ä¸ºè¯¥ frontier ä¸­çš„é¡¶ç‚¹å¯åŠ¨çº¿ç¨‹ã€‚\nExample of a Vertex-centric Push (top-down) BFS Traversal from Level 1 to Level 2 with Frontiers\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ã€‚é¦–å…ˆä¸º frontier çš„æ¯ä¸ªå…ƒç´ åˆ†é…ä¸€ä¸ªçº¿ç¨‹ï¼Œä½¿ç”¨ CSR srcPtrs æ•°ç»„æ¥å®šä½é¡¶ç‚¹çš„å‡ºè¾¹å¹¶è¿›è¡Œè¿­ä»£ã€‚å¯¹äºæ¯ä¸ªå‡ºè¾¹ï¼Œçº¿ç¨‹ä½¿ç”¨ CSR dst æ•°ç»„ç¡®å®šå…¶ç›®çš„é¡¶ç‚¹ï¼Œè‹¥æœªè¢«è®¿é—®è¿‡ï¼Œå¹¶å°†å…¶æ ‡è®°ä¸ºå±äºå½“å‰å±‚çº§ã€‚ä¸ºäº†é¿å…å¤šä¸ªçº¿ç¨‹å°†é‚»å±…è§†ä¸ºæœªè®¿é—®ï¼Œåº”è¯¥ä»¥åŸå­æ–¹å¼æ‰§è¡Œé‚»å±…æ ‡ç­¾çš„æ£€æŸ¥å’Œæ›´æ–°ã€‚atomicCAS å†…ç½®å‡½æ•°æä¾› compare-and-swap çš„åŸå­æ“ä½œã€‚å¦‚æœæ¯”è¾ƒæˆåŠŸ,ä¸å…¶ä»–åŸå­æ“ä½œä¸€æ ·ï¼ŒatomicCAS è¿”å›å­˜å‚¨çš„æ—§å€¼ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯”è¾ƒè¿”å›å€¼ä¸è¢«æ¯”è¾ƒçš„å€¼æ¥æ£€æŸ¥è¯¥é¡¶ç‚¹æ˜¯å¦è¢«è®¿é—®è¿‡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 __global__ void frontier_bfs_kernel(CSRGRAPH graph, unsigned int* level, unsigned int* prevFroniter, unsigned int* currFroniter, unsigned int numPrevFroniter, unsigned int* numCurrFroniter, unsigned int* currLevel) { // Each thread processes a node in prevFroniter. unsigned int i = blockIdx.x * blockDim.x + threadIdx.x; if (i \u0026lt; numPrevFroniter) { unsigned int vertexId = prevFroniter[i]; // All its neighbouring nodes are traversed. for (unsigned int edge = graph.scrPtrs[vertexId]; edge \u0026lt; graph.scrPtrs[vertexId + 1]; edge++) { unsigned int neighbor = graph.dstList[edge]; if (atomicCAS(level + neighbor, 0xFFFFFFFF, currLevel) == 0xFFFFFFFF) { // check if neighbor is unvisited unsigned int currFroniterIndex = atomicAdd(numCurrFroniter, 1); currFroniter[currFroniterIndex] = neighbor; } } } } è¿™ç§åŸºäº frontier çš„æ–¹æ³•çš„ä¼˜åŠ¿åœ¨äºï¼Œå®ƒé€šè¿‡åªå¯åŠ¨å¤„ç†ç›¸å…³é¡¶ç‚¹çš„çº¿ç¨‹å‡å°‘äº†å†—ä½™å·¥ä½œã€‚ç¼ºç‚¹æ˜¯é•¿å»¶è¿ŸåŸå­æ“ä½œçš„å¼€é”€ï¼Œç‰¹åˆ«æ˜¯å½“è¿™äº›æ“ä½œç«äº‰è®¿é—®ç›¸åŒçš„åœ°å€æ—¶ã€‚å¯¹äº atomicAdd æ“ä½œäº‰ç”¨ä¼šå¾ˆé«˜ï¼Œå› ä¸ºæ‰€æœ‰çº¿ç¨‹éƒ½å¢åŠ åŒä¸€ä¸ªè®¡æ•°å™¨ã€‚\n15.6 Reducing Contention with Privatization ç§æœ‰åŒ–å¯ä»¥åº”ç”¨äºå¯¹ numCurrFrontier çš„å¢åŠ ï¼Œä»¥å‡å°‘æ’å…¥ frontier æ—¶çš„äº‰ç”¨ã€‚æˆ‘ä»¬å¯ä»¥è®©æ¯ä¸ªçº¿ç¨‹å—åœ¨æ•´ä¸ªè®¡ç®—è¿‡ç¨‹ä¸­ç»´æŠ¤è‡ªå·±çš„æœ¬åœ° frontierï¼Œå¹¶åœ¨å®Œæˆåæ›´æ–°å…¨å±€ frontier. æœ¬åœ° frontier åŠå…¶è®¡æ•°å™¨å¯ä»¥å­˜å‚¨åœ¨å…±äº«å†…å­˜ä¸­ï¼Œä»è€Œæ”¯æŒå¯¹è®¡æ•°å™¨å’Œå­˜å‚¨åˆ°æœ¬åœ°è¾¹ç•Œçš„ä½å»¶è¿ŸåŸå­æ“ä½œã€‚æ­¤å¤–ï¼Œå½“å°†å…±äº«å†…å­˜ä¸­çš„ frontier å­˜å‚¨åˆ°å…¨å±€å†…å­˜ä¸­çš„å…¬å…± frontier æ—¶ï¼Œè®¿é—®å¯ä»¥åˆå¹¶ã€‚\nä¸‹å›¾è¯´æ˜äº† frontier ç§æœ‰åŒ–çš„æ‰§è¡Œæƒ…å†µã€‚\nPrivatization of Frontiers Example\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ã€‚æ³¨æ„åˆ°å…¬å…± frontiner çš„ç´¢å¼• currFrontierIdx æ˜¯ç”¨ currFrontierIdx_s è¡¨ç¤ºçš„ï¼Œè€Œ currFrontierIdx_s æ˜¯ç”¨ threadIdx.x è¡¨ç¤ºçš„ã€‚å› æ­¤ï¼Œç›¸é‚»çº¿ç¨‹å­˜å‚¨åˆ°è¿ç»­çš„å…¨å±€å†…å­˜ä½ç½®ï¼Œè¿™æ„å‘³ç€å†…å­˜è®¿é—®æ˜¯åˆå¹¶çš„ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #define LOCAL_FRONTIER_SIZE 4 __global__ void private_frontier_bfs_kernel(CSRGRAPH graph, unsigned int* level, unsigned int* prevFroniter, unsigned int* currFroniter, unsigned int numPrevFroniter, unsigned int* numCurrFroniter, unsigned int* currLevel) { // Initialize privative frontier __shared__ unsigned int currFrontier_s[LOCAL_FRONTIER_SIZE]; __shared__ unsigned int numCurrFrontier_s; if (threadIdx.x == 0) { numCurrFrontier_s = 0; } __syncthreads(); // Perform BFS on private frontier unsigned int i = blockIdx.x * blockDim.x + threadIdx.x; if (i \u0026lt; numPrevFroniter) { unsigned int vertexId = prevFroniter[i]; for (unsigned int edge = graph.scrPtrs[vertexId]; edge \u0026lt; graph.scrPtrs[vertexId + 1]; edge++) { unsigned int neighbor = graph.dstList[edge]; if (atomicCAS(level + neighbor, 0xFFFFFFFF, currLevel) == 0xFFFFFFFF) { // Once a new frontier node is found, unsigned currFroniterIndex = atomicAdd(\u0026amp;numCurrFrontier_s, 1); if (currFroniterIndex \u0026lt; LOCAL_FRONTIER_SIZE) { // Try to add it to the private frontier (currFrontier_s) currFrontier_s[currFroniterIndex] = neighbor; } else { numCurrFrontier_s = LOCAL_FRONTIER_SIZE; // frontier is full, stop adding new elements unsigned int currFrontierIdx = atomicAdd(numCurrFroniter, 1); currFroniter[currFrontierIdx] = neighbor; } } } } // Copy private frontier to global frontier __syncthreads(); __shared__ unsigned int currFrontierStartIdx; // Start index of private frontier in global frontier if (threadIdx.x == 0) { currFrontierStartIdx = atomicAdd(numCurrFroniter, numCurrFrontier_s); } __syncthreads(); // Commit private frontier to global frontier for (unsigned int j = threadIdx.x; j \u0026lt; numCurrFrontier_s; j += blockDim.x) { unsigned int currFroniterIdx = currFrontierStartIdx + j; currFroniter[currFroniterIdx] = currFrontier_s[j]; } } ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch15/","summary":"Personal notebook 15 of Programming Massively Parallel","title":"PMPP Learning-Chapter 15 Graph traversal"},{"content":"14 Sparse Matrix Computation åœ¨ç¨€ç–çŸ©é˜µä¸­ï¼Œå¤§å¤šæ•°å…ƒç´ æ˜¯é›¶ã€‚å­˜å‚¨å’Œå¤„ç†è¿™äº›é›¶å…ƒç´ åœ¨å†…å­˜å®¹é‡ã€å†…å­˜å¸¦å®½ã€æ—¶é—´å’Œèƒ½é‡æ–¹é¢æ˜¯æµªè´¹çš„ã€‚\n14.1 Background çŸ©é˜µå¸¸ç”¨äºæ±‚è§£ N ä¸ªæœªçŸ¥æ•° N ä¸ªæ–¹ç¨‹çš„çº¿æ€§ç³»ç»Ÿï¼Œå…¶å½¢å¼ä¸º AX+Y = 0ï¼Œå…¶ä¸­Aæ˜¯ä¸€ä¸ª NxN çŸ©é˜µï¼ŒX æ˜¯ä¸€ä¸ª N ç»´çš„æœªçŸ¥æ•°å‘é‡ï¼ŒY æ˜¯ä¸€ä¸ª N ç»´çš„å¸¸æ•°å‘é‡ã€‚æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„çš„è¿­ä»£æ–¹æ³•ä¸­æœ€è€—æ—¶çš„éƒ¨åˆ†æ˜¯å¯¹è®¡ç®— AX+Yï¼Œè¿™æ˜¯ä¸€ä¸ªç¨€ç–çŸ©é˜µå‘é‡çš„ä¹˜æ³•å’Œç´¯åŠ ã€‚ åˆ é™¤æ‰€æœ‰çš„é›¶å…ƒç´ ä¸ä»…èŠ‚çœäº†å­˜å‚¨ç©ºé—´ï¼Œè€Œä¸”æ¶ˆé™¤äº†ä»å†…å­˜ä¸­è·å–è¿™äº›é›¶å…ƒç´ å¹¶å¯¹å®ƒä»¬æ‰§è¡Œæ— ç”¨çš„ä¹˜æ³•æˆ–åŠ æ³•æ“ä½œçš„å†—ä½™æ­¥éª¤ã€‚ ä»¥ä¸‹æ˜¯ä¸€äº›åœ¨ç¨€ç–çŸ©é˜µå­˜å‚¨æ ¼å¼çš„ç»“æ„ä¸­çš„å…³é”®è€ƒè™‘å› ç´ å¦‚ä¸‹:\nç©ºé—´æ•ˆç‡ (Space efficiency): ä½¿ç”¨å­˜å‚¨æ ¼å¼è¡¨ç¤ºçŸ©é˜µæ‰€éœ€çš„å†…å­˜å®¹é‡ã€‚ çµæ´»æ€§ (Flexibility): é€šè¿‡æ·»åŠ æˆ–åˆ é™¤éé›¶æ¥ä¿®æ”¹çŸ©é˜µçš„å­˜å‚¨æ ¼å¼çš„æ–¹ä¾¿ç¨‹åº¦â€¢ å¯è®¿é—®æ€§ (Accessibility): å­˜å‚¨æ ¼å¼æ˜¯å¦æ˜“äºè®¿é—®æ•°æ®ã€‚ å†…å­˜è®¿é—®æ•ˆç‡ (Memory access efficiency): å­˜å‚¨æ ¼å¼åœ¨å¤šå¤§ç¨‹åº¦ä¸Šä¸ºç‰¹å®šè®¡ç®—å®ç°äº†æœ‰æ•ˆçš„å†…å­˜è®¿é—®æ¨¡å¼ (æ­£åˆ™åŒ–çš„ä¸€ä¸ªæ–¹é¢). è´Ÿè½½å¹³è¡¡ (Load balancing): å­˜å‚¨æ ¼å¼åœ¨å¤šå¤§ç¨‹åº¦ä¸Šä¸ºç‰¹å®šè®¡ç®—åœ¨ä¸åŒçº¿ç¨‹ä¹‹é—´å¹³è¡¡è´Ÿè½½ (æ­£åˆ™åŒ–çš„å¦ä¸€ä¸ªæ–¹é¢). 14.2 A simple SpMV kernel with the COO format å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ COO (COOrdinate) æ ¼å¼æ˜¯ä¸€ç§ç¨€ç–çŸ©é˜µçš„å­˜å‚¨æ ¼å¼ï¼Œå…¶ä¸­çŸ©é˜µå…ƒç´ ä»¥ä¸‰å…ƒç»„çš„å½¢å¼å­˜å‚¨ï¼Œå³ (i, j, a_ij). ã€\nExample of the Coordinate List (COO) Format\nä½¿ç”¨ä»¥ COO æ ¼å¼è¡¨ç¤ºçš„ç¨€ç–çŸ©é˜µå¹¶è¡Œæ‰§è¡Œ SpMV (Sparse Matrix Vector Multiplication) çš„ä¸€ç§æ–¹æ³•æ˜¯ä¸ºçŸ©é˜µä¸­çš„æ¯ä¸ªéé›¶å…ƒç´ åˆ†é…ä¸€ä¸ªçº¿ç¨‹ï¼Œä¸‹å›¾æ˜¯å…¶ç¤ºæ„å›¾ã€‚\nExample of Parallelizing SpMV with the COO Format\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼Œå®ƒåœ¨åˆ—ç´¢å¼•å¯¹åº”çš„ä½ç½®æŸ¥æ‰¾è¾“å…¥å‘é‡å€¼ï¼Œå°†å…¶ä¹˜ä»¥éé›¶å€¼ï¼Œç„¶åå°†ç»“æœç´¯åŠ åˆ°å¯¹åº”çš„è¡Œç´¢å¼•å¤„çš„è¾“å‡ºå€¼ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 struct COOMATRIX { int* rowIdx; int* colIdx; float* val; int numNonZeros; }; __global__ void spmv_coo_kernel(COOMATRIX m, float* x, float* y) { // Assign a thread to each nonzero element unsigned int i = blockIdx.x * blockDim.x + threadIdx.x; if (i \u0026lt; m.numNonZeros) { int row = m.rowIdx[i]; int col = m.colIdx[i]; int val = m.val[i]; atomicAdd(\u0026amp;y[row], val * x[col]); // Perform the matrix-vector multiplication } } ä¸‹é¢æ¥åˆ†æ COO æ ¼å¼åœ¨å‡ ä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚\nç©ºé—´æ•ˆç‡ï¼šCOO éœ€è¦ä¸‰ä¸ªæ•°ç»„ï¼ŒrowIdx, colIdx å’Œ valueï¼Œæ¯ä¸ªæ•°ç»„çš„å…ƒç´ æ•°é‡ä¸éé›¶å…ƒç´ çš„æ•°é‡ç›¸åŒã€‚ çµæ´»æ€§ï¼šåªè¦ä»¥ç›¸åŒçš„æ–¹å¼é‡æ–°æ’åº rowIdx, colIdx å’Œ value æ•°ç»„ï¼Œå°±å¯ä»¥åœ¨ä¸ä¸¢å¤±ä»»ä½•ä¿¡æ¯çš„æƒ…å†µä¸‹ä»»æ„åœ°ä»¥ COO æ ¼å¼é‡æ–°æ’åºå…ƒç´ ã€‚ å¯è®¿é—®æ€§æ–¹é¢ï¼šCOO ä¸æ˜“è®¿é—®æŸä¸€è¡Œæˆ–æŸä¸€åˆ—ä¸­çš„æ‰€æœ‰éé›¶å…ƒç´ ã€‚ å†…å­˜è®¿é—®æ•ˆç‡ï¼šç›¸é‚»çº¿ç¨‹è®¿é—® COO æ ¼å¼çš„æ¯ä¸ªæ•°ç»„ä¸­çš„ç›¸é‚»å…ƒç´ ã€‚å› æ­¤ï¼Œé€šè¿‡ SpMV/COO å¯¹çŸ©é˜µçš„è®¿é—®æ˜¯å†…å­˜åˆå¹¶çš„ã€‚ è´Ÿè½½å¹³è¡¡ï¼šç”±äºæ¯ä¸ªçº¿ç¨‹è´Ÿè´£è®¡ç®—ä¸€ä¸ªéé›¶å…ƒç´ ï¼Œæ‰€æœ‰çº¿ç¨‹è´Ÿè´£ç›¸åŒæ•°é‡çš„å·¥ä½œã€‚ SpMV/COO çš„ä¸»è¦ç¼ºç‚¹æ˜¯éœ€è¦ä½¿ç”¨åŸå­æ“ä½œï¼Œéå¸¸è€—æ—¶ã€‚ 14.3 Grouping Row Nonzeros with the CSR Format å¦‚æœå°†åŒä¸€è¡Œä¸­çš„æ‰€æœ‰éé›¶éƒ½åˆ†é…ç»™åŒä¸€ä¸ªçº¿ç¨‹ï¼Œé‚£ä¹ˆè¯¥çº¿ç¨‹å°†æ˜¯å”¯ä¸€æ›´æ–°ç›¸åº”è¾“å‡ºå€¼çš„çº¿ç¨‹ï¼Œåˆ™å¯ä»¥é¿å…åŸå­æ“ä½œã€‚è¿™ç§å¯è®¿é—®æ€§å¯ä»¥é€šè¿‡ CSR (Compressed Sparse Row ) å­˜å‚¨æ ¼å¼å®ç°ã€‚ä¸‹å›¾è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨ CSR æ ¼å¼å­˜å‚¨ 14.1 èŠ‚ä¸­çš„çŸ©é˜µã€‚CSR ä¹Ÿå°†éé›¶å€¼å­˜å‚¨åœ¨ä¸€ç»´æ•°ç»„ä¸­ï¼Œä½†è¿™äº›éé›¶å€¼æ˜¯æŒ‰è¡Œåˆ†ç»„çš„ã€‚COO æ ¼å¼å’Œ CSR æ ¼å¼ä¹‹é—´çš„å…³é”®åŒºåˆ«åœ¨äºï¼ŒCSR æ ¼å¼ç”¨ rowPtrs æ•°ç»„æ›¿æ¢äº† rowIdx æ•°ç»„ï¼ŒrowPtrs æ•°ç»„å­˜å‚¨äº† colIdx å’Œ value æ•°ç»„ä¸­æ¯è¡Œéé›¶çš„èµ·å§‹åç§»é‡ï¼Œæ¯è¡Œä¸­çš„éé›¶å…ƒç´ ä¸ä¸€å®šæŒ‰åˆ—ç´¢å¼•æ’åºã€‚\nExample of Compressed Sparse Row (CSR) Format\nå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¦ä½¿ç”¨ä»¥ CSR æ ¼å¼è¡¨ç¤ºçš„ç¨€ç–çŸ©é˜µå¹¶è¡Œæ‰§è¡Œ SpMVï¼Œå¯ä»¥ä¸ºçŸ©é˜µçš„æ¯ä¸€è¡Œåˆ†é…ä¸€ä¸ªçº¿ç¨‹ã€‚ç”±äºä¸€ä¸ªçº¿ç¨‹éå†ä¸€è¡Œï¼Œæ‰€ä»¥æ¯ä¸ªçº¿ç¨‹å°†è¾“å‡ºå†™å…¥ä¸åŒçš„å†…å­˜ä½ç½®ã€‚\nExample of Parallelizing SpMV with the CSR Format\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ï¼Œæ¯ä¸ªçº¿ç¨‹ç¡®å®šå®ƒè´Ÿè´£çš„è¡Œï¼Œå¾ªç¯éå†è¯¥è¡Œçš„éé›¶å…ƒç´ æ¥æ‰§è¡Œç‚¹ç§¯ã€‚çº¿ç¨‹åœ¨ rowPtrs æ•°ç»„ä¸­ç¡®å®šå®ƒä»¬çš„èµ·å§‹ç´¢å¼• (rowPtrs[row])å’Œé€šè¿‡ä¸‹ä¸€è¡Œéé›¶çš„èµ·å§‹ç´¢å¼• (rowPtrs[row+1]) æ¥ç¡®å®šç»“æŸä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct CSRMatrix { int* rowPtrs; int* colIdx; float* val; int numRows; }; __global__ void spmv_csr_kernel(CSRMatrix m, float* x, float* y) { // Assign a thread to each row unsigned int row = blockIdx.x * blockDim.x + threadIdx.x; if (row \u0026lt; m.numRows) { int start = m.rowPtrs[row]; int end = m.rowPtrs[row + 1]; float sum = 0.0f; for (int i = start; i \u0026lt; end; i++) { int col = m.colIdx[i]; float val = m.val[i]; sum += val * x[col]; } y[row] = sum; // Perform the matrix-vector multiplication } } ä¸‹é¢æ¥åˆ†æ CSR æ ¼å¼åœ¨å‡ ä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚\nç©ºé—´æ•ˆç‡ï¼šCSR éœ€è¦ä¸‰ä¸ªæ•°ç»„ï¼Œå…¶ä¸­ colIdx å’Œ value çš„ç»´åº¦å’Œéé›¶å…ƒç´ çš„æ•°é‡ä¸€æ ·ã€‚rowPtrs ç»´åº¦ç­‰äºè¡Œæ•°åŠ  1. çµæ´»æ€§ï¼šCSR æ ¼å¼ä¸­è¦æ·»åŠ çš„éé›¶å¿…é¡»æ·»åŠ åˆ°å®ƒæ‰€å±çš„ç‰¹å®šè¡Œä¸­ã€‚è¿™æ„å‘³ç€åé¢è¡Œçš„éé›¶å…ƒç´ éƒ½éœ€è¦ç§»åŠ¨ï¼Œåé¢è¡Œçš„è¡ŒæŒ‡é’ˆéƒ½éœ€è¦ç›¸åº”å¢åŠ ã€‚ å¯è®¿é—®æ€§ï¼šCSR å¯ä»¥å¾ˆå®¹æ˜“åœ°è®¿é—®ç»™å®šè¡Œçš„éé›¶å…ƒç´ ï¼Œå…è®¸åœ¨ SpMV/CSR ä¸­è·¨è¡Œå¹¶è¡Œã€‚ å†…å­˜è®¿é—®æ•ˆç‡ï¼šCSR è®¿é—®æ¨¡å¼ä½¿å¾—è¿ç›¸é‚»ç¨‹è®¿é—®çš„æ•°æ®ç›¸è·å¾ˆè¿œï¼Œå¹¶ä¸èƒ½è¿›è¡Œå†…å­˜åˆå¹¶ã€‚ è´Ÿè½½å¹³è¡¡ï¼šçº¿ç¨‹åœ¨ç‚¹ç§¯å¾ªç¯ä¸­è¿›è¡Œçš„è¿­ä»£æ¬¡æ•°å–å†³äºåˆ†é…ç»™çº¿ç¨‹çš„è¡Œä¸­éé›¶å…ƒç´ çš„æ•°é‡ï¼Œå› æ­¤å¤§å¤šæ•°ç”šè‡³æ‰€æœ‰çº¿ç¨‹ä¸­éƒ½å­˜åœ¨æ§åˆ¶å‘æ•£ã€‚ 14.4 Improving Memory Coalescing with the ELL Format ELL å­˜å‚¨æ ¼å¼é€šè¿‡å¯¹ç¨€ç–çŸ©é˜µæ•°æ®è¿›è¡Œå¡«å……å’Œè½¬ç½®ï¼Œå¯ä»¥è§£å†³éåˆå¹¶å†…å­˜è®¿é—®çš„é—®é¢˜ã€‚å®ƒçš„åå­—æ¥æºäº ELLPACK ä¸­çš„ç¨€ç–çŸ©é˜µåŒ…ï¼Œä¸€ä¸ªç”¨äºæ±‚è§£æ¤­åœ†è¾¹å€¼é—®é¢˜çš„åŒ…ã€‚ ä¸€ä¸ªç”¨ ELL æ ¼å¼å­˜å‚¨çš„ä¾‹å­å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ä»æŒ‰è¡Œåˆ†ç»„éé›¶çš„ CSR æ ¼å¼ä¸­ç¡®å®šå…·æœ‰æœ€å¤§éé›¶å…ƒç´ æ•°é‡çš„è¡Œã€‚ç„¶ååœ¨æ‰€æœ‰å…¶ä»–è¡Œçš„éé›¶å…ƒç´ ä¹‹åçš„æ·»åŠ å¡«å……å…ƒç´ ï¼Œä½¿å®ƒä»¬ä¸æœ€å¤§è¡Œé•¿åº¦ç›¸åŒã€‚æœ€åæŒ‰åˆ—ä¸»å…ƒç´ é¡ºåºå­˜å‚¨å¡«å……çŸ©é˜µã€‚\nExample of ELL Storage Format\nä¸‹å›¾ä½¿ç”¨ ELL æ ¼å¼å¹¶è¡ŒåŒ– SpMVã€‚ä¸ CSR ä¸€æ ·ï¼Œæ¯ä¸ªçº¿ç¨‹è¢«åˆ†é…åˆ°çŸ©é˜µçš„ä¸åŒè¡Œã€‚\nExample of Parallelizing SpMV with the ELL Format\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ï¼Œç‚¹ç§¯å¾ªç¯éå†æ¯è¡Œçš„éé›¶å…ƒç´ ã€‚SpMV/ELL å†…æ ¸å‡è®¾è¾“å…¥çŸ©é˜µæœ‰ä¸€ä¸ªå‘é‡ ellMatrix.nnzPerRow è®°å½•æ¯è¡Œä¸­éé›¶çš„æ•°é‡ï¼Œæ¯ä¸ªçº¿ç¨‹åªè¿­ä»£å…¶åˆ†é…çš„è¡Œä¸­çš„éé›¶å…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 struct ELLMATRIX { int* nnzPerRow; // Number of nonzeros per row int* colIdx; // Column indices of nonzeros float* val; // Nonzero values int numRows; // Number of rows }; __global__ void spmv_ell_kernel(ELLMATRIX m, float* x, float* y) { unsigned int row = blockIdx.x * blockDim.x + threadIdx.x; if (row \u0026lt; m.numRows) { float sum = 0.0f; for (unsigned int i = 0; i \u0026lt; m.nnzPerRow[row]; i++) { // ell matrix stores values in column-major order unsigned int col = m.colIdx[i * m.numRows + row]; float val = m.val[i * m.numRows + row]; sum += val * x[col]; } y[row] = sum; // Perform the matrix-vector multiplication } } ä¸‹é¢æ¥åˆ†æ CSR æ ¼å¼åœ¨å‡ ä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚\nç©ºé—´æ•ˆç‡ï¼šç”±äºå¡«å……å…ƒç´ çš„ç©ºé—´å¼€é”€ï¼ŒELLæ ¼å¼çš„ç©ºé—´æ•ˆç‡ä½äºCSRæ ¼å¼ã€‚ çµæ´»æ€§ï¼šELL æ ¼å¼çš„æ¯” CSR æ ¼å¼æœ‰æ›´é«˜çš„çµæ´»æ€§ã€‚åªè¦ä¸€è¡Œæ²¡æœ‰è¾¾åˆ°çŸ©é˜µä¸­éé›¶çš„æœ€å¤§æ•°ç›®ï¼Œå°±å¯ä»¥é€šè¿‡ç®€å•åœ°ç”¨å®é™…å€¼æ›¿æ¢å¡«å……å…ƒç´ æ¥å‘è¯¥è¡Œæ·»åŠ éé›¶ã€‚ å¯è®¿é—®æ€§ï¼šELL å¯ä»¥è®¿é—®æŸä¸€è¡Œçš„éé›¶å…ƒç´ ã€‚ELL è¿˜å…è®¸åœ¨ç»™å®šéé›¶å…ƒç´ çš„ç´¢å¼•åå¾—åˆ°è¯¥å…ƒç´ çš„è¡Œå’Œåˆ—ç´¢å¼•ï¼Œå› ä¸º i = col*m.numRows + row, é€šè¿‡ i % m.numRows å°±å¯ä»¥å¾—åˆ°æ‰€åœ¨çš„è¡Œã€‚ å†…å­˜è®¿é—®æ•ˆç‡ï¼šç”±äºå…ƒç´ æŒ‰åˆ—ä¸»åºæ’åˆ—ï¼Œæ‰€æœ‰ç›¸é‚»çš„çº¿ç¨‹ç°åœ¨éƒ½è®¿é—®ç›¸é‚»çš„å†…å­˜ä½ç½®ã€‚ è´Ÿè½½å¹³è¡¡ï¼šSpMV/ELL ä»ç„¶å’Œ SpMV/CSR å…·æœ‰ç›¸åŒçš„è´Ÿè½½ä¸å¹³è¡¡é—®é¢˜ï¼Œå› ä¸ºæ¯ä¸ªçº¿ç¨‹å¾ªç¯æ¬¡æ•°ä»å–å†³å®ƒè´Ÿè´£çš„è¡Œä¸­çš„éé›¶å…ƒç´ æ•°é‡ã€‚ 14.5 Regulating Padding with the Hybrid ELL-COO Format åœ¨ ELL æ ¼å¼ä¸­ï¼Œå½“ä¸€è¡Œæˆ–å°‘æ•°è¡Œå…·æœ‰éå¸¸å¤šçš„éé›¶å…ƒç´ æ—¶ï¼Œç©ºé—´æ•ˆç‡ä½å’Œæ§åˆ¶å‘æ•£çš„é—®é¢˜æœ€ä¸ºæ˜æ˜¾ã€‚COO æ ¼å¼å¯ç”¨äºé™åˆ¶ ELL æ ¼å¼ä¸­çš„è¡Œé•¿åº¦ã€‚åœ¨å°†ç¨€ç–çŸ©é˜µè½¬æ¢ä¸º ELL ä¹‹å‰ï¼Œæˆ‘ä»¬å¯ä»¥ä»å…·æœ‰å¤§é‡éé›¶å…ƒç´ çš„è¡Œä¸­å–å‡ºä¸€äº›å…ƒç´ ï¼Œå¹¶å°†è¿™äº›å…ƒç´ ç”¨å•ç‹¬çš„ COO æ ¼å¼å­˜å‚¨ã€‚ ä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ··åˆ ELL-COO æ ¼å¼å­˜å‚¨å›¾ä¸­çŸ©é˜µã€‚ä» ELL æ ¼å¼ä¸­åˆ é™¤ç¬¬äºŒè¡Œçš„æœ€å 3 ä¸ªéé›¶å…ƒç´ å’Œç¬¬å…­è¡Œçš„æœ€å 2 ä¸ªéé›¶å…ƒç´ ï¼Œå¹¶å°†å®ƒä»¬ç§»åŠ¨åˆ°å•ç‹¬çš„ COO æ ¼å¼ä¸­ã€‚\nHybrid ELL-COO Example\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ï¼Œç‚¹ç§¯å°†è¢«åˆ’åˆ†ä¸ºä¸¤éƒ¨åˆ†å¤„ç†ï¼Œä¸€éƒ¨åˆ†è´Ÿè´£å¤„ç† ELL æ ¼å¼çš„éé›¶å…ƒç´ ï¼Œå¦ä¸€éƒ¨åˆ†è´Ÿè´£å¤„ç† COO æ ¼å¼ä¸­ rowIdx ä¸ row ç›¸åŒçš„éé›¶å…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 __global__ void spmv_hybrid_ell_coo_kernel(ELLMATRIX ell, COOMATRIX coo, float* x, float* y) { unsigned int row = blockIdx.x * blockDim.x + threadIdx.x; float sum = 0.0f; // ELL part if (row \u0026lt; ell.numRows) { for (int i = 0; i \u0026lt; ell.nnzPerRow[row]; i++) { unsigned int col = ell.colIdx[i * ell.numRows + row]; float val = ell.val[col]; sum += val * x[col]; } } y[row] = sum; // Perform the matrix-vector multiplication // COO part for (int i = 0; i \u0026lt; coo.numNonZeros; i++) { int col = coo.colIdx[i]; float val = coo.val[i]; sum += val * x[col]; atomicAdd(\u0026amp;y[row], val * x[col]); } } ä¸‹é¢æ¥åˆ†ææ··åˆ ELL-COO æ ¼å¼åœ¨å‡ ä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚\nç©ºé—´æ•ˆç‡ï¼šå› ä¸ºå‡å°‘äº†å¡«å……å…ƒç´ ï¼Œæ··åˆ ELL-COO æ ¼å¼æ¯”å•ç‹¬ä½¿ç”¨ ELL æ ¼å¼çš„ç©ºé—´æ•ˆç‡æ›´é«˜ã€‚ çµæ´»æ€§ï¼šæ··åˆ COO-ELL æ—¢å¯ä»¥é€šè¿‡æ›¿æ¢å¡«å……å…ƒç´ æ¥æ·»åŠ éé›¶ã€‚å¦‚æœè¯¥è¡Œæ²¡æœ‰ä»»ä½•å¯ä»¥åœ¨ ELL éƒ¨åˆ†ä¸­æ›¿æ¢çš„å¡«å……å…ƒç´ ï¼Œä¹Ÿå¯ä»¥åœ¨æ ¼å¼çš„ COO éƒ¨åˆ†æ·»åŠ ã€‚ å¯è®¿é—®æ€§ï¼šè®¿é—®ç»™å®šè¡Œä¸­æ‰€æœ‰çš„éé›¶å…ƒç´ åªèƒ½ç”¨äºé€‚åˆç”¨ ELL æ ¼å¼å­˜å‚¨çš„éƒ¨åˆ†è¡Œã€‚ å†…å­˜è®¿é—®æ•ˆç‡ï¼šSpMV/ELL å’Œ SpMV/COO éƒ½èƒ½å¯¹ç¨€ç–çŸ©é˜µè¿›è¡Œåˆå¹¶å†…å­˜è®¿é—®ã€‚å› æ­¤ï¼Œå®ƒä»¬çš„ç»„åˆä¹Ÿå°†æ˜¯åˆå¹¶è®¿é—®æ¨¡å¼ã€‚ è´Ÿè½½å¹³è¡¡ï¼šä»ELL æ ¼å¼éƒ¨åˆ†ç§»é™¤ä¸€äº›éé›¶å…ƒç´ å¯ä»¥å‡å°‘ SpMV/ELL å†…æ ¸çš„æ§åˆ¶å‘æ•£ã€‚è¿™äº›éé›¶å…ƒç´ è¢«æ”¾åœ¨ COO æ ¼å¼éƒ¨åˆ†ï¼Œä¸ä¼šå‡ºç°æ§åˆ¶å‘æ•£ã€‚ 14.6 Reducing Control Divergence with the JDS Format æ ¹æ®çŸ©é˜µä¸­è¡Œçš„éé›¶å…ƒç´ å¤ºå°‘è¿›è¡Œé™åºæ’åºä¹‹åçŸ©é˜µåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šçœ‹èµ·æ¥åƒä¸‰è§’å½¢çŸ©é˜µï¼Œå› æ­¤è¿™ç§æ ¼å¼é€šå¸¸è¢«ç§°ä¸º JDS (Jagged Diagonal Storage) æ ¼å¼ã€‚ ä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ JDS æ ¼å¼å­˜å‚¨çŸ©é˜µã€‚é¦–å…ˆï¼Œä¸ CSR å’Œ ELL æ ¼å¼ä¸€æ ·å°†éé›¶å…ƒç´ æŒ‰è¡Œåˆ†ç»„ã€‚æ¥ä¸‹æ¥ï¼ŒæŒ‰æ¯è¡Œä¸­éé›¶çš„ä¸ªæ•°ä»å¤§åˆ°å°æ’åºã€‚value æ•°ç»„ä¸­çš„éé›¶å€¼åŠå…¶å­˜å‚¨å…¶å¯¹åº”åˆ—ç´¢å¼•çš„ colIdx æ•°ç»„æŒ‰åˆ—ä¸»å…ƒç´ é¡ºåºå­˜å‚¨ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­æ·»åŠ ä¸€ä¸ª iterPtr æ•°ç»„æ¥è·Ÿè¸ªéé›¶å…ƒç´ çš„å¼€å§‹ä½ç½®ã€‚å¹¶ä¸”ç»´æŠ¤ä¸€ä¸ªä¿ç•™åŸå§‹è¡Œç´¢å¼•çš„ rowIdx æ•°ç»„ã€‚\nExample of JDS Storage Format\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ï¼Œæˆ‘ä»¬ä¸€å…±è¦è¿­ä»£ maxNumNonZerosPerRow æ¬¡ï¼Œæ¯æ¬¡è¿­ä»£ä¸­æ¯ä¸ªçº¿ç¨‹åˆ¤æ–­è‡ªå·±è´Ÿè´£çš„è¡Œæ˜¯å¦è¿˜å­˜åœ¨éé›¶å…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 struct JDSMATRIX { int* iterPtr; // Pointer to the start of each row in the JDS format int* colIdx; // Column indices of nonzeros float* val; // Nonzero values int* rowIdx; // Original row indices int numRows; int maxNumNonZerosPerRow; }; __global__ void spmv_jds_kernel(JDSMATRIX m, float* x, float* y) { unsigned int row = blockIdx.x * blockDim.x + threadIdx.x; if (row \u0026lt; m.numRows) { float sum = 0.0f; for (int i = 0; i \u0026lt; m.maxNumNonZerosPerRow + 1; i++) { int start = m.iterPtr[i]; int end = m.iterPtr[i + 1]; if (row + i * blockDim.x \u0026gt;= end) { break; } else { sum += m.val[row + i * blockDim.x]; } } y[m.rowIdx[row]] = sum; // Perform the matrix-vector multiplication } } ä¸‹é¢æ¥åˆ†æ JDS æ ¼å¼åœ¨å‡ ä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚\nç©ºé—´æ•ˆç‡ï¼šå› ä¸ºé¿å…äº†å¡«å…… JDS æ ¼å¼æ¯” ELL æ ¼å¼æ•ˆç‡æ›´é«˜ã€‚ çµæ´»æ€§ï¼šJDS æ ¼å¼çš„çµæ´»æ€§è¾ƒå·®ï¼Œå› ä¸ºæ·»åŠ éé›¶ä¼šæ”¹å˜è¡Œå¤§å°ï¼Œè¿™å¯èƒ½éœ€è¦é‡æ–°å¯¹è¡Œè¿›è¡Œæ’åºã€‚ å¯è®¿é—®æ€§ï¼šJDS æ ¼å¼ç±»ä¼¼äºCSRæ ¼å¼ï¼Œå…è®¸åœ¨ç»™å®šè¡Œç´¢å¼•çš„æƒ…å†µä¸‹è®¿é—®è¯¥è¡Œçš„éé›¶å…ƒç´ ã€‚ å†…å­˜è®¿é—®æ•ˆç‡ï¼šJDS æ ¼å¼çš„å†…å­˜è®¿é—®æ•ˆç‡æ¯” ELL æ ¼å¼é«˜ï¼Œå› ä¸ºå®ƒå¯ä»¥å¯¹ç¨€ç–çŸ©é˜µè¿›è¡Œåˆå¹¶è®¿é—®ã€‚ è´Ÿè½½å¹³è¡¡ï¼šJDS æ ¼å¼å¯¹çŸ©é˜µçš„è¡Œè¿›è¡Œæ’åºï¼Œä½¿å¾—ç›¸é‚»çº¿ç¨‹éé•¿åº¦æ¥è¿‘çš„è¡Œã€‚å› æ­¤ï¼ŒJDS æ ¼å¼èƒ½å‡å°‘æ§åˆ¶å‘æ•£ã€‚ ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch14/","summary":"Personal notebook 14 of Programming Massively Parallel","title":"PMPP Learning-Chapter 14 Sparse Matrix Computation"},{"content":"13 Sorting æ’åºç®—æ³•å°†åˆ—è¡¨ä¸­çš„æ•°æ®å…ƒç´ æŒ‰ä¸€å®šçš„é¡ºåºæ’åˆ—ã€‚\n13.1 Background ä»»ä½•æ’åºç®—æ³•éƒ½å¿…é¡»æ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªæ¡ä»¶:\nè¾“å‡ºæ˜¯éé€’å‡é¡ºåºæˆ–éé€’å¢é¡ºåºã€‚ è¾“å‡ºæ˜¯è¾“å…¥çš„ä¸€ç§æ’åˆ— (permutation). æ’åºç®—æ³•å¯ä»¥åˆ†ä¸ºç¨³å®šç®—æ³•å’Œä¸ç¨³å®šç®—æ³•ã€‚å½“ä¸¤ä¸ªå…ƒç´ å…·æœ‰ç›¸åŒçš„é”®å€¼æ—¶ï¼Œç¨³å®šçš„æ’åºç®—æ³•ä¿ç•™äº†åŸå§‹çš„å‡ºç°é¡ºåºã€‚ æ’åºç®—æ³•ä¹Ÿå¯ä»¥åˆ†ä¸ºåŸºäºæ¯”è¾ƒçš„ç®—æ³•å’ŒéåŸºäºæ¯”è¾ƒçš„ç®—æ³•ã€‚åŸºäºæ¯”è¾ƒçš„æ’åºç®—æ³•æ— æ³•è¾¾åˆ°æ¯” O(NlogN) æ›´å¥½çš„å¤æ‚åº¦ï¼Œå› ä¸ºå®ƒä»¬å¿…é¡»åœ¨å…ƒç´ ä¹‹é—´æ‰§è¡Œæœ€å°‘æ¬¡æ•°çš„æ¯”è¾ƒã€‚\n13.2 Radix Sort åŸºæ•°æ’åºæ˜¯ä¸€ç§åŸºäºéæ¯”è¾ƒçš„æ’åºç®—æ³•ï¼Œå…¶å·¥ä½œåŸç†æ˜¯æ ¹æ®åŸºæ•°å€¼å°†è¦æ’åºçš„é”®åˆ†å¸ƒåˆ°æ¡¶ (bucket) ä¸­ã€‚å¦‚æœé”®ç”±å¤šä¸ªæ•°å­—ç»„æˆï¼Œåˆ™é‡å¤å¯¹æ¯ä¸ªæ•°å­—é‡å¤åˆ†é…æ¡¶ï¼Œç›´åˆ°è¦†ç›–æ‰€æœ‰æ•°å­—ã€‚ ä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ 1 ä½åŸºæ•°å¯¹ 4 ä½æ•´æ•°åˆ—è¡¨è¿›è¡ŒåŸºæ•°æ’åºã€‚\nA Radix Sort Example\n13.3 Parallel Radix Sort åŸºæ•°æ’åºçš„æ¯æ¬¡è¿­ä»£éƒ½ä¾èµ–äºå‰ä¸€æ¬¡è¿­ä»£çš„æ•´ä¸ªç»“æœã€‚å› æ­¤ï¼Œè¿­ä»£æ˜¯ç›¸å¯¹äºå½¼æ­¤é¡ºåºæ‰§è¡Œçš„ã€‚æˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨æ‰§è¡Œå•ä¸ªåŸºæ•°æ’åºè¿­ä»£çš„å†…æ ¸çš„å®ç°ï¼Œå¹¶å‡è®¾ä¸»æœºä»£ç æ¯æ¬¡è¿­ä»£è°ƒç”¨è¯¥å†…æ ¸ä¸€æ¬¡ã€‚ åœ¨ GPU ä¸Šå¹¶è¡ŒåŒ–åŸºæ•°æ’åºè¿­ä»£çš„ä¸€ç§ç›´æ¥æ–¹æ³•æ˜¯è®©æ¯ä¸ªçº¿ç¨‹è´Ÿè´£è¾“å…¥åˆ—è¡¨ä¸­çš„ä¸€ä¸ªé”®ã€‚çº¿ç¨‹å¿…é¡»ç¡®å®šé”®åœ¨è¾“å‡ºåˆ—è¡¨ä¸­çš„ä½ç½®ï¼Œç„¶åå°†é”®å­˜å‚¨åˆ°è¯¥ä½ç½®ã€‚ ä¸‹å›¾å±•ç¤ºäº†è¿™ç§å¹¶è¡ŒåŒ–æ–¹æ³•ç¬¬ä¸€æ¬¡è¿­ä»£çš„æ‰§è¡Œæƒ…å†µã€‚å¯¹äºæ˜ å°„åˆ° 0 æ¡¶çš„é”®ï¼Œç›®æ ‡ç´¢å¼•å¯ä»¥é€šè¿‡å¦‚ä¸‹å…¬å¼è®¡ç®—ï¼š $$\r\\begin{align*} \\text{destination of a zero} \u0026= \\text{\\#zeros before} \\\\\r\u0026=\\text{\\#keys before} - \\text{\\#ones before} \\\\\r\u0026=\\text{key index}-\\text{\\#ones before}\r\\end{align*}\r$$å¯¹äºæ˜ å°„åˆ° 1 æ¡¶çš„é”®ï¼Œç›®æ ‡ç´¢å¼•å¦‚ä¸‹æ‰€ç¤º:\n$$\r\\begin{align*}\r\\text{destination of a one}\u0026=\\text{\\#zeros in total}+\\text{\\#ones before} \\\\\r\u0026=(\\text{\\#keys in total}-\\text{\\#ones in total})+\\text{\\#ones before} \\\\\r\u0026=\\text{input size}-\\text{\\#ones in total}+\\text{\\#ones before}\r\\end{align*}\r$$\rParallelizing a Radix Sort Iteration by Assigning One Input Key to Each Thread\nä¸‹å›¾å±•ç¤ºäº†æ¯ä¸ªçº¿ç¨‹æŸ¥æ‰¾å…¶é”®çš„ç›®æ ‡ç´¢å¼•æ‰€æ‰§è¡Œçš„æ“ä½œã€‚\nFinding the Destination of Each Input Key\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚åœ¨æ¯ä¸ªçº¿ç¨‹ç¡®å®šè‡ªå·±çš„ç´¢å¼•å¹¶æå–å‡ºå¯¹åº”çš„ bit åï¼Œå› ä¸ºè¿™äº›ä½ä¸æ˜¯ 0 å°±æ˜¯ 1ï¼Œæ‰€ä»¥æ’é™¤æ‰«æçš„ç»“æœå°±ç­‰äºç´¢å¼•å‰é¢ 1 çš„ä¸ªæ•°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 __global__ void exclusiveScan(unsigned int* bits, int N) { extern __shared__ unsigned int temp[]; int thid = threadIdx.x; int offset = 1; // Load input into shared memory temp[2 * thid] = (2 * thid \u0026lt; N) ? bits[2 * thid] : 0; temp[2 * thid + 1] = (2 * thid + 1 \u0026lt; N) ? bits[2 * thid + 1] : 0; // Build sum in place up the tree for (int d = N \u0026gt;\u0026gt; 1; d \u0026gt; 0; d \u0026gt;\u0026gt;= 1) { __syncthreads(); if (thid \u0026lt; d) { int ai = offset * (2 * thid + 1) - 1; int bi = offset * (2 * thid + 2) - 1; temp[bi] += temp[ai]; } offset *= 2; } // Clear the last element if (thid == 0) { temp[N - 1] = 0; } // Traverse down the tree for (int d = 1; d \u0026lt; N; d *= 2) { offset \u0026gt;\u0026gt;= 1; __syncthreads(); if (thid \u0026lt; d) { int ai = offset * (2 * thid + 1) - 1; // left child index of the thread int bi = offset * (2 * thid + 2) - 1; // right unsigned int t = temp[ai]; temp[ai] = temp[bi]; temp[bi] += t; } } // Write results to output array __syncthreads(); if (2 * thid \u0026lt; N) bits[2 * thid] = temp[2 * thid]; if (2 * thid + 1 \u0026lt; N) bits[2 * thid + 1] = temp[2 * thid + 1]; } __global__ void radix_sort_iter(unsigned int* input, unsigned int* output, unsigned int* bits, int N, unsigned int iter) { unsigned int i = blockIdx.x * blockDim.x + threadIdx.x; unsigned int key, bit; if (i \u0026lt; N) { key = input[i]; bit = (key \u0026gt;\u0026gt; iter) \u0026amp; 1; bits[i] = bit; } exclusiveScan(bits, N); // # ones before if (i \u0026lt; N) { unsigned int numberOnesBefore = bits[i]; unsigned int numberOnesTotal = bits[N]; unsigned int dst = (bit == 0) ? (i - numberOnesBefore) : (N - numberOnesTotal - numberOnesBefore); output[dst] = key; } } 13.4 Optimizing for Memory Coalescing ä¸Šé¢æ–¹æ³•æ•ˆç‡ä½ä¸‹çš„ä¸€ä¸ªä¸»è¦åŸå› æ˜¯ï¼Œå¯¹è¾“å‡ºæ•°ç»„çš„å†™å…¥æ˜¾ç¤ºå‡ºä¸èƒ½ä»¥å†…å­˜åˆå¹¶çš„æ¨¡å¼è®¿é—®ã€‚æ”¹è¿›åçš„ç®—æ³•å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¯ä¸ªå—ä¸­çš„çº¿ç¨‹å°†é¦–å…ˆæ‰§è¡Œå—çº§åˆ«çš„å±€éƒ¨æ’åºï¼Œä»¥åˆ†ç¦»å…±äº«å†…å­˜ä¸­æ˜ å°„åˆ° 0 bucket çš„é”®å’Œæ˜ å°„åˆ° 1 bucket çš„é”®ã€‚æ­¤ä¼˜åŒ–ä¸­çš„ä¸»è¦æŒ‘æˆ˜æ˜¯æ¯ä¸ªçº¿ç¨‹å—åœ¨å…¨å±€ bucket ä¸­ç¡®å®šå…¶ä½ç½®ã€‚çº¿ç¨‹å—çš„ 0 æ¡¶çš„ä½ç½®åœ¨å‰é¢çº¿ç¨‹å—çš„æ‰€æœ‰ 0 æ¡¶ä¹‹åã€‚å¦ä¸€æ–¹é¢ï¼Œçº¿ç¨‹å—çš„ 1 æ¡¶çš„ä½ç½®åœ¨æ‰€æœ‰çº¿ç¨‹å—çš„ 0 æ¡¶å’Œä¹‹å‰çº¿ç¨‹å—çš„æ‰€æœ‰ 1 æ¡¶ä¹‹åã€‚\nOptimizing for Memory Coalescing by Sorting Locally in Shared Memory\nä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ’é™¤æ‰«ææ¥æŸ¥æ‰¾æ¯ä¸ªçº¿ç¨‹å—çš„æœ¬åœ°æ¡¶çš„ä½ç½®çš„ã€‚åœ¨å®Œæˆå±€éƒ¨åŸºæ•°æ’åºä¹‹åï¼Œæ¯ä¸ªçº¿ç¨‹å—æ ‡è¯†å…¶æ¯ä¸ªè‡ªå·±æ¡¶ä¸­é”®çš„æ•°é‡ã€‚ç„¶åæ¯ä¸ªå—å°†ç»“æœè®°å½•åœ¨å¦‚å›¾ä¸­æ‰€ç¤ºçš„è¡¨ä¸­ï¼Œè¯¥è¡¨æŒ‰è¡Œä¸»é¡ºåºå­˜å‚¨ï¼Œå¯¹çº¿æ€§åŒ–çš„è¡¨æ‰§è¡Œæ’é™¤æ‰«æï¼Œç»“æœè¡¨ç¤ºçº¿ç¨‹å—çš„æœ¬åœ° bucket çš„èµ·å§‹ä½ç½®ã€‚\nFinding the Destination of Each Thread Block\u0026#39;s Local Buckets\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #define SECTION_SIZE 32 __global__ void memory_coalescing_radix_sort(unsigned int* input, unsigned int* output, unsigned int* bits, unsigned int* table, int N, int iter) { __shared__ unsigned int input_s[SECTION_SIZE]; __shared__ unsigned int output_s[SECTION_SIZE]; // Load input into shared memory unsigned int globalIdx = blockIdx.x * blockDim.x + threadIdx.x; if (globalIdx \u0026lt; N) { input_s[threadIdx.x] = input[globalIdx]; } __syncthreads(); // Sort each section radix_sort_iter(input_s, output_s, bits + blockIdx.x * SECTION_SIZE, SECTION_SIZE, iter); __syncthreads(); // Store local bucket num if (threadIdx.x == 0) { unsigned int numberOnesTotal = 0; unsigned int numberZerosTotal = 0; for (int i = 0; i \u0026lt; SECTION_SIZE; ++i) { numberOnesTotal += bits[blockIdx.x * SECTION_SIZE + i]; } numberZerosTotal = SECTION_SIZE - numberOnesTotal; table[blockIdx.x] = numberZerosTotal; table[blockIdx.x + gridDim.x] = numberOnesTotal; } __syncthreads(); // Exclusive prefix sum to determine output index exclusiveScan(table, 2 * gridDim.x); // Write results to output array if (globalIdx \u0026lt; N) { int zeroOffset = table[blockIdx.x]; int oneOffset = table[blockIdx.x + gridDim.x]; unsigned int bit = bits[blockIdx.x * SECTION_SIZE + threadIdx.x]; unsigned int dst = (bit == 0) ? (globalIdx - zeroOffset) : (N - oneOffset); output[dst] = input[globalIdx]; } } 13.5 Choice of Radix Value ä½¿ç”¨ 2 bit çš„åŸºæ•°æ—¶ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¯æ¬¡è¿­ä»£ä½¿ç”¨ä¸¤ä¸ªæ¯”ç‰¹å°†é”®åˆ†å‘åˆ°å­˜å‚¨æ¡¶ã€‚å› æ­¤ï¼Œä¸¤æ¬¡è¿­ä»£å°±å¯ä»¥å¯¹ 4 bit é”®è¿›è¡Œå®Œå…¨æ’åºã€‚\nRadix Sort Example with 2-bit Radix\nä¸ºäº†å†…å­˜åˆå¹¶è®¿é—®ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¯ä¸ªçº¿ç¨‹å—å¯ä»¥åœ¨å…±äº«å†…å­˜ä¸­å¯¹å…¶é”®è¿›è¡Œæœ¬åœ°æ’åºï¼Œç„¶åå°†æ¯ä¸ªæœ¬åœ°æ¡¶ä¸­çš„é”®çš„æ•°é‡å†™å…¥è¡¨ä¸­ã€‚å’Œ 13.4 èŠ‚ä¸€æ ·ï¼Œå¯¹äº r ä½åŸºæ•°ï¼Œå¯¹å…·æœ‰ 2^r è¡Œçš„è¡¨æ‰§è¡Œæ’é™¤æ‰«ææ“ä½œã€‚æœ€åä»¥åˆå¹¶çš„æ–¹å¼å°†æœ¬åœ° bucket å†™å…¥å…¨å±€å†…å­˜ã€‚\nOptimizing 2-bit Radix Sorting for Memory Coalescing Using the Shared Memory\nä½¿ç”¨æ›´å¤§çš„åŸºæ•°ä¹Ÿæœ‰ç¼ºç‚¹\næ¯ä¸ªçº¿ç¨‹å—æœ‰æ›´å¤šçš„æœ¬åœ°æ¡¶ï¼Œæ¯ä¸ªæ¡¶æœ‰æ›´å°‘çš„é”®ã€‚è¿™æ ·å°±ä¼šå‘å¤šä¸ªå…¨å±€å†…å­˜å—è¿›è¡Œå†™å…¥ï¼Œä½†æ¯ä¸€éƒ¨åˆ†å†™å…¥çš„æ•°æ®å˜å°‘ï¼Œä¸åˆ©äºå†…å­˜åˆå¹¶ã€‚ è¿›è¡Œæ’é™¤æ‰«æçš„è¡¨ä¼šéšç€åŸºæ•°çš„å¢å¤§è€Œå˜å¤§ï¼Œæ‰«æçš„å¼€é”€éšç€åŸºæ•°çš„å¢åŠ è€Œå¢åŠ ã€‚ Finding the Destination of Each Block\u0026#39;s Local Buckets for a 2-bit Radix\n13.6 Thread Coarsening to Improve Coalescing è·¨å¤šä¸ªçº¿ç¨‹å—å¹¶è¡ŒåŒ–åŸºæ•°æ’åºçš„ä¸€ä¸ªä»£ä»·æ˜¯å¯¹å…¨å±€å†…å­˜çš„å†™çš„è®¿é—®åˆå¹¶å¾ˆå·®ã€‚æ¯ä¸ªçº¿ç¨‹å—éƒ½æœ‰è‡ªå·±çš„æœ¬åœ°æ¡¶ï¼Œå¹¶å°†å…¶å†™å…¥å…¨å±€å†…å­˜ã€‚æ‹¥æœ‰æ›´å¤šçš„çº¿ç¨‹å—æ„å‘³ç€æ¯ä¸ªçº¿ç¨‹å—æ‹¥æœ‰æ›´å°‘çš„é”®ï¼Œè¿™æ„å‘³ç€æœ¬åœ°å­˜å‚¨æ¡¶å°†æ›´å°ï¼Œä»è€Œåœ¨å°†å®ƒä»¬å†™å…¥å…¨å±€å†…å­˜æ—¶åˆå¹¶æœºä¼šæ›´å°‘ã€‚å¦ä¸€ä¸ªä»£ä»·æ˜¯æ‰§è¡Œå…¨å±€æ’é™¤æ‰«æä»¥è¯†åˆ«æ¯ä¸ªçº¿ç¨‹å—çš„æœ¬åœ°æ¡¶çš„å­˜å‚¨ä½ç½®çš„å¼€é”€ã€‚é€šè¿‡åº”ç”¨çº¿ç¨‹ç²—åŒ–ï¼Œå¯ä»¥å‡å°‘å—çš„æ•°é‡ï¼Œä»è€Œå‡å°‘è¡¨çš„å¤§å°å’Œæ’é™¤æ‰«ææ“ä½œçš„å¼€é”€ã€‚ ä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•å°†çº¿ç¨‹ç²—åŒ–åº”ç”¨äº 2 ä½åŸºæ•°æ’åºã€‚æ¯ä¸ªçº¿ç¨‹è¢«åˆ†é…ç»™è¾“å…¥åˆ—è¡¨ä¸­çš„å¤šä¸ªé”®ã€‚\nRadix Sort for a 2-bit Radix with Thread Coarsening\n13.7 Parallel Merge Sort ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch13/","summary":"Personal notebook 13 of Programming Massively Parallel","title":"PMPP Learning-Chapter 13 Sorting"},{"content":"12 Merge-An Introduction to Dynamic Input Data Identification æœ‰åºå½’å¹¶æ“ä½œæ¥å—ä¸¤ä¸ªæœ‰åºåˆ—è¡¨å¹¶ç”Ÿæˆä¸€ä¸ªåˆå¹¶åçš„æœ‰åºåˆ—è¡¨ã€‚\n12.1 Background å‡è®¾æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æœ‰ä¸€ä¸ªé”®å¹¶ä¸”é”®å®šä¹‰äº†ä¸€ä¸ªç”¨ â‰¤ è¡¨ç¤ºçš„é¡ºåºå…³ç³»ã€‚ä¸‹å›¾å±•ç¤ºäº†åŸºäºæ•°å­—æ’åºå…³ç³»çš„ç®€å•å½’å¹¶å‡½æ•°çš„æ“ä½œã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœé”®å€¼ç›¸ç­‰çš„å…ƒç´ åœ¨è¾“å‡ºä¸­çš„é¡ºåºä¸å…¶åœ¨è¾“å…¥ä¸­çš„é¡ºåºç›¸åŒï¼Œåˆ™ç§°æ’åºæ“ä½œæ˜¯ç¨³å®šçš„ã€‚\nExample of a Merge Operation\n12.2 A Sequential Merge Algorithm å½’å¹¶æ“ä½œå¯ä»¥ç”¨å¦‚ä¸‹ä¸€ä¸ªç®€å•çš„é¡ºåºç®—æ³•æ¥å®ç°ã€‚é¡ºåºå½’å¹¶å‡½æ•°è®¿é—® A å’Œ B çš„æ¯ä¸ªè¾“å…¥å…ƒç´ ä¸€æ¬¡ï¼Œå¹¶å‘ C ä¸­æ¯ä¸ªä½ç½®å†™å…¥ä¸€æ¬¡ã€‚å…¶ç®—æ³•å¤æ‚åº¦ä¸º O(m+n).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void merge_sequential(int* A, int* B, int* C, int m, int n) { int i = 0, j = 0, k = 0; // Indices for A, B, and C while (i \u0026lt; m \u0026amp;\u0026amp; j \u0026lt; n) { if (A[i] \u0026lt; B[j]) { C[k++] = A[i++]; } else { C[k++] = B[j++]; } if (i == m) { // Done with A[], handling remaining B while (j \u0026lt; n) { C[k++] = B[j++]; } } else { // Done with B[], handling remaining A while (i \u0026lt; m) { C[k++] = A[i++]; } } } } 12.3 A Parallelization Approach æ¯ä¸ªçº¿ç¨‹é¦–å…ˆç¡®å®šå®ƒå°†è¦è´Ÿè´£çš„è¾“å‡ºä½ç½®èŒƒå›´ï¼Œå¹¶ä½¿ç”¨è¯¥è¾“å‡ºèŒƒå›´ä½œä¸º co-rank å‡½æ•°çš„è¾“å…¥ï¼Œä»¥ç¡®å®šæ‰€è´Ÿè´£ C è¾“å‡ºèŒƒå›´çš„å¯¹åº”çš„ A å’Œ B è¾“å…¥èŒƒå›´ã€‚è¿™æ ·æ¯ä¸ªçº¿ç¨‹åœ¨å®ƒä»¬çš„å­æ•°ç»„ä¸Šæ‰§è¡Œé¡ºåºåˆå¹¶å‡½æ•°ï¼Œä»è€Œå¹¶è¡Œåœ°è¿›è¡Œåˆå¹¶ã€‚\nExamples of Observations\nObservation 1ï¼šå­æ•°ç»„ C[0]-C[k-1] (k ä¸ªå…ƒç´ ) æ˜¯ A[0]-A[i-1] (i ä¸ªå…ƒç´ ) å’Œ B[0]-B[k-i-1] (k-i ä¸ªå…ƒç´ ) çš„å½’å¹¶ç»“æœã€‚ Observation 2ï¼šå¯¹äºä»»æ„æ»¡è¶³ 0â‰¤kâ‰¤m+n çš„ kï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°å”¯ä¸€çš„ i å’Œ j ä½¿å¾— k=i+j, 0â‰¤iâ‰¤m, 0â‰¤jâ‰¤nï¼Œå¹¶ä¸”å­æ•°ç»„ C[0]-C[k-1] æ˜¯å­æ•°ç»„ A[0]-A[i-1] å’Œå­æ•°ç»„ B[0]-B[j-1] åˆå¹¶çš„ç»“æœã€‚å”¯ä¸€çš„ç´¢å¼• i å’Œ j è¢«ç§° C[k] çš„ co-rank. æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†è¾“å‡ºæ•°ç»„åˆ’åˆ†ä¸ºå­æ•°ç»„ï¼Œå¹¶è®©æ¯ä¸ªçº¿ç¨‹è´Ÿè´£ä¸€ä¸ªå­æ•°ç»„çš„ç”Ÿæˆæ¥åˆ’åˆ†å·¥ä½œã€‚ç”±äºå¹¶è¡Œå½’å¹¶ç®—æ³•ä¸­æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨çš„è¾“å…¥å…ƒç´ çš„èŒƒå›´å–å†³äºå®é™…çš„è¾“å…¥å€¼ä½¿å¾—æˆ‘ä»¬éœ€è¦è¾…åŠ©å‡½æ•°æ¥å®Œæˆã€‚\n12.4 Co-rank Function Implementation å°† co-rank å‡½æ•°å®šä¹‰ä¸ºæ¥å—è¾“å‡ºæ•°ç»„ C ä¸­å…ƒç´ çš„ä½ç½® k å’Œä¸¤ä¸ªè¾“å…¥æ•°ç»„ A å’Œ Bçš„ä¿¡æ¯ï¼Œå¹¶è¿”å›è¾“å…¥æ•°ç»„ A å¯¹åº”çš„ co-rank å€¼ i. ä»¥ä¸‹å›¾ä¸ºä¾‹ï¼Œå‡è®¾çº¿ç¨‹ 1 çš„ co-rank å‡½æ•°çš„ç›®æ ‡æ˜¯ä¸ºå…¶ç§© k1=4 ç¡®å®š co-rankå€¼ i1=3 å’Œ j1=1. ä¹Ÿå°±æ˜¯è¯´ï¼Œä» C[4] å¼€å§‹çš„å­æ•°ç»„å°†ç”±ä» A[3] å’Œ B[1] å¼€å§‹çš„å­æ•°ç»„åˆå¹¶ç”Ÿæˆã€‚æˆ‘ä»¬å¯ä»¥å‘ç°çº¿ç¨‹ t ä½¿ç”¨çš„è¾“å…¥å­æ•°ç»„ç”±çº¿ç¨‹ t å’Œçº¿ç¨‹ t+1 çš„ co-rank ç¡®å®šã€‚\nExample of co-rank Function Execution\nç›®æ ‡æ˜¯æ‰¾åˆ°ä½¿å¾— A[i - 1] \u0026lt;= B[j] å¹¶ä¸” B[j - 1] \u0026lt;= A[i] çš„ç´¢å¼•ã€‚\nå¦‚æœ A[i-1] \u0026gt; B[j]ï¼Œè¯´æ˜ A[i] å¤ªå¤§ï¼Œéœ€è¦å‡å°‘ iï¼Œå¹¶å¢åŠ  jã€‚ å¦‚æœ B[j-1] \u0026gt; A[i]ï¼Œè¯´æ˜ B[j] å¤ªå¤§ï¼Œéœ€è¦å‡å°‘ jï¼Œå¹¶å¢åŠ  iã€‚ æ¯æ¬¡è°ƒæ•´æ—¶ï¼Œi å’Œ j éƒ½æŒ‰ç…§äºŒåˆ†æ–¹å¼è°ƒæ•´ï¼Œå³è°ƒæ•´çš„æ­¥é•¿æ˜¯ delta / 2. i å’Œ i_low ç¡®å®šäº†å½“å‰æ­£åœ¨æœç´¢çš„æ•°ç»„ A çš„èŒƒå›´ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 int co_rank(int k, int* A, int m, int* B, int n) { // C[k] comes from A[i] of B[j] // k = i + j int i = k \u0026lt; m ? k : m; // max starting search value for A, i.e. A[k-1] \u0026lt; B[0] int i_low = 0 \u0026gt; (k - n) ? 0 : k - n; // when B is done, min starting search value for A is k-n int j = k - i; int j_low = 0 \u0026gt; (k - m) ? 0 : (k - m); int delta; bool active = true; while (active) { // Binary search for C[k] if (i \u0026gt; 0 \u0026amp;\u0026amp; j \u0026lt; n \u0026amp;\u0026amp; A[i - 1] \u0026gt; B[j]) { delta = (i - i_low + 1) \u0026gt;\u0026gt; 1; j_low = j; j += delta; i -= delta; } else if (j \u0026gt; 0 \u0026amp;\u0026amp; i \u0026lt; m \u0026amp;\u0026amp; B[j - 1] \u0026gt; A[i]) { delta = (j - j_low + 1) \u0026gt;\u0026gt; 1; i_low = i; i += delta; j -= delta; } else { // Found the correct position for C[k] active = false; } return i; } } 12.5 A Basic Parallel Merge Kernel åœ¨å‰©ä¸‹çš„å°èŠ‚é‡Œï¼Œæˆ‘ä»¬å‡è®¾è¾“å…¥æ•°ç»„ A å’Œ B å­˜å‚¨åœ¨å…¨å±€å†…å­˜ä¸­ï¼Œä¸€ä¸ªå†…æ ¸è¢«å¯åŠ¨ç”¨æ¥åˆå¹¶ä¸¤ä¸ªè¾“å…¥æ•°ç»„ï¼Œè¾“å‡ºä¸€ä¸ªåŒæ ·ä½äºå…¨å±€å†…å­˜ä¸­çš„æ•°ç»„ C. ä¸‹é¢å†…æ ¸æ˜¯å¹¶è¡Œå½’å¹¶çš„ç›´æ¥å®ç°ã€‚å®ƒé¦–å…ˆé€šè¿‡è®¡ç®—å½“å‰çº¿ç¨‹ (k_curr) å’Œä¸‹ä¸€ä¸ªçº¿ç¨‹ (k_next) äº§ç”Ÿçš„è¾“å‡ºå­æ•°ç»„çš„èµ·ç‚¹æ¥ç¡®å®šè´Ÿè´£è¾“å‡ºçš„èŒƒå›´ã€‚ç„¶ååˆ†åˆ«è°ƒç”¨è‡ªå·±å’Œåä¸€ä¸ªçº¿ç¨‹çš„ co_rank å‡½æ•°æ¥ç¡®å®šå¯¹åº”çš„ A å’Œ B è¾“å…¥å­æ•°ç»„çš„èŒƒå›´ã€‚æœ€åè°ƒç”¨é¡ºåºåˆå¹¶å‡½æ•°æ¥åˆå¹¶ä¸¤ä¸ªè¾“å…¥å­æ•°ç»„ï¼Œå¹¶å°†ç»“æœå†™å…¥è¾“å‡ºå­æ•°ç»„ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 __global__ void mergre_basic_kernel(int* A, int* B, int* C, int m, int n) { // Each thread handles a section of C int tid = blockIdx.x * blockDim.x + threadIdx.x; int elementsPerThread = ceil(m + n) / (blockDim.x * gridDim.x); int start = tid * elementsPerThread; int end = std::min(start + elementsPerThread, m + n); // Determin the range of A and B to be merged for this thread int i_curr = co_rank(start, A, m, B, n); int i_next = co_rank(end, A, m, B, n); int j_curr = start - i_curr; int j_next = end - i_next; merge_sequential(A + i_curr, B + j_curr, C + start, i_next - i_curr, j_next - j_curr); } ä¸Šé¢çš„åŸºæœ¬å½’å¹¶å†…æ ¸æœ‰ 2 ä¸ªé—®é¢˜ï¼š\nwarp ä¸­çš„ç›¸é‚»çº¿ç¨‹åœ¨è¯»å†™è¾“å…¥å’Œè¾“å‡ºå­æ•°ç»„å…ƒç´ æ—¶ä¸ä¼šè®¿é—®ç›¸é‚»çš„å†…å­˜ä½ç½®ã€‚ çº¿ç¨‹åœ¨æ‰§è¡Œ co-rank å‡½æ•°æ—¶è¿˜éœ€è¦ä»å…¨å±€å†…å­˜è®¿é—® A å’Œ B çš„å…ƒç´ ã€‚ 12.6 A Tiled Merge Kernel to Improve Coalescing æ³¨æ„åˆ°ç›¸é‚»çº¿ç¨‹ä½¿ç”¨çš„ A å’Œ B å­æ•°ç»„åœ¨å†…å­˜ä¸­å½¼æ­¤ç›¸é‚»ã€‚æˆ‘ä»¬å¯ä»¥ä¸ºä¸ºæ¯ä¸ªå—è°ƒç”¨ co-rank å‡½æ•°æ¥è·å¾—å…¶ A å’Œ B å­æ•°ç»„çš„èµ·å§‹å’Œç»“æŸä½ç½®ã€‚ Info\nå›å¿†ä¸€ä¸‹æ”¹è¿›å†…æ ¸å†…å­˜åˆå¹¶çš„ä¸»è¦ç­–ç•¥æœ‰ä¸‰ç§:\né‡æ–°ç»„ç»‡çº¿ç¨‹åˆ°æ•°æ®çš„æ˜ å°„ã€‚ é‡æ–°ç»„ç»‡æ•°æ®æœ¬èº«ã€‚ ä»¥åˆå¹¶çš„æ–¹å¼åœ¨å…¨å±€å†…å­˜å’Œå…±äº«å†…å­˜ä¹‹é—´ä¼ è¾“æ•°æ®ï¼Œå¹¶åœ¨å…±äº«å†…å­˜ä¸­æ‰§è¡Œä¸è§„åˆ™è®¿é—®ã€‚ ä¸‹å›¾å±•ç¤ºäº†åˆ†æ®µåˆå¹¶å†…æ ¸çš„å—çº§åˆ«è®¾è®¡ã€‚A_S å’Œ B_S å¯èƒ½æ— æ³•è¦†ç›–å—çš„æ•´ä¸ªè¾“å…¥å­æ•°ç»„ï¼Œå› æ­¤åœ¨æ¯æ¬¡è¿­ä»£æœŸé—´ï¼Œå—ä¸­çš„æ‰€æœ‰çº¿ç¨‹å°†åä½œä»å—çš„ A å’Œ B å­æ•°ç»„ä¸­åŠ è½½ x ä¸ªå…ƒç´ ã€‚è¿™æ ·æ¯ä¸ªå—æœ‰è¶³å¤Ÿçš„è¾“å…¥å…ƒç´ æ¥ç”Ÿæˆè‡³å°‘ x ä¸ªè¾“å‡ºæ•°ç»„å…ƒç´  (åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œå½“å‰è¾“å‡ºéƒ¨åˆ†çš„æ‰€æœ‰å…ƒç´ å¯èƒ½éƒ½æ¥è‡ª A æˆ– B çš„å­æ•°ç»„)ã€‚å‡è®¾æ¯ä¸ªå—è´Ÿè´£ y ä¸ªè¾“å‡ºå…ƒç´ ï¼Œåˆ™éœ€è¦è¿›è¡Œ y/x æ¬¡å½’å¹¶ã€‚æ¯ä¸ªå—ä¸­çš„çº¿ç¨‹å°†åœ¨æ¯æ¬¡è¿­ä»£ä¸­ä½¿ç”¨ A_S çš„ä¸€éƒ¨åˆ†å’Œ B_S çš„ä¸€éƒ¨åˆ† (æ·±ç°è‰²éƒ¨åˆ†)\nDesign of a Tiled Merge Kernel\nä¸‹é¢æ˜¯åˆ†æ®µåˆå¹¶å†…æ ¸çš„å®ç°çš„ç¬¬ä¸€éƒ¨åˆ†ã€‚æœ¬è´¨ä¸Šæ˜¯çº¿ç¨‹çº§åŸºæœ¬åˆå¹¶å†…æ ¸çš„å—çº§ç‰ˆæœ¬çš„ä»£ç ã€‚æ¯ä¸ªå—çš„ç¬¬ä¸€ä¸ªçº¿ç¨‹è´Ÿè´£è®¡ç®—å½“å‰å—å’Œä¸‹ä¸€ä¸ªå—çš„å¼€å§‹è¾“å‡ºç´¢å¼•çš„ä½ç½®ä»¥åŠä»–ä»¬çš„ co-rank. ç»“æœè¢«æ”¾å…¥å…±äº«å†…å­˜ä¸­ï¼Œä»¥ä¾¿å—ä¸­çš„æ‰€æœ‰çº¿ç¨‹éƒ½å¯ä»¥çœ‹åˆ°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 __global__ void merge_tiled_kernel(int* A, int* B, int* C, int m, int n, int tile_size) { /* Part 1: Identify block-level output \u0026amp; input subarrays */ // Use extern keywords to determine // the shared memory size at runtime rather than compilation extern __shared__ int shared_AB[]; int* A_s = \u0026amp;shared_AB[0]; // Start index of ShareA int* B_s = \u0026amp;shared_AB[tile_size]; // Start index of ShareB int C_curr = blockIdx.x * ceil((m + n) / gridDim.x); // Start index of C for this block int C_next = std::min(C_curr + int(ceil((m + n) / gridDim.x)), m + n); // End index of C for this block if (threadIdx.x == 0) { A_s[0] = co_rank(C_curr, A, m, B, n); // Make block level co-rank values visible A_s[1] = co_rank(C_next, A, m, B, n); // Next threads co-rank values in the block } __synctyhreads(); int A_curr = A_s[0]; int A_next = A_s[1]; int B_curr = C_curr - A_curr; int B_next = C_next - A_next; ç¬¬äºŒéƒ¨åˆ†çº¿ç¨‹ä½¿ç”¨å®ƒä»¬çš„ threadIdx.x çš„å€¼æ¥ç¡®å®šè¦åŠ è½½çš„å…ƒç´ ï¼Œå› æ­¤è¿ç»­çš„çº¿ç¨‹åŠ è½½è¿ç»­çš„å…ƒç´ ï¼Œå†…å­˜è®¿é—®æ˜¯åˆå¹¶çš„ã€‚æ¯æ¬¡è¿­ä»£ä» A å’Œ B æ•°ç»„ä¸­åŠ è½½å½“å‰tileçš„èµ·å§‹ç‚¹å–å†³äºå—çš„æ‰€æœ‰çº¿ç¨‹åœ¨ä¹‹å‰çš„è¿­ä»£ä¸­æ¶ˆè€—çš„ A å’Œ B å…ƒç´ çš„æ€»æ•°ã€‚ä¸‹å›¾è¯´æ˜äº† while å¾ªç¯ç¬¬äºŒæ¬¡è¿­ä»£çš„ç´¢å¼•è®¡ç®—ã€‚æ¯ä¸ªå—åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­æ¶ˆè€—çš„ A å…ƒç´ éƒ¨åˆ† ä¸º A å­æ•°ç»„å¼€å¤´çš„ç™½è‰²å°éƒ¨åˆ† (ç”¨ç«–æ¡æ ‡è®°)ã€‚if è¯­å¥ç¡®ä¿çº¿ç¨‹åªåŠ è½½ A å­æ•°ç»„å‰©ä½™éƒ¨åˆ†ä¸­çš„å…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* Part 2: Loading A \u0026amp; B elements into the shared memory */ int counter = 0; int lenC = C_next - C_curr; int lenA = A_next - A_curr; int lenB = B_next - B_curr; int num_iterations = ceil(lenC / tile_size); // index of completed merge in int C_completed = 0; int A_completed = 0; int B_completed = 0; while (counter \u0026lt; num_iterations) { // Each iter threads in a block will generate tile_size C elements // Loading tile_size A and B elements into shared memory for (int i = 0; i \u0026lt; tile_size; i += blockDim.x) { // Coalecsing loading from global memory if (i + threadIdx.x \u0026lt; lenA - A_completed) { A_s[i + threadIdx.x] = A[i + threadIdx.x + A_curr + A_completed]; } if (i + threadIdx.x \u0026lt; lenB - B_completed) { B_s[i + threadIdx.x] = B[i + threadIdx.x + B_curr + B_completed]; } } __syncthreads(); ç¬¬ä¸‰éƒ¨åˆ†åˆ™æ˜¯æ¯ä¸ªå—çš„çº¿ç¨‹å¯¹å…±äº«å†…å­˜çš„æ•°ç»„è¿›è¡Œå½’å¹¶ã€‚åœ¨æ›´æ–°ç´¢å¼•çš„éƒ¨åˆ†ä¸­æœ€åä¸€æ¬¡è¿­ä»£ä¸­ A_s å’Œ B_s å¯èƒ½æ²¡æœ‰ tile_size ä¸ªå…ƒç´ ï¼Œè°ƒç”¨ co-rank å¯èƒ½ä¼šå¾—åˆ°é”™è¯¯ç»“æœã€‚ä½†æ˜¯ï¼Œç”±äº while å¾ªç¯ä¸ä¼šè¿›ä¸€æ­¥è¿­ä»£ï¼Œå› æ­¤ä¸ä¼šä½¿ç”¨ç»“æœï¼Œå› æ­¤ä¸ä¼šé€ æˆä»»ä½•å½±å“ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* Part 3: All threads merge their subarrays in prallel */ int c_curr = threadIdx.x * (tile_size / blockDim.x); // Output index in shared memory int c_next = c_curr + (tile_size / blockDim.x); c_curr = (c_curr \u0026lt;= lenC - C_completed) ? c_curr : lenC - C_completed; c_next = (c_next \u0026lt;= lenC - C_completed) ? c_next : lenC - C_completed; // find co-rank for c_curr and c_next int a_curr = co_rank(c_curr, A_s, std::min(tile_size, lenA - A_completed), B_s, std::min(tile_size, lenB - B_completed)); int b_curr = c_curr - a_curr; int a_next = co_rank(c_next, A_s, std::min(tile_size, lenA - A_completed), B_s, std::min(tile_size, lenB - B_completed)); int b_next = c_next - a_next; // merge the subarrays merge_sequential(A_s + a_curr, B_s + b_curr, C + C_curr + C_completed + c_curr, a_next - a_curr, b_next - b_curr); // Update completed indices C_completed += tile_size; A_completed += co_rank(tile_size, A_s, tile_size, B_s, tile_size); // Idx of A_s to generate tile_size Idx of merged A_s and B_s B_completed += tile_size - A_completed; } } 12.7 A Circular Buffer Merge Kernel ä¸Šä¸€èŠ‚çš„å†…æ ¸ä¸æ˜¯é‚£ä¹ˆé«˜æ•ˆå› ä¸ºä¸‹ä¸€æ¬¡è¿­ä»£ tile çš„ä¸€éƒ¨åˆ†å·²ç»è¢«åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­ï¼Œä½†æ˜¯æˆ‘ä»¬æ¯æ¬¡è¿­ä»£ä»å…¨å±€å†…å­˜ä¸­é‡æ–°åŠ è½½æ•´ä¸ªå—ï¼Œå¹¶è¦†ç›–æ‰å‰ä¸€æ¬¡è¿­ä»£ä¸­çš„è¿™äº›å…ƒç´ ã€‚ä¸‹å›¾å±•ç¤ºäº† merge_circular_buffer_kernel çš„ä¸»è¦æ€æƒ³ï¼Œæ·»åŠ äº†ä¸¤ä¸ªé¢å¤–çš„å˜é‡ A_S_start å’ŒB_S_startï¼Œä½¿å¾— while å¾ªç¯çš„æ¯æ¬¡è¿­ä»£åŠ¨æ€ç¡®å®šä» A å’Œ B çš„å“ªä¸ªä½ç½®å¼€å§‹åŠ è½½ï¼Œè¿™æ ·å¯ä»¥åˆ©ç”¨å‰ä¸€æ¬¡è¿­ä»£ä¸­å‰©ä½™çš„ A_s å’Œ B_s å…ƒç´ ã€‚ä¿®æ”¹åæ¯ä¸ª for å¾ªç¯éƒ½åªåŠ è½½ A_S_consumed è¡¨ç¤ºçš„å¡«å…… tile æ‰€éœ€çš„å…ƒç´ æ•°é‡ã€‚å› æ­¤ï¼Œçº¿ç¨‹åœ¨ç¬¬ i æ¬¡ for å¾ªç¯è¿­ä»£ä¸­åŠ è½½çš„A å…ƒç´ æ˜¯ A[A_curr+A_S_consumed+i+threadIdx.x]. å–æ¨¡(%) æ“ä½œæ£€æŸ¥ç´¢å¼•å€¼æ˜¯å¦å¤§äºæˆ–ç­‰äº tile_size.\n!A Circular Buffer Scheme for Managing the Shared Memory Tiles\n12.8 Thread Coarsening for Merge å¤šä¸ªçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œå½’å¹¶çš„ä»£ä»·æ˜¯æ¯ä¸ªçº¿ç¨‹å¿…é¡»æ‰§è¡Œè‡ªå·±çš„äºŒè¿›åˆ¶æœç´¢æ“ä½œæ¥è¯†åˆ«å…¶è¾“å‡ºç´¢å¼•çš„ co-rank. æœ¬ç« ä¸­ä»‹ç»çš„æ‰€æœ‰å†…æ ¸éƒ½å·²ç»åº”ç”¨äº†çº¿ç¨‹ç²—åŒ–ï¼Œå› ä¸ºå®ƒä»¬éƒ½æ˜¯ä¸ºæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªå…ƒç´ è€Œè®¾è®¡çš„ã€‚åœ¨å®Œå…¨æœªç²—åŒ–çš„å†…æ ¸ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹å°†è´Ÿè´£å•ä¸ªè¾“å‡ºå…ƒç´ ã€‚\n","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch12/","summary":"Personal notebook 12 of Programming Massively Parallel","title":"PMPP Learning-Chapter 12 Merge-An Introduction to Dynamic Input Data Identification"},{"content":"11 Prefix sum (scan)-An Introduction to Work Efficiency in Parallel Algorithms ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœè®¡ç®—æœ¬è´¨ä¸Šå¯ä»¥è¢«æè¿°ä¸ºæ•°å­¦é€’å½’ï¼Œå³åºåˆ—ä¸­çš„æ¯ä¸€é¡¹éƒ½æ˜¯æ ¹æ®å‰ä¸€é¡¹å®šä¹‰çš„ï¼Œé‚£ä¹ˆå®ƒå¯èƒ½è¢«å¹¶è¡ŒåŒ–ä¸ºå¹¶è¡Œæ‰«æ (parallel scan) è¿ç®—ã€‚\n11.1 Background åŒ…å«æ‰«æ (inclusive scan) æ“ä½œæ¥æ”¶ä¸€ä¸ªäºŒå…ƒå¯äº¤æ¢è¿ç®—ç¬¦ $\\oplus$ å’Œä¸€ä¸ªåŒ…å« n ä¸ªå…ƒç´ çš„è¾“å…¥æ•°ç»„ $[x_0,x_1,\\ldots,x_{n-1}]$ï¼Œè¾“å‡ºæ•°ç»„ $[x_0,(x_0\\oplus x_1),\\ldots,(x_0\\oplus x_1\\oplus\\ldots\\oplus x_{n-1})]$ . åŒ…å«æ‰«æçš„åç§°ä½“ç°åœ¨è¾“å‡ºæ•°ç»„æ¯ä¸ªä½ç½®çš„ç»“æœéƒ½æœ‰å¯¹åº”è¾“å…¥å…ƒç´ å‚ä¸ã€‚è€ƒè™‘åŒ…å«æ‰«æçš„ä¸€ç§ç›´è§‚æ–¹å¼æ˜¯ï¼Œæ¥æ”¶ä¸€ç»„æ‰€éœ€é¦™è‚ çš„é•¿åº¦çš„è®¢å•ï¼Œå¹¶ä¸€æ¬¡æ€§å¾—å‡ºæ‰€æœ‰æ‰€æœ‰è®¢å•å¯¹åº”çš„åˆ‡å‰²ç‚¹ã€‚ æ’é™¤æ‰«ææ“ä½œç±»ä¼¼äºåŒ…å«æ‰«ææ“ä½œï¼Œåªæ˜¯è¾“å‡ºæ•°ç»„çš„æ’åˆ—ç•¥æœ‰ä¸åŒ: $[i,x_0,(x_0\\oplus x_1),\\ldots,(x_0\\oplus x_1\\oplus\\ldots\\oplus x_{n-2})]$ . æ¯ä¸ªè¾“å‡ºå…ƒç´ çš„è®¡ç®—éƒ½ä¸ç›¸åº”è¾“å…¥å…ƒç´ æ— å…³ã€‚ ç”¨åŒ…å«æ‰«æå‡½æ•°è®¡ç®—æ’é™¤æ‰«æçš„ç»“æœæ—¶ï¼Œåªéœ€å°†æ‰€æœ‰å…ƒç´ å‘å³ç§»åŠ¨ï¼Œå¹¶ä¸ºç¬¬ 0 ä¸ªå…ƒç´ å¡«å……æ’ç­‰å€¼ã€‚åä¹‹ï¼Œåªéœ€è¦å°†æ‰€æœ‰å…ƒç´ å‘å·¦ç§»åŠ¨ï¼Œå¹¶ç”¨æ’é™¤æ‰«æç»“æœçš„æœ€åä¸€ä¸ªå…ƒç´  $\\oplus$ æœ€åä¸€ä¸ªè¾“å…¥å…ƒç´ æ¥å¡«å……æœ€åä¸€ä¸ªå…ƒç´ ã€‚\n11.2 Parallel Scan with the Kogge-Stone Algorithm è®¡ç®—ä½ç½® i çš„è¾“å‡ºå…ƒç´  éœ€è¦è¿›è¡Œ i æ¬¡åŠ æ³•è¿ç®—ï¼Œå› æ­¤é™¤éæ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥å…±äº«ä¸åŒè¾“å‡ºå…ƒç´ çš„å½’çº¦æ ‘çš„éƒ¨åˆ†å’Œï¼Œå¦åˆ™è¿™ç§æ–¹æ³•è®¡ç®—å¤æ‚åº¦ä¸º $O(N^2)$. Kogge-Stone ç®—æ³•æœ€åˆæ˜¯ä¸ºäº†è®¾è®¡å¿«é€ŸåŠ æ³•å™¨ç”µè·¯è€Œå‘æ˜çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå®ƒæ˜¯ä¸€ç§å°±åœ°æ‰«æç®—æ³•ï¼Œå®ƒå¯¹æœ€åˆåŒ…å«è¾“å…¥å…ƒç´ çš„æ•°ç»„ XY è¿›è¡Œæ“ä½œã€‚ç»è¿‡ k æ¬¡è¿­ä»£åï¼ŒXY[i] å°†åŒ…å«åœ¨è¯¥ä½ç½®åŠä¹‹å‰çš„æœ€å¤š 2^k ä¸ªè¾“å…¥å…ƒç´ çš„å’Œã€‚\nA Parallel Inclusive Scan Algorithm Based on Kogge-Stone Adder Design\nå¯¹åº”çš„å†…æ ¸å‡½æ•°å¦‚ä¸‹ï¼Œå‡è®¾è¾“å…¥æœ€åˆä½äºå…¨å±€å†…å­˜æ•°ç»„ X ä¸­ã€‚è®©æ¯ä¸ªçº¿ç¨‹è®¡ç®—å…¶å…¨å±€æ•°æ®ç´¢å¼•ï¼Œå³å…¶è´Ÿè´£è®¡ç®—è¾“å‡ºæ•°ç»„çš„ä½ç½®ã€‚æ¯ä¸ªä¸ªæ´»åŠ¨çº¿ç¨‹é¦–å…ˆå°†å…¶ä½ç½®çš„éƒ¨åˆ†å’Œå­˜å‚¨åˆ°ä¸€ä¸ªä¸´æ—¶å˜é‡ä¸­(åœ¨å¯„å­˜å™¨ä¸­)ã€‚å½“æ­¥å¹…å€¼å¤§äº threadIdx.x æ—¶ï¼Œæ„å‘³ç€çº¿ç¨‹åˆ†é…çš„ XY ä½ç½®å·²ç»ç´¯åŠ äº†æ‰€æœ‰æ‰€éœ€çš„è¾“å…¥å€¼ï¼Œé€€å‡ºæ´»åŠ¨çŠ¶æ€ã€‚éœ€è¦é¢å¤–çš„ temp å’Œ __syncthreads() å› ä¸ºæ›´æ–°ä¸­å­˜åœ¨è¯»åå†™æ•°æ®ä¾èµ–ç«äº‰å…³ç³»ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #define SECTION_SIZE 32 __global__ void Kogge_Stone_Scan_Kernel(int* X, int* Y, unsigned int N) { __shared__ float XY[SECTION_SIZE]; unsigned int i = blockIdx.x * blockDim.x + threadIdx.x; /* Exclusive kernel initilization if (i \u0026lt; N \u0026amp;\u0026amp; threadIdx.x != 0) { XY[threadIdx.x] = X[i]; } else { XY[threadIdx.x] = 0.0f; } */ if (i \u0026lt; N) { XY[threadIdx.x] = X[i]; } else { XY[threadIdx.x] = 0.0f; } for (unsigned stride = 1; stride \u0026lt; blockDim.x; stride *= 2) { __syncthreads(); float temp; if (threadIdx.x \u0026gt;= stride) { temp = XY[threadIdx.x] + XY[threadIdx.x - stride]; } __syncthreads(); // write-after-read dependence if (threadIdx.x \u0026gt;= stride) { // Only N - stride threads are active XY[threadIdx.x] = temp; } } if (i \u0026lt; N) { Y[i] = XY[threadIdx.x]; } } Kogge-Stone ç®—æ³•é‡ç”¨äº†æ¨ªè·¨å½’çº¦æ ‘çš„éƒ¨åˆ†å’Œæ¥é™ä½è®¡ç®—å¤æ‚åº¦ã€‚åœ¨ä¸Šä¸€ç« çš„å½’çº¦å†…æ ¸ä¸­ï¼Œæ´»åŠ¨çº¿ç¨‹åœ¨è¿­ä»£ä¸­å†™å…¥çš„å…ƒç´ ä¸ä¼šåœ¨åŒä¸€è¿­ä»£ä¸­è¢«ä»»ä½•å…¶ä»–æ´»åŠ¨çº¿ç¨‹è¯»å–ï¼Œå› æ­¤ä¸å­˜åœ¨è¯»åå†™ç«äº‰æ¡ä»¶ã€‚å¦‚æœå¸Œæœ›é¿å…åœ¨æ¯æ¬¡è¿­ä»£ä¸­éƒ½æœ‰ barrier åŒæ­¥ï¼Œé‚£ä¹ˆå…‹æœç«äº‰æ¡ä»¶çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä¸ºè¾“å…¥å’Œè¾“å‡ºä½¿ç”¨å•ç‹¬çš„æ•°ç»„ã€‚è¿™ç§æ–¹æ³•éœ€è¦ä¸¤ä¸ªå…±äº«å†…å­˜ç¼“å†²åŒºã€‚äº¤æ›¿å˜åŒ–ä¸èƒ½è¾“å…¥/è¾“å‡ºç¼“å†²åŒºçš„è§’è‰²ï¼Œç›´åˆ°è¿­ä»£å®Œæˆã€‚è¿™ç§ä¼˜åŒ–ç§°ä¸ºåŒç¼“å†² (double buffering).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 #define SECTION_SIZE 32 __global__ void DF_Kogge_Stone_Scan_Kernel(int* X, int* Y, unsigned int N) { __shared__ float XY_in[SECTION_SIZE]; __shared__ float XY_out[SECTION_SIZE]; unsigned int i = blockIdx.x * blockDim.x + threadIdx.x; // Initialization if (i \u0026lt; N) { XY_in[threadIdx.x] = X[i]; } else { XY_in[threadIdx.x] = 0.0f; } bool read_in = true; // Alternating ther role of XY_in and XY_out for (unsigned stride = 1; stride \u0026lt; blockDim.x; stride *= 2) { if (read_in) { if (threadIdx.x \u0026gt;= stride) { XY_out[threadIdx.x] = XY_in[threadIdx.x] + XY_in[threadIdx.x - stride]; } else { XY_out[threadIdx.x] = XY_in[threadIdx.x]; } } else { if (threadIdx.x \u0026gt;= stride) { XY_in[threadIdx.x] = XY_out[threadIdx.x] + XY_out[threadIdx.x - stride]; } else { XY_in[threadIdx.x] = XY_out[threadIdx.x]; } } read_in = !read_in; // åˆ‡æ¢æ•°ç»„ } // å°†ç»“æœå†™å›å…¨å±€å†…å­˜ if (i \u0026lt; N) { if (read_in) { Y[i] = XY_in[threadIdx.x]; } else { Y[i] = XY_out[threadIdx.x]; } } } 11.3 Speed and Work Efficiency Consideration ç®—æ³•çš„å·¥ä½œæ•ˆç‡ï¼ˆwork efficiencyï¼‰æ˜¯æŒ‡ç®—æ³•æ‰€å®Œæˆçš„å·¥ä½œæ¥è¿‘äºè®¡ç®—æ‰€éœ€çš„æœ€å°å·¥ä½œé‡çš„ç¨‹åº¦ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œéæ´»åŠ¨çº¿ç¨‹çš„æ•°é‡ç­‰äºæ­¥é•¿ã€‚å› æ­¤æˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºå·¥ä½œé‡ä¸º\n$$\r\\sum_{stride}(N-\\mathrm{stride}), \\text{for strides} 1, 2, 4, \\ldots N/2(\\mathrm{log}_2N \\text{terms}) = N\\log_2N - (N-1)\r$$å› æ­¤ï¼ŒKogge-Stone ç®—æ³•çš„è®¡ç®—å¤æ‚åº¦ä¸º $O(N\\log_2N)$.\nä½¿ç”¨è®¡ç®—æ­¥æ•° (compute steps) çš„æ¦‚å¿µä½œä¸ºæ¯”è¾ƒæ‰«æç®—æ³•çš„è¿‘ä¼¼æŒ‡æ ‡ã€‚é¡ºåºæ‰«æç”¨ N-1 æ­¥æ¥å¤„ç† N ä¸ªè¾“å…¥å…ƒç´ ï¼›è‹¥ CUDA è®¾å¤‡æœ‰ P ä¸ªæ‰§è¡Œå•å…ƒï¼ŒKogge-Stone å†…æ ¸æ‰§è¡Œéœ€è¦æ­¥æ•°ä¸º $O(N\\log_2N)/P$. Kogge-Stone å†…æ ¸ç›¸æ¯”ä¸²è¡Œä»£ç æ‰€åšçš„é¢å¤–å·¥ä½œæœ‰ä¸¤ä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼Œä½¿ç”¨ç¡¬ä»¶æ‰§è¡Œå¹¶è¡Œå†…æ ¸çš„æ•ˆç‡è¦ä½å¾—å¤šã€‚ç¬¬äºŒï¼Œæ‰€æœ‰é¢å¤–çš„å·¥ä½œæ¶ˆè€—é¢å¤–çš„èƒ½é‡ï¼Œä¸åˆ©äºç§»åŠ¨åº”ç”¨ç­‰åœºæ™¯ã€‚Kogge-Stone å†…æ ¸çš„å¼ºå¤§ä¹‹å¤„åœ¨äºï¼Œå½“æœ‰è¶³å¤Ÿçš„ç¡¬ä»¶èµ„æºæ—¶ï¼Œå®ƒå¯ä»¥è¾¾åˆ°éå¸¸å¥½çš„æ‰§è¡Œé€Ÿåº¦ã€‚\n11.4 Parallel Scan with the Brent-Kung Algorithm å¯¹ä¸€ç»„å€¼è¿›è¡Œæ±‚å’Œæœ€å¿«çš„æ–¹æ³•æ˜¯ä½¿ç”¨å½’çº¦æ ‘ï¼Œå¦‚æœæœ‰è¶³å¤Ÿçš„æ‰§è¡Œå•å…ƒï¼Œå°±å¯ä»¥åœ¨ $O(N\\log_2N)$ æ—¶é—´å†…è®¡ç®— N ä¸ªå€¼çš„æ±‚å’Œç»“æœã€‚è¯¥æ ‘è¿˜å¯ä»¥ç”Ÿæˆå‡ ä¸ªå­åºåˆ—çš„å’Œï¼Œå®ƒä»¬å¯ç”¨äºè®¡ç®—æŸäº›æ‰«æè¾“å‡ºå€¼ã€‚ ä¸‹å›¾å±•ç¤ºäº†åŸºäº Brent-Kung åŠ æ³•å™¨è®¾è®¡çš„å¹¶è¡ŒåŒ…å«æ‰«æç®—æ³•çš„æ­¥éª¤ã€‚å›¾ä¸­ä¸ŠåŠéƒ¨åˆ†ï¼ŒèŠ± 4 æ­¥è®¡ç®—æ‰€æœ‰ 16 ä¸ªå…ƒç´ çš„å’Œã€‚ä¸‹åŠéƒ¨åˆ†æ˜¯ä½¿ç”¨åå‘æ ‘å°†éƒ¨åˆ†å’Œåˆ†é…åˆ°å¯ä»¥ä½¿ç”¨éƒ¨åˆ†å’Œçš„ä½ç½®ï¼Œä»¥è®¡ç®—è¿™äº›ä½ç½®çš„ç»“æœã€‚çº¦ç®€æ ‘ä¸­çš„æ±‚å’Œæ€»æ˜¯åœ¨å¯¹ä¸€ä¸ªè¿ç»­çš„èŒƒå›´å†…çš„è¾“å…¥å…ƒç´ è¿›è¡Œã€‚å› æ­¤ï¼Œæ±‚å’Œç´¯ç§¯åˆ° XY çš„æ¯ä¸ªä½ç½®çš„å€¼æ€»æ˜¯å¯ä»¥è¡¨ç¤ºä¸ºè¾“å…¥å…ƒç´ çš„ä¸€ä¸ª xiâ€¦xj çš„èŒƒå›´ï¼Œå…¶ä¸­ xi æ˜¯å¼€å§‹ä½ç½®ï¼Œ xj æ˜¯ç»“æŸä½ç½® (åŒ…æ‹¬)ã€‚\nA Parallel Inclusive Scan Algorithm Based on the Brentâ€“Kung Adder Design\nä¸‹å›¾å±•ç¤ºäº†åå‘æ ‘ä¸­æ¯ä¸ªä½ç½® (åˆ—) çš„çŠ¶æ€ï¼ŒåŒ…æ‹¬å·²ç»ç´¯ç§¯åˆ°è¯¥ä½ç½®çš„å€¼ä»¥åŠåœ¨åå‘æ ‘çš„æ¯çº§ (è¡Œ) ä¸Šéœ€è¦çš„é¢å¤–è¾“å…¥å…ƒç´ å€¼ (æµ…ç°è‰²è¡¨ç¤º 2ï¼Œæ·±ç°è‰²è¡¨ç¤º 1ï¼Œé»‘è‰²è¡¨ç¤º 0).\nProgression of Values in XY After Each Level of Additions in the Reverse Tree.\nä¸ŠåŠéƒ¨åˆ†å½’çº¦æ ‘çš„å†…æ ¸ä»£ç å¦‚ä¸‹ï¼Œå’Œç¬¬åç« ä¸åŒçš„æ˜¯\næˆ‘ä»¬æŠŠæ±‚å’Œç»“æœå†™åˆ°æœ€å¤§ç´¢å¼•çš„ä½ç½®ã€‚ æˆ‘ä»¬å°†çº¿ç¨‹ç´¢å¼•ç»„ç»‡æˆ $2^n-1$ çš„å½¢å¼ (n ä¸ºæ ‘çš„é«˜åº¦)ã€‚ 1 2 3 4 5 6 for (unsigned int stride = 1; stride \u0026lt; blockDim.x; stride *= 2) { __syncthreads(); if ((threadIdx.x + 1) % (2 * stride) == 0) { XY[threadIdx.x] += XY[threadIdx.x - stride]; } } è¿™ç§å½’çº¦æ–¹å¼çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯å­˜åœ¨æ§åˆ¶å‘æ•£é—®é¢˜ã€‚å› æ­¤éœ€è¦å°†çº¿ç¨‹çš„è¿ç»­éƒ¨åˆ†æ˜ å°„åˆ°ç´¢å¼•ä¸º $k*2^n-1$ å½¢å¼çš„ XY ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 // Mapping a continous section of threads to the XY positions for (unsigned int stride = 1; stride \u0026lt;= blockDim.x; stride *= 2) { __syncthreads(); unsigned int index = (threadIdx.x + 1) * 2 * stride - 1; // index of the left child if (index \u0026lt; SECTION_SIZE) { XY[index] += XY[index - stride]; } } åå‘æ ‘çš„å®ç°è¦å¤æ‚ä¸€äº›ã€‚æ­¥é•¿ä» SECTION_SIZE/4 å‡å°åˆ° 1. åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°† XY å…ƒç´ ç´¢å¼•å€¼ä»æ­¥é•¿å‡å» 1 åçš„ä¸¤å€çš„ä½ç½®å‘å³æ¨åˆ°è·ç¦»å…¶ä¸€ä¸ªæ­¥é•¿çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 // Reverse tree stride value decreases from SECTION_SIZE / 4 to 1 for (unsigned int stride = SECTION_SIZE / 4; stride \u0026gt; 0; stride /= 2) { __syncthreads(); unsigned int index = (threadIdx.x + 1) * 2 * stride - 1; // index of the left child if (index + stride \u0026lt; SECTION_SIZE) { XY[index + stride] += XY[index]; } } æˆ‘ä»¬å¯ä»¥çœ‹åˆ° Brent-Kung ç®—æ³•æ— è®ºåœ¨å½’çº¦é˜¶æ®µè¿˜æ˜¯åˆ†å‘é˜¶æ®µï¼Œéƒ½ä¸éœ€è¦è¶…è¿‡ SECTION_SIZE/2 çš„çº¿ç¨‹ã€‚å¹¶è¡Œæ‰«æä¸­çš„è¿ç®—æ€»æ•°ï¼ŒåŒ…æ‹¬å½’çº¦æ ‘ (N-1 æ¬¡) å’Œåå‘æ ‘ ( $N-1-log_2N$ æ¬¡) é˜¶æ®µï¼Œæ€»å…± $2N-2-log_2N$ æ¬¡ã€‚å½“è¾“å…¥é•¿åº¦å˜å¤§æ—¶ï¼ŒBrent-Kung ç®—æ³•æ‰§è¡Œçš„æ“ä½œæ•°é‡æ°¸è¿œä¸ä¼šè¶…è¿‡é¡ºåºç®—æ³•æ‰§è¡Œçš„æ“ä½œæ•°é‡çš„ 2 å€ã€‚\nBrent-Kung ç®—æ³•çš„æ´»åŠ¨çº¿ç¨‹çš„æ•°é‡é€šè¿‡å½’çº¦æ ‘æ¯” Kogge-Stone ç®—æ³•ä¸‹é™å¾—å¿«å¾—å¤šã€‚ç„¶è€Œï¼Œä¸€äº›éæ´»åŠ¨çº¿ç¨‹å¯èƒ½ä»ç„¶ä¼šæ¶ˆè€— CUDA è®¾å¤‡ä¸­çš„æ‰§è¡Œèµ„æºï¼Œå› ä¸ºå®ƒä»¬é€šè¿‡ SIMD ç»‘å®šåˆ°å…¶ä»–æ´»åŠ¨çº¿ç¨‹ã€‚è¿™ä½¿å¾—åœ¨ CUDA è®¾å¤‡ä¸Šå‰è€…å·¥ä½œæ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ä¸é‚£ä¹ˆæ˜æ˜¾ã€‚åœ¨æœ‰å……è¶³æ‰§è¡Œèµ„æºçš„æƒ…å†µä¸‹ï¼Œç”±äºéœ€è¦é¢å¤–çš„æ­¥éª¤æ¥æ‰§è¡Œåå‘æ ‘é˜¶æ®µï¼ŒBrent-Kung çš„æ—¶é—´æ˜¯ Kogge-Stone çš„ä¸¤å€ã€‚\n11.5 Coarsening for Even More Work Efficiency å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œç²—åŒ–æ‰«æåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬è®©æ¯ä¸ªçº¿ç¨‹å¯¹å…¶ç›¸é‚»çš„å­çº¿ç¨‹æ‰§è¡Œä¸²è¡Œæ‰«æã€‚éœ€è¦æ³¨æ„å¦‚æœæ¯ä¸ªçº¿ç¨‹é€šè¿‡è®¿é—®å…¨å±€å†…å­˜çš„è¾“å…¥ç›´æ¥æ‰§è¡Œæ‰«æï¼Œåˆ™å®ƒä»¬çš„è®¿é—®ä¸ä¼šåˆå¹¶ã€‚æ‰€ä»¥æˆ‘ä»¬ä»¥åˆå¹¶çš„æ–¹å¼åœ¨å…±äº«å†…å­˜å’Œå…¨å±€å†…å­˜ä¹‹é—´ä¼ è¾“æ•°æ®ï¼Œå¹¶åœ¨å…±äº«å†…å­˜ä¸­æ‰§è¡Œä¸æ˜¯é‚£ä¹ˆå¥½çš„å†…å­˜è®¿é—®æ¨¡å¼ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ¯ä¸ªå—ä¸­çš„æ‰€æœ‰çº¿ç¨‹åä½œå¹¶å¯¹ç”±æ¯ä¸ªéƒ¨åˆ†çš„æœ€åä¸€ä¸ªå…ƒç´ ç»„æˆçš„é€»è¾‘æ•°ç»„æ‰§è¡Œæ‰«ææ“ä½œã€‚åœ¨ç¬¬ä¸‰é˜¶æ®µï¼Œæ¯ä¸ªçº¿ç¨‹å°†å…¶å‰ä¸€ä¸ªéƒ¨åˆ†çš„æœ€åä¸€ä¸ªå…ƒç´ çš„æ–°å€¼ä¸è‡ªèº«éƒ¨åˆ†é™¤æœ€åä¸€ä¸ªçš„æ‰€æœ‰å…ƒç´ ç›¸åŠ ã€‚å¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ã€‚\nA Three-phase Parallel Scan for Higher Work Efficiency\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #define CORASE_FACTOR 4 #define SUBSECTION_SIZE (SECTION_SIZE / CORASE_FACTOR) __global__ void Corasened_Scan_Kernel(int* X, int* Y, unsigned int N) { // Partition X into blockDim.x subsections // Load X into shared memory in coalesced fashion __shared__ float XY[SECTION_SIZE]; __shared__ float subXY[SUBSECTION_SIZE]; for (int i = 0; i \u0026lt; SECTION_SIZE; i+= blockDim.x) { XY[threadIdx.x + i] = X[threadIdx.x + i]; } __syncthreads(); // Part 1: Compute prefix sum of each subsection in sequenial for (int i = 1; i \u0026lt; SUBSECTION_SIZE; i++) { XY[threadIdx.x * SUBSECTION_SIZE + i] += XY[threadIdx.x * SUBSECTION_SIZE + i - 1]; } __syncthreads(); // Part 2: Compute prefix sum of the last element of each subsection in parallel unsigned int lastElemId = (blockIdx.x + 1) * blockDim.x * CORASE_FACTOR - 1; subXY[threadIdx.x] = XY[(threadIdx.x + 1) * SUBSECTION_SIZE - 1]; float temp = 0.0f; for (int stride = 1; stride \u0026lt; SUBSECTION_SIZE; stride *= 2) { __syncthreads(); if (threadIdx.x \u0026gt;= stride) { temp = subXY[threadIdx.x] + subXY[threadIdx.x - stride]; } __syncthreads(); if (threadIdx.x \u0026gt;= stride) { subXY[threadIdx.x] = temp; } } __syncthreads(); // Part 3: Add the reduction sum of the previous subsection to the current subsection (except the last element) for (int i = 1; i \u0026lt; SUBSECTION_SIZE - 1; i++) { XY[threadIdx.x * SUBSECTION_SIZE + i] += subXY[threadIdx.x]; } __syncthreads(); // Store back to Y for (int i = 0; i \u0026lt; SECTION_SIZE; i+= blockDim.x) { Y[threadIdx.x + i] = XY[threadIdx.x + i]; } } 11.6 Segmented Parallel Scan for Arbitrary-length Inputs å¯¹äºé•¿åº¦å¾ˆå¤§çš„è¾“å…¥æ•°æ®ï¼Œæˆ‘ä»¬é¦–å…ˆå°†å…¶åˆ’åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼Œä»¥ä¾¿æ¯ä¸ªéƒ¨åˆ†éƒ½å¯ä»¥æ”¾å…¥æµå¤šå¤„ç†å™¨çš„å…±äº«å†…å­˜ä¸­ï¼Œå¹¶ç”±å•ä¸ªå—è¿›è¡Œå¤„ç†ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œç¬¬ä¸€æ­¥åœ¨æ¯ä¸ªå—å†…éƒ¨å…ˆè¿›è¡Œæ‰«æï¼Œå®Œæˆåæ¯ä¸ªæ‰«æå—çš„æœ€åä¸€ä¸ªè¾“å‡ºå…ƒç´ ä¸ºè¯¥æ‰«æå—çš„æ‰€æœ‰è¾“å…¥å…ƒç´ çš„å’Œã€‚ç¬¬äºŒæ­¥å°†æ¯ä¸ªæ‰«æå—çš„æœ€åä¸€ä¸ªç»“æœå…ƒç´ æ”¶é›†åˆ°ä¸€ä¸ªæ•°ç»„ä¸­ï¼Œå¹¶å¯¹è¿™äº›è¾“å‡ºå…ƒç´ æ‰§è¡Œæ‰«æã€‚ç¬¬ä¸‰æ­¥å°†ç¬¬äºŒæ­¥æ‰«æè¾“å‡ºå€¼ä¸å…¶å¯¹åº”æ‰«æå—çš„å€¼ç›¸åŠ ã€‚\nA Hierarchical Scan for Arbitrary Length Inputs\næˆ‘ä»¬å¯ä»¥ç”¨ä¸‰ä¸ªå†…æ ¸å®ç°åˆ†æ®µæ‰«æã€‚ç¬¬ä¸€ä¸ªå†…æ ¸ä¸ 11.5 èŠ‚çš„å†…æ ¸åŸºæœ¬ç›¸åŒï¼Œç¬¬äºŒä¸ªå†…æ ¸åªæ˜¯å•ä¸ªçº¿ç¨‹å—çš„å¹¶è¡Œæ‰«æå†…æ ¸ï¼Œç¬¬ä¸‰ä¸ªå†…æ ¸å°† S æ•°ç»„å’Œ Y æ•°ç»„ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶è¾“å‡ºå†™å› Y.\n11.7 Single-pass Scan for Memory Access Efficiency ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch11/","summary":"Personal notebook 11 of Programming Massively Parallel","title":"PMPP Learning-Chapter 11 Prefix sum (scan)-An Introduction to Work Efficiency in Parallel Algorithms"},{"content":"10 Reduction and Minimizing Divergence å½’çº¦ (Reduction) æ˜¯ä»è¾“å…¥æ•°ç»„è®¡ç®—å‡ºä¸€ä¸ªæ•°çš„è¿ç®—ã€‚\n10.1 Background å½’çº¦æ˜¯ä»è¾“å…¥æ•°ç»„è®¡ç®—å‡ºä¸€ä¸ªæ•°çš„è¿ç®—ï¼Œé€šå¸¸æ˜¯é€šè¿‡å¯¹æ•°ç»„ä¸­çš„å…ƒç´ è¿›è¡ŒæŸç§äºŒå…ƒè¿ç®—æ¥å®ç°çš„ã€‚å¦‚æœäºŒå…ƒæ“ä½œç¬¦å…·æœ‰å®šä¹‰è‰¯å¥½çš„æ’ç­‰å€¼ (ä¾‹å¦‚åŠ æ³•ä¸­çš„ 0ï¼Œä¹˜æ³•ä¸­çš„ 1)ï¼Œåˆ™å¯ä»¥ä¸ºåŸºäºè¯¥æ“ä½œç¬¦è¿›è¡Œè¿ç®—çš„ä¸€ä¸ªæ•°ç»„ä¸­çš„å€¼å®šä¹‰å½’çº¦æ“ä½œã€‚å¯ä»¥é€šè¿‡é¡ºåºéå†æ•°ç»„çš„æ¯ä¸ªå…ƒç´ æ¥è¿›è¡Œå½’çº¦ã€‚ä¸‹é¢ä¼ªä»£ç ä¸ºè¿ç®—ç¬¦çš„ä¸€èˆ¬å½’çº¦å½¢å¼ï¼Œå®ƒè¢«å®šä¹‰ä¸ºæ¥å—ä¸¤ä¸ªè¾“å…¥å¹¶è¿”å›ä¸€ä¸ªå€¼çš„å‡½æ•°ã€‚\n1 2 3 4 acc = IDENTITY; for (i = 0; i \u0026lt; n; i++) { acc = Operator(acc, input[i]); } 10.2 Reduction Trees å¹¶è¡Œå½’çº¦çš„åŸºæœ¬æ€æƒ³å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ—¶é—´ç«–ç›´å‘ä¸‹å¢åŠ ï¼Œæ°´å¹³æ–¹å‘ä¸ºçº¿ç¨‹åœ¨æ¯ä¸ªæ—¶é—´ç‚¹å¹¶è¡Œæ‰§è¡Œçš„æ´»åŠ¨ã€‚å¹¶è¡Œçº¦ç®€å‡å®šè¾“å‡ºä¸éšç€è¾“å…¥å€¼è¿›è¡Œè¿ç®—çš„é¡ºåºè€Œæ”¹å˜ (å³å…·æœ‰äº¤æ¢å¾‹)ã€‚\nA Parallel Max Reduction Tree\nä¸Šå›¾ä¸­çš„å¹¶è¡Œå½’çº¦æ¨¡å¼è¢«ç§°ä¸ºå½’çº¦æ ‘ (reduction tree)ï¼Œå› ä¸ºå®ƒçœ‹èµ·æ¥åƒä¸€æ£µå¶å­æ˜¯åŸå§‹è¾“å…¥å…ƒç´ ï¼Œæ ¹æ˜¯æœ€ç»ˆç»“æœçš„æ ‘ã€‚å½’çº¦æ ‘çš„è¾¹æ˜¯æ— å®é™…æ„ä¹‰ï¼Œåªæ˜¯åæ˜ äº†ä»ä¸€ä¸ªæ—¶é—´æ­¥æ‰§è¡Œçš„æ“ä½œåˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥æ‰§è¡Œçš„æ“ä½œçš„ä¿¡æ¯æµã€‚æ‰§è¡Œçš„æ“ä½œæ€»æ•°æ˜¯ä¸€ä¸ªå‡ ä½•çº§æ•° $\\frac{1}{2}N + \\frac{1}{2^2}N + \\cdots + \\frac{1}{N}N = N-1$. å½’çº¦æ ‘éœ€è¦ $log_{2}{N}$ æ­¥éª¤æ¥å®Œæˆã€‚å®Œæˆè®¡ç®—æ‰€éœ€çš„èµ„æºæ•°é‡éšç€æ—¶é—´æ­¥çš„å¢åŠ è€Œè¿…é€Ÿå‡å°‘ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„å¹¶è¡Œåº¦ä¸æ‰€éœ€çš„æ‰§è¡Œå•å…ƒæ•°é‡ç›¸åŒã€‚å¹¶è¡Œåº¦å’Œèµ„æºæ¶ˆè€—éšç€æ—¶é—´æ­¥é•¿çš„å‰§çƒˆå˜åŒ–è®©å½’çº¦æ ‘æˆä¸ºä¸€ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„å¹¶è¡Œæ¨¡å¼ã€‚\n10.3 A Simple Reduction Kernel ä»å®ç°ä¸€ä¸ªåœ¨å•ä¸ªçº¿ç¨‹å—å†…æ‰§è¡Œæ±‚å’Œå½’çº¦æ ‘çš„å†…æ ¸å¼€å§‹ã€‚å…¶å¹¶è¡Œæ‰§è¡Œçš„æƒ…å†µå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå‡è®¾è¾“å…¥æ•°ç»„ä½äºå…¨å±€å†…å­˜ä¸­ï¼Œå¹¶ä¸”åœ¨è°ƒç”¨å†…æ ¸å‡½æ•°æ—¶å°†å…¶æŒ‡é’ˆä½œä¸ºè¾“å…¥å‚æ•°ä¼ å…¥ã€‚æ¯ä¸ªçº¿ç¨‹è¢«åˆ†é…åˆ°ç´¢å¼•2*threadIdx.x å¤„ï¼Œæ¯ä¸€æ­¥å½’çº¦çš„ç»“æœä¹Ÿä¼šè¢«å†™å…¥æ­¤å¤„ã€‚\nThreads Arrangment of the Input Array in the Simple Kernel\nå¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼Œfor å¾ªç¯ä¸­çš„ __syncthreads() ç¡®ä¿ä»»ä½•ä¸€ä¸ªçº¿ç¨‹å¼€å§‹ä¸‹ä¸€æ¬¡è¿­ä»£ä¹‹å‰ï¼Œæ‰€æœ‰çº¿ç¨‹éƒ½å·²ç»å®Œæˆäº†ä¸Šä¸€æ¬¡è¿­ä»£çš„è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 __global__ void SimpleReductionKernel(float* input, float* output) { // launch single block with 1/2 #elements threads unsigned int i = threadIdx.x * 2; for (unsigned int stride = 1; stride = blockDim.x; stride *= 2) { if (threadIdx.x % 2 == 0) { input[i] += input[i + stride]; } __syncthreads(); // Ensure partial sums have been written to the destinition. } if (threadIdx.x == 0) { *output = input[0]; } } 10.4 Minimizing Control Divergence ä¸Šé¢ä»£ç åœ¨æ¯æ¬¡è¿­ä»£ä¸­å¯¹æ´»åŠ¨å’Œéæ´»åŠ¨çº¿ç¨‹çš„ç®¡ç†å¯¼è‡´äº†æ§åˆ¶å‘æ•£ã€‚åªæœ‰é‚£äº›çº¿ç¨‹çš„ threadIdx.x ä¸ºå¶æ•°çš„çº¿ç¨‹åœ¨ç¬¬äºŒæ¬¡è¿­ä»£ä¸­æ‰§è¡ŒåŠ æ³•æ“ä½œã€‚ç”±äºæ§åˆ¶å‘æ•£é€ æˆçš„æ‰§è¡Œèµ„æºæµªè´¹éšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ è€Œå¢åŠ ï¼Œç¬¬äºŒæ¬¡è¿­ä»£ä¸­æ¯ä¸ª warp åªæœ‰ä¸€åŠçš„çº¿ç¨‹æ‰§è¡ŒåŠ æ³•æ“ä½œï¼Œä½†æ¶ˆè€—çš„è®¡ç®—èµ„æºå´æ˜¯ç›¸åŒçš„ã€‚å¦‚æœè¾“å…¥æ•°ç»„çš„å¤§å°å¤§äº32ï¼Œæ•´ä¸ª warp å°†åœ¨ç¬¬äº”æ¬¡è¿­ä»£åä¸å†æ‰§è¡ŒåŠ æ³•æ“ä½œã€‚æ¶ˆè€—çš„æ‰§è¡Œèµ„æºçš„æ€»æ•°ä¸æ‰€æœ‰è¿­ä»£ä¸­æ´»åŠ¨ warp çš„æ€»æ•°æˆæ­£æ¯”ï¼Œè®¡ç®—æ–¹å¼å¦‚ä¸‹ã€‚\n$$\\text{active warps} = (5+\\frac{1}{2}+\\frac{1}{4}+\\cdots+1)*\\frac{N}{64}*32$$å…¶ä¸­ N/64 ä»£è¡¨å¯åŠ¨çš„ warp æ€»æ•°ã€‚æ¯ä¸ª warp åœ¨å‰äº”æ¬¡è¿­ä»£ä¸­éƒ½å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œä¹‹åæ¯æ¬¡è¿­ä»£éƒ½åªæœ‰ä¸Šæ¬¡ä¸€åŠçš„çº¿ç¨‹åœ¨æ´»åŠ¨çŠ¶æ€ï¼Œç›´åˆ°åªå‰©æœ€åä¸€ä¸ªã€‚ æ¯æ¬¡è¿­ä»£ä¸­æ´»åŠ¨çº¿ç¨‹è®¡ç®—å‡ºçš„ç»“æœä¸ªæ•°ç­‰äºæ´»åŠ¨çº¿ç¨‹çš„æ€»æ•°\n$$\\text{active threads} = \\frac{N}{64}*(32+16+8+4+2+1)+\\frac{N}{64}*\\frac{1}{2}*1+\\frac{N}{64}*\\frac{1}{4}*1+\\cdots+1$$æ¯ä¸ª warp åœ¨å‰äº”æ¬¡è¿­ä»£ä¸­å¤„äºæ´»åŠ¨çŠ¶æ€çš„çº¿ç¨‹æ•°å‡åŠï¼Œä¹‹åæ¯æ¬¡è¿­ä»£ä¸­æ¯ä¸ªå¤„äºæ´»åŠ¨çŠ¶æ€çš„ warp åªæœ‰ä¸€ä¸ªçº¿ç¨‹å¤„äºæ´»åŠ¨çŠ¶æ€ã€‚è¿™ä¸ªç»“æœåº”è¯¥éå¸¸ç›´è§‚çš„ï¼Œå› ä¸ºå…¶æ­£ç­‰äºå®Œæˆå½’çº¦æ‰€éœ€çš„æ“ä½œæ€»æ•°ã€‚ ç”±æ­¤æˆ‘ä»¬å¯ä»¥å¾—å‡ºå½“è¾“å…¥å¤§å°ä¸º 256 æ—¶ï¼Œæ‰§è¡Œèµ„æºåˆ©ç”¨ç‡ä¸º 255/736 = 0.35. å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸ºäº†å‡å°‘æ§åˆ¶åˆ†æ•£åº”è¯¥å®‰æ’çº¿ç¨‹å’Œå®ƒä»¬è®¡ç®—çš„ä½ç½®ä½¿å¾—èƒ½å¤Ÿéšç€æ—¶é—´çš„æ¨ç§»è€Œå½¼æ­¤é è¿‘ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›æ­¥å¹…éšç€æ—¶é—´çš„æ¨ç§»è€Œå‡å°‘ï¼Œè€Œä¸æ˜¯å¢åŠ ã€‚ä¿®æ”¹åçš„å†…æ ¸å‡½æ•°å¦‚ä¸‹ï¼Œæ¯æ¬¡è¿­ä»£ä¸­æ‰§è¡ŒåŠ æ³•æ“ä½œçš„çº¿ç¨‹æ•°æ˜¯ç›¸åŒçš„ï¼Œä½†ç›´åˆ°åŒæ—¶è¿›è¡ŒåŠ æ³•çš„çº¿ç¨‹æ•°å°äº 32 ä¹‹å‰ï¼Œä¸€ä¸ª warp çš„çº¿ç¨‹æ•°æ‰€èµ°çš„åˆ†æ”¯ç›¸åŒã€‚\nArrangement with Less Control Divergence\n1 2 3 4 5 6 7 8 9 10 11 12 13 __global__ void ConvergentSumReductionKernel(float* input, float* output) { unsigned int i = threadIdx.x; for (unsigned int stride = blockDim.x; stride \u0026gt;= 1; stride /= 2) { // Decrease stride to reduce control divergence if (threadIdx.x \u0026lt; stride) { input[i] += input[i + stride]; } __syncthreads(); } if (threadIdx.x == 0) { *output = input[0]; } } è¿™ç§æƒ…å†µä¸‹çš„è¿›è¡Œè§„çº¦æ“ä½œæ¶ˆè€—çš„è®¡ç®—èµ„æºæ€»æ•°ä¸º $$(\\frac{N}{64}*1 + \\frac{N}{64}*\\frac{1}{2}*1 + \\frac{N}{64}*\\frac{1}{4}*1 + \\cdots + 1 + 5*1) * 32 $$ 5*1 ä»£è¡¨æœ€åçš„äº”æ¬¡è¿­ä»£ï¼Œåªæœ‰ä¸€ä¸ªæ´»åŠ¨çš„warpï¼Œå¹¶ä¸”å®ƒçš„æ‰€æœ‰32ä¸ªçº¿ç¨‹éƒ½æ¶ˆè€—æ‰§è¡Œèµ„æºï¼Œå³ä½¿åªæœ‰ä¸€å°éƒ¨åˆ†çº¿ç¨‹æ˜¯æ´»åŠ¨çŠ¶æ€ã€‚æ‰§è¡Œèµ„æºçš„åˆ©ç”¨ç‡ä¸º 255/384 = 0.66.\n10.5 Minimizing Memory Divergence ä¸Šé¢çš„å†…æ ¸è¿˜æœ‰å†…å­˜åˆ†æ•£çš„é—®é¢˜ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹å¯¹å…¨å±€å†…å­˜æ‰§è¡Œ 2 æ¬¡è¯»å–å’Œ 1 æ¬¡å†™å…¥ã€‚ç¬¬ä¸€æ¬¡ä»è‡ªå·±çš„ä½ç½®è¯»å–ï¼Œç¬¬äºŒæ¬¡ä»ç¦»è‡ªå·± stride çš„ä½ç½®è¯»å–ï¼Œç›¸åŠ åå†™å…¥åˆ°è‡ªå·±çš„ä½ç½®ã€‚ 10.3 èŠ‚çš„å†…æ ¸ä»£ç ä¸­ï¼Œç¬¬ä¸€æ¬¡è¿­ä»£æ¯ä¸ª warp ä¸­çš„ç›¸é‚»çº¿ç¨‹é—´éš” 2 ä¸ªå…ƒç´ ï¼Œå› æ­¤è¦è®¿é—® 2 ä¸ªå†…å­˜ä½ç½®ï¼Œæ­¤åæ¯æ¬¡è¿­ä»£ stride éƒ½å¢åŠ ï¼Œç›´åˆ°ç¬¬å…­æ¬¡è¿­ä»£æ—¶ï¼Œæ¯ä¸ª warp éƒ½åªæœ‰ä¸€ä¸ªçº¿ç¨‹å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œåªç”¨è®¿é—® 1 ä¸ªä½ç½®ã€‚å› æ­¤è¿›è¡Œå†…å­˜è®¿é—®çš„æ€»æ¬¡æ•°ä¸º $$(5*\\frac{N}{64}*2+\\frac{N}{64}*1+\\frac{N}{64}*\\frac{1}{2}*1+\\cdots+1)*3$$ 10.4 èŠ‚çš„å†…æ ¸ä»£ç ä¸­ï¼Œæ¯ä¸ª warp åœ¨ä»»ä½•è¯»æˆ–å†™æ—¶åªè¿›è¡Œä¸€ä¸ªå…¨å±€å†…å­˜è¯·æ±‚ï¼Œç›´åˆ°è¯¥ warp ä¸­çš„æ‰€æœ‰çº¿ç¨‹éƒ½å¤„äºéæ´»åŠ¨çŠ¶æ€ã€‚æœ€åäº”æ¬¡è¿­ä»£çš„çº¿ç¨‹éƒ½ä½äºä¸€ä¸ª warp ä¸­ï¼Œå› æ­¤è¿›è¡Œå†…å­˜è®¿é—®çš„æ€»æ¬¡æ•°ä¸º $$((\\frac{N}{64}*1+\\frac{N}{64}*\\frac{1}{2}*1+\\frac{N}{64}*\\frac{1}{4}*1+\\cdots+1)+5)*3$$ å¯¹äºé•¿åº¦ä¸º 2048 çš„è¾“å…¥ï¼Œå‰è€…å’Œåè€…å…¨å±€å†…å­˜è¯·æ±‚çš„æ€»æ•°åˆ†åˆ«ä¸º 1149 å’Œ 204. åè€…åœ¨ä½¿ç”¨ DRAM å¸¦å®½æ–¹é¢ä¹Ÿå…·æœ‰æ›´é«˜çš„æ•ˆç‡ã€‚\n10.6 Minimizing Global Memory Accesses é€šè¿‡ä½¿ç”¨å…±äº«å†…å­˜ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ”¹è¿› 10.4 èŠ‚çš„å†…æ ¸ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œçº¿ç¨‹å°†å®ƒä»¬çš„éƒ¨åˆ†å’Œç»“æœå€¼å†™å…¥å…¨å±€å†…å­˜ï¼Œè¿™äº›å€¼åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ç”±ç›¸åŒçš„çº¿ç¨‹å’Œå…¶ä»–çº¿ç¨‹é‡æ–°è¯»å–ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé€šè¿‡å°†éƒ¨åˆ†å’Œç»“æœä¿å­˜åœ¨å…±äº«å†…å­˜ä¸­ï¼Œå¯ä»¥è¿›ä¸€æ­¥æé«˜æ‰§è¡Œé€Ÿåº¦ã€‚\nUse Shared Memory to Reduce Accesses from the Global Memory å¯¹åº”çš„ä»£ç å¦‚ä¸‹ï¼Œæ¯ä¸ªçº¿ç¨‹ä»å…¨å±€å†…å­˜åŠ è½½å¹¶ 2 ä¸ªè¾“å…¥å…ƒç´ å¹¶å°†éƒ¨åˆ†å’Œå†™å…¥å…±äº«å†…å­˜ã€‚å‰©ä¸‹çš„æ‰€æœ‰è¿­ä»£ä¸­çš„è®¡ç®—éƒ½åœ¨å…±äº«å†…å­˜ä¸­è¿›è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #define BLOCK_DIM 512 __global__ void SharedMemoryReductionKernel(float* input) { __shared__ float input_s[BLOCK_DIM]; unsigned int i = threadIdx.x; input_s[i] = input[i] + input[i + blockDim.x]; // Partial sum of first iteration for (unsigned int stride = blockDim.x / 2; stride \u0026gt;= 1; stride /= 2) { __syncthreads(); // Ensure all partial sums have been written to shared memory if (threadIdx.x \u0026lt; stride) { input_s[i] += input_s[i + stride]; // Partial sum of subsequent iterations } } if (threadIdx.x == 0) { input[0] = input_s[0]; // Write final sum to output } } å…¨å±€å†…å­˜è®¿é—®çš„æ¬¡æ•°å‡å°‘åˆ°åˆå§‹åŠ è½½è¾“å…¥æ•°ç»„å’Œæœ€ç»ˆå†™å…¥ input[0]ï¼Œæ€»å…±åªæœ‰ (N/32) + 1 ä¸ªå…¨å±€å†…å­˜è¯·æ±‚ã€‚\n10.7 Hierarchical Reduction for Arbitrary Input Length ç”±äº __syncthreads() åªå¯¹åŒä¸€å—ä¸­çš„çº¿ç¨‹æœ‰æ•ˆï¼Œå› æ­¤æ— æ³•åœ¨ä¸åŒå—ä¹‹é—´åŒæ­¥ã€‚ä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨åˆ†çº§å½’çº¦æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå…¶æ€æƒ³æ˜¯å°†è¾“å…¥æ•°ç»„åˆ’åˆ†ä¸ºå¤šä¸ªé€‚åˆäºçº¿ç¨‹å—å¤§å°çš„æ®µã€‚ç„¶åï¼Œæ‰€æœ‰å—éƒ½ç‹¬ç«‹åœ°æ‰§è¡Œå½’çº¦æ ‘ï¼Œå¹¶ä½¿ç”¨åŸå­åŠ æ³•æ“ä½œå°†å®ƒä»¬çš„ç»“æœç´¯ç§¯åˆ°æœ€ç»ˆè¾“å‡ºã€‚\nSegmented Multiblock Reduction Using Atomic Operations å¯¹åº”çš„å†…æ ¸ä»£ç å¦‚ä¸‹ã€‚æ¯ä¸ªçº¿ç¨‹å—å¤„ç† 2*blockDim.x ä¸ªå…ƒç´ ã€‚åœ¨æ¯ä¸ªçº¿ç¨‹å—å†…ï¼Œæˆ‘ä»¬é€šè¿‡çº¿ç¨‹æ‰€å±å—çš„æ®µèµ·å§‹ä½ç½®åŠ ä¸Š threadIdx.x ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ†é…å…¶è¾“å…¥å…ƒç´ çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 __global__ void SegmentedSumReductionKernel(float* input, float* output) { __shared__ float input_s[BLOCK_DIM]; unsigned int segment = blockIdx.x * blockDim.x * 2; // Each block processes 2*blockDim.x elements unsigned int i = segment + threadIdx.x; unsigned int t = threadIdx.x; input_s[t] = input[t + blockDim.x]; // Partial sum of first iteration of each block for (unsigned int stride = blockDim.x / 2; stride \u0026gt;= 1; stride /= 2) { __syncthreads(); // Ensure all partial sums have been written to shared memory if (t \u0026lt; stride) { input_s[t] += input_s[t + stride]; // Partial sum of subsequent iterations } } if (t == 0) { atomicAdd(\u0026amp;output, input_s[0]); // Write final sum to output } } 10.8 Thread Coarsening for Reduced Overhead åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿‡çš„å½’çº¦å†…æ ¸éƒ½è¯•å›¾é€šè¿‡ä½¿ç”¨å°½å¯èƒ½å¤šçš„çº¿ç¨‹æ¥æœ€å¤§åŒ–å¹¶è¡Œæ€§ã€‚è‹¥çº¿ç¨‹å—å¤§å°ä¸º 1024 ä¸ªçº¿ç¨‹ï¼Œåˆ™éœ€è¦å¯åŠ¨çš„çº¿ç¨‹å—æ•°é‡ä¸º N/2048. ä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•å°†çº¿ç¨‹ç²—åŒ–ã€‚çº¿ç¨‹ç‹¬ç«‹åœ°æ·»åŠ å®ƒä»¬è´Ÿè´£çš„å››ä¸ªå…ƒç´ ï¼Œå®ƒä»¬ä¸éœ€è¦åŒæ­¥ï¼Œç›´åˆ°å°†æ‰€æœ‰çš„å››ä¸ªå…ƒç´ ç›¸åŠ ä¹‹åæ‰èƒ½å°†éƒ¨åˆ†å’Œç»“æœå†™å…¥å…±äº«å†…å­˜ã€‚å‰©ä¸‹çš„æ­¥éª¤ä¸ 10.7 èŠ‚åç»­ç›¸åŒã€‚\nThread Coarsening in Reduction å¯¹åº”çš„å†…æ ¸å¦‚ä¸‹ï¼Œæˆ‘ä»¬ä¹˜ä»¥ COARSE_FACTOR æ¥è¡¨ç¤ºæ¯ä¸ªçº¿ç¨‹å—çš„è´Ÿè´£çš„æ®µçš„å¤§å°æ˜¯åŸæ¥çš„ COARSE_FACTOR å€ã€‚éƒ¨åˆ†å’Œç´¯åŠ åˆ°å±€éƒ¨å˜é‡ sum ä¸­ï¼Œå¹¶ä¸”å› ä¸ºçº¿ç¨‹æ˜¯ç‹¬ç«‹è¿è¡Œçš„ï¼Œåœ¨å¾ªç¯ä¸­ä¸ä¼šè°ƒç”¨ __syncthreads().\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #define COARSE_FACTOR 2 __global__ void CoarsenedSumReductionKernel(float* input, float* output) { __shared__ float input_s[BLOCK_DIM]; unsigned int segment = blockIdx.x * COARSE_FACTOR * blockDim.x * 2; unsigned int i = segment + threadIdx.x; unsigned int t = threadIdx.x; float sum = input[i]; for (int tile = 1; tile \u0026lt; COARSE_FACTOR; tile++) { // Partitial sum is accumulated independently sum += input[i + tile * blockDim.x]; } input_s[t] = sum; for (unsigned int stride = blockDim.x / 2; stride \u0026gt;= 1; stride /= 2) { __syncthreads(); if (t \u0026lt; stride) { input_s[t] += input_s[t + stride]; } } if (t == 0) { atomicAdd(\u0026amp;output, input_s[0]); } } ä¸‹å›¾æ¯”è¾ƒäº†ä¸¤ä¸ªåŸå§‹çº¿ç¨‹å—åœ¨æ²¡æœ‰è¿›è¡Œçº¿ç¨‹ç²—åŒ–ä¸‹è¢«ç¡¬ä»¶é¡ºåºæ‰§è¡Œæƒ…å†µï¼Œå›¾ A å½“ç¬¬ä¸€ä¸ªçº¿ç¨‹å—å®Œæˆåï¼Œç¡¬ä»¶è°ƒåº¦ç¬¬äºŒä¸ªçº¿ç¨‹å—ï¼Œåœ¨ä¸åŒçš„æ•°æ®æ®µä¸Šæ‰§è¡Œç›¸åŒçš„æ­¥éª¤ã€‚å›¾ B çš„è¿™ä¸ªçº¿ç¨‹å—å¼€å§‹éœ€è¦ä¸‰ä¸ªæ­¥éª¤ï¼Œå…¶ä¸­æ¯ä¸ªçº¿ç¨‹å¯¹å®ƒè´Ÿè´£çš„å››ä¸ªå…ƒç´ æ±‚å’Œã€‚å‰©ä¸‹çš„ä¸‰ä¸ªæ­¥éª¤æ‰§è¡Œå½’çº¦æ ‘ï¼Œæ¯ä¸ªæ­¥éª¤ä¸­æœ‰ä¸€åŠçš„çº¿ç¨‹é€€å‡ºæ´»åŠ¨çŠ¶æ€ã€‚ç›¸æ¯”å›¾ Aï¼Œå›¾ B åªéœ€è¦6ä¸ªæ­¥éª¤ (è€Œä¸æ˜¯ 8 ä¸ª)ï¼Œå…¶ä¸­ 3 ä¸ªæ­¥éª¤ (è€Œä¸æ˜¯ 2 ä¸ª) å……åˆ†åˆ©ç”¨äº†ç¡¬ä»¶ã€‚ å½“æˆ‘ä»¬ç²—åŒ–çº¿ç¨‹æ—¶ï¼Œå¹¶è¡Œå®Œæˆçš„å·¥ä½œå°±ä¼šå‡å°‘ã€‚å› æ­¤ï¼Œå¢åŠ ç²—åŒ–å› å­å°†å‡å°‘ç¡¬ä»¶æ­£åœ¨åˆ©ç”¨çš„æ•°æ®å¹¶è¡Œæ€§çš„æ•°é‡ã€‚\nComparing Parallel Reduction with and without Thread Coarsening\n","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch10/","summary":"Personal notebook 10 of Programming Massively Parallel","title":"PMPP Learning-Chapter 10 Reduction and Minimizing Divergence"},{"content":"8 Stencil åœ¨æµä½“åŠ¨åŠ›å­¦ã€çƒ­ä¼ å¯¼ã€ç‡ƒçƒ§ã€å¤©æ°”é¢„æŠ¥ã€æ°”å€™æ¨¡æ‹Ÿå’Œç”µç£å­¦ç­‰åº”ç”¨é¢†åŸŸï¼Œæ¨¡æ¿æ˜¯æ±‚è§£åå¾®åˆ†æ–¹ç¨‹çš„æ•°å€¼æ–¹æ³•çš„åŸºç¡€ã€‚æ¨¡æ¿æ–¹æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œå°†åå¾®åˆ†æ–¹ç¨‹çš„æ±‚è§£è½¬åŒ–ä¸ºæ±‚è§£ä¸€ä¸ªå±€éƒ¨çš„çº¿æ€§æ–¹ç¨‹ç»„ï¼Œç„¶ååœ¨è¯¥å±€éƒ¨è¿›è¡Œè¿­ä»£æ±‚è§£ï¼Œæœ€åå¾—åˆ°å…¨å±€è§£ã€‚ç”±äºæ±‚è§£å¾®åˆ†é—®é¢˜æ—¶å¯¹æ•°å€¼ç²¾åº¦çš„è¦æ±‚ï¼Œæ¨¡æ¿å¤„ç†çš„æ•°æ®å¾€å¾€æ˜¯é«˜ç²¾åº¦çš„æµ®åŠ¨æ•°æ®ï¼Œå¯¹äº tiling æŠ€æœ¯æ¥è¯´ï¼Œè¿™éœ€è¦æ¶ˆè€—æ›´å¤šçš„ç‰‡ä¸Šå†…å­˜ã€‚\nBackgroud ç”¨è®¡ç®—æœºæ•°å€¼è®¡ç®—å’Œæ±‚è§£å‡½æ•°ã€æ¨¡å‹ã€å˜é‡å’Œæ–¹ç¨‹çš„ç¬¬ä¸€æ­¥æ˜¯å°†å®ƒä»¬è½¬æ¢æˆç¦»æ•£çš„è¡¨ç¤ºå½¢å¼ã€‚è¡¨ç¤ºçš„ä¿çœŸåº¦æˆ–è¿™äº›è¿‘ä¼¼æ’å€¼æŠ€æœ¯çš„å‡½æ•°å€¼çš„å‡†ç¡®æ€§å–ä¸€æ–¹é¢å†³äºç½‘æ ¼ç‚¹ä¹‹é—´çš„é—´è·:é—´è·è¶Šå°ï¼Œè¿‘ä¼¼è¶Šå‡†ç¡®ã€‚ç¦»æ•£è¡¨ç¤ºçš„ä¿çœŸåº¦è¿˜å–å†³äºæ‰€ä½¿ç”¨æ•°å­—çš„ç²¾åº¦ã€‚æœ¬ç« ä¸­å°†é‡ç‚¹å…³æ³¨è®¡ç®—æ¨¡å¼ï¼Œå…¶ä¸­æ¨¡æ¿åº”ç”¨äºæ‰€æœ‰ç›¸å…³çš„è¾“å…¥ç½‘æ ¼ç‚¹ä»¥ç”Ÿæˆæ‰€æœ‰ç½‘æ ¼ç‚¹çš„è¾“å‡ºå€¼ï¼Œè¿™å°†è¢«ç§°ä¸ºæ¨¡æ¿æ‰«æ (stencil sweep).\nOne-dimensional Stencil Example\nTwo-dimensional \u0026amp; Three-dimensional Stencil Example\n8.2 Parallel stencil: A Basic Algorithm 2D æƒ…å†µä¸‹è¾“å‡ºç½‘æ ¼çš„ tiling å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªçº¿ç¨‹å—è´Ÿè´£ä¸€ä¸ª 4*4 å¤§å°çš„è¾“å‡º tile. ä¸€ä¸ªåŸºæœ¬çš„ 3D stencil å†…æ ¸å‡½æ•°å¦‚ä¸‹ï¼Œå…¶ä¸­æ¯ä¸ªçº¿ç¨‹å—è´Ÿè´£è®¡ç®—ä¸€ä¸ªè¾“å‡º tile çš„å€¼ï¼Œæ¯ä¸ªçº¿ç¨‹ç”¨äºè®¡ç®—ä¸€ä¸ªå…ƒç´ ã€‚æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œ13æ¬¡æµ®ç‚¹æ“ä½œ (7 æ¬¡ä¹˜æ³•å’Œ 6 æ¬¡åŠ æ³•)ï¼Œå¹¶åŠ è½½ 7 ä¸ªè¾“å…¥å…ƒç´  (æ¯ä¸ª 4 å­—èŠ‚)ã€‚å› æ­¤ï¼Œè¿™ä¸ªå†…æ ¸çš„æµ®ç‚¹å¯¹è®¡ç®—è®¿å­˜æ¯”æ˜¯ 13 / (7*4) = 0.46 OP/B.\n2D 5-point Stencil Tiling for Output Grid\n1 2 3 4 5 6 7 8 9 10 11 12 13 __global__ void stencil_kernel(float* in, float* out, unsigned int N) { unsigned int i = blockIdx.z*blockDim.z+threadIdx.z; unsigned int j = blockIdx.y*blockDim.y+threadIdx.y; unsigned int k = blockIdx.x*blockDim.x+threadIdx.x; if (i \u0026gt;= 1 \u0026amp;\u0026amp; i \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 1 \u0026amp;\u0026amp; j \u0026lt; N - 1 \u0026amp;\u0026amp; k \u0026gt;= 1 \u0026amp;\u0026amp; k \u0026lt; N - 1) { out[i * N * N + j * N + k] = c0 * in[i * N * N + j * N + k] + c1 * in[i * N * N + j * N + k - 1] + c2 * in[i * N * N + j * N + k + 1] + c3 * in[i * N * N + (j - 1) * N + k] + c4 * in[i * N * N + (j + 1) * N + k] + c5 * in[(i - 1) * N * N + j * N + k] + c6 * in[(i + 1) * N * N + j * N + k]; } } 8.3 Shared Memory Tiling for Stencil Sweep ä¸‹å›¾å±•ç¤ºäº†äºŒç»´äº”ç‚¹æ¨¡æ¿çš„è¾“å…¥å’Œè¾“å‡º tileï¼Œå¯ä»¥å‘ç°äº”ç‚¹æ¨¡æ¿çš„è¾“å…¥ tile ä¸åŒ…æ‹¬å››ä¸ªè§’è½çš„å…ƒç´ ã€‚å› ä¸ºæ¯ä¸ªè¾“å‡ºç½‘æ ¼ç‚¹å€¼åªä½¿ç”¨è¾“å…¥ tile çš„ 5 ä¸ªå…ƒç´ ï¼Œè€Œ 3*3 å·ç§¯ä½¿ç”¨ 9 ä¸ªå…ƒç´ ã€‚è€Œ 3D æƒ…å†µä¸‹ä¸ƒç‚¹æ¨¡æ¿ç›¸å¯¹äº 3*3*3 å·ç§¯ä»å°†è¾“å…¥ç½‘æ ¼ç‚¹åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­èƒ½è·å¾—çš„æ”¶ç›Šæ›´ä½ã€‚ç”±äºä¸ºå·ç§¯åŠ è½½è¾“å…¥ tile çš„æ‰€æœ‰ç­–ç•¥éƒ½ç›´æ¥åº”ç”¨äºæ¨¡æ¿æ‰«æï¼Œä¸‹é¢ç»™å‡ºäº†ä¸€ä¸ªåŠ è½½åˆ°å…±äº«å†…å­˜ç‰ˆæœ¬çš„å†…æ ¸å‡½æ•°ï¼Œçº¿ç¨‹å—çš„å¤§å°ä¸è¾“å…¥ tile ç›¸åŒï¼Œåœ¨è®¡ç®—è¾“å‡º tile ç‚¹å€¼æ—¶æ²¡æœ‰ä½¿ç”¨éƒ¨åˆ†çº¿ç¨‹ã€‚æ¯ä¸ªè¡¨è¾¾å¼ä¸­å‡å»çš„å€¼1æ˜¯å› ä¸ºå†…æ ¸å‡è®¾ä¸€ä¸ª3Dä¸ƒç‚¹æ¨¡æ¿ï¼Œæ¯è¾¹æœ‰ä¸€ä¸ªç½‘æ ¼ç‚¹\nInput and Output Tiles for a 2D 5-point Stencil\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #define IN_TILE_DIM 16 __global__ void stencil_shared_mem_tiling_kernel(float* in, float* out, unsigned int N) { // upper left corner of input tile unsigned int i = blockIdx.z*blockDim.z+threadIdx.z - 1; unsigned int j = blockIdx.y*blockDim.y+threadIdx.y - 1; unsigned int k = blockIdx.x*blockDim.x+threadIdx.x - 1; __shared__ float in_s[IN_TILE_DIM][IN_TILE_DIM][IN_TILE_DIM]; if (i \u0026gt;= 1 \u0026amp;\u0026amp; i \u0026lt; IN_TILE_DIM \u0026amp;\u0026amp; j \u0026gt;= 1 \u0026amp;\u0026amp; j \u0026lt; IN_TILE_DIM \u0026amp;\u0026amp; k \u0026gt;= 1 \u0026amp;\u0026amp; k \u0026lt; IN_TILE_DIM) { in_s[threadIdx.z][threadIdx.y][threadIdx.x] = in[i * N * N + j * N + k]; } __syncthreads(); if (i \u0026gt;= 1 \u0026amp;\u0026amp; i \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 1 \u0026amp;\u0026amp; j \u0026lt; N - 1 \u0026amp;\u0026amp; k \u0026gt;= 1 \u0026amp;\u0026amp; k \u0026lt; N - 1) { if (threadIdx.x \u0026gt;=1 \u0026amp;\u0026amp; threadIdx.x \u0026lt; IN_TILE_DIM-1 \u0026amp;\u0026amp; threadIdx.y \u0026gt;=1 \u0026amp;\u0026amp; threadIdx.y \u0026lt; IN_TILE_DIM-1 \u0026amp;\u0026amp; threadIdx.z \u0026gt;=1 \u0026amp;\u0026amp; threadIdx.z \u0026lt; IN_TILE_DIM-1) { // 7 point template out[i * N * N + j * N + k] = c0 * in_s[threadIdx.z][threadIdx.y][threadIdx.x] + c1 * in_s[threadIdx.z][threadIdx.y][threadIdx.x - 1] + c2 * in_s[threadIdx.z][threadIdx.y][threadIdx.x + 1] + c3 * in_s[threadIdx.z][threadIdx.y - 1][threadIdx.x] + c4 * in_s[threadIdx.z][threadIdx.y + 1][threadIdx.x] + c5 * in_s[threadIdx.z - 1][threadIdx.y][threadIdx.x] + c6 * in_s[threadIdx.z + 1][threadIdx.y][threadIdx.x]; } } ç¡¬ä»¶é™åˆ¶æ¯ä¸ªå—æœ€å¤§ä¸º 1024 ï¼Œå› æ­¤ tile é€šå¸¸æ¯”è¾ƒå°ã€‚ä¸€èˆ¬ tile çš„è¾¹é•¿ä¸º8ï¼Œæ¯ä¸ªå—çš„å¤§å°ä¸º 512 ä¸ªçº¿ç¨‹ã€‚ç›¸åï¼Œå·ç§¯é€šå¸¸ç”¨äºå¤„ç†äºŒç»´å›¾åƒï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤§çš„ tile å°ºå¯¸ (32x32). ç¬¬ä¸€ä¸ªç¼ºç‚¹æ˜¯ç”±äº halo cell çš„å¼€é”€ï¼Œé‡ç”¨ç‡éšç€ tile å¤§å°çš„é™ä½è€Œé™ä½ã€‚ç¬¬äºŒä¸ªç¼ºç‚¹æ˜¯å®ƒå¯¹å†…å­˜åˆå¹¶æœ‰ä¸åˆ©å½±å“ã€‚å¯¹äºä¸€ä¸ª 8x8x8 tileï¼Œæ¯ warp çš„çº¿ç¨‹å°†è®¿é—®å…¨å±€å†…å­˜ä¸­è‡³å°‘å››è¡Œ (888*4 bytes, 32 threads, 64 bits/DRAM = 4)\n8.4 Thread Coarsening ä¸‹å›¾å‡è®¾æ¯ä¸ªè¾“å…¥ tile ç”± 6x6x6 ä¸ªç½‘æ ¼ç‚¹ç»„æˆã€‚ä¸ºäº†ä½¿è¾“å…¥ tileçš„å†…éƒ¨å¯è§ï¼Œå—çš„å‰ã€å·¦å’Œä¸Šé¢æ²¡æœ‰ç”»å‡ºã€‚å‡è®¾æ¯ä¸ªè¾“å‡º tile ç”± 4x4x4ä¸ªç½‘æ ¼ç‚¹ç»„æˆã€‚åˆ†é…ç»™å¤„ç†è¯¥ tile çš„çº¿ç¨‹å—ç”±ä¸è¾“å…¥ tile çš„ä¸€ä¸ªx-yå¹³é¢ (å³ 6x6) ç›¸åŒæ•°é‡çš„çº¿ç¨‹ç»„æˆã€‚ç¨‹åºä¸€å¼€å§‹ï¼Œæ¯ä¸ªå—éœ€è¦å°†åŒ…å«è®¡ç®—è¾“å‡ºå—å¹³é¢å€¼æ‰€éœ€çš„æ‰€æœ‰ç‚¹çš„ä¸‰ä¸ªè¾“å…¥å—å¹³é¢åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­ã€‚åœ¨æ¯æ¬¡è¿­ä»£æœŸé—´ï¼Œå—ä¸­çš„æ‰€æœ‰çº¿ç¨‹å°†å¤„ç†è¾“å‡º tile ä¸è¿­ä»£å€¼ç›¸åŒçš„ z ç´¢å¼•å¯¹åº”çš„ x-y å¹³é¢ã€‚\nMapping of Shared Memory Array after First Iteration\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #define OUT_TILE_DIM IN_TILE_DIM - 2 __global__ void stencil_thread_coarsening_kernel(float* in, float* out, unsigned int N) { int iStart = blockIdx.z * OUT_TILE_DIM; int j = blockIdx.y * blockDim.y + threadIdx.y - 1; int k = blockIdx.x * blockDim.x + threadIdx.x - 1; __shared__ float inPrev_s[IN_TILE_DIM][IN_TILE_DIM]; __shared__ float inCurr_s[IN_TILE_DIM][IN_TILE_DIM]; __shared__ float inNext_s[IN_TILE_DIM][IN_TILE_DIM]; if (iStart \u0026gt;= 1 \u0026amp;\u0026amp; iStart \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; N \u0026amp;\u0026amp; k \u0026gt;= 0 \u0026amp;\u0026amp; k \u0026lt; N) { inPrev_s[threadIdx.y][threadIdx.x] = in[(iStart - 1) * N * N + j * N + k]; } if (iStart \u0026gt;= 0 \u0026amp;\u0026amp; iStart \u0026lt; N \u0026amp;\u0026amp; j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; N \u0026amp;\u0026amp; k \u0026gt;= 0) { inCurr_s[threadIdx.y][threadIdx.x] = in[iStart * N * N + j * N + k]; } for (int i = 0; i \u0026lt; OUT_TILE_DIM; i++) { i += iStart; if (i \u0026gt;= -1 \u0026amp;\u0026amp; i \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; N \u0026amp;\u0026amp; k \u0026gt;= 0 \u0026amp;\u0026amp; k \u0026lt; N) { inNext_s[threadIdx.y][threadIdx.x] = in[(i + 1) * N * N + j * N + k]; } __syncthreads(); if (i \u0026gt;= 1 \u0026amp;\u0026amp; i \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 1 \u0026amp;\u0026amp; j \u0026lt; N - 1 \u0026amp;\u0026amp; k \u0026gt;= 1 \u0026amp;\u0026amp; k \u0026lt; N - 1 \u0026amp;\u0026amp; threadIdx.y \u0026gt;= 1 \u0026amp;\u0026amp; threadIdx.y \u0026lt; IN_TILE_DIM - 1 \u0026amp;\u0026amp; threadIdx.x \u0026gt;= 1 \u0026amp;\u0026amp; threadIdx.x \u0026lt; IN_TILE_DIM - 1) { out[i * N * N + j * N + k] = c0 * inCurr_s[threadIdx.y][threadIdx.x] + c1 * inCurr_s[threadIdx.y][threadIdx.x - 1] + c2 * inCurr_s[threadIdx.y][threadIdx.x + 1] + c3 * inCurr_s[threadIdx.y - 1][threadIdx.x] + c4 * inCurr_s[threadIdx.y + 1][threadIdx.x] + c5 * inPrev_s[threadIdx.y][threadIdx.x] + c6 * inNext_s[threadIdx.y][threadIdx.x]; } } inPrev_s[threadIdx.y][threadIdx.x] = inCurr_s[threadIdx.y][threadIdx.x]; inCurr_s[threadIdx.y][threadIdx.x] = inNext_s[threadIdx.y][threadIdx.x]; } çº¿ç¨‹ç²—åŒ–å†…æ ¸çš„ä¼˜ç‚¹æ˜¯ï¼Œå®ƒä¸è¦æ±‚è¾“å…¥ tile çš„æ‰€æœ‰å¹³é¢éƒ½å‡ºç°åœ¨å…±äº«å†…å­˜ä¸­ã€‚åœ¨ä»»æ„æ—¶åˆ»ï¼Œåªæœ‰ä¸‰å±‚è¾“å…¥ tile éœ€è¦åœ¨å…±äº«å†…å­˜ä¸­ã€‚\n8.5 Register Tiling æ ¹æ®è®¡ç®—è¿‡ç¨‹å¯ä»¥å‘ç°æ¯ä¸ª inPrev_s å’Œ inNext_s çš„å…ƒç´ ä»…ç”±ä¸€ä¸ªçº¿ç¨‹åœ¨è®¡ç®—å…·æœ‰ç›¸åŒ x-y ç´¢å¼•çš„è¾“å‡º tile ç½‘æ ¼ç‚¹æ—¶ä½¿ç”¨ã€‚åªæœ‰ inCurr_s çš„å…ƒç´ è¢«å¤šä¸ªçº¿ç¨‹è®¿é—®ï¼ŒçœŸæ­£éœ€è¦ä½äºå…±äº«å†…å­˜ä¸­ã€‚å› æ­¤æˆ‘ä»¬å¯ä»¥ä¿®æ”¹å†…æ¶µå‡½æ•°å¦‚ä¸‹ï¼Œå¯„å­˜å™¨å˜é‡ inPrev å’Œ inNext åˆ†åˆ«æ›¿æ¢å…±äº«å†…å­˜æ•°ç»„ inPrev_s å’Œ inNext_s. ä¿ç•™äº† inCurr_s ä»¥å…è®¸åœ¨çº¿ç¨‹ä¹‹é—´å…±äº« x-y å¹³é¢ç›¸é‚»ç½‘æ ¼ç‚¹å€¼ã€‚è¿™æ ·è¿™ä¸ªå†…æ ¸ä½¿ç”¨çš„å…±äº«å†…å­˜é‡å‡å°‘åˆ°åŸæ¥çš„ 1/3.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 void stencil_register_tiling_coarsening_kernel(float* in, float* out, unsigned int N) { int iStart = blockIdx.z * OUT_TILE_DIM; int j = blockIdx.y * blockDim.y + threadIdx.y - 1; int k = blockIdx.x * blockDim.x + threadIdx.x - 1; float inPrev; float inCurr; float inNext; __shared__ float inCurr_s[IN_TILE_DIM][IN_TILE_DIM]; if (iStart \u0026gt;= 1 \u0026amp;\u0026amp; iStart \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; N \u0026amp;\u0026amp; k \u0026gt;= 0 \u0026amp;\u0026amp; k \u0026lt; N) { inPrev = in[(iStart - 1) * N * N + j * N + k]; } if (iStart \u0026gt;= 0 \u0026amp;\u0026amp; iStart \u0026lt; N \u0026amp;\u0026amp; j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; N \u0026amp;\u0026amp; k \u0026gt;= 0) { inCurr = in[iStart * N * N + j * N + k]; inCurr_s[threadIdx.y][threadIdx.x] = inCurr; } for (int i = 0; i \u0026lt; OUT_TILE_DIM; i++) { i += iStart; if (i \u0026gt;= -1 \u0026amp;\u0026amp; i \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; N \u0026amp;\u0026amp; k \u0026gt;= 0 \u0026amp;\u0026amp; k \u0026lt; N) { inNext = in[(i + 1) * N * N + j * N + k]; } __syncthreads(); if (i \u0026gt;= 1 \u0026amp;\u0026amp; i \u0026lt; N - 1 \u0026amp;\u0026amp; j \u0026gt;= 1 \u0026amp;\u0026amp; j \u0026lt; N - 1 \u0026amp;\u0026amp; k \u0026gt;= 1 \u0026amp;\u0026amp; k \u0026lt; N - 1 \u0026amp;\u0026amp; threadIdx.y \u0026gt;= 1 \u0026amp;\u0026amp; threadIdx.y \u0026lt; IN_TILE_DIM - 1 \u0026amp;\u0026amp; threadIdx.x \u0026gt;= 1 \u0026amp;\u0026amp; threadIdx.x \u0026lt; IN_TILE_DIM - 1) { out[i * N * N + j * N + k] = c0 * inCurr + c1 * inCurr_s[threadIdx.y][threadIdx.x - 1] + c2 * inCurr_s[threadIdx.y][threadIdx.x + 1] + c3 * inCurr_s[threadIdx.y - 1][threadIdx.x] + c4 * inCurr_s[threadIdx.y + 1][threadIdx.x] + c5 * inPrev + c6 * inNext; } } __syncthreads(); inPrev = inCurr; inCurr = inNext; inCurr_s[threadIdx.y][threadIdx.x] = inNext; } é¦–å…ˆï¼Œè®¸å¤šå¯¹å…±äº«å†…å­˜çš„è¯»å†™ç°åœ¨è¢«è½¬ç§»åˆ°å¯„å­˜å™¨ä¸­ã€‚å…¶æ¬¡ï¼Œæ¯ä¸ªå—åªæ¶ˆè€—ä¸‰åˆ†ä¹‹ä¸€çš„å…±äº«å†…å­˜ã€‚å½“ç„¶ï¼Œè¿™æ˜¯ä»¥æ¯ä¸ªçº¿ç¨‹å¤šä½¿ç”¨ 3 ä¸ªå¯„å­˜å™¨ä¸ºä»£ä»·å®ç°çš„ã€‚éœ€è¦æ³¨æ„å…¨å±€å†…å­˜è®¿é—®çš„æ•°é‡æ²¡æœ‰æ”¹å˜ã€‚\n","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch8/","summary":"Personal notebook 8 of Programming Massively Parallel Processors.","title":"PMPP Learning-Chapter 8 Stencil"},{"content":"9 Parallel Histogram-An Introduction to Atomic Operations and Privatization æœ¬ç« ä»‹ç»å¹¶è¡Œç›´æ–¹å›¾è®¡ç®—æ¨¡å¼ï¼Œå…¶ä¸­æ¯ä¸ªè¾“å‡ºå…ƒç´ éƒ½å¯ä»¥ç”±ä»»ä½•çº¿ç¨‹æ›´æ–°ã€‚å› æ­¤ï¼Œå½“çº¿ç¨‹æ›´æ–°è¾“å‡ºå…ƒç´ æ—¶å¿…é¡»æ³¨æ„çº¿ç¨‹ä¹‹é—´çš„åè°ƒï¼Œé¿å…ä»»ä½•å¯èƒ½ç ´åæœ€ç»ˆç»“æœçš„å¹²æ‰°ã€‚\n9.1 Background ç›´æ–¹å›¾æ˜¯æ•°æ®é›†ä¸­æ•°æ®å€¼å‡ºç°çš„æ•°é‡è®¡æ•°æˆ–ç™¾åˆ†æ¯”çš„æ˜¾ç¤ºã€‚åœ¨æœ€å¸¸è§çš„ç›´æ–¹å›¾å½¢å¼ä¸­ï¼Œé—´éš”åŒºé—´æ²¿æ°´å¹³è½´ç»˜åˆ¶ï¼Œæ¯ä¸ªé—´éš”ä¸­çš„æ•°æ®å€¼è®¡æ•°è¡¨ç¤ºä¸ºä»æ°´å¹³è½´ä¸Šå‡çš„çŸ©å½¢æˆ–æ¡å½¢çš„é«˜åº¦ã€‚ è®¸å¤šåº”ç”¨é¢†åŸŸä¾èµ–äºç›´æ–¹å›¾æ¥æ€»ç»“æ•°æ®é›†è¿›è¡Œæ•°æ®åˆ†æã€‚å…¶ä¸­ä¸€ä¸ªé¢†åŸŸå°±æ˜¯è®¡ç®—æœºè§†è§‰ã€‚å›¾åƒå­åŒºåŸŸç›´æ–¹å›¾çš„è®¡ç®—è¿‡ç¨‹æ˜¯è®¡ç®—æœºè§†è§‰ä¸­ç‰¹å¾ (å›¾åƒä¸­æ„Ÿå…´è¶£çš„æ¨¡å¼) æå–çš„é‡è¦æ–¹æ³•ã€‚\nA Histogram Representation of â€œprogramming massively parallel processorsâ€\n9.2 Atomic Operations and A Basic Histogram Kernel å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¹¶è¡ŒåŒ–ç›´æ–¹å›¾è®¡ç®—çš„æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯å¯åŠ¨æ•°æ®ä¸€æ ·å¤šçš„çº¿ç¨‹ï¼Œè®©æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€ä¸ªå…ƒç´ ã€‚æ¯ä¸ªçº¿ç¨‹è¯»å–å…¶åˆ†é…çš„è¾“å…¥å…ƒç´ ï¼Œå¹¶å¢åŠ å¯¹åº”çš„éš”è®¡æ•°å™¨çš„å€¼ã€‚\nBasic Parallelization of a Histogram\nhisto æ•°ç»„ä¸­é—´éš”è®¡æ•°å™¨çš„å¢åŠ æ˜¯å¯¹å†…å­˜ä½ç½®çš„æ›´æ–°æˆ– read-modify-write æ“ä½œã€‚è¯¥æ“ä½œåŒ…æ‹¬è¯»å–å†…å­˜ä½ç½®(è¯»)ï¼Œåœ¨åŸå§‹å€¼ä¸ŠåŠ  1(ä¿®æ”¹)ï¼Œå¹¶å°†æ–°å€¼å†™å›å†…å­˜ä½ç½® (å†™)ã€‚åœ¨å®é™…è¿‡ç¨‹ä¸­ä¼šå‡ºç°è¯»-ä¿®æ”¹-å†™ç«äº‰æ¡ä»¶ (read-modify-write race condition)ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸¤ä¸ªæˆ–å¤šä¸ªåŒæ­¥æ›´æ–°æ“ä½œçš„ç»“æœä¼šæ ¹æ®æ‰€æ¶‰åŠçš„æ“ä½œçš„ç›¸å¯¹æ—¶é—´è€Œå˜åŒ–ã€‚ ä¸‹å›¾ A ä¸­çº¿ç¨‹ 1 åœ¨æ—¶é—´æ®µ 1~3 æœŸé—´å®Œæˆäº†å…¶è¯»-ä¿®æ”¹-å†™åºåˆ—çš„æ‰€æœ‰ä¸‰ä¸ªéƒ¨åˆ†ï¼Œç„¶åçº¿ç¨‹ 2 åœ¨æ—¶é—´æ®µ 4 å¼€å§‹ï¼Œæœ€åç»“æœæ­£ç¡®ã€‚åœ¨å›¾ B ä¸­ï¼Œä¸¤ä¸ªçº¿ç¨‹çš„è¯»-ä¿®æ”¹-å†™é¡ºåºé‡å ã€‚çº¿ç¨‹ 1 åœ¨æ—¶é—´æ®µ 4 æ—¶å°†æ–°å€¼å†™å…¥ histo[x]ã€‚å½“çº¿ç¨‹ 2 åœ¨æ—¶é—´æ®µ 3 è¯»å– histo[x]æ—¶ï¼Œå®ƒçš„å€¼ä»ç„¶æ˜¯ 0ï¼Œå› æ­¤æœ€åçš„å†™å…¥çš„å€¼æ˜¯ 1.\nRace Condition in Updating a histo Array Element\nåŸå­æ“ä½œ (atomic operation) çš„è¯»ã€ä¿®æ”¹å’Œå†™éƒ¨åˆ†æ„æˆä¸€ä¸ªä¸å¯åˆ†å‰²çš„å•å…ƒï¼Œå› æ­¤ç§°ä¸ºåŸå­æ“ä½œã€‚å¯¹è¯¥ä½ç½®çš„å…¶ä»–è¯»-ä¿®æ”¹-å†™åºåˆ—ä¸èƒ½ä¸å…¶åœ¨æ—¶é—´ä¸Šæœ‰é‡å ã€‚éœ€è¦æ³¨æ„åŸå­æ“ä½œåœ¨çº¿ç¨‹ä¹‹é—´ä¸å¼ºåˆ¶ä»»ä½•ç‰¹å®šçš„æ‰§è¡Œé¡ºåºï¼Œæ¯”å¦‚çº¿ç¨‹ 1 å¯ä»¥åœ¨çº¿ç¨‹ 2 ä¹‹å‰æˆ–ä¹‹åè¿è¡Œã€‚CUDAå†…æ ¸å¯ä»¥é€šè¿‡å‡½æ•°è°ƒç”¨å¯¹å†…å­˜ä½ç½®æ‰§è¡ŒåŸå­åŠ æ³•æ“ä½œ:\n1 int atomicAdd(int* address, int val); atomicAdd æ˜¯ä¸€ä¸ªå†…å»ºå‡½æ•° (intrinsic function)ï¼Œå®ƒè¢«ç¼–è¯‘æˆä¸€ä¸ªç¡¬ä»¶åŸå­æ“ä½œæŒ‡ä»¤ã€‚è¯¥æŒ‡ä»¤è¯»å–å…¨å±€æˆ–å…±äº«å†…å­˜ä¸­ address å‚æ•°æ‰€æŒ‡å‘çš„32ä½å­—ï¼Œå°† val åŠ ä¸Šæ—§å€¼ä¸­å¹¶å†™å…¥ç»“æœå›ç›¸åŒåœ°å€çš„å†…å­˜ä¸­ã€‚è¯¥å‡½æ•°è¿”å›åœ°å€å¤„çš„æ—§å€¼ã€‚\nIntrinsic Functions ç°ä»£å¤„ç†å™¨é€šå¸¸æä¾›ç‰¹æ®ŠæŒ‡ä»¤ï¼Œè¿™äº›æŒ‡ä»¤è¦ä¹ˆæ‰§è¡Œå…³é”®åŠŸèƒ½ (å¦‚åŸå­æ“ä½œ)ï¼Œè¦ä¹ˆå¤§å¹…æé«˜æ€§èƒ½ (å¦‚çŸ¢é‡æŒ‡ä»¤)ã€‚è¿™äº›æŒ‡ä»¤é€šå¸¸ä½œä¸ºå†…å»ºå‡½æ•°æš´éœ²ç»™ç¨‹åºå‘˜ï¼Œä»ç¨‹åºå‘˜çš„è§’åº¦æ¥çœ‹ï¼Œè¿™äº›æ˜¯åº“å‡½æ•°ã€‚ç„¶è€Œï¼Œå®ƒä»¬è¢«ç¼–è¯‘å™¨ä»¥ä¸€ç§ç‰¹æ®Šçš„æ–¹å¼å¤„ç†ã€‚æ¯ä¸ªè¿™æ ·çš„è°ƒç”¨éƒ½è¢«ç¿»è¯‘æˆç›¸åº”çš„ç‰¹æ®ŠæŒ‡ä»¤ã€‚åœ¨æœ€ç»ˆä»£ç ä¸­æ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼Œåªæœ‰ä¸ç”¨æˆ·ä»£ç ä¸€è‡´çš„ç‰¹æ®ŠæŒ‡ä»¤ã€‚ 1 2 3 4 5 6 7 8 9 10 __global__ void histo_kernel(char* data, unsigned int length, unsigned int* histo) { unsigned int i = threadIdx.x + blockIdx.x * blockDim.x; if (i \u0026lt; length) { int alphabet_position = data[i] - \u0026#39;a\u0026#39;; if (alphabet_position \u0026gt;= 0 \u0026amp;\u0026amp; alphabet_position \u0026lt; 26) { atomicAdd(\u0026amp;histo[alphabet_position / 4], 1); } } } 9.3 Latency and Throughput of Atomic Operations é«˜å†…å­˜è®¿é—®ååé‡çš„å…³é”®æ˜¯åŒæ—¶è¿›è¡Œè®¸å¤š DRAM è®¿é—®ã€‚ç„¶è€Œï¼Œå½“è®¸å¤šåŸå­æ“ä½œæ›´æ–°ç›¸åŒçš„å†…å­˜ä½ç½®æ—¶ï¼Œä¸€ä¸ªåé¢çº¿ç¨‹çš„è¯»-ä¿®æ”¹-å†™åºåˆ—åœ¨å‰ä¸€ä¸ªçº¿ç¨‹çš„å†™æ“ä½œç»“æŸä¹‹å‰ä¸èƒ½å¼€å§‹ï¼Œå³å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒåŒæ—¶åªèƒ½æœ‰ä¸€ä¸ªçº¿ç¨‹åœ¨åŒä¸€å†…å­˜ä½ç½®æ‰§è¡ŒåŸå­æ“ä½œã€‚æ›´æ–°è¿™äº›é—´éš”çš„å¤§é‡äº‰ç”¨æµé‡ä¼šä½¿å¾—ååé‡é™ä½ã€‚\nThe Execution of Atomic Operations at the Same Location\næé«˜åŸå­æ“ä½œååé‡çš„ä¸€ç§æ–¹æ³•æ˜¯å‡å°‘å¯¹ç«äº‰ä¸¥é‡çš„ä½ç½®çš„è®¿é—®å»¶è¿Ÿã€‚ç°ä»£ GPU å…è®¸åœ¨è¢«æ‰€æœ‰ SM å…±äº«çš„æœ€åä¸€çº§ç¼“å­˜ä¸­æ‰§è¡ŒåŸå­æ“ä½œã€‚ç”±äºå¯¹æœ€åä¸€çº§ç¼“å­˜çš„è®¿é—®æ—¶é—´æ˜¯å‡ åä¸ªå‘¨æœŸè€Œä¸æ˜¯å‡ ç™¾ä¸ªå‘¨æœŸï¼Œå› æ­¤åŸå­æ“ä½œçš„ååé‡ä¸æ—©æœŸGPUç›¸æ¯”è‡³å°‘æé«˜äº†ä¸€ä¸ªæ•°é‡çº§ã€‚\n9.4 Privatization æé«˜åŸå­æ“ä½œååé‡çš„å¦ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡å¼•å¯¼æµé‡è¿œç¦»ç«äº‰ä¸¥é‡çš„ä½ç½®ã€‚è¿™å¯ä»¥é€šè¿‡ä¸€ç§ç§°ä¸ºç§æœ‰åŒ– (privatization) çš„æŠ€æœ¯æ¥å®ç°ã€‚å…¶æ€æƒ³æ˜¯å°†é«˜åº¦ç«äº‰çš„è¾“å‡ºæ•°æ®ç»“æ„å¤åˆ¶åˆ°ç§æœ‰å‰¯æœ¬ä¸­ï¼Œä»¥ä¾¿çº¿ç¨‹çš„æ¯ä¸ªå­é›†éƒ½å¯ä»¥æ›´æ–°å…¶ç§æœ‰å‰¯æœ¬ã€‚ ä¸‹å›¾å±•ç¤ºäº†å¦‚ä½•å°†ç§æœ‰åŒ–åº”ç”¨äºç›´æ–¹å›¾ç»Ÿè®¡ã€‚æ¯ä¸ªçº¿ç¨‹å—ç”± 8 ä¸ªçº¿ç¨‹ç»„æˆï¼Œäº‰ç”¨åªä¼šåœ¨åŒä¸€å—ä¸­çš„çº¿ç¨‹ä¹‹é—´ä»¥åŠåœ¨æœ€ååˆå¹¶ç§æœ‰å‰¯æœ¬æ—¶å‘ç”Ÿï¼Œè€Œä¸æ˜¯æ›´æ–°ç›¸åŒç›´æ–¹å›¾ bin çš„æ‰€æœ‰çº¿ç¨‹ä¹‹é—´å‘ç”Ÿäº‰ç”¨ã€‚\nReduce Contention of Atomic Operations by Private Copies of Histogram\nä¸€ä¸ªç§æœ‰åŒ–ç‰ˆæœ¬çš„ä»£ç å¦‚ä¸‹ï¼Œä¸º histo æ•°ç»„åˆ†é…è¶³å¤Ÿçš„è®¾å¤‡å†…å­˜ (gridDim.x*NUM_BINS*4 bytes) æ¥ä¿å­˜ç›´æ–¹å›¾çš„æ‰€æœ‰ç§æœ‰å‰¯æœ¬ã€‚åœ¨æ‰§è¡Œç»“æŸæ—¶ï¼Œæ¯ä¸ªçº¿ç¨‹å—å°†æŠŠç§æœ‰å‰¯æœ¬ä¸­çš„å€¼æäº¤åˆ° å— 0 çš„éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #define NUM_BINS 7 // # histo bins __global__ void histo_private_kernel(char* data, unsigned int length, unsigned int* histo) { unsigned int i = threadIdx.x + blockIdx.x * blockDim.x; if (i \u0026lt; length) { int alphabet_position = data[i] - \u0026#39;a\u0026#39;; if (alphabet_position \u0026gt;= 0 \u0026amp;\u0026amp; alphabet_position \u0026lt; 26) { atomicAdd(\u0026amp;histo[blockIdx.x * 7 + alphabet_position / 4], 1); } } if (blockIdx.x \u0026gt; 0) { __syncthreads(); // for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { unsigned int binValue = histo[blockIdx * NUM_BINS + bin]; atomicAdd(\u0026amp;histo[bin], binValue); } } } åœ¨æ¯ä¸ªçº¿ç¨‹å—çš„åŸºç¡€ä¸Šåˆ›å»ºç›´æ–¹å›¾çš„ç§æœ‰å‰¯æœ¬çš„ä¸€ä¸ªå¥½å¤„æ˜¯çº¿ç¨‹å¯ä»¥åœ¨æäº¤è‡ªå·±çš„ç»Ÿè®¡ç»“æœä¹‹å‰ä½¿ç”¨ __syncthreads() æ¥ç­‰å¾…å½¼æ­¤ã€‚å¦ä¸€ä¸ªå¥½å¤„æ˜¯ï¼Œå¦‚æœç›´æ–¹å›¾ä¸­çš„ bin æ•°é‡è¶³å¤Ÿå°ï¼Œåˆ™å¯ä»¥åœ¨å…±äº«å†…å­˜ä¸­å£°æ˜ç›´æ–¹å›¾çš„ç§æœ‰å‰¯æœ¬ (æ¯ä¸ªçº¿ç¨‹å—ä¸€ä¸ª)ã€‚ä¸‹é¢ä»£ç ç›´æ–¹å›¾åœ¨å…±äº«å†…å­˜ä¸­åˆ†é…ç§æœ‰å‰¯æœ¬ histo_s æ•°ç»„ï¼Œå¹¶ç”±å—çš„çº¿ç¨‹å¹¶è¡Œåˆå§‹åŒ–ä¸º 0.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 __global__ void histo_shared_private_kernel(char* data, unsigned int length, unsigned int* histo) { // Initializing private bins __shared__ unsigned int histo_s[NUM_BINS]; for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { histo_s[bin] = 0; } __syncthreads(); // Histogram unsigned int i = threadIdx.x + blockIdx.x * blockDim.x; if (i \u0026lt; length) { int alphabet_position = data[i] - \u0026#39;a\u0026#39;; if (alphabet_position \u0026gt;= 0 \u0026amp;\u0026amp; alphabet_position \u0026lt; 26) { atomicAdd(\u0026amp;histo_s[alphabet_position / 4], 1); } } __syncthreads(); // Commit to global memory for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { unsigned binValue = histo_s[bin]; if (binValue \u0026gt; 0) { atomicAdd(\u0026amp;histo[bin], binValue); } } } 9.5 Coarsening ç§æœ‰åŒ–çš„å¼€é”€æ˜¯éœ€è¦å°†ç§æœ‰å‰¯æœ¬æäº¤åˆ°å…¬å…±å‰¯æœ¬ã€‚æ¯ä¸ªçº¿ç¨‹å—éƒ½ä¼šæ‰§è¡Œä¸€æ¬¡æäº¤æ“ä½œï¼Œå› æ­¤ï¼Œä½¿ç”¨çš„çº¿ç¨‹å—è¶Šå¤šï¼Œè¿™ä¸ªå¼€é”€å°±è¶Šå¤§ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‡å°‘å—çš„æ•°é‡æ¥å‡å°‘ç§æœ‰å‰¯æœ¬çš„æ•°é‡ï¼Œä»è€Œå‡å°‘æäº¤åˆ°å…¬å…±å‰¯æœ¬çš„æ¬¡æ•°ï¼Œè®©æ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªè¾“å…¥å…ƒç´ ã€‚\nContiguous Partition of Input Elements\nä¸‹é¢ä»£ç æ˜¯ä¸€ä¸ªè¿ç»­åˆ†åŒº (contiguous partition) ç­–ç•¥çš„ç¤ºä¾‹ï¼Œè¾“å…¥è¢«è¿ç»­åˆ’åˆ†æˆå¤šä¸ªæ®µï¼Œæ¯ä¸ªæ®µè¢«åˆ†é…ç»™ä¸€ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ªçº¿ç¨‹ä» tid*CFACTOR è¿­ä»£åˆ° (tid+1)*CFACTOR è¿›è¡Œæ‰€è´Ÿè´£éƒ¨åˆ†çš„ç»Ÿè®¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #define CFACTOR 3 __global__ void histo_shared_private_contiguous_kernel(char* data, unsigned int length, unsigned int* histo) { { // Initializing private bins __shared__ unsigned int histo_s[NUM_BINS]; for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { histo_s[bin] = 0; } __syncthreads(); // Histogram unsigned tid = blockIdx.x * blockDim.x + threadIdx.x; for (unsigned int i = tid * CFACTOR; i \u0026lt; (tid + 1)*CFACTOR \u0026amp;\u0026amp; i \u0026lt; length; i++) { int alphabet_position = data[i] - \u0026#39;a\u0026#39;; if (alphabet_position \u0026gt;= 0 \u0026amp;\u0026amp; alphabet_position \u0026lt; 26) { atomicAdd(\u0026amp;histo_s[alphabet_position / 4], 1); } } __syncthreads(); // Commit to global memory for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { unsigned binValue = histo_s[bin]; if (binValue \u0026gt; 0) { atomicAdd(\u0026amp;histo[bin], binValue); } } } ä¸Šè¿°åœ¨ GPU ä¸Šè¿ç»­åˆ†åŒºçš„æ€è·¯ä¼šå¯¼è‡´å†…å­˜ä¸å‹å¥½çš„è®¿é—®æ¨¡å¼ï¼Œå› ä¸º threadIdx ç›¸åŒçš„çº¿ç¨‹è®¿é—®çš„ä¸æ˜¯ä¸€å—è¿ç»­çš„å†…å­˜åŒºåŸŸã€‚å› æ­¤æˆ‘ä»¬è¦é‡‡ç”¨äº¤é”™åˆ†åŒº (interleaved partition)ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå³ä¸åŒçº¿ç¨‹è¦å¤„ç†çš„åˆ†åŒºå½¼æ­¤äº¤é”™ã€‚å®é™…åº”ç”¨ä¸­æ¯ä¸ªçº¿ç¨‹åœ¨æ¯æ¬¡è¿­ä»£ä¸­åº”è¯¥å¤„ç† 4 ä¸ª char (ä¸€ä¸ª 32 ä½å­—)ï¼Œä»¥å……åˆ†åˆ©ç”¨ç¼“å­˜å’Œ SMs ä¹‹é—´çš„äº’è¿å¸¦å®½ã€‚\nInterleaved Partition of Input Elements\nä¸‹é¢ä»£ç æ˜¯ä¸€ä¸ªäº¤é”™åˆ†åŒºçš„ç¤ºä¾‹ã€‚åœ¨å¾ªç¯çš„ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹ä½¿ç”¨å…¶å…¨å±€çº¿ç¨‹ç´¢å¼•è®¿é—®æ•°æ®æ•°ç»„:çº¿ç¨‹ 0 è®¿é—®å…ƒç´  0ï¼Œçº¿ç¨‹ 1 è®¿é—®å…ƒç´  1ï¼Œçº¿ç¨‹ 2 è®¿é—®å…ƒç´  2\u0026hellip;æ‰€æœ‰çº¿ç¨‹å…±åŒå¤„ç†è¾“å…¥çš„ç¬¬ä¸€ä¸ª blockDim.x*gridDim.x å…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 __global__ void histo_shared_private_interleaved_kernel(char* data, unsigned int length, unsigned int* histo) { { // Initializing private bins __shared__ unsigned int histo_s[NUM_BINS]; for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { histo_s[bin] = 0; } __syncthreads(); // Histogram unsigned tid = blockIdx.x * blockDim.x + threadIdx.x; for (unsigned int i = tid; i \u0026lt; length; i += blockDim.x * gridDim.x) { int alphabet_position = data[i] - \u0026#39;a\u0026#39;; if (alphabet_position \u0026gt;= 0 \u0026amp;\u0026amp; alphabet_position \u0026lt; 26) { atomicAdd(\u0026amp;histo_s[alphabet_position / 4], 1); } } __syncthreads(); // Commit to global memory for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { unsigned binValue = histo_s[bin]; if (binValue \u0026gt; 0) { atomicAdd(\u0026amp;histo[bin], binValue); } } } 9.6 Aggregation ä¸€äº›æ•°æ®é›†åœ¨å±€éƒ¨åŒºåŸŸæœ‰å¤§é‡ç›¸åŒçš„æ•°æ®å€¼ã€‚å¦‚æ­¤é«˜åº¦é›†ä¸­çš„ç›¸åŒå€¼ä¼šå¯¼è‡´ä¸¥é‡çš„äº‰ç”¨ï¼Œå¹¶é™ä½å¹¶è¡Œç›´æ–¹å›¾è®¡ç®—çš„ååé‡ã€‚ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„ä¼˜åŒ–æ˜¯ï¼Œå¦‚æœæ¯ä¸ªçº¿ç¨‹æ­£åœ¨æ›´æ–°ç›´æ–¹å›¾çš„ç›¸åŒå…ƒç´ ï¼Œåˆ™å°†è¿ç»­çš„æ›´æ–°èšåˆä¸ºå•ä¸ªæ›´æ–°ã€‚ä¸‹é¢çš„ä»£ç å±•ç¤ºäº†èšåˆçš„ç›´æ–¹å›¾è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 __global__ void histo_shared_private_interleaved_aggregated_kernel(char* data, unsigned int length, unsigned int* histo) { // Initializing private bins __shared__ unsigned int histo_s[NUM_BINS]; for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { histo_s[bin] = 0; } __syncthreads(); // Histogram unsigned int accumulator = 0; int prevBinIdx = -1; unsigned tid = blockIdx.x * blockDim.x + threadIdx.x; for (unsigned int i = tid; i \u0026lt; length; i += blockDim.x * gridDim.x) { int alphabet_position = data[i] - \u0026#39;a\u0026#39;; if (alphabet_position \u0026gt;= 0 \u0026amp;\u0026amp; alphabet_position \u0026lt; 26) { int currBinIdx = alphabet_position / 4; if (currBinIdx != prevBinIdx) { // Update previous statistics if (accumulator \u0026gt; 0) { atomicAdd(\u0026amp;histo_s[prevBinIdx], accumulator); } accumulator = 1; prevBinIdx = currBinIdx; } else { // Accumulate statistics accumulator++; } } } if (accumulator \u0026gt; 0) { // Update last bin atomicAdd(\u0026amp;histo_s[prevBinIdx], accumulator); } __syncthreads(); // Commit to global memory for (unsigned int bin = threadIdx.x; bin \u0026lt; NUM_BINS; bin += blockDim.x) { unsigned binValue = histo_s[bin]; if (binValue \u0026gt; 0) { atomicAdd(\u0026amp;histo[bin], binValue); } } } å¯ä»¥çœ‹å‡ºèšåˆå†…æ ¸éœ€è¦æ›´å¤šçš„è¯­å¥å’Œå˜é‡ã€‚æ·»åŠ çš„ if è¯­å¥å¯èƒ½ä¼šå‡ºç°æ§åˆ¶å‘æ•£ã€‚ç„¶è€Œï¼Œå¦‚æœæ²¡æœ‰äº‰ç”¨æˆ–å­˜åœ¨ä¸¥é‡çš„äº‰ç”¨ï¼Œå°±å¾ˆå°‘æœ‰æ§åˆ¶å‘æ•£ï¼Œå› ä¸ºçº¿ç¨‹è¦ä¹ˆéƒ½åœ¨å¢åŠ ç´¯åŠ å™¨å€¼ï¼Œè¦ä¹ˆéƒ½åœ¨è¿ç»­åˆ·æ–°ã€‚\n","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch9/","summary":"Personal notebook 9 of Programming Massively Parallel Processors.","title":"PMPP Learning-Chapter 9 Parallel Histogram-An Introduction to Atomic Operations and Privatization"},{"content":"7 Convolution-An Introduction to Constant Memory and Caching å·ç§¯çš„æ¯ä¸ªè¾“å‡ºæ•°æ®å…ƒç´ å¯ä»¥ç›¸äº’ç‹¬ç«‹åœ°è®¡ç®—ï¼Œè¿™æ˜¯å¹¶è¡Œè®¡ç®—çš„ç†æƒ³ç‰¹æ€§ã€‚å¦ä¸€æ–¹é¢ï¼Œåœ¨å¤„ç†å…·æœ‰è¾¹ç•Œæ¡ä»¶çš„è¾“å‡ºæ•°æ®å…ƒç´ æ—¶ï¼Œæœ‰å¤§é‡çš„è¾“å…¥æ•°æ®å…±äº«ã€‚è¿™ä½¿å¾—å·ç§¯å¯ä»¥å®ç°å¤æ‚çš„ tiling æ–¹æ³•å’Œè¾“å…¥æ•°æ®åˆ†æ®µæ–¹æ³•ã€‚\n7.1 Background è¾“å…¥æ•°æ®å‘é‡ $[x_0, x_1, \\cdots, x_{n-1}]$ å’ŒåŒ…å« 2r+1 ä¸ªå…ƒç´ çš„ filter æ•°ç»„ $[f_0, f_1, \\cdots, f_{2r}]$ï¼Œ 1Då·ç§¯è®¡ç®—å…¬å¼ä¸º $$y_i=\\sum_{j=-r}^rf_{i+j}\\times x_i$$ åŒæ ·å¯¹äº n*n å¤§å°çš„äºŒç»´è¾“å…¥ï¼Œå’Œ r*r å¤§å°çš„ filterï¼Œ2D å·ç§¯è®¡ç®—å…¬å¼ä¸º $$P_{y,x}=\\sum_{j=-r_y}^{r_y}\\sum_{k=-r_x}^{r_x}f_{y+j,x+k}\\times N_{y,x}$$7.2 Parallel Convolution: a Basic Algorithm å‡è®¾äºŒç»´å·ç§¯å†…æ ¸æ¥æ”¶äº”ä¸ªå‚æ•°: è¾“å…¥æ•°ç»„ N çš„æŒ‡é’ˆ; æ»¤æ³¢å™¨ F çš„æŒ‡é’ˆ; è¾“å‡ºæ•°ç»„ P çš„æŒ‡é’ˆ; æ–¹å½¢æ»¤æ³¢å™¨çš„åŠå¾„ r; è¾“å…¥è¾“å‡ºæ•°ç»„çš„å®½åº¦; è¾“å…¥å’Œè¾“å‡ºæ•°ç»„çš„é«˜åº¦ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸€ä¸ªç®€å•çš„å¹¶è¡Œæ–¹å¼æ˜¯ç½‘æ ¼ä¸­çš„æ¯ä¸ªçº¿ç¨‹è®¡ç®—ä¸è‡ªèº«åæ ‡ç›¸åŒçš„è¾“å‡ºåƒç´ ã€‚å¯¹åº”çš„å†…æ ¸å‡½æ•°ä»£ç å¦‚ä¸‹ï¼Œæµ®ç‚¹è®¡ç®—ä¸å…¨å±€å†…å­˜è®¿é—®çš„æ¯”ä»…ä¸º 0.25 OP/B (æ¯åŠ è½½ 8 å­—èŠ‚æ‰§è¡Œ 2 æ¬¡è¿ç®—)\nParallelization and Thread Organization for 2D Convolution\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 __global__ void convolution_2D_basic_kernel (float *N, float *F, float *P, int r, int width, int height) { int outCol = blockIdx.x * blockDim.x + threadIdx.x; int outRow = blockIdx.y * blockDim.y + threadIdx.y; int Pvalue = 0.0f; for (int fRow = 0; fRow \u0026lt; 2*r+1; fRow++) { for (int fCol = 0; fCol \u0026lt; 2 * r + 1; fCol++) { int inRow = outRow - r + fRow; int inCol = outCol - r + fCol; if (inRow \u0026gt; 0 \u0026amp;\u0026amp; inRow \u0026lt; height \u0026amp;\u0026amp; inCol \u0026gt; 0 \u0026amp;\u0026amp; inCol \u0026lt; width) { Pvalue += P[inRow * width + inCol] * F[fRow * r + fCol]; } } } P[outRow * width + outCol] = Pvalue; } 7.3 Constant Memory and Caching å¯ä»¥å‘ç°å·ç§¯æ ¸ F é€šå¸¸å¾ˆå°ï¼Œåœ¨æ•´ä¸ªå·ç§¯å†…æ ¸çš„æ‰§è¡Œè¿‡ç¨‹ä¸­ä¸ä¼šæ”¹å˜ï¼Œæ‰€æœ‰çº¿ç¨‹éƒ½ä»¥ç›¸åŒçš„é¡ºåºè®¿é—®å…¶å…ƒç´ ã€‚å› æ­¤æˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†å…¶å­˜å‚¨åœ¨å¸¸é‡å†…å­˜é‡Œï¼Œä¹‹å‰è¯´è¿‡å®ƒå’Œå…¨å±€å†…å­˜çš„åŒºåˆ«æ˜¯çº¿ç¨‹ä¸èƒ½ä¿®æ”¹å¸¸é‡å†…å­˜å˜é‡çš„å€¼å¹¶ä¸”å¸¸é‡å†…å­˜éå¸¸å°ï¼Œç›®å‰ä¸º 64 KB. å‡è®¾å·²ç»åœ¨ä¸»æœºä»£ç é‡Œåˆ†é…å¥½ F_h çš„å†…å­˜ï¼Œå¯ä»¥é€šè¿‡ cudaMemcpyToSymbol() å°†å…¶ä»ä¸»æœºå†…å­˜ä¼ è¾“åˆ°è®¾å¤‡å¸¸é‡å†…å­˜ä¸­ã€‚å†…æ ¸å‡½æ•°ä»¥å…¨å±€å˜é‡çš„å½¢å¼è®¿é—®å¸¸é‡å†…å­˜å˜é‡ã€‚å› æ­¤ï¼Œå®ƒä»¬çš„æŒ‡é’ˆä¸éœ€è¦ä½œä¸ºå‚æ•°ä¼ é€’ç»™å†…æ ¸å‡½æ•°ã€‚\nå¦‚æœä¸»æœºä»£ç å’Œå†…æ ¸ä»£ç ä½äºä¸åŒçš„æ–‡ä»¶ä¸­ï¼Œå†…æ ¸ä»£ç æ–‡ä»¶å¿…é¡»åŒ…å«ç›¸å…³çš„å¤–éƒ¨å£°æ˜çš„å¤´æ–‡ä»¶ï¼Œä»¥ç¡®ä¿å£°æ˜å¯¹å†…æ ¸å¯è§ã€‚\nCUDA runtime çŸ¥é“å¸¸é‡å†…å­˜å˜é‡åœ¨å†…æ ¸æ‰§è¡ŒæœŸé—´ä¸ä¼šè¢«ä¿®æ”¹ï¼Œå› æ­¤ä¼šè®©ç¡¬ä»¶åœ¨å†…æ ¸æ‰§è¡ŒæœŸé—´ç›´æ¥ç¼“å­˜å¸¸é‡å†…å­˜å˜é‡ã€‚åœ¨ä¸éœ€è¦æ”¯æŒå†™çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥åœ¨å‡å°èŠ¯ç‰‡é¢ç§¯å’Œé™ä½åŠŸè€—çš„æƒ…å†µä¸‹è®¾è®¡ç”¨äºå¸¸é‡å†…å­˜å˜é‡çš„ä¸“ç”¨ç¼“å­˜ï¼Œè¢«ç§°ä¸ºå¸¸é‡ç¼“å­˜ (constant caching).\n7.4 Tiled Convolution with Halo Cells æˆ‘ä»¬å®šä¹‰è¾“å‡º tile ä¸ºæ¯ä¸ªå—å¤„ç†çš„è¾“å‡ºå…ƒç´ ï¼Œè¾“å…¥ tile ä¸ºè®¡ç®—è¾“å‡º tile ä¸­å…ƒç´ æ‰€éœ€çš„è¾“å…¥å…ƒç´ çš„é›†åˆã€‚ä¸‹å›¾ç»™å‡ºäº†ä¸€ä¸ªä¾‹å­ï¼Œå¯ä»¥çœ‹åˆ°è¾“å…¥ tile å¤§å°å’Œè¾“å‡º tile å¤§å°ä¹‹é—´çš„å·®å¼‚ä½¿ tile å·ç§¯æ ¸çš„è®¾è®¡å˜å¾—å¤æ‚ã€‚æœ‰ä¸¤ç§çº¿ç¨‹ç»„ç»‡å¯ä»¥å¤„ç†è¿™ç§å·®å¼‚ã€‚\nå¯åŠ¨ä¸è¾“å…¥ tile å…·æœ‰ç›¸åŒç»´åº¦çš„çº¿ç¨‹å—ã€‚è¿™æ ·å› ä¸ºæ¯ä¸ªçº¿ç¨‹åªéœ€è¦åŠ è½½ä¸€ä¸ªè¾“å…¥å…ƒç´ ã€‚ä½†ç”±äºè¾“å…¥ tile æ¯”å¯¹åº”çš„è¾“å‡º tile å¤§ï¼Œåœ¨è®¡ç®—è¾“å‡ºå…ƒç´ æ—¶éœ€è¦ç¦ç”¨ä¸€äº›çº¿ç¨‹ï¼Œé™ä½äº†èµ„æºåˆ©ç”¨ç‡ã€‚ å¯åŠ¨ä¸è¾“å‡º tile å…·æœ‰ç›¸åŒç»´åº¦çš„çº¿ç¨‹å—ã€‚è¿™æ ·çº¿ç¨‹éœ€è¦è¿­ä»£ä»¥ç¡®ä¿åŠ è½½æ‰€æœ‰è¾“å…¥ tile å…ƒç´ ã€‚ä½†ç®€åŒ–äº†è¾“å‡ºå…ƒç´ çš„è®¡ç®—ã€‚ Input Tile vs. Output Tile in 2D Convolution\nç¬¬ä¸€ç§çº¿ç¨‹ç»„ç»‡æ–¹å¼çš„å†…æ ¸å¦‚ä¸‹ã€‚ç°åœ¨æ¯ä¸ªå—ä¸­çš„çº¿ç¨‹å…±åŒæ‰§è¡Œ OUT_TILE_DIM^2*(2*FILTER_RADIUS+1) æ¬¡æµ®ç‚¹è¿ç®—ã€‚åˆ†é…ç»™è¾“å…¥ tile å…ƒç´ çš„æ¯ä¸ªçº¿ç¨‹åŠ è½½ä¸€ä¸ª4å­—èŠ‚çš„è¾“å…¥å€¼ã€‚å› æ­¤æ¯ä¸ªblockåŠ è½½ IN_TILE_DIM^2*4=(OUT_TILE_DIM+2*FILTER_RADIUS)^2*4\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #define IN_TILE_DIM 32 #define FILTER_RADIUS 5 #define OUT_TILE_DIM (IN_TILE_DIM - 2*(FILTER_RADIUS)) __constant__ float F_c[2 * FILTER_RADIUS + 1][FILTER_RADIUS + 1]; __global__ void convolution_tiled_2D_constant_mem_kernel_1( float* N, float* P, int width, int height) { // Upper left input tile coord int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS; int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS; // Loading input tile __shared__ float N_s[IN_TILE_DIM][IN_TILE_DIM]; if (row \u0026gt;= 0 \u0026amp;\u0026amp; row \u0026lt; height \u0026amp;\u0026amp; col \u0026gt;= 0 \u0026amp;\u0026amp; col \u0026lt; width) { N_s[threadIdx.y][threadIdx.x] = N[row * width + col]; } else { N_s[threadIdx.y][threadIdx.x] = 0.0f; } __syncthreads(); // Calculate output elements int tileCol = threadIdx.x - FILTER_RADIUS; int tileRow = threadIdx.y - FILTER_RADIUS; if (row \u0026gt;= 0 \u0026amp;\u0026amp; row \u0026lt; height \u0026amp;\u0026amp; col \u0026gt;= 0 \u0026amp;\u0026amp; col \u0026lt; width \u0026amp;\u0026amp; tileCol \u0026gt;= 0 \u0026amp;\u0026amp; tileCol \u0026lt; OUT_TILE_DIM \u0026amp;\u0026amp; tileRow \u0026gt;= 0 \u0026amp;\u0026amp; tileRow \u0026lt; OUT_TILE_DIM) { float Pvalue = 0.0f; for (int fRow = 0; fRow \u0026lt; 2 * FILTER_RADIUS + 1; fRow++) { for (int fCol = 0; fCol \u0026lt; 2 * FILTER_RADIUS + 1; fCol++) { Pvalue += F_c[fRow][fCol] * N_s[tileRow + fRow][tileCol + fCol]; } } P[row * width + col] = Pvalue; } } ç¬¬äºŒç§çº¿ç¨‹ç»„ç»‡æ–¹å¼çš„å†…æ ¸å¦‚ä¸‹ï¼Œæ¯ä¸ªçº¿ç¨‹ç°åœ¨å¯èƒ½éœ€è¦åŠ è½½å¤šä¸ªè¾“å…¥ tile çš„å…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 __global__ void convolution_tiled_2D_constant_mem_kernel_2( // OUT_TILE_DIM^2 threads per block float* N, float* P, int width, int height) { // Upper left output tile coord int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x; int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y; // Each thread may need to load multiple elements into shared memory __shared__ float N_s[IN_TILE_DIM][IN_TILE_DIM]; for (int i = threadIdx.y; i \u0026lt; IN_TILE_DIM; i += OUT_TILE_DIM) { for (int j = threadIdx.x; j \u0026lt; IN_TILE_DIM; j += OUT_TILE_DIM) { int in_col = blockIdx.x * OUT_TILE_DIM + j - FILTER_RADIUS; int in_row = blockIdx.y * OUT_TILE_DIM + i - FILTER_RADIUS; if (in_row \u0026gt;= 0 \u0026amp;\u0026amp; in_row \u0026lt; height \u0026amp;\u0026amp; in_col \u0026gt;= 0 \u0026amp;\u0026amp; in_col \u0026lt; width) { N_s[i][j] = N[in_row * width + in_col]; } else { N_s[i][j] = 0.0f; } } } __syncthreads(); // Calculate output elements if (threadIdx.x \u0026lt; OUT_TILE_DIM \u0026amp;\u0026amp; threadIdx.y \u0026lt; OUT_TILE_DIM \u0026amp;\u0026amp; row \u0026lt; height \u0026amp;\u0026amp; col \u0026lt; width) { float Pvalue = 0.0f; for (int fRow = 0; fRow \u0026lt; 2 * FILTER_RADIUS + 1; fRow++) { for (int fCol = 0; fCol \u0026lt; 2 * FILTER_RADIUS + 1; fCol++) { Pvalue += F_c[fRow][fCol] * N_s[threadIdx.y + fRow][threadIdx.x + fCol]; } } P[row * width + col] = Pvalue; } } 7.5 Tiled Convolution Using Caches for Halo Cells å½“ä¸€ä¸ªå—éœ€è¦å®ƒçš„ halo cell æ—¶ï¼Œç”±äºç›¸é‚»å—çš„è®¿é—®ï¼Œå®ƒä»¬å·²ç»åœ¨äºŒçº§ç¼“å­˜ä¸­äº†ã€‚å› æ­¤ï¼Œå¯¹è¿™äº› halo cell çš„å†…å­˜è®¿é—®å¯ä»¥ä» L2 ç¼“å­˜æä¾›ï¼Œè€Œä¸ä¼šé€ æˆé¢å¤–çš„ DRAM æµé‡ã€‚æˆ‘ä»¬å¯ä»¥å¯¹åŸæ¥çš„ N è¿›è¡Œè¿™äº› halo cell çš„è®¿é—®ï¼Œè€Œä¸æ˜¯å°†å®ƒä»¬åŠ è½½åˆ° N_ds ä¸­ã€‚ä»£ç å¦‚ä¸‹ï¼ŒåŠ è½½ N_s å˜å¾—æ›´ç®€å•ï¼Œå› ä¸ºæ¯ä¸ªçº¿ç¨‹å¯ä»¥ç®€å•åœ°åŠ è½½ä¸å…¶åˆ†é…çš„è¾“å‡ºå…ƒç´ å…·æœ‰ç›¸åŒåæ ‡çš„è¾“å…¥å…ƒç´ ã€‚ç„¶è€Œï¼Œè®¡ç®—Pä¸ªå…ƒç´ çš„å¾ªç¯ä½“å˜å¾—æ›´åŠ å¤æ‚ã€‚å®ƒéœ€è¦æ·»åŠ æ¡ä»¶æ¥æ£€æŸ¥ helo cell å’Œ ghost cell.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 __global__ void convolution_tiled_cached_2D_shared_mem_kernel( // OUT_TILE_DIM^2 threads per block float* N, float* P, int width, int height) { int col =blockIdx.x * OUT_TILE_DIM + threadIdx.x; int row =blockIdx.y * OUT_TILE_DIM + threadIdx.y; // loading input tile __shared__ float N_s[IN_TILE_DIM][IN_TILE_DIM]; if (row \u0026lt; height \u0026amp;\u0026amp; col \u0026lt; width) { N_s[threadIdx.y][threadIdx.x] = N[row * width + col]; } else { N_s[threadIdx.y][threadIdx.x] = 0.0f; } __syncthreads(); // Calculate output elements if (col \u0026lt; width \u0026amp;\u0026amp; row \u0026lt; height) { float Pvalue = 0.0f; // turning off the threads at the edge of the block for (int fRow = 0; fRow \u0026lt; 2 * FILTER_RADIUS + 1; fRow++) { for (int fCol = 0; fCol \u0026lt; 2 * FILTER_RADIUS + 1; fCol++) { if (threadIdx.x + fCol - FILTER_RADIUS \u0026gt;= 0 \u0026amp;\u0026amp; threadIdx.x + fCol - FILTER_RADIUS \u0026lt; IN_TILE_DIM \u0026amp;\u0026amp; threadIdx.x + fRow - FILTER_RADIUS \u0026gt;= 0 \u0026amp;\u0026amp; threadIdx.x + fRow - FILTER_RADIUS \u0026lt; IN_TILE_DIM) { Pvalue += F_c[fRow][fCol] * N_s[threadIdx.y + fRow][threadIdx.x + fCol]; } else { if (row - FILTER_RADIUS + fRow \u0026gt;= 0 \u0026amp;\u0026amp; row - FILTER_RADIUS + fRow \u0026lt; height \u0026amp;\u0026amp; col - FILTER_RADIUS + fCol \u0026gt;= 0 \u0026amp;\u0026amp; col - FILTER_RADIUS + fCol \u0026lt; width) { Pvalue += F_c[fRow][fCol] * N[(row - FILTER_RADIUS + fRow) * width + (col - FILTER_RADIUS + fCol)]; } } } } N[row * width + col] = Pvalue; } } Halo Cell: å®é™…è®¡ç®—åŒºåŸŸå‘¨å›´æ·»åŠ çš„ä¸€åœˆé¢å¤–çš„å•å…ƒæ ¼ã€‚æœ¬è´¨ä¸Šæ˜¯ \u0026ldquo;è™šæ‹Ÿ\u0026rdquo; å•å…ƒæ ¼ï¼Œå­˜åœ¨äºä¸ç›´æ¥å…³æ³¨çš„åŒºåŸŸä¹‹å¤–ã€‚ Ghost Cell: å­˜å‚¨æ¥è‡ªç›¸é‚» tile çš„æ•°æ®å‰¯æœ¬ï¼Œä½¿å¾— block åœ¨æ— éœ€ç›´æ¥è®¿é—®å½¼æ­¤çš„å†…å­˜çš„æƒ…å†µä¸‹è®¿é—®ç›¸é‚»çš„å¿…è¦æ•°æ®ã€‚ ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch7/","summary":"Personal notebook 7 of Programming Massively Parallel Processors.","title":"PMPP Learning-Chapter 7 Convolution-An Introduction to Constant Memory and Caching"},{"content":"6 Performance Considerations å¹¶è¡Œç¨‹åºçš„æ‰§è¡Œé€Ÿåº¦æ ¹æ®ç¨‹åºçš„èµ„æºéœ€æ±‚å’Œç¡¬ä»¶çš„èµ„æºçº¦æŸä¹‹é—´çš„ç›¸äº’åˆ¶çº¦ä¼šæœ‰å¾ˆå¤§çš„å˜åŒ–ã€‚ç®¡ç†å¹¶è¡Œä»£ç å’Œç¡¬ä»¶èµ„æºçº¦æŸä¹‹é—´çš„äº¤äº’å¯¹äºåœ¨å‡ ä¹æ‰€æœ‰å¹¶è¡Œç¼–ç¨‹æ¨¡å‹ä¸­å®ç°é«˜æ€§èƒ½éå¸¸é‡è¦ã€‚\n6.1 Memory Coalescing å½±å“ CUDA å†…æ ¸æ€§èƒ½æœ€é‡è¦çš„å› ç´ ä¹‹ä¸€æ˜¯è®¿é—®å…¨å±€å†…å­˜ä¸­çš„æ•°æ®ï¼Œæœ‰é™çš„å¸¦å®½å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚CUDA è®¾å¤‡çš„å…¨å±€å†…å­˜æ˜¯ç”¨ DRAM å®ç°çš„ã€‚æ•°æ®å­˜å‚¨åœ¨DRAMå•å…ƒä¸­ï¼Œè®¿é—®æ—¶é—´é€šå¸¸æ˜¯çº³ç§’çº§åˆ«ï¼Œç›¸å¯¹äºäºšçº³ç§’çº§åˆ«çš„æ—¶é’Ÿå‘¨æœŸæ¥è¯´å¾ˆæ…¢ã€‚ç°ä»£ DRAM é€šè¿‡å¹¶è¡ŒåŒ–è®¾è®¡æ¥æé«˜æ•°æ®è®¿é—®é€Ÿç‡ï¼Œé€šå¸¸ç§°ä¸ºå†…å­˜è®¿é—®ååé‡ (memory access throughput).\nWhy Are DRAMs So Slow DRAM é€šè¿‡ä¸€ä¸ªä¸ª CMOS æ™¶ä½“ç®¡ (ç§°ä¸º cell) æ¥å­˜å‚¨ 0/1. å½“ç»™æ™¶ä½“ç®¡æœ€ä¸Šé¢çš„ä¸€ç«¯ (ç§°ä½œæ …æ) åŠ ä¸Šç”µå‹æˆ–æ˜¯å–æ¶ˆç”µå‹ï¼Œæ™¶ä½“ç®¡ä¸¤ç«¯å°±å¯ä»¥æµè¿‡ç”µæµã€‚cell ä¸­çš„å°ç”µå®¹æ˜¯å­˜å‚¨ä¿¡æ¯çš„å…³é”®ï¼Œå°ç”µå®¹å¯ä»¥å­˜å‚¨ç”µè·ï¼Œå½“ç”µå®¹å­˜æœ‰ç”µè·ï¼Œcell å­˜å‚¨ 1ï¼›å½“ç”µå®¹ä¸å­˜ç”µè·ï¼Œå­˜å‚¨ 0. å½“è¦è¯»å– cell çš„å­˜å‚¨å€¼ï¼Œé¦–å…ˆæ‰“å¼€æ™¶ä½“ï¼‰ï¼Œç„¶åæ ¹æ®å¯¼é€šåçš„ç”µå®¹æ˜¯å¦ä¼šè¿›è¡Œå……æ”¾ç”µä¿¡æ¯è·å¾—å­˜å‚¨å€¼ã€‚å¦‚æœ cell å­˜å‚¨ 1ï¼Œå³ç”µå®¹å­˜æœ‰ç”µè·ï¼Œé‚£ä¹ˆå½“æ‰“å¼€å¼€å…³æ—¶ç”µå®¹å°±ä¼šæ”¾ç”µï¼›åä¹‹åˆ™ä¸ä¼šã€‚ ä¸€ä¸ª cell åªèƒ½å­˜å‚¨ 1 æ¯”ç‰¹ä¿¡æ¯ï¼Œä¸ºäº†å­˜å‚¨å¤§é‡ä¿¡æ¯ï¼Œéœ€è¦æ„å»ºèµ·å¦‚å›¾æ‰€ç¤ºçš„ cell é˜µåˆ—ã€‚å¯ä»¥çœ‹åˆ°æ¯è¡Œ cell çš„æ™¶ä½“ç®¡çš„æ …æéƒ½æ˜¯è¿åœ¨ä¸€èµ·çš„ï¼Œå³éƒ½è¿åœ¨å­—çº¿ (word line) ä¸Šï¼Œè¿™æ„å‘³ç€ç»™å­—çº¿æ–½åŠ ç”µå‹ï¼Œå­—çº¿å¯¹åº”çš„ä¸€è¡Œcelléƒ½ä¼šè¢«æ‰“å¼€ã€‚å½“ä¸€è¡Œ cell è¢«æ‰“å¼€ï¼Œcell ç”µå®¹å°±ä¼šå‘ä½çº¿ (bit line) å……æ”¾ç”µï¼Œä¸€è¡Œä¸­çš„æ¯ä¸ª cell éƒ½ä¸ä¸€æ¡ä½çº¿ç›´æ¥ç›¸è¿ï¼Œè¯»å–ä½çº¿çš„ç”µå‹å˜åŒ–ï¼Œå³å¯çŸ¥é“ cell çš„å­˜å‚¨ä¿¡æ¯ã€‚\nå­—çº¿ï¼šç”¨æ¥æ§åˆ¶è¯»å–å“ªä¸€ä¸ªå­—ï¼Œä¸€ä¸ªå­—ç”± 4å­—èŠ‚ç»„æˆã€‚ä¹‹æ‰€ä»¥å«å­—çº¿ï¼Œæ˜¯å› ä¸ºç»™è¿™æ ¹çº¿é€šç”µï¼Œä¸€è¡Œ cell éƒ½ä¼šè¢«æ‰“å¼€.å¤šä¸ª cell ç»„åˆèµ·æ¥å°±æ˜¯å¤šä¸ªå­—ï¼Œå› ä¸ºè¿™æ ¹çº¿å¯ä»¥æ‰“å¼€å¤šä¸ªå­—ï¼Œæ‰€ä»¥å«å­—çº¿ ä½çº¿ï¼šåœ¨è¯»å–ä¿¡æ¯æ—¶ï¼Œæ¯ä¸€æ ¹çº¿ä¸Šçš„ç”µå‹æ³¢åŠ¨éƒ½ä»£è¡¨ä¸€ä½æ¯”ç‰¹ä¿¡æ¯ï¼Œæ‰€ä»¥å«åšä½çº¿ã€‚ cell çš„è¯»å–ä¾é å°ç”µå®¹å……æ”¾ç”µï¼Œç”µå®¹å……æ”¾ç”µå¯¼è‡´ä½çº¿äº§ç”Ÿç”µå‹æ³¢åŠ¨ï¼Œé€šè¿‡è¯»å–ä½çº¿ç”µå‹æ³¢åŠ¨å³å¯è·å–ä¿¡æ¯ã€‚å°ç”µå®¹å……æ”¾ç”µæ‰€äº§ç”Ÿçš„ç”µå‹æ³¢åŠ¨æ˜¯å¾ˆå¾®å¼±çš„ï¼Œå……æ”¾ç”µæ‰€é€ æˆçš„ç”µå‹æ³¢åŠ¨çš„æ—¶é—´ä¹Ÿæ˜¯å¾ˆçŸ­çš„ï¼Œå› æ­¤å¾ˆéš¾ç›´æ¥è¯»å–å……æ”¾ç”µä¿¡æ¯ï¼Œä¸ºæ­¤ cell é˜µåˆ—çš„è¯»å–ä½¿ç”¨åˆ°äº† sense amplifierï¼Œå³è¯»å‡ºæ”¾å¤§å™¨ã€‚è¯»å‡ºæ”¾å¤§å™¨å¯ä»¥æ•æ‰åˆ°å¾®å¼±çš„ç”µå‹æ³¢åŠ¨ï¼Œå¹¶æ ¹æ®ç”µå‹æ³¢åŠ¨çš„æƒ…å†µåœ¨æœ¬åœ°è¿˜åŸå‡º cell çš„ç”µå®¹ç”µå‹ï¼Œè€Œä¸”æ”¾å¤§å™¨å†…è¿˜æœ‰é”å­˜å™¨ï¼Œå¯ä»¥æŠŠè¿˜åŸå‡ºæ¥çš„ç”µå®¹ç”µå‹å€¼ä¿å­˜èµ·æ¥ï¼Œè¿™æ ·ä¸€æ¥ cell ä¿å­˜çš„ä¿¡æ¯å°±ä» cell ç”µå®¹è½¬ç§»åˆ°äº†æ”¾å¤§å™¨æœ¬åœ°ã€‚ æ¯æ¡ä½çº¿éƒ½è¦æ¥åˆ°ä¸€ä¸ªæ”¾å¤§å™¨ä¸­ã€‚åœ¨è¯»å– cell è¡Œå‰ï¼Œéœ€è¦æŠŠæ¯æ ¹ä½çº¿éƒ½é¢„å……ç”µ (precharge) åˆ°ç”µå®¹ç”µå‹/ä¾›ç”µç”µå‹æœ€å¤§å€¼çš„ä¸€åŠã€‚åœ¨ DRAM èŠ¯ç‰‡ä¸­ï¼Œè¯»å‡ºæ”¾å¤§å™¨æŠŠ cell é˜µåˆ—åˆ†æˆäº†ä¸¤åŠï¼Œå› ä¸ºå…¶é‡‡ç”¨çš„æ˜¯å·®åˆ†æ”¾å¤§å™¨ï¼Œéœ€è¦åŒæ—¶æ¥å…¥ä¸¤æ ¹ä½çº¿ã€‚æ”¾å¤§ä¿¡å·æ³¢åŠ¨æ—¶éœ€è¦ç”¨ä¸€ä¸ªåŸºå‡†å’Œå¾…æµ‹çº¿ä½œæ¯”è¾ƒï¼Œæ¥åˆ°æ”¾å¤§å™¨ä¸Šçš„ä¸¤æ¡ä½çº¿çš„å…¶ä¸­ä¸€æ¡å°±ä½œä¸ºåŸºå‡†ã€‚åœ¨è¯»å‡ºæ•°æ®ä¹‹åï¼Œæ ¹æ®æ”¾å¤§å™¨é”å­˜çš„å€¼ï¼ŒæŠŠå„æ¡ä½çº¿æ‹‰åˆ°ä¾›ç”µç”µå‹æˆ–æ¥åˆ°åœ°ï¼Œç„¶å cell ç”µå®¹å°±ä¼šæ ¹æ®ä½çº¿ç”µå‹è¿›è¡Œå……ç”µæˆ–æ”¾ç”µï¼Œå½“ cell ç”µå®¹å……æ”¾ç”µç»“æŸï¼Œå°±å¯ä»¥æ–­å¼€å­—çº¿ï¼Œå®£å‘Šæœ¬æ¬¡ DRAM è¯»å–ç»“æŸã€‚ ç®€å•æ¥è¯´è¯»å–ä¸€ä¸ªæ¯”ç‰¹çš„æ€»ä½“æµç¨‹æ˜¯ï¼šè·å¾—è¡Œå·ï¼Œè¯‘ç è¡Œå·ï¼Œå¼€å¯å•å…ƒè¡Œï¼Œæ”¾å¤§ä½çº¿ç”µå‹æ³¢åŠ¨å¹¶æš‚å­˜æ•°æ®åˆ°æ”¾å¤§å™¨ï¼Œè·å¾—åˆ—å·å¹¶æ ¹æ®åˆ—å·é€‰æ‹©ä¸€ä½è¿›è¡Œè¾“å‡ºï¼Œå†™å›æ•°æ®ï¼Œå…³é—­å­—çº¿ï¼Œé‡æ–°é¢„å……ç”µã€‚è€Œå†™ä¸€ä¸ªæ¯”ç‰¹çš„æ€»ä½“æµç¨‹æ˜¯ï¼šè·å¾—è¡Œå·ï¼Œè¯‘ç è¡Œå·ï¼Œå¼€å¯å•å…ƒè¡Œï¼Œæ”¾å¤§ä½çº¿ç”µå‹æ³¢åŠ¨å¹¶æš‚å­˜æ•°æ®åˆ°æ”¾å¤§å™¨ï¼Œè·å¾—åˆ—å·å¹¶è¾“å…¥å†™å…¥æ•°æ®ï¼Œæ ¹æ®åˆ—å·æŠŠå†™å…¥æ•°æ®é€åˆ°æ”¾å¤§å™¨å¹¶æ”¹å†™æš‚å­˜å€¼ï¼Œå†™å›æ•°æ®ï¼Œå…³é—­å­—çº¿ï¼Œé‡æ–°é¢„å……ç”µã€‚ å…¶ä¸­èŠ±è´¹æ—¶é—´æœ€ä¹…çš„ä¸¤é¡¹æ˜¯å¼€å¯å•å…ƒè¡Œå’Œæ”¾å¤§ç”µå‹æ³¢åŠ¨å¹¶æš‚å­˜æ•°æ®ã€‚å¼€å¯å•å…ƒè¡Œæ—¶è¡Œåœ°å€è¯‘ç å™¨éœ€è¦æ‹‰é«˜ä¸€æ¡å­—çº¿ï¼Œç„¶åç”¨è¿™ä¸€æ¡å­—çº¿æ‹‰é«˜å•å…ƒè¡Œä¸Šæ‰€æœ‰æ™¶ä½“ç®¡çš„æ …æç”µå‹ï¼Œç›¸å½“äºç»™ä¸€ä¸ªå¾ˆå¤§çš„ç”µå®¹å……ç”µï¼Œéå¸¸èŠ±è´¹æ—¶é—´ã€‚æ”¾å¤§å™¨å¤§éƒ¨åˆ†æ˜¯æ¨¡æ‹Ÿç”µè·¯ï¼Œå·¥ä½œé€Ÿåº¦ä¸å¿«ï¼Œå› æ­¤æ”¾å¤§ç”µå‹æ³¢åŠ¨å¹¶æš‚å­˜æ•°æ®ä¹Ÿå¾ˆèŠ±è´¹æ—¶é—´ã€‚ DRAM Cell Array\nç”±äºè¯»å–éå¸¸è€—æ—¶ï¼ŒDRAM æ¯æ¬¡è¯»å–æ•°æ®éƒ½ä¼šå­˜å‚¨åœ¨æ”¾å¤§å™¨æœ¬åœ°ç¼“å­˜ (row buffer / cache line). ç¼“å­˜è¡Œå†…çš„å„ä¸ªå­—åœ¨å†…å­˜ä¸Šæ˜¯ç›¸é‚»çš„ï¼Œæ¯å½“è¯»å– cell é˜µåˆ—ä¸­çš„ä¸€ä¸ªæ¯”ç‰¹ä¼šæŠŠå…¶æ‰€åœ¨ç¼“å­˜è¡Œçš„æ‰€æœ‰æ¯”ç‰¹éƒ½é€åˆ°è¾“å‡ºç¼“å­˜ï¼Œè¿™ç§è¯»å–æ–¹å¼å«åšçªå‘ (burst). å½“ warp ä¸­çš„æ‰€æœ‰çº¿ç¨‹è®¿é—®è¿ç»­çš„å…¨å±€å†…å­˜ä½ç½®æ—¶ï¼Œç¡¬ä»¶å°†æ‰€æœ‰è¿™äº›è®¿é—®åˆå¹¶ (colaesce) ä¸ºå¯¹è¿ç»­ DRAM ä½ç½®çš„è®¿é—® (å³è¡Œåœ°å€)ã€‚ æœ‰å„ç§ä¼˜åŒ–ç­–ç•¥æ¥å®ç°å†…å­˜åˆå¹¶ã€‚\né‡æ–°æ’åˆ—çº¿ç¨‹åˆ°æ•°æ®çš„æ˜ å°„ã€‚ é‡æ–°æ’åˆ—æ•°æ®æœ¬èº«çš„å¸ƒå±€ã€‚ corner turning: ä»¥åˆå¹¶çš„æ–¹å¼åœ¨å…¨å±€å†…å­˜å’Œå…±äº«å†…å­˜ä¹‹é—´ä¼ è¾“æ•°æ®ï¼Œå¹¶åœ¨å…±äº«å†…å­˜ä¸­æ‰§è¡Œä¸åˆ©çš„è®¿é—®æ¨¡å¼ã€‚å…±äº«å†…å­˜æ˜¯ç”¨SRAMæŠ€æœ¯å®ç°çš„ï¼Œä¸éœ€è¦åˆå¹¶ï¼Œå› æ­¤ä¸æ˜¯è¿ç»­çš„åœ°å€è®¿é—®å¸¦æ¥çš„å½±å“ä¸å¤§ã€‚ å†…å­˜åˆå¹¶çš„ä¸»è¦ä¼˜ç‚¹æ˜¯ï¼Œèƒ½é€šè¿‡å°†å¤šä¸ªå†…å­˜è®¿é—®åˆå¹¶ä¸ºå•ä¸ªè®¿é—®æ¥å‡å°‘å…¨å±€å†…å­˜æµé‡ã€‚ 6.2 Hiding memory latency ä¸€ä¸ª cell é˜µåˆ—ä¸€æ¬¡å¯ä»¥æä¾›ä¸€ä¸ªæ¯”ç‰¹ï¼Œé‚£ä¹ˆ 8 ä¸ª cell é˜µåˆ—å°±å¯ä»¥ä¸€æ¬¡æä¾› 8 ä¸ªæ¯”ç‰¹ï¼Œä»–ä»¬å…±äº«ä¸€ç»„è¡Œåœ°å€å’Œåˆ—åœ°å€ï¼Œè¢«ç§°ä½œä¸€ä¸ª bank. å¤„ç†å™¨åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªé€šé“ (channel). æ¯ä¸ªé€šé“éƒ½æ˜¯ä¸€ä¸ªå¸¦æœ‰æ€»çº¿çš„å†…å­˜æ§åˆ¶å™¨ï¼Œè¯¥æ€»çº¿å°†ä¸€ç»„ DRAM ç»„è¿æ¥åˆ°å¤„ç†å™¨ã€‚ å¦‚ä¸‹å›¾æ‰€ç¤ºå½“ä¸¤ä¸ª bank è¿æ¥åˆ°é€šé“æ€»çº¿æ—¶ï¼Œå½“ç¬¬ä¸€ä¸ª bank ä¸ºå¦ä¸€ä¸ªè®¿é—®æä¾›æœåŠ¡æ—¶ï¼Œå¯ä»¥åœ¨ç¬¬äºŒä¸ª bank å‘èµ·è®¿é—®ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœ cell é˜µåˆ—è®¿é—®å»¶è¿Ÿä¸æ•°æ®ä¼ è¾“æ—¶é—´ä¹‹æ¯”ä¸º Rï¼Œåˆ™å……åˆ†åˆ©ç”¨ä¿¡é“æ€»çº¿çš„æ•°æ®ä¼ è¾“å¸¦å®½è‡³å°‘éœ€è¦ R+1 ä¸ª bank ã€‚æ›´å¤šçš„ bank å‡å°‘äº†é’ˆå¯¹åŒä¸€ bank çš„å¤šä¸ªåŒæ—¶è®¿é—®çš„æ¦‚ç‡ï¼Œè¿™ç§ç°è±¡ç§°ä¸º bank å†²çª (bank conflict). ç”±äºæ¯ä¸ª bank ä¸€æ¬¡åªèƒ½è¯‘ç ä¸€è¡Œå­—çº¿ï¼Œå› æ­¤è¿™äº›å†²çªè®¿é—®çš„å•å…ƒé˜µåˆ—è®¿é—®å»¶è¿Ÿä¸èƒ½å†é‡å ã€‚æ‹¥æœ‰æ›´å¤šæ•°é‡çš„ bank ä¼šå¢åŠ è¿™äº›è®¿é—®åˆ†æ•£åˆ°å¤šä¸ª bank çš„å¯èƒ½æ€§ã€‚ç¬¬äºŒä¸ªåŸå› æ˜¯æ¯ä¸ª cell é˜µåˆ—çš„å¤§å°é™åˆ¶äº†æ¯ä¸ª bank å¯ä»¥æä¾›çš„æ¯”ç‰¹æ•°ã€‚å› æ­¤ç¬¬å››ç« æ‰€è¯´çš„æœ€å¤§åŒ–å ç”¨ç‡è¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„å¥½å¤„ï¼Œé‚£å°±æ˜¯ç¡®ä¿å‘å‡ºè¶³å¤Ÿçš„å†…å­˜è®¿é—®è¯·æ±‚æ¥éšè— DRAM è®¿é—®å»¶è¿Ÿã€‚\nBanking Improves the Utilization of Data Transfer Bandwidth of a Channel\nåˆ†å¸ƒæ–¹æ¡ˆå­˜å‚¨å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé€šå¸¸ç§°ä¸ºäº¤é”™æ•°æ®åˆ†å¸ƒ (interleaved data distribution). å¯¹äºä¸€ä¸ª 4*4 çš„çŸ©é˜µï¼Œæ¯è¾“å‡ºçŸ©é˜µçš„æ¯ä¸ªå…ƒç´ è®¡ç®—å°†å¯¹é€šé“ 0 ä¸­çš„ä¸¤ä¸ª bank ä»¥åŠé€šé“ 2 ä¸­çš„ä¸¤ä¸ª bank è¿›è¡Œåˆå¹¶è®¿é—®ã€‚\nAn Example of Interleaved Data Distribution\n6.3 Thread Coarsening ä»¥æœ€ç»†ç²’åº¦å¹¶è¡ŒåŒ–å·¥ä½œçš„ç¼ºç‚¹åœ¨äºï¼Œå¹¶è¡ŒåŒ–å·¥ä½œéœ€è¦ä»˜å‡ºä»£ä»·ï¼Œä¾‹å¦‚ä¸åŒçº¿ç¨‹å—å¯¹æ•°æ®çš„é‡å¤åŠ è½½ã€å†—ä½™å·¥ä½œã€åŒæ­¥å¼€é”€ç­‰ã€‚å¦‚æœç¡¬ä»¶æœ€ç”±äºèµ„æºä¸è¶³è€Œé¡ºåºæ‰§è¡Œï¼Œé‚£ä¹ˆè¿™ä¸ªä»£ä»·æ˜¯ä¸å¿…è¦çš„ã€‚éƒ¨åˆ†åºåˆ—åŒ–å·¥ä½œï¼Œå‡å°‘ä¸ºå¹¶è¡Œæ€§ä»˜å‡ºçš„ä»£ä»·ã€‚å› æ­¤å¯ä»¥é€šè¿‡ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ†é…å¤šä¸ªæœ€ç»†ç²’åº¦çš„å·¥ä½œæ¥è§£å†³ï¼Œé€šå¸¸è¢«ç§°ä¸ºçº¿ç¨‹ç²—åŒ– (thread coarsening). å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨ä¹‹å‰çš„ tiled çŸ©é˜µä¹˜æ³•é‡Œï¼Œç”±äºå…±äº«å†…å­˜å†…å®¹ä¸èƒ½è·¨å—å…±äº«ï¼Œæ¯ä¸ªå—å¿…é¡»åŠ è½½çŸ©é˜µ M çš„ tile å‰¯æœ¬ã€‚å› æ­¤å¯ä»¥è®©å—ä¸­çš„æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸¤ä¸ªè¾“å‡ºå…ƒç´ ã€‚è¿™æ ·ï¼Œç²—åŒ–çš„çº¿ç¨‹å—å°†åŠ è½½ M çš„ tile ä¸€æ¬¡ï¼Œå¹¶å°†å®ƒä»¬ç”¨äºè®¡ç®—ä¸ºå¤šä¸ªè¾“å‡º tile.\nThread Coarsening for Tiled Matrix Multiplication\nä¸‹é¢çš„ä»£ç å±•ç¤ºäº†çº¿ç¨‹ç²—åŒ–çš„çŸ©é˜µä¹˜æ³•å†…æ ¸å‡½æ•°ï¼Œåœ¨ width/TILE_WIDTH çš„æ¯æ¬¡è¿­ä»£ä¸­ï¼Œä¸€ä¸ªçº¿ç¨‹è®¡ç®—åŸæ¥ COARSE_FACTOR ä¸ªçº¿ç¨‹å¯¹åº”ä½ç½®çš„è¾“å‡ºã€‚\nä½¿ç”¨çº¿ç¨‹ç²—åŒ–æ—¶è¦æ³¨æ„ï¼š\nä¸è¦åœ¨ä¸å¿…è¦çš„æ—¶å€™ä½¿ç”¨ï¼Œå½“å¹¶è¡ŒåŒ–çš„ä»£ä»·å¯ä»¥é€šè¿‡ç²—åŒ–æ¥é™ä½æ—¶ï¼Œç²—åŒ–æ˜¯æœ‰ç›Šçš„ã€‚ ä¸è¦ä½¿ç”¨è¿‡å¤šçš„ç²—åŒ–ï¼Œä»¥å…ç¡¬ä»¶èµ„æºå¾—ä¸åˆ°å……åˆ†åˆ©ç”¨ã€‚ é¿å…å°†èµ„æºæ¶ˆè€—å¢åŠ åˆ°æŸå®³å ç”¨çš„ç¨‹åº¦ã€‚æ ¹æ®å†…æ ¸çš„ä¸åŒï¼Œçº¿ç¨‹ç²—åŒ–å¯èƒ½éœ€è¦æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨æ›´å¤šçš„å¯„å­˜å™¨æˆ–æ¯ä¸ªçº¿ç¨‹å—ä½¿ç”¨æ›´å¤šçš„å…±äº«å†…å­˜ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 __global__ void CoarsingMatrixMulKernel(float* M, float* N, float* P, int width) { __shared__ float Mds[TILE_WIDTH][TILE_WIDTH]; __shared__ float Nds[TILE_WIDTH][TILE_WIDTH]; int bx = blockIdx.x; int by = blockIdx.y; int tx = threadIdx.x; int ty = threadIdx.y; // Identify the row and column of the P element to work on int row = by * TILE_WIDTH + ty; int colStart = bx * TILE_WIDTH * COARSE_FACTOR + tx; // Initialize Pvalue for all output elements float Pvalue[COARSE_FACTOR]; for (int i = 0; i \u0026lt; COARSE_FACTOR; i++) { Pvalue[i] = 0; } // Loop over the M and N tiles required to compute P element for (int ph = 0; ph \u0026lt; width/TILE_WIDTH; ph++) { // the COARSE_FACTOR tiles of N needs the same tile of M Mds[ty][tx] = M[row * width + ph * TILE_WIDTH + tx]; for (int c = 0; c \u0026lt; COARSE_FACTOR; c++) { int col = colStart + c * TILE_WIDTH; // Value to be computed in the c th tile // Collaborative loading of N tile into shared memory Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col]; __syncthreads(); for (int k = 0; k \u0026lt; TILE_WIDTH; k++) { Pvalue[c] += Mds[ty][k] * Nds[k][tx]; } __syncthreads(); } for (int c = 0; c \u0026lt; COARSE_FACTOR; c++) { int col = colStart + c * TILE_WIDTH; P[row * width + col] = Pvalue[c]; } } } ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch6/","summary":"Personal notebook 6 of Programming Massively Parallel","title":"PMPP Learning-Chapter 6 Performance Considerations"},{"content":"Compute Architecture and Scheduling æœ¬ç« ä»‹ç» GPU è®¡ç®—æ¶æ„ï¼Œå¹¶è¯´æ˜çµæ´»èµ„æºåˆ†é…ã€å—è°ƒåº¦å’Œå ç”¨çš„æ¦‚å¿µã€‚ç„¶åå°†æ·±å…¥è®¨è®ºçº¿ç¨‹è°ƒåº¦ã€å»¶è¿Ÿå®¹å¿ã€æ§åˆ¶å‘æ•£å’ŒåŒæ­¥ã€‚\n4.1 Architecture of a modern GPU ä¸‹å›¾å±•ç¤ºäº† CUDA GPU æ¶æ„ï¼Œå®ƒè¢«ç»„ç»‡æˆä¸€ä¸ªæµå¼å¤šå¤„ç†å™¨ (Streaming Multiprocessors, SMs) æ•°ç»„ã€‚æ¯ä¸ª SM éƒ½æœ‰å‡ ä¸ªå¤„ç†å•å…ƒï¼Œç§°ä¸ºæµå¤„ç†å™¨æˆ– CUDA core (ç®€ç§°ä¸º core)ï¼Œå¦‚å›¾ä¸­ SMs å†…éƒ¨çš„å°å—æ‰€ç¤ºï¼Œå®ƒä»¬å…±äº«æ§åˆ¶é€»è¾‘å’Œå†…å­˜èµ„æºã€‚\nSMs è¿˜å¸¦æœ‰ä¸åŒçš„ç‰‡ä¸Šå­˜å‚¨ç»“æ„ï¼Œç»Ÿç§°ä¸ºå†…å­˜ã€‚GPU è¿˜å¸¦æœ‰åƒå…†å­—èŠ‚çš„ç‰‡å¤–è®¾å¤‡å†…å­˜ï¼Œç§°ä¸ºå…¨å±€å†…å­˜ (global memory).\nè™½ç„¶æ—§çš„GPUä½¿ç”¨ DDR DRAMï¼Œä½†ä» NVIDIA çš„ Pascal æ¶æ„å¼€å§‹ GPU å¯èƒ½ä½¿ç”¨HBM (High-Bandwidth Memory) æˆ– HBM2ï¼Œå®ƒä»¬ç”± DRAM æ¨¡å—ç»„æˆï¼Œä¸GPUç´§å¯†é›†æˆåœ¨åŒä¸€ä¸ªå°è£…ä¸­ã€‚\nArchitecture of a CUDA-capable GPU\n4.2 Block Scheduling å½“è°ƒç”¨å†…æ ¸æ—¶ï¼ŒCUDA runtime ç³»ç»Ÿå¯åŠ¨æ‰§è¡Œå†…æ ¸ä»£ç çš„çº¿ç¨‹ç½‘æ ¼ï¼Œå—ä¸­çš„æ‰€æœ‰çº¿ç¨‹åŒæ—¶åˆ†é…ç»™åŒä¸€ä¸ªçš„ SM. ä¸‹å›¾ä¸­æ¯ä¸ª SM åˆ†é…äº†ä¸‰ä¸ªå—ï¼Œä½†æ˜¯å—éœ€è¦å ç”¨ç¡¬ä»¶èµ„æºæ¥æ‰§è¡Œï¼Œå› æ­¤åŒæ—¶åªèƒ½å°†æœ‰é™æ•°é‡çš„å—åˆ†é…ç»™ç»™å®šçš„ SM. ä¸ºäº†ç¡®ä¿ç½‘æ ¼ä¸­çš„æ‰€æœ‰å—éƒ½å¾—åˆ°æ‰§è¡Œï¼Œruntime ç³»ç»Ÿç»´æŠ¤ä¸€ä¸ªéœ€è¦æ‰§è¡Œçš„å—åˆ—è¡¨ï¼Œå¹¶åœ¨å…ˆå‰åˆ†é…çš„å—å®Œæˆæ‰§è¡Œåå†å°†æ–°å—åˆ†é…ç»™ SMs. ä»¥å—ä¸ºåŸºæœ¬å•å…ƒå°†çº¿ç¨‹åˆ†é…ç»™ SMs ä¿è¯äº†åŒä¸€å—ä¸­çš„çº¿ç¨‹åœ¨åŒä¸€SMä¸ŠåŒæ—¶è¢«è°ƒåº¦ã€‚\nThread Block Assignment to SMs\n4.3 Synchronization and Transparent Scalability CUDA å…è®¸åŒä¸€å—ä¸­çš„çº¿ç¨‹ä½¿ç”¨ barrier åŒæ­¥å‡½æ•° __syncthreads() æ¥åè°ƒå…¶è¡ŒåŠ¨ã€‚ä¸‹å›¾å±•ç¤ºäº†å±éšœåŒæ­¥çš„æ‰§è¡Œæƒ…å†µï¼Œç®­å¤´è¡¨ç¤ºçº¿ç¨‹å„è‡ªæ‰§è¡Œè¿è¡Œçš„æ—¶é—´ã€‚å¼¯æ›²çº¿æ ‡è®°äº†æ¯ä¸ªçº¿ç¨‹å¼€å§‹æ‰§è¡Œ __syncthreads() çš„æ—¶é—´ã€‚å¼¯æ›²çº¿å³ä¾§çš„ç©ºç™½åŒºåŸŸè¡¨ç¤ºæ¯ä¸ªçº¿ç¨‹ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆæ‰€éœ€çš„æ—¶é—´ã€‚ç«–çº¿æ ‡å¿—ç€æœ€åä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œ __syncthreads() çš„æ—¶é—´ï¼Œä¹‹åæ‰€æœ‰çº¿ç¨‹éƒ½è¢«å…è®¸ç»§ç»­æ‰§è¡Œ __syncthreads() ä¹‹åçš„ä»£ç ã€‚\nä¸è¦åœ¨åˆ†æ”¯è¯­å¥ä¸­ä½¿ç”¨ __syncthreads()\næ”¾åœ¨ if è¯­å¥ä¸­æ—¶ï¼Œå—ä¸­çš„æ‰€æœ‰çº¿ç¨‹è¦ä¹ˆå…¨æ‰§è¡ŒåŒ…å« __syncthreads() çš„è·¯å¾„ï¼Œè¦ä¹ˆéƒ½ä¸æ‰§è¡Œã€‚ if-else è¯­å¥ä¸­çš„ä¸¤ä¸ªåˆ†æ”¯éƒ½å­˜åœ¨ï¼Œå—ä¸­çš„æ‰€æœ‰çº¿ç¨‹è¦ä¹ˆå…¨æ‰§è¡Œ if æƒ…å†µä¸‹çš„ __syncthreads() çš„è·¯å¾„ï¼Œè¦ä¹ˆå…¨æ‰§è¡Œ else ä¸‹çš„è·¯å¾„ã€‚ A Example Execution of Barrier Synchronization\nç³»ç»Ÿéœ€è¦ç¡®ä¿æ‰€æœ‰å‚ä¸ barrier åŒæ­¥çš„çº¿ç¨‹éƒ½èƒ½è®¿é—®è¶³å¤Ÿèµ„æºä»¥åˆ°è¾¾ barrier. å¦åˆ™ï¼Œé‚£äº›åˆ°è¾¾ä¸äº†çº¿ç¨‹å¯èƒ½ä¼šå¯¼è‡´æ­»é”ã€‚å› æ­¤åªæœ‰å½“ runtime ç³»ç»Ÿç¡®ä¿äº†å—ä¸­æ‰€æœ‰çº¿ç¨‹æœ‰å®Œæˆæ‰§è¡Œæ‰€éœ€çš„æ‰€æœ‰èµ„æºæ—¶ï¼Œä¸€ä¸ªå—æ‰èƒ½å¼€å§‹æ‰§è¡Œã€‚ é€šè¿‡ç¦æ­¢ä¸åŒå—ä¸­çš„çº¿ç¨‹ä¸€èµ·æ‰§è¡Œ barrier åŒæ­¥ï¼ŒCUDA runtime ç³»ç»Ÿå¯ä»¥ä»¥ä»»ä½•é¡ºåºæ‰§è¡Œå—ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨åªæœ‰å°‘é‡æ‰§è¡Œèµ„æºçš„ç³»ç»Ÿä¸­ï¼Œä¸€æ¬¡æ‰§è¡Œä¸¤ä¸ªå—ã€‚åä¹‹ï¼Œå¯ä»¥åŒæ—¶æ‰§è¡Œå¤šä¸ªå—ã€‚è¿™ç§åœ¨ä¸åŒç¡¬ä»¶ä¸Šä½¿ç”¨ä¸åŒæ•°é‡çš„æ‰§è¡Œèµ„æºæ‰§è¡Œç›¸åŒçš„ä»£ç çš„èƒ½åŠ›è¢«ç§°ä¸ºé€æ˜å¯æ‰©å±•æ€§ (transparent scalability)\nTransparent Scalability of CUDA Programs\n4.4 Warps and SIMD Hardware å½“ä¸€ä¸ªå—è¢«åˆ†é…ç»™ä¸€ä¸ª SM æ—¶ï¼Œå®ƒä¼šè¢«è¿›ä¸€æ­¥åˆ’åˆ†ä¸º 32 ä¸ªçº¿ç¨‹ä¸ºä¸€ç»„çš„å•å…ƒï¼Œç§°ä¸º warp. åœ¨ SMs ä¸­ï¼Œwarp æ˜¯çº¿ç¨‹è°ƒåº¦çš„å•ä½ã€‚ä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ªåˆ’åˆ†çš„ä¾‹å­ã€‚\nBlocks are Partitioned into Warps for Thread Scheduling\nç”±å¤šç»´åº¦çš„çº¿ç¨‹ç»„æˆçš„å—ï¼Œå°†è¢«æŠ•å½±åˆ°çº¿æ€§åŒ–çš„è¡Œä¸»å¸ƒå±€ä¸­æ¥åˆ’åˆ†ã€‚çº¿æ€§å¸ƒå±€æ˜¯ä»¥ (z, y, x) åæ ‡å‡åºçš„æ–¹å¼æ’åˆ—ã€‚ä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ªå¤§å°ä¸º 4*4 å—çš„çº¿æ€§åŒ–è§†å›¾ã€‚å‰ 4 ä¸ªçº¿ç¨‹çš„ threadIdx.y ä¸º 0ï¼Œå®ƒä»¬ä»¥ threadIdx.x å‡åºçš„æ–¹å¼æ’åˆ—ã€‚\nLinear Layout of 2D Threads\nSM æ˜¯å•æŒ‡ä»¤å¤šæ•°æ® (SIMD) æ¨¡å‹ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰çº¿ç¨‹ï¼Œwarp ä¸­çš„æ‰€æœ‰çº¿ç¨‹åŒæ—¶æ‰§è¡Œä¸€æ¡æŒ‡ä»¤ã€‚ä¸‹å›¾å±•ç¤ºäº† SM ä¸­çš„å†…æ ¸å¦‚ä½•è¢«åˆ†ç»„ä¸ºå¤„ç†å—ï¼Œå…¶ä¸­æ¯ 8 ä¸ªå†…æ ¸æ„æˆä¸€ä¸ªå¤„ç†å— (processing block) å¹¶å…±äº«ä¸€ä¸ªæŒ‡ä»¤è·å–/è°ƒåº¦å•å…ƒã€‚åŒä¸€ warp ä¸­çš„çº¿ç¨‹è¢«åˆ†é…åˆ°ç›¸åŒçš„å¤„ç†å—ï¼Œè¯¥å¤„ç†å—è·å–æŒ‡ä»¤å¹¶è®© warp ä¸­çš„æ‰€æœ‰çº¿ç¨‹å¯¹å„è‡ªè´Ÿè´£æ•°æ®çš„éƒ¨åˆ†æ‰§è¡Œè¯¥æŒ‡ä»¤ã€‚è¿™ç§è®¾è®¡å…è®¸è¾ƒå°æ¯”ä¾‹çš„ç¡¬ä»¶ä¸“æ³¨äºæ§åˆ¶ï¼Œè€Œè¾ƒå¤§æ¯”ä¾‹çš„ç¡¬ä»¶ä¸“æ³¨äºæé«˜è®¡ç®—ååé‡ã€‚\nProcessing Blocks Organization\n4.5 Control divergence å½“åŒä¸€ warp ä¸­çš„çº¿ç¨‹æ‰§è¡Œä¸åŒçš„è·¯å¾„æ—¶ï¼Œè¿™äº›çº¿ç¨‹çš„è¡Œä¸ºè¢«ç§°ä½œæ§åˆ¶å‘æ•£ (control divergence). ä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ª warp åœ¨é‡åˆ°åˆ†æ”¯è¯­å¥æ—¶çš„æ‰§è¡Œæ–¹å¼ï¼Œå³é€šè¿‡ä¸¤æ¬¡ pass (æ‰§è¡Œä»£ç çš„é˜¶æ®µ) æ¥åˆ†åˆ«æ‰§è¡Œ then-path å’Œ else-pathï¼Œæœ€ç»ˆå®ç°æ‰€æœ‰çº¿ç¨‹çš„æ±‡åˆã€‚\nPascal åŠä¹‹å‰æ¶æ„ä¸­ï¼Œwarp éœ€è¦é¡ºåºæ‰§è¡Œä¸¤ä¸ª passï¼Œä¸€ä¸ª pass æ‰§è¡Œå®Œæ‰èƒ½å¼€å§‹ä¸‹ä¸€ä¸ª passã€‚ Pass 1ï¼š çº¿ç¨‹ 0-23 æ‰§è¡Œ then-path çš„ä»£ç  Aï¼Œçº¿ç¨‹ 24-31 å¤„äº inactive çŠ¶æ€ã€‚ Pass 2ï¼š çº¿ç¨‹ 24-31 æ‰§è¡Œ else-path çš„ä»£ç  Bï¼Œçº¿ç¨‹ 0-23 å¤„äº inactive çŠ¶æ€ã€‚ Pass 3ï¼š æ‰€æœ‰çº¿ç¨‹æ±‡åˆï¼Œæ‰§è¡Œåç»­ä»£ç  Cã€‚ Volta åŠä¹‹åæ¶æ„ä¸­ï¼Œwarp å¯ä»¥åŒæ—¶æ‰§è¡Œä¸¤ä¸ª passï¼Œä¸åŒçš„çº¿ç¨‹å¯ä»¥äº¤é”™æ‰§è¡Œä¸åŒçš„ä»£ç è·¯å¾„ã€‚ Pass 1ï¼š çº¿ç¨‹ 0-23 å¼€å§‹æ‰§è¡Œ A çš„ç¬¬ä¸€ä¸ªæŒ‡ä»¤ï¼Œçº¿ç¨‹ 24-31 å¼€å§‹æ‰§è¡Œ B çš„ç¬¬ä¸€ä¸ªæŒ‡ä»¤ã€‚ Pass 2ï¼š çº¿ç¨‹ 0-23 æ‰§è¡Œ A çš„ç¬¬äºŒä¸ªæŒ‡ä»¤ï¼Œçº¿ç¨‹ 24-31 æ‰§è¡Œ B çš„ç¬¬äºŒä¸ªæŒ‡ä»¤ã€‚ \u0026hellip; Pass Nï¼š çº¿ç¨‹ 0-23 æ‰§è¡Œå®Œ A çš„æ‰€æœ‰æŒ‡ä»¤ï¼Œçº¿ç¨‹ 24-31 æ‰§è¡Œå®Œ B çš„æ‰€æœ‰æŒ‡ä»¤ã€‚ Pass N+1ï¼š æ‰€æœ‰çº¿ç¨‹æ±‡åˆï¼Œæ‰§è¡Œåç»­ä»£ç  Cã€‚ Example of a Warp Diverging at an if-else Statement\nå‘æ•£ä¹Ÿå¯èƒ½å‡ºç°åœ¨å…¶ä»–æ§åˆ¶æµä¸­ã€‚ä¸‹å›¾å±•ç¤ºäº† warp å¦‚ä½•æ‰§è¡Œå‘æ•£ for å¾ªç¯ã€‚é€šå¸¸æ¥è¯´å¦‚æœåˆ¤æ–­æ¡ä»¶åŸºäº threadIdx çš„å€¼ï¼Œé‚£ä¹ˆæ§åˆ¶è¯­å¥å¯èƒ½ä¼šå¯¼è‡´çº¿ç¨‹å‘æ•£ã€‚ç”±äºçº¿ç¨‹æ€»æ•°éœ€è¦æ˜¯çº¿ç¨‹å—å¤§å°çš„å€æ•°ï¼Œè€Œæ•°æ®å¤§å°å¯ä»¥æ˜¯ä»»æ„çš„ï¼Œå› æ­¤å…·æœ‰çº¿ç¨‹æ§åˆ¶å‘æ•£çš„æ§åˆ¶æµç¨‹å¾ˆå¸¸è§ã€‚ç”±ä»¥ä¸Šä¸¤ä¸ªä¾‹å­å¯ä»¥çœ‹å‡ºä¸èƒ½å‡è®¾ warp ä¸­çš„æ‰€æœ‰çº¿ç¨‹éƒ½å…·æœ‰ç›¸åŒçš„æ‰§è¡Œæ—¶é—´ã€‚å¦‚æœ warp ä¸­çš„æ‰€æœ‰çº¿ç¨‹éƒ½å¿…é¡»å®Œæˆæ‰§è¡Œçš„ä¸€ä¸ªé˜¶æ®µï¼Œç„¶åæ‰èƒ½ç»§ç»­å‰è¿›ï¼Œåˆ™å¿…é¡»ä½¿ç”¨ barrier åŒæ­¥æœºåˆ¶ (å¦‚ __syncwarp() )æ¥ç¡®ä¿æ­£ç¡®æ€§ã€‚\næ§åˆ¶å‘æ•£å¯¹æ€§èƒ½çš„å½±å“éšç€è¢«å¤„ç†å‘é‡å¤§å°çš„å¢åŠ è€Œå‡å°ã€‚ä¾‹å¦‚å¯¹äºé•¿åº¦ä¸º 100 çš„å‘é‡ï¼Œ4ä¸ª warp ä¸­æœ‰ 1 ä¸ªå°†ä¼šæ§åˆ¶å‘æ•£ (25%)ï¼›å¯¹äºå¤§å°ä¸º1000çš„çŸ¢é‡ï¼Œ32 ä¸ª warp ä¸­åªæœ‰ 1 ä¸ªå°†ä¼šæ§åˆ¶å‘æ•£ (3.125%).\nExample of a Warp Diverging at a for-loop\n4.6 Warp scheduling and latency tolerance å½“å°†çº¿ç¨‹åˆ†é…ç»™ SMs æ—¶ï¼Œåˆ†é…ç»™ SM çš„çº¿ç¨‹é€šå¸¸æ¯” SM ä¸­ core çš„ä¸ªæ•°è¿˜è¦å¤šï¼Œå¯¼è‡´æ¯ä¸ª SM åªèƒ½åŒæ—¶æ‰§è¡Œåˆ†é…ç»™å®ƒçš„æ‰€æœ‰çº¿ç¨‹çš„ä¸€éƒ¨åˆ†ã€‚å½“è¦ç”± warp æ‰§è¡Œçš„æŒ‡ä»¤éœ€è¦ç­‰å¾…å…ˆå‰å¯åŠ¨çš„æ“ä½œçš„ç»“æœæ—¶ï¼Œä¸ä¼šé€‰æ‹©è¯¥ warp æ‰§è¡Œã€‚è€Œæ˜¯é€‰æ‹©æ‰§è¡Œå¦ä¸€ä¸ªä¸ç”¨ç­‰å¾…å…ˆå‰æŒ‡ä»¤ç»“æœçš„ warpã€‚è¿™ç§ç”¨å…¶ä»–çº¿ç¨‹çš„å·¥ä½œå¡«å……æŸäº›çº¿ç¨‹æ“ä½œå»¶è¿Ÿæ—¶é—´çš„æœºåˆ¶é€šå¸¸ç§°ä¸ºå»¶è¿Ÿå®¹å¿ (latency tolerance) æˆ–è€…å»¶è¿Ÿéšè— (latency hiding). è€Œé€‰æ‹©å‡†å¤‡æ‰§è¡Œçš„ warp ä¸ä¼šåœ¨æ‰§è¡Œæ—¶é—´çº¿ä¸­å¼•å…¥ä»»ä½•ç©ºé—²æˆ–æµªè´¹çš„æ—¶é—´çš„ç­–ç•¥è¢«ç§°ä¸ºé›¶å¼€é”€çº¿ç¨‹è°ƒåº¦ (zero-overhead thread scheduling). è¿™ç§å®¹å¿é•¿æ“ä½œå»¶è¿Ÿçš„èƒ½åŠ›æ˜¯ GPU ä¸åƒ CPU é‚£æ ·ä¸ºç¼“å­˜å’Œåˆ†æ”¯é¢„æµ‹æœºåˆ¶åˆ†é…é‚£ä¹ˆå¤šèŠ¯ç‰‡é¢ç§¯çš„ä¸»è¦åŸå› ï¼Œå› æ­¤å¯ä»¥æ›´ä¸“æ³¨äºæµ®ç‚¹æ•°è®¡ç®—å’Œå†…å­˜è¯»å–ã€‚\nThreads, Context-switching, and Zero-overhead Scheduling ä¹‹å‰ä»‹ç»è¿‡çº¿ç¨‹ç”±ç¨‹åºçš„ä»£ç ã€æ­£åœ¨æ‰§è¡Œçš„ä»£ç ä¸­çš„æŒ‡ä»¤ã€å˜é‡çš„å€¼å’Œæ•°æ®ç»“æ„ç»„æˆã€‚åœ¨åŸºäºå†¯Â·è¯ºä¼Šæ›¼æ¨¡å‹çš„è®¡ç®—æœºä¸­ï¼Œç¨‹åºçš„ä»£ç å­˜å‚¨åœ¨å­˜å‚¨å™¨ä¸­ã€‚PC (Program Counter) è·Ÿè¸ªæ­£åœ¨æ‰§è¡Œçš„ç¨‹åºæŒ‡ä»¤çš„åœ°å€ã€‚IR (Instruction Register) ä¿å­˜æ­£åœ¨æ‰§è¡Œçš„æŒ‡ä»¤ã€‚å¯„å­˜å™¨å’Œå†…å­˜ä¿å­˜å˜é‡å’Œæ•°æ®ç»“æ„çš„å€¼ã€‚ ç°ä»£å¤„ç†å™¨çš„è®¾è®¡å…è®¸ä¸Šä¸‹æ–‡åˆ‡æ¢ (Context-switching)ï¼Œå¤šä¸ªçº¿ç¨‹å¯ä»¥é€šè¿‡è½®æµæ‰§è¡Œçš„æ–¹å¼åˆ†æ—¶å¤ç”¨ä¸€ä¸ªå¤„ç†å™¨ã€‚é€šè¿‡ä¿å­˜å’Œæ¢å¤ PC å€¼ä»¥åŠå¯„å­˜å™¨å’Œå†…å­˜çš„å†…å®¹ï¼Œå¯ä»¥æš‚åœçº¿ç¨‹çš„æ‰§è¡Œï¼Œå¹¶åœ¨ç¨åæ­£ç¡®æ¢å¤çº¿ç¨‹çš„æ‰§è¡Œã€‚ä¸è¿‡ä¿å­˜å’Œæ¢å¤å¯„å­˜å™¨å†…å®¹å¯èƒ½ä¼šå¢åŠ å¤§é‡æ‰§è¡Œæ—¶é—´ã€‚ ä¼ ç»Ÿçš„ CPU ä»ä¸€ä¸ªçº¿ç¨‹åˆ‡æ¢åˆ°å¦ä¸€ä¸ªçº¿ç¨‹éœ€è¦å°†æ‰§è¡ŒçŠ¶æ€ (ä¾‹å¦‚è¢«åˆ‡æ¢çº¿ç¨‹çš„å¯„å­˜å™¨å†…å®¹) ä¿å­˜åˆ°å†…å­˜ä¸­ï¼Œç¨åå†ä»å†…å­˜ä¸­åŠ è½½ï¼Œè¿™æ ·ä¼šäº§ç”Ÿç©ºé—²å‘¨æœŸã€‚GPU SMs é€šè¿‡åœ¨ç¡¬ä»¶å¯„å­˜å™¨ä¸­ä¿å­˜æŒ‡å®š warp çš„æ‰€æœ‰æ‰§è¡ŒçŠ¶æ€æ¥å®ç°é›¶å¼€é”€è°ƒåº¦ï¼Œå› æ­¤ä¸éœ€è¦ä¿å­˜å’Œæ¢å¤çŠ¶æ€ã€‚ 4.7 Resource partitioning and occupancy ç»™ SM åˆ†é…å…¶æ‰€æ”¯æŒçš„æœ€å¤§ warp æ•°å¹¶ä¸æ€»æ˜¯å¯è¡Œã€‚åˆ†é…ç»™ SM çš„ warp æ•°é‡ä¸å…¶æ”¯æŒçš„ warp æ•°é‡ä¹‹æ¯”ç§°ä¸ºå ç”¨ç‡ (occupancy). ä¾‹å¦‚ï¼ŒAmpere A100 GPU æ¯ä¸ª SM æœ€å¤šæ”¯æŒ 32 ä¸ª blockï¼Œæ¯ä¸ª SM æœ€å¤šæ”¯æŒ 64 ä¸ª warp (2048 ä¸ªçº¿ç¨‹)ï¼Œæ¯ä¸ª block æœ€å¤šæ”¯æŒ 1024 ä¸ªçº¿ç¨‹ã€‚æ„å‘³ç€å—å¤§å°å¯ä»¥ä» 641024 ä¸ç­‰ï¼Œæ¯ä¸ª SM åˆ†åˆ«å¯ä»¥æœ‰ 322 ä¸ªå—ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œåˆ†é…ç»™SMçš„çº¿ç¨‹æ€»æ•°ä¸º2048ï¼Œè¿™ä½¿å ç”¨ç‡æœ€å¤§åŒ–ã€‚ SM ä¸­çš„æ‰§è¡Œèµ„æºåŒ…æ‹¬å¯„å­˜å™¨ã€å…±äº«å†…å­˜çº¿ç¨‹å—æ§½ (æ¯ä¸ª SM æœ€å¤§èƒ½è¢«åˆ†é…çš„çº¿ç¨‹å—æ•°é‡) å’Œçº¿ç¨‹æ§½ (æ¯ä¸ªçº¿ç¨‹å—æœ€å¤§èƒ½è¢«åˆ†é…çš„çº¿ç¨‹æ•°é‡)ï¼Œè¿™äº›èµ„æºåœ¨çº¿ç¨‹ä¹‹é—´åŠ¨æ€åˆ†é…ã€‚èµ„æºçš„åŠ¨æ€åˆ†é…å¯èƒ½å¯¼è‡´ä»–ä»¬ä¹‹é—´ç›¸äº’åˆ¶çº¦ï¼Œä½¿å¾—èµ„æºåˆ©ç”¨ä¸è¶³ã€‚\nç¡¬ä»¶èµ„æºæ”¯æŒçš„å½±å“ã€‚å½“æ¯ä¸ªå—æœ‰32ä¸ªçº¿ç¨‹æ—¶ã€‚Ampere A100 GPU ä¼šå°† 2048 ä¸ªçº¿ç¨‹æ§½åˆ†é…ç»™ 64 ä¸ªå—ã€‚ç„¶è€Œ Volta SM åªæ”¯æŒ 32 ä¸ªçº¿ç¨‹å—æ§½ï¼Œå¯¼è‡´å ç”¨ç‡åªæœ‰ 50%. å½“æ¯ä¸ªå—çš„æœ€å¤§çº¿ç¨‹æ•°ä¸èƒ½æ•´é™¤å—å¤§å°æ—¶ã€‚å½“å—å¤§å°ä¸º 768ï¼ŒSM å°†åªèƒ½å®¹çº³ 2 ä¸ªçº¿ç¨‹å— (1536ä¸ªçº¿ç¨‹)ï¼Œå‰©ä¸‹512ä¸ªçº¿ç¨‹æ§½æœªä½¿ç”¨ï¼Œå ç”¨ç‡ä¸º 75%. å¯„å­˜å™¨èµ„æºé™åˆ¶å¯¹å ç”¨ç‡çš„å½±å“ã€‚Ampere A100 GPU å…è®¸æ¯ä¸ª SM æœ€å¤šå æœ‰ 65,536ä¸ªå¯„å­˜å™¨ã€‚ä¸ºäº†è¾¾åˆ°æ»¡å ç”¨ç‡æ¯ä¸ªçº¿ç¨‹ä¸åº”è¯¥ä½¿ç”¨è¶…è¿‡ 32 ä¸ªå¯„å­˜å™¨ã€‚ è¿™ç§é™åˆ¶å¯¼è‡´èµ„æºä½¿ç”¨çš„è½»å¾®å¢åŠ å¯èƒ½å¯¼è‡´å¹¶è¡Œæ€§å’Œæ€§èƒ½çš„æ˜¾è‘—é™ä½ï¼Œç§°ä¸º performance cliff. ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch4/","summary":"Personal notebook 3 of Programming Massively Parallel","title":"PMPP Learning-Chapter 4 Compute Architecture and Scheduling"},{"content":"5 Memory Architecture and Data Locality ä¹‹å‰ç« èŠ‚æ‰€å†™çš„ CUDA å†…æ ¸åªèƒ½è¾¾åˆ°åº•å±‚ç¡¬ä»¶å³°å€¼ç®—é‡Œçš„ä¸€å°éƒ¨åˆ†ã€‚å› ä¸ºå…¨å±€å†…å­˜ (é€šå¸¸ä½¿ç”¨ç‰‡å¤– DRAM å®ç°) å¾€å¾€å…·æœ‰è¾ƒé•¿çš„è®¿é—®å»¶è¿Ÿ (æ•°ç™¾ä¸ªæ—¶é’Ÿå‘¨æœŸ) å’Œæœ‰é™çš„è®¿é—®å¸¦å®½ã€‚\n5.1 Importance of Memory Access Efficiency åœ¨ä¹‹å‰çŸ©é˜µä¹˜æ³•çš„å†…æ ¸å‡½æ•°ä¸­ï¼Œæ¯æ¬¡è¿­ä»£é‡Œæ‰§è¡Œä¸€æ¬¡æµ®ç‚¹ä¹˜æ³•å’Œä¸€æ¬¡æµ®ç‚¹åŠ æ³•éœ€è¦è®¿é—®å…¨å±€å†…å­˜ä¸¤æ¬¡ã€‚å› æ­¤ï¼Œä»å…¨å±€å†…å­˜è®¿é—®çš„æµ®ç‚¹æ“ä½œæ¬¡æ•° (FLOP) ä¸å­—èŠ‚æ•° (B) çš„æ¯”ç‡ä¸º 2 FLOP-to-8 Bï¼Œå³ 0.25FLOP/B. è®¡ç®—è®¿å­˜æ¯” (compute to global memory access ratio) å®šä¹‰ä¸ºåœ¨ç¨‹åºçš„ä¸€ä¸ªåŒºåŸŸå†…å¯¹å…¨å±€å†…å­˜è®¿é—®çš„å•ä½å­—èŠ‚æ‰§è¡Œçš„ FLOPS æ•°ã€‚ è®¡ç®—è®¿å­˜æ¯”å¯¹ CUDA å†…æ ¸çš„æ€§èƒ½æœ‰é‡å¤§å½±å“ã€‚A100 GPU çš„å…¨å±€å†…å­˜å¸¦å®½å³°å€¼ä¸º 1555 GB/sï¼ŒçŸ©é˜µä¹˜æ³•å†…æ ¸è®¡ç®—è®¿å­˜æ¯”ä¸º 0.25 OP/Bï¼Œå› æ­¤å†…æ ¸å¯ä»¥æ‰§è¡Œçš„å•ç²¾åº¦ FLOPs çš„ååé‡ä¸º 389 GFLOPSï¼Œä»…ä¸º A100 GPU å³°å€¼å•ç²¾åº¦è¿ç®—ååé‡ (19,500 GFLOPS) çš„ 2%. æˆ‘ä»¬æŠŠæ‰§è¡Œé€Ÿåº¦å—å†…å­˜å¸¦å®½é™åˆ¶çš„ç¨‹åºç§°ä¸ºå†…å­˜ç“¶é¢ˆ (memory bound) ç¨‹åºã€‚\nRoofline Model Rooline æ¨¡å‹ç”¨äºè¯„ä¼°åº”ç”¨ç¨‹åºç›¸åœ¨å…¶æ‰€è¿è¡Œçš„ç¡¬ä»¶çš„é™åˆ¶ä¸Šè¾¾åˆ°çš„æ€§èƒ½ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œx è½´è¡¨ç¤ºç®—æœ¯æˆ–è®¡ç®—å¼ºåº¦ (computational intensity)ï¼Œå•ä½ä¸º FLOP/B. y è½´è¡¨ç¤ºä»¥ GFLOPS ä¸ºå•ä½çš„è®¡ç®—ååé‡ã€‚æ¨ªçº¿è¡¨ç¤ºç¡¬ä»¶å¯ä»¥æä¾›çš„å³°å€¼è®¡ç®—ååé‡ã€‚ ç¡¬ä»¶é€šå¸¸å…³æ³¨ä¸¤ä¸ªæŒ‡æ ‡:\nç®—åŠ› Ï€ï¼šä¹Ÿç§°ä¸ºè®¡ç®—å¹³å°çš„æ€§èƒ½ä¸Šé™ï¼ŒæŒ‡çš„æ˜¯ä¸€ä¸ªè®¡ç®—å¹³å°å€¾å°½å…¨åŠ›æ¯ç§’é’Ÿæ‰€èƒ½å®Œæˆçš„æµ®ç‚¹è¿ç®—æ•°ã€‚å•ä½æ˜¯ FLOP/sã€‚ å¸¦å®½ ÃŸï¼šå³è®¡ç®—å¹³å°çš„å¸¦å®½ä¸Šé™ï¼ŒæŒ‡çš„æ˜¯ä¸€ä¸ªè®¡ç®—å¹³å°å€¾å°½å…¨åŠ›æ¯ç§’æ‰€èƒ½å®Œæˆçš„å†…å­˜äº¤æ¢é‡ã€‚å•ä½æ˜¯Byte/sã€‚ ä¸¤ä¸ªæŒ‡æ ‡ç›¸é™¤å³å¯å¾—åˆ°è®¡ç®—å¹³å°çš„è®¡ç®—å¼ºåº¦ä¸Šé™ I_max = Ï€ / ÃŸï¼Œå®ƒæè¿°çš„æ˜¯åœ¨è¿™ä¸ªè®¡ç®—å¹³å°ä¸Šï¼Œå•ä½å†…å­˜äº¤æ¢æœ€å¤šç”¨æ¥è¿›è¡Œå¤šå°‘æ¬¡è®¡ç®—ã€‚ Roofline Model\nä»å›¾ä¸­å¯ä»¥çœ‹å‡ºç®—åŠ›å†³å®šâ€œå±‹é¡¶â€çš„é«˜åº¦ï¼ˆç»¿è‰²çº¿æ®µï¼‰ï¼Œå¸¦å®½å†³å®šâ€œæˆ¿æªâ€çš„æ–œç‡ï¼ˆçº¢è‰²çº¿æ®µï¼‰ã€‚\nMemory-Bound: å½“æ¨¡å‹çš„è®¡ç®—å¼ºåº¦ I å°äºç¡¬ä»¶çš„è®¡ç®—å¼ºåº¦ä¸Šé™ I_max æ—¶ï¼Œç”±äºæ­¤æ—¶æ¨¡å‹ä½äºâ€œæˆ¿æªâ€åŒºé—´ï¼Œå› æ­¤æ¨¡å‹ç†è®ºæ€§èƒ½ P çš„å¤§å°å®Œå…¨ç”±ç¡¬ä»¶çš„å¸¦å®½ä¸Šé™ ÃŸ ï¼ˆæˆ¿æªçš„æ–œç‡ï¼‰ä»¥åŠæ¨¡å‹è‡ªèº«çš„è®¡ç®—å¼ºåº¦ I æ‰€å†³å®šï¼Œå› æ­¤è¿™æ—¶å€™å°±ç§°æ¨¡å‹å¤„äº Memory-Bound çŠ¶æ€ã€‚ Compute-Bound: ä¸ç®¡æ¨¡å‹çš„è®¡ç®—å¼ºåº¦ I æœ‰å¤šå¤§ï¼Œå®ƒçš„ç†è®ºæ€§èƒ½ P æœ€å¤§åªèƒ½ç­‰äºç¡¬ä»¶çš„ç®—åŠ› Ï€ ã€‚å½“æ¨¡å‹çš„è®¡ç®—å¼ºåº¦ I å¤§äºç¡¬ä»¶çš„è®¡ç®—å¼ºåº¦ä¸Šé™ I_max æ—¶ï¼Œæ¨¡å‹åœ¨å½“å‰ç¡¬ä»¶å¤„äº Compute-Bound çŠ¶æ€ ä¸ºäº†è®©å†…æ ¸å…·æœ‰æ›´é«˜çš„æ€§èƒ½ï¼Œéœ€è¦é€šè¿‡å‡å°‘å†…æ ¸æ‰§è¡Œçš„å…¨å±€å†…å­˜è®¿é—®æ¬¡æ•°æ¥å¢åŠ è®¡ç®—è®¿å­˜æ¯”ã€‚\n5.2 CUDA memory types ä¸‹å›¾å±•ç¤ºäº† CUDA è®¾å¤‡çš„å†…å­˜ã€‚å…¨å±€å†…å­˜å’Œå¸¸é‡å†…å­˜è¿™ä¸¤ç§ç±»å‹çš„å†…å­˜éƒ½å¯ä»¥è¢«ä¸»æœºå†™å…¥ (W) å’Œè¯»å– (R) ã€‚å…¨å±€å†…å­˜ä¹Ÿå¯ä»¥è¢«è®¾å¤‡è¯»å†™ï¼Œè€Œå¸¸é‡å†…å­˜åªæ”¯æŒè®¾å¤‡å¯¹å…¶è¯»å–ã€‚ å¦ä¸€ç§ç±»å‹çš„å†…å­˜æ˜¯æœ¬åœ°å†…å­˜ï¼Œä¹Ÿå¯ä»¥è¢«è¯»å†™ã€‚æœ¬åœ°å†…å­˜å®é™…ä¸Šæ”¾åœ¨å…¨å±€å†…å­˜ä¸­ï¼Œå…·æœ‰ç›¸ä¼¼çš„è®¿é—®å»¶è¿Ÿï¼Œä½†å®ƒä¸æ˜¯è·¨çº¿ç¨‹å…±äº«çš„ã€‚æ¯ä¸ªçº¿ç¨‹éƒ½æœ‰è‡ªå·±çš„å…¨å±€å†…å­˜éƒ¨åˆ†ï¼Œå°†å…¶ç”¨ä½œè‡ªå·±çš„ç§æœ‰æœ¬åœ°å†…å­˜ï¼Œå­˜æ”¾ç§æœ‰ä½†ä¸èƒ½åœ¨å¯„å­˜å™¨ä¸­åˆ†é…çš„æ•°æ®ã€‚ å¯„å­˜å™¨ (register) å’Œå…±äº«å†…å­˜ (shared memory) æ˜¯ç‰‡ä¸Šå†…å­˜ã€‚å­˜å‚¨åœ¨è¿™äº›ç±»å‹å†…å­˜ä¸­çš„å˜é‡å¯ä»¥ä»¥é«˜åº¦å¹¶è¡Œçš„æ–¹å¼ä»¥é«˜é€Ÿè®¿é—®ã€‚å…¶ä¸­æ¯ä¸ªçº¿ç¨‹åªèƒ½è®¿é—®è‡ªå·±çš„å¯„å­˜å™¨ã€‚\nOverview of CUDA Memory Model\nä¸åŸºäºå†¯Â·è¯ºä¼Šæ›¼æ¨¡å‹çš„è®¡ç®—æœºç±»æ¯”ï¼ŒCUDA è®¾å¤‡ä¸­çš„å…¨å±€å†…å­˜å¯¹åº”äºå†…å­˜æ¡†ï¼Œå¯„å­˜å™¨å¯¹åº”äºå¯„å­˜å™¨å †ã€‚ä¸è®¿é—®å…¨å±€å†…å­˜ç›¸æ¯”ï¼Œæ¯æ¬¡è®¿é—®å¯„å­˜å™¨æ‰€æ¶‰åŠçš„æŒ‡ä»¤æ›´å°‘ã€‚å½“ç®—æœ¯æŒ‡ä»¤çš„æ“ä½œæ•°åœ¨å¯„å­˜å™¨ä¸­æ—¶ï¼Œä¸éœ€è¦é¢å¤–çš„æŒ‡ä»¤ä½¿ç®—æœ¯é€»è¾‘å•å…ƒ(ALU)å¯ä»¥ä½¿ç”¨è¯¥æ“ä½œæ•°çš„å€¼ã€‚å¦‚æœæ“ä½œæ•°å€¼åœ¨å…¨å±€å†…å­˜ä¸­ï¼Œå¤„ç†å™¨éœ€è¦æ‰§è¡Œå†…å­˜åŠ è½½æ“ä½œè®© ALU èƒ½ä½¿ç”¨æ“ä½œæ•°ã€‚å¹¶ä¸”ä»å¯„å­˜å™¨å †è®¿é—®æ‰€æ¶ˆè€—çš„èƒ½é‡è‡³å°‘æ¯”ä»å…¨å±€å†…å­˜è®¿é—®ä½ä¸€ä¸ªæ•°é‡çº§ã€‚\nMemory vs. Registers in a Modern Computer Based on the von Neumann Model\nä¸‹å›¾å±•ç¤ºäº† CUDA è®¾å¤‡ä¸­çš„å…±äº«å†…å­˜å’Œå¯„å­˜å™¨ã€‚å…±äº«å†…å­˜å®é™…ä¸Šæ˜¯ä¸€ç§æš‚å­˜å­˜å‚¨å™¨ (scratchpad memory)ï¼Œä½œä¸ºç‰‡ä¸Šå†…å­˜çš„ä¸€éƒ¨åˆ†ã€‚å½“å¤„ç†å™¨è®¿é—®å­˜å‚¨åœ¨å…±äº«å†…å­˜ä¸­çš„æ•°æ®æ—¶ï¼Œéœ€è¦æ‰§è¡Œå†…å­˜åŠ è½½æ“ä½œã€‚CUDA ä¸­å…±äº«å†…å­˜å’Œå¯„å­˜å™¨ä¹‹é—´çš„ä¸€ä¸ªé‡è¦åŒºåˆ«æ˜¯ï¼Œå­˜å‚¨åœ¨å…±äº«å†…å­˜ä¸­çš„å˜é‡å¯ä»¥è¢«å—ä¸­çš„æ‰€æœ‰çº¿ç¨‹è®¿é—®ï¼Œè€Œå¯„å­˜å™¨æ•°æ®æ˜¯çº¿ç¨‹ç§æœ‰çš„ã€‚\nShared Memory vs. Registers in a CUDA Device SM\nä¸‹è¡¨ç»™å‡ºäº†å°†ç¨‹åºå˜é‡å£°æ˜ä¸ºå„ç§å†…å­˜ç±»å‹çš„ CUDA è¯­æ³•ã€‚\næ‰€æœ‰åœ¨å†…æ ¸å’Œè®¾å¤‡å‡½æ•°ä¸­å£°æ˜çš„ automatic scalar variables éƒ½è¢«æ”¾å…¥å¯„å­˜å™¨ä¸­ã€‚ Automatic array variables å­˜å‚¨åœ¨çº¿ç¨‹çš„æœ¬åœ°å†…å­˜ä¸­ã€‚å¦‚æœæ‰€æœ‰è®¿é—®éƒ½ä½¿ç”¨å¸¸é‡ç´¢å¼•å€¼ï¼Œç¼–è¯‘å™¨å¯èƒ½å†³å®šå°†å°†å…¶å­˜å‚¨åˆ°å¯„å­˜å™¨ä¸­ã€‚ å—ä¸­çš„æ‰€æœ‰çº¿ç¨‹éƒ½çœ‹åˆ° shared variable çš„ç›¸åŒç‰ˆæœ¬ã€‚å†…æ ¸æ‰§è¡ŒæœŸé—´æ¯ä¸ªå—ä¼šåˆ›å»ºå’Œä½¿ç”¨ä¸€ä¸ªç§æœ‰ç‰ˆæœ¬ã€‚é€šå¸¸ä½¿ç”¨å…±äº«å˜é‡æ¥ä¿å­˜åœ¨å†…æ ¸æ‰§è¡Œé˜¶æ®µç»å¸¸ä½¿ç”¨å’Œé‡ç”¨çš„å…¨å±€å†…å­˜æ•°æ®éƒ¨åˆ†ã€‚ Constant variables é€šå¸¸ç”¨äºå‘æ ¸å‡½æ•°æä¾›è¾“å…¥ã€‚å†…æ ¸å‡½æ•°ä¸èƒ½ä¿®æ”¹å¸¸é‡å˜é‡çš„å€¼ã€‚ Global variables é€šå¸¸ç”¨äºå°†ä¿¡æ¯ä»ä¸€ä¸ªå†…æ ¸è°ƒç”¨ä¼ é€’åˆ°å¦ä¸€ä¸ªå†…æ ¸è°ƒç”¨ã€‚ Variable Declaration Memory Scope Lifetime Automatic variables other than arrays Register Thread Kernel AutomaticÂ array variables Local Thread Kernel __device__Â __shared__ int SharedVar; Shared Block Kernel __device__Â int GlobalVar; Global Grid Application __device__Â __constant__ int ConstantVar; Constant Grid Application åœ¨ CUDA ä¸­ï¼ŒæŒ‡é’ˆå¯ä»¥ç”¨æ¥æŒ‡å‘å…¨å±€å†…å­˜ä¸­çš„æ•°æ®å¯¹è±¡ï¼Œé€šå¸¸æœ‰ä»¥ä¸‹ä¸¤ç§æƒ…å†µä¼šä½¿ç”¨\nå¯¹è±¡ç”±ä¸»æœºå‡½æ•°åˆ†é…ï¼ŒæŒ‡å‘å¯¹è±¡çš„æŒ‡é’ˆç”±å†…å­˜åˆ†é…å‡½æ•° (å¦‚ cudaMalloc) åˆå§‹åŒ–ï¼Œä½œä¸ºå‚æ•°ä¼ é€’ç»™å†…æ ¸å‡½æ•°ã€‚ å°†åœ¨å…¨å±€å†…å­˜ä¸­å£°æ˜çš„å˜é‡çš„åœ°å€èµ‹ç»™æŒ‡é’ˆå˜é‡ã€‚ 5.3 Tiling for Reduced Memory Traffic ä¸€ç§å¸¸è§çš„ç­–ç•¥æ˜¯å°†æ•°æ®åˆ’åˆ†ä¸ºç§°ä¸º tile çš„å­é›†ï¼Œä»¥ä¾¿æ¯ä¸ª tile éƒ½é€‚åˆå…±äº«å†…å­˜ã€‚èƒ½è¿›è¡Œåˆ’åˆ†çš„ä¸€ä¸ªé‡è¦çš„æ ‡å‡†æ˜¯è¿™äº› tile ä¸Šçš„å†…æ ¸è®¡ç®—å¯ä»¥å½¼æ­¤ç‹¬ç«‹åœ°å®Œæˆã€‚ ä¸‹å›¾å±•ç¤ºäº† block(0,0) çš„å››ä¸ªçº¿ç¨‹æ‰€å®Œæˆçš„è®¡ç®—ã€‚è¿™å››ä¸ªçº¿ç¨‹è®¡ç®—P(0,0), P(0,1), P(1,0) å’Œ P(1,1). æ¯ä¸ªçº¿ç¨‹åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­è®¿é—® M çš„ 4 ä¸ªå…ƒç´ å’Œ N çš„ 4 ä¸ªå…ƒç´ ï¼Œå¯ä»¥çœ‹å‡ºæœ‰æ˜æ˜¾é‡å¤çš„éƒ¨åˆ†ã€‚å°†æ¯ä¸ªå—éœ€è¦è®¿é—®çš„æ•°æ®å…ˆåŠ è½½åˆ°å…±äº«å†…å­˜ï¼Œè¿™æ ·å¯ä»¥é¿å…æ¯ä¸ªçº¿ç¨‹ä»å…¨å±€å†…å­˜é‡ŒåŠ è½½é‡å¤çš„æ•°æ®ã€‚å…¨å±€å†…å­˜æµé‡çš„å‡å°‘ä¸å—çš„ç»´åº¦æˆæ­£æ¯”ã€‚æ¯ä¸ªå—å¤§å°ä¸º Width*Width æ—¶ï¼Œå…¨å±€å†…å­˜æµé‡å°†å‡å°‘ä¸ºåŸæ¥çš„ 1/Width.\nA Small Example of Matrix Multiplication\næŒ‰ tile è¿›è¡ŒçŸ©é˜µä¹˜æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯è®©çº¿ç¨‹åœ¨å„è‡ªä½¿ç”¨å…ƒç´ æ¥è¿›è¡Œå†…ç§¯è®¡ç®—ä¹‹å‰ï¼Œå°† M å’Œ N å…ƒç´ çš„å­é›†åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºæŠŠ M å’Œ N åˆ†æˆå¤§å°ä¸º 2*2 çš„å—ã€‚æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œçš„å†…ç§¯è®¡ç®—ç°åœ¨è¢«åˆ’åˆ†ä¸ºå‡ ä¸ªé˜¶æ®µã€‚åœ¨æ¯ä¸ªé˜¶æ®µï¼Œä¸€ä¸ªå—ä¸­çš„æ‰€æœ‰çº¿ç¨‹åä½œå°†å¯¹åº”çš„ M å’Œ N çš„ tile åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­ã€‚è¿™æ ·æ¯ä¸ªé˜¶æ®µå…³æ³¨çš„æ˜¯è¾“å…¥çŸ©é˜µå…ƒç´ çš„ä¸€ä¸ªå°å­é›†ã€‚è¿™ç§é›†ä¸­çš„è®¿é—®è¡Œä¸ºç§°ä¸ºå±€éƒ¨æ€§ (locality).\nTiling M and N to Utilize Shared Memory\n5.4 A Tiled Matrix Multiplication Kernel æŒ‰ç…§ä¸Šè¿°æ–¹æ³•ç¼–å†™çš„å†…æ ¸å‡½æ•°å¦‚ä¸‹ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œx è½´æ–¹å‘ä¸Šåæ ‡ä¸º bx å’Œ tx çš„çº¿ç¨‹åº”è¯¥è´Ÿè´£è®¡ç®— P ä¸­ç´¢å¼•ä¸º bx * tile_width + tx å…ƒç´ ã€‚ç±»ä¼¼åœ°ï¼Œy è½´æ–¹å‘ä¸Šçº¿ç¨‹è¦å¤„ç†çš„ P ä¸­ç´¢å¼•ä¸º by * tile_width + ty. å¤–å¾ªç¯çš„æ¯æ¬¡è¿­ä»£å¯¹åº”äºè®¡ç®—çš„ä¸€ä¸ªé˜¶æ®µã€‚ä¸¤æ¬¡è°ƒç”¨ __syncthreads() çš„åŸå› ä¸åŒï¼Œç¬¬ä¸€æ¬¡è¢«ç§°ä¸ºå†™åè¯» (read-after-write) ä¾èµ–å…³ç³»ï¼Œå› ä¸ºçº¿ç¨‹åœ¨å°è¯•è¯»å–æ•°æ®ä¹‹å‰å¿…é¡»ç­‰å¾…å…¶ä»–çº¿ç¨‹å°†æ•°æ®å†™å…¥æ­£ç¡®çš„ä½ç½®ã€‚ç¬¬äºŒç§è¢«ç§°ä¸ºè¯»åå†™ (write-after-read) ä¾èµ–ï¼Œå› ä¸ºçº¿ç¨‹å¿…é¡»ç­‰å¾…æ‰€æœ‰éœ€è¦å®ƒçš„çº¿ç¨‹è¯»å–æ•°æ®ï¼Œç„¶åæ‰èƒ½è¦†ç›–å®ƒã€‚\nå†™åè¯»ä¾èµ–æ˜¯ä¸€ç§çœŸæ­£ä¾èµ– (true dependence)ï¼Œå› ä¸ºè¯»çº¿ç¨‹ç¡®å®éœ€è¦å†™çº¿ç¨‹æä¾›çš„æ•°æ®ï¼Œæ‰€ä»¥å®ƒåˆ«æ— é€‰æ‹©ï¼Œåªèƒ½ç­‰å¾…ã€‚è¯»åå†™ä¾èµ–å…³ç³»æ˜¯ä¼ªä¾èµ– (false dependence) å…³ç³»ï¼Œå› ä¸ºå†™çº¿ç¨‹ä¸éœ€è¦æ¥è‡ªè¯»çº¿ç¨‹çš„ä»»ä½•æ•°æ®ã€‚è¿™ç§ä¾èµ–æ€§æ˜¯å› ä¸ºå®ƒä»¬è®¿é—®ç›¸åŒçš„å†…å­˜åœ°å€ï¼Œå¦‚æœå®ƒä»¬è®¿é—®ä¸åŒçš„åœ°å€ï¼Œåˆ™ä¸å­˜åœ¨è¿™ç§ä¾èµ–æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 __global__ void TilingMatrixMulKernel(float* M, float* N, float* P, int width) { __shared__ float Mds[TILE_WIDTH][TILE_WIDTH]; __shared__ float Nds[TILE_WIDTH][TILE_WIDTH]; int bx = blockIdx.x; int by = blockIdx.y; int tx = threadIdx.x; int ty = threadIdx.y; // Identify the row and column of the P element to work on int Row = by * TILE_WIDTH + ty; int Col = bx * TILE_WIDTH + tx; float Pvalue = 0; // Loop over the M and N tiles required to compute the P elemrnt for (int ph = 0; ph \u0026lt; width/TILE_WIDTH; ph++) { // Collaborative loading of M and N tiles into shared memory Mds[ty][tx] = M[Row * width + ph * TILE_WIDTH + tx]; Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + Col]; __syncthreads(); for (int k = 0; k \u0026lt; TILE_WIDTH; k++) { Pvalue += Mds[ty][k] * Nds[k][tx]; } __syncthreads(); P[Row * width + Col] = Pvalue; } } Tiling æŠ€æœ¯å¹¶ä¸æ˜¯ GPU ä¸Šæ‰èƒ½å®ç°ã€‚CPU ä¸Šçš„ tiling ä¾èµ–ç¼“å­˜æ¥å°†é‡ç”¨çš„æ•°æ®ä¿ç•™åœ¨èŠ¯ç‰‡ä¸Šï¼Œè€Œ GPU ä¸Šçš„ tiling åˆ™ç›´æ¥åœ°ä½¿ç”¨å…±äº«å†…å­˜æ¥å­˜å‚¨ç‰‡ä¸Šæ•°æ®ã€‚CPU æ ¸å¿ƒé€šå¸¸åªè¿è¡Œä¸€ä¸ªæˆ–ä¸¤ä¸ªçº¿ç¨‹ï¼Œå› æ­¤çº¿ç¨‹å¯ä»¥ä¾èµ–äºç¼“å­˜æ¥ä¿å­˜æœ€è¿‘ä½¿ç”¨çš„æ•°æ®ã€‚ç›¸åï¼ŒGPU SM åŒæ—¶è¿è¡Œå¤šä¸ªçº¿ç¨‹ä»¥éšè—å»¶è¿Ÿï¼Œäº›çº¿ç¨‹ä¼šç«äº‰ç¼“å­˜æ§½ï¼Œä½¿å¾— GPU ç¼“å­˜ä¸å¤ªå¯é ã€‚\n5.5 Boundary Checks æˆ‘ä»¬éœ€è¦æ‰©å±• tiling çŸ©é˜µä¹˜æ³•å†…æ ¸ä½¿å…¶å¤„ç†ä»»æ„å¤§å°çš„çŸ©é˜µã€‚ä¸‹å›¾å±•ç¤ºäº† block(0,0) åœ¨ phase 1 çš„å†…å­˜è®¿é—®æ¨¡å¼ã€‚åœ¨ä¸è¿›è¡Œè¾¹ç•Œæ£€æŸ¥æ—¶ thead(0,1) è¯•å›¾è®¿é—® M(0,3) æ—¶å®é™…ä¸Šè·å¾—çš„æ˜¯ M(1,0). åŒæ ·åœ¨ Block(1,1) åœ¨ phase 0 è®¿é—®æ—¶ä¹Ÿä¼šå‡ºç°ç±»ä¼¼çš„é—®é¢˜ã€‚å› æ­¤åœ¨åŠ è½½æ‰€éœ€çš„ M å’Œ N çš„ tile æ—¶è¾¹ç•Œæ¡ä»¶ä¸ºä¸¤ä¸ªç´¢å¼•éƒ½å°äº Width: Row \u0026lt; Width \u0026amp;\u0026amp; (ph * TILE_WIDT + tx) \u0026lt; Widthï¼Œå¦åˆ™å°† 0.0f å­˜å…¥å¯¹åº”ä½ç½®ã€‚\nMemory Access of Block(0,0) in Phase 1\næ‰©å±•ä¸ºä¸€èˆ¬çš„çŸ©é˜µä¹˜æ³•å†…æ ¸æ˜¯å¾ˆå®¹æ˜“çš„ã€‚å°† Width å‚æ•°æ›¿æ¢ä¸ºä¸‰ä¸ªæ— ç¬¦å·æ•´æ•°å‚æ•°: m, k, n; å°†ç”¨äºæŒ‡ä»£ M çš„è¡Œæ•°/åˆ—æ•°å’Œ P çš„è¡Œæ•°/åˆ—æ•°çš„ Width æ›¿æ¢ä¸º m/nï¼›å°†ç”¨äºæŒ‡ä»£ M çš„åˆ—æ•°å’Œ P çš„è¡Œæ•°çš„ Width æ›¿æ¢ä¸º k. ä¿®æ”¹åä»£ç å¦‚ä¸‹\nCalculation of the Matrix Indexes in Tiled Multiplication\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 __global__ void GEMMKernel(float* M, float* N, float* P, int m, int n, int k) { __shared__ float Mds[TILE_WIDTH][TILE_WIDTH]; __shared__ float Nds[TILE_WIDTH][TILE_WIDTH]; int bx = blockIdx.x; int by = blockIdx.y; int tx = threadIdx.x; int ty = threadIdx.y; // Identify the row and column of the P element to work on int Row = by * TILE_WIDTH + ty; int Col = bx * TILE_WIDTH + tx; float Pvalue = 0; // Loop over the M and N tiles required to compute the P element for (int ph = 0; ph \u0026lt; (k + TILE_WIDTH - 1) / TILE_WIDTH; ph++) { // Collaborative loading of M and N tiles into shared memory if (Row \u0026lt; m \u0026amp;\u0026amp; ph * TILE_WIDTH + tx \u0026lt; k) { Mds[ty][tx] = M[Row * k + ph * TILE_WIDTH + tx]; } else { Mds[ty][tx] = 0.0f; } if (ph * TILE_WIDTH + ty \u0026lt; k \u0026amp;\u0026amp; Col \u0026lt; n) { Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * n + Col]; } else { Nds[ty][tx] = 0.0f; } __syncthreads(); for (int i = 0; i \u0026lt; TILE_WIDTH; i++) { Pvalue += Mds[ty][i] * Nds[i][tx]; } __syncthreads(); } if (Row \u0026lt; m \u0026amp;\u0026amp; Col \u0026lt; n) { P[Row * n + Col] = Pvalue; } } 5.6 Impact of Memory Usage on Occupancy CUDA è®¾å¤‡æä¾›æœ‰é™çš„èµ„æºé™åˆ¶äº†å¯ä»¥åŒæ—¶åœ¨ç»™å®šç¨‹åºçš„ SM ä¸­åˆ†é…çš„çº¿ç¨‹æ•°é‡ã€‚ä¸Šé¢ä»£ç ä¸æ”¯æŒä¸»æœºä»£ç å¯¹å…±äº«å†…å­˜ä½¿ç”¨æƒ…å†µçš„ä»»ä½•åŠ¨æ€è°ƒæ•´ï¼Œå› ä¸ºå…±äº«å†…å­˜ä½¿ç”¨çš„å¤§å°æ˜¯ä¸€ä¸ªå¸¸é‡ã€‚ è§£å†³çš„æ–¹æ³•æ˜¯å…±äº«å†…å­˜å£°æ˜å‰æ·»åŠ ä¸€ä¸ª extern å…³é”®å­—ï¼Œå¹¶åœ¨å£°æ˜ä¸­çœç•¥æ•°ç»„çš„å¤§å°ã€‚å½“è°ƒç”¨å†…æ ¸æ—¶ï¼Œå¯ä»¥æ ¹æ®è®¾å¤‡æŸ¥è¯¢ç»“æœåŠ¨æ€é…ç½®æ¯ä¸ªå—è¦ä½¿ç”¨çš„å…±äº«å†…å­˜é‡ï¼Œå¹¶å°†å…¶ä½œä¸ºç¬¬ä¸‰ä¸ªæ‰§è¡Œé…ç½®å‚æ•°æä¾›ç»™å†…æ ¸è°ƒç”¨ã€‚ç„¶åå°†æ•°ç»„ä¸­æ¯ä¸ªéƒ¨åˆ†çš„å¤§å°ä½œä¸ºå‚æ•°ä¼ é€’ç»™å†…æ ¸å‡½æ•°ã€‚\n1 2 3 4 5 6 7 8 9 size = ...; matrixMulKernel\u0026lt;\u0026lt;\u0026lt;dimGrid,dimBlock,size\u0026gt;\u0026gt;\u0026gt;(Mdï¼ŒNdï¼ŒPd, Widthï¼Œsize/2ï¼Œsize/2); __global__ void matrixMulKernel(float* M, float* N,float* P,int width, unsigned Mdz_sz, unsigned Nds_sz) { extern __shared__ char float Mds_Nds[]; float *Mds = (float *) Mds_Nds; float *Nds = (float*) Mds_Nds + Mds_sz; } ","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch5/","summary":"Personal notebook 5 of Programming Massively Parallel","title":"PMPP Learning-Chapter 5 Memory Architecture and Data Locality"},{"content":"3 Multidimensional Grids and Data æœ¬ç« å°†æ›´å¹¿æ³›åœ°ä»‹ç»çº¿ç¨‹æ˜¯å¦‚ä½•ç»„ç»‡çš„å’Œå¦‚ä½•ä½¿ç”¨çº¿ç¨‹å’Œå—æ¥å¤„ç†å¤šç»´æ•°ç»„ã€‚\n3.1 Multidimensional Grid Organization å†æ¬¡å¼ºè°ƒç½‘æ ¼ä¸­çš„æ‰€æœ‰çº¿ç¨‹æ‰§è¡Œç›¸åŒçš„å†…æ ¸å‡½æ•°ï¼Œå®ƒä»¬ä¾èµ–äºçº¿ç¨‹ç´¢å¼•æ¥åŒºåˆ†å½¼æ­¤ï¼Œå¹¶ç¡®å®šå„è‡ªè¦å¤„ç†çš„æ•°æ®çš„éƒ¨åˆ†ã€‚è¿™äº›çº¿ç¨‹è¢«ç»„ç»‡æˆä¸¤çº§ç»“æ„: ä¸€ä¸ªç½‘æ ¼ç”±ä¸€ä¸ªæˆ–å¤šä¸ªå—ç»„æˆï¼Œæ¯ä¸ªå—ç”±ä¸€ä¸ªæˆ–å¤šä¸ªçº¿ç¨‹ç»„æˆã€‚è°ƒç”¨å†…æ ¸å‡½æ•°æ—¶éœ€è¦æŒ‡å®šæ‰§è¡Œé…ç½®å‚æ•° gridDim å’Œ blockDimï¼ŒgridDim æ˜¯ä¸€ä¸ªä¸‰ç»´å—æ•°ç»„ï¼ŒblockDim æ˜¯ä¸€ä¸ªä¸‰ç»´çº¿ç¨‹æ•°ç»„ã€‚ä»–ä»¬çš„ç±»å‹éƒ½æ˜¯ dim3ï¼Œæ˜¯åŒ…å«ä¸‰ä¸ªå…ƒç´  x, y å’Œ z çš„æ•´æ•°å‘é‡ç±»å‹ï¼Œåˆ†åˆ«æŒ‡å®šäº†æ¯ä¸ªç»´åº¦ä¸Šçš„å—ä¸ªæ•°å’Œçº¿ç¨‹ä¸ªæ•°ã€‚ä½¿ç”¨å°‘äº 3 ä¸ªç»´åº¦æ—¶å¯ä»¥å°†æœªä½¿ç”¨çš„ç»´åº¦å¤§å°è®¾ç½®ä¸º 1ã€‚ç½‘æ ¼ä¸­çš„æ‰€æœ‰å—éƒ½å…·æœ‰ç›¸åŒçš„ç»´åº¦å’Œå¤§å°ã€‚ä¸€æ—¦ç½‘æ ¼å¯åŠ¨ï¼Œç½‘æ ¼å’Œå—çš„å°ºå¯¸å°†ä¿æŒä¸å˜ï¼Œç›´åˆ°æ•´ä¸ªç½‘æ ¼å®Œæˆæ‰§è¡Œã€‚\nå½“å‰ CUDA ç³»ç»Ÿä¸­ï¼Œæ¯ä¸ªå—çš„æ€»å¤§å°é™åˆ¶ä¸º 1024 ä¸ªçº¿ç¨‹ã€‚åªè¦çº¿ç¨‹æ€»æ•°ä¸è¶…è¿‡ 1024ï¼Œè¿™äº›çº¿ç¨‹å°±å¯ä»¥ä»¥ä»»ä½•æ–¹å¼åˆ†å¸ƒåœ¨ä¸‰ä¸ªç»´åº¦ä¸Šã€‚\n1 function_name\u0026lt;\u0026lt;\u0026lt;gridDim, blockDim\u0026gt;\u0026gt;\u0026gt;(...); ä¸€ä¸ªä¾‹å­å¦‚ä¸‹ï¼ŒdimBlockå’ŒdimGridæ˜¯ç”±ç¨‹åºå‘˜å®šä¹‰çš„ä¸»æœºä»£ç å˜é‡ã€‚\n1 2 3 dim3 dimGrid(32, 1, 1); dim3 dimBlock(128, 1, 1); vecAddKernel\u0026lt;\u0026lt;\u0026lt;dimGrid, dimBlock\u0026gt;\u0026gt;\u0026gt;(...); ä¸‹å›¾å±•ç¤ºäº† gridDim(2,2,1) å’Œ blockDim (4,2,2) æƒ…å†µä¸‹çº¿ç¨‹ç»„ç»‡çš„æƒ…å†µã€‚\nA Multidimensional Example of CUDA Grid Organization\n3.2 Mapping threads to multidimensional data é€‰æ‹© 1Dã€2D æˆ– 3D çš„çº¿ç¨‹ç»„ç»‡é€šå¸¸åŸºäºæ•°æ®çš„æ€§è´¨ã€‚ä¾‹å¦‚å›¾åƒæ˜¯ä¸€ä¸ªäºŒç»´åƒç´ æ•°ç»„ã€‚ä½¿ç”¨ç”± 2D å—ç»„æˆçš„ 2D ç½‘æ ¼å¯ä»¥æ–¹ä¾¿åœ°å¤„ç†å›¾åƒä¸­çš„åƒç´ ã€‚ä¸‹å›¾å±•ç¤ºäº†å¤„ç†å¤§å°ä¸º 62*76 1F1F çš„å›¾ç‰‡ P çš„ä¸€ç§ç»„ç»‡æ–¹å¼ã€‚å‡è®¾ä½¿ç”¨ 16*16 å¤§å°çš„å—ï¼Œé‚£ä¹ˆåœ¨ y æ–¹å‘ä¸Šéœ€è¦ 4 ä¸ªå—ï¼Œåœ¨ x æ–¹å‘ä¸Šéœ€è¦ 5 ä¸ªå—ã€‚æ¨ªçºµåæ ‡çš„è®¡ç®—æ–¹å¼ä¸º\n1 2 row coordinate = blockIdx.y * blockDim.y + threadIdx.y col coordinate = blockIdx.x * blockDim.x + threadIdx.x æˆ‘ä»¬å°†æŒ‰ç»´åº¦çš„é™åº (z, y, x) è¡¨ç¤ºå¤šç»´æ•°æ®ã€‚è¿™ç§é¡ºåºä¸ gridDim å’Œ blockDim ç»´åº¦ä¸­æ•°æ®ç»´åº¦çš„é¡ºåºç›¸åï¼ï¼ï¼\nå®é™…ä¸Šï¼Œç”±äºç°ä»£è®¡ç®—æœºä¸­ä½¿ç”¨äºŒç»´å­˜å‚¨ç©ºé—´ï¼ŒC è¯­è¨€ä¸­çš„æ‰€æœ‰å¤šç»´æ•°ç»„éƒ½æ˜¯çº¿æ€§åŒ–çš„ã€‚è™½ç„¶å¯ä»¥ä½¿ç”¨å¦‚ Pin_d[j][i] è¿™æ ·çš„å¤šç»´æ•°ç»„è¯­æ³•è®¿é—®å¤šç»´æ•°ç»„çš„å…ƒç´ ï¼Œä½†ç¼–è¯‘å™¨å°†è¿™äº›è®¿é—®è½¬æ¢ä¸ºæŒ‡å‘æ•°ç»„å¼€å§‹å…ƒç´ çš„åŸºæŒ‡é’ˆï¼Œä»¥åŠä»è¿™äº›å¤šç»´ç´¢å¼•è®¡ç®—å‡ºçš„ä¸€ç»´åç§»é‡ã€‚ è‡³å°‘æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å¯¹äºŒç»´æ•°ç»„è¿›è¡Œçº¿æ€§åŒ–ã€‚å°†åŒä¸€è¡Œ/åˆ—çš„æ‰€æœ‰å…ƒç´ æ”¾ç½®åˆ°è¿ç»­çš„ä½ç½®ã€‚ç„¶åå°†è¡Œ/åˆ—ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°æ”¾å…¥å†…å­˜ç©ºé—´ä¸­ã€‚è¿™ç§æ’åˆ—ç§°ä¸ºè¡Œ/åˆ—ä¸»åºå¸ƒå±€ (row/column-major layout). CUDA C ä½¿ç”¨è¡Œä¸»åºå¸ƒå±€ã€‚\nRow-major Layout for a 2D C Array\nä¸‹é¢å†…æ ¸ä»£ç å°†æ¯ä¸ªé¢œè‰²åƒç´ è½¬æ¢ä¸ºå¯¹åº”çš„ç°åº¦åƒç´ ã€‚æˆ‘ä»¬è®¡ç®—åæ ‡ä¸º (row, col) çš„åƒç´ å¯¹åº”çš„ 1D ç´¢å¼• row * width + col. è¿™ä¸ª 1D ç´¢å¼• grayOffset å°±æ˜¯ Pout çš„åƒç´ ç´¢å¼•ï¼Œå› ä¸ºè¾“å‡ºç°åº¦å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ éƒ½æ˜¯ 1å­—èŠ‚ (unsigned char)ã€‚æ¯ä¸ªå½©è‰²åƒç´ ç”¨ä¸‰ä¸ªå…ƒç´ (r, g, b)å­˜å‚¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º1å­—èŠ‚ã€‚å› æ­¤ rgbOffset ç»™å‡ºäº† Pin æ•°ç»„ä¸­é¢œè‰²åƒç´ çš„èµ·å§‹ä½ç½®ã€‚ä» Pin æ•°ç»„çš„ä¸‰ä¸ªè¿ç»­å­—èŠ‚ä½ç½®è¯»å–æ¯ä¸ªé€šé“å¯¹åº”çš„å€¼ï¼Œæ‰§è¡Œç°åº¦åƒç´ å€¼çš„è®¡ç®—ï¼Œå¹¶ä½¿ç”¨ grayOffset å°†è¯¥å€¼å†™å…¥ Pout æ•°ç»„ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // we have 3 channels corresponding to RGB // The input image is encoded as unsigned characters [0, 255] __global__ void colorToGreyscaleConversion(unsigned char * Pout, unsigned char * Pin, int width, int height) { int Col = threadIdx.x + blockIdx.x * blockDim.x; int Row = threadIdx.y + blockIdx.y * blockDim.y; if (Col \u0026lt; width \u0026amp;\u0026amp; Row \u0026lt; height) { // get 1D coordinate for the grayscale image int greyOffset = Row*width + Col; // one can think of the RGB image having // CHANNEL times columns than the grayscale image int rgbOffset = greyOffset*CHANNELS; unsigned char r = Pin[rgbOffset + 0]; // red value for pixel unsigned char g = Pin[rgbOffset + 1]; // green value for pixel unsigned char b = Pin[rgbOffset + 2]; // blue value for pixel // perform the rescaling and store it // We multiply by floating point constants Pout[grayOffset] = 0.21f*r + 0.71f*g + 0.07f*b; } } 3.3 Image blur: a more complex kernel å›¾åƒæ¨¡ç³Šå‡½æ•°å°†è¾“å‡ºå›¾åƒåƒç´ çš„å€¼è®¡ç®—ä¸ºç›¸é‚»åƒç´  (åŒ…æ‹¬è¾“å…¥å›¾åƒä¸­åƒç´ ) çš„åŠ æƒå’Œã€‚ç®€ä¾¿èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨ç›¸é‚»åƒç´ çš„å¹³å‡å€¼æ¥è®¡ç®—ç»“æœï¼Œå¯¹åº”çš„ä»£ç å¦‚ä¸‹ã€‚ä¸ colorToGrayscaleConversion ä¸­ä½¿ç”¨çš„ç­–ç•¥ç±»ä¼¼ï¼Œå¯¹æ¯ä¸ªè¾“å‡ºåƒç´ ä½¿ç”¨ 1 ä¸ªçº¿ç¨‹æ¥è®¡ç®—ã€‚colå’Œ row è¡¨ç¤ºè¾“å…¥åƒç´  patch çš„ä¸­å¿ƒåƒç´ ä½ç½®ã€‚åµŒå¥—çš„ for å¾ªç¯éå† patch ä¸­çš„æ‰€æœ‰åƒç´ ã€‚if è¯­å¥çš„ curRow \u0026lt; 0 å’Œ curCol \u0026lt; 0 æ¡ä»¶ç”¨äºè·³è¿‡æ‰§è¡Œè¶…å‡ºå›¾åƒèŒƒå›´çš„éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 __global__ void blurKernel(unsigned char *in, unsigned char *out, int width, int height) { int Col = threadIdx.x + blockIdx.x * blockDim.x; int Row = threadIdx.y + blockIdx.y * blockDim.y; if (Col \u0026lt; width \u0026amp;\u0026amp; Row \u0026lt; height) { int pixVal = 0; int pixels = 0; // Get the average of the surrounding BLUR_SIZE x BLUR_SIZE box for (int blurRow = -BLUR_SIZE; blurRow \u0026lt; BLUR_SIZE + 1; blurRow++) { for (int blurCol = -BLUR_SIZE; blurCol \u0026lt; BLUR_SIZE + 1; blurCol++) { int curRow = Row + blurRow; int curCol = Col + blurCol; // If the pixel is within the image, add its value to the sum if(curRow \u0026gt; -1 \u0026amp;\u0026amp; curRow \u0026lt; height \u0026amp;\u0026amp; curCol \u0026gt; -1 \u0026amp;\u0026amp; curCol \u0026lt; width) { pixVal += in[curRow*width + curCol]; pixels++; // Keep track of the number of pixels in the avg } } } // Write our new pixel value out out[Row*width + Col] = (unsigned char)(pixVal / pixels); } } 3.4 Matrix multiplication çŸ©é˜µä¹˜æ³•æ˜¯ Basic Linear Algebra Subprograms (BLAS) çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚\nLevel 1 å½¢å¦‚ $y = \\alpha x + y$ çš„å‘é‡è¿ç®—ã€‚ Level 2 å½¢å¦‚ $y = \\alpha Ax + \\beta y$ çš„çŸ©é˜µ-å‘é‡è¿ç®—ã€‚ Level 3 å½¢å¦‚ $y = \\alpha AB + \\beta C$ çš„çŸ©é˜µ-çŸ©é˜µè¿ç®—ã€‚ ä¸ºäº†ç”¨ CUDA å®ç°çŸ©é˜µä¹˜æ³•ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡å–ä¸ colorToGrayscaleConversion ç›¸åŒçš„æ–¹æ³•å°†ç½‘æ ¼ä¸­çš„çº¿ç¨‹æ˜ å°„åˆ°è¾“å‡ºçŸ©é˜µ P çš„å…ƒç´ ï¼Œå³æ¯ä¸ªçº¿ç¨‹è´Ÿè´£è®¡ç®— P ä¸­çš„ä¸€ä¸ªå…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Assuming square matrices of size Width x Width __global__ void MatrixMulKernel(float* M, float* N, float* P, int Width) { // Calculate the row index of the P element and M int Row = blockIdx.y*blockDim.y+threadIdx.y; // Calculate the column index of P and N int Col = blockIdx.x*blockDim.x+threadIdx.x; if ((Row \u0026gt;= Width) || (Col \u0026gt;= Width)) return; float Pvalue = 0; // each thread computes one element of the block sub-matrix for (int k = 0; k \u0026lt; Width; ++k) Pvalue += M[Row*Width+k]*N[k*Width+Col]; P[Row*Width+Col] = Pvalue; } Matrix Multiplication by Tiling P\n","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch3/","summary":"Personal notebook 3 of Programming Massively Parallel","title":"PMPP Learning-Chapter 3 Multidimensional Grids and Data"},{"content":"2 Heterogeneous Data Parallel Computing æ•°æ®å¹¶è¡Œ (Data Parallel) æ˜¯æŒ‡åœ¨æ•°æ®é›†çš„ä¸åŒéƒ¨åˆ†ä¸Šæ‰§è¡Œçš„è®¡ç®—å·¥ä½œå¯ä»¥å½¼æ­¤ç‹¬ç«‹åœ°å®Œæˆï¼Œä»è€Œå¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„ç°è±¡ã€‚\n2.1 Data Parallel åœ¨å›¾åƒå¤„ç†ä¸­ï¼Œå°†å½©è‰²åƒç´ è½¬æ¢ä¸ºç°åº¦åªéœ€è¦è¯¥åƒç´ çš„æ•°æ®ã€‚æ¨¡ç³Šå›¾åƒå°†æ¯ä¸ªåƒç´ çš„é¢œè‰²ä¸é™„è¿‘åƒç´ çš„é¢œè‰²å¹³å‡ï¼Œåªéœ€è¦åƒç´ çš„å°é‚»åŸŸçš„æ•°æ®ã€‚å³ä½¿æ˜¯ä¸€ä¸ªçœ‹ä¼¼å…¨å±€çš„æ“ä½œï¼Œæ¯”å¦‚æ‰¾åˆ°å›¾åƒä¸­æ‰€æœ‰åƒç´ çš„å¹³å‡äº®åº¦ï¼Œä¹Ÿå¯ä»¥åˆ†è§£æˆè®¸å¤šå¯ä»¥ç‹¬ç«‹æ‰§è¡Œçš„è¾ƒå°çš„è®¡ç®—ã€‚è¿™ç§å¯¹ä¸åŒæ•°æ®å—çš„ç‹¬ç«‹è®¡ç®—æ˜¯æ•°æ®å¹¶è¡Œæ€§çš„åŸºç¡€ã€‚ ä¸ºäº†å°†å½©è‰²å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾åƒï¼Œæˆ‘ä»¬é€šè¿‡ä»¥ä¸‹åŠ æƒå’Œå…¬å¼è®¡ç®—æ¯ä¸ªåƒç´ çš„äº®åº¦å€¼L. è¿™äº›é€åƒç´ è®¡ç®—éƒ½ä¸ä¾èµ–äºå½¼æ­¤ï¼Œéƒ½å¯ä»¥ç‹¬ç«‹æ‰§è¡Œã€‚æ˜¾ç„¶ï¼Œå½©è‰²å›¾åˆ°ç°åº¦å›¾çš„è½¬æ¢å…·æœ‰å¤§é‡çš„æ•°æ®å¹¶è¡Œæ€§ã€‚ $L=0.21r+0.72g+0.07b$\nTask Parallelism vs. Data Parallelism æ•°æ®å¹¶è¡Œå¹¶ä¸æ˜¯å¹¶è¡Œç¼–ç¨‹ä¸­ä½¿ç”¨çš„å”¯ä¸€ç±»å‹çš„å¹¶è¡Œã€‚ä»»åŠ¡å¹¶è¡Œ (Task Parallelism) åœ¨å¹¶è¡Œç¼–ç¨‹ä¸­ä¹Ÿå¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ã€‚ä»»åŠ¡å¹¶è¡Œæ€§é€šå¸¸é€šè¿‡åº”ç”¨ç¨‹åºçš„ä»»åŠ¡åˆ†è§£æ¥æš´éœ²ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç®€å•çš„åº”ç”¨ç¨‹åºå¯èƒ½éœ€è¦åšä¸€ä¸ªå‘é‡åŠ æ³•å’Œä¸€ä¸ªçŸ©é˜µ-å‘é‡ä¹˜æ³•ã€‚æ¯ä¸ªéƒ½æ˜¯ä¸€ä¸ªä»»åŠ¡ã€‚å¦‚æœä¸¤ä¸ªä»»åŠ¡å¯ä»¥ç‹¬ç«‹å®Œæˆï¼Œåˆ™å­˜åœ¨ä»»åŠ¡å¹¶è¡Œæ€§ã€‚I/Oå’Œæ•°æ®ä¼ è¾“ä¹Ÿæ˜¯å¸¸è§çš„ä»»åŠ¡ã€‚ Data Parallelsim in Image2Grayscale Conversion\n2.2 CUDA C Program Structure CUDA C ç”¨æœ€å°‘çš„æ–°è¯­æ³•å’Œåº“å‡½æ•°æ‰©å±•äº†æµè¡Œçš„ ANSI C è¯­è¨€ã€‚CUDA C ç¨‹åºçš„ç»“æ„åæ˜ äº†è®¡ç®—æœºä¸­ä¸»æœº (CPU) å’Œä¸€ä¸ªæˆ–å¤šä¸ªè®¾å¤‡ (GPU) çš„å…±å­˜ã€‚æ¯ä¸ª CUDA C æºæ–‡ä»¶å¯ä»¥åŒæ—¶åŒ…å«ä¸»æœº (host) ä»£ç å’Œè®¾å¤‡ (device) ä»£ç ã€‚ CUDAç¨‹åºçš„æ‰§è¡Œæµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚æ‰§è¡Œä»ä¸»æœºä»£ç  (CPU ä¸²è¡Œä»£ç ) å¼€å§‹ï¼Œå½“è°ƒç”¨å†…æ ¸å‡½æ•° (kernel function) æ—¶ï¼Œä¼šåœ¨è®¾å¤‡ä¸Šå¯åŠ¨å¤§é‡çº¿ç¨‹1æ¥æ‰§è¡Œå†…æ ¸ã€‚ç”±å†…æ ¸è°ƒç”¨å¯åŠ¨çš„æ‰€æœ‰çº¿ç¨‹ç»Ÿç§°ä¸ºç½‘æ ¼ (grid)ã€‚è¿™äº›çº¿ç¨‹æ˜¯ CUDA å¹¶è¡Œæ‰§è¡Œçš„ä¸»è¦è½½ä½“ã€‚\nExecution of a CUDA Program\n2.3 A vector addition kernel ä½¿ç”¨å‘é‡åŠ æ³•æ¥å±•ç¤º CUDA C ç¨‹åºç»“æ„ã€‚ä¸‹é¢å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„ä¼ ç»Ÿ C ç¨‹åºï¼Œå®ƒç”±ä¸€ä¸ªä¸»å‡½æ•°å’Œä¸€ä¸ªå‘é‡åŠ æ³•å‡½æ•°ç»„æˆã€‚\nå½“éœ€è¦åŒºåˆ†ä¸»æœºå’Œè®¾å¤‡æ•°æ®æ—¶ï¼Œæˆ‘ä»¬éƒ½ä¼šåœ¨ä¸»æœºä½¿ç”¨çš„å˜é‡ååé¢åŠ ä¸Š â€œ_hâ€ï¼Œè€Œåœ¨è®¾å¤‡ä½¿ç”¨çš„å˜é‡ååé¢åŠ ä¸Š â€œ_dâ€.\n1 2 3 4 5 6 7 8 9 10 11 12 13 // Compute vector sum h_C = h_A+h_B void vecAdd(float* h_A, float* h_B, float* h_C, int n) { for (int i = 0; i \u0026lt; n; i++) h_C[i] = h_A[i] + h_B[i]; } int main() { // Memory allocation for h_A, h_B, and h_C // I/O to read h_A and h_B, N elements each // â€¦ vecAdd(h_A, h_B, h_C, N); } å¹¶è¡Œæ‰§è¡Œå‘é‡åŠ æ³•çš„ä¸€ç§ç›´æ¥æ–¹æ³•æ˜¯ä¿®æ”¹ vecAdd å‡½æ•°å¹¶å°†å…¶è®¡ç®—ç§»åˆ°è®¾å¤‡ä¸Šã€‚ä¿®æ”¹åçš„ç»“æ„å¦‚ä¸‹æ‰€ç¤ºã€‚\nStructure of the Modified VecAdd\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;cuda_runtime.h\u0026gt; // â€¦ void vecAdd(float* A, float* B, float* C, int n) { int size = n* sizeof(float); float *d_A *d_B, *d_C; /* â€¦ 1. // Allocate device memory for A, B, and C // copy A and B to device memory 2. // Kernel launch code â€“ to have the device // to perform the actual vector addition 3. // copy C from the device memory // Free device vectors */ } 2.4 Device Global Memory and Data Transfer åœ¨å½“å‰çš„CUDAç³»ç»Ÿä¸­ï¼Œè®¾å¤‡é€šå¸¸æ˜¯å¸¦æœ‰è‡ªå·±çš„ DRAM çš„ç¡¬ä»¶å¡ï¼Œç§°ä¸º (è®¾å¤‡)å…¨å±€å†…å­˜ (device global memory). å¯¹äºå‘é‡åŠ æ³•å†…æ ¸ï¼Œåœ¨è°ƒç”¨å†…æ ¸ä¹‹å‰ï¼Œç¨‹åºå‘˜éœ€è¦åœ¨è®¾å¤‡å…¨å±€å†…å­˜ä¸­åˆ†é…ç©ºé—´ï¼Œå¹¶å°†æ•°æ®ä»ä¸»æœºå†…å­˜ä¼ è¾“åˆ°è®¾å¤‡å…¨å±€å†…å­˜ä¸­åˆ†é…çš„ç©ºé—´ã€‚è¿™å¯¹åº”äº 1. éƒ¨åˆ†ã€‚ç±»ä¼¼åœ°ï¼Œåœ¨è®¾å¤‡æ‰§è¡Œä¹‹åï¼Œç¨‹åºå‘˜éœ€è¦å°†ç»“æœæ•°æ®ä»è®¾å¤‡å…¨å±€å†…å­˜ä¼ è¾“å›ä¸»æœºå†…å­˜ï¼Œå¹¶é‡Šæ”¾è®¾å¤‡å…¨å±€å†…å­˜ä¸­ä¸å†éœ€è¦çš„å·²åˆ†é…ç©ºé—´ã€‚è¿™å¯¹åº”äº 3. éƒ¨åˆ†ã€‚ cudaMalloc å‡½æ•°å¯ä»¥ä»ä¸»æœºä»£ç ä¸­è°ƒç”¨ï¼Œä¸ºå¯¹è±¡åˆ†é…ä¸€å—è®¾å¤‡å…¨å±€å†…å­˜ã€‚ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æŒ‡é’ˆå˜é‡çš„åœ°å€ï¼Œè¯¥å˜é‡å°†è¢«è®¾ç½®ä¸ºæŒ‡å‘åˆ†é…çš„å¯¹è±¡ã€‚æŒ‡é’ˆå˜é‡çš„åœ°å€åº”å¼ºåˆ¶è½¬æ¢ä¸º void**ï¼Œè¿™æ ·å¯ä»¥å…è®¸ cudaMalloc å‡½æ•°å°†åˆ†é…å†…å­˜çš„åœ°å€å†™å…¥æ‰€æä¾›çš„æŒ‡é’ˆå˜é‡ä¸­ï¼Œè€Œä¸è€ƒè™‘å…¶ç±»å‹2ã€‚\n1 cudaError_t cudaMalloc(void** devPtr, size_t size); devPtrï¼šæŒ‡å‘æŒ‡å‘è®¾å¤‡å†…å­˜çš„æŒ‡é’ˆçš„æŒ‡é’ˆã€‚ sizeï¼šè¦åˆ†é…çš„å†…å­˜å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚ cudaFree å‡½æ•°é€šè¿‡é‡Šæ”¾è®¾å¤‡å†…å­˜å¹¶å°†å…¶è¿”å›åˆ°å¯ç”¨å†…å­˜æ± æ¥ç®¡ç†è®¾å¤‡å†…å­˜èµ„æºã€‚å®ƒåªéœ€è¦ A_d çš„å€¼æ¥è¯†åˆ«è¦é‡Šæ”¾çš„å†…å­˜åŒºåŸŸï¼Œè€Œä¸éœ€è¦æ”¹å˜ A_d æŒ‡é’ˆæœ¬èº«çš„åœ°å€ã€‚\nåœ¨ä¸»æœºä»£ç ä¸­å¯¹è®¾å¤‡å…¨å±€å†…å­˜æŒ‡é’ˆè¿›è¡Œè§£å¼•ç”¨å¼•ç”¨å¯èƒ½å¯¼è‡´å¼‚å¸¸æˆ–å…¶ä»–ç±»å‹çš„è¿è¡Œé”™è¯¯ã€‚\ncudaMemcpy å‡½æ•°æ˜¯ CUDA ä¸­ç”¨äºåœ¨ä¸»æœºå†…å­˜å’Œè®¾å¤‡å†…å­˜ä¹‹é—´ä¼ è¾“æ•°æ®çš„æ ¸å¿ƒå‡½æ•°ã€‚å®ƒå…è®¸å°†æ•°æ®ä»ä¸»æœºå†…å­˜å¤åˆ¶åˆ°è®¾å¤‡å†…å­˜ï¼Œæˆ–ä»è®¾å¤‡å†…å­˜å¤åˆ¶åˆ°ä¸»æœºå†…å­˜ã€‚\n1 cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind); dstï¼šç›®æ ‡å†…å­˜åœ°å€ï¼Œå¯ä»¥æ˜¯ä¸»æœºå†…å­˜åœ°å€æˆ–è®¾å¤‡å†…å­˜åœ°å€ã€‚ srcï¼š æºå†…å­˜åœ°å€ï¼Œå¯ä»¥æ˜¯ä¸»æœºå†…å­˜åœ°å€æˆ–è®¾å¤‡å†…å­˜åœ°å€ã€‚ countï¼š è¦å¤åˆ¶çš„æ•°æ®å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚ kindï¼š å¤åˆ¶æ–¹å‘ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æšä¸¾å€¼ï¼š cudaMemcpyHostToDeviceï¼šä¸»æœºå†…å­˜-\u0026gt;è®¾å¤‡å†…å­˜ã€‚ cudaMemcpyDeviceToHostï¼šè®¾å¤‡å†…å­˜-\u0026gt;ä¸»æœºå†…å­˜ã€‚ cudaMemcpyDeviceToDeviceï¼šè®¾å¤‡å†…å­˜-\u0026gt;è®¾å¤‡å†…å­˜ã€‚ cudaMemcpyHostToHostï¼šä¸»æœºå†…å­˜-\u0026gt;ä¸»æœºå†…å­˜ äº†è§£å®Œè¿™äº›åï¼Œå¯ä»¥æ›´æ–°ä»£ç çš„æ¡†æ¶å¦‚ä¸‹\nChecking and Handling in CUDA CUDA API å‡½æ•°è¿”å›ä¸€ä¸ª cudaError_t ç±»å‹çš„æ ‡å¿—ï¼ŒæŒ‡ç¤ºå½“å®ƒä»¬å¤„ç†è¯·æ±‚æ—¶æ˜¯å¦å‘ç”Ÿé”™è¯¯ã€‚ åœ¨ CUDA è¿è¡Œæ—¶åº“çš„å¤´æ–‡ä»¶ cuda_runtime.h ä¸­ï¼ŒcudaError_t è¢«å®šä¹‰ä¸ºä¸€ä¸ª int ç±»å‹çš„åˆ«å\n1 typedef int cudaError_t; ä¸€ä¸ªä¾‹å­å¦‚ä¸‹\n1 2 3 4 5 6 7 8 // ... float *d_a; cudaError_t err = cudaMalloc(\u0026amp;d_a, 1024 * sizeof(float)); if (err != cudaSuccess) { printf(\u0026#34;cudaMalloc failed: %s\\n\u0026#34;, cudaGetErrorString(err)); return 1; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 void vecAdd(float* A, float* B, float* C, int n) { int size = n* sizeof(float); float *d_A *d_B, *d_C; cudaMalloc((void **) %d_A, size); cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice); cudaMalloc((void **) %d_B, size); cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice); cudaMalloc((void **) %d_C, size); // Kernel invocation code - to be shown later // ... cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost); // Free device memory for A, B, C cudaFree(d_A); cudaFree(d_B); cudaFree(d_C); } 2.5 Kernel functions and threading å†…æ ¸å‡½æ•°æŒ‡æ‰€æœ‰çº¿ç¨‹åœ¨å¹¶è¡Œé˜¶æ®µæ‰§è¡Œçš„ä»£ç ï¼Œç½‘æ ¼ä¸­çš„æ‰€æœ‰çº¿ç¨‹æ‰§è¡Œç›¸åŒçš„å†…æ ¸ä»£ç ã€‚ã€‚å½“ç¨‹åºçš„ä¸»æœºä»£ç è°ƒç”¨å†…æ ¸æ—¶ï¼ŒCUDA runtime ç³»ç»Ÿå¯åŠ¨ä¸€ä¸ªçº¿ç¨‹ç½‘æ ¼ï¼Œè¿™äº›çº¿ç¨‹è¢«ç»„ç»‡æˆä¸€ä¸ªä¸¤çº§å±‚æ¬¡ç»“æ„ã€‚æ¯ä¸ªç½‘æ ¼éƒ½è¢«ç»„ç»‡ä¸ºçº¿ç¨‹å— (thread block, ç®€ç§°ä¸ºå—) æ•°ç»„ã€‚ç½‘æ ¼çš„æ‰€æœ‰å—éƒ½æ˜¯ç›¸åŒçš„å¤§å°ã€‚åœ¨è°ƒç”¨å†…æ ¸æ—¶ï¼Œæ¯ä¸ªçº¿ç¨‹å—ä¸­çš„çº¿ç¨‹æ€»æ•°ç”±ä¸»æœºä»£ç æŒ‡å®šã€‚ åŒä¸€ä¸ªå†…æ ¸å¯ä»¥åœ¨ä¸»æœºä»£ç çš„ä¸åŒéƒ¨åˆ†ç”¨ä¸åŒæ•°é‡çš„çº¿ç¨‹è°ƒç”¨ã€‚å¯¹äºç»™å®šçš„çº¿ç¨‹ç½‘æ ¼ï¼Œä¸€ä¸ªå—ä¸­çš„çº¿ç¨‹æ•°å¯ä»¥åœ¨åä¸º blockDim çš„å†…ç½®å˜é‡ä¸­è·å¾—ï¼Œå®ƒæ˜¯ä¸€ä¸ªå…·æœ‰ä¸‰ä¸ªæ— ç¬¦å·æ•´æ•°å­—æ®µ (x, y, z) çš„ç»“æ„ä½“ã€‚ ä¸‹å›¾ç»™å‡ºäº†ä¸€ä¸ªç¤ºä¾‹ï¼Œå…¶ä¸­æ¯ä¸ªå—ç”±256ä¸ªçº¿ç¨‹ç»„æˆã€‚æ¯ä¸ªçº¿ç¨‹éƒ½ç”¨ä¸€ä¸ªç®­å¤´è¡¨ç¤ºï¼Œæ ‡æœ‰çº¿ç¨‹åœ¨å—ä¸­çš„ç´¢å¼•å·çš„æ–¹æ¡†ã€‚ç”±äºæ•°æ®æ˜¯ä¸€ç»´å‘é‡ï¼Œå› æ­¤æ¯ä¸ªçº¿ç¨‹å—è¢«ç»„ç»‡ä¸ºä¸€ç»´çº¿ç¨‹æ•°ç»„ã€‚blockDim.x çš„å€¼è¡¨ç¤ºæ¯ä¸ªå—ä¸­çš„çº¿ç¨‹æ€»æ•°ã€‚threadaIdx å˜é‡è¡¨ç¤ºæ¯ä¸ªçº¿ç¨‹åœ¨å—ä¸­çš„åæ ‡ã€‚å…¨å±€ç´¢å¼• i çš„è®¡ç®—å…¬å¼ä¸º i = blockIdx.x * blockDim.x + threadIdx.x\nè®¸å¤šç¼–ç¨‹è¯­è¨€éƒ½æœ‰å†…ç½®å˜é‡ã€‚è¿™äº›å˜é‡å…·æœ‰ç‰¹æ®Šçš„å«ä¹‰å’Œç›®çš„ã€‚è¿™äº›å˜é‡çš„å€¼é€šå¸¸ç”±è¿è¡Œæ—¶ç³»ç»Ÿé¢„å…ˆåˆå§‹åŒ–ï¼Œå¹¶ä¸”åœ¨ç¨‹åºä¸­é€šå¸¸æ˜¯åªè¯»çš„ã€‚\nHierarchical Organization in CUDA\nå‘é‡åŠ æ³•çš„æ ¸å‡½æ•°å®šä¹‰å¦‚ä¸‹ã€‚ç½‘æ ¼ä¸­çš„æ¯ä¸ªçº¿ç¨‹å¯¹åº”äºåŸå§‹å¾ªç¯çš„ä¸€æ¬¡è¿­ä»£ï¼Œè¿™è¢«ç§°ä¸ºå¾ªç¯å¹¶è¡Œ (loop parallel)ï¼Œæ„ä¸ºåŸå§‹é¡ºåºä»£ç çš„è¿­ä»£ç”±çº¿ç¨‹å¹¶è¡Œæ‰§è¡Œã€‚addVecKernel ä¸­æœ‰ä¸€ä¸ª if (i \u0026lt; n) è¯­å¥ï¼Œå› ä¸ºå¹¶éæ‰€æœ‰çš„å‘é‡é•¿åº¦éƒ½å¯ä»¥è¡¨ç¤ºä¸ºå—å¤§å°çš„å€æ•°ã€‚\n1 2 3 4 5 6 __global__ void vecAddKernel(float* A, float* B, float* C, int n) { int i = blockDim.x * blockIdx.x + threadIdx.x; if(i \u0026lt; n) C[i] = A[i] + B[i]; } CUDA C ä½¿ç”¨äº†ä¸‰ä¸ªå¯ä»¥åœ¨å‡½æ•°å£°æ˜ä¸­ä½¿ç”¨çš„é™å®šå­—ã€‚ä¸‹è¡¨å±•ç¤ºäº†è¿™äº›å…³é”®è¯çš„æ„ä¹‰ã€‚\n__host__ å°±æ˜¯åœ¨ä¸»æœºä¸Šæ‰§è¡Œçš„ä¼ ç»Ÿ C å‡½æ•°ï¼Œåªèƒ½ä»å¦ä¸€ä¸ªä¸»æœºå‡½æ•°è°ƒç”¨ã€‚ __global__ è¡¨ç¤ºè¢«å£°æ˜çš„å‡½æ•°æ˜¯ CUDA C å†…æ ¸å‡½æ•°ã€‚å†…æ ¸å‡½æ•°åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œå¹¶ä¸”å¯ä»¥ä»ä¸»æœºä¸Šè°ƒç”¨ã€‚ __device__ å‡½æ•°åœ¨ CUDA è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œåªèƒ½ä»å†…æ ¸å‡½æ•°æˆ–å…¶ä»–è®¾å¤‡å‡½æ•°è°ƒç”¨ã€‚ å¯ä»¥åœ¨å‡½æ•°å£°æ˜ä¸­åŒæ—¶ä½¿ç”¨ __host__ å’Œ __device__. ç¼–è¯‘ç³»ç»Ÿä¼šä¸ºåŒä¸€ä¸ªå‡½æ•°ç”Ÿæˆä¸¤ä¸ªç‰ˆæœ¬çš„ç›®æ ‡ä»£ç ã€‚\nQualifier Keyword Callable From Executed on Executed by __host__ (default) Host Host Caller host thread __global__ Host/Device Device New grid of device thread __device__ Device Device Caller device thread 2.6 Calling kernel functions å®ç°å†…æ ¸å‡½æ•°ä¹‹åï¼Œå‰©ä¸‹çš„æ­¥éª¤æ˜¯ä»ä¸»æœºä»£ç è°ƒç”¨è¯¥å‡½æ•°æ¥å¯åŠ¨ç½‘æ ¼ã€‚å½“ä¸»æœºä»£ç è°ƒç”¨å†…æ ¸æ—¶ï¼Œå®ƒé€šè¿‡æ‰§è¡Œé…ç½®å‚æ•° (execution configuration parameters) è®¾ç½®ç½‘æ ¼å’Œçº¿ç¨‹å—å¤§å°é…ç½®å‚æ•°åœ¨åœ¨ä¼ ç»Ÿçš„Cå‡½æ•°å‚æ•°ä¹‹å‰ç”± \u0026lt;\u0026lt;\u0026lt;...\u0026gt;\u0026gt;\u0026gt; ä¹‹é—´ç»™å‡ºã€‚ç¬¬ä¸€ä¸ªé…ç½®å‚æ•°ç»™å‡ºç½‘æ ¼ä¸­çš„å—æ•°é‡ã€‚ç¬¬äºŒä¸ªå‚æ•°æŒ‡å®šæ¯ä¸ªå—ä¸­çš„çº¿ç¨‹æ•°ã€‚\n1 2 3 4 5 6 7 int vectAdd(float* A, float* B, float* C, int n) { // d_A, d_B, d_C allocations and copies omitted // ... // Run ceil(n/256) (or by (n + 256 - 1) / 256) blocks of 256 threads each vecAddKernel\u0026lt;\u0026lt;\u0026lt;ceil(n/256.0), 256\u0026gt;\u0026gt;\u0026gt;(d_A, d_B, d_C, n); } ä¸‹é¢å±•ç¤ºäº† vecAdd å‡½æ•°ä¸­çš„æœ€ç»ˆä¸»æœºä»£ç ã€‚æ‰€æœ‰çš„çº¿ç¨‹å—æ“ä½œå‘é‡çš„ä¸åŒéƒ¨åˆ†ã€‚å®ƒä»¬å¯ä»¥æŒ‰ä»»æ„é¡ºåºæ‰§è¡Œã€‚\nå®é™…ä¸Šï¼Œåˆ†é…è®¾å¤‡å†…å­˜ã€ä»ä¸»æœºåˆ°è®¾å¤‡çš„è¾“å…¥æ•°æ®ä¼ è¾“ã€ä»è®¾å¤‡åˆ°ä¸»æœºçš„è¾“å‡ºæ•°æ®ä¼ è¾“ä»¥åŠé‡Šæ”¾è®¾å¤‡å†…å­˜çš„å¼€é”€å¯èƒ½ä¼šä½¿ç”Ÿæˆçš„ä»£ç æ¯”åŸå§‹é¡ºåºä»£ç æ…¢ï¼Œè¿™æ˜¯å› ä¸ºå†…æ ¸å®Œæˆçš„è®¡ç®—é‡ç›¸å¯¹äºå¤„ç†æˆ–ä¼ è¾“çš„æ•°æ®é‡æ¥è¯´å¾ˆå°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 void vecAdd(float* A, float* B, float* C, int n) { int size = n * sizeof(float); float *d_A *d_B, *d_C; cudaMalloc(\u0026amp;d_A, size); cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice); cudaMalloc(\u0026amp;d_B, size); cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice); cudaMalloc(\u0026amp;d_C, size); vecAddKernel\u0026lt;\u0026lt;\u0026lt;ceil(n/256.0), 256\u0026gt;\u0026gt;\u0026gt;(d_A, d_B, d_C, n); cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost); // Free device memory for A, B, C cudaFree(d_A); cudaFree(d_B); cudaFree(d_C); } 2.7 Compilation NVCC (NVIDIA C Compiler) å¤„ç†ä¸€ä¸ªCå¤„ç†ä¸€ä¸ªCUDA Cç¨‹åºï¼Œä½¿ç”¨ CUDA å…³é”®å­—æ¥åˆ†ç¦»ä¸»æœºä»£ç å’Œè®¾å¤‡ä»£ç ã€‚\nä¸»æœºä»£ç æ˜¯å°±æ˜¯æ™®é€šçš„ANSI Cä»£ç ï¼Œä½¿ç”¨ C/C++ ç¼–è¯‘å™¨è¿›è¡Œç¼–è¯‘ï¼Œå¹¶ä½œä¸ºä¼ ç»Ÿçš„ CPU è¿›ç¨‹è¿è¡Œã€‚ è®¾å¤‡ä»£ç åŠå…¶ç›¸å…³è¾…åŠ©å‡½æ•°å’Œæ•°æ®ç»“æ„çš„CUDAå…³é”®å­—ï¼Œç”±NVCCç¼–è¯‘æˆç§°ä¸º PTX (Parallel Thread Execution) æ–‡ä»¶çš„è™šæ‹ŸäºŒè¿›åˆ¶æ–‡ä»¶, ç”± NVCC runtime ç»„ä»¶è¿›ä¸€æ­¥ç¼–è¯‘æˆç›®æ ‡æ–‡ä»¶ï¼Œå¹¶åœ¨æ”¯æŒ cuda çš„ GPU è®¾å¤‡ä¸Šæ‰§è¡Œã€‚ Overview of the Compilation Process of a CUDA C Program\nçº¿ç¨‹ç”±ç¨‹åºçš„ä»£ç ã€æ­£åœ¨æ‰§è¡Œçš„ä»£ç ä¸­çš„ä½ç½®ä»¥åŠå®ƒçš„å˜é‡å’Œæ•°æ®ç»“æ„çš„å€¼ç»„æˆã€‚\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ncudaMalloc ä¸ C è¯­è¨€ malloc å‡½æ•°çš„æ ¼å¼ä¸åŒã€‚å‰è€…æ¥å—ä¸¤ä¸ªå‚æ•°ï¼ŒæŒ‡é’ˆå˜é‡å…¶åœ°å€ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°ç»™å‡ºã€‚åè€…åªæ¥å—ä¸€ä¸ªå‚æ•°æ¥æŒ‡å®šåˆ†é…å¯¹è±¡çš„å¤§å°ï¼Œè¿”å›ä¸€ä¸ªæŒ‡å‘åˆ†é…å¯¹è±¡çš„æŒ‡é’ˆã€‚\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch2/","summary":"Personal notebook 2 of Programming Massively Parallel","title":"PMPP Learning-Chapter 2 Heterogeneous Data Parallel"},{"content":"1 Introduction åŸºäºå•ä¸ªä¸­å¤®å¤„ç†å™¨ (Central Processor Unit, CPU) çš„å¾®å¤„ç†å™¨å¤–éƒ¨çœ‹èµ·æ¥æ˜¯æŒ‰é¡ºåºæ‰§è¡ŒæŒ‡ä»¤ï¼Œä¾‹å¦‚è‹±ç‰¹å°”å’Œ AMD çš„ x86 å¤„ç†å™¨ï¼Œéšç€æ—¶é’Ÿé¢‘ç‡å’Œç¡¬ä»¶èµ„æºçš„å¿«é€Ÿå¢é•¿ï¼Œåœ¨20ä¸–çºª80å¹´ä»£å’Œ90å¹´ä»£æ¨åŠ¨äº†è®¡ç®—æœºåº”ç”¨ç¨‹åºçš„æ€§èƒ½å¿«é€Ÿæé«˜å’Œæˆæœ¬é™ä½ã€‚å¯ä»¥ç»™æ¡Œé¢åº”ç”¨æä¾› GFLOPS çº§åˆ«çš„æµ®ç‚¹è¿ç®—ï¼Œç»™æ•°æ®ä¸­å¿ƒæä¾› TFLOPS çº§åˆ«çš„æµ®ç‚¹è¿ç®—ã€‚ç„¶è€Œï¼Œç”±äºèƒ½æºæ¶ˆè€—å’Œæ•£çƒ­é—®é¢˜ï¼Œè¿™ç§è¶‹åŠ¿ä»2003å¹´å¼€å§‹æ”¾ç¼“ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†æ—¶é’Ÿé¢‘ç‡çš„å¢åŠ å’Œä¿æŒæŒ‰é¡ºåºæ­¥éª¤æ‰§è¡ŒæŒ‡ä»¤çš„åŒæ—¶åœ¨å•ä¸ª CPU ä¸Šæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸå†…å¯ä»¥æ‰§è¡Œçš„è¡ŒåŠ¨ã€‚ ä¹‹åå‡ ä¹æ‰€æœ‰çš„å¾®å¤„ç†å™¨ä¾›åº”å•†éƒ½è½¬å‘äº†åœ¨æ¯ä¸ªèŠ¯ç‰‡ä¸Šä½¿ç”¨å¤šä¸ªç‰©ç† CPU (ç§°ä¸ºå¤„ç†å™¨æ ¸å¿ƒ) æ¥æé«˜å¤„ç†èƒ½åŠ›ã€‚åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œä¼ ç»Ÿçš„CPUå¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªå•æ ¸CPUã€‚è¿™æ ·å°±è¦æ±‚å¿…é¡»æœ‰å¤šä¸ªæŒ‡ä»¤åºåˆ—å¹¶ä¸”å¯ä»¥åŒæ—¶åœ¨è¿™äº›å¤„ç†å™¨æ ¸å¿ƒä¸Šæ‰§è¡Œ (æ— è®ºæ˜¯æ¥è‡ªç›¸åŒçš„åº”ç”¨ç¨‹åºè¿˜æ˜¯æ¥è‡ªä¸åŒçš„åº”ç”¨ç¨‹åº)ã€‚ä¸ºäº†ä½¿ä¸€ä¸ªç‰¹å®šçš„åº”ç”¨ç¨‹åºå—ç›Šäºå¤šä¸ªå¤„ç†å™¨æ ¸å¿ƒï¼Œå®ƒçš„å·¥ä½œå¿…é¡»åˆ†æˆå¤šä¸ªæŒ‡ä»¤åºåˆ—ï¼Œè¿™äº›æŒ‡ä»¤åºåˆ—å¯ä»¥åŒæ—¶åœ¨è¿™äº›å¤„ç†å™¨æ ¸å¿ƒä¸Šæ‰§è¡Œã€‚è¿™ç§ä»å•ä¸ªCPUæŒ‰é¡ºåºæ‰§è¡ŒæŒ‡ä»¤åˆ°å¤šä¸ªå†…æ ¸å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæŒ‡ä»¤åºåˆ—çš„è½¬å˜é€ å°±äº†å¹¶è¡Œè®¡ç®—çš„éœ€æ±‚ã€‚\n1.1 Heterogeneous parallel computing åŠå¯¼ä½“è¡Œä¸šç¡®å®šäº†è®¾è®¡å¾®å¤„ç†å™¨çš„ä¸¤æ¡ä¸»è¦è·¯çº¿\nMulticore Trajectory: å¯»æ±‚åœ¨è½¬å˜åˆ°å¤šä¸ªæ ¸æ—¶ä¿æŒé¡ºåºç¨‹åºçš„æ‰§è¡Œé€Ÿåº¦ã€‚ Many-thread Trajectory: æ›´å¤šåœ°å…³æ³¨å¹¶è¡Œåº”ç”¨ç¨‹åºçš„æ‰§è¡Œååé‡ã€‚ è‡ª2003å¹´ä»¥æ¥ï¼Œå¤šçº¿ç¨‹å¤„ç†å™¨å°¤å…¶æ˜¯ GPUï¼Œä¸€ç›´åœ¨æµ®ç‚¹è®¡ç®—æ€§èƒ½ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚å¤šæ ¸å’Œå¤šçº¿ç¨‹ä¹‹é—´åœ¨å³°å€¼æ€§èƒ½ä¸Šçš„å¦‚æ­¤å¤§çš„å·®è·ä¿ƒä½¿è®¸å¤šåº”ç”¨ç¨‹åºå¼€å‘äººå‘˜å°†å…¶è½¯ä»¶çš„è®¡ç®—å¯†é›†å‹éƒ¨åˆ†è½¬ç§»åˆ°gpuä¸Šæ‰§è¡Œã€‚\n64-bit double-precision 32-bit single-precision Tesla A100 GPU 9.7 TFLOPS 156 TFLOPS Intel 24-core Processor 0.33 TLOPS 0.66 TLOPS CPU çš„è®¾è®¡ä¸ºé¢å‘å»¶è¿Ÿçš„ (latency-oriented) è®¾è®¡ã€‚é’ˆå¯¹é¡ºåºä»£ç æ€§èƒ½è¿›è¡Œäº†ä¼˜åŒ–ã€‚è®¡ç®—å•å…ƒå’Œæ“ä½œæ•°ä¼ è¾“é€»è¾‘çš„è®¾è®¡æ˜¯ä¸ºäº†æœ€å°åŒ–è®¡ç®—çš„æœ‰æ•ˆå»¶è¿Ÿï¼Œä»£ä»·æ˜¯å¢åŠ èŠ¯ç‰‡é¢ç§¯å’Œå•ä½åŠŸç‡çš„ä½¿ç”¨ã€‚é‡‡ç”¨å¤æ‚çš„åˆ†æ”¯é¢„æµ‹é€»è¾‘å’Œæ‰§è¡Œæ§åˆ¶é€»è¾‘æ¥å‡å°‘æ¡ä»¶åˆ†æ”¯æŒ‡ä»¤çš„å»¶è¿Ÿä½¿å¾—æ¯ä¸ªçº¿ç¨‹çš„æ‰§è¡Œå»¶è¿Ÿé™ä½ã€‚ç„¶è€Œï¼Œä½å»¶è¿Ÿè®¡ç®—å•å…ƒã€å¤æ‚çš„æ“ä½œæ•°ä¼ é€’é€»è¾‘ã€å¤§ç¼“å­˜å­˜å‚¨å™¨å’Œæ§åˆ¶é€»è¾‘æ¶ˆè€—äº†èŠ¯ç‰‡é¢ç§¯å’ŒåŠŸç‡ï¼Œå¦åˆ™å¯ä»¥ç”¨æ¥æä¾›æ›´å¤šçš„ç®—æœ¯æ‰§è¡Œå•å…ƒå’Œå†…å­˜è®¿é—®é€šé“ã€‚ GPU çš„è®¾è®¡æ˜¯é¢å‘ååé‡ (throught-put oriented)çš„è®¾è®¡ã€‚å¯»æ±‚åœ¨æœ‰é™çš„èŠ¯ç‰‡é¢ç§¯å’ŒåŠŸè€—é¢„ç®—ä¸‹æœ€å¤§åŒ–æµ®ç‚¹è®¡ç®—å’Œå†…å­˜è®¿é—®ååé‡ã€‚è®¸å¤šå›¾å½¢åº”ç”¨ç¨‹åºçš„é€Ÿåº¦å—åˆ°æ•°æ®ä»å†…å­˜ç³»ç»Ÿä¼ è¾“åˆ°å¤„ç†å™¨çš„é€Ÿç‡çš„é™åˆ¶ï¼Œå¿…é¡»èƒ½å¤Ÿå°†å¤§é‡æ•°æ®åŠ è½½å’Œå­˜å‚¨åˆ° DRAM ä¸­çš„å›¾å½¢å¸§ç¼“å†²åŒºã€‚ æ¸¸æˆåº”ç”¨ç¨‹åºæ™®éæ¥å—çš„å®½æ¾å†…å­˜æ¨¡å‹(å„ç§ç³»ç»Ÿè½¯ä»¶ï¼Œåº”ç”¨ç¨‹åºå’ŒI/Oè®¾å¤‡æœŸæœ›å…¶å†…å­˜è®¿é—®å·¥ä½œçš„æ–¹å¼)ä¹Ÿä½¿ GPU æ›´å®¹æ˜“æ”¯æŒè®¿é—®å†…å­˜çš„å¤§è§„æ¨¡å¹¶è¡Œæ€§ã€‚é€šç”¨å¤„ç†å™¨å¿…é¡»æ»¡è¶³é—ç•™æ“ä½œç³»ç»Ÿã€åº”ç”¨ç¨‹åºå’ŒI/Oè®¾å¤‡çš„è¦æ±‚ï¼Œè¿™äº›è¦æ±‚å¯¹æ”¯æŒå¹¶è¡Œå†…å­˜è®¿é—®æå‡ºäº†æ›´å¤šæŒ‘æˆ˜ï¼Œä»è€Œä½¿æé«˜å†…å­˜è®¿é—®çš„ååé‡ (é€šå¸¸ç§°ä¸ºå†…å­˜å¸¦å®½ memory bandwidth) å˜å¾—æ›´åŠ å›°éš¾ã€‚ å°±åŠŸè€—å’ŒèŠ¯ç‰‡é¢ç§¯è€Œè¨€ï¼Œå‡å°‘å»¶è¿Ÿæ¯”å¢åŠ ååé‡è¦æ˜‚è´µå¾—å¤š1ã€‚å› æ­¤ï¼ŒGPU çš„ä¸»æµè§£å†³æ–¹æ¡ˆæ˜¯é’ˆå¯¹å¤§é‡çº¿ç¨‹çš„æ‰§è¡Œååé‡è¿›è¡Œä¼˜åŒ–ï¼Œè€Œä¸æ˜¯å‡å°‘å•ä¸ªçº¿ç¨‹çš„å»¶è¿Ÿã€‚è¿™ç§è®¾è®¡æ–¹æ³•å…è®¸åˆ†çº§å­˜å‚¨å±‚æ¬¡å’Œè®¡ç®—å…·æœ‰è¾ƒé•¿çš„å»¶è¿Ÿï¼Œä»è€ŒèŠ‚çœäº†èŠ¯ç‰‡é¢ç§¯å’ŒåŠŸè€—ã€‚\nCPU and GPU Design Philosophies\n1.2 Why More Speed or Parallelism åŸºäºäººå·¥ç¥ç»ç½‘ç»œçš„æ·±åº¦å­¦ä¹ æ˜¯é€šè¿‡å¤§å¹…æé«˜è®¡ç®—ååé‡è€Œå®ç°çš„æ–°åº”ç”¨ã€‚è™½ç„¶è‡ª 20 ä¸–çºª 70 å¹´ä»£ä»¥æ¥ï¼Œç¥ç»ç½‘ç»œå¾—åˆ°äº†ç§¯æçš„å…³æ³¨ï¼Œä½†ç”±äºéœ€è¦å¤ªå¤šçš„æ ‡è®°æ•°æ®å’Œå¤ªå¤šçš„è®¡ç®—æ¥è®­ç»ƒè¿™äº›ç½‘ç»œï¼Œå®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­ä¸€ç›´æ•ˆæœä¸ä½³ã€‚äº’è”ç½‘çš„å…´èµ·æä¾›äº†å¤§é‡æœ‰æ ‡ç­¾çš„å›¾ç‰‡ï¼Œè€Œ GPU çš„å…´èµ·åˆ™å¸¦æ¥äº†è®¡ç®—ååé‡çš„æ¿€å¢ã€‚å› æ­¤ï¼Œè‡ª2012å¹´ä»¥æ¥ï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„åº”ç”¨åœ¨è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢å¾—åˆ°äº†å¿«é€Ÿçš„é‡‡ç”¨ã€‚è¿™ç§é‡‡ç”¨å½»åº•æ”¹å˜äº†è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ï¼Œå¹¶å¼•å‘äº†è‡ªåŠ¨é©¾é©¶æ±½è½¦å’Œå®¶åº­è¾…åŠ©è®¾å¤‡çš„å¿«é€Ÿå‘å±•ã€‚\n1.3 Speeding up real applications å¹¶è¡Œè®¡ç®—ç³»ç»Ÿç›¸å¯¹äºä¸²è¡Œè®¡ç®—ç³»ç»Ÿæ‰€èƒ½å®ç°çš„åŠ é€Ÿçš„ä¸€ä¸ªé‡è¦å› ç´ æ˜¯å¯ä»¥å¹¶è¡ŒåŒ–çš„åº”ç”¨ç¨‹åºéƒ¨åˆ†ï¼Œå¦ä¸€ä¸ªé‡è¦å› ç´ æ˜¯ä»å†…å­˜è®¿é—®æ•°æ®å’Œå‘å†…å­˜å†™å…¥æ•°æ®çš„é€Ÿåº¦æœ‰å¤šå¿«ã€‚ä¸‹å›¾å±•ç¤ºäº†é¡ºåºå’Œå¹¶è¡Œåº”ç”¨ç¨‹åºéƒ¨åˆ†çš„è¦†ç›–ç‡ã€‚é¡ºåºéƒ¨åˆ†å’Œä¼ ç»Ÿçš„(å•æ ¸)CPUè¦†ç›–éƒ¨åˆ†ç›¸äº’é‡å ã€‚ä»¥å‰çš„GPGPUæŠ€æœ¯å¯¹æ•°æ®å¹¶è¡Œéƒ¨åˆ†çš„è¦†ç›–éå¸¸æœ‰é™ï¼Œå› ä¸ºå®ƒä»…é™äºå¯ä»¥è¡¨ç¤ºä¸ºç»˜åˆ¶åƒç´ çš„è®¡ç®—ã€‚éšœç¢æ˜¯æŒ‡éš¾ä»¥æ‰©å±•å•æ ¸cpuä»¥è¦†ç›–æ›´å¤šæ•°æ®å¹¶è¡Œéƒ¨åˆ†çš„åŠŸç‡é™åˆ¶ã€‚\nCoverage of Application Portions\n1.4 Challenges in parallel programming è®¾è®¡å…·æœ‰ä¸é¡ºåºç®—æ³•ç›¸åŒçš„ç®—æ³•(è®¡ç®—)å¤æ‚åº¦çš„å¹¶è¡Œç®—æ³•å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ è®¸å¤šåº”ç”¨ç¨‹åºçš„æ‰§è¡Œé€Ÿåº¦å—åˆ°å†…å­˜è®¿é—®å»¶è¿Ÿå’Œ/æˆ–ååé‡çš„é™åˆ¶ã€‚ ä¸é¡ºåºç¨‹åºç›¸æ¯”ï¼Œå¹¶è¡Œç¨‹åºçš„æ‰§è¡Œé€Ÿåº¦é€šå¸¸å¯¹è¾“å…¥æ•°æ®ç‰¹å¾æ›´ä¸ºæ•æ„Ÿã€‚ æœ‰äº›åº”ç”¨ç¨‹åºå¯ä»¥å¹¶è¡ŒåŒ–ï¼Œè€Œä¸éœ€è¦è·¨ä¸åŒçº¿ç¨‹çš„åä½œ (embarrassingly parallel)ã€‚å…¶ä»–åº”ç”¨ç¨‹åºéœ€è¦ä½¿ç”¨åŒæ­¥æ“ä½œ (synchronization operations) ä½¿å¾—çº¿ç¨‹èƒ½ç›¸äº’åä½œã€‚ ä¾‹å¦‚ï¼Œå¯ä»¥é€šè¿‡å°†è®¡ç®—å•å…ƒçš„æ•°é‡ç¿»å€æ¥ä½¿ååé‡ç¿»å€ï¼Œä½†ä»£ä»·æ˜¯èŠ¯ç‰‡é¢ç§¯å’ŒåŠŸè€—ç¿»å€ã€‚ç„¶è€Œï¼Œå°†ç®—æœ¯å»¶è¿Ÿå‡å°‘ä¸€åŠå¯èƒ½éœ€è¦ç”µæµç¿»å€ï¼Œä»£ä»·æ˜¯ä½¿ç”¨çš„èŠ¯ç‰‡é¢ç§¯å¢åŠ ä¸€å€ä»¥ä¸Šï¼ŒåŠŸè€—å˜ä¸ºå››å€ã€‚\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/blogs/courselearning/pmpp/pmpp-ch1/","summary":"Personal notebook 1 of Programming Massively Parallel","title":"PMPP Learning-Chapter 1 Introduction"},{"content":"Pattern Match and Rewriting ä¸‹é¢ä»£ç ä¸­ MyModule åŒ…å«ä¸€ä¸ªå¸¦æœ‰ä¸¤ä¸ªé«˜çº§ç®—å­ relax.opmultiply å’Œ relax.op.add çš„ relax å‡½æ•°ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°è¿™ä¸¤ä¸ªç®—å­ï¼Œå¹¶å°†å…¶æ›¿æ¢ä¸ºå¯¹ relax.ewise_fma ç®—å­çš„è°ƒç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 @tvm.script.ir_module class MyModule: @R.function def main(x: R.Tensor((3, 4), \u0026#34;float32\u0026#34;), y: R.Tensor((3, 4), \u0026#34;float32\u0026#34;)): # type: ignore with R.dataflow(): cls = MyModule lv0 = relax.op.multiply(x, y) gv0 = relax.op.add(lv0, y) R.output(gv0) return gv0 æ¯ä¸ª IRModule éƒ½åŒ…å«ä¸€ç»„å‡½æ•°ï¼Œå‡½æ•°ä½“ç”±ä¸€ç»„ç§°ä¸ºæŠ½è±¡è¯­æ³•æ ‘ï¼ˆASTï¼‰çš„æ•°æ®ç»“æ„ç»„æˆã€‚ {% fold info @Abstract Syntax Tree %} æŠ½è±¡è¯­æ³•æ ‘ï¼ˆAbstract Syntax Treeï¼ŒASTï¼‰æ˜¯ä¸€ç§å¹¿æ³›ç”¨äºç¼–ç¨‹è¯­è¨€å¤„ç†çš„æ ‘çŠ¶æ•°æ®ç»“æ„ã€‚å®ƒæ˜¯ä¸€ç§å¯¹æºä»£ç è¯­æ³•ç»“æ„çš„æŠ½è±¡è¡¨ç¤ºï¼Œå»æ‰äº†ç¼–ç¨‹è¯­è¨€çš„å…·ä½“è¯­æ³•ç»†èŠ‚ï¼Œä½†ä¿ç•™äº†ä»£ç çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚ AST æ˜¯ä¸€æ£µæ ‘çŠ¶ç»“æ„ï¼Œå…¶èŠ‚ç‚¹è¡¨ç¤ºæºä»£ç ä¸­çš„è¯­æ³•ç»“æ„ã€‚ä¾‹å¦‚ï¼Œå˜é‡å£°æ˜ã€æ“ä½œç¬¦ã€å‡½æ•°è°ƒç”¨ã€æ§åˆ¶ç»“æ„ï¼ˆå¦‚æ¡ä»¶è¯­å¥ã€å¾ªç¯ï¼‰ç­‰ã€‚æ¯ä¸ªèŠ‚ç‚¹åŒ…å«ä¸ç›¸åº”è¯­æ³•ç»“æ„ç›¸å…³çš„ä¿¡æ¯ï¼Œå¦‚æ“ä½œç¬¦çš„ç±»å‹ã€å˜é‡çš„åç§°ã€å¸¸é‡çš„å€¼ç­‰ã€‚\n1 a = b + 1 è¿™ä¸ªä»£ç å¯ä»¥è½¬æ¢ä¸ºå¦‚ä¸‹å½¢å¼çš„ ASTï¼š\n1 2 3 4 5 Assignment â”œâ”€â”€ Identifier (a) â””â”€â”€ BinaryOperation â”œâ”€â”€ Identifier (b) â””â”€â”€ Constant (1) {% endfold %} æ¯ä¸ªå‡½æ•°éƒ½ç”±ä¸€ä¸ª relax.expr.Function èŠ‚ç‚¹è¡¨ç¤ºã€‚\n1 2 relax_func = MyModule[\u0026#34;main\u0026#34;] type(relax_func) # \u0026lt;class \u0026#39;tvm.relax.expr.Function\u0026#39;\u0026gt; è¯¥å‡½æ•°åŒ…å«ä¸€ç³»åˆ—å‚æ•°\n1 print(relax_func.params) # [x, y] è¯¥å‡½æ•°åŒ…å«ä¸€ä¸ªè¿”å›å€¼è¡¨è¾¾å¼ï¼Œå’Œå‡½æ•°ä¸­çš„ä¸€ç»„ binding blocks.\n1 2 func_body = relax_func.body print(type(func_body)) # \u0026lt;class \u0026#39;tvm.relax.expr.SeqExpr\u0026#39;\u0026gt; å‡½æ•°ä¸»ä½“ SeqExpr åŒ…å«ä¸€ç³»åˆ— binding.\n1 2 3 4 5 6 7 8 9 print(relax_func.body.blocks) \u0026#39;\u0026#39;\u0026#39; [x: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;) y: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;) with R.dataflow(): lv0: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;) = R.multiply(x, y) gv0: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;) = R.add(lv0, y) R.output(gv0)] \u0026#39;\u0026#39;\u0026#39; åœ¨ DataflowBlock ä¸­,æˆ‘ä»¬å¯ä»¥è®¿é—®å„ä¸ª binding ,åŒ…æ‹¬ value å’Œ var.\n1 2 3 4 5 6 dataflow_block = func_body.blocks[0] print(type(dataflow_block)) # \u0026lt;class \u0026#39;tvm.relax.expr.DataflowBlock\u0026#39;\u0026gt; binding = dataflow_block.bindings[0] print(type(binding)) # \u0026lt;class \u0026#39;tvm.relax.expr.VarBinding\u0026#39;\u0026gt; print(binding.var) # LHS of binding: lv0 print(binding.value) # # LHS of binding: R.multiply(x, y) Relax Function Data Structure\næ”¹å†™ç¨‹åºå¯ä»¥é€šè¿‡é€’å½’éå† MyModule çš„ AST ï¼Œå¹¶ç”Ÿæˆè½¬æ¢åçš„ AST æ¥å®ç°ã€‚ä½†æ˜¯æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢å¤–çš„å·¥å…·æ”¯æŒæ¥ç®€åŒ–æµç¨‹ã€‚ä¸‹é¢çš„ä»£ç éµå¾ªä¸€ç§ç§°ä¸º visitor pattern çš„è®¾è®¡æ¨¡å¼ï¼Œå…è®¸æˆ‘ä»¬è®¿é—®æ¯ä¸ª AST èŠ‚ç‚¹å¹¶å°†å®ƒä»¬é‡å†™ä¸ºè½¬æ¢åçš„ç‰ˆæœ¬ã€‚ä¸»è¦ç›®çš„æ˜¯å°†å½¢å¦‚ a * b + c çš„è¡¨è¾¾å¼è½¬æ¢ä¸º ewise_fma(a, b, c) çš„å½¢å¼ã€‚\nEwiseFMARewriter ç»§æ‰¿è‡ª relax.PyExprMutatorï¼Œè¿™æ˜¯ TVM ä¸­çš„ä¸€ä¸ªåŸºç±»ï¼Œç”¨äºéå†å’Œä¿®æ”¹è¡¨è¾¾å¼æ ‘ä¸­çš„èŠ‚ç‚¹ã€‚visit_call_ æ–¹æ³•è¢«é‡è½½æ¥å¤„ç† relax.Call èŠ‚ç‚¹ï¼Œè¢«é‡è½½æ¥å¤„ç† relax.Call èŠ‚ç‚¹ã€‚\nå¦‚æœå½“å‰èŠ‚ç‚¹ä¸æ˜¯åŠ æ³•æ“ä½œï¼Œç›´æ¥è¿”å›è¯¥èŠ‚ç‚¹ï¼Œè¡¨ç¤ºå¯¹è¯¥èŠ‚ç‚¹ä¸è¿›è¡Œä»»ä½•ä¿®æ”¹ã€‚å¦‚æœåŠ æ³•çš„ç¬¬ä¸€ä¸ªæ“ä½œæ•°ä¸æ˜¯ä¹˜æ³•æ“ä½œï¼Œæˆ–è€…ç¬¬ä¸€ä¸ªæ“ä½œæ•°çš„ç»‘å®šå€¼ä¸æ˜¯ä¸€ä¸ª relax.Call èŠ‚ç‚¹ï¼Œç›´æ¥è¿”å›è¯¥åŠ æ³•èŠ‚ç‚¹ã€‚å¦‚æœåŒ¹é…æˆåŠŸï¼Œæ„é€ ä¸€ä¸ªæ–°çš„ ewise_fma æ“ä½œèŠ‚ç‚¹ï¼Œå°†ä¹˜æ³•çš„ä¸¤ä¸ªæ“ä½œæ•°å’ŒåŠ æ³•çš„ç¬¬äºŒä¸ªæ“ä½œæ•°ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @relax.expr_functor.mutator class EwiseFMARewriter(relax.PyExprMutator): def visit_call_(self, op: relax.Call): # Reloaded call = self.visit_expr_post_order(op) add_op = tvm.ir.Op.get(\u0026#34;relax.add\u0026#34;) multiply_op = tvm.ir.Op.get(\u0026#34;relax.multiply\u0026#34;) ewise_fma_op = tvm.ir.Op.get(\u0026#34;relax.ewise_fma\u0026#34;) if call.op != add_op: return call value = self.lookup_binding(call.args[0]) if not isinstance(value, relax.Call) or value.op != multiply_op: return call fma_call = relax.Call( ewise_fma_op, [value.args[0], value.args[1], call.args[1]], None, None ) return fma_call updated_fn = EwiseFMARewriter().visit_expr(MyModule[\u0026#34;main\u0026#34;]) updated_fn.show() #----------------------------- @R.function def main(x: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;), y: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;): with R.dataflow(): lv0: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;) = R.multiply(x, y) gv0: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;) = R.ewise_fma(x, y, y) R.output(gv0) return gv0 ä½¿ç”¨ remove_all_unused æ¥åˆ é™¤ä»£ç ä¸­æ²¡æœ‰ç”¨åˆ°çš„ DataflowBlocks å’Œ VarBindings.\n1 2 3 4 5 6 7 8 9 relax.analysis.remove_all_unused(updated_fn).show() #------------------------------------------- @R.function def main(x: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;), y: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;): with R.dataflow(): gv0: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;) = R.ewise_fma(x, y, y) R.output(gv0) return gv0 Fuse Linear and ReLU ä¸‹é¢åœ¨ç«¯åˆ°ç«¯æ¨¡å‹ä¸Šè¿›è¡Œè®¡ç®—å›¾çš„æ”¹å†™ã€‚é‡‡ç”¨çš„è¿˜æ˜¯ä¹‹å‰ä½¿ç”¨çš„ FashionMNIST MLP æ¨¡å‹ã€‚ä¸ºäº†ç®€åŒ–è¿‡ç¨‹ï¼Œç›´æ¥ä½¿ç”¨é«˜çº§è¿ç®—ç¬¦æ„å»ºæ¨¡å‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 import pickle as pkl mlp_params = pkl.load(open(\u0026#34;fasionmnist_mlp_params.pkl\u0026#34;, \u0026#34;rb\u0026#34;)) def create_model(): bb = relax.BlockBuilder() x = relax.Var(\u0026#34;x\u0026#34;, relax.TensorStructInfo((1, 784), \u0026#34;float32\u0026#34;)) w0 = relax.const(mlp_params[\u0026#34;w0\u0026#34;], \u0026#34;float32\u0026#34;) b0 = relax.const(mlp_params[\u0026#34;b0\u0026#34;], \u0026#34;float32\u0026#34;) w1 = relax.const(mlp_params[\u0026#34;w1\u0026#34;], \u0026#34;float32\u0026#34;) b1 = relax.const(mlp_params[\u0026#34;b1\u0026#34;], \u0026#34;float32\u0026#34;) with bb.function(\u0026#34;main\u0026#34;, [x]): with bb.dataflow(): lv0 = bb.emit(relax.op.matmul(x, relax.op.permute_dims(w0))) lv1 = bb.emit(relax.op.add(lv0, b0)) lv2 = bb.emit(relax.op.nn.relu(lv1)) lv3 = bb.emit(relax.op.matmul(lv2, relax.op.permute_dims(w1))) lv4 = bb.emit(relax.op.add(lv3, b1)) gv = bb.emit_output(lv4) bb.emit_func_output(gv) return bb.get() MLPModel = create_model() MLPModel.show() #------------------------------- @I.ir_module class Module: @R.function def main(x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): with R.dataflow(): lv: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][0], axes=None) lv1: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.matmul(x, lv, out_dtype=\u0026#34;void\u0026#34;) lv2: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.add(lv1, metadata[\u0026#34;relax.expr.Constant\u0026#34;][1]) lv3: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.nn.relu(lv2) lv4: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][2], axes=None) lv5: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.matmul(lv3, lv4, out_dtype=\u0026#34;void\u0026#34;) lv6: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.add(lv5, metadata[\u0026#34;relax.expr.Constant\u0026#34;][3]) gv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = lv6 R.output(gv) return gv æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¯¹ matmul å’Œ add è¿›è¡Œç®—å­èåˆã€‚å…·ä½“å®ç°æ­¥éª¤ä¸ FMA ç›¸ä¼¼ï¼š\nè¯†åˆ« matmul å’Œ add ç®—å­ã€‚ ç”Ÿæˆå¦ä¸€ä¸ªè°ƒç”¨ matmul å’Œ add ç®—å­çš„å­å‡½æ•°ã€‚ å°† matmul å’Œ add æ›¿æ¢ä¸ºèåˆåçš„å­å‡½æ•°ã€‚ ä¸‹é¢ä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º DenseAddFusor çš„ç±»ï¼Œç”¨äºåœ¨ TVM çš„ Relax æ¡†æ¶ä¸­å°†ç‰¹å®šçš„çŸ©é˜µä¹˜æ³•å’ŒåŠ æ³•æ“ä½œæ¨¡å¼èåˆæˆä¸€ä¸ªé«˜æ•ˆçš„åŸè¯­å‡½æ•°ã€‚\ntransform æ–¹æ³•éå†æ¨¡å—ä¸­çš„æ¯ä¸ªå‡½æ•°ã€‚å¦‚æœå‡½æ•°å·²ç»è¢«æ ‡è®°ä¸º primitiveï¼ˆå³å·²ç»è¢«èåˆè¿‡ï¼‰ï¼Œåˆ™è·³è¿‡ã€‚å¯¹æ¯ä¸ªå‡½æ•°åº”ç”¨ visit_expr ä»¥è¿›è¡Œæ¨¡å¼åŒ¹é…å’Œæ½œåœ¨çš„èåˆæ“ä½œï¼Œç„¶ååˆ é™¤æœªä½¿ç”¨çš„å˜é‡ï¼Œå¹¶æ›´æ–°å‡½æ•°ã€‚æœ€åï¼Œè¿”å›æ›´æ–°åçš„ IRModuleã€‚ visit_call_ æ–¹æ³•ç”¨äºè®¿é—® relax.Call èŠ‚ç‚¹ï¼ˆè¡¨ç¤ºæ“ä½œç¬¦è°ƒç”¨ï¼‰ã€‚å®ƒé¦–å…ˆé€’å½’å¤„ç†å­è¡¨è¾¾å¼ï¼Œç„¶åå°è¯•åŒ¹é…ç‰¹å®šæ¨¡å¼ã€‚match_call æ˜¯ä¸€ä¸ªå†…éƒ¨å‡½æ•°ï¼Œç”¨äºæ£€æŸ¥æŸä¸ªèŠ‚ç‚¹æ˜¯å¦æ˜¯ç‰¹å®šæ“ä½œç¬¦çš„è°ƒç”¨ã€‚å¦‚æœå½“å‰èŠ‚ç‚¹ä¸æ˜¯ add æ“ä½œï¼Œæˆ–è€… add æ“ä½œçš„ç¬¬ä¸€ä¸ªå‚æ•°ä¸æ˜¯ matmulï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰æ“ä½œï¼Œåˆ™ç›´æ¥è¿”å›å½“å‰èŠ‚ç‚¹ï¼Œä¸è¿›è¡Œä¿®æ”¹ã€‚å¦‚æœåŒ¹é…æˆåŠŸï¼Œåˆ™æå– matmul çš„ä¸¤ä¸ªæ“ä½œæ•° x å’Œ w ä»¥åŠ add çš„ç¬¬äºŒä¸ªæ“ä½œæ•° bï¼Œå‡†å¤‡è¿›è¡Œèåˆã€‚ é€šè¿‡ relax.BlockBuilderå®šä¹‰ä¸€ä¸ªåä¸º fused_dense_addXæ–°çš„èåˆå‡½æ•°ï¼Œå…¶ä¸­ X æ˜¯ä¸€ä¸ªé€’å¢çš„è®¡æ•°å™¨ã€‚è¯¥å‡½æ•°æ¥æ”¶ xã€wã€b ä½œä¸ºå‚æ•°ï¼Œé¦–å…ˆè¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œç„¶åå°†ç»“æœä¸ b ç›¸åŠ ï¼Œæœ€ç»ˆè¾“å‡ºç»“æœã€‚ ç»™æ–°ç”Ÿæˆçš„èåˆå‡½æ•°æ·»åŠ ä¸€ä¸ªå±æ€§ Primitiveï¼Œæ ‡è®°ä¸ºå·²ç»èåˆçš„åŸè¯­å‡½æ•°ã€‚é€šè¿‡ builder_ æ›´æ–°å…¨å±€æ¨¡å—ï¼Œå°†èåˆå‡½æ•°æ·»åŠ åˆ°æ¨¡å—ä¸­ (GlobalVar ç”¨äºæŒ‡ä»£å­˜å‚¨åœ¨ IRModule ä¸­çš„å…¨å±€å‡½æ•°)ã€‚è¿”å›ä¸€ä¸ªæ–°çš„ relax.Call èŠ‚ç‚¹ï¼Œè¯¥èŠ‚ç‚¹è°ƒç”¨ç”Ÿæˆçš„èåˆå‡½æ•°ï¼Œå¹¶ä¼ é€’åŸå§‹çš„è¾“å…¥å‚æ•° xã€wã€bã€‚ VisitExpr TVM ä¸­çš„ VisitExpr æµç¨‹æ˜¯ä¸€ç§é€’å½’éå† IR èŠ‚ç‚¹çš„æœºåˆ¶,å®ƒæ˜¯å®ç°å„ç§ IR è½¬æ¢å’Œä¼˜åŒ–çš„åŸºç¡€ã€‚å…·ä½“æµç¨‹å¦‚ä¸‹:\né¦–å…ˆåˆ›å»ºä¸€ä¸ª ExprVisitor æˆ– ExprMutator çš„å­ç±»å®ä¾‹,è¿™ä¸ªå­ç±»ä¼šå®ç°å„ç§å…·ä½“çš„è®¿é—®é€»è¾‘ã€‚ è°ƒç”¨ visit_expr æ–¹æ³•,ä¼ å…¥æ ¹ IR èŠ‚ç‚¹ã€‚è¿™ä¸ªæ–¹æ³•ä¼šè§¦å‘æ•´ä¸ªéå†è¿‡ç¨‹çš„å¯åŠ¨ã€‚ visit_expr æ–¹æ³•ä¼šé¦–å…ˆè°ƒç”¨ visit_expr_post_order æ–¹æ³•,è¿™ä¸ªæ–¹æ³•ä¼šä»¥æ·±åº¦ä¼˜å…ˆçš„æ–¹å¼éå†æ‰€æœ‰å­èŠ‚ç‚¹ã€‚ å¯¹äºæ¯ä¸ªå­èŠ‚ç‚¹,visit_expr_post_order ä¼šæ ¹æ®èŠ‚ç‚¹çš„å…·ä½“ç±»å‹,è°ƒç”¨ç›¸åº”çš„ visit_XXX_ æ–¹æ³•ã€‚è¿™äº› visit_XXX_ æ–¹æ³•æ˜¯ç”±è®¿é—®å™¨å­ç±»å®ç°çš„,åŒ…å«äº†å…·ä½“çš„è®¿é—®é€»è¾‘ã€‚ åœ¨ visit_XXX_ æ–¹æ³•ä¸­,å¦‚æœé‡åˆ°å­èŠ‚ç‚¹,ä¼šé€’å½’è°ƒç”¨ visit_expr_post_order æ–¹æ³•ç»§ç»­éå†ã€‚ å½“éå†å®Œæ•´ä¸ª IR æ ‘å,visit_expr æ–¹æ³•ä¼šè¿”å›æœ€ç»ˆçš„ç»“æœ,å³ç»è¿‡è½¬æ¢å’Œä¿®æ”¹çš„ IR èŠ‚ç‚¹ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @relax.expr_functor.mutator class DenseAddFusor(relax.PyExprMutator): def __init__(self, mod: IRModule) -\u0026gt; None: super().__init__(mod) self.mod_ = mod # cache pre-defined ops self.add_op = tvm.ir.Op.get(\u0026#34;relax.add\u0026#34;) self.dense_op = tvm.ir.Op.get(\u0026#34;relax.matmul\u0026#34;) self.counter = 0 def transform(self) -\u0026gt; IRModule: for global_var, func in self.mod_.functions_items(): if not isinstance(func, relax.Function): continue # avoid already fused primitive function if \u0026#34;Primitive\u0026#34; in func.attrs.keys() and func.attrs[\u0026#34;primitive\u0026#34;] != 0: continue updated_fn = self.visit_expr(func) updated_fn = relax.analysis.remove_all_unused(updated_fn) self.builder_.update_func(global_var, updated_fn) return self.builder_.get() def visit_call_(self, op: relax.Call): call = self.visit_expr_post_order(op) def match_call(node, op): if not isinstance(node, relax.Call): return False return node.op == op # pattern match dense =\u0026gt; add if not match_call(call, self.add_op): return call value = self.lookup_binding(call.args[0]) if value is None: return call if not match_call(value, self.dense_op): return call x = value.args[0] w = value.args[1] b = call.args[1] # construct a new fused primitive function param_x = relax.Var(\u0026#34;x\u0026#34;, relax.TensorStructInfo(x.struct_info.shape, x.struct_info.dtype)) param_w = relax.Var(\u0026#34;w\u0026#34;, relax.TensorStructInfo(w.struct_info.shape, w.struct_info.dtype)) param_b = relax.Var(\u0026#34;b\u0026#34;, relax.TensorStructInfo(b.struct_info.shape, b.struct_info.dtype)) bb = relax.BlockBuilder() fn_name = \u0026#34;fused_dense_add%d\u0026#34; % (self.counter) self.counter += 1 with bb.function(fn_name, [param_x, param_w, param_b]): with bb.dataflow(): lv0 = bb.emit(relax.op.matmul(param_x, param_w)) gv0 = bb.emit_output(relax.op.add(lv0, param_b)) bb.emit_func_output(gv0) # add primitive attribute to the fused functions fused_fn = bb.get()[fn_name].with_attr(\u0026#34;Primitive\u0026#34;, 1) global_var = self.builder_.add_func(fused_fn, fn_name) # construct call into the fused function return relax.Call(global_var, [x, w, b], None, None) @tvm.ir.transform.module_pass(opt_level=2, name=\u0026#34;DenseAddFuse\u0026#34;) class FuseDenseAddPass: \u0026#39;\u0026#39;\u0026#39;The wrapper for the LowerTensorIR pass.\u0026#39;\u0026#39;\u0026#39; def transform_module(self, mod, ctx): return DenseAddFusor(mod).transform() MLPFused = FuseDenseAddPass()(MLPModel) MLPFused.show() èåˆåçš„ MLPFused å¯¹åº”çš„ TensorIR å¦‚ä¸‹\nTVM æ¡†æ¶ä¸­ä½¿ç”¨ module_pass æ¥ç®¡ç†å„ç§ä¼˜åŒ–æ“ä½œã€‚è¿™ç§æœºåˆ¶å…è®¸å°†ä¸åŒçš„ä¼˜åŒ–æ“ä½œï¼ˆå¦‚å›¾ä¼˜åŒ–ã€ä»£ç ç”Ÿæˆã€ç®—å­èåˆç­‰ï¼‰ç»„ç»‡æˆä¸€ä¸ªæµæ°´çº¿ï¼ˆpipelineï¼‰ï¼ŒæŒ‰é¡ºåºå¯¹æ¨¡å—è¿›è¡Œå¤„ç†ã€‚å°† DenseAddFusor å°è£…ä¸ºä¸€ä¸ª module_passï¼Œä½¿å¾—å®ƒèƒ½å¤Ÿè½»æ¾é›†æˆåˆ° TVM çš„ Pass æµæ°´çº¿ä¸­ï¼Œä¸å…¶ä»– Pass ä¸€èµ·å·¥ä½œï¼Œä»è€Œä¿è¯ä¼˜åŒ–è¿‡ç¨‹çš„æ•´ä½“æ€§å’Œä¸€è‡´æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @I.ir_module class Module: @R.function def fused_dense_add0(x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;), w: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;), b: R.Tensor((128,), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;): R.func_attr({\u0026#34;Primitive\u0026#34;: 1}) with R.dataflow(): lv: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.matmul(x, w, out_dtype=\u0026#34;void\u0026#34;) gv: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.add(lv, b) R.output(gv) return gv @R.function def fused_dense_add1(x: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;), w: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;), b: R.Tensor((10,), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): R.func_attr({\u0026#34;Primitive\u0026#34;: 1}) with R.dataflow(): lv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.matmul(x, w, out_dtype=\u0026#34;void\u0026#34;) gv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.add(lv, b) R.output(gv) return gv @R.function def main(x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][0], axes=None) lv2: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = cls.fused_dense_add0(x, lv, metadata[\u0026#34;relax.expr.Constant\u0026#34;][1]) lv3: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.nn.relu(lv2) lv4: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][2], axes=None) lv6: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = cls.fused_dense_add1(lv3, lv4, metadata[\u0026#34;relax.expr.Constant\u0026#34;][3]) gv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = lv6 R.output(gv) return gv ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸¤ä¸ªå‰ç¼€ä¸º fuse_matmul_add çš„å­å‡½æ•°ã€‚ è¿™äº›å­å‡½æ•°åŒ…å«æœ‰èåˆåç®—å­çš„è®¡ç®—ä¿¡æ¯ã€‚ è¿™ç§é‡å†™çš„æ›¿ä»£æ–¹æ³•æ˜¯ç®€å•åœ°ä¸ºèåˆç®—å­åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„åŸè¯­ç®—å­ï¼ˆå¦‚ewise_fmaï¼‰ã€‚ ä½†æ˜¯ï¼Œå½“æˆ‘ä»¬å°è¯•èåˆæ›´å¤šç®—å­æ—¶ï¼Œå¯èƒ½å­˜åœ¨æŒ‡æ•°çº§æ•°é‡çš„ç»„åˆã€‚ å°†èåˆæ“ä½œåˆ†ç»„åœ¨ä¸€èµ·çš„å­å‡½æ•°ä¸ºåç»­çš„ pass ä¿ç•™äº†åŸå§‹ä¿¡æ¯ï¼Œè¿›è€Œä¾¿äºåˆ†æï¼Œæ— éœ€ä¸ºæ¯ä¸ªèåˆ pattern å¼•å…¥ä¸“ç”¨çš„é«˜çº§ç®—å­ã€‚\nMap to TensorIR Calls ä¸ºäº†è¿›ä¸€æ­¥è¿›è¡Œåº•å±‚ä¼˜åŒ–å’Œä»£ç ç”Ÿæˆï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›é«˜çº§åŸè¯­è¿ç®—è½¬æ¢ä¸ºç›¸åº”çš„ TensorIR å‡½æ•°ã€‚ä¸‹é¢ä»£ç ä¸»è¦åŠŸèƒ½æ˜¯å°† Relax è¡¨è¾¾å¼æ ‘ä¸­çš„é«˜å±‚æ¬¡ç®—å­ï¼ˆ matmulã€addã€reluï¼‰è½¬æ¢ä¸ºå¯¹åº”çš„ TensorIR è¡¨ç¤ºï¼Œä»è€Œä½¿å¾—è¿™äº›ç®—å­èƒ½å¤Ÿæ˜ å°„åˆ°åº•å±‚çš„å¼ é‡æ“ä½œï¼ˆtensor operationsï¼‰ã€‚è¿™ç§è½¬æ¢ä½¿å¾—ç¼–è¯‘å™¨å¯ä»¥ç”Ÿæˆæ›´æ¥è¿‘ç¡¬ä»¶çš„é«˜æ•ˆä»£ç ï¼Œå¹¶ä¸ºåç»­çš„ä»£ç ä¼˜åŒ–å’Œç”Ÿæˆåšå¥½å‡†å¤‡ã€‚\nè°ƒç”¨ transform æ–¹æ³•ä¼šéå† mod_ ä¸­çš„æ‰€æœ‰å‡½æ•°: å¯¹äºæ¯ä¸ªå‡½æ•°,é¦–å…ˆè°ƒç”¨ visit_expr æ–¹æ³•,è¿™ä¼šè§¦å‘ VisitExpr æµç¨‹ visit_expr æ–¹æ³•ä¼šè°ƒç”¨ visit_expr_post_orderæ–¹æ³•è¿›è¡Œæ·±åº¦ä¼˜å…ˆéå† åœ¨éå†è¿‡ç¨‹ä¸­å¯¹äºæ¯ä¸ª relax.Call èŠ‚ç‚¹,ä¼šè°ƒç”¨ visit_call_ æ–¹æ³• visit_call_ æ–¹æ³•ä¼šæ£€æŸ¥ op_map å­—å…¸,å¦‚æœå½“å‰æ“ä½œåœ¨å­—å…¸ä¸­,åˆ™è°ƒç”¨å¯¹åº”çš„è½¬æ¢å‡½æ•°( map_dense, map_add, map_relu) è¿™äº›è½¬æ¢å‡½æ•°ä¼šä½¿ç”¨ bb.call_te æ–¹æ³•,å°† Relax IR æ“ä½œè½¬æ¢ä¸º TensorIR æ“ä½œ åœ¨ transform æ–¹æ³•çš„æœ€å,ä¼šè°ƒç”¨ builder_.get() æ–¹æ³•,è¿”å›è½¬æ¢åçš„æ–° IR æ¨¡å—ã€‚ æœ€å LowerToTensorIRPass ç±»å°† LowerToTensorIR è½¬æ¢å™¨åŒ…è£…æˆä¸€ä¸ªå¯æ³¨å†Œåˆ° TVM ä¼˜åŒ– pipeline çš„ pass. module_pass çš„ opt_level å‚æ•°å†³å®šäº†ä¼˜åŒ– pass åœ¨ä¼˜åŒ– pipeline ä¸­çš„æ‰§è¡Œé¡ºåºã€‚ TVM çš„ä¼˜åŒ– pipeline æ˜¯ç”±å¤šä¸ª module_pass ç»„æˆçš„,æ¯ä¸ª module_pass éƒ½æœ‰ä¸€ä¸ª opt_level å±æ€§æ¥æŒ‡å®šå®ƒçš„ä¼˜åŒ–çº§åˆ«ã€‚\nå½“ TVM è¿›è¡Œä¼˜åŒ–æ—¶,å®ƒä¼šæŒ‰ç…§ opt_level ä»ä½åˆ°é«˜çš„é¡ºåºä¾æ¬¡åº”ç”¨å„ä¸ª module_pass. opt_level=0 çš„ pass ä¼šé¦–å…ˆè¢«æ‰§è¡Œã€‚è¿™äº› pass é€šå¸¸ä¼šæ‰§è¡Œä¸€äº›åŸºç¡€çš„ã€å¿…è¦çš„è½¬æ¢,ä¸ºåç»­çš„ä¼˜åŒ–å¥ å®šåŸºç¡€ã€‚ éšåä¼šæ‰§è¡Œ opt_level=1 çš„ pass,è¿™äº› pass å¯èƒ½ä¼šæ‰§è¡Œä¸€äº›æ›´å¤æ‚çš„ä¼˜åŒ–,æ¯”å¦‚å¾ªç¯ä¼˜åŒ–ã€å†…å­˜è®¿é—®ä¼˜åŒ–ç­‰ã€‚ä¾æ­¤ç±»æ¨,opt_level è¶Šé«˜çš„ pass ä¼šåœ¨ä¼˜åŒ– pipeline çš„åæœŸæ‰§è¡Œ,å®ƒä»¬æ‰§è¡Œçš„ä¼˜åŒ–é€šå¸¸ä¹Ÿè¶Šå¤æ‚å’Œæ·±å…¥ã€‚\né€šè¿‡åˆç†åœ°è®¾ç½® opt_level,å¼€å‘è€…å¯ä»¥æ§åˆ¶å„ä¸ªä¼˜åŒ– pass çš„æ‰§è¡Œé¡ºåº,ä»è€Œæ„å»ºå‡ºé’ˆå¯¹æ€§å¼ºã€æ€§èƒ½ä¼˜ç§€çš„ä¼˜åŒ– pipeline ã€‚è¿™ç§çµæ´»çš„ä¼˜åŒ–ç®¡ç†æœºåˆ¶æ˜¯ TVM çš„ä¸€å¤§ç‰¹ç‚¹ã€‚\nå¯¹äº LowerToTensorIRPass,å®ƒçš„ opt_level è¢«è®¾ç½®ä¸º 0, è¯´æ˜å®ƒæ˜¯ä¸€ä¸ªåŸºç¡€çš„ pass, ä¸»è¦ç”¨äºå°†é«˜çº§çš„ Relax IR æ“ä½œè½¬æ¢ä¸ºåº•å±‚çš„ TensorIR æ“ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @relax.expr_functor.mutator class LowerToTensorIR(relax.PyExprMutator): def __init__(self, mod: IRModule, op_map: dict) -\u0026gt; None: super().__init__(mod) self.mod_ = mod self.op_map = { tvm.ir.Op.get(k): v for k, v in op_map.items() } def visit_call_(self, op: relax.Call): call = self.visit_expr_post_order(op) if call.op in self.op_map: return self.op_map[call.op](self.builder_, call) return call def transform(self) -\u0026gt; IRModule: for global_val, func in self.mod_.functions_items(): if not isinstance(func, relax.Function): continue updated_fn = self.visit_expr(func) self.builder_.update_func(global_val, updated_fn) return self.builder_.get() def map_dense(bb, call): x, w = call.args return bb.call_te(topi.nn.matmul, x, w) def map_add(bb, call): a, b = call.args return bb.call_te(topi.add, a, b) def map_relu(bb, call): return bb.call_te(topi.nn.relu, call.args[0]) op_map = { \u0026#34;relax.matmul\u0026#34;: map_dense, \u0026#34;relax.add\u0026#34;: map_add, \u0026#34;relax.nn.relu\u0026#34;: map_relu } @tvm.ir.transform.module_pass(opt_level=0, name=\u0026#34;LowerToTensorIR\u0026#34;) class LowerToTensorIRPass: \u0026#39;\u0026#39;\u0026#39;The wrapper for the LowerTensorIR pass.\u0026#39;\u0026#39;\u0026#39; def transform_module(self, mod, ctx): return LowerToTensorIR(mod, op_map).transform() MLPModelTIR = LowerToTensorIRPass()(MLPFused) MLPModelTIR.show() èåˆåçš„ TensorIR å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 @I.ir_module class Module: @T.prim_func(private=True) def add(lv: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;), b: T.Buffer((T.int64(128),), \u0026#34;float32\u0026#34;), T_add: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for ax0, ax1 in T.grid(T.int64(1), T.int64(128)): with T.block(\u0026#34;T_add\u0026#34;): v_ax0, v_ax1 = T.axis.remap(\u0026#34;SS\u0026#34;, [ax0, ax1]) T.reads(lv[v_ax0, v_ax1], b[v_ax1]) T.writes(T_add[v_ax0, v_ax1]) T_add[v_ax0, v_ax1] = lv[v_ax0, v_ax1] + b[v_ax1] @T.prim_func(private=True) def add1(lv: T.Buffer((T.int64(1), T.int64(10)), \u0026#34;float32\u0026#34;), b: T.Buffer((T.int64(10),), \u0026#34;float32\u0026#34;), T_add: T.Buffer((T.int64(1), T.int64(10)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for ax0, ax1 in T.grid(T.int64(1), T.int64(10)): with T.block(\u0026#34;T_add\u0026#34;): v_ax0, v_ax1 = T.axis.remap(\u0026#34;SS\u0026#34;, [ax0, ax1]) T.reads(lv[v_ax0, v_ax1], b[v_ax1]) T.writes(T_add[v_ax0, v_ax1]) T_add[v_ax0, v_ax1] = lv[v_ax0, v_ax1] + b[v_ax1] @T.prim_func(private=True) def matmul(x: T.Buffer((T.int64(1), T.int64(784)), \u0026#34;float32\u0026#34;), w: T.Buffer((T.int64(784), T.int64(128)), \u0026#34;float32\u0026#34;), T_matmul_NN: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;layout_free_buffers\u0026#34;: [1], \u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1, k in T.grid(T.int64(1), T.int64(128), T.int64(784)): with T.block(\u0026#34;T_matmul_NN\u0026#34;): v_i0, v_i1, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, i1, k]) T.reads(x[v_i0, v_k], w[v_k, v_i1]) T.writes(T_matmul_NN[v_i0, v_i1]) with T.init(): T_matmul_NN[v_i0, v_i1] = T.float32(0.0) T_matmul_NN[v_i0, v_i1] = T_matmul_NN[v_i0, v_i1] + x[v_i0, v_k] * w[v_k, v_i1] @T.prim_func(private=True) def matmul1(x: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;), w: T.Buffer((T.int64(128), T.int64(10)), \u0026#34;float32\u0026#34;), T_matmul_NN: T.Buffer((T.int64(1), T.int64(10)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;layout_free_buffers\u0026#34;: [1], \u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1, k in T.grid(T.int64(1), T.int64(10), T.int64(128)): with T.block(\u0026#34;T_matmul_NN\u0026#34;): v_i0, v_i1, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, i1, k]) T.reads(x[v_i0, v_k], w[v_k, v_i1]) T.writes(T_matmul_NN[v_i0, v_i1]) with T.init(): T_matmul_NN[v_i0, v_i1] = T.float32(0.0) T_matmul_NN[v_i0, v_i1] = T_matmul_NN[v_i0, v_i1] + x[v_i0, v_k] * w[v_k, v_i1] @T.prim_func(private=True) def relu(lv2: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1 in T.grid(T.int64(1), T.int64(128)): with T.block(\u0026#34;compute\u0026#34;): v_i0, v_i1 = T.axis.remap(\u0026#34;SS\u0026#34;, [i0, i1]) T.reads(lv2[v_i0, v_i1]) T.writes(compute[v_i0, v_i1]) compute[v_i0, v_i1] = T.max(lv2[v_i0, v_i1], T.float32(0.0)) @R.function def fused_dense_add0(x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;), w: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;), b: R.Tensor((128,), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;): R.func_attr({\u0026#34;Primitive\u0026#34;: 1}) cls = Module with R.dataflow(): lv = R.call_tir(cls.matmul, (x, w), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) gv = R.call_tir(cls.add, (lv, b), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) R.output(gv) return gv @R.function def fused_dense_add1(x: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;), w: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;), b: R.Tensor((10,), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): R.func_attr({\u0026#34;Primitive\u0026#34;: 1}) cls = Module with R.dataflow(): lv = R.call_tir(cls.matmul1, (x, w), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) gv = R.call_tir(cls.add1, (lv, b), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) R.output(gv) return gv @R.function def main(x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][0], axes=None) lv2: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = cls.fused_dense_add0(x, lv, metadata[\u0026#34;relax.expr.Constant\u0026#34;][1]) lv3 = R.call_tir(cls.relu, (lv2,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv4: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][2], axes=None) lv6: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = cls.fused_dense_add1(lv3, lv4, metadata[\u0026#34;relax.expr.Constant\u0026#34;][3]) gv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = lv6 R.output(gv) return gv åœ¨ä¸Šé¢çš„ IRModule ä¸­ fused_matmul_add0 å’Œ fused_matmul_add1 ä»ç„¶æ˜¯ relax å‡½æ•°ï¼Œå®ƒä»¬è°ƒç”¨ç›¸åº”çš„ TensorIR matmul å’Œ add å‡½æ•°ã€‚ æˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬å˜æˆä¸€ä¸ªå•ä¸€çš„ TensorIR å‡½æ•°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 MLPModelFinal = relax.transform.FuseTIR()(MLPModelTIR) MLPModelFinal.show() #----------------------- @I.ir_module class Module: @T.prim_func(private=True) def fused_dense_add0(x: T.Buffer((T.int64(1), T.int64(784)), \u0026#34;float32\u0026#34;), w: T.Buffer((T.int64(784), T.int64(128)), \u0026#34;float32\u0026#34;), b: T.Buffer((T.int64(128),), \u0026#34;float32\u0026#34;), T_add_intermediate: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): T_matmul_NN_intermediate = T.alloc_buffer((T.int64(1), T.int64(128))) for i0, i1, k in T.grid(T.int64(1), T.int64(128), T.int64(784)): with T.block(\u0026#34;T_matmul_NN\u0026#34;): v_i0, v_i1, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, i1, k]) T.reads(x[v_i0, v_k], w[v_k, v_i1]) T.writes(T_matmul_NN_intermediate[v_i0, v_i1]) with T.init(): T_matmul_NN_intermediate[v_i0, v_i1] = T.float32(0.0) T_matmul_NN_intermediate[v_i0, v_i1] = T_matmul_NN_intermediate[v_i0, v_i1] + x[v_i0, v_k] * w[v_k, v_i1] for ax0, ax1 in T.grid(T.int64(1), T.int64(128)): with T.block(\u0026#34;T_add\u0026#34;): v_ax0, v_ax1 = T.axis.remap(\u0026#34;SS\u0026#34;, [ax0, ax1]) T.reads(T_matmul_NN_intermediate[v_ax0, v_ax1], b[v_ax1]) T.writes(T_add_intermediate[v_ax0, v_ax1]) T_add_intermediate[v_ax0, v_ax1] = T_matmul_NN_intermediate[v_ax0, v_ax1] + b[v_ax1] @T.prim_func(private=True) def fused_dense_add1(x: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;), w: T.Buffer((T.int64(128), T.int64(10)), \u0026#34;float32\u0026#34;), b: T.Buffer((T.int64(10),), \u0026#34;float32\u0026#34;), T_add_intermediate: T.Buffer((T.int64(1), T.int64(10)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): T_matmul_NN_intermediate = T.alloc_buffer((T.int64(1), T.int64(10))) for i0, i1, k in T.grid(T.int64(1), T.int64(10), T.int64(128)): with T.block(\u0026#34;T_matmul_NN\u0026#34;): v_i0, v_i1, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, i1, k]) T.reads(x[v_i0, v_k], w[v_k, v_i1]) T.writes(T_matmul_NN_intermediate[v_i0, v_i1]) with T.init(): T_matmul_NN_intermediate[v_i0, v_i1] = T.float32(0.0) T_matmul_NN_intermediate[v_i0, v_i1] = T_matmul_NN_intermediate[v_i0, v_i1] + x[v_i0, v_k] * w[v_k, v_i1] for ax0, ax1 in T.grid(T.int64(1), T.int64(10)): with T.block(\u0026#34;T_add\u0026#34;): v_ax0, v_ax1 = T.axis.remap(\u0026#34;SS\u0026#34;, [ax0, ax1]) T.reads(T_matmul_NN_intermediate[v_ax0, v_ax1], b[v_ax1]) T.writes(T_add_intermediate[v_ax0, v_ax1]) T_add_intermediate[v_ax0, v_ax1] = T_matmul_NN_intermediate[v_ax0, v_ax1] + b[v_ax1] @T.prim_func(private=True) def relu(lv2: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1 in T.grid(T.int64(1), T.int64(128)): with T.block(\u0026#34;compute\u0026#34;): v_i0, v_i1 = T.axis.remap(\u0026#34;SS\u0026#34;, [i0, i1]) T.reads(lv2[v_i0, v_i1]) T.writes(compute[v_i0, v_i1]) compute[v_i0, v_i1] = T.max(lv2[v_i0, v_i1], T.float32(0.0)) @R.function def main(x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][0], axes=None) lv2 = R.call_tir(cls.fused_dense_add0, (x, lv, metadata[\u0026#34;relax.expr.Constant\u0026#34;][1]), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv3 = R.call_tir(cls.relu, (lv2,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv4: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(metadata[\u0026#34;relax.expr.Constant\u0026#34;][2], axes=None) gv = R.call_tir(cls.fused_dense_add1, (lv3, lv4, metadata[\u0026#34;relax.expr.Constant\u0026#34;][3]), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) R.output(gv) return gv ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch8/","summary":"Personal notebook 7.","title":"TVM Learning (10)-Computational Graph Optimization"},{"content":"Key Elements of Specialized Code ä¸‹é¢ç”¨ low-level numpy å†™çš„ python ä»£ç å±•ç¤ºäº†ä¸€ç³»åˆ—åœ¨ä¸“ç”¨ç¡¬ä»¶åç«¯å¯èƒ½ä½¿ç”¨åˆ°çš„æ“ä½œã€‚\n1 2 3 4 5 6 7 8 def accel_fill_zero(C): C[:] = 0 def accel_tmm_add(C, A, B): C[:] += A @ B.T def accel_dma_copy(reg, dram): reg[:] = dram[:] æˆ‘ä»¬å‡è®¾åŸºç¡€çš„è¿ç®—å•å…ƒå¯ä»¥è¿›è¡Œ 16x16çš„çŸ©é˜µä¹˜æ³• (accel_tmm_add)ï¼Œæ¥æ”¶2ä¸ªå¯„å­˜å™¨é‡Œçš„ RHS è¾“å…¥å’Œè¡¨ç¤ºç´¯åŠ ä¸­é—´ç»“æœçš„ LHS è¾“å…¥ï¼Œæ•°æ®æ‹·è´ä½¿ç”¨çš„æ˜¯ä¸“ç”¨å‡½æ•° (accel_dma_copy).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # The basis unit of computation is a 16*16*16 matrix multiplication def lnumpy_tmm(A: np.ndarray, B: np.ndarray, C: np.ndarray): # a special accumulator memory C_accumulator = np.empty((16, 16), dtype=\u0026#34;float32\u0026#34;) A_reg = np.empty((16, 16), dtype=\u0026#34;float32\u0026#34;) B_reg = np.empty((16, 16), dtype=\u0026#34;float32\u0026#34;) for i in range(64): for j in range(64): accel_fill_zero(C_accumulator) for k in range(64): accel_dma_copy(A_reg[:], A[i*16 : (i+1)*16, k*16 : (k+1)*16]) accel_dma_copy(B_reg[:], B[j*16 : (j+1)*16, k*16 : (k+1)*16]) accel_tmm_add(C_accumulator, A_reg, B_reg) accel_dma_copy(C[i*16 : (i+1)*16, j*16 : (j+1)*16], C_accumulator) A Block with Tensorized Computation ä¸“ç”¨åŠ é€Ÿå™¨ä»£ç çš„ç»“æ„å¹¶éä»¥æ ‡é‡è®¡ç®—ä¸ºå•ä½ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿è¡Œçš„å¤§å¤šæ•° TensorIR ä»£ç éƒ½åŒ…å«ä¸€ä¸ª blockï¼Œç”¨äºè®¡ç®—è¾“å‡ºå¼ é‡ä¸­çš„å•ä¸ªå…ƒç´ ã€‚è®¸å¤šä¸“ç”¨åŠ é€Ÿå™¨åœ¨å¼ é‡åŒºåŸŸå†…è¿›è¡Œè®¡ç®—ã€‚TensorIRä¸­çš„ block å¯ä»¥å¸®åŠ©æˆ‘ä»¬å°†è¿™äº›ç›¸å…³è®¡ç®—åˆ†ç»„ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @tvm.script.ir_module class MatmulBlockModule: @T.prim_func def main(A: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], B: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], C: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;]) -\u0026gt; None: T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i0, j0, k0 in T.grid(64, 64, 64): with T.block(\u0026#34;tmm-16x16\u0026#34;): vi0, vj0, vk0 = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, j0, k0]) with T.init(): for i1, j1 in T.grid(16, 16): with T.block(\u0026#34;tmm_init\u0026#34;): vi1, vj1 = T.axis.remap(\u0026#34;SS\u0026#34;, [i1, j1]) C[vi0 * 16 + vi1, vj0 * 16 + vj1] = T.float32(0) for i1, j1, k1 in T.grid(16, 16, 16): with T.block(\u0026#34;tmm\u0026#34;): vi1, vj1, vk1 = T.axis.remap(\u0026#34;SSR\u0026#34;, [i1, j1, k1]) C[vi0 * 16 + vi1, vj0 * 16 + vj1] += A[vi0 * 16 + vi1, vk0 * 16 + vk1] * B[vj0 * 16 + vj1, vk0 * 16 + vk1] è°ƒç”¨ MatmulBlockModule.show() åæ˜¾ç¤ºçš„ TensorIRå¦‚ä¸‹\n1 2 T.reads(C[vi0 * 16 + vi1, vj0 * 16 + vj1], A[vi0 * 16 + vi1, vk0 * 16 + vk1], B[vj0 * 16 + vj1, vk0 * 16 + vk1]) T.writes(C[vi0 * 16 + vi1, vj0 * 16 + vj1]) è¯¥ä»£ç ä» A å’Œ B çš„ 16x16 åŒºåŸŸè¯»å–æ•°æ®ï¼Œå¹¶å†™å…¥ C çš„ 16x16 åŒºåŸŸã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå—çš„å†…å®¹åŒ…å«å­åŒºåŸŸè®¡ç®—çš„å…·ä½“å®ç°çš„è¿›ä¸€æ­¥ç»†èŠ‚ã€‚æˆ‘ä»¬ç§°è¿™ç§åŒºå—ä¸ºå¼ é‡åŒºå—ï¼Œå› ä¸ºå®ƒä»¬åŒ…å«è·¨è¶Šå¼ é‡å­åŒºåŸŸçš„è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), B: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), C: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0, j0, k0 in T.grid(64, 64, 64): with T.block(\u0026#34;tmm-16x16\u0026#34;): vi0, vj0, vk0 = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, j0, k0]) T.reads(A[vi0 * 16:vi0 * 16 + 16, vk0 * 16:vk0 * 16 + 16], B[vj0 * 16:vj0 * 16 + 16, vk0 * 16:vk0 * 16 + 16]) T.writes(C[vi0 * 16:vi0 * 16 + 16, vj0 * 16:vj0 * 16 + 16]) with T.init(): for i1, j1 in T.grid(16, 16): with T.block(\u0026#34;tmm_init\u0026#34;): vi1, vj1 = T.axis.remap(\u0026#34;SS\u0026#34;, [i1, j1]) T.reads() T.writes(C[vi0 * 16 + vi1, vj0 * 16 + vj1]) C[vi0 * 16 + vi1, vj0 * 16 + vj1] = T.float32(0.0) for i1, j1, k1 in T.grid(16, 16, 16): with T.block(\u0026#34;tmm\u0026#34;): vi1, vj1, vk1 = T.axis.remap(\u0026#34;SSR\u0026#34;, [i1, j1, k1]) T.reads(C[vi0 * 16 + vi1, vj0 * 16 + vj1], A[vi0 * 16 + vi1, vk0 * 16 + vk1], B[vj0 * 16 + vj1, vk0 * 16 + vk1]) T.writes(C[vi0 * 16 + vi1, vj0 * 16 + vj1]) C[vi0 * 16 + vi1, vj0 * 16 + vj1] = C[vi0 * 16 + vi1, vj0 * 16 + vj1] + A[vi0 * 16 + vi1, vk0 * 16 + vk1] * B[vj0 * 16 + vj1, vk0 * 16 + vk1] Transforming Loops Around Tensorized Block æˆ‘ä»¬å¯ä»¥å¯¹å¼ é‡è®¡ç®—å—çš„å¾ªç¯è¿›è¡Œå˜æ¢ï¼Œè¿™äº›å¾ªç¯å˜æ¢å¯ä»¥é‡æ–°ç»„ç»‡è®¡ç®—è¯¥å—çš„è¿­ä»£æ–¹å¼ï¼Œå¾—åˆ°ä¸åŒçš„å¼ é‡ç¨‹åºã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 sch = tvm.tir.Schedule(MatmulBlockModule) block_mm = sch.get_block(\u0026#34;tmm-16x16\u0026#34;) i, j, k = sch.get_loops(block_mm) i0, i1 = sch.split(i, [None, 4]) sch.reorder(i0, j, i1, k) sch.mod.show() #------------------------------------ @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), B: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), C: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0_0, j0, i0_1, k0 in T.grid(16, 64, 4, 64): with T.block(\u0026#34;tmm-16x16\u0026#34;): vi0 = T.axis.spatial(64, i0_0 * 4 + i0_1) vj0, vk0 = T.axis.remap(\u0026#34;SR\u0026#34;, [j0, k0]) T.reads(A[vi0 * 16:vi0 * 16 + 16, vk0 * 16:vk0 * 16 + 16], B[vj0 * 16:vj0 * 16 + 16, vk0 * 16:vk0 * 16 + 16]) T.writes(C[vi0 * 16:vi0 * 16 + 16, vj0 * 16:vj0 * 16 + 16]) with T.init(): for i1, j1 in T.grid(16, 16): with T.block(\u0026#34;tmm_init\u0026#34;): vi1, vj1 = T.axis.remap(\u0026#34;SS\u0026#34;, [i1, j1]) T.reads() T.writes(C[vi0 * 16 + vi1, vj0 * 16 + vj1]) C[vi0 * 16 + vi1, vj0 * 16 + vj1] = T.float32(0.0) for i1, j1, k1 in T.grid(16, 16, 16): with T.block(\u0026#34;tmm\u0026#34;): vi1, vj1, vk1 = T.axis.remap(\u0026#34;SSR\u0026#34;, [i1, j1, k1]) T.reads(C[vi0 * 16 + vi1, vj0 * 16 + vj1], A[vi0 * 16 + vi1, vk0 * 16 + vk1], B[vj0 * 16 + vj1, vk0 * 16 + vk1]) T.writes(C[vi0 * 16 + vi1, vj0 * 16 + vj1]) C[vi0 * 16 + vi1, vj0 * 16 + vj1] = C[vi0 * 16 + vi1, vj0 * 16 + vj1] + A[vi0 * 16 + vi1, vk0 * 16 + vk1] * B[vj0 * 16 + vj1, vk0 * 16 + vk1] Blockization \u0026ndash; Creating Tensorized Blocks TensorIR æä¾›äº†ä¸€ç§å˜æ¢åŸè¯­ blockize æ¥å°†å¾ªç¯çš„å­åŒºåŸŸç»„åˆåœ¨ä¸€èµ·ä»¥å½¢æˆå¼ é‡åŒ–çš„è®¡ç®— block. ä¾‹å¦‚æˆ‘ä»¬å¯ä»¥å°†ä¸‹é¢2ä¸ªçš„ 1024x1024 çŸ©é˜µä¹˜æ³•åˆ†è§£æˆå¾ˆå¤šä¸ª 16x16 çš„çŸ©é˜µä¹˜æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @tvm.script.ir_module class MatmulModule: @T.prim_func def main( A: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], B: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], C: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], ) -\u0026gt; None: T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i, j, k in T.grid(1024, 1024, 1024): with T.block(\u0026#34;matmul\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) with T.init(): C[vi, vj] = T.float32(0) C[vi, vj] += A[vi, vk] * B[vj, vk] sch = tvm.tir.Schedule(MatmulModule) i, j, k = sch.get_loops(\u0026#34;matmul\u0026#34;) i, ii = sch.split(i, factors=[None, 16]) j, ji = sch.split(j, factors=[None, 16]) k, ki = sch.split(k, factors=[None, 16]) sch.reorder(i, j, k, ii, ji, ki) sch.mod.show() #------------------------------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), B: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), C: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i_0, j_0, k_0, i_1, j_1, k_1 in T.grid(64, 64, 64, 16, 16, 16): with T.block(\u0026#34;matmul\u0026#34;): vi = T.axis.spatial(1024, i_0 * 16 + i_1) vj = T.axis.spatial(1024, j_0 * 16 + j_1) vk = T.axis.reduce(1024, k_0 * 16 + k_1) T.reads(A[vi, vk], B[vj, vk]) T.writes(C[vi, vj]) with T.init(): C[vi, vj] = T.float32(0.0) C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vj, vk] blockize æ˜¯ç”¨æ¥å°†ä¸€ä¸ªæˆ–å¤šä¸ªå—(block)æˆ–ä¸€ä¸ªç‰¹å®šå¾ªç¯çš„å­æ ‘åˆå¹¶æˆä¸€ä¸ªæ–°çš„å—ã€‚å¦‚æœ target æ˜¯ä¸€ä¸ªå¾ªç¯çš„æ ¹èŠ‚ç‚¹,åˆ™ä¼šå°†è¯¥å¾ªç¯ä¸‹çš„æ‰€æœ‰å—åˆå¹¶æˆä¸€ä¸ªæ–°å—ï¼Œå¦‚æœ target æ˜¯ä¸€ä¸ªå—çš„åˆ—è¡¨,åˆ™ä¼šå°†è¿™äº›å—åˆå¹¶æˆä¸€ä¸ªæ–°å—ã€‚ç„¶åå°†æ–°å—è¿”å›\nå‚æ•°è¯´æ˜ :\ntarget: éœ€è¦è¢«åˆå¹¶çš„å—æˆ–å¾ªç¯çš„æ ¹èŠ‚ç‚¹ã€‚å¯ä»¥æ˜¯ LoopRV ç±»å‹(è¡¨ç¤ºä¸€ä¸ªå¾ªç¯)æˆ– List[BlockRV] ç±»å‹(è¡¨ç¤ºå¤šä¸ªå—)ã€‚ preserve_unit_iters: ä¸€ä¸ªå¸ƒå°”å€¼,è¡¨ç¤ºæ˜¯å¦ä¿ç•™å—ç»‘å®šä¸­çš„å•å…ƒè¿­ä»£å™¨ã€‚ é™åˆ¶æ¡ä»¶ :\nblockize è¦æ±‚ç»™å®šçš„å¾ªç¯ä¸‹åªæœ‰ä¸€ä¸ªå—,ä¸”è¯¥å—çš„ç»‘å®šå¿…é¡»èƒ½å¤Ÿè¢«è¯¥å¾ªç¯çš„å­ç©ºé—´æ•´é™¤ã€‚ è°ƒç”¨ blockize åçš„ TensorIR å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 block_mm = sch.blockize(ii) sch.mod.show() #------------------------------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), B: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), C: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i_0, j_0, k_0 in T.grid(64, 64, 64): with T.block(\u0026#34;matmul_o\u0026#34;): vi_o, vj_o, vk_o = T.axis.remap(\u0026#34;SSR\u0026#34;, [i_0, j_0, k_0]) T.reads(A[vi_o * 16:vi_o * 16 + 16, vk_o * 16:vk_o * 16 + 16], B[vj_o * 16:vj_o * 16 + 16, vk_o * 16:vk_o * 16 + 16]) T.writes(C[vi_o * 16:vi_o * 16 + 16, vj_o * 16:vj_o * 16 + 16]) with T.init(): for i_1, j_1 in T.grid(16, 16): with T.block(\u0026#34;matmul_init\u0026#34;): vi_i_init, vj_i_init = T.axis.remap(\u0026#34;SS\u0026#34;, [i_1, j_1]) T.reads() T.writes(C[vi_o * 16 + vi_i_init, vj_o * 16 + vj_i_init]) C[vi_o * 16 + vi_i_init, vj_o * 16 + vj_i_init] = T.float32(0.0) for i_1, j_1, k_1 in T.grid(16, 16, 16): with T.block(\u0026#34;matmul\u0026#34;): vi_i, vj_i, vk_i = T.axis.remap(\u0026#34;SSR\u0026#34;, [i_1, j_1, k_1]) T.reads(C[vi_o * 16 + vi_i, vj_o * 16 + vj_i], A[vi_o * 16 + vi_i, vk_o * 16 + vk_i], B[vj_o * 16 + vj_i, vk_o * 16 + vk_i]) T.writes(C[vi_o * 16 + vi_i, vj_o * 16 + vj_i]) C[vi_o * 16 + vi_i, vj_o * 16 + vj_i] = C[vi_o * 16 + vi_i, vj_o * 16 + vj_i] + A[vi_o * 16 + vi_i, vk_o * 16 + vk_i] * B[vj_o * 16 + vj_i, vk_o * 16 + vk_i] Transforming TensorIR to Introduce Special Memory Scope æ­£å¦‚åœ¨ low-level NumPy ä»£ç ä¸­æåˆ°çš„ï¼Œåº•å±‚ TensorIR çš„ä¸€ä¸ªå…³é”®è¦ç´ æ˜¯åŠ é€Ÿè¿‡ç¨‹ä¸­ä½¿ç”¨çš„ç‰¹æ®Šå†…å­˜èŒƒå›´ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ cache_read å’Œ write æ¥åˆ›å»ºä¸­é—´å†…å­˜é˜¶æ®µã€‚\nstorage_scope åœ¨è¿™é‡ŒæŒ‡çš„æ˜¯å†…å­˜å­˜å‚¨èŒƒå›´æˆ–å­˜å‚¨å±‚æ¬¡ã€‚å¸¸è§çš„å­˜å‚¨èŒƒå›´åŒ…æ‹¬:\nglobal: è¡¨ç¤ºæ•°æ®å­˜å‚¨åœ¨å…¨å±€å†…å­˜ä¸­ã€‚è¿™æ˜¯æœ€é«˜å±‚æ¬¡çš„å†…å­˜èŒƒå›´ã€‚ shared: è¡¨ç¤ºæ•°æ®å­˜å‚¨åœ¨GPUçš„å…±äº«å†…å­˜ä¸­ã€‚ local: è¡¨ç¤ºæ•°æ®å­˜å‚¨åœ¨CPUæˆ–GPUçš„å¯„å­˜å™¨ä¸­ã€‚è¿™æ˜¯æœ€åº•å±‚çš„å†…å­˜èŒƒå›´ã€‚ global.A_reg è¡¨ç¤ºæ•°æ®å°†è¢«ç¼“å­˜åˆ°ä¸€ä¸ªåä¸º A_reg çš„å…¨å±€å†…å­˜ç¼“å­˜ä¸­ã€‚\nStorage Scope\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 A_reg = sch.cache_read(block_mm, 0, storage_scope=\u0026#34;global.A_reg\u0026#34;) B_reg = sch.cache_read(block_mm, 1, storage_scope=\u0026#34;global.B_reg\u0026#34;) sch.compute_at(A_reg, k) sch.compute_at(B_reg, k) write_back_block = sch.cache_write(block_mm, 0, storage_scope=\u0026#34;global.accumulator\u0026#34;) sch.reverse_compute_at(write_back_block, j) sch.mod.show() #----------------------------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), B: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), C: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): A_global_A_reg = T.alloc_buffer((1024, 1024), scope=\u0026#34;global.A_reg\u0026#34;) B_global_B_reg = T.alloc_buffer((1024, 1024), scope=\u0026#34;global.B_reg\u0026#34;) C_global_accumulator = T.alloc_buffer((1024, 1024), scope=\u0026#34;global.accumulator\u0026#34;) for i_0, j_0 in T.grid(64, 64): for k_0 in range(64): for ax0, ax1 in T.grid(16, 16): with T.block(\u0026#34;A_global.A_reg\u0026#34;): v0 = T.axis.spatial(1024, i_0 * 16 + ax0) v1 = T.axis.spatial(1024, k_0 * 16 + ax1) T.reads(A[v0, v1]) T.writes(A_global_A_reg[v0, v1]) A_global_A_reg[v0, v1] = A[v0, v1] for ax0, ax1 in T.grid(16, 16): with T.block(\u0026#34;B_global.B_reg\u0026#34;): v0 = T.axis.spatial(1024, j_0 * 16 + ax0) v1 = T.axis.spatial(1024, k_0 * 16 + ax1) T.reads(B[v0, v1]) T.writes(B_global_B_reg[v0, v1]) B_global_B_reg[v0, v1] = B[v0, v1] with T.block(\u0026#34;matmul_o\u0026#34;): vi_o, vj_o, vk_o = T.axis.remap(\u0026#34;SSR\u0026#34;, [i_0, j_0, k_0]) T.reads(A_global_A_reg[vi_o * 16:vi_o * 16 + 16, vk_o * 16:vk_o * 16 + 16], B_global_B_reg[vj_o * 16:vj_o * 16 + 16, vk_o * 16:vk_o * 16 + 16]) T.writes(C_global_accumulator[vi_o * 16:vi_o * 16 + 16, vj_o * 16:vj_o * 16 + 16]) with T.init(): for i_1, j_1 in T.grid(16, 16): with T.block(\u0026#34;matmul_init\u0026#34;): vi_i_init, vj_i_init = T.axis.remap(\u0026#34;SS\u0026#34;, [i_1, j_1]) T.reads() T.writes(C_global_accumulator[vi_o * 16 + vi_i_init, vj_o * 16 + vj_i_init]) C_global_accumulator[vi_o * 16 + vi_i_init, vj_o * 16 + vj_i_init] = T.float32(0.0) for i_1, j_1, k_1 in T.grid(16, 16, 16): with T.block(\u0026#34;matmul\u0026#34;): vi_i, vj_i, vk_i = T.axis.remap(\u0026#34;SSR\u0026#34;, [i_1, j_1, k_1]) T.reads(C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i], A_global_A_reg[vi_o * 16 + vi_i, vk_o * 16 + vk_i], B_global_B_reg[vj_o * 16 + vj_i, vk_o * 16 + vk_i]) T.writes(C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i]) C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i] = C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i] + A_global_A_reg[vi_o * 16 + vi_i, vk_o * 16 + vk_i] * B_global_B_reg[vj_o * 16 + vj_i, vk_o * 16 + vk_i] for ax0, ax1 in T.grid(16, 16): with T.block(\u0026#34;C_global.accumulator\u0026#34;): v0 = T.axis.spatial(1024, i_0 * 16 + ax0) v1 = T.axis.spatial(1024, j_0 * 16 + ax1) T.reads(C_global_accumulator[v0, v1]) T.writes(C[v0, v1]) C[v0, v1] = C_global_accumulator[v0, v1] Tensorization ç°åœ¨æˆ‘ä»¬å·²ç»åˆ›å»ºäº†ä¸€ç»„æ˜ å°„åˆ° TensorIR ä¸­ç›¸åº”è®¡ç®—é˜¶æ®µçš„å—ã€‚å‰©ä¸‹çš„æ­¥éª¤æ˜¯æ˜ å°„éƒ¨åˆ†å¼ é‡å—ï¼Œä»¥ä½¿ç”¨æ˜ å°„åˆ°ç¡¬ä»¶åŠ é€ŸæŒ‡ä»¤çš„ç‰¹å®šå®ç°ã€‚è¿™ä¸€æ˜ å°„è¿‡ç¨‹ç§°ä¸ºå¼ é‡åŒ–ã€‚ä¸ºäº†å®ç°å¼ é‡åŒ–ï¼Œæˆ‘ä»¬é¦–å…ˆæ³¨å†Œä¸€ä¸ª TensorIntrinï¼Œå…¶ä¸­åŒ…å«è®¡ç®—å’Œå®ç°çš„æè¿°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @T.prim_func def tmm16_desc(a: T.handle, b: T.handle, c: T.handle) -\u0026gt; None: A = T.match_buffer(a, (16, 16), \u0026#34;float32\u0026#34;, offset_factor=16, scope=\u0026#34;global.A_reg\u0026#34;) B = T.match_buffer(b, (16, 16), \u0026#34;float32\u0026#34;, offset_factor=16, scope=\u0026#34;global.B_reg\u0026#34;) C = T.match_buffer(c, (16, 16), \u0026#34;float32\u0026#34;, offset_factor=16, scope=\u0026#34;global.accumulator\u0026#34;) with T.block(\u0026#34;root\u0026#34;): T.reads(C[0:16, 0:16], A[0:16, 0:16], B[0:16, 0:16]) T.writes(C[0:16, 0:16]) for i, j, k in T.grid(16, 16, 16): with T.block(\u0026#34;\u0026#34;): vii, vjj, vkk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) C[vii, vjj] = C[vii, vjj] + A[vii, vkk] * B[vjj, vkk] @T.prim_func def tmm16_impl(a: T.handle, b: T.handle, c: T.handle) -\u0026gt; None: A = T.match_buffer(a, (16, 16), \u0026#34;float32\u0026#34;, offset_factor=16, scope=\u0026#34;global.A_reg\u0026#34;) B = T.match_buffer(b, (16, 16), \u0026#34;float32\u0026#34;, offset_factor=16, scope=\u0026#34;global.B_reg\u0026#34;) C = T.match_buffer(c, (16, 16), \u0026#34;float32\u0026#34;, offset_factor=16, scope=\u0026#34;global.accumulator\u0026#34;) sa = T.int32(16)#T.var(\u0026#34;int32\u0026#34;) sb = T.int32(16)#T.var(\u0026#34;int32\u0026#34;) sc = T.int32(16)#T.var(\u0026#34;int32\u0026#34;) with T.block(\u0026#34;root\u0026#34;): T.reads(C[0:16, 0:16], A[0:16, 0:16], B[0:16, 0:16]) T.writes(C[0:16, 0:16]) T.evaluate( T.call_extern(\u0026#34;float32\u0026#34;, \u0026#34;tmm16\u0026#34;, C.access_ptr(\u0026#34;w\u0026#34;), A.access_ptr(\u0026#34;r\u0026#34;), B.access_ptr(\u0026#34;r\u0026#34;), sa, sb, sc) ) tvm.tir.TensorIntrin.register(\u0026#34;tmm16\u0026#34;, tmm16_desc, tmm16_impl) é¦–å…ˆæˆ‘ä»¬ç”¨ decompose_reduction å°† C_global_accumulator çš„åˆå§‹åŒ–å’Œæ›´æ–°éƒ¨åˆ†åˆ†å¼€æˆ T.block(\u0026quot;matmul_init\u0026quot;) å’Œ T.block(\u0026quot;matmul_o_update\u0026quot;)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 sch.decompose_reduction(block_mm, k) sch.mod.show() #--------------------------------------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), B: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), C: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): A_global_A_reg = T.alloc_buffer((1024, 1024), scope=\u0026#34;global.A_reg\u0026#34;) B_global_B_reg = T.alloc_buffer((1024, 1024), scope=\u0026#34;global.B_reg\u0026#34;) C_global_accumulator = T.alloc_buffer((1024, 1024), scope=\u0026#34;global.accumulator\u0026#34;) for i_0, j_0 in T.grid(64, 64): with T.block(\u0026#34;matmul_o_init\u0026#34;): vi_o, vj_o = T.axis.remap(\u0026#34;SS\u0026#34;, [i_0, j_0]) T.reads() T.writes(C_global_accumulator[vi_o * 16:vi_o * 16 + 16, vj_o * 16:vj_o * 16 + 16]) for i_1, j_1 in T.grid(16, 16): with T.block(\u0026#34;matmul_init\u0026#34;): vi_i_init, vj_i_init = T.axis.remap(\u0026#34;SS\u0026#34;, [i_1, j_1]) T.reads() T.writes(C_global_accumulator[vi_o * 16 + vi_i_init, vj_o * 16 + vj_i_init]) C_global_accumulator[vi_o * 16 + vi_i_init, vj_o * 16 + vj_i_init] = T.float32(0.0) for k_0 in range(64): for ax0, ax1 in T.grid(16, 16): with T.block(\u0026#34;A_global.A_reg\u0026#34;): v0 = T.axis.spatial(1024, i_0 * 16 + ax0) v1 = T.axis.spatial(1024, k_0 * 16 + ax1) T.reads(A[v0, v1]) T.writes(A_global_A_reg[v0, v1]) A_global_A_reg[v0, v1] = A[v0, v1] for ax0, ax1 in T.grid(16, 16): with T.block(\u0026#34;B_global.B_reg\u0026#34;): v0 = T.axis.spatial(1024, j_0 * 16 + ax0) v1 = T.axis.spatial(1024, k_0 * 16 + ax1) T.reads(B[v0, v1]) T.writes(B_global_B_reg[v0, v1]) B_global_B_reg[v0, v1] = B[v0, v1] with T.block(\u0026#34;matmul_o_update\u0026#34;): vi_o, vj_o, vk_o = T.axis.remap(\u0026#34;SSR\u0026#34;, [i_0, j_0, k_0]) T.reads(C_global_accumulator[vi_o * 16:vi_o * 16 + 16, vj_o * 16:vj_o * 16 + 16], A_global_A_reg[vi_o * 16:vi_o * 16 + 16, vk_o * 16:vk_o * 16 + 16], B_global_B_reg[vj_o * 16:vj_o * 16 + 16, vk_o * 16:vk_o * 16 + 16]) T.writes(C_global_accumulator[vi_o * 16:vi_o * 16 + 16, vj_o * 16:vj_o * 16 + 16]) for i_1, j_1, k_1 in T.grid(16, 16, 16): with T.block(\u0026#34;matmul\u0026#34;): vi_i, vj_i, vk_i = T.axis.remap(\u0026#34;SSR\u0026#34;, [i_1, j_1, k_1]) T.reads(C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i], A_global_A_reg[vi_o * 16 + vi_i, vk_o * 16 + vk_i], B_global_B_reg[vj_o * 16 + vj_i, vk_o * 16 + vk_i]) T.writes(C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i]) C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i] = C_global_accumulator[vi_o * 16 + vi_i, vj_o * 16 + vj_i] + A_global_A_reg[vi_o * 16 + vi_i, vk_o * 16 + vk_i] * B_global_B_reg[vj_o * 16 + vj_i, vk_o * 16 + vk_i] for ax0, ax1 in T.grid(16, 16): with T.block(\u0026#34;C_global.accumulator\u0026#34;): v0 = T.axis.spatial(1024, i_0 * 16 + ax0) v1 = T.axis.spatial(1024, j_0 * 16 + ax1) T.reads(C_global_accumulator[v0, v1]) T.writes(C[v0, v1]) C[v0, v1] = C_global_accumulator[v0, v1] ç„¶åæˆ‘ä»¬è°ƒç”¨ tensorizeï¼Œå°† block_mmï¼ˆå¯¹åº”äº matmul_o_update block ï¼‰æ˜ å°„åˆ° tmm16_impl. è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ T.call_extern æ¥è°ƒç”¨ç¯å¢ƒä¸­çš„å¤–éƒ¨å‡½æ•°ã€‚ ä¸‹æ¸¸ç¼–è¯‘æ­¥éª¤å¯ä»¥è½»æ¾åœ°å°†å®ç°æ˜ å°„åˆ°å®ç°æ“ä½œçš„æŒ‡ä»¤ã€‚æˆ–è€…æˆ‘ä»¬å¯ä»¥å°† tmm16 æ˜ å°„åˆ°å®ç°è¿™ç§å¼ é‡åŒ–è®¡ç®—çš„å¾®å†…æ ¸ã€‚ ä»¥ä¸‹ä»£ç æ˜¾ç¤ºäº†å¦‚ä½•é€šè¿‡å¤–éƒ¨ C++ ä»£ç æ‰§è¡Œæ­¤æ“ä½œã€‚\nå…·ä½“å®ç°æ­¥éª¤å¦‚ä¸‹:\nå®šä¹‰ C++ é£æ ¼çš„ tmm16 å‡½æ•°: è¿™ä¸ªå‡½æ•°å®ç°äº†ä¸€ä¸ª 16x16 çŸ©é˜µä¹˜æ³•çš„è®¡ç®—é€»è¾‘ã€‚å®ƒæ¥å—ä¸‰ä¸ªè¾“å…¥å¼ é‡ aaã€bb å’Œ ccï¼Œä»¥åŠå¯¹åº”çš„æ­¥é•¿ stride_aã€stride_b å’Œ stride_cã€‚å‡½æ•°ä½¿ç”¨ä¸‰é‡å¾ªç¯æ‰§è¡ŒçŸ©é˜µä¹˜æ³•çš„è®¡ç®—,å°†ç»“æœç´¯åŠ åˆ° cc å¼ é‡ä¸­ã€‚ ä½¿ç”¨ TVM çš„ clang æ¨¡å—å°† C++ ä»£ç ç¼–è¯‘ä¸º LLVM IR ä»£ç : é¦–å…ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½• temp ç”¨äºå­˜å‚¨ç”Ÿæˆçš„ LLVM IR æ–‡ä»¶ã€‚ç„¶åè°ƒç”¨ clang.create_llvm() å‡½æ•°,ä¼ å…¥ C++ ä»£ç å­—ç¬¦ä¸² cc_codeã€‚create_llvm() å‡½æ•°ä¼šå°† C++ ä»£ç ç¼–è¯‘ä¸º LLVM IR ä»£ç ,å¹¶ä¿å­˜åˆ° ll_path æŒ‡å®šçš„æ–‡ä»¶ä¸­ã€‚æœ€åè¿”å›ç”Ÿæˆçš„ LLVM IR ä»£ç ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def tmm_kernel(): cc_code = \u0026#39;\u0026#39;\u0026#39; extern \u0026#34;C\u0026#34; int tmm16(float *cc, float *aa, float *bb, int stride_a, int stride_b, int stride_c) { for (int i = 0; i \u0026lt; 16; i++) { for (int j = 0; i \u0026lt; 16; j++) { for (int k = 0; k \u0026lt; 16; k++) { cc[i * stride_c + j] += aa[i * stride_a + k] * bb[j * stride_b + k]; } } } return 0; } \u0026#39;\u0026#39;\u0026#39; from tvm.contrib import utils, clang temp = utils.tempdir() ll_path = temp.relpath(\u0026#34;temp.ll\u0026#34;) # Create LLVM ir from c source code ll_code = clang.create_llvm(cc_code, output=ll_path) return ll_code è°ƒç”¨ sch.tensorize(block_mm, \u0026quot;tmm16\u0026quot;)æŠ¥é”™ï¼ŒåŸå› æœªçŸ¥ã€‚\n1 2 3 4 5 å‘ç”Ÿå¼‚å¸¸: TVMError TVMError: invalid unordered_map\u0026lt;K, T\u0026gt; key File \u0026#34;C:\\Users\\17725\\Desktop\\Machine Learning Compilation\\chapter7.py\u0026#34;, line 186, in \u0026lt;module\u0026gt; sch.tensorize(block_mm, \u0026#34;tmm16\u0026#34;) tvm._ffi.base.TVMError: TVMError: invalid unordered_map\u0026lt;K, T\u0026gt; key ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch7/","summary":"Personal notebook 7.","title":"TVM Learning (9)-GPU and Hardware Acceleration, Part 2"},{"content":"GPU Architecture å…¸å‹çš„ GPU åŒ…å«ä¸€ç³»åˆ—æµå¤šå¤„ç†å™¨ (Stream Multi-processor, SM)ï¼Œæ¯ä¸ªå¤šå¤„ç†å™¨éƒ½æœ‰è®¸å¤šå†…æ ¸ (core). GPU å…·æœ‰é«˜åº¦å¹¶è¡Œæ€§ï¼Œå¯ä»¥åŒæ—¶æ‰§è¡Œå¤šé¡¹ä»»åŠ¡ã€‚\nGPU Architecture\nè¦å¯¹ GPU è¿›è¡Œç¼–ç¨‹ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ç»„çº¿ç¨‹å— (thread blocks)ï¼Œæ¯ä¸ª thread æ˜ å°„åˆ°å•ä¸ªæ ¸å¿ƒï¼Œè€Œ block æ˜ å°„åˆ°æµå¼å¤šå¤„ç†å™¨ (SM)ã€‚\nGPU Programming\næˆ‘ä»¬ä»¥ä¸¤ä¸ªé•¿åº¦ä¸º1024çš„å‘é‡åŠ æ³• C=A+Bä¸ºä¾‹ï¼Œæˆ‘ä»¬å…ˆæŠŠå¤–å¾ªç¯ split æˆä¸¤éƒ¨åˆ†\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @tvm.script.ir_module class MyModuleVecAdd: @T.prim_func def main(A: T.Buffer[(1024, ), \u0026#34;float32\u0026#34;], B: T.Buffer[(1024, ), \u0026#34;float32\u0026#34;], C: T.Buffer[(1024, ), \u0026#34;float32\u0026#34;]) -\u0026gt; None: T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i in T.grid(1024): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.remap(\u0026#34;S\u0026#34;, [i]) C[vi] = A[vi] + B[vi] sch = tvm.tir.Schedule(MyModuleVecAdd) block_C = sch.get_block(\u0026#34;C\u0026#34;) i, = sch.get_loops(block=block_C) i0, i1 = sch.split(i, [None, 128]) sch.mod.show() å¾—åˆ°çš„ TensorIR å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024,), \u0026#34;float32\u0026#34;), B: T.Buffer((1024,), \u0026#34;float32\u0026#34;), C: T.Buffer((1024,), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i_0, i_1 in T.grid(8, 128): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(1024, i_0 * 128 + i_1) T.reads(A[vi], B[vi]) T.writes(C[vi]) C[vi] = A[vi] + B[vi] Build and Run the TensorIR Function on GPU ä¸€ä¸ªCUDAç¨‹åºçš„è®¡ç®—è¢«ç»„ç»‡æˆä¸‰å±‚æ¬¡ï¼šç½‘æ ¼ï¼ˆGridï¼‰ã€çº¿ç¨‹å—ï¼ˆBlockï¼‰å’Œçº¿ç¨‹ï¼ˆThreadï¼‰ã€‚ç½‘æ ¼æ˜¯ä¸€ä¸ªäºŒç»´çš„æ•°ç»„ï¼ŒåŒ…å«å¤šä¸ªçº¿ç¨‹å—ã€‚æ¯ä¸ªçº¿ç¨‹å—ä¹Ÿæ˜¯ä¸€ä¸ªäºŒç»´çš„æ•°ç»„ï¼ŒåŒ…å«å¤šä¸ªçº¿ç¨‹ã€‚æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œç›¸åŒçš„ä»£ç ï¼Œä½†æ˜¯åœ¨æ‰§è¡Œæ—¶å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ•°æ®ã€‚æ¯ä¸ªçº¿ç¨‹ç”±ä¸¤ä¸ªç´¢å¼•è¿›è¡Œè¡¨ç¤º threadIdx.xå’Œ blockIdx.x. åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæœ‰å¤šç»´çº¿ç¨‹ç´¢å¼•ï¼Œä½†è¿™é‡Œæˆ‘ä»¬ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œå°†å®ƒä»¬å›ºå®šä¸ºä¸€ç»´è¡¨ç¤ºã€‚\nGPU Thread Block\nsch.bind(i0, \u0026quot;blockIdx.x\u0026quot;) å°† i0 å¾ªç¯ç»‘å®šåˆ° GPU çš„ block ç´¢å¼•ï¼Œä»¥ä¾¿å°†è®¡ç®—åˆ†å‘åˆ°ä¸åŒçš„ GPU block ä¸Šã€‚ sch.bind(i1, \u0026quot;threadIdx.x\u0026quot;) å°† i1 å¾ªç¯ç»‘å®šåˆ° GPU çš„ thread ç´¢å¼•ï¼Œä»¥ä¾¿å°†è®¡ç®—åˆ†å‘åˆ°æ¯ä¸ª block å†…çš„ä¸åŒçš„ GPU thread ä¸Šã€‚ å¯ä»¥çœ‹åˆ°å¾ªç¯å˜é‡å˜æˆäº† T.thead_binding\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 sch.bind(i0, \u0026#34;blockIdx.x\u0026#34;) sch.bind(i1, \u0026#34;threadIdx.x\u0026#34;) sch.mod.show() #-------------------------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024,), \u0026#34;float32\u0026#34;), B: T.Buffer((1024,), \u0026#34;float32\u0026#34;), C: T.Buffer((1024,), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i_0 in T.thread_binding(8, thread=\u0026#34;blockIdx.x\u0026#34;): for i_1 in T.thread_binding(128, thread=\u0026#34;threadIdx.x\u0026#34;): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(1024, i_0 * 128 + i_1) T.reads(A[vi], B[vi]) T.writes(C[vi]) C[vi] = A[vi] + B[vi] ç„¶åæˆ‘ä»¬å¯ä»¥åœ¨GPUä¸Šæ„å»ºå¹¶æµ‹è¯•ç¨‹åºçš„æ­£ç¡®æ€§\n1 2 3 4 5 6 7 8 9 10 rt_mod = tvm.build(sch.mod, target=\u0026#34;cuda\u0026#34;) A_np = np.random.uniform(size=(1024,)).astype(\u0026#34;float32\u0026#34;) B_np = np.random.uniform(size=(1024,)).astype(\u0026#34;float32\u0026#34;) A_nd = tvm.nd.array(A_np, tvm.cuda(0)) B_nd = tvm.nd.array(B_np, tvm.cuda(0)) C_nd = tvm.nd.array(np.zeros((1024,), dtype=\u0026#34;float32\u0026#34;), tvm.cuda(0)) rt_mod[\u0026#34;main\u0026#34;](A_nd, B_nd, C_nd) np.testing.assert_allclose(C_nd.numpy(), A_np + B_np) Window Sum Example æ»‘åŠ¨çª—å£æ±‚å’Œå¯ä»¥è¢«è§†ä¸ºæƒé‡ä¸º [1,1,1]çš„å·ç§¯ï¼Œå¯¹è¾“å…¥è¿›è¡Œæ»‘åŠ¨å¹¶å°†ä¸‰ä¸ªç›¸é‚»å€¼ç›¸åŠ ã€‚\nWindow Sum\nè·Ÿä¸Šä¸€èŠ‚ä¸€æ ·æˆ‘ä»¬å°†å¾ªç¯splitåæŠŠå¤–å¾ªç¯å’Œå†…å¾ªç¯åˆ†åˆ«bindåˆ°blockå’Œthreadä¸Š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @tvm.script.ir_module class MyModuleWindowSum: @T.prim_func def main(A: T.Buffer[(1027, ), \u0026#34;float32\u0026#34;], B: T.Buffer[(1024, ), \u0026#34;float32\u0026#34;]) -\u0026gt; None: T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i in T.grid(1024): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.remap(\u0026#34;S\u0026#34;, [i]) B[vi] = A[vi] + A[vi + 1] + A[vi + 2] sch = tvm.tir.Schedule(MyModuleWindowSum) nthread = 128 block_C = sch.get_block(\u0026#34;C\u0026#34;) i, = sch.get_loops(block=block_C) i0, i1 = sch.split(i, [None, nthread]) sch.bind(i0, \u0026#34;blockIdx.x\u0026#34;) sch.bind(i1, \u0026#34;threadIdx.x\u0026#34;) å¯¹åº”çš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1027,), \u0026#34;float32\u0026#34;), B: T.Buffer((1024,), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i_0 in T.thread_binding(8, thread=\u0026#34;blockIdx.x\u0026#34;): for i_1 in T.thread_binding(128, thread=\u0026#34;threadIdx.x\u0026#34;): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(1024, i_0 * 128 + i_1) T.reads(A[vi:vi + 3]) T.writes(B[vi]) B[vi] = A[vi] + A[vi + 1] + A[vi + 2] Cache in Shared Memory æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨çª—å£æ»‘åŠ¨çš„è¿‡ç¨‹ä¸­æœ‰ä¸€éƒ¨åˆ†æ•°æ®æ˜¯é‡å¤çš„ã€‚æ¯ä¸ª block åŒ…å«æ‰€æœ‰çº¿ç¨‹éƒ½å¯ä»¥åœ¨å—å†…è®¿é—®çš„å…±äº«å†…å­˜ (shared memory)ï¼Œä¸ºäº†é¿å…é‡å¤ä» global memory åŠ è½½ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠéƒ¨åˆ†æ•°æ®ç¼“å­˜åˆ°å…±äº«å†…å­˜ä¸Š\nB[vi] = A[vi] + A[vi + 1] + A[vi + 2] è¿™ä¸€è¡Œä»£ç ä¼šé‡å¤è¯»å– A ç¼“å†²åŒºä¸­çš„æ•°æ®ã€‚ sch.cache_read(block_C, read_buffer_index=0, storage_scope=\u0026quot;shared\u0026quot;) åˆ›å»ºäº†ä¸€ä¸ªåä¸º A_shared çš„å…±äº«å†…å­˜ç¼“å­˜ï¼Œç”¨äºå­˜å‚¨ A ç¼“å†²åŒºä¸­çš„ä¸€éƒ¨åˆ†æ•°æ®ã€‚ block_C æŒ‡ç¤ºç¼“å­˜ä¸ C block ç›¸å…³è”ã€‚ read_buffer_index=0 æŒ‡ç¤ºç¼“å­˜ A ç¼“å†²åŒºï¼Œå› ä¸º A æ˜¯ C block ä¸­çš„ç¬¬ä¸€ä¸ªè¯»å–ç¼“å†²åŒºã€‚ storage_scope=\u0026quot;shared\u0026quot; æŒ‡ç¤ºç¼“å­˜ä½¿ç”¨å…±äº«å†…å­˜ã€‚ sch.compute_at(A_shared, i1) å°† A_shared çš„è®¡ç®—ä½ç½®è®¾ç½®ä¸º i1 å¾ªç¯ï¼Œè¿™æ„å‘³ç€ A_shared å°†åœ¨æ¯ä¸ª thread ä¸­è¢«è®¡ç®—ã€‚ 1 2 3 4 5 6 7 8 9 10 sch = tvm.tir.Schedule(MyModuleWindowSum) nthread = 128 block_C = sch.get_block(\u0026#34;C\u0026#34;) i, = sch.get_loops(block=block_C) i0, i1 = sch.split(i, [None, nthread]) sch.bind(i0, \u0026#34;blockIdx.x\u0026#34;) sch.bind(i1, \u0026#34;threadIdx.x\u0026#34;) A_shared = sch.cache_read(block_C, read_buffer_index=0, storage_scope=\u0026#34;shared\u0026#34;) sch.compute_at(A_shared, i1) sch.mod.show() å˜æ¢åçš„TensorIRå¦‚ä¸‹ï¼Œä¸»è¦è¿›è¡Œäº†\nå…±äº«å†…å­˜åˆ†é…ï¼š åœ¨æ¯ä¸ª GPU block çš„å…±äº«å†…å­˜ä¸­åˆ†é…äº†ä¸€ä¸ªå¤§å°ä¸º (1027,) çš„ç¼“å†²åŒº A_sharedã€‚\nA_shared = T.alloc_buffer((1027,), scope=\u0026#34;shared\u0026#34;) æ·»åŠ äº†ä¸€ä¸ªæ–°çš„ block A_sharedï¼Œå¾ªç¯éå†æ¯ä¸ª threadå¹¶å°† A ç¼“å†²åŒºä¸­çš„æ•°æ®ç¼“å­˜åˆ° A_shared ä¸­ï¼š\nfor i_0 in T.thread_binding(8, thread=\u0026#34;blockIdx.x\u0026#34;): for i_1 in T.thread_binding(128, thread=\u0026#34;threadIdx.x\u0026#34;): for ax0 in range(130): with T.block(\u0026#34;A_shared\u0026#34;): v0 = T.axis.spatial(1027, i_0 * 128 + ax0) T.reads(A[v0]) T.writes(A_shared[v0]) A_shared[v0] = A[v0] ç æ›´æ–°äº† C block ä¸­çš„è®¡ç®—ï¼Œä½¿å…¶ä» A_shared ä¸­è¯»å–æ•°æ®ï¼š\nwith T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(1024, i_0 * 128 + i_1) T.reads(A_shared[vi:vi + 3]) T.writes(B[vi]) B[vi] = A_shared[vi] + A_shared[vi + 1] + A_shared[vi + 2] rane(130) çš„å‡ºç°æ˜¯å› ä¸ºéœ€è¦å°† A ç¼“å†²åŒºä¸­çš„æ•°æ®ç¼“å­˜åˆ°å…±äº«å†…å­˜ A_shared ä¸­ã€‚æ¯ä¸ª GPU block å¤„ç†çš„æ•°æ®èŒƒå›´æ˜¯ 128 ä¸ªå…ƒç´ ï¼Œå¯¹åº”äº i1 å¾ªç¯çš„èŒƒå›´ã€‚ç”±äºçª—å£æ±‚å’Œæ“ä½œéœ€è¦è®¿é—® A ç¼“å†²åŒºä¸­å½“å‰å…ƒç´ çš„ä¸‰ä¸ªç›¸é‚»å…ƒç´ ï¼Œå› æ­¤æ¯ä¸ª thread éœ€è¦è®¿é—® 128 + 2 = 130 ä¸ªå…ƒç´ ã€‚ä¸ºäº†ç¡®ä¿æ¯ä¸ª thread éƒ½èƒ½è®¿é—®åˆ°æ‰€éœ€çš„æ•°æ®ï¼Œéœ€è¦å°† A ç¼“å†²åŒºä¸­ 130 ä¸ªå…ƒç´ ç¼“å­˜åˆ° A_shared ä¸­ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1027,), \u0026#34;float32\u0026#34;), B: T.Buffer((1024,), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): A_shared = T.alloc_buffer((1027,), scope=\u0026#34;shared\u0026#34;) for i_0 in T.thread_binding(8, thread=\u0026#34;blockIdx.x\u0026#34;): for i_1 in T.thread_binding(128, thread=\u0026#34;threadIdx.x\u0026#34;): for ax0 in range(130): with T.block(\u0026#34;A_shared\u0026#34;): v0 = T.axis.spatial(1027, i_0 * 128 + ax0) T.reads(A[v0]) T.writes(A_shared[v0]) A_shared[v0] = A[v0] with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(1024, i_0 * 128 + i_1) T.reads(A_shared[vi:vi + 3]) T.writes(B[vi]) B[vi] = A_shared[vi] + A_shared[vi + 1] + A_shared[vi + 2] Get CUDA Source æˆ‘ä»¬å¯ä»¥æ£€æŸ¥ç›¸åº”çš„åº•å±‚ä»£ç ï¼ˆCUDA ï¼‰\n1 2 rt_mod = tvm.build(sch.mod, target=\u0026#34;cuda\u0026#34;) print(rt_mod.imported_modules[0].get_source()) ç”Ÿæˆçš„ä»£ç åŒ…å«ä¸¤éƒ¨åˆ†ï¼š\nåœ¨ä¸»æœº (CPU) ä¸Šçš„è°ƒç”¨ GPU ç¨‹åºçš„éƒ¨åˆ†ï¼› ç›¸åº”è®¡ç®—çš„ CUDA å†…æ ¸ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #if (((__CUDACC_VER_MAJOR__ == 11) \u0026amp;\u0026amp; (__CUDACC_VER_MINOR__ \u0026gt;= 4)) || \\ (__CUDACC_VER_MAJOR__ \u0026gt; 11)) #define TVM_ENABLE_L2_PREFETCH 1 #else #define TVM_ENABLE_L2_PREFETCH 0 #endif #ifdef _WIN32 using uint = unsigned int; using uchar = unsigned char; using ushort = unsigned short; using int64_t = long long; using uint64_t = unsigned long long; #else #define uint unsigned int #define uchar unsigned char #define ushort unsigned short #define int64_t long long #define uint64_t unsigned long long #endif extern \u0026#34;C\u0026#34; __global__ void __launch_bounds__(128) main_kernel(float* __restrict__ A, float* __restrict__ B); extern \u0026#34;C\u0026#34; __global__ void __launch_bounds__(128) main_kernel(float* __restrict__ A, float* __restrict__ B) { __shared__ float A_shared[130]; for (int ax0 = 0; ax0 \u0026lt; 130; ++ax0) { A_shared[ax0] = A[((((int)blockIdx.x) * 128) + ax0)]; } __syncthreads(); B[((((int)blockIdx.x) * 128) + ((int)threadIdx.x))] = ((A_shared[((int)threadIdx.x)] + A_shared[(((int)threadIdx.x) + 1)]) + A_shared[(((int)threadIdx.x) + 2)]); } Matrix Multiplication ä¸‹é¢æˆ‘ä»¬å¯¹åŸå§‹çš„ 1024*1024çš„çŸ©é˜µä¹˜æ³•è¿›è¡Œä¼˜åŒ–\n1 2 3 4 5 6 7 8 9 10 11 12 13 @tvm.script.ir_module class MyModuleMatmul: @T.prim_func def main(A: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], B: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], C: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;]) -\u0026gt; None: T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i, j, k in T.grid(1024, 1024, 1024): with T.block(\u0026#34;C\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) with T.init(): C[vi, vj] = 0.0 C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj] Local Blocking ä¸‹é¢çš„blocking å‡½æ•°ä½¿ç”¨äº†ä¸€ç§ç§°ä¸º å±€éƒ¨é˜»å¡ çš„ä¼˜åŒ–ç­–ç•¥ï¼Œå°†çŸ©é˜µä¹˜æ³•çš„è®¡ç®—åˆ†è§£æˆæ›´å°çš„å—ï¼Œå¹¶ä½¿ç”¨å…±äº«å†…å­˜ç¼“å­˜æ¥æé«˜æ€§èƒ½ã€‚\nLocal Blocking\nå°†ä¸‰ä¸ªå¾ªç¯ iã€j å’Œ k åˆ†åˆ«æ‹†åˆ†æˆå¤šä¸ªå¾ªç¯ï¼Œä¾‹å¦‚å°† i æ‹†åˆ†æˆ i0ã€i1 å’Œ i2ï¼Œåˆ†åˆ«å¯¹åº”äº block ç´¢å¼•ã€thread ç´¢å¼•å’Œå±€éƒ¨å¾ªç¯ç´¢å¼•ã€‚ k1è¡¨ç¤ºçŸ©é˜µè®¡ç®—è¢«æ‹†åˆ†æˆå¤šå°‘ä¸ªå°å—ï¼Œk0å†³å®šäº†æ¯ä¸ªçº¿ç¨‹éœ€è¦è¿›è¡Œå¤šå°‘æ¬¡ç´¯åŠ æ“ä½œã€‚è°ƒæ•´å¾ªç¯çš„é¡ºåºï¼Œä»¥ä¾¿åœ¨æ¯ä¸ª thread ä¸­è®¡ç®— k0 å¾ªç¯çš„æ‰€æœ‰è¿­ä»£ï¼Œä»è€Œåˆ©ç”¨å…±äº«å†…å­˜ç¼“å­˜ã€‚ ä½¿ç”¨ cache_write å‡½æ•°åˆ›å»ºä¸€ä¸ªåä¸º C_local çš„å…±äº«å†…å­˜ç¼“å­˜ï¼Œç”¨äºå­˜å‚¨ C çŸ©é˜µçš„ä¸­é—´ç»“æœã€‚ ä½¿ç”¨ reverse_compute_at å‡½æ•°å°† C_local çš„è®¡ç®—ä½ç½®è®¾ç½®ä¸º j1 å¾ªç¯ï¼Œä»¥ä¾¿åœ¨æ¯ä¸ª thread ä¸­è®¡ç®— C_local çš„æ‰€æœ‰è¿­ä»£ï¼Œä»è€Œåˆ©ç”¨å…±äº«å†…å­˜ç¼“å­˜ã€‚ å°† i0 å’Œ j0 ç»‘å®šåˆ° GPU çš„ blockIdx.y å’Œ blockIdx.x çº¿ç¨‹ç´¢å¼•ï¼Œå°† i1 å’Œ j1 ç»‘å®šåˆ° GPU çš„ threadIdx.y å’Œ threadIdx.x çº¿ç¨‹ç´¢å¼•ã€‚ ä½¿ç”¨ unroll å‡½æ•°å±•å¼€ k1 å¾ªç¯ï¼Œä»¥ä¾¿åœ¨æ¯ä¸ª thread ä¸­å±•å¼€è®¡ç®—ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚ ä½¿ç”¨ decompose_reduction å‡½æ•°åˆ†è§£ k0 å¾ªç¯ï¼Œä»¥ä¾¿åœ¨æ¯ä¸ª thread ä¸­è®¡ç®— k0 å¾ªç¯çš„æ‰€æœ‰è¿­ä»£ï¼Œä»è€Œåˆ©ç”¨å…±äº«å†…å­˜ç¼“å­˜ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def blocking(sch: tvm.tir.Schedule, tile_local_y, tile_local_x, tile_block_y, tile_block_x, tile_k): block_C = sch.get_block(\u0026#34;C\u0026#34;) C_local = sch.cache_write(block_C, 0, \u0026#34;local\u0026#34;) i, j, k = sch.get_loops(block=block_C) i0, i1, i2 = sch.split(loop=i, factors=[None, tile_block_y, tile_local_y]) j0, j1, j2 = sch.split(loop=j, factors=[None, tile_block_x, tile_local_x]) k0, k1 = sch.split(loop=k, factors=[None, tile_k]) sch.unroll(k1) sch.reorder(i0, j0, i1, j1, k0, k1, i2, j2) sch.reverse_compute_at(C_local, j1) sch.bind(i0, \u0026#34;blockIdx.y\u0026#34;) sch.bind(j0, \u0026#34;blockIdx.x\u0026#34;) sch.bind(i1, \u0026#34;threadIdx.y\u0026#34;) sch.bind(j1, \u0026#34;threadIdx.x\u0026#34;) sch.decompose_reduction(block_C, k0) return sch è¿›è¡Œ Local Blocking åçš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 sch = tvm.tir.Schedule(MyModuleMatmul) sch = blocking(sch, 8, 8, 8, 8, 4) sch.mod.show() #--------------------------------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), B: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;), C: T.Buffer((1024, 1024), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): C_local = T.alloc_buffer((1024, 1024), scope=\u0026#34;local\u0026#34;) for i_0 in T.thread_binding(16, thread=\u0026#34;blockIdx.y\u0026#34;): for j_0 in T.thread_binding(16, thread=\u0026#34;blockIdx.x\u0026#34;): for i_1 in T.thread_binding(8, thread=\u0026#34;threadIdx.y\u0026#34;): for j_1 in T.thread_binding(8, thread=\u0026#34;threadIdx.x\u0026#34;): for i_2_init, j_2_init in T.grid(8, 8): with T.block(\u0026#34;C_init\u0026#34;): vi = T.axis.spatial(1024, i_0 * 64 + i_1 * 8 + i_2_init) vj = T.axis.spatial(1024, j_0 * 64 + j_1 * 8 + j_2_init) T.reads() T.writes(C_local[vi, vj]) C_local[vi, vj] = T.float32(0.0) for k_0 in range(256): for k_1 in T.unroll(4): for i_2, j_2 in T.grid(8, 8): with T.block(\u0026#34;C_update\u0026#34;): vi = T.axis.spatial(1024, i_0 * 64 + i_1 * 8 + i_2) vj = T.axis.spatial(1024, j_0 * 64 + j_1 * 8 + j_2) vk = T.axis.reduce(1024, k_0 * 4 + k_1) T.reads(C_local[vi, vj], A[vi, vk], B[vk, vj]) T.writes(C_local[vi, vj]) C_local[vi, vj] = C_local[vi, vj] + A[vi, vk] * B[vk, vj] for ax0, ax1 in T.grid(8, 8): with T.block(\u0026#34;C_local\u0026#34;): v0 = T.axis.spatial(1024, i_0 * 64 + i_1 * 8 + ax0) v1 = T.axis.spatial(1024, j_0 * 64 + j_1 * 8 + ax1) T.reads(C_local[v0, v1]) T.writes(C[v0, v1]) C[v0, v1] = C_local[v0, v1] Shared Memory Blocking ä¸Šé¢çš„æ–¹æ³•æ²¡æœ‰è€ƒè™‘ç›¸é‚» thread ä½äºåŒä¸€ä¸ª block ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬éœ€è¦çš„æ•°æ®åŠ è½½åˆ° shared memory ä¸­ã€‚\nShared Memory Blocking\ncache_read_and_coop_fetch å‡½æ•°è´Ÿè´£å°† A å’Œ B çŸ©é˜µä¸­çš„æ•°æ®åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­ã€‚é¦–å…ˆä½¿ç”¨ cache_read åˆ›å»ºä¸€ä¸ªå…±äº«å†…å­˜ç¼“å­˜ï¼Œç”¨äºå­˜å‚¨ A æˆ– B çŸ©é˜µçš„æ•°æ®ã€‚ç„¶åä½¿ç”¨ compute_at å°†ç¼“å­˜çš„è®¡ç®—ä½ç½®è®¾ç½®ä¸º k0 å¾ªç¯ï¼Œåœ¨æ¯ä¸ªçº¿ç¨‹ä¸­è®¡ç®—ç¼“å­˜çš„æ‰€æœ‰è¿­ä»£ã€‚æœ€åä½¿ç”¨ split å’Œ vectorize å‡½æ•°å¯¹ k0 å¾ªç¯è¿›è¡Œå‘é‡åŒ–ï¼Œæé«˜åŠ è½½æ•°æ®çš„æ•ˆç‡ã€‚\n1 2 3 4 5 6 7 8 9 def cache_read_and_coop_fetch(sch: tvm.tir.Schedule, block, nthread, read_idx, read_loc): read_cache = sch.cache_read(block=block, read_buffer_index=read_idx, storage_scope=\u0026#34;shared\u0026#34;) sch.compute_at(block=read_cache, loop=read_loc) # vertorized cooperative fetch inner0, inner1 = sch.get_loops(block=read_cache)[-2:] inner = sch.fuse(inner0, inner1) _, tx, vec = sch.split(loop=inner, factors=[None, nthread, 4]) sch.vectorize(vec) sch.bind(tx, \u0026#34;threadIdx.x\u0026#34;) å…¶ä½™çš„æ“ä½œå’Œ Local Blocking ä¸€è‡´\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def blocking_with_shared(sch: tvm.tir.Schedule, tile_local_y, tile_local_x, tile_block_y, tile_block_x, tile_k): block_C = sch.get_block(\u0026#34;C\u0026#34;) C_local = sch.cache_write(block_C, 0, \u0026#34;local\u0026#34;) i, j, k = sch.get_loops(block=block_C) i0, i1, i2 = sch.split(loop=i, factors=[None, tile_block_y, tile_local_y]) j0, j1, j2 = sch.split(loop=j, factors=[None, tile_block_x, tile_local_x]) k0, k1 = sch.split(loop=k, factors=[None, tile_k]) sch.reorder(i0, j0, i1, j1, k0, k1, i2, j2) sch.reverse_compute_at(C_local, j1) sch.bind(i0, \u0026#34;blockIdx.y\u0026#34;) sch.bind(j0, \u0026#34;blockIdx.x\u0026#34;) tx = sch.fuse(i1, j1) sch.bind(tx, \u0026#34;threadIdx.x\u0026#34;) nthread = tile_block_y * tile_block_x cache_read_and_coop_fetch(sch, block_C, nthread, 0, k0) cache_read_and_coop_fetch(sch, block_C, nthread, 1, k0) sch.decompose_reduction(block_C, k0) return sch ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch6/","summary":"Personal notebook 6.","title":"TVM Learning (8)-GPU and Hardware Acceleration, Part 1"},{"content":"Model Preparation æˆ‘ä»¬é‡‡ç”¨Pytorchæ¡†æ¶å…ˆå®šä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ¥å—ä¸€æ‰¹å›¾åƒä¸ºè¾“å…¥ï¼Œç„¶åå¯¹å®ƒä»¬ä¾æ¬¡ä½œç”¨å·ç§¯å±‚ï¼Œæ¿€æ´»å±‚ï¼Œæ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ï¼Œå¾—åˆ°åˆ†ç±»ç»“æœã€‚å¹¶ä»è®­ç»ƒå¥½çš„æ¨¡å‹é‡ŒåŠ è½½æƒé‡ï¼Œè¾“å…¥å›¾åƒæ¥è‡ªFashionMNISTæ•°æ®é›†ï¼Œshapeä¸º(1, 28, 28)ï¼Œæˆ‘ä»¬è®¾ç½®batch size=4.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Load the weight map from file. weight_map = pkl.load(open(\u0026#34;fasionmnist_mlp_assignment_params.pkl\u0026#34;, \u0026#34;rb\u0026#34;)) class_names = [\u0026#39;T-shirt/top\u0026#39;, \u0026#39;Trouser\u0026#39;, \u0026#39;Pullover\u0026#39;, \u0026#39;Dress\u0026#39;, \u0026#39;Coat\u0026#39;, \u0026#39;Sandal\u0026#39;, \u0026#39;Shirt\u0026#39;, \u0026#39;Sneaker\u0026#39;, \u0026#39;Bag\u0026#39;, \u0026#39;Ankle boot\u0026#39;] def pytorch_model(): list = [] list.append(nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), bias=True)) list.append(nn.ReLU()) list.append(nn.MaxPool2d(kernel_size=(2, 2))) list.append(nn.Flatten()) list.append(nn.Linear(in_features=5408, out_features=100, bias=True)) list.append(nn.ReLU()) list.append(nn.Linear(in_features=100, out_features=10, bias=True)) list.append(nn.Softmax(dim=1)) model = nn.Sequential(*list).cuda() name_map = { \u0026#34;0.weight\u0026#34;: \u0026#34;conv2d_weight\u0026#34;, \u0026#34;0.bias\u0026#34;: \u0026#34;conv2d_bias\u0026#34;, \u0026#34;4.weight\u0026#34;: \u0026#34;linear0_weight\u0026#34;, \u0026#34;4.bias\u0026#34;: \u0026#34;linear0_bias\u0026#34;, \u0026#34;6.weight\u0026#34;: \u0026#34;linear1_weight\u0026#34;, \u0026#34;6.bias\u0026#34;: \u0026#34;linear1_bias\u0026#34;, } for name, param in model.named_parameters(): param.data = torch.from_numpy(weight_map[name_map[name]]).cuda() return model Ingest Model From Pytorch ä¹‹å‰æˆ‘ä»¬éƒ½æ˜¯æ‰‹å†™T.prim_funcæ¥å®ç°ç¥ç»ç½‘ç»œçš„æ¯ä¸€å±‚ï¼Œè¿™æ ·å¾ˆå®¹æ˜“å‡ºé”™å¹¶ä¸”ä¸æ˜“äºè°ƒè¯•ã€‚TVMæä¾›äº† relax.BlockBuilderç±»å¯ä»¥ä»å¤´å¼€å§‹ä¸€æ­¥æ­¥æ„é€ ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªåä¸º emit_teçš„APIï¼Œå®ƒå¯ä»¥å°†ä¸€ä¸ªå¼ é‡è¡¨è¾¾å¼çš„ç®—å­æè¿°è½¬å˜æˆä¸€ä¸ªå¯¹åº”TensorIRå‡½æ•°çš„ call_tiræ“ä½œã€‚\nåœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œä¸ºäº†æ„å»ºä¸€ä¸ªæ‰§è¡Œå•ä¸ªReLUç®—å­çš„Relaxå‡½æ•°ï¼Œåœ¨ emit_te_exampleä¸­æˆ‘ä»¬é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ª BlockBuilderå®ä¾‹ bbã€‚åŒæ ·å®šä¹‰äº†ä¸€ä¸ª 128x128å¤§å°çš„å¼ é‡å˜é‡ xï¼Œå®ƒå°†ä½œä¸ºReLUæ“ä½œçš„è¾“å…¥ï¼ˆåŒæ—¶ä¹Ÿæ˜¯Relaxå‡½æ•°çš„è¾“å…¥ï¼‰ã€‚\nåœ¨è¿™ä¹‹åï¼Œæˆ‘ä»¬ç”¨ with bb.function(name, [*input]) APIæ„å»ºä¸€ä¸ªä»¥ xä¸ºè¾“å…¥çš„Relaxå‡½æ•° mainã€‚ç„¶åæˆ‘ä»¬æ„å»ºä¸€ä¸ªdataflow blockã€‚åœ¨è¿™ä¸ªdataflow blocké‡Œï¼Œæˆ‘ä»¬é¦–å…ˆç”¨ emit_teç”Ÿæˆä¸€ä¸ªè°ƒç”¨ReLUç®—å­çš„ call_tirã€‚ emit_teä¼šåœ¨IRModuleä¸­ç”Ÿæˆä¸€ä¸ªåå­—ä¸º reluçš„TensorIRå‡½æ•°ï¼Œç„¶ååœ¨dataflow blockä¸­ç”Ÿæˆ call_tir(relu, (x,), (128, 128), dtype=\u0026quot;float32\u0026quot;)æ“ä½œã€‚call_tirä¹‹åæ˜¯å‡½æ•°è¿”å›ã€‚åœ¨è¿™ä¸€æ„é€ ä¹‹åï¼ŒBlockBuilderå®ä¾‹ bbåŒ…å«æ„å»ºå®Œçš„IRModuleï¼Œå¯ä»¥é€šè¿‡ bb.get()å¾—åˆ°ã€‚\nemit_te çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ª TVM å¼ é‡è¡¨è¾¾å¼ï¼ˆTEï¼‰å‡½æ•°è½¬æ¢ä¸º Relax ä¸­çš„è°ƒç”¨èŠ‚ç‚¹ï¼ˆCall Nodeï¼‰ã€‚å®ƒå…è®¸ä½ åœ¨ Relax ä¸­ä½¿ç”¨ TE å‡½æ•°æ¥è¿›è¡Œè®¡ç®—ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„ TVM Script ä»£ç ã€‚è¯¥å‡½æ•°é¦–å…ˆå°† Relax è¡¨è¾¾å¼çš„å‚æ•°è½¬æ¢ä¸º TE å¼ é‡ã€‚ç„¶åï¼Œå®ƒè°ƒç”¨ TE å‡½æ•°ï¼Œå¹¶å°†è½¬æ¢åçš„ TE å¼ é‡ä½œä¸ºå‚æ•°ä¼ é€’ç»™å®ƒã€‚TE å‡½æ•°æ‰§è¡Œè®¡ç®—å¹¶è¿”å›ä¸€ä¸ª TE å¼ é‡æˆ– TE å¼ é‡åˆ—è¡¨ã€‚è¯¥å‡½æ•°å°†è¿”å›çš„ TE å¼ é‡è½¬æ¢ä¸º Relax ä¸­çš„ Call Node. æœ€åï¼Œå®ƒä½¿ç”¨ self.emit æ–¹æ³•å°†è°ƒç”¨èŠ‚ç‚¹æ·»åŠ åˆ° Relax BlockBuilder ä¸­ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–°çš„ Relax å˜é‡ï¼Œè¯¥å˜é‡ç»‘å®šåˆ° Call Node.\nå‡½æ•°å‚æ•°ï¼š\nfunc: ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œå®ƒä»£è¡¨ä¸€ä¸ª TE å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å— Relax å¼ é‡ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ª TE å¼ é‡æˆ– TE å¼ é‡åˆ—è¡¨ã€‚ *args: funcè¾“å…¥çš„ä½ç½®å‚æ•° (relax Tensor)ã€‚ **kwargs: funcè¾“å…¥çš„çš„å…³é”®å­—å‚æ•° (relax Tensor)ã€‚ name_hint: å¯é€‰å‚æ•°ï¼Œç”¨äºæŒ‡å®šç”Ÿæˆçš„ PrimFunc çš„åç§°ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def relu(A): B = te.compute(shape=(128, 128), fcompute=lambda i, j: te.max(A[i, j], 0), name=\u0026#34;B\u0026#34;) return B def emit_te_example(): # relax.BlockBuilder can construct e2e models # step by step in an IRModule that starts empty. bb =relax.BlockBuilder() # relax.DynTensorType is the type assigned to tensors with a known dtype and unknown shape. x = relax.Var(\u0026#34;x\u0026#34;, relax.TensorStructInfo((128, 128), \u0026#34;float32\u0026#34;)) with bb.function(\u0026#34;main\u0026#34;, [x]): # construct a Relax function main with x as input with bb.dataflow(): # Emit a call node according to the te function # which should return a te tensor or a list of te tensors. lv0 = bb.emit_te(relu, x) gv = bb.emit_output(lv0) # mark the dataflow output bb.emit_func_output(gv) # mark the function output return bb.get() # return the constructed IRModule å¯ä»¥çœ‹åˆ°é€šè¿‡BlockBuilderç”Ÿæˆçš„IRModuleåŒ…å«äº†ReLUçš„TensorIRå®ç°å’Œä¸€ä¸ªå«æœ‰è°ƒç”¨ReLUå®ç°çš„ call_tirçš„Relaxå‡½æ•°\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @I.ir_module class Module: @T.prim_func(private=True) def relu(x: T.Buffer((T.int64(128), T.int64(128)), \u0026#34;float32\u0026#34;), B: T.Buffer((T.int64(128), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i, j in T.grid(T.int64(128), T.int64(128)): with T.block(\u0026#34;B\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(x[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = T.max(x[v_i, v_j], T.float32(0.0)) @R.function def main(x: R.Tensor((128, 128), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((128, 128), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv = R.call_tir(cls.relu, (x,), out_sinfo=R.Tensor((128, 128), dtype=\u0026#34;float32\u0026#34;)) gv: R.Tensor((128, 128), dtype=\u0026#34;float32\u0026#34;) = lv R.output(gv) return gv Construct IRModule Equals to Pytorch æˆ‘ä»¬å¯ä»¥ç”¨ BlockBuilderå’Œ emit_teæ¥åˆ›å»ºä¸€ä¸ªå’Œä¹‹å‰å®šä¹‰çš„PyTorchæ¨¡å‹ç­‰ä»·çš„IRModuleã€‚é¦–å…ˆæˆ‘ä»¬è¦å®ç°è¿™äº›ç®—å­çš„å¼ é‡è¡¨è¾¾å¼è¿ç®—å‡½æ•°ã€‚\nåœ¨åŠ ä¸Šbiasçš„æ—¶å€™è¦å’Œreductionæ“ä½œåˆ†å¼€è¿›è¡Œï¼Œå³ä¸èƒ½åœ¨ä¸€ä¸ªte.computeé‡Œé¢è¿›è¡Œ te.sum+bias[...]çš„æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥é”™\n1 2 3 4 TVMError Traceback (most recent call last): File \u0026#34;D:\\Work\\tvm\\tvm0.18\\tvm\\src\\te\\operation\\compute_op.cc\u0026#34;, line 566 InternalError: Check failed: (0 == level_) is false: Reductions are only allowed at the top level of compute. Please create another tensor for further composition. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def my_conv2d(X, K, B): # No padding, stride = 1 N, CI, H, W = X.shape CO, _, KH, KW = K.shape k = te.reduce_axis((0, CI), name=\u0026#34;k\u0026#34;) r = te.reduce_axis((0, KH), name=\u0026#34;r\u0026#34;) s = te.reduce_axis((0, KW), name=\u0026#34;s\u0026#34;) OH = (H - KH) + 1 OW = (W - KW) + 1 conv2d_te = te.compute(shape=(N, CO, OH, OW), fcompute=lambda n, co, oh, ow: te.sum( X[n, k, oh + r, ow + s] * K[co, k, r, s], axis=[k, r, s]), name=\u0026#34;conv2d\u0026#34;) out = te.compute(shape=(N, CO, OH, OW), fcompute=lambda n, co, oh, ow: conv2d_te[n, co, oh, ow] + B[0, co, 0, 0]) return out def my_relu(X): return te.compute(shape=X.shape, fcompute=lambda *i: te.max(X(*i), 0)) def my_maxpool2d(X, S): N, C, H, W = X.shape i = te.reduce_axis((0, S), name=\u0026#34;i\u0026#34;) j = te.reduce_axis((0, S), name=\u0026#34;j\u0026#34;) maxpool2d_te = te.compute(shape=(N, C, H//2, W//2), fcompute=lambda n, co, oh, ow: te.max( X[n, co, oh*S+i, ow*S+j], axis=[i, j]), name=\u0026#34;maxpool2d\u0026#34;) return maxpool2d_te def my_flatten(X): N, C, H, W = X.shape flatten_te = te.compute(shape=(N, C*H*W), fcompute=lambda n, i: X[n, i//(H*W), i//(W)%(H), i%(W)]) return flatten_te def my_linear(X, W, B=None): FO, FI = W.shape N, _ = X.shape fi = te.reduce_axis((0, FI), name=\u0026#34;FI\u0026#34;) linear_te = te.compute(shape=(N, FO), fcompute=lambda i, j: te.sum( X[i, fi] * W[j, fi], axis=fi)) if B is not None: out = te.compute(shape=(N, FO), fcompute=lambda i, j: B[0, j] + linear_te[i, j]) else: out = linear_te return out def my_softmax(X): N, C = X.shape c = te.reduce_axis((0, C), name=\u0026#34;c\u0026#34;) max_val = te.compute(shape=(N, ), fcompute=lambda i: te.max(X[i, c], axis=c)) exp_te = te.compute(shape=(N, C), fcompute=lambda i, j: te.exp(X[i, j] - max_val[i])) sum_exp_te = te.compute(shape=(N, ), fcompute=lambda i: te.sum(exp_te[i, c], axis=c)) softmax_te = te.compute(shape=(N, C), fcompute=lambda i, j: exp_te[i, j] / sum_exp_te[i]) return softmax_te ç„¶åæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨ BlockBuilderæ„å»ºIRModule\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def create_model_via_emit_te(): batch_size = 4 input_shape = (batch_size, 1, 28, 28) # BCHW bb = relax.BlockBuilder() x = relax.Var(\u0026#34;x\u0026#34;, relax.TensorStructInfo(input_shape, \u0026#34;float32\u0026#34;)) conv2d_weight = relax.const(weight_map[\u0026#34;conv2d_weight\u0026#34;], \u0026#34;float32\u0026#34;) conv2d_bias = relax.const(weight_map[\u0026#34;conv2d_bias\u0026#34;].reshape(1, 32, 1, 1), \u0026#34;float32\u0026#34;) linear0_weight = relax.const(weight_map[\u0026#34;linear0_weight\u0026#34;], \u0026#34;float32\u0026#34;) linear0_bias = relax.const(weight_map[\u0026#34;linear0_bias\u0026#34;].reshape(1, 100), \u0026#34;float32\u0026#34;) linear1_weight = relax.const(weight_map[\u0026#34;linear1_weight\u0026#34;], \u0026#34;float32\u0026#34;) linear1_bias = relax.const(weight_map[\u0026#34;linear1_bias\u0026#34;].reshape(1, 10), \u0026#34;float32\u0026#34;) # Build the model using BlockBuilder with bb.function(\u0026#34;main\u0026#34;, [x]): with bb.dataflow(): gv_conv = bb.emit_te(my_conv2d, x, conv2d_weight, conv2d_bias) gv_relu1 = bb.emit_te(my_relu, gv_conv) gv_pool = bb.emit_te(my_maxpool2d, gv_relu1, 2) gv_flatten = bb.emit_te(my_flatten, gv_pool) gv_dense1 = bb.emit_te(my_linear, gv_flatten, linear0_weight, linear0_bias) gv_relu2 = bb.emit_te(my_relu, gv_dense1) gv_dense2 = bb.emit_te(my_linear, gv_relu2, linear1_weight, linear1_bias) gv_softmax = bb.emit_te(my_softmax, gv_dense2) out = bb.emit_output(gv_softmax) bb.emit_func_output(out) return bb.get() å¾—åˆ°çš„IRModuleçš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 mod = create_model_via_emit_te() exec = relax.build(mod, \u0026#34;llvm\u0026#34;) dev = tvm.cpu() vm = relax.VirtualMachine(exec, dev) print(mod.script()) mod.script 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @I.ir_module class Module: @T.prim_func(private=True) def my_conv2d(x: T.Buffer((T.int64(4), T.int64(1), T.int64(28), T.int64(28)), \u0026#34;float32\u0026#34;), B: T.Buffer((T.int64(32), T.int64(1), T.int64(3), T.int64(3)), \u0026#34;float32\u0026#34;), C: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): conv2d = T.alloc_buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26))) for n, co, oh, ow, k, r, s in T.grid(T.int64(4), T.int64(32), T.int64(26), T.int64(26), T.int64(1), T.int64(3), T.int64(3)): with T.block(\u0026#34;conv2d\u0026#34;): v_n, v_co, v_oh, v_ow, v_k, v_r, v_s = T.axis.remap(\u0026#34;SSSSRRR\u0026#34;, [n, co, oh, ow, k, r, s]) T.reads(x[v_n, v_k, v_oh + v_r, v_ow + v_s], B[v_co, v_k, v_r, v_s]) T.writes(conv2d[v_n, v_co, v_oh, v_ow]) with T.init(): conv2d[v_n, v_co, v_oh, v_ow] = T.float32(0.0) conv2d[v_n, v_co, v_oh, v_ow] = conv2d[v_n, v_co, v_oh, v_ow] + x[v_n, v_k, v_oh + v_r, v_ow + v_s] * B[v_co, v_k, v_r, v_s] for n, co, oh, ow in T.grid(T.int64(4), T.int64(32), T.int64(26), T.int64(26)): with T.block(\u0026#34;compute\u0026#34;): v_n, v_co, v_oh, v_ow = T.axis.remap(\u0026#34;SSSS\u0026#34;, [n, co, oh, ow]) T.reads(conv2d[v_n, v_co, v_oh, v_ow], C[T.int64(0), v_co, T.int64(0), T.int64(0)]) T.writes(compute[v_n, v_co, v_oh, v_ow]) compute[v_n, v_co, v_oh, v_ow] = conv2d[v_n, v_co, v_oh, v_ow] + C[T.int64(0), v_co, T.int64(0), T.int64(0)] @T.prim_func(private=True) def my_flatten(lv2: T.Buffer((T.int64(4), T.int64(32), T.int64(13), T.int64(13)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(4), T.int64(5408)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for n, i in T.grid(T.int64(4), T.int64(5408)): with T.block(\u0026#34;compute\u0026#34;): v_n, v_i = T.axis.remap(\u0026#34;SS\u0026#34;, [n, i]) T.reads(lv2[v_n, v_i // T.int64(169), v_i % T.int64(169) // T.int64(13), v_i % T.int64(13)]) T.writes(compute[v_n, v_i]) compute[v_n, v_i] = lv2[v_n, v_i // T.int64(169), v_i % T.int64(169) // T.int64(13), v_i % T.int64(13)] @T.prim_func(private=True) def my_linear(lv3: T.Buffer((T.int64(4), T.int64(5408)), \u0026#34;float32\u0026#34;), B: T.Buffer((T.int64(100), T.int64(5408)), \u0026#34;float32\u0026#34;), C: T.Buffer((T.int64(1), T.int64(100)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(4), T.int64(100)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): compute_1 = T.alloc_buffer((T.int64(4), T.int64(100))) for i, j, FI in T.grid(T.int64(4), T.int64(100), T.int64(5408)): with T.block(\u0026#34;compute\u0026#34;): v_i, v_j, v_FI = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, FI]) T.reads(lv3[v_i, v_FI], B[v_j, v_FI]) T.writes(compute_1[v_i, v_j]) with T.init(): compute_1[v_i, v_j] = T.float32(0.0) compute_1[v_i, v_j] = compute_1[v_i, v_j] + lv3[v_i, v_FI] * B[v_j, v_FI] for i, j in T.grid(T.int64(4), T.int64(100)): with T.block(\u0026#34;compute_1\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(C[T.int64(0), v_j], compute_1[v_i, v_j]) T.writes(compute[v_i, v_j]) compute[v_i, v_j] = C[T.int64(0), v_j] + compute_1[v_i, v_j] @T.prim_func(private=True) def my_linear1(lv5: T.Buffer((T.int64(4), T.int64(100)), \u0026#34;float32\u0026#34;), B: T.Buffer((T.int64(10), T.int64(100)), \u0026#34;float32\u0026#34;), C: T.Buffer((T.int64(1), T.int64(10)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(4), T.int64(10)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): compute_1 = T.alloc_buffer((T.int64(4), T.int64(10))) for i, j, FI in T.grid(T.int64(4), T.int64(10), T.int64(100)): with T.block(\u0026#34;compute\u0026#34;): v_i, v_j, v_FI = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, FI]) T.reads(lv5[v_i, v_FI], B[v_j, v_FI]) T.writes(compute_1[v_i, v_j]) with T.init(): compute_1[v_i, v_j] = T.float32(0.0) compute_1[v_i, v_j] = compute_1[v_i, v_j] + lv5[v_i, v_FI] * B[v_j, v_FI] for i, j in T.grid(T.int64(4), T.int64(10)): with T.block(\u0026#34;compute_1\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(C[T.int64(0), v_j], compute_1[v_i, v_j]) T.writes(compute[v_i, v_j]) compute[v_i, v_j] = C[T.int64(0), v_j] + compute_1[v_i, v_j] @T.prim_func(private=True) def my_maxpool2d(lv1: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \u0026#34;float32\u0026#34;), maxpool2d: T.Buffer((T.int64(4), T.int64(32), T.int64(13), T.int64(13)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for n, co, oh, ow, i, j in T.grid(T.int64(4), T.int64(32), T.int64(13), T.int64(13), T.int64(2), T.int64(2)): with T.block(\u0026#34;maxpool2d\u0026#34;): v_n, v_co, v_oh, v_ow, v_i, v_j = T.axis.remap(\u0026#34;SSSSRR\u0026#34;, [n, co, oh, ow, i, j]) T.reads(lv1[v_n, v_co, v_oh * T.int64(2) + v_i, v_ow * T.int64(2) + v_j]) T.writes(maxpool2d[v_n, v_co, v_oh, v_ow]) with T.init(): maxpool2d[v_n, v_co, v_oh, v_ow] = T.float32(-340282346638528859811704183484516925440.0) maxpool2d[v_n, v_co, v_oh, v_ow] = T.max(maxpool2d[v_n, v_co, v_oh, v_ow], lv1[v_n, v_co, v_oh * T.int64(2) + v_i, v_ow * T.int64(2) + v_j]) @T.prim_func(private=True) def my_relu(lv: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(4), T.int64(32), T.int64(26), T.int64(26)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1, i2, i3 in T.grid(T.int64(4), T.int64(32), T.int64(26), T.int64(26)): with T.block(\u0026#34;compute\u0026#34;): v_i0, v_i1, v_i2, v_i3 = T.axis.remap(\u0026#34;SSSS\u0026#34;, [i0, i1, i2, i3]) T.reads(lv[v_i0, v_i1, v_i2, v_i3]) T.writes(compute[v_i0, v_i1, v_i2, v_i3]) compute[v_i0, v_i1, v_i2, v_i3] = T.max(lv[v_i0, v_i1, v_i2, v_i3], T.float32(0.0)) @T.prim_func(private=True) def my_relu1(lv4: T.Buffer((T.int64(4), T.int64(100)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(4), T.int64(100)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1 in T.grid(T.int64(4), T.int64(100)): with T.block(\u0026#34;compute\u0026#34;): v_i0, v_i1 = T.axis.remap(\u0026#34;SS\u0026#34;, [i0, i1]) T.reads(lv4[v_i0, v_i1]) T.writes(compute[v_i0, v_i1]) compute[v_i0, v_i1] = T.max(lv4[v_i0, v_i1], T.float32(0.0)) @T.prim_func(private=True) def my_softmax(lv6: T.Buffer((T.int64(4), T.int64(10)), \u0026#34;float32\u0026#34;), compute: T.Buffer((T.int64(4), T.int64(10)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): compute_1 = T.alloc_buffer((T.int64(4),)) compute_2 = T.alloc_buffer((T.int64(4), T.int64(10))) compute_3 = T.alloc_buffer((T.int64(4),)) for i, c in T.grid(T.int64(4), T.int64(10)): with T.block(\u0026#34;compute\u0026#34;): v_i, v_c = T.axis.remap(\u0026#34;SR\u0026#34;, [i, c]) T.reads(lv6[v_i, v_c]) T.writes(compute_1[v_i]) with T.init(): compute_1[v_i] = T.float32(-340282346638528859811704183484516925440.0) compute_1[v_i] = T.max(compute_1[v_i], lv6[v_i, v_c]) for i, j in T.grid(T.int64(4), T.int64(10)): with T.block(\u0026#34;compute_1\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(lv6[v_i, v_j], compute_1[v_i]) T.writes(compute_2[v_i, v_j]) compute_2[v_i, v_j] = T.exp(lv6[v_i, v_j] - compute_1[v_i]) for i, c in T.grid(T.int64(4), T.int64(10)): with T.block(\u0026#34;compute_2\u0026#34;): v_i, v_c = T.axis.remap(\u0026#34;SR\u0026#34;, [i, c]) T.reads(compute_2[v_i, v_c]) T.writes(compute_3[v_i]) with T.init(): compute_3[v_i] = T.float32(0.0) compute_3[v_i] = compute_3[v_i] + compute_2[v_i, v_c] for i, j in T.grid(T.int64(4), T.int64(10)): with T.block(\u0026#34;compute_3\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(compute_2[v_i, v_j], compute_3[v_i]) T.writes(compute[v_i, v_j]) compute[v_i, v_j] = compute_2[v_i, v_j] / compute_3[v_i] @R.function def main(x: R.Tensor((4, 1, 28, 28), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((4, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv = R.call_tir(cls.my_conv2d, (x, metadata[\u0026#34;relax.expr.Constant\u0026#34;][0], metadata[\u0026#34;relax.expr.Constant\u0026#34;][1]), out_sinfo=R.Tensor((4, 32, 26, 26), dtype=\u0026#34;float32\u0026#34;)) lv1 = R.call_tir(cls.my_relu, (lv,), out_sinfo=R.Tensor((4, 32, 26, 26), dtype=\u0026#34;float32\u0026#34;)) lv2 = R.call_tir(cls.my_maxpool2d, (lv1,), out_sinfo=R.Tensor((4, 32, 13, 13), dtype=\u0026#34;float32\u0026#34;)) lv3 = R.call_tir(cls.my_flatten, (lv2,), out_sinfo=R.Tensor((4, 5408), dtype=\u0026#34;float32\u0026#34;)) lv4 = R.call_tir(cls.my_linear, (lv3, metadata[\u0026#34;relax.expr.Constant\u0026#34;][2], metadata[\u0026#34;relax.expr.Constant\u0026#34;][3]), out_sinfo=R.Tensor((4, 100), dtype=\u0026#34;float32\u0026#34;)) lv5 = R.call_tir(cls.my_relu1, (lv4,), out_sinfo=R.Tensor((4, 100), dtype=\u0026#34;float32\u0026#34;)) lv6 = R.call_tir(cls.my_linear1, (lv5, metadata[\u0026#34;relax.expr.Constant\u0026#34;][4], metadata[\u0026#34;relax.expr.Constant\u0026#34;][5]), out_sinfo=R.Tensor((4, 10), dtype=\u0026#34;float32\u0026#34;)) lv7 = R.call_tir(cls.my_softmax, (lv6,), out_sinfo=R.Tensor((4, 10), dtype=\u0026#34;float32\u0026#34;)) gv: R.Tensor((4, 10), dtype=\u0026#34;float32\u0026#34;) = lv7 R.output(gv) return gv æˆ‘ä»¬å¯ä»¥ä¸Pytorchæ¨¡å‹çš„æ‰§è¡Œç»“æœè¿›è¡Œæ¯”è¾ƒæ¥éªŒè¯æ­£ç¡®æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def build_mod(mod): exec = relax.vm.build(mod, \u0026#34;llvm\u0026#34;) dev = tvm.cpu() vm = relax.VirtualMachine(exec, dev) return vm def check_equivalence(mod, torch_model, test_loader): torch_model.eval() with torch.no_grad(): rt_mod = build_mod(mod) for data, label in test_loader: data, label = data.cpu(), label.cpu() output_from_pytorch = torch_model(data).numpy() output_from_relax = rt_mod[\u0026#34;main\u0026#34;](tvm.nd.array(data, tvm.cpu())).numpy() tvm.testing.assert_allclose(output_from_pytorch, output_from_relax, rtol=1e-4) test_data = torchvision.datasets.FashionMNIST( \u0026#34;./data\u0026#34;, download=True, train=False, transform=transforms.Compose([transforms.ToTensor()]) ) test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False) mod = create_model_via_emit_te() torch_model = pytorch_model() check_equivalence(mod, torch_model, test_loader) ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch5/","summary":"Personal notebook 5.","title":"TVM Learning (6)-Exercise of End to End Model Execution"},{"content":"Transform a Primitive Tensor Function ä¹‹å‰å·²ç»è®²è¿‡å¦‚ä½•é€šè¿‡ tir.Scheduleå¯¹T.prim_funcè¿›è¡Œå˜æ¢ï¼Œä»ä»¥çŸ©é˜µä¹˜æ³•ä¸ºä¾‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 @tvm.script.ir_module class MyModule: @T.prim_func def main(A: T.Buffer((128, 128), \u0026#34;float32\u0026#34;), # type: ignore B: T.Buffer((128, 128), \u0026#34;float32\u0026#34;), # type: ignore C: T.Buffer((128, 128), \u0026#34;float32\u0026#34;)): # type: ignore T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i, j, k in T.grid(128, 128, 128): with T.block(\u0026#34;C\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) with T.init(): C[vi, vj] = 0.0 C[vi, vj] += A[vi, vk] * B[vk, vj] å¯¹å…¶è¿›è¡Œ split, reorderå’Œ decompose_reductionå˜æ¢å¾—åˆ°çš„TensorIRå¦‚ä¸‹ã€‚\né€šè¿‡ä»¥ä¸Šå˜æ¢åï¼ŒçŸ©é˜µä¹˜æ³•çš„æ‰§è¡Œæ—¶é—´å‡å°‘æ˜¯ç”±äºï¼š\nå¾ªç¯æ‹†åˆ† (sch.split) ï¼š å°† jå¾ªç¯æ‹†åˆ†æˆäº†ä¸¤ä¸ªå¾ªç¯ï¼šj_0å’Œ j_1ï¼Œå…¶ä¸­ j_1çš„å› å­ä¸º4ï¼ˆå†…å±‚å¾ªç¯ï¼‰ã€‚ æé«˜æ•°æ®çš„å±€éƒ¨æ€§ï¼Œå› ä¸ºè¾ƒå°çš„æ•°æ®å—ä¼šåœ¨æ›´çŸ­çš„æ—¶é—´å†…è¢«é¢‘ç¹è®¿é—®ï¼Œä»è€Œæ›´å¥½åœ°åˆ©ç”¨ç¼“å­˜ã€‚ å¾ªç¯é‡æ’ (sch.reorder) ï¼š å°†å¾ªç¯çš„é¡ºåºè°ƒæ•´ä¸º i, j_0, k, j_1ï¼Œæ„å‘³ç€å¤–å±‚å¾ªç¯å…ˆéå† iå’Œ j_0ï¼Œå†…å±‚å¾ªç¯å†éå† kå’Œ j_1ã€‚ ä¼˜å…ˆè€ƒè™‘äº†æ•°æ®åœ¨å¯„å­˜å™¨æˆ–ç¼“å­˜ä¸­çš„é‡ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨å†…å±‚å¾ªç¯æ“ä½œæœŸé—´ AçŸ©é˜µä¸­çš„å…ƒç´ ã€‚ åˆ†è§£å½’çº¦ (sch.decompose_reduction) ï¼š å°†å¯¹ kçš„å½’çº¦æ“ä½œåˆ†è§£ä¸ºåˆå§‹åŒ–é˜¶æ®µå’Œæ›´æ–°é˜¶æ®µï¼Œæœ‰åŠ©äºå°†è®¡ç®—çš„ä¸¤ä¸ªé˜¶æ®µï¼ˆå³è®¾ç½®åˆå§‹å€¼å’Œå®é™…å½’çº¦ï¼‰åˆ†å¼€ã€‚ æé«˜å¹¶è¡ŒåŒ–çš„æœºä¼šï¼Œå¹¶ä¸”å…è®¸æ›´å¥½åœ°åˆ©ç”¨å‘é‡åŒ–æŒ‡ä»¤æˆ–å…¶ä»–ç¡¬ä»¶ä¼˜åŒ–ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def schedule_mm(sch: tvm.tir.Schedule, jfactor=4): block_C = sch.get_block(\u0026#34;C\u0026#34;, \u0026#34;main\u0026#34;) i, j, k = sch.get_loops(block=block_C) j_0, j_1 = sch.split(loop=j, factors=[None, jfactor]) sch.reorder(i, j_0, k, j_1) sch.decompose_reduction(block_C, k) return sch sch = tvm.tir.Schedule(MyModule) sch = schedule_mm(sch) sch.mod.show() #----------------------------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((128, 128), \u0026#34;float32\u0026#34;), B: T.Buffer((128, 128), \u0026#34;float32\u0026#34;), C: T.Buffer((128, 128), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i, j_0 in T.grid(128, 32): for j_1_init in range(4): with T.block(\u0026#34;C_init\u0026#34;): vi = T.axis.spatial(128, i) vj = T.axis.spatial(128, j_0 * 4 + j_1_init) T.reads() T.writes(C[vi, vj]) C[vi, vj] = T.float32(0.0) for k, j_1 in T.grid(128, 4): with T.block(\u0026#34;C_update\u0026#34;): vi = T.axis.spatial(128, i) vj = T.axis.spatial(128, j_0 * 4 + j_1) vk = T.axis.reduce(128, k) T.reads(C[vi, vj], A[vi, vk], B[vk, vj]) T.writes(C[vi, vj]) C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj] æˆ‘ä»¬å¯ä»¥æ¯”è¾ƒå˜æ¢å‰åçš„è®¡ç®—ç”¨æ—¶\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 a_np = np.random.rand(128, 128).astype(dtype) b_np = np.random.rand(128, 128).astype(dtype) c_mm = a_np @ b_np a_nd = tvm.nd.array(a_np) b_nd = tvm.nd.array(b_np) c_nd = tvm.nd.empty((128, 128), dtype=\u0026#34;float32\u0026#34;) # Before transformation lib = tvm.build(MyModule, target= \u0026#34;llvm\u0026#34;) f_timer_before = lib.time_evaluator(\u0026#34;main\u0026#34;, tvm.cpu()) print(\u0026#34;Time cost of MyModule: %.3f ms\u0026#34; % (f_timer_before(a_nd, b_nd, c_nd).mean * 1000)) #Time cost of MyModule: 1.365 ms # After transformation lib = tvm.build(sch.mod, target=\u0026#34;llvm\u0026#34;) f_timer_after = lib.time_evaluator(\u0026#34;main\u0026#34;, tvm.cpu()) print(\u0026#34;Time cost of MyModule=\u0026gt;schedule_mm: %.3f ms\u0026#34; % (f_timer_after(a_nd, b_nd, c_nd).mean * 1000)) # Time cost of MyModule=\u0026gt;schedule_mm: 1.041 ms Transformation Trace é™¤äº† sch.modå­—æ®µï¼Œtir.Scheduleè¿˜æä¾›äº†ä¸€ä¸ªè·Ÿè¸ªå­—æ®µ sch.traceï¼Œç”¨äºæ˜¾ç¤ºå˜æ¢IRModuleçš„æ­¥éª¤ã€‚\n1 2 3 4 5 6 7 8 print(sch.trace) #------------------------------------------- def apply_trace(sch: tir.Schedule) -\u0026gt; None: b0 = sch.get_block(name=\u0026#34;C\u0026#34;, func_name=\u0026#34;main\u0026#34;) l1, l2, l3 = sch.get_loops(block=b0) l4, l5 = sch.split(loop=l2, factors=[None, 4], preserve_unit_iters=True, disable_predication=False) sch.reorder(l1, l4, l3, l5) b6 = sch.decompose_reduction(block=b0, loop=l3) Stochastic Schedule Transformation åœ¨ä¹‹å‰çš„å˜æ¢ä¸­ï¼Œæˆ‘ä»¬éƒ½æ˜¯æŒ‡å®šè¿™äº›å‡½æ•°çš„è¾“å…¥å‚æ•°ã€‚å®é™…æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥éšæœºæ€§ï¼Œæ ¹æ®ä¸åŒå˜æ¢çš„è¾“å…¥å‚æ•°å¾—å‡ºçš„æ‰§è¡Œæ—¶é—´æ¥é€‰æ‹©æ€§èƒ½æœ€å¥½çš„ä¸€ä¸ªã€‚\nsample_perfect_tileå‡½æ•°å¯ä»¥è®¡ç®—ä»»åŠ¡ä¸­çš„ç‰¹å®šå¾ªç¯é‡‡æ ·æœ€ä¼˜çš„åˆ‡åˆ†ç­–ç•¥ã€‚\nè¾“å…¥å‚æ•°ï¼š\nloopï¼šè¦åˆ‡åˆ†çš„å¾ªç¯ã€‚ nï¼šè¦åˆ‡åˆ†æˆå‡ ä»½ã€‚ max_innermost_factorï¼šå…è®¸åœ¨æœ€å†…å±‚å¾ªç¯ä¸­é‡‡æ ·çš„æœ€å¤§åˆ‡åˆ†å¤§å°ã€‚æ­¤å‚æ•°æœ‰åŠ©äºæ§åˆ¶å¹³é“ºçš„ç²’åº¦ã€‚ decisionï¼šä¸€ä¸ªå¯é€‰çš„æ•´æ•°åˆ—è¡¨ï¼Œè¡¨ç¤ºé¢„å…ˆç¡®å®šçš„åˆ‡åˆ†å†³ç­–ã€‚å¦‚æœæä¾›ï¼Œå‡½æ•°å°†ä½¿ç”¨æ­¤å†³ç­–è€Œä¸æ˜¯é‡‡æ ·ã€‚ ä¸‹é¢å‡½æ•° stochastic_schedule_mmå’Œ schedule_mmå”¯ä¸€çš„åŒºåˆ«æ˜¯æŒ‡å®š j_factorsé‡‡ç”¨çš„æ˜¯éšæœºçš„ç­–ç•¥ã€‚\n1 2 3 4 5 6 7 8 def stochastic_schedule_mm(sch: tvm.tir.Schedule): block_C = sch.get_block(\u0026#34;C\u0026#34;, \u0026#34;main\u0026#34;) i, j, k = sch.get_loops(block=block_C) j_factors = sch.sample_perfect_tile(loop=j, n=2) # tvm.tir.expr.Var j_0, j_1 = sch.split(loop=j, factors=j_factors) sch.reorder(i, j_0, k, j_1) sch.decompose_reduction(block_C, k) return sch å¯ä»¥å‘ç°ï¼Œå®ƒæ˜¯å¯¹åŸæ¥çš„ç¡®å®šæ€§å˜æ¢çš„æ³›åŒ–ç‰ˆæœ¬ï¼Œåªæ˜¯å¤šäº†ä¸¤ä¸ªå…ƒç´ ï¼š\næ¥è‡ª sample_perfect_tile çš„éšæœºå˜é‡ï¼Œä»¥åŠæˆ‘ä»¬åœ¨ç¤ºä¾‹ä¸­æ²¡æœ‰æ¶‰åŠçš„å…¶ä»–é‡‡æ ·æ“ä½œã€‚ æ ¹æ®éšæœºå˜é‡é‡‡å–è¡ŒåŠ¨çš„ scheduleæ“ä½œã€‚ j_factors ä¸­çš„å…ƒç´ ä¸æ˜¯æ•´æ•°ã€‚ç›¸å®ƒä»¬æ˜¯ç¬¦å·å˜é‡ï¼ŒæŒ‡çš„æ˜¯æ­£åœ¨é‡‡æ ·çš„éšæœºå˜é‡ã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™äº›å˜é‡ä¼ é€’ç»™è½¬æ¢ APIï¼Œä»¥æŒ‡å®šfactors. è°ƒç”¨ stochastic_schedule_mmåçš„traceå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 sch = tvm.tir.Schedule(MyModule) sch = stochastic_schedule_mm(sch) print(sch.trace) #------------------------------------------------------ def apply_trace(sch: tir.Schedule) -\u0026gt; None: b0 = sch.get_block(name=\u0026#34;C\u0026#34;, func_name=\u0026#34;main\u0026#34;) l1, l2, l3 = sch.get_loops(block=b0) v4, v5 = sch.sample_perfect_tile(loop=l2, n=2, max_innermost_factor=16, decision=[64, 2]) l6, l7 = sch.split(loop=l2, factors=[v4, v5], preserve_unit_iters=True, disable_predication=False) sch.reorder(l1, l6, l3, l7) b8 = sch.decompose_reduction(block=b0, loop=l3) Search Over Stochastic Transformations stochastic_schedule_mmå®é™…ä¸Šä¼šæ ¹æ®æ¯ä¸ªé‡‡æ ·æ­¥éª¤çš„å®é™…å†³å®šï¼Œåˆ›å»ºä¸€ä¸ªç¨‹åºçš„æœç´¢ç©ºé—´ã€‚\nTransformation Search Space\næˆ‘ä»¬éœ€è¦ä¸€ç§æœç´¢ç®—æ³•èƒ½æ‰¾åˆ°æ€§èƒ½æœ€å¥½çš„å˜æ¢ã€‚ä¸‹é¢çš„å‡½æ•°ä½¿ç”¨æœ€ç›´æ¥çš„æœç´¢ç®—æ³•\u0026ndash;éšæœºæœç´¢ã€‚å®ƒå°è¯•é‡å¤è¿è¡Œ stochastic_schedule_mmï¼Œå¾—åˆ°ä¸€ä¸ªè½¬æ¢åçš„IR moduleï¼Œè¿è¡Œbenchmarkï¼Œç„¶åå°†æ€§èƒ½æœ€å¥½çš„IR moduleè®°å½•ä¸‹æ¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def random_search(mod: tvm.IRModule, num_trails=5): best_result = None best_sch = False for i in range(num_trails): sch = stochastic_schedule_mm(tvm.tir.Schedule(mod)) lib = tvm.build(sch.mod, target=\u0026#34;llvm\u0026#34;) f_timer_after = lib.time_evaluator(\u0026#34;main\u0026#34;, tvm.cpu()) result = f_timer_after(a_nd, b_nd, c_nd).mean print(\u0026#34;=====Attempt %d, time-cost: %.3f ms====\u0026#34; % (i, result * 1000)) print(sch.trace) # book keep the best result so far if best_result is None or result \u0026lt; best_result: best_result = result best_sch = sch return best_sch å®é™…æƒ…å†µä¸‹ä¼šä½¿ç”¨æ›´é«˜çº§çš„ç®—æ³•ã€‚è¿˜éœ€è¦æä¾›é¢å¤–çš„å·¥å…·ï¼Œä¾‹å¦‚åœ¨è¿œç¨‹è®¾å¤‡ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ç­‰ã€‚TVM çš„ meta_schedule API æä¾›äº†è¿™äº›åŠŸèƒ½ã€‚\nmeta_scheduleæ˜¯ä¸€ä¸ªå‘½åç©ºé—´ï¼Œç”¨äºæ”¯æŒåœ¨å¯èƒ½çš„å˜æ¢ç©ºé—´ä¸­è¿›è¡Œæœç´¢ã€‚\nè·¨å¤šä¸ªè¿›ç¨‹çš„å¹¶è¡ŒåŸºå‡†æµ‹è¯•ã€‚ ä½¿ç”¨ cost modelï¼Œé¿å…æ¯æ¬¡éƒ½è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚ åœ¨ trace ä¸Šè¿›è¡Œè¿›åŒ–æœç´¢ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½éšæœºå–æ ·ã€‚ tune_tir API ä»ä½¿ç”¨éšæœºå˜æ¢æ¥æŒ‡å®šå¥½ç¨‹åºçš„æœç´¢ç©ºé—´å¹¶åœ¨æœç´¢ç©ºé—´å†…æ‰¾åˆ°ä¼˜åŒ–çš„æ–¹æ¡ˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 database = ms.tune_tir( mod=MyModule, target=\u0026#34;llvm --num-cores=1\u0026#34;, max_trials_global=64, num_trials_per_iter=64, space=ms.space_generator.ScheduleFn(stochastic_schedule_mm), work_dir=\u0026#34;./tune_tmp\u0026#34;, task_name=\u0026#34;main\u0026#34; ) sch_tuned = ms.tir_integration.compile_tir(database, MyModule, target=\u0026#34;llvm --num-cores=1\u0026#34;) print(sch_tuned.trace) clang error on Windows ä¸çŸ¥é“ä¸ºä½•Windowsä¸Šè¿è¡Œclangä¼šå‡ºé”™\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 LocalRunner: An exception occurred Traceback (most recent call last): File \u0026#34;D:\\Work\\Anaconda\\envs\\tvm-build\\lib\\site-packages\\tvm-0.18.dev0-py3.9-win-amd64.egg\\tvm\\exec\\popen_worker.py\u0026#34;, line 87, in main result = fn(*args, **kwargs) File \u0026#34;D:\\Work\\Anaconda\\envs\\tvm-build\\lib\\site-packages\\tvm-0.18.dev0-py3.9-win-amd64.egg\\tvm\\meta_schedule\\runner\\local_runner.py\u0026#34;, line 148, in _worker_func rt_mod = tvm.runtime.load_module(artifact_path) File \u0026#34;D:\\Work\\Anaconda\\envs\\tvm-build\\lib\\site-packages\\tvm-0.18.dev0-py3.9-win-amd64.egg\\tvm\\runtime\\module.py\u0026#34;, line 696, in load_module _cc.create_shared(path + \u0026#34;.so\u0026#34;, files) File \u0026#34;D:\\Work\\Anaconda\\envs\\tvm-build\\lib\\site-packages\\tvm-0.18.dev0-py3.9-win-amd64.egg\\tvm\\contrib\\cc.py\u0026#34;, line 96, in create_shared _windows_compile(output, objects, options, cwd, ccache_env) File \u0026#34;D:\\Work\\Anaconda\\envs\\tvm-build\\lib\\site-packages\\tvm-0.18.dev0-py3.9-win-amd64.egg\\tvm\\contrib\\cc.py\u0026#34;, line 415, in _windows_compile raise RuntimeError(msg) RuntimeError: Compilation error: clang -O2 -shared -o C:\\Users\\17725\\AppData\\Local\\Temp\\tmp96lbzaxg\\tvm_tmp_mod.tar.so C:\\Users\\17725\\AppData\\Local\\Temp\\tmp96lbzaxg\\tvm_tmp_mod\\lib0.o ld.lld: error: undefined symbol: _fltused \u0026gt;\u0026gt;\u0026gt; referenced by C:\\Users\\17725\\AppData\\Local\\Temp\\tmp96lbzaxg\\tvm_tmp_mod\\lib0.o clang: error: linker command failed with exit code 1 (use -v to see invocation) ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch4/","summary":"Personal notebook 4.","title":"TVM Learning (5)-Automatic Program Optimization"},{"content":"E2E Model Integration æˆ‘ä»¬ä»¥ä¸‹å›¾ä¸­çš„ MLP ç½‘ç»œä¸ºä¾‹ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤å±‚å…¨è¿æ¥ç½‘ç»œï¼Œå¹¶ä¸”çœç•¥äº†æœ€åçš„ Softmax å±‚ã€‚\nMLP Model\nåˆ©ç”¨é«˜çº§Numpyçš„å®ç°å¦‚ä¸‹\n1 2 3 4 5 def numpy_mlp(data, w0, b0, w1, b1): lv0 = data @ w0.T + b0 lv1 = np.maximum(lv0, 0) lv2 = lv1 @ w1.T + b1 return lv2 ä¸ºäº†æ–¹ä¾¿è¯´æ˜åº•å±‚è®¡ç®—è¿‡ç¨‹ï¼Œç”¨ Low-level Numpy è¿›è¡Œé‡å†™åå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def lnumpy_linear0(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray): Y = np.empty((1, 128), dtype=\u0026#34;float32\u0026#34;) for i in range(1): for j in range(128): for k in range(784): if k == 0: Y[i, j] = 0 Y[i, j] = Y[i, j] + X[i, k] * W[j, k] for i in range(1): for j in range(128): Z[i, j] = Y[i, j] + B[j] def lnumpy_relu0(X: np.ndarray, Y: np.ndarray): for i in range(1): for j in range(128): Y[i, j] = np.maximum(X[i, j], 0) def lnumpy_linear1(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray): Y = np.empty((1, 10), dtype=\u0026#34;float32\u0026#34;) for i in range(1): for j in range(10): for k in range(128): if k == 0: Y[i, j] = 0 Y[i, j] = Y[i, j] + X[i, k] * W[j, k] for i in range(1): for j in range(10): Z[i, j] = Y[i, j] + B[j] def lnumpy_mlp(data, w0, b0, w1, b1): lv0 = np.empty((1, 128), dtype=\u0026#34;float32\u0026#34;) lnumpy_linear0(data, w0, b0, lv0) lv1 = np.empty((1, 128), dtype=\u0026#34;float32\u0026#34;) lnumpy_relu0(lv0, lv1) out = np.empty((1, 10), dtype=\u0026#34;float32\u0026#34;) lnumpy_linear1(lv1, w1, b1, out) return out Constructing an E2E IRModule in TVMScript åŒæ ·å¯ä»¥ç”¨ TVMScript æ„å»ºè¿™ä¸ªç½‘ç»œçš„ IRModuleï¼Œåªä¸è¿‡è¿™æ¬¡é™¤äº†è¦ç”¨ Primitive Tensor Function (@T.prim_function) è¿˜è¦ç”¨ Relax Function (@R.function) æ¥æŠ½è±¡ç¥ç»ç½‘ç»œçš„è®¡ç®—è¿‡ç¨‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @tvm.script.ir_module class MyModule: @T.prim_func def relu0(X: T.Buffer((1, 128), \u0026#34;float32\u0026#34;), Y: T.Buffer((1, 128), \u0026#34;float32\u0026#34;)): # function attr dict T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;relu0\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i, j in T.grid(1, 128): with T.block(\u0026#34;Y\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) Y[vi, vj] = T.max(X[vi, vj], T.float32(0)) @T.prim_func def linear0(X: T.Buffer((1, 784), \u0026#34;float32\u0026#34;), W: T.Buffer((128, 784), \u0026#34;float32\u0026#34;), B: T.Buffer((128,), \u0026#34;float32\u0026#34;), Z: T.Buffer((1, 128), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;linear0\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) Y = T.alloc_buffer((1, 128), \u0026#34;float32\u0026#34;) for i, j, k in T.grid(1, 128, 784): with T.block(\u0026#34;Y\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) with T.init(): Y[vi, vj] = T.float32(0) Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk] for i, j in T.grid(1, 128): with T.block(\u0026#34;Z\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) Z[vi, vj] = Y[vi, vj] + B[vj] @T.prim_func def linear1(X: T.Buffer((1, 128), \u0026#34;float32\u0026#34;), W: T.Buffer((10, 128), \u0026#34;float32\u0026#34;), B: T.Buffer((10,), \u0026#34;float32\u0026#34;), Z: T.Buffer((1, 10), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;linear1\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) Y = T.alloc_buffer((1, 10), \u0026#34;float32\u0026#34;) for i, j, k in T.grid(1, 10, 128): with T.block(\u0026#34;Y\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) with T.init(): Y[vi, vj] = T.float32(0) Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk] for i, j in T.grid(1, 10): with T.block(\u0026#34;Z\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) Z[vi, vj] = Y[vi, vj] + B[vj] @R.function def main(x: R.Tensor((1, 784), \u0026#34;float32\u0026#34;), w0: R.Tensor((128, 784), \u0026#34;float32\u0026#34;), b0: R.Tensor((128,), \u0026#34;float32\u0026#34;), w1: R.Tensor((10, 128), \u0026#34;float32\u0026#34;), b1: R.Tensor((10,), \u0026#34;float32\u0026#34;)): with R.dataflow(): cls = MyModule lv0 = R.call_tir(cls.linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv1 = R.call_tir(cls.relu0, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) out = R.call_tir(cls.linear1, (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) R.output(out) return out Computational Graph View è¯¥ç½‘ç»œçš„è®¡ç®—å›¾å¦‚ä¸‹ï¼Œè®¡ç®—å›¾é€šå¸¸å…·æœ‰ä»¥ä¸‹æ€§è´¨ï¼š\næ¡†çš„æ¯ä¸ªè¾“å…¥è¾¹å¯¹åº”äºæ“ä½œçš„è¾“å…¥ï¼› æ¯ä¸ªå‡ºè¾¹å¯¹åº”äºæ“ä½œçš„è¾“å‡ºï¼› å¯ä»¥ä»»æ„è°ƒæ•´æ“ä½œçš„é¡ºåºï¼Œåªè¦ä¿è¯è¾¹çš„æ‹“æ‰‘æ’åºï¼ˆTopological Orderï¼‰æ²¡æœ‰æ”¹å˜ã€‚ Topological Order æ‹“æ‰‘æ’åºæ˜¯é’ˆå¯¹æœ‰å‘æ— ç¯å›¾ (DAG) çš„ä¸€ç§æ’åºç®—æ³•ï¼Œå®ƒå°†å›¾ä¸­çš„èŠ‚ç‚¹æ’æˆä¸€ä¸ªçº¿æ€§åºåˆ—ï¼Œæ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š\nå¯¹äºå›¾ä¸­çš„ä»»æ„ä¸€æ¡è¾¹ (u, v)ï¼ŒèŠ‚ç‚¹ u åœ¨æ’åºä¸­éƒ½å‡ºç°åœ¨èŠ‚ç‚¹ v ä¹‹å‰ã€‚ Example DAG\nè¿›è¡Œæ‹“æ‰‘æ’åºè¾ƒå¸¸ç”¨çš„æ–¹æ³•ï¼š\nä» DAG å›¾ä¸­é€‰æ‹©ä¸€ä¸ª æ²¡æœ‰å‰é©±ï¼ˆå³å…¥åº¦ä¸º0ï¼‰çš„é¡¶ç‚¹å¹¶è¾“å‡ºã€‚ ä»å›¾ä¸­åˆ é™¤è¯¥é¡¶ç‚¹å’Œæ‰€æœ‰ä»¥å®ƒä¸ºèµ·ç‚¹çš„æœ‰å‘è¾¹ã€‚ é‡å¤ 1 å’Œ 2 ç›´åˆ°å½“å‰çš„ DAG å›¾ä¸ºç©ºæˆ– å½“å‰å›¾ä¸­ä¸å­˜åœ¨æ— å‰é©±çš„é¡¶ç‚¹ä¸ºæ­¢ ã€‚åä¸€ç§æƒ…å†µè¯´æ˜æœ‰å‘å›¾ä¸­å¿…ç„¶å­˜åœ¨ç¯ã€‚ Topological Sort Algorithm\nComputational Graph View\nR.call_tir R.call_tir æ­£å¦‚åå­—ä¸€æ ·è°ƒç”¨ä¸€ä¸ª T.prim_func å¹¶è¿”å›è®¡ç®—ç»“æœã€‚å®ƒçš„è¡Œä¸ºç”¨Numpyè¡¨ç¤ºå¦‚ä¸‹ï¼Œå…ˆæ ¹æ® shapeå’Œ dtypeå¼€è¾Ÿè¾“å‡ºæ•°æ®çš„å†…å­˜ç©ºé—´ï¼Œç„¶åè°ƒç”¨å‡½æ•°ï¼Œæœ€åè¿”å›è¾“å‡ºç»“æœã€‚R.call_tirå‡½æ•°çš„è¾“å…¥æ˜¯è¿™ç§å½¢å¼çš„åŸå› æ˜¯ T.prim_funcå‡½æ•°çš„è¾“å…¥éœ€è¦æˆ‘ä»¬å…ˆä¸ºè¾“å‡ºç»“æœå¼€è¾Ÿå†…å­˜ï¼Œç§°ä¸º ç›®æ ‡ä¼ é€’ (destination passing) ã€‚\n1 2 3 4 def lnumpy_call_tir(prim_func, inputs, shape, dtype): res = np.empty(shape, dtype=dtype) prim_func(*inputs, res) return res ä¸ºäº†è®©ç¨‹åºæ‰§è¡Œå…·æœ‰è®¡ç®—å›¾çš„æ€§è´¨ï¼Œæˆ‘ä»¬é‡‡ç”¨è¿™ç§æ–¹å¼è¿›è¡Œè°ƒç”¨\n1 2 3 4 5 def lnumpy_mlp_with_call_tir(data, w0, b0, w1, b1): lv0 = lnumpy_call_tir(lnumpy_linear0, (data, w0, b0), (1, 128), dtype=\u0026#34;float32\u0026#34;) lv1 = lnumpy_call_tir(lnumpy_relu0, (lv0, ), (1, 128), dtype=\u0026#34;float32\u0026#34;) out = lnumpy_call_tir(lnumpy_linear1, (lv1, w1, b1), (1, 10), dtype=\u0026#34;float32\u0026#34;) return out Dataflow Block ç†æƒ³æƒ…å†µä¸‹ï¼Œè®¡ç®—å›¾ä¸­çš„æ“ä½œåº”ä¸º side-effect freeï¼Œå³ä¸€ä¸ªå‡½æ•°åªä»å…¶è¾“å…¥ä¸­è¯»å–å¹¶é€šè¿‡å…¶è¾“å‡ºè¿”å›ç»“æœï¼Œä¸ä¼šæ”¹å˜ç¨‹åºçš„å…¶ä»–éƒ¨åˆ†ï¼ˆä¾‹å¦‚é€’å¢å…¨å±€è®¡æ•°å™¨ï¼‰ã€‚å¦‚æœè¦å¼•å…¥åŒ…å« side-effect çš„æ“ä½œï¼Œå°±éœ€è¦å®šä¹‰å¤šä¸ªdataflow blockï¼Œåœ¨ä»–ä»¬ä¹‹å¤–æˆ–è€…ä¹‹é—´è¿›è¡Œæ“ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @R.function def main(x: Tensor((1, 784), \u0026#34;float32\u0026#34;), w0: Tensor((128, 784), \u0026#34;float32\u0026#34;), b0: Tensor((128,), \u0026#34;float32\u0026#34;), w1: Tensor((10, 128), \u0026#34;float32\u0026#34;), b1: Tensor((10,), \u0026#34;float32\u0026#34;)): with R.dataflow(): lv0 = R.call_tir(cls.linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) gv0 = R.call_tir(cls.relu0, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) R.output(gv0) gv1 = R.alloc_tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) # side-effect operation with R.dataflow(): out = R.call_tir(cls.linear1, (gv0, gv1, b0), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) R.output(out) return out Build and Run the Model è¯¥ç½‘ç»œå¯¹åº”çš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @I.ir_module class Module: @T.prim_func def linear0( X: T.Buffer((1, 784), \u0026#34;float32\u0026#34;), W: T.Buffer((128, 784), \u0026#34;float32\u0026#34;), B: T.Buffer((128,), \u0026#34;float32\u0026#34;), Z: T.Buffer((1, 128), \u0026#34;float32\u0026#34;), ): T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;linear0\u0026#34;, \u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): Y = T.alloc_buffer((1, 128)) for i, j, k in T.grid(1, 128, 784): with T.block(\u0026#34;Y\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) T.reads(X[vi, vk], W[vj, vk]) T.writes(Y[vi, vj]) with T.init(): Y[vi, vj] = T.float32(0) Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk] for i, j in T.grid(1, 128): with T.block(\u0026#34;Z\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(Y[vi, vj], B[vj]) T.writes(Z[vi, vj]) Z[vi, vj] = Y[vi, vj] + B[vj] @T.prim_func def linear1( X: T.Buffer((1, 128), \u0026#34;float32\u0026#34;), W: T.Buffer((10, 128), \u0026#34;float32\u0026#34;), B: T.Buffer((10,), \u0026#34;float32\u0026#34;), Z: T.Buffer((1, 10), \u0026#34;float32\u0026#34;), ): T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;linear1\u0026#34;, \u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): Y = T.alloc_buffer((1, 10)) for i, j, k in T.grid(1, 10, 128): with T.block(\u0026#34;Y\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) T.reads(X[vi, vk], W[vj, vk]) T.writes(Y[vi, vj]) with T.init(): Y[vi, vj] = T.float32(0) Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk] for i, j in T.grid(1, 10): with T.block(\u0026#34;Z\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(Y[vi, vj], B[vj]) T.writes(Z[vi, vj]) Z[vi, vj] = Y[vi, vj] + B[vj] @T.prim_func def relu0(X: T.Buffer((1, 128), \u0026#34;float32\u0026#34;), Y: T.Buffer((1, 128), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;relu0\u0026#34;, \u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i, j in T.grid(1, 128): with T.block(\u0026#34;Y\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(X[vi, vj]) T.writes(Y[vi, vj]) Y[vi, vj] = T.max(X[vi, vj], T.float32(0)) @R.function def main( x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;), w0: R.Tensor((128, 784), dtype=\u0026#34;float32\u0026#34;), b0: R.Tensor((128,), dtype=\u0026#34;float32\u0026#34;), w1: R.Tensor((10, 128), dtype=\u0026#34;float32\u0026#34;), b1: R.Tensor((10,), dtype=\u0026#34;float32\u0026#34;), ) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv0 = R.call_tir(cls.linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv1 = R.call_tir(cls.relu0, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) out = R.call_tir(cls.linear1, (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) R.output(out) return out æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢æ–¹å¼æ¥æ„é€  virtual machine. relax.buildè¿”å›ä¸€ä¸ª tvm.relax.Executableå¯¹è±¡ï¼Œç„¶åå°±å¯ä»¥åœ¨æŒ‡å®šçš„ç¡¬ä»¶ä¸Šåˆ›å»ºvirtual machine æ¥æ‰§è¡Œè®¡ç®—å›¾ã€‚\n1 2 3 4 5 6 7 8 ex = relax.build(MyModule, target=\u0026#34;llvm\u0026#34;) vm = relax.VirtualMachine(ex, tvm.cpu()) nd_res = vm[\u0026#34;main\u0026#34;](data_nd, nd_params[\u0026#34;w0\u0026#34;], nd_params[\u0026#34;b0\u0026#34;], nd_params[\u0026#34;w1\u0026#34;], nd_params[\u0026#34;b1\u0026#34;]) Integrate Existing Libraries in the Environment é™¤äº†ç”¨ T.prim_funcæ„é€ RelaxIRï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä»ç°æœ‰çš„æ·±åº¦å­¦ä¹ åº“çš„å‡½æ•°æ¥æ„é€ ã€‚\nè¿™æ˜¯é€šè¿‡ R.call_dps_packedæ¥å®Œæˆçš„ï¼Œå®ƒç”¨äºè°ƒç”¨ä¸€ä¸ªç›®æ ‡ä¼ é€’é£æ ¼ (Destination-Passing Style) çš„æ‰“åŒ…å‡½æ•° (Packed Function)ï¼Œå¹¶è¿”å›è¾“å‡ºç»“æœã€‚\nç›®æ ‡ä¼ é€’é£æ ¼ (Destination-Passing Style): ç›®æ ‡ä¼ é€’é£æ ¼æ˜¯ä¸€ç§å‡½æ•°è°ƒç”¨æ–¹å¼ï¼Œå…¶ä¸­å‡½æ•°çš„è¾“å‡ºå‚æ•°ä½œä¸ºå‡½æ•°å‚æ•°ä¼ é€’ç»™å‡½æ•°ã€‚ æ‰“åŒ…å‡½æ•° (Packed Function): æ‰“åŒ…å‡½æ•°æ˜¯ä¸€ç§å‡½æ•°ï¼Œå…¶è¾“å…¥å‚æ•°å’Œè¾“å‡ºå‚æ•°éƒ½è¢«æ‰“åŒ…æˆä¸€ä¸ªç»“æ„ä½“ã€‚ çº¯å‡½æ•° (Pure Function): çº¯å‡½æ•°æ˜¯æŒ‡ä¸äº§ç”Ÿå‰¯ä½œç”¨çš„å‡½æ•°ï¼Œå³å‡½æ•°çš„æ‰§è¡Œç»“æœåªä¾èµ–äºè¾“å…¥å‚æ•°ï¼Œå¹¶ä¸”ä¸ä¼šä¿®æ”¹ä»»ä½•å…¨å±€çŠ¶æ€ã€‚\nç¤ºä¾‹ï¼š\n1 R.call_dps_packed(\u0026#34;env.linear\u0026#34;, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) å‡½æ•°å‚æ•°ï¼š\nfunc: å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–è¡¨è¾¾å¼ï¼Œè¡¨ç¤ºç›®æ ‡ä¼ é€’é£æ ¼çš„å‡½æ•°ã€‚å¦‚æœ func æ˜¯å­—ç¬¦ä¸²ï¼Œå®ƒå°†è¢«è½¬æ¢ä¸º ExternFunc å¯¹è±¡ã€‚ args: è¡¨è¾¾å¼ï¼Œè¡¨ç¤ºè¾“å…¥å‚æ•°ã€‚å¦‚æœ args æ˜¯å•ä¸ªè¡¨è¾¾å¼ï¼Œå®ƒå°†è¢«åŒ…è£…æˆä¸€ä¸ª RxTuple å¯¹è±¡ã€‚ out_sinfo: å¯ä»¥æ˜¯ TensorStructInfo å¯¹è±¡æˆ– TensorStructInfo å¯¹è±¡åˆ—è¡¨ï¼Œè¡¨ç¤º call_dps_packed å‡½æ•°è¾“å‡ºçš„ç»“æ„ä¿¡æ¯ã€‚æ¯ä¸ª TensorStructInfo å¯¹è±¡è¡¨ç¤ºä¸€ä¸ªè¿”å›çš„å¼ é‡çš„ç»“æ„ä¿¡æ¯ã€‚ å‡½æ•°è¿”å›å€¼ï¼š\nret: Call å¯¹è±¡ï¼Œè¡¨ç¤º call_dps_packed æ“ä½œç¬¦çš„è°ƒç”¨èŠ‚ç‚¹ã€‚ Registering Runtime Function ä¸ºäº†èƒ½å¤Ÿæ‰§è¡Œè°ƒç”¨å¤–éƒ¨å‡½æ•°çš„ä»£ç ï¼Œæˆ‘ä»¬éœ€è¦æ³¨å†Œç›¸åº”çš„å‡½æ•°ã€‚ä¸‹é¢è¿™æ®µä»£ç æ³¨å†Œäº†ä¸¤ä¸ªè‡ªå®šä¹‰å‡½æ•°ï¼Œåˆ†åˆ«ç”¨äºå®ç°çº¿æ€§å±‚å’Œ ReLU æ¿€æ´»å‡½æ•°ã€‚\n@tvm.register_func(\u0026quot;env.linear\u0026quot;, override=True): ä½¿ç”¨ @tvm.register_func è£…é¥°å™¨å°† torch_linear å‡½æ•°æ³¨å†Œä¸ºåä¸º \u0026quot;env.linear\u0026quot; çš„ TVM å‡½æ•°ã€‚ override=True è¡¨ç¤ºå¦‚æœå·²ç»å­˜åœ¨åŒåå‡½æ•°ï¼Œåˆ™è¦†ç›–å®ƒã€‚ torch_linear(x: tvm.nd.NDArray, w: tvm.nd.NDArray, b: tvm.nd.NDArray, out: tvm.nd.NDArray): è¯¥å‡½æ•°æ¥å—å››ä¸ªå‚æ•°ï¼š x: è¾“å…¥å¼ é‡ã€‚ w: æƒé‡å¼ é‡ã€‚ b: åç½®å¼ é‡ã€‚ out: è¾“å‡ºå¼ é‡ã€‚ å‡½æ•°å†…éƒ¨ï¼š ä½¿ç”¨ torch.from_dlpack å°† TVM çš„ NDArray å¯¹è±¡è½¬æ¢ä¸º PyTorch çš„ Tensor å¯¹è±¡ã€‚ ä½¿ç”¨ PyTorch çš„ torch.mm å‡½æ•°è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œå°† x å’Œ w çš„è½¬ç½®ç›¸ä¹˜ï¼Œå¹¶å°†ç»“æœå†™å…¥ outã€‚ ä½¿ç”¨ PyTorch çš„ torch.add å‡½æ•°å°† b åŠ åˆ° out ä¸Šã€‚ @tvm.register_func(\u0026quot;env.relu\u0026quot;, override=True): ä½¿ç”¨ @tvm.register_func è£…é¥°å™¨å°† lnumpy_relu å‡½æ•°æ³¨å†Œä¸ºåä¸º \u0026quot;env.relu\u0026quot; çš„ TVM å‡½æ•°ã€‚ override=True è¡¨ç¤ºå¦‚æœå·²ç»å­˜åœ¨åŒåå‡½æ•°ï¼Œåˆ™è¦†ç›–å®ƒã€‚ lnumpy_relu(x: tvm.nd.NDArray, out: tvm.nd.NDArray): è¯¥å‡½æ•°æ¥å—ä¸¤ä¸ªå‚æ•°ï¼š x: è¾“å…¥å¼ é‡ã€‚ out: è¾“å‡ºå¼ é‡ã€‚ å‡½æ•°å†…éƒ¨ï¼š ä½¿ç”¨ torch.from_dlpack å°† TVM çš„ NDArray å¯¹è±¡è½¬æ¢ä¸º PyTorch çš„ Tensor å¯¹è±¡ã€‚ ä½¿ç”¨ PyTorch çš„ torch.maximum å‡½æ•°è®¡ç®— x å’Œ 0 ä¹‹é—´çš„æœ€å¤§å€¼ï¼Œå¹¶å°†ç»“æœå†™å…¥ outã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @tvm.register_func(\u0026#34;env.linear\u0026#34;, override=True) def torch_linear(x: tvm.nd.NDArray, w: tvm.nd.NDArray, b: tvm.nd.NDArray, out: tvm.nd.NDArray): x_torch = torch.from_dlpack(x) w_torch = torch.from_dlpack(w) b_torch = torch.from_dlpack(b) out_torch = torch.from_dlpack(out) torch.mm(x_torch, w_torch.T, out=out_torch) torch.add(out_torch, b_torch, out=out_torch) @tvm.register_func(\u0026#34;env.relu\u0026#34;, override=True) def lnumpy_relu(x: tvm.nd.NDArray, out: tvm.nd.NDArray): x_torch = torch.from_dlpack(x) out_torch = torch.from_dlpack(out) torch.maximum(x_torch, torch.Tensor([0.0]), out=out_torch) ç„¶åæˆ‘ä»¬å°±å¯ä»¥åˆ›å»ºIRModuleå¹¶é€šè¿‡ä¸Šä¸€èŠ‚æ‰€è¯´æ–¹æ³•å» build and run.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @tvm.script.ir_module class MyModuleWithExternCall: @R.function def main(x: R.Tensor((1, 784), \u0026#34;float32\u0026#34;), w0: R.Tensor((128, 784), \u0026#34;float32\u0026#34;), b0: R.Tensor((128,), \u0026#34;float32\u0026#34;), w1: R.Tensor((10, 128), \u0026#34;float32\u0026#34;), b1: R.Tensor((10,), \u0026#34;float32\u0026#34;)): # block 0 with R.dataflow(): lv0 = R.call_dps_packed(\u0026#34;env.linear\u0026#34;, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv1 = R.call_dps_packed(\u0026#34;env.relu\u0026#34;, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) out = R.call_dps_packed(\u0026#34;env.linear\u0026#34;, (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) R.output(out) return out ex = relax.build(MyModuleWithExternCall, target=\u0026#34;llvm\u0026#34;) vm = relax.VirtualMachine(ex, tvm.cpu()) Mixing TensorIR Code and Libraries æˆ‘ä»¬å¯ä»¥æ··åˆä½¿ç”¨T.prim_funcå’Œ æ³¨å†Œçš„ runtime å‡½æ•°æ¥åˆ›å»º RelaxIR. ä»¥ä¸‹ä»£ç å±•ç¤ºäº†ä¸€ä¸ªä¾‹å­ï¼Œå…¶ä¸­ linear0 ä»åœ¨ TensorIR ä¸­å®ç°ï¼Œè€Œå…¶ä»–å‡½æ•°åˆ™è¢«é‡å®šå‘åˆ°åº“å‡½æ•°ä¸­ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @tvm.script.ir_module class MyModuleMixture: @T.prim_func def linear0(X: T.Buffer((1, 784), \u0026#34;float32\u0026#34;), W: T.Buffer((128, 784), \u0026#34;float32\u0026#34;), B: T.Buffer((128,), \u0026#34;float32\u0026#34;), Z: T.Buffer((1, 128), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;linear0\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) Y = T.alloc_buffer((1, 128), \u0026#34;float32\u0026#34;) for i, j, k in T.grid(1, 128, 784): with T.block(\u0026#34;Y\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) with T.init(): Y[vi, vj] = T.float32(0) Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk] for i, j in T.grid(1, 128): with T.block(\u0026#34;Z\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) Z[vi, vj] = Y[vi, vj] + B[vj] @R.function def main(x: R.Tensor((1, 784), \u0026#34;float32\u0026#34;), w0: R.Tensor((128, 784), \u0026#34;float32\u0026#34;), b0: R.Tensor((128,), \u0026#34;float32\u0026#34;), w1: R.Tensor((10, 128), \u0026#34;float32\u0026#34;), b1: R.Tensor((10,), \u0026#34;float32\u0026#34;)): with R.dataflow(): cls = MyModuleMixture lv0 = R.call_tir(cls.linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv1 = R.call_dps_packed(\u0026#34;env.relu\u0026#34;, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) out = R.call_dps_packed(\u0026#34;env.linear\u0026#34;, (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) R.output(out) return out Bind Parameters to IRModule ä¹‹å‰éƒ½æ˜¯é€šè¿‡æ˜¾ç¤ºä¼ é€’å‚æ•°ç»™ vm[\u0026quot;main\u0026quot;]å‡½æ•°æ¥è°ƒç”¨ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å°†å‚æ•°å½“ä½œå¸¸ç†Ÿä¸IRModuleè¿›è¡Œç»‘å®šã€‚\nmetadata[\u0026quot;relax.expr.Constant\u0026quot;]å¯¹åº”çš„æ˜¯å­˜å‚¨å¸¸é‡çš„éšå¼å­—å…¸ï¼ˆè™½ç„¶æ²¡æœ‰æ˜¾ç¤ºåœ¨è„šæœ¬ä¸­ï¼Œä½†ä»æ˜¯ IRModule çš„ä¸€éƒ¨åˆ†ï¼‰ã€‚æ„å»ºäº†è½¬æ¢åçš„ IRModuleï¼Œç°åœ¨åªéœ€è¾“å…¥æ•°æ®å°±å¯ä»¥è°ƒç”¨å‡½æ•°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 MyModuleWithParams = relax.transform.BindParams(\u0026#34;main\u0026#34;, nd_params)(MyModuleMixture) MyModuleWithParams.show() #------------------------------------- @I.ir_module class Module: @T.prim_func def linear0(X: T.Buffer((1, 784), \u0026#34;float32\u0026#34;), W: T.Buffer((128, 784), \u0026#34;float32\u0026#34;), B: T.Buffer((128,), \u0026#34;float32\u0026#34;), Z: T.Buffer((1, 128), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): Y = T.alloc_buffer((1, 128)) for i, j, k in T.grid(1, 128, 784): with T.block(\u0026#34;Y\u0026#34;): vi, vj, vk = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) T.reads(X[vi, vk], W[vj, vk]) T.writes(Y[vi, vj]) with T.init(): Y[vi, vj] = T.float32(0.0) Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk] for i, j in T.grid(1, 128): with T.block(\u0026#34;Z\u0026#34;): vi, vj = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(Y[vi, vj], B[vj]) T.writes(Z[vi, vj]) Z[vi, vj] = Y[vi, vj] + B[vj] @R.function def main(x: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv0 = R.call_tir(cls.linear0, (x, metadata[\u0026#34;relax.expr.Constant\u0026#34;][0], metadata[\u0026#34;relax.expr.Constant\u0026#34;][1]), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv1 = R.call_dps_packed(\u0026#34;env.relu\u0026#34;, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) out = R.call_dps_packed(\u0026#34;env.linear\u0026#34;, (lv1, metadata[\u0026#34;relax.expr.Constant\u0026#34;][2], metadata[\u0026#34;relax.expr.Constant\u0026#34;][3]), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) R.output(out) return out ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch3/","summary":"Personal notebook 3.","title":"TVM Learning (4)-End to End Model Execution"},{"content":"LoopRV \u0026amp; BlockRV Object Scheduleè¦æ“ä½œçš„å¯¹è±¡ä¸»è¦å°±æ˜¯LoopRVå’ŒBlockRVï¼Œå¯¹åº”äºæˆ‘ä»¬TVMScriptä¸­çš„å¾ªç¯å˜é‡å’Œè®¡ç®—å—éƒ¨åˆ†ã€‚ä¸‹é¢ä»£ç ä¸ºåœ¨ TVM ä¸­æ³¨å†Œ LoopRV çš„è‡ªå®šä¹‰å¯¹è±¡ç±»å‹çš„è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡ FFIï¼ˆForeign Function Interfaceï¼‰æœºåˆ¶å°† C++ ä¸­çš„å‡½æ•°æš´éœ²ç»™ Python.\næ³¨å†Œè¿‡ç¨‹è§£æï¼š\nå®šä¹‰ç±»: é¦–å…ˆï¼Œå®šä¹‰ä¸€ä¸ªåä¸º LoopRV çš„ç±»ï¼Œå®ƒç»§æ‰¿è‡ª tvm.Object ç±»ã€‚è¿™ä¸ªç±»è¡¨ç¤ºä¸€ä¸ªä¸å¾ªç¯ç›¸å…³çš„éšæœºå˜é‡ã€‚ ä½¿ç”¨ @_register_object è£…é¥°å™¨: LoopRV ç±»ä½¿ç”¨ @_register_object(\u0026quot;tir.LoopRV\u0026quot;) è£…é¥°å™¨è¿›è¡Œæ³¨å†Œã€‚è¿™ä¸ªè£…é¥°å™¨ä¼šè°ƒç”¨ register_object å‡½æ•°ï¼Œå°† LoopRV ç±»æ³¨å†Œåˆ° TVM çš„å¯¹è±¡ç³»ç»Ÿä¸­ï¼Œå¹¶ä½¿ç”¨ç±»å‹é”® \u0026ldquo;tir.LoopRV\u0026rdquo; æ¥æ ‡è¯†å®ƒã€‚ FFI åˆå§‹åŒ–: tvm._ffi._init_api(\u0026quot;tir.schedule\u0026quot;, __name__) è¿™è¡Œä»£ç ä½¿ç”¨ _init_api å‡½æ•°åˆå§‹åŒ– FFIï¼Œå°† C++ ä¸­çš„ \u0026ldquo;tir.schedule\u0026rdquo; æ¨¡å—çš„å‡½æ•°æš´éœ²ç»™ Pythonã€‚ _init_api å’Œ _init_api_prefix å‡½æ•°: _init_api å‡½æ•°ç”¨äºåˆå§‹åŒ– FFIï¼Œå®ƒä¼šè°ƒç”¨ _init_api_prefix å‡½æ•°æ¥å¤„ç†å…·ä½“çš„å‡½æ•°æ³¨å†Œè¿‡ç¨‹ã€‚ å‡½æ•°æ³¨å†Œ: _init_api_prefix å‡½æ•°ä¼šéå†æ‰€æœ‰ C++ ä¸­çš„å…¨å±€å‡½æ•°ï¼Œæ‰¾åˆ°ä»¥ \u0026ldquo;tir.schedule\u0026rdquo; å¼€å¤´çš„å‡½æ•°ï¼Œå¹¶å°†å…¶æ³¨å†Œåˆ° Python ä¸­ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @_register_object(\u0026#34;tir.LoopRV\u0026#34;) class LoopRV(Object): \u0026#34;\u0026#34;\u0026#34;A random variable that refers to a loop\u0026#34;\u0026#34;\u0026#34; def __init__(self) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;Construct a new LoopRV.\u0026#34;\u0026#34;\u0026#34; self.__init_handle_by_constructor__( _ffi_api.LoopRV # type: ignore # pylint: disable=no-member ) \u0026#34;\u0026#34;\u0026#34;FFI APIs for tvm.tir.schedule\u0026#34;\u0026#34;\u0026#34; import tvm._ffi tvm._ffi._init_api(\u0026#34;tir.schedule\u0026#34;, __name__) # pylint: disable=protected-access _register_object 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def register_object(type_key=None): def register(cls): \u0026#34;\u0026#34;\u0026#34;internal register function\u0026#34;\u0026#34;\u0026#34; if hasattr(cls, \u0026#34;_type_index\u0026#34;): tindex = cls._type_index else: tidx = ctypes.c_uint() if not _RUNTIME_ONLY: check_call(_LIB.TVMObjectTypeKey2Index(c_str(object_name), ctypes.byref(tidx))) else: # directly skip unknown objects during runtime. ret = _LIB.TVMObjectTypeKey2Index(c_str(object_name), ctypes.byref(tidx)) if ret != 0: return cls tindex = tidx.value _register_object(tindex, cls) return cls if isinstance(type_key, str): return register return register(type_key) è£…é¥°å™¨åŠŸèƒ½:\næ³¨å†Œå¯¹è±¡ç±»å‹: è£…é¥°å™¨ register_object çš„ä¸»è¦ä½œç”¨æ˜¯å°†ä¸€ä¸ªç±»æ³¨å†Œåˆ° TVM çš„å¯¹è±¡ç³»ç»Ÿä¸­ï¼Œä»¥ä¾¿ TVM èƒ½å¤Ÿè¯†åˆ«å’Œä½¿ç”¨è¯¥ç±»ã€‚ ç±»å‹é”®: è£…é¥°å™¨æ¥å—ä¸€ä¸ªå¯é€‰å‚æ•° type_keyï¼Œç”¨äºæŒ‡å®šè¯¥å¯¹è±¡çš„ç±»å‹é”®ã€‚ç±»å‹é”®æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†è¯¥å¯¹è±¡ç±»å‹ã€‚å¦‚æœ type_key æœªæŒ‡å®šï¼Œåˆ™ä½¿ç”¨ç±»çš„åç§°ä½œä¸ºç±»å‹é”®ã€‚ å†…éƒ¨æ³¨å†Œå‡½æ•°: è£…é¥°å™¨å†…éƒ¨å®šä¹‰äº†ä¸€ä¸ªåä¸º register çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°è´Ÿè´£å®é™…çš„æ³¨å†Œæ“ä½œã€‚ æ³¨å†Œè¿‡ç¨‹: è·å–ç±»å‹ç´¢å¼•: register å‡½æ•°é¦–å…ˆè·å–è¯¥ç±»å‹çš„ç´¢å¼•ï¼Œå¦‚æœè¯¥ç±»å‹å·²ç»æ³¨å†Œï¼Œåˆ™ç›´æ¥è·å–å·²æœ‰çš„ç´¢å¼•ï¼›å¦åˆ™ï¼Œè°ƒç”¨ TVM çš„ C API å‡½æ•° TVMObjectTypeKey2Index è·å–æ–°çš„ç´¢å¼•ã€‚ æ³¨å†Œå¯¹è±¡: register å‡½æ•°ä½¿ç”¨ _register_object å‡½æ•°å°†ç±»å‹ç´¢å¼•å’Œç±»å¯¹è±¡æ³¨å†Œåˆ° TVM çš„å¯¹è±¡ç³»ç»Ÿä¸­ã€‚ BlockRVç±»çš„å®šä¹‰åŒç†ã€‚\n1 2 3 4 5 6 7 8 9 @_register_object(\u0026#34;tir.BlockRV\u0026#34;) class BlockRV(Object): \u0026#34;\u0026#34;\u0026#34;A random variable that refers to a block\u0026#34;\u0026#34;\u0026#34; def __init__(self) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;Construct a new BlockRV.\u0026#34;\u0026#34;\u0026#34; self.__init_handle_by_constructor__( _ffi_api.BlockRV # type: ignore # pylint: disable=no-member ) Schedule Primitive Scheduleæ˜¯ä¸€ç»„æ”¹å˜äº†è®¡ç®—çš„é¡ºåºï¼Œä½†ä¿ç•™äº†è®¡ç®—çš„è¯­ä¹‰çš„å˜æ¢ã€‚å®ƒçš„æ„é€ å‡½æ•°éœ€è¦ä¸€ä¸ª IRModuleå®ä¾‹ä½œä¸ºå‚æ•°ã€‚æˆ‘ä»¬ä»¥ä¸‹é¢çš„çŸ©é˜µçš„ element-wiseä¹˜æ³•ä¸ºä¾‹æ¥ä»‹ç»ä»¥ä¸‹å¯èƒ½çš„å˜æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import tvm from tvm import te import numpy as np # Declare some variables for use later n = te.var(\u0026#34;n\u0026#34;) m = te.var(\u0026#34;m\u0026#34;) # Declare a matrix element-wise multiply A = te.placeholder((m, n), name=\u0026#34;A\u0026#34;) B = te.placeholder((m, n), name=\u0026#34;B\u0026#34;) C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name=\u0026#34;C\u0026#34;) print(type(A)) s = te.create_schedule([C.op]) # lower å°†è®¡ç®—ä»å®šä¹‰è½¬æ¢æˆå¯ä»¥è°ƒç”¨çš„IRModule tvm.lower(s, [A, B, C], simple_mode=True).show() tvm.lower tvm.lower å‡½æ•°æ˜¯ TVM ä¸­ç”¨äºå°†è®¡ç®—å›¾ï¼ˆCompute Graphï¼‰é™ä½ï¼ˆlowerï¼‰åˆ°æ›´ä½çº§åˆ«çš„è¡¨ç¤ºå½¢å¼ï¼Œä¾‹å¦‚ Relay IR æˆ– TensorIR ï¼Œè¯¥å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªIRModule.\nå‚æ•°è§£é‡Š:\ninp: è¾“å…¥å‚æ•°ï¼Œå¯ä»¥æ˜¯ä»¥ä¸‹ä¸‰ç§ç±»å‹ä¹‹ä¸€ï¼štvm.te.schedule.Schedule å¯¹è±¡ï¼šè¡¨ç¤ºè®¡ç®—å›¾çš„è°ƒåº¦ä¿¡æ¯ã€‚\ntvm.tir.PrimFunc å¯¹è±¡ï¼šè¡¨ç¤º TensorIR çš„ä¸»å‡½æ•°ã€‚\nIRModule å¯¹è±¡ï¼šè¡¨ç¤ºä¸€ä¸ªåŒ…å«å¤šä¸ªå‡½æ•°çš„æ¨¡å—ã€‚\nargs: å¯é€‰å‚æ•°ï¼Œè¡¨ç¤ºè¾“å…¥å¼ é‡çš„åˆ—è¡¨ï¼Œä»…åœ¨ inp æ˜¯ tvm.te.schedule.Schedule å¯¹è±¡æ—¶ä½¿ç”¨ã€‚\nname: å¯é€‰å‚æ•°ï¼Œè¡¨ç¤ºç”Ÿæˆçš„å‡½æ•°çš„åç§°ï¼Œé»˜è®¤ä¸º \u0026ldquo;main\u0026rdquo;ã€‚\nbinds: å¯é€‰å‚æ•°ï¼Œè¡¨ç¤ºä¸€ä¸ªå­—å…¸ï¼Œç”¨äºæŒ‡å®šè¾“å…¥å¼ é‡çš„ç»‘å®šï¼Œä»…åœ¨ inp æ˜¯ tvm.te.schedule.Schedule å¯¹è±¡æ—¶ä½¿ç”¨ã€‚\nsimple_mode: å¯é€‰å‚æ•°ï¼Œè¡¨ç¤ºæ˜¯å¦ä½¿ç”¨ç®€åŒ–çš„æ¨¡å¼ï¼Œé»˜è®¤ä¸º Falseã€‚\nä¸Šè¿°ä»£ç ç”Ÿæˆçš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # from tvm.script import ir as I # from tvm.script import tir as T @I.ir_module class Module: @T.prim_func def main(A: T.handle, B: T.handle, C: T.handle): T.func_attr({\u0026#34;from_legacy_te_schedule\u0026#34;: T.bool(True), \u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A_1 = T.match_buffer(A, (m, n), strides=(\u0026#34;stride\u0026#34;, \u0026#34;stride\u0026#34;), buffer_type=\u0026#34;auto\u0026#34;) B_1 = T.match_buffer(B, (m, n), strides=(\u0026#34;stride\u0026#34;, \u0026#34;stride\u0026#34;), buffer_type=\u0026#34;auto\u0026#34;) C_1 = T.match_buffer(C, (m, n), strides=(\u0026#34;stride\u0026#34;, \u0026#34;stride\u0026#34;), buffer_type=\u0026#34;auto\u0026#34;) for i, j in T.grid(m, n): C_2 = T.Buffer((C_1.strides[0] * m,), data=C_1.data, buffer_type=\u0026#34;auto\u0026#34;) A_2 = T.Buffer((A_1.strides[0] * m,), data=A_1.data, buffer_type=\u0026#34;auto\u0026#34;) B_2 = T.Buffer((B_1.strides[0] * m,), data=B_1.data, buffer_type=\u0026#34;auto\u0026#34;) C_2[i * C_1.strides[0] + j * C_1.strides[1]] = A_2[i * A_1.strides[0] + j * A_1.strides[1]] * B_2[i * B_1.strides[0] + j * B_1.strides[1]] Merge Fuse fuse æ–¹æ³•ç”¨äºå°†ä¸€ç»„è¿ç»­çš„å¾ªç¯åˆå¹¶æˆä¸€ä¸ªå¾ªç¯ã€‚åˆå¹¶åçš„å¾ªç¯å°†åŒ…å«æ‰€æœ‰åŸå§‹å¾ªç¯çš„è¿­ä»£ç©ºé—´ã€‚\né™åˆ¶æ¡ä»¶:\nå¾ªç¯ä¸èƒ½åŒ…å«ä»»ä½•æ³¨è§£æˆ–çº¿ç¨‹ç»‘å®šï¼Œä¾‹å¦‚ @T.pragma æˆ– @T.thread_binding å¾ªç¯å¿…é¡»æ˜¯è¿ç»­çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªå¾ªç¯çš„çˆ¶å¾ªç¯å¿…é¡»æ˜¯å‰ä¸€ä¸ªå¾ªç¯ã€‚ å¾ªç¯çš„èµ·å§‹å€¼å¿…é¡»ä¸º 0 æ¯ä¸ªå¾ªç¯çš„åŸŸä¸èƒ½ä¾èµ–äºå…¶ä»–è¦åˆå¹¶çš„å¾ªç¯ã€‚ å‚æ•°:\nloops: ä¸€ä¸ªå¾ªç¯åˆ—è¡¨ï¼Œè¡¨ç¤ºè¦åˆå¹¶çš„å¾ªç¯ã€‚ preserve_unit_iters: ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦ä¿ç•™å•ä½è¿­ä»£çš„å¾ªç¯ã€‚é»˜è®¤å€¼ä¸º Trueï¼Œè¡¨ç¤ºä¿ç•™å•ä½è¿­ä»£çš„å¾ªç¯ã€‚ è¿”å›å€¼:\nfused_loop: ä¸€ä¸ªæ–°çš„å¾ªç¯å¯¹è±¡ï¼Œè¡¨ç¤ºåˆå¹¶åçš„å¾ªç¯ã€‚ ä»¥ B[i, j]=A[i, j]*2ä¸ºä¾‹ï¼Œfuse å‰å¯¹åº”çš„TensorIR\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 A = te.placeholder((m, n), name=\u0026#34;A\u0026#34;) B = te.compute((m, n), lambda i, j: A[i, j] * 2, name=\u0026#34;B\u0026#34;) func = te.create_prim_func([A, B]) func = func.with_attr(\u0026#34;global_symbol\u0026#34;, \u0026#34;main\u0026#34;) ir_module = IRModule({\u0026#34;main\u0026#34;: func}) ir_module.show() #----------TensorIR Before Fuse-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) B = T.match_buffer(var_B, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i, j in T.grid(m, n): with T.block(\u0026#34;B\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(A[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = A[v_i, v_j] * T.float32(2.0) fuse åå¯¹åº”çš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sch = tvm.tir.Schedule(ir_module) block_B = sch.get_block(\u0026#34;B\u0026#34;) i, j= sch.get_loops(block_B) sch.fuse(i, j) sch.mod.show() #----------TensorIR After Fuse-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) B = T.match_buffer(var_B, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i_j_fused in range(m * n): with T.block(\u0026#34;B\u0026#34;): v_i = T.axis.spatial(m, i_j_fused % (n * m) // n) v_j = T.axis.spatial(n, i_j_fused % n) T.reads(A[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = A[v_i, v_j] * T.float32(2.0) Split split æ–¹æ³•å°†ä¸€ä¸ªå¾ªç¯æ‹†åˆ†æˆå¤šä¸ªè¿ç»­çš„å¾ªç¯ï¼Œæ¯ä¸ªå¾ªç¯çš„è¿­ä»£æ¬¡æ•°ç”± factors å‚æ•°æŒ‡å®šã€‚\né™åˆ¶æ¡ä»¶:\nè¦æ‹†åˆ†çš„å¾ªç¯ä¸èƒ½æœ‰ä»»ä½•æ³¨è§£ (annotation) æˆ–çº¿ç¨‹ç»‘å®š (thread binding). è¦æ‹†åˆ†çš„å¾ªç¯å¿…é¡»ä» 0 å¼€å§‹è¿­ä»£ã€‚ åœ¨ factors åˆ—è¡¨ä¸­ï¼Œæœ€å¤šåªèƒ½æœ‰ä¸€ä¸ªå…ƒç´ ä¸º Noneï¼Œè¡¨ç¤ºè¯¥å…ƒç´ çš„è¿­ä»£æ¬¡æ•°å°†è‡ªåŠ¨æ¨æ–­ã€‚ å‚æ•°:\nloop: è¦æ‹†åˆ†çš„å¾ªç¯å¯¹è±¡ã€‚ factors: ä¸€ä¸ªåˆ—è¡¨ï¼Œè¡¨ç¤ºæ‹†åˆ†åçš„æ¯ä¸ªå¾ªç¯çš„è¿­ä»£æ¬¡æ•°ã€‚åˆ—è¡¨ä¸­çš„å…ƒç´ å¯ä»¥æ˜¯æ•´æ•°ã€è¡¨è¾¾å¼æˆ– Noneã€‚å¦‚æœåˆ—è¡¨ä¸­åŒ…å« Noneï¼Œåˆ™è¯¥å…ƒç´ çš„è¿­ä»£æ¬¡æ•°å°†è‡ªåŠ¨æ¨æ–­ã€‚ preserve_unit_iters: ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦ä¿ç•™å•ä½è¿­ä»£å™¨ã€‚å¦‚æœè®¾ç½®ä¸º Trueï¼Œåˆ™ä¼šä¿ç•™å•ä½è¿­ä»£å™¨ï¼Œå¦åˆ™ä¼šå°†å•ä½è¿­ä»£å™¨åˆå¹¶åˆ°å…¶ä»–å¾ªç¯ä¸­ã€‚ disable_predication: ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦ç¦ç”¨è°“è¯ (predicate). å¦‚æœè®¾ç½®ä¸º Trueï¼Œåˆ™ä¸ä¼šåˆ›å»ºè°“è¯æ¥ä¿æŠ¤å¾ªç¯ã€‚ ä»¥ B[i]=A[i]*2ä¸ºä¾‹ï¼Œsplitå‰å¯¹åº”çš„TensorIR\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 A = te.placeholder((m, ), name=\u0026#34;A\u0026#34;) B = te.compute((m, ), lambda i: A[i] * 2, name=\u0026#34;B\u0026#34;) s = te.create_schedule(B.op) func = te.create_prim_func([A, B]) func = func.with_attr(\u0026#34;global_symbol\u0026#34;, \u0026#34;main\u0026#34;) ir_module = IRModule({\u0026#34;main\u0026#34;: func}) ir_module.show() #----------TensorIR Before Split-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m = T.int32() A = T.match_buffer(var_A, (m,)) B = T.match_buffer(var_B, (m,)) # with T.block(\u0026#34;root\u0026#34;): for i in range(m): with T.block(\u0026#34;B\u0026#34;): v_i = T.axis.spatial(m, i) T.reads(A[v_i]) T.writes(B[v_i]) B[v_i] = A[v_i] * T.float32(2.0) split åå¯¹åº”çš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sch = tvm.tir.Schedule(ir_module) block_b = sch.get_block(\u0026#34;B\u0026#34;) i, = sch.get_loops(block_b) sch.split(i, factors=[None, 32]) sch.mod.show() #----------TensorIR After Split-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m = T.int32() A = T.match_buffer(var_A, (m,)) B = T.match_buffer(var_B, (m,)) # with T.block(\u0026#34;root\u0026#34;): for i_0, i_1 in T.grid((m + 31) // 32, 32): with T.block(\u0026#34;B\u0026#34;): v_i = T.axis.spatial(m, i_0 * 32 + i_1) T.where(i_0 * 32 + i_1 \u0026lt; m) T.reads(A[v_i]) T.writes(B[v_i]) B[v_i] = A[v_i] * T.float32(2.0) Loop Partition loop_partition æ–¹æ³•ç”¨äºå°†ä¸€ä¸ªå¾ªç¯åˆ†å‰²æˆå¤šä¸ªè¿ç»­çš„å¾ªç¯\né™åˆ¶æ¡ä»¶:\nå¾ªç¯ä¸èƒ½æœ‰æ³¨è§£æˆ–çº¿ç¨‹ç»‘å®šã€‚ factors åˆ—è¡¨ä¸­æœ€å¤šåªèƒ½æœ‰ä¸€ä¸ªå…ƒç´ ä¸º None ä¸æ”¯æŒå¾ªç¯çš„å€¼æœªçŸ¥çš„æƒ…å†µã€‚ å‚æ•°:\nloop: è¦åˆ†å‰²çš„å¾ªç¯ã€‚ factors: åˆ†å‰²å› å­åˆ—è¡¨ã€‚ preserve_unit_iters: æ˜¯å¦ä¿ç•™å•ä½è¿­ä»£çš„å¾ªç¯ï¼Œé»˜è®¤å€¼ä¸º Trueã€‚ ä»ä»¥ B[i, j]=A[i, j]*2ä¸ºä¾‹ï¼Œloop_partitionå‰å¯¹åº”çš„TensorIR\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 m = 128 n = 128 A = te.placeholder((m, n), name=\u0026#34;A\u0026#34;) B = te.compute((m, n), lambda i, j: A[i, j] * 2, name=\u0026#34;B\u0026#34;) func = te.create_prim_func([A, B]) func = func.with_attr(\u0026#34;global_symbol\u0026#34;, \u0026#34;main\u0026#34;) ir_module = IRModule({\u0026#34;main\u0026#34;: func}) ir_module.show() #----------TensorIR Before Loop Partition-------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((128,), \u0026#34;float32\u0026#34;), B: T.Buffer((128,), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i in range(128): with T.block(\u0026#34;B\u0026#34;): v_i = T.axis.spatial(128, i) T.reads(A[v_i]) T.writes(B[v_i]) B[v_i] = A[v_i] * T.float32(2.0) æˆ‘ä»¬æŒ‡å®š factors=[2,64]ï¼Œç›¸å½“äºæŠŠæ•´ä¸ªå¾ªç¯åœ¨2å’Œ64å¤„åˆ†æˆ3ä»½ï¼Œloop_partitionåå¯¹åº”çš„TensorIRå¦‚ä¸‹ã€‚åœ¨ä½¿ç”¨ loop_partition åï¼Œä¼šåˆ›å»ºå¤šä¸ªåµŒå¥—çš„å—ï¼Œä¾‹å¦‚ rootã€B_i_common ä»¥åŠæ¯ä¸ªåˆ†å‰²åçš„å¾ªç¯å¯¹åº”çš„å—ï¼Œå‰ä¸¤ä¸ªå—ä¸­ä¼šæ‰§è¡Œä¸€ä¸ªç©ºçš„ T.reads å’Œ T.writes æ“ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 sch = tvm.tir.Schedule(ir_module) block_B = sch.get_block(\u0026#34;B\u0026#34;) [i] = sch.get_loops(block_B) # return a list of LoopRV sch.loop_partition(i, [2, 64]) sch.mod.show() #----------TensorIR After Loop Partition-------------- @I.ir_module class Module: @T.prim_func def main(A: T.Buffer((128,), \u0026#34;float32\u0026#34;), B: T.Buffer((128,), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) with T.block(\u0026#34;root\u0026#34;): T.reads() T.writes() with T.block(\u0026#34;B_i_common\u0026#34;): T.reads() T.writes() with T.block(\u0026#34;B_i0_partition\u0026#34;): T.reads() T.writes() for i0 in range(2): with T.block(\u0026#34;B_i0\u0026#34;): v_i = T.axis.spatial(2, i0) T.reads(A[0:2]) T.writes(B[0:2]) B[v_i] = A[v_i] * T.float32(2.0) with T.block(\u0026#34;B_i1_partition\u0026#34;): T.reads() T.writes() for i1 in range(2, 66): with T.block(\u0026#34;B_i1\u0026#34;): v_i = T.axis.spatial((2, 66), i1) T.reads(A[2:66]) T.writes(B[2:66]) B[v_i] = A[v_i] * T.float32(2.0) with T.block(\u0026#34;B_i2_partition\u0026#34;): T.reads() T.writes() for i2 in range(66, 128): with T.block(\u0026#34;B_i2\u0026#34;): v_i = T.axis.spatial((66, 128), i2) T.reads(A[66:128]) T.writes(B[66:128]) B[v_i] = A[v_i] * T.float32(2.0) Reorder reorder æ–¹æ³•ç”¨äºé‡æ–°æ’åˆ—å¾ªç¯çš„æ‰§è¡Œé¡ºåºã€‚\né™åˆ¶æ¡ä»¶:\næ‰€æœ‰å¾ªç¯å¿…é¡»å±äºåŒä¸€ä¸ªå¾ªç¯é“¾ï¼Œè¿™æ„å‘³ç€å®ƒä»¬å¯ä»¥æŒ‰ç…§ç¥–å…ˆ-åä»£å…³ç³»æ’åºï¼Œå¹¶ä¸”å®ƒä»¬ä¹‹é—´åªæœ‰å•åˆ†æ”¯å¾ªç¯ï¼ˆå³æ²¡æœ‰ if è¯­å¥ï¼‰ã€‚ å¤–å±‚å¾ªç¯çš„èŒƒå›´ä¸èƒ½ä¾èµ–äºå†…å±‚å¾ªç¯ã€‚ æ¯ä¸ªå¾ªç¯åµŒå¥—ä¸‹çš„å—ç»‘å®šå¿…é¡»æ˜¯ä»¿å°„çš„ï¼Œå¹¶ä¸”å—å˜é‡å¿…é¡»éƒ½ä¸ºæ•°æ®å¹¶è¡Œæˆ–å½’çº¦ã€‚ ordered_loops ä¸­ä¸èƒ½åŒ…å«é‡å¤çš„å¾ªç¯ã€‚ å‚æ•°:\nordered_loops: ä¸€ä¸ªæˆ–å¤šä¸ªå¾ªç¯åˆ—è¡¨ï¼Œè¡¨ç¤ºæ–°çš„å¾ªç¯æ‰§è¡Œé¡ºåºã€‚ reorder_block_iter_var æ–¹æ³•çš„åŠŸèƒ½ä¸reorderç›¸åŒï¼Œåªä¸è¿‡å®ƒæ¥æ”¶çš„å‚æ•°ä¸º\nblock: å¾…è¿›è¡Œå˜æ¢çš„BlockRVå¯¹è±¡ new_order: æ•´æ•°åˆ—è¡¨ï¼Œä»£è¡¨è¯¥blockæ–°çš„è¿­ä»£é¡ºåº å‰é¢ç« èŠ‚å·²ç»™å‡ºå¾ˆå¤šä¾‹å­ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚\nParallel parallelæ–¹æ³•å°†ä¸€ä¸ªå¾ªç¯ loopRV æ ‡è®°ä¸ºå¹¶è¡Œæ‰§è¡Œï¼Œå³å¾ªç¯çš„è¿­ä»£å¯ä»¥åŒæ—¶åœ¨å¤šä¸ªçº¿ç¨‹æˆ–å¤„ç†å™¨ä¸Šæ‰§è¡Œï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡ã€‚\né™åˆ¶æ¡ä»¶:\nä¸ºäº†ç¡®ä¿å¹¶è¡ŒåŒ–æ“ä½œçš„æ­£ç¡®æ€§å’Œæœ‰æ•ˆæ€§ï¼Œè¯¥å‡½æ•°éœ€è¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š\nå¾ªç¯æ‰€åœ¨çš„å—å¿…é¡»å…·æœ‰é˜¶æ®µæµæ°´çº¿å±æ€§ã€‚è¿™æ„å‘³ç€è¯¥å—ä¸­çš„è®¡ç®—å¯ä»¥è¢«åˆ†è§£æˆå¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µå¯ä»¥ç‹¬ç«‹æ‰§è¡Œã€‚ å¾ªç¯ä¸‹çš„æ‰€æœ‰å—å¿…é¡»æ˜¯å®Œæ•´å—æˆ–å½’çº¦å—ï¼Œå¹¶ä¸”å…·æœ‰ä»¿å°„ç»‘å®šã€‚ å¯¹äºå¾ªç¯ä¸‹çš„æ¯ä¸ªå—ï¼Œå¾ªç¯åªèƒ½åŒ…å«åœ¨æ•°æ®å¹¶è¡Œå—è¿­ä»£çš„ç»‘å®šä¸­ã€‚ å‚æ•°:\nloop: è¦å¹¶è¡ŒåŒ–çš„å¾ªç¯ã€‚ ä»¥ä¸‹é¢çš„çŸ©é˜µçš„ element-wiseä¹˜æ³•ä¸ºä¾‹ï¼Œparallelå‰å¯¹åº”çš„TensorIRä¸º\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 A = te.placeholder((m, n), name=\u0026#34;A\u0026#34;) B = te.placeholder((m, n), name=\u0026#34;B\u0026#34;) C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name=\u0026#34;C\u0026#34;) func = te.create_prim_func([A, B, C]) func = func.with_attr(\u0026#34;global_symbol\u0026#34;, \u0026#34;main\u0026#34;) ir_module = IRModule({\u0026#34;main\u0026#34;: func}) ir_module.show() #----------TensorIR Before Parallel-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle, var_C: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) B = T.match_buffer(var_B, (m, n)) C = T.match_buffer(var_C, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i, j in T.grid(m, n): with T.block(\u0026#34;C\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(A[v_i, v_j], B[v_i, v_j]) T.writes(C[v_i, v_j]) C[v_i, v_j] = A[v_i, v_j] * B[v_i, v_j] å¯¹å¤–å¾ªç¯è¿›è¡Œparallelï¼Œå¯ä»¥çœ‹åˆ° T.parallelå–ä»£äº†ä¹‹å‰çš„ T.gridï¼Œå®ƒä¼šå°†æ‰€æœ‰è¿­ä»£åˆ†é…åˆ°å¤šä¸ªçº¿ç¨‹æˆ–å¤„ç†å™¨ä¸ŠåŒæ—¶æ‰§è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sch = tvm.tir.Schedule(ir_module) block_c = sch.get_block(\u0026#34;C\u0026#34;) i, j = sch.get_loops(block_c) sch.parallel(i) sch.mod.show() #----------TensorIR After Parallel-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle, var_C: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) B = T.match_buffer(var_B, (m, n)) C = T.match_buffer(var_C, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i, j in T.grid(m, n): with T.block(\u0026#34;C\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(A[v_i, v_j], B[v_i, v_j]) T.writes(C[v_i, v_j]) C[v_i, v_j] = A[v_i, v_j] * B[v_i, v_j] Vectorize vectorizeæ–¹æ³•å°†ä¸€ä¸ªå¾ªç¯ loop æ ‡è®°ä¸ºå‘é‡åŒ–æ‰§è¡Œï¼Œè¿™æ„å‘³ç€å¾ªç¯çš„è¿­ä»£å¯ä»¥è¢«åˆ†ç»„ä¸ºå‘é‡ï¼Œç„¶ååœ¨å•ä¸ªæŒ‡ä»¤ä¸­æ‰§è¡Œï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡ã€‚\né™åˆ¶æ¡ä»¶:\nå¾ªç¯æ‰€åœ¨çš„å—å¿…é¡»å…·æœ‰é˜¶æ®µæµæ°´çº¿å±æ€§ï¼Œå³è¯¥å—ä¸­çš„è®¡ç®—å¯ä»¥è¢«åˆ†è§£æˆå¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µå¯ä»¥ç‹¬ç«‹æ‰§è¡Œã€‚ å¾ªç¯ä¸‹çš„æ‰€æœ‰å—å¿…é¡»æ˜¯å®Œæ•´å—æˆ–å½’çº¦å—ï¼Œå¹¶ä¸”å…·æœ‰ä»¿å°„ç»‘å®šã€‚ å¯¹äºå¾ªç¯ä¸‹çš„æ¯ä¸ªå—ï¼Œå¾ªç¯åªèƒ½åŒ…å«åœ¨æ•°æ®å¹¶è¡Œå—è¿­ä»£çš„ç»‘å®šä¸­ã€‚ å‚æ•°:\nloop: è¦å‘é‡åŒ–çš„å¾ªç¯ã€‚ ä»ä»¥ B[i, j]=A[i, j]*2ä¸ºä¾‹ï¼Œloop_partitionå‰å¯¹åº”çš„TensorIRä¸ Loop Partition ä¸­çš„ç›¸åŒã€‚\nVectorize æ˜¯ä¸€ç§é‡è¦çš„ä¼˜åŒ–æŠ€æœ¯ï¼Œå®ƒåˆ©ç”¨ç°ä»£å¤„ç†å™¨ä¸­çš„ SIMD (Single Instruction, Multiple Data)æŒ‡ä»¤ï¼Œå°†å¤šä¸ªæ•°æ®åŒæ—¶è¿›è¡Œè®¡ç®—ï¼Œä»è€Œæå‡è®¡ç®—æ•ˆç‡ã€‚SIMD æŒ‡ä»¤ä½¿ç”¨å‘é‡å¯„å­˜å™¨æ¥å­˜å‚¨å’Œæ“ä½œå¤šä¸ªæ•°æ®ã€‚å‘é‡å¯„å­˜å™¨çš„é•¿åº¦é€šå¸¸æ˜¯ 128 ä½æˆ– 256 ä½ï¼Œå¯ä»¥å­˜å‚¨å¤šä¸ªæ•°æ®ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ª SIMD æŒ‡ä»¤å¯ä»¥åŒæ—¶å¯¹ 4 ä¸ªæµ®ç‚¹æ•°è¿›è¡ŒåŠ æ³•è¿ç®—ã€‚å°†å¾ªç¯å‘é‡åŒ–æ„å‘³ç€å°†å¾ªç¯çš„è¿­ä»£åˆ†ç»„ä¸ºå‘é‡ï¼Œç„¶åä½¿ç”¨ SIMD æŒ‡ä»¤å¯¹è¿™äº›å‘é‡è¿›è¡Œæ“ä½œã€‚T.vectorized åœ¨ TVM ä¸­ç”¨æ¥æ ‡è®°ä¸€ä¸ªå¾ªç¯å·²ç»è¢«å‘é‡åŒ–äº†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sch = tvm.tir.Schedule(ir_module) block_b = sch.get_block(\u0026#34;B\u0026#34;) i, j = sch.get_loops(block_b) sch.vectorize(j) sch.mod.show() #----------TensorIR After Vectorize-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) B = T.match_buffer(var_B, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i in range(m): for j in T.vectorized(n): with T.block(\u0026#34;B\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(A[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = A[v_i, v_j] * T.float32(2.0) Unroll unroll å‡½æ•°æ¥æ”¶ä¸€ä¸ª LoopRV (å¾ªç¯è¡¨ç¤ºå˜é‡) ä½œä¸ºè¾“å…¥ï¼Œä½œç”¨æ˜¯å°†ä¸€ä¸ªå¾ªç¯å±•å¼€ã€‚å®ƒæœ¬è´¨ä¸Šæ˜¯å°†å¾ªç¯ä½“å¤åˆ¶å¤šæ¬¡ï¼Œå¹¶å°†å¾ªç¯è®¡æ•°å™¨æ›¿æ¢ä¸ºå…·ä½“çš„æ•°å€¼ã€‚æœ‰ä»¥ä¸‹å‡ ä¸ªä¼˜ç‚¹\nå‡å°‘å¾ªç¯æ§åˆ¶æŒ‡ä»¤çš„æ‰§è¡Œæ¬¡æ•°ï¼Œä»è€Œæé«˜æ•ˆç‡ã€‚ å°†å¾ªç¯ä½“ä¸­çš„æ•°æ®è®¿é—®é›†ä¸­åœ¨ä¸€èµ·ï¼Œä»è€Œæé«˜æ•°æ®å±€éƒ¨æ€§ï¼Œè¿›è€Œæé«˜ç¼“å­˜å‘½ä¸­ç‡ã€‚ å¢åŠ æŒ‡ä»¤çº§å¹¶è¡Œæ€§ï¼Œä»è€Œæé«˜ç¨‹åºæ‰§è¡Œé€Ÿåº¦ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sch = tvm.tir.Schedule(ir_module) block_b = sch.get_block(\u0026#34;B\u0026#34;) i, j = sch.get_loops(block_b) sch.unroll(i) sch.mod.show() #----------TensorIR After Vectorize-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) B = T.match_buffer(var_B, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i in T.unroll(m): for j in range(n): with T.block(\u0026#34;B\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(A[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = A[v_i, v_j] * T.float32(2.0) (Reverse) Compute at compute_atæ–¹æ³•çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ªç”Ÿäº§è€…å—ï¼ˆproducer blockï¼‰ç§»åŠ¨åˆ°ä¸€ä¸ªç‰¹å®šå¾ªç¯ï¼ˆloopï¼‰çš„å†…éƒ¨ï¼Œå¹¶é‡æ–°ç”Ÿæˆç”±è¯¥ç”Ÿäº§è€…å—å¼•èµ·çš„å¾ªç¯ï¼Œä»¥ç¡®ä¿ç”Ÿäº§è€…å—ç”Ÿæˆçš„ç¼“å†²åŒºåŒºåŸŸèƒ½å¤Ÿè¦†ç›–å…¶æ¶ˆè´¹è€…å—åœ¨è¯¥å¾ªç¯ä¸‹æ‰€ä½¿ç”¨çš„åŒºåŸŸã€‚reverse_compute_atåˆ™æ˜¯ç§»åŠ¨æ¶ˆè´¹è€…å—ï¼ˆconsumer blockï¼‰\nç”Ÿäº§è€…å—ï¼ˆproducer blockï¼‰ï¼š ç”Ÿæˆæ•°æ®ï¼ˆé€šå¸¸æ˜¯ç¼“å†²åŒºï¼‰çš„ä»£ç å—ã€‚ æ¶ˆè´¹è€…å—ï¼ˆconsumer blockï¼‰ï¼š ä½¿ç”¨ç”Ÿäº§è€…å—ç”Ÿæˆçš„æ•°æ®çš„ä»£ç å—ã€‚ é™åˆ¶æ¡ä»¶ï¼š\nblock å’Œ loop å¿…é¡»åœ¨åŒä¸€ä¸ªä½œç”¨åŸŸå†…ã€‚ ä¸èƒ½å°† blockç§»åŠ¨åˆ°å®ƒè‡ªèº«æ‰€åœ¨çš„å¾ªç¯çš„ç¥–å…ˆå¾ªç¯ä¸­ã€‚ ä½œç”¨åŸŸå—å¿…é¡»å…·æœ‰é˜¶æ®µ-æµæ°´çº¿å±æ€§ã€‚ ä½œç”¨åŸŸå—çš„å­æ ‘å¿…é¡»æ»¡è¶³ç´§å‡‘æ•°æ®æµæ¡ä»¶ï¼Œå³å­æ ‘ä¸­çš„æ‰€æœ‰å—å¿…é¡»æ˜¯å®Œæ•´å—æˆ–å½’çº¦å—ã€‚ å—ä¸æ˜¯ä½œç”¨åŸŸå—çš„è¾“å‡ºå—ï¼Œå³å—å†™å…¥çš„ç¼“å†²åŒºåœ¨ä½œç”¨åŸŸå—ä¸‹åˆ†é…ã€‚ å—çš„æ‰€æœ‰æ¶ˆè´¹è€…éƒ½åœ¨ç»™å®šçš„å¾ªç¯ä¸‹ã€‚ æˆ‘ä»¬ä»¥ C[i,j]=A[i,j] * 2 + 1ä¸ºä¾‹ï¼Œcompute_atå‰å¯¹åº”çš„TesnsorIRå¦‚ä¸‹\nWarning\næˆ‘ä»¬åœ¨åˆ›å»º prim_funcæ—¶çš„è¾“å…¥åªä½¿ç”¨äº† A, Cï¼Œå¦åˆ™Bå°±ä¸ä¼šæ˜¯ä½œä¸ºä¸­é—´å˜é‡çš„ T.alloc_bufferï¼Œè°ƒç”¨ compute_atä¼šå› ä¸ºè¿åç¬¬äº”æ¡æŠ¥é”™ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 A = te.placeholder((m, n), name=\u0026#34;A\u0026#34;) B = te.compute((m, n), lambda i, j: A[i, j] * 2, name=\u0026#34;B\u0026#34;) C = te.compute((m, n), lambda i, j: B[i, j] + 1, name=\u0026#34;C\u0026#34;) func = te.create_prim_func([A, C]) fuc = func.with_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;}) ir_module = IRModule({\u0026#34;main\u0026#34;: func}) ir_module.show() #----------TensorIR Before Compute_at-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_C: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) C = T.match_buffer(var_C, (m, n)) # with T.block(\u0026#34;root\u0026#34;): B = T.alloc_buffer((m, n)) for i, j in T.grid(m, n): with T.block(\u0026#34;B\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(A[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = A[v_i, v_j] * T.float32(2.0) for i, j in T.grid(m, n): with T.block(\u0026#34;C\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(B[v_i, v_j]) T.writes(C[v_i, v_j]) C[v_i, v_j] = B[v_i, v_j] + T.float32(1.0) åœ¨è°ƒç”¨ compute_atä¹‹åå—Bçš„è®¡ç®—è¢«ç§»åŠ¨åˆ°å—Cçš„å¾ªç¯iä¹‹ä¸‹ï¼Œç›¸å½“äºè°ƒç”¨ reverse_compute_atå°†å—Cçš„è®¡ç®—ç§»åŠ¨åˆ°å—Bçš„å¾ªç¯iä¹‹ä¸‹ï¼Œå¯¹åº”çš„TesnorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 sch = tvm.tir.Schedule(ir_module) block = sch.get_block(\u0026#34;B\u0026#34;) loop, _ = sch.get_loops(sch.get_block(\u0026#34;C\u0026#34;)) sch.compute_at(block, loop, preserve_unit_loops=False) \u0026#39;\u0026#39;\u0026#39; same way block = sch.get_block(\u0026#34;C\u0026#34;) loop, _ = sch.get_loops(sch.get_block(\u0026#34;B\u0026#34;)) sch.reverse_compute_at(block, loop, preserve_unit_loops=False) \u0026#39;\u0026#39;\u0026#39; sch.mod.show() #----------TensorIR After Compute_at-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_C: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) C = T.match_buffer(var_C, (m, n)) # with T.block(\u0026#34;root\u0026#34;): B = T.alloc_buffer((m, n)) for i in range(m): for ax0 in range(n): with T.block(\u0026#34;B\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, ax0]) T.reads(A[v_i, v_j]) T.writes(B[v_i, v_j]) B[v_i, v_j] = A[v_i, v_j] * T.float32(2.0) for j in range(n): with T.block(\u0026#34;C\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(B[v_i, v_j]) T.writes(C[v_i, v_j]) C[v_i, v_j] = B[v_i, v_j] + T.float32(1.0) (Reverse) Compute Inline compute_inline æ–¹æ³•ç”¨äºå°†ä¸€ä¸ªå—ï¼ˆblockï¼‰å†…è”åˆ°å…¶æ¶ˆè´¹è€…ï¼ˆconsumerï¼‰ä¸­ã€‚ç®€å•æ¥è¯´å°±æ˜¯å°†ä¸€ä¸ªå—çš„è®¡ç®—é€»è¾‘ç›´æ¥åµŒå…¥åˆ°ä½¿ç”¨å®ƒç»“æœçš„å—ä¸­ï¼Œä»è€Œæ¶ˆé™¤ä¸­é—´å—ï¼Œç®€åŒ–è®¡ç®—æµç¨‹ã€‚reverse_compute_inlineåˆ™æ˜¯ç”¨äºå°†ä¸€ä¸ªå—ï¼ˆblockï¼‰å†…è”åˆ°å…¶ç”Ÿäº§è€…ï¼ˆproducerï¼‰ä¸­ã€‚\né™åˆ¶æ¡ä»¶ï¼š\nè¦å†…è”çš„å—å¿…é¡»æ˜¯ä¸€ä¸ªå®Œæ•´çš„éæ ¹å—ï¼ˆroot å—ï¼‰ï¼Œå¹¶ä¸”å®ƒå¿…é¡»åªäº§ç”Ÿä¸€ä¸ªç¼“å†²åŒºã€‚ è¦å†…è”çš„å—ä¸èƒ½æ˜¯å…¶ä½œç”¨åŸŸå†…çš„å”¯ä¸€å¶èŠ‚ç‚¹ã€‚ è¦å†…è”çš„å—çš„ä»£ç ä½“å¿…é¡»æ˜¯ä¸€ä¸ªç¼“å†²åŒºå­˜å‚¨è¯­å¥ï¼Œä¾‹å¦‚ A[i, j, k, ...] = ...ã€‚è¯¥è¯­å¥çš„å·¦ä¾§ç´¢å¼•å¿…é¡»æ˜¯ä¸åŒçš„åŸå­å˜é‡ï¼Œå¹¶ä¸”è¯­å¥ä¸­ä¸èƒ½åŒ…å«å…¶ä»–å˜é‡ã€‚ ä»¥ä¸Šä¸€èŠ‚çš„ C[i,j]=A[i,j] * 2 + 1ä¸ºä¾‹ï¼Œå¯¹åº”çš„TensorIRå·²ç»™å‡ºã€‚åœ¨æ‰§è¡ŒCompute_inlineä¹‹åå—Bçš„è®¡ç®—é€»è¾‘ç›´æ¥åµŒå…¥åˆ°å—Cä¸­ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 sch = tvm.tir.Schedule(ir_module) block = sch.get_block(\u0026#34;B\u0026#34;) # same: sch.reverse_compute_inline(sch.get_block(\u0026#34;C\u0026#34;)) sch.compute_inline(block) sch.mod.show() #----------TensorIR After Compute_inline-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_C: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, n = T.int32(), T.int32() A = T.match_buffer(var_A, (m, n)) C = T.match_buffer(var_C, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i, j in T.grid(m, n): with T.block(\u0026#34;C\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i, j]) T.reads(A[v_i, v_j]) T.writes(C[v_i, v_j]) C[v_i, v_j] = A[v_i, v_j] * T.float32(2.0) + T.float32(1.0) Decompose Reduction decompose_reduction å‡½æ•°ç”¨äºå°†ä¸€ä¸ªå½’çº¦å—ï¼ˆreduction blockï¼‰åˆ†è§£æˆä¸¤ä¸ªç‹¬ç«‹çš„å—åˆå§‹åŒ–å—ï¼ˆinit blockï¼‰å’Œæ›´æ–°å—ï¼ˆupdate blockï¼‰\nNote\nåˆå§‹åŒ–å—ï¼ˆinit blockï¼‰ï¼š ä»å½’çº¦å—çš„åˆå§‹åŒ–è¯­å¥ï¼ˆinit statementï¼‰è½¬æ¢è€Œæ¥ã€‚ æ›´æ–°å—ï¼ˆupdate blockï¼‰ï¼š åŸå§‹çš„å½’çº¦å—ï¼Œä½†å»æ‰äº†åˆå§‹åŒ–è¯­å¥ã€‚ é™åˆ¶æ¡ä»¶ï¼š\nè¦åˆ†è§£çš„å—å¿…é¡»æ˜¯ä¸€ä¸ªå½’çº¦å—ã€‚ æŒ‡å®šçš„å¾ªç¯å¿…é¡»æ˜¯å½’çº¦å—çš„ç¥–å…ˆå¾ªç¯ã€‚ æŒ‡å®šçš„å¾ªç¯ä¸èƒ½ä½äºä¸å½’çº¦å—å˜é‡ç›¸å…³çš„æ‰€æœ‰å¾ªç¯ã€‚ ä»¥çŸ©é˜µä¹˜æ³• C = A @ Bä¸ºä¾‹ï¼Œdecompose_reductionå‰çš„TensorIRä¸º\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 l = te.var(\u0026#34;l\u0026#34;) A = te.placeholder((m, l), name=\u0026#34;A\u0026#34;) B = te.placeholder((l, n), name=\u0026#34;B\u0026#34;) k = te.reduce_axis((0, l), name=\u0026#34;l\u0026#34;) C = te.compute((m, n), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name=\u0026#34;C\u0026#34;) #----------TensorIR Before Decompose Reduction-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle, var_C: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, l = T.int32(), T.int32() A = T.match_buffer(var_A, (m, l)) n = T.int32() B = T.match_buffer(var_B, (l, n)) C = T.match_buffer(var_C, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i, j, l_1 in T.grid(m, n, l): with T.block(\u0026#34;C\u0026#34;): v_i, v_j, v_l = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, l_1]) T.reads(A[v_i, v_l], B[v_l, v_j]) T.writes(C[v_i, v_j]) with T.init(): C[v_i, v_j] = T.float32(0.0) C[v_i, v_j] = C[v_i, v_j] + A[v_i, v_l] * B[v_l, v_j] è°ƒç”¨ decompose_reduction æ–¹æ³•åå°†å— C åˆ†è§£æˆä¸€ä¸ªåˆå§‹åŒ–å—å’Œä¸€ä¸ªæ›´æ–°å—ï¼Œå¹¶å°†åˆå§‹åŒ–å—æ’å…¥åˆ° i å¾ªç¯ä¹‹å‰ï¼Œå¯¹åº”çš„TensorIRå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 sch = tvm.tir.Schedule(ir_module) block_c = sch.get_block(\u0026#34;C\u0026#34;) i, j, k = sch.get_loops(block_c) sch.decompose_reduction(block_c, i) sch.mod.show() #----------TensorIR After Decompose Reduction-------------- @I.ir_module class Module: @T.prim_func def main(var_A: T.handle, var_B: T.handle, var_C: T.handle): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) m, l = T.int32(), T.int32() A = T.match_buffer(var_A, (m, l)) n = T.int32() B = T.match_buffer(var_B, (l, n)) C = T.match_buffer(var_C, (m, n)) # with T.block(\u0026#34;root\u0026#34;): for i_init, j_init in T.grid(m, n): with T.block(\u0026#34;C_init\u0026#34;): v_i, v_j = T.axis.remap(\u0026#34;SS\u0026#34;, [i_init, j_init]) T.reads() T.writes(C[v_i, v_j]) C[v_i, v_j] = T.float32(0.0) for i, j, l_1 in T.grid(m, n, l): with T.block(\u0026#34;C_update\u0026#34;): v_i, v_j, v_l = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, l_1]) T.reads(C[v_i, v_j], A[v_i, v_l], B[v_l, v_j]) T.writes(C[v_i, v_j]) ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tcm-ch10/","summary":"Personal notebook 3.","title":"TVM Learning (3)-Schedule Analysis"},{"content":"Primitive Tensor Function æœºå™¨å­¦ä¹ ç¼–è¯‘çš„è¿‡ç¨‹å¯ä»¥è¢«çœ‹ä½œå¼ é‡å‡½æ•°ä¹‹é—´çš„å˜æ¢ã€‚ä¸€ä¸ªå…¸å‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ‰§è¡ŒåŒ…å«è®¸å¤šæ­¥å°†è¾“å…¥å¼ é‡ä¹‹é—´è½¬åŒ–ä¸ºæœ€ç»ˆé¢„æµ‹çš„è®¡ç®—æ­¥éª¤ï¼Œå…¶ä¸­çš„æ¯ä¸€æ­¥éƒ½è¢«ç§°ä¸ºå…ƒå¼ é‡å‡½æ•° (Primitive Tensor Function) Primitive Tensor Function\né€šå¸¸æ¥è¯´ï¼Œä¸€ä¸ªå…¸å‹çš„å…ƒå¼ é‡å‡½æ•°å®ç°çš„æŠ½è±¡åŒ…å«äº†ä»¥ä¸‹æˆåˆ†ï¼šå­˜å‚¨æ•°æ®çš„å¤šç»´æ•°ç»„ï¼Œé©±åŠ¨å¼ é‡è®¡ç®—çš„å¾ªç¯åµŒå¥—ä»¥åŠè®¡ç®—éƒ¨åˆ†æœ¬èº«çš„è¯­å¥ã€‚ä¸‹å›¾ä»¥ä¸Šä¸€ç¯‡ä¸­çš„å‘é‡åŠ æ³•ä¸ºä¾‹å­è¿›è¡Œäº†åˆ†è§£ã€‚ Tensor Function Elements\næˆ‘ä»¬ç§°è¿™ç±»æŠ½è±¡ä¸ºå¼ é‡ç¨‹åºæŠ½è±¡(Tensor Program Abstraction). å¼ é‡ç¨‹åºæŠ½è±¡çš„ä¸€ä¸ªé‡è¦æ€§è´¨æ˜¯ï¼Œä»–ä»¬èƒ½å¤Ÿè¢«ä¸€ç³»åˆ—æœ‰æ•ˆçš„ç¨‹åºå˜æ¢æ‰€æ”¹å˜ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬èƒ½å¤Ÿé€šè¿‡ä¸€ç»„å˜æ¢æ“ä½œï¼ˆå¦‚å¾ªç¯æ‹†åˆ†ã€å¹¶è¡Œå’Œå‘é‡åŒ–ï¼‰å°†ä¸‹å›¾å·¦ä¾§çš„ä¸€ä¸ªåˆå§‹å¾ªç¯ç¨‹åºå˜æ¢ä¸ºå³ä¾§çš„ç¨‹åºã€‚ Tensor Function Transforms\nLearning one Tensor Program Abstraction \u0026ndash; TensorIR æˆ‘ä»¬å¯¹äºç¥ç»ç½‘ç»œçš„ä¸€ä¸ªåŸºæœ¬çš„ Linear+ReLU å±‚å¯ä»¥ç”¨ä»¥ä¸‹çš„æ•°å­¦å…¬å¼è¡¨ç¤º\n$Y_{ij} = \\sum_k A_{ik} B_{kj}$ $C_{ij} = \\mathbb{ReLU}(Y_{ij}) = \\mathbb{max}(Y_{ij}, 0)$ å…¶Numpyå®ç°å¦‚ä¸‹ï¼Œä¸‹é¢çš„ä»£ç ç›´æ¥è°ƒç”¨äº†Numpyçš„é«˜çº§APIï¼Œçœ‹èµ·æ¥éå¸¸ç®€æ´ã€‚\n1 2 3 4 5 dtype = \u0026#34;float32\u0026#34; a_np = np.random.rand(128, 128).astype(dtype) b_np = np.random.rand(128, 128).astype(dtype) # a @ b is equivalent to np.matmul(a, b) c_mm_relu = np.maximum(a_np @ b_np, 0) æˆ‘ä»¬å¯ä»¥å°†ä¸Šè¿°ç¨‹åºæ”¹å†™æˆLow-level Numpyï¼Œæ„å‘³ç€å¯¹äºå¤æ‚çš„è®¡ç®—æˆ‘ä»¬ä½¿ç”¨å¾ªç¯è¿›è¡Œè¡¨ç¤ºï¼Œå¹¶ä¸”å†™å‡ºå¼€è¾Ÿæ•°ç»„ç©ºé—´çš„è¿‡ç¨‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 def lnumpy_mm_relu(A: np.ndarray, B: np.ndarray, C: np.ndarray): Y = np.empty((128, 128), dtype=\u0026#34;float32\u0026#34;) for i in range(128): for j in range(128): for k in range(128): if k == 0: Y[i, j] = 0 Y[i, j] = Y[i, j] + A[i, k] * B[k, j] for i in range(128): for j in range(128): C[i, j] = max(Y[i, j], 0) è¯¥å‡½æ•°æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\nçŸ©é˜µä¹˜æ³•ï¼š å°†ä¸¤ä¸ªçŸ©é˜µ A å’Œ B ç›¸ä¹˜ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨ Y ä¸­ã€‚ ReLU æ¿€æ´»ï¼š å°† ReLU æ¿€æ´»å‡½æ•°åº”ç”¨äº Y çš„å…ƒç´ ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨ C ä¸­ã€‚ å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç æ¥æ£€æŸ¥ä¸Šè¿°å®ç°çš„æ­£ç¡®æ€§ï¼š\n1 2 3 c_np = np.empty((128, 128), dtype=dtype) lnumpy_mm_relu(a_np, b_np, c_np) np.testing.assert_allclose(c_mm_relu, c_np, rtol=1e-5) ç¤ºä¾‹ numpy ä»£ç åŒ…å«äº†å®é™…è¿‡ç¨‹ä¸­å®ç°è¿™äº›è®¡ç®—æ—¶å¯èƒ½ä¼šç”¨åˆ°çš„æ‰€æœ‰å…ƒç´ ï¼Œç”¨Numpyå‡½æ•°å†…éƒ¨å·¥ä½œæœºåˆ¶ (Under the Hood) å®ç°äº†MM-ReLUã€‚\nå¼€è¾Ÿå¤šç»´æ•°ç»„ç©ºé—´ã€‚ å¾ªç¯éå†æ•°ç»„çš„ç»´åº¦ã€‚ è®¡ç®—åœ¨å¾ªç¯å†…æ‰§è¡Œã€‚ æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨ä¸Šä¸€èŠ‚çš„TensorIRæ¥å®ç°ï¼ŒTVMScript æ˜¯åµŒå…¥åœ¨ Python AST ä¸­çš„é¢†åŸŸç‰¹å®šè¯­è¨€çš„ Dialect, å®ƒæœ¬è´¨ä¸Šæ˜¯ Python çš„ä¸€ä¸ªå­é›†ï¼Œä½†æ·»åŠ äº†ä¸€äº›ç‰¹å®šäº TVM çš„æ‰©å±•ï¼Œä¾‹å¦‚ç”¨äºæè¿°è®¡ç®—å›¾çš„ç‰¹æ®Šè¯­æ³•å’Œè¯­ä¹‰ã€‚\nDialect é€šå¸¸æŒ‡ä¸€ç§è¯­è¨€çš„å˜ä½“æˆ–å­é›†ï¼Œå®ƒä¸åŸå§‹è¯­è¨€å…±äº«å¤§éƒ¨åˆ†è¯­æ³•å’Œè¯­ä¹‰ï¼Œä½†ä¹Ÿæœ‰ä¸€äº›ç‹¬ç‰¹çš„ç‰¹å¾ã€‚ æŠ½è±¡è¯­æ³•æ ‘ (AST) æ˜¯æºä»£ç çš„æ ‘çŠ¶è¡¨ç¤ºå½¢å¼ã€‚å®ƒå°†ä»£ç çš„ç»“æ„ä»¥ä¸€ç§å±‚æ¬¡åŒ–çš„æ–¹å¼å‘ˆç°ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä»£ç ä¸­çš„ä¸€ä¸ªè¯­æ³•å…ƒç´ ï¼Œä¾‹å¦‚å˜é‡ã€è¿ç®—ç¬¦ã€å‡½æ•°è°ƒç”¨ç­‰ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @tvm.script.ir_module class MyModule: @T.prim_func def mm_relu(A: T.Buffer[(128, 128), \u0026#34;float32\u0026#34;], B: T.Buffer[(128, 128), \u0026#34;float32\u0026#34;], C: T.Buffer[(128, 128), \u0026#34;float32\u0026#34;]): T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;mm_relu\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) Y = T.alloc_buffer((128, 128), dtype=\u0026#34;float32\u0026#34;) for i, j, k in T.grid(128, 128, 128): with T.block(\u0026#34;Y\u0026#34;): vi = T.axis.spatial(128, i) vj = T.axis.spatial(128, j) vk = T.axis.reduce(128, k) with T.init(): Y[vi, vj] = T.float32(0) Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj] for i, j in T.grid(128, 128): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(128, i) vj = T.axis.spatial(128, j) C[vi, vj] = T.max(Y[vi, vj], T.float32(0)) ä¸Šè¿° TensorIR ç¨‹åºçš„ä¸€ä¸ªç¤ºä¾‹å®ä¾‹æ¶µç›–äº†å¤§éƒ¨åˆ†å†…å®¹ï¼ŒåŒ…æ‹¬\nå‚æ•°å’Œä¸­é—´ä¸´æ—¶å†…å­˜ä¸­çš„ç¼“å†²åŒºå£°æ˜ã€‚ For å¾ªç¯è¿­ä»£ã€‚ Block å’Œ Block Axiså±æ€§ã€‚ Transformation TVM çš„ tvm.tir.Schedule æä¾›äº†ä¸€ç³»åˆ—ç”¨äºè°ƒåº¦å’Œä¼˜åŒ–è®¡ç®—å›¾çš„å˜æ¢å‡½æ•°ã€‚è¿™äº›å‡½æ•°å…è®¸ç”¨æˆ·çµæ´»åœ°è°ƒæ•´è®¡ç®—é¡ºåºã€å†…å­˜è®¿é—®æ¨¡å¼å’Œå¹¶è¡ŒåŒ–ç­–ç•¥ï¼Œä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚\næˆ‘ä»¬å¯ä»¥ç”¨ä»¥ä¸‹å‡½æ•°è·å¾—è®¡ç®—å—å’Œå…¶å¯¹åº”çš„å¾ªç¯\n1 2 block_Y = sch.get_block(\u0026#34;Y\u0026#34;, func_name=\u0026#34;mm_relu\u0026#34;) i, j, k = sch.get_loops(block_Y) æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ splitå‡½æ•°å°†ä¸€ä¸ªå¾ªç¯æ‹†æˆå¤šä¸ªå¾ªç¯ï¼Œç”¨ reorderå‡½æ•°äº¤æ¢å¾ªç¯çš„é¡ºåºï¼Œç”¨ reverse_compute_at å‡½æ•°ç§»åŠ¨è®¡ç®—å—æ‰€åœ¨çš„å¾ªç¯ï¼Œç”¨ decompose_reductionå‡½æ•°å°†åˆå§‹åŒ–å’Œå½’çº¦æ“ä½œåˆ†å¼€ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 j0, j1 = sch.split(j, factors=[None, 4]) sch.reorder(j0, k, j1) block_C = sch.get_block(\u0026#34;C\u0026#34;, \u0026#34;mm_relu\u0026#34;) sch.reverse_compute_at(block_C, j0) block_Y = sch.get_block(\u0026#34;Y\u0026#34;, \u0026#34;mm_relu\u0026#34;) sch.decompose_reduction(block_Y, k) sch.mod.show() # Output @tvm.script.ir_module class Module: @T.prim_func def mm_relu(A: T.Buffer[(128, 128), \u0026#34;float32\u0026#34;], B: T.Buffer[(128, 128), \u0026#34;float32\u0026#34;], C: T.Buffer[(128, 128), \u0026#34;float32\u0026#34;]) -\u0026gt; None: # function attr dict T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;mm_relu\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) # body # with T.block(\u0026#34;root\u0026#34;) Y = T.alloc_buffer([128, 128], dtype=\u0026#34;float32\u0026#34;) for i, j_0 in T.grid(128, 32): for j_1_init in T.serial(4): with T.block(\u0026#34;Y_init\u0026#34;): vi = T.axis.spatial(128, i) vj = T.axis.spatial(128, j_0 * 4 + j_1_init) T.reads() T.writes(Y[vi, vj]) Y[vi, vj] = T.float32(0) for k, j_1 in T.grid(128, 4): with T.block(\u0026#34;Y_update\u0026#34;): vi = T.axis.spatial(128, i) vj = T.axis.spatial(128, j_0 * 4 + j_1) vk = T.axis.reduce(128, k) T.reads(Y[vi, vj], A[vi, vk], B[vk, vj]) T.writes(Y[vi, vj]) Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj] for ax0 in T.serial(4): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(128, i) vj = T.axis.spatial(128, j_0 * 4 + ax0) T.reads(Y[vi, vj]) T.writes(C[vi, vj]) C[vi, vj] = T.max(Y[vi, vj], T.float32(0)) å¯¹åº”çš„ Low-level Numpy å‡½æ•°å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def lnumpy_mm_relu_v3(A: np.ndarray, B: np.ndarray, C: np.ndarray): Y = np.empty((128, 128), dtype=\u0026#34;float32\u0026#34;) for i in range(128): for j0 in range(32): # Y_init for j1 in range(4): j = j0 * 4 + j1 Y[i, j] = 0 # Y_update for k in range(128): for j1 in range(4): j = j0 * 4 + j1 Y[i, j] = Y[i, j] + A[i, k] * B[k, j] # C for j1 in range(4): j = j0 * 4 + j1 C[i, j] = max(Y[i, j], 0) Why Do Loop Influence the Exec Time CPU Architecture CPU å¸¦æœ‰å¤šçº§ç¼“å­˜ï¼Œéœ€è¦å…ˆå°†æ•°æ®æå–åˆ°ç¼“å­˜ä¸­ï¼Œç„¶å CPU æ‰èƒ½è®¿é—®å®ƒã€‚è€Œä¸”è®¿é—®å·²ç»åœ¨ç¼“å­˜ä¸­çš„æ•°æ®è¦å¿«å¾—å¤šã€‚CPU é‡‡ç”¨çš„ä¸€ç§ç­–ç•¥æ˜¯è·å–å½¼æ­¤æ›´æ¥è¿‘çš„æ•°æ®ã€‚ å½“æˆ‘ä»¬è¯»å–å†…å­˜ä¸­çš„ä¸€ä¸ªå…ƒç´ æ—¶ï¼Œå®ƒä¼šå°è¯•å°†é™„è¿‘çš„å…ƒç´ ï¼ˆCache Lineï¼‰è·å–åˆ°ç¼“å­˜ä¸­ï¼Œå½“è¯»å–ä¸‹ä¸€ä¸ªå…ƒç´ æ—¶å®ƒå·²ç»åœ¨ç¼“å­˜ä¸­ã€‚ å› æ­¤ï¼Œå…·æœ‰è¿ç»­å†…å­˜è®¿é—®çš„ä»£ç é€šå¸¸æ¯”éšæœºè®¿é—®å†…å­˜ä¸åŒéƒ¨åˆ†çš„ä»£ç æ›´å¿«ã€‚\nLoop Order j1 è¿™ä¸€è¿­ä»£äº§ç”Ÿäº†å¯¹ B å…ƒç´ çš„è¿ç»­è®¿é—®ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒæ„å‘³ç€åœ¨ j1=0 å’Œ j1=1 æ—¶æˆ‘ä»¬è¯»å–çš„å€¼å½¼æ­¤ç›¸é‚»ã€‚è¿™å¯ä»¥è®©æˆ‘ä»¬æ‹¥æœ‰æ›´å¥½çš„ç¼“å­˜è®¿é—®è¡Œä¸ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ C çš„è®¡ç®—æ›´æ¥è¿‘ Yï¼Œä»è€Œå®ç°æ›´å¥½çš„ç¼“å­˜è¡Œä¸ºã€‚\nWays to Create and Interact with TensorIR Create TensorIR via TVMScript åˆ›å»º TensorIR å‡½æ•°çš„ç¬¬ä¸€ç§æ–¹æ³•æ˜¯ç›´æ¥åœ¨ TVMScript ä¸­ç¼–å†™å‡½æ•°ï¼Œå®ƒä¹Ÿæ˜¯ä¸€ç§åœ¨å˜æ¢è¿‡ç¨‹ä¸­æ£€æŸ¥å¼ é‡å‡½æ•°çš„æœ‰ç”¨æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥æ‰“å°å‡º TVMScriptï¼Œè¿›è¡Œä¸€äº›æ‰‹åŠ¨ç¼–è¾‘ï¼Œç„¶åå°†å…¶åé¦ˆç»™ MLC æµç¨‹ä»¥è°ƒè¯•å’Œå°è¯•å¯èƒ½çš„ï¼ˆæ‰‹åŠ¨ï¼‰å˜æ¢ï¼Œç„¶åå°†å˜æ¢åçš„ç¨‹åºé‡æ–°åº”ç”¨åˆ° MLC æµç¨‹ä¸­ã€‚\nGenerate TensorIR code using Tensor Expression å¼ é‡è¡¨è¾¾å¼ (TE) æ˜¯ä¸€ç§ç‰¹å®šé¢†åŸŸçš„è¯­è¨€ï¼Œå®ƒé€šè¿‡ API ä¹‹ç±»çš„è¡¨è¾¾å¼æè¿°ä¸€ç³»åˆ—è®¡ç®—ã€‚MM-ReLU å¯ä»¥é€šè¿‡ä»¥ä¸‹ç¨‹åºå®Œæˆ\n1 2 3 4 5 6 from tvm import te A = te.placeholder((128, 128), \u0026#34;float32\u0026#34;, name=\u0026#34;A\u0026#34;) B = te.placeholder((128, 128), \u0026#34;float32\u0026#34;, name=\u0026#34;B\u0026#34;) k = te.reduce_axis((0, 128), \u0026#34;k\u0026#34;) Y = te.compute((128, 128), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name=\u0026#34;Y\u0026#34;) C = te.compute((128, 128), lambda i, j: te.max(Y[i, j], 0), name=\u0026#34;C\u0026#34;) ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch2/","summary":"Personal notebook 2.","title":"TVM Learning (2)-Tensor Program Abstraction Case"},{"content":"My notebook of MLC: https://mlc.ai/summer22-zh\nConstructing Tensor Program by TVMScript åœ¨æœºå™¨å­¦ä¹ ç¼–è¯‘ (Machine Learning Compilation) ä¸­ï¼ŒTensor Program æŒ‡çš„æ˜¯ä¸€ç§è¡¨ç¤ºæœºå™¨å­¦ä¹ æ¨¡å‹è®¡ç®—è¿‡ç¨‹çš„ç¨‹åºï¼Œå®ƒä»¥å¼ é‡ (Tensor) ä¸ºåŸºæœ¬æ•°æ®å•å…ƒï¼Œå¹¶ä½¿ç”¨å¼ é‡æ“ä½œæ¥æè¿°æ¨¡å‹çš„è®¡ç®—æ­¥éª¤ã€‚\nVector-Add Example ä¸‹é¢è¿™æ®µä»£ç ä½¿ç”¨ TVM çš„ script æ¨¡å—å®šä¹‰äº†ä¸€ä¸ªåä¸º MyModule çš„æ¨¡å—ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªåä¸º main çš„è®¡ç®—å‡½æ•°ã€‚\nè¯¥å‡½æ•°å®ç°äº†ç®€å•çš„å‘é‡åŠ æ³• (vector add) æ“ä½œ, ä¸¤ä¸ªè¾“å…¥å‘é‡ A å’Œ B ç›¸åŠ ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åˆ°è¾“å‡ºå‘é‡ C ä¸­ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import tvm from tvm.ir.module import IRModule from tvm.script import tir as T import numpy as np @tvm.script.ir_module class MyModule: @T.prim_func def main(A: T.Buffer[128, \u0026#34;float32\u0026#34;], B: T.Buffer[128, \u0026#34;float32\u0026#34;], C: T.Buffer[128, \u0026#34;float32\u0026#34;]): # extra annotations for the function T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) for i in range(128): with T.block(\u0026#34;C\u0026#34;): # declare a data parallel iterator on spatial domain vi = T.axis.spatial(128, i) C[vi] = A[vi] + B[vi] 1. æ¨¡å—å®šä¹‰:\n1 2 3 @tvm.script.ir_module class MyModule: # ... @tvm.script.ir_module: ç”¨äºå°† MyModule ç±»å®šä¹‰ä¸ºä¸€ä¸ª TVM çš„ IRModule å¯¹è±¡ã€‚IRModule æ˜¯ TVM ä¸­ç”¨äºè¡¨ç¤ºè®¡ç®—å›¾ (Computation Graph) çš„æ ‡å‡†æ•°æ®ç»“æ„ã€‚ class MyModule:: å®šä¹‰ä¸€ä¸ªåä¸º MyModule çš„ç±»ï¼Œè¯¥ç±»å°†åŒ…å«è®¡ç®—å‡½æ•°ã€‚ Decorator åœ¨ Python ä¸­ï¼Œè£…é¥°å™¨ (Decorator) æ˜¯ä¸€ç§ç‰¹æ®Šçš„å‡½æ•°ï¼Œå®ƒå¯ä»¥ç”¨æ¥ä¿®æ”¹å…¶ä»–å‡½æ•°çš„è¡Œä¸ºï¼Œè€Œæ— éœ€ç›´æ¥ä¿®æ”¹è¢«è£…é¥°çš„å‡½æ•°ä»£ç ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 def decorator_function(func): def wrapper(*args, **kwargs): # åœ¨è°ƒç”¨è¢«è£…é¥°çš„å‡½æ•°ä¹‹å‰æ‰§è¡Œçš„æ“ä½œ result = func(*args, **kwargs) # åœ¨è°ƒç”¨è¢«è£…é¥°çš„å‡½æ•°ä¹‹åæ‰§è¡Œçš„æ“ä½œ return result return wrapper @decorator_function def my_function(x, y): # è¢«è£…é¥°çš„å‡½æ•° return x + y decorator_function: è£…é¥°å™¨å‡½æ•°ï¼Œå®ƒæ¥æ”¶è¢«è£…é¥°çš„å‡½æ•°ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…è£…å‡½æ•°ã€‚ wrapper: åŒ…è£…å‡½æ•°ï¼Œå®ƒåœ¨è°ƒç”¨è¢«è£…é¥°çš„å‡½æ•°ä¹‹å‰å’Œä¹‹åæ‰§è¡Œä¸€äº›æ“ä½œã€‚ @decorator_function: è£…é¥°å™¨è¯­æ³•ï¼Œå°† decorator_function åº”ç”¨åˆ° my_function ä¸Šã€‚ è£…é¥°å™¨çš„å·¥ä½œåŸç†:\nå½“ Python é‡åˆ° @decorator_function è¯­æ³•æ—¶ï¼Œå®ƒä¼šå°† my_function ä½œä¸ºå‚æ•°ä¼ é€’ç»™ decorator_functionã€‚ decorator_function æ‰§è¡Œï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…è£…å‡½æ•° wrapperã€‚ wrapper å‡½æ•°å°†æ›¿æ¢ my_function çš„åŸå§‹å®šä¹‰ã€‚ å½“è°ƒç”¨ my_function æ—¶ï¼Œå®é™…ä¸Šæ˜¯åœ¨è°ƒç”¨ wrapper å‡½æ•°ã€‚ 2. è®¡ç®—å‡½æ•°å®šä¹‰:\n1 2 3 4 5 @T.prim_func def main(A: T.Buffer[128, \u0026#34;float32\u0026#34;], B: T.Buffer[128, \u0026#34;float32\u0026#34;], C: T.Buffer[128, \u0026#34;float32\u0026#34;]): # ... @T.prim_func: è¿™æ˜¯ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºå°† main å‡½æ•°å®šä¹‰ä¸ºä¸€ä¸ª TVM çš„ prim_func å¯¹è±¡ã€‚prim_func æ˜¯ TVM ä¸­ç”¨äºè¡¨ç¤ºåº•å±‚è®¡ç®—å‡½æ•°çš„æ ‡å‡†æ•°æ®ç»“æ„ã€‚ def main(...): å®šä¹‰ä¸€ä¸ªåä¸º main çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸‰ä¸ªå‚æ•°ï¼š A: ä¸€ä¸ªé•¿åº¦ä¸º 128 çš„ float32 ç±»å‹ Bufferï¼Œè¡¨ç¤ºç¬¬ä¸€ä¸ªè¾“å…¥å‘é‡ã€‚ B: ä¸€ä¸ªé•¿åº¦ä¸º 128 çš„ float32 ç±»å‹ Bufferï¼Œè¡¨ç¤ºç¬¬äºŒä¸ªè¾“å…¥å‘é‡ã€‚ C: ä¸€ä¸ªé•¿åº¦ä¸º 128 çš„ float32 ç±»å‹ Bufferï¼Œç”¨äºå­˜å‚¨è®¡ç®—ç»“æœã€‚ 3. å‡½æ•°å±æ€§:\n1 T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) T.func_attr({\u0026quot;global_symbol\u0026quot;: \u0026quot;main\u0026quot;, \u0026quot;tir.noalias\u0026quot;: True})ï¼š è®¾ç½®å‡½æ•°çš„å±æ€§ã€‚ global_symbol: è®¾ç½®å‡½æ•°çš„å…¨å±€ç¬¦å·åç§°ä¸º mainã€‚ tir.noalias: è®¾ç½®å‡½æ•°çš„åˆ«åå±æ€§ä¸º Trueï¼Œè¡¨ç¤ºå‡½æ•°ä¸ä¼šä¿®æ”¹è¾“å…¥ç¼“å†²åŒºã€‚ 4. è®¡ç®—å¾ªç¯:\n1 2 3 for i inrange(128): with T.block(\u0026#34;C\u0026#34;): # ... T.block å°†è®¡ç®—å›¾åˆ†è§£æˆå¤šä¸ªç‹¬ç«‹çš„è®¡ç®—å—ï¼Œæ¯ä¸ªå—å¯¹åº”ä¸€ä¸ªç‰¹å®šçš„è®¡ç®—ä»»åŠ¡ï¼Œå¯ä»¥åŒ…å«å¤šä¸ªè¿­ä»£å™¨ï¼Œè¿™äº›è¿­ä»£å™¨å…±åŒå®šä¹‰äº†è®¡ç®—å—çš„è®¡ç®—èŒƒå›´ã€‚\nfor i in range(128): å®šä¹‰ä¸€ä¸ªå¾ªç¯ï¼Œè¿­ä»£ 128 æ¬¡ï¼Œç”¨äºå¤„ç†æ¯ä¸ªå‘é‡å…ƒç´ ã€‚ with T.block(\u0026quot;C\u0026quot;): å®šä¹‰ä¸€ä¸ªåä¸º C çš„è®¡ç®—å—ï¼Œè¯¥å—åŒ…å«å¾ªç¯çš„è®¡ç®—é€»è¾‘ã€‚ 5. è¿­ä»£å™¨å®šä¹‰:\n1 vi = T.axis.spatial(128, i) vi = T.axis.spatial(128, i): å®šä¹‰ä¸€ä¸ªåä¸º vi çš„ç©ºé—´è¿­ä»£å™¨ï¼Œå®ƒéå† 128 ä¸ªå…ƒç´ ï¼Œæ¯ä¸ªå…ƒç´ çš„ç´¢å¼•ç”± i ç¡®å®šã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œç©ºé—´è¿­ä»£å™¨çš„è®¿é—®é¡ºåºå¯¹æœ€åç»“æœä¸äº§ç”Ÿå½±å“ã€‚\n6. è®¡ç®—æ“ä½œ:\n1 C[vi] = A[vi] + B[vi] C[vi] = A[vi] + B[vi]ï¼š å°† A å’Œ B ä¸­å¯¹åº”å…ƒç´ ç›¸åŠ ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åˆ° C ä¸­ã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡ MyModule.show() æ¥æ˜¾ç¤ºæ„å»ºçš„IRModule.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @tvm.script.ir_module class Module: @T.prim_func def main(A: T.Buffer[128, \u0026#34;float32\u0026#34;], B: T.Buffer[128, \u0026#34;float32\u0026#34;], C: T.Buffer[128, \u0026#34;float32\u0026#34;]) -\u0026gt; None: # function attr dict T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) # body # with T.block(\u0026#34;root\u0026#34;) for i in T.serial(128): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(128, i) T.reads(A[vi], B[vi]) T.writes(C[vi]) C[vi] = A[vi] + B[vi] Build and Run æˆ‘ä»¬å¯ä»¥é€šè¿‡ tvm.buildå‡½æ•°å°†ä¸€ä¸ªIRModuleè½¬å˜æˆå¯ä»¥è¿è¡Œçš„å‡½æ•°ï¼Œé€šè¿‡å®šä¹‰çš„å‡½æ•°åå¯ä»¥è·å–æƒ³è¦çš„å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸‰ä¸ª NDArray æ•°ç»„æ¥è°ƒç”¨å‡½æ•°ã€‚\n1 2 3 4 5 6 rt_mod = tvm.build(MyModule, target=\u0026#34;llvm\u0026#34;) func = rt_mod[\u0026#34;main\u0026#34;] a = tvm.nd.array(np.arange(128, dtype=\u0026#34;float32\u0026#34;)) b = tvm.nd.array(np.ones(128, dtype=\u0026#34;float32\u0026#34;)) c = tvm.nd.empty((128,), dtype=\u0026#34;float32\u0026#34;) func(a, b, c) tvm.build å‡½æ•°çš„å‚æ•°:\nfunc: è¦ç¼–è¯‘çš„è®¡ç®—å›¾ï¼Œå¯ä»¥æ˜¯ tvm.script.ir_module å¯¹è±¡ã€tvm.relay.Function å¯¹è±¡æˆ–å…¶ä»–æ”¯æŒçš„è®¡ç®—å›¾ç±»å‹ã€‚ target: ç›®æ ‡å¹³å°ï¼Œä¾‹å¦‚ï¼Œllvm -mcpu=core-avx2ã€cudaã€opencl ç­‰ã€‚ name: ç¼–è¯‘åçš„æ¨¡å—åç§°ã€‚ Transform the Tensor Program åœ¨ TVM ä¸­ï¼Œtvm.tir.Schedule æ˜¯ä¸€ä¸ªç”¨äºå¯¹è®¡ç®—å›¾è¿›è¡Œæ‰‹åŠ¨ä¼˜åŒ–çš„å·¥å…·ã€‚å®ƒå…è®¸å¯¹è®¡ç®—å›¾ä¸­çš„å¾ªç¯ã€å—å’Œæ“ä½œè¿›è¡Œé‡æ’åºã€èåˆã€å¹¶è¡ŒåŒ–ç­‰æ“ä½œï¼Œä»¥æé«˜è®¡ç®—æ•ˆç‡ã€‚\nä¸‹é¢è¿™æ®µä»£ç åšäº†ä»¥ä¸‹ä¼˜åŒ–ï¼š\nå¾ªç¯åˆ‡åˆ†: å°†å¾ªç¯ i åˆ‡åˆ†æˆä¸‰ä¸ªå¾ªç¯ï¼Œå¯ä»¥æ›´å¥½åœ°åˆ©ç”¨å†…å­˜å±€éƒ¨æ€§ï¼Œä¾‹å¦‚ï¼Œå°† i_1 å’Œ i_2 çš„å¤§å°è®¾ç½®ä¸º 4ï¼Œå¯ä»¥å°†æ•°æ®åŠ è½½åˆ°ç¼“å­˜ä¸­ï¼Œå‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°ã€‚ å¾ªç¯é‡æ’åº: æŒ‰ç…§ i_0ã€i_2 å’Œ i_1 è¿™ä¸ªé¡ºåºæ‰§è¡Œã€‚ å¹¶è¡ŒåŒ–: å°† i_0 å¹¶è¡ŒåŒ–ï¼Œå¯ä»¥åˆ©ç”¨å¤šæ ¸ CPU æˆ– GPU çš„è®¡ç®—èƒ½åŠ›ï¼Œæé«˜è®¡ç®—é€Ÿåº¦ 1 2 3 4 5 6 7 8 9 10 11 sch = tvm.tir.Schedule(MyModule) # Get block by its name block_c = sch.get_block(\u0026#34;C\u0026#34;) # Get loops surronding the block (i,) = sch.get_loops(block_c) # Tile the loop nesting. i_0, i_1, i_2 = sch.split(i, factors=[None, 4, 4]) # Reorder the loop. sch.reorder(i_0, i_2, i_1) sch.parallel(i_0) sch.mod.show() ä¼˜åŒ–åçš„è®¡ç®—å›¾å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @tvm.script.ir_module class Module: @T.prim_func def main(A: T.Buffer[128, \u0026#34;float32\u0026#34;], B: T.Buffer[128, \u0026#34;float32\u0026#34;], C: T.Buffer[128, \u0026#34;float32\u0026#34;]) -\u0026gt; None: # function attr dict T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) # body # with T.block(\u0026#34;root\u0026#34;) for i_0 in T.parallel(8): for i_2, i_1 in T.grid(4, 4): with T.block(\u0026#34;C\u0026#34;): vi = T.axis.spatial(128, i_0 * 16 + i_1 * 4 + i_2) T.reads(A[vi], B[vi]) T.writes(C[vi]) C[vi] = A[vi] + B[vi] Constructing Tensor Program by Tensor Expression Tensor Expression æŒ‡çš„æ˜¯ä¸€ç§ç”¨äºæè¿°å¼ é‡è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ã€‚\nConstruct Vector-Add by TE æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ¥åˆ›å»ºå’Œ ä¸Šä¸€èŠ‚ ä¸€æ ·çš„IRModule.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # namespace for tensor expression utility from tvm import te # declare the computation using the expression API A = te.placeholder((128, ), name=\u0026#34;A\u0026#34;) B = te.placeholder((128, ), name=\u0026#34;B\u0026#34;) C = te.compute((128,), lambda i: A[i] + B[i], name=\u0026#34;C\u0026#34;) # create a function with the specified list of arguments. func = te.create_prim_func([A, B, C]) # mark that the function name is main func = func.with_attr(\u0026#34;global_symbol\u0026#34;, \u0026#34;main\u0026#34;) ir_mod_from_te = IRModule({\u0026#34;main\u0026#34;: func}) ir_mod_from_te.show() å®šä¹‰å¼ é‡:\nA = te.placeholder((128,), name=\u0026#34;A\u0026#34;) B = te.placeholder((128,), name=\u0026#34;B\u0026#34;) è¿™ä¸¤è¡Œä»£ç å®šä¹‰äº†ä¸¤ä¸ªåä¸º A å’Œ B çš„å¼ é‡ï¼Œå®ƒä»¬éƒ½æ˜¯ä¸€ç»´å¼ é‡ï¼Œå¤§å°ä¸º 128ã€‚te.placeholder å‡½æ•°ç”¨äºåˆ›å»ºå ä½ç¬¦å¼ é‡ï¼Œå®ƒä»£è¡¨è¾“å…¥æ•°æ®ã€‚\nå®šä¹‰è®¡ç®—:\nC = te.compute((128,), lambda i: A[i] + B[i], name=\u0026#34;C\u0026#34;) è¿™è¡Œä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º C çš„å¼ é‡ï¼Œå®ƒè¡¨ç¤º A å’Œ B çš„å…ƒç´ ç›¸åŠ çš„ç»“æœã€‚te.compute å‡½æ•°ç”¨äºå®šä¹‰å¼ é‡è®¡ç®—ï¼Œå®ƒæ¥å—ä¸¤ä¸ªå‚æ•°ï¼š\nç¬¬ä¸€ä¸ªå‚æ•° shapeæ˜¯å¼ é‡çš„å½¢çŠ¶ï¼Œè¿™é‡Œä¸º (128,)ã€‚ ç¬¬äºŒä¸ªå‚ fcomputeæ•°æ˜¯ä¸€ä¸ª lambda å‡½æ•°ï¼Œå®ƒå®šä¹‰äº†æ¯ä¸ªå…ƒç´ çš„è®¡ç®—æ–¹å¼ï¼Œè¿™é‡Œä¸º A[i] + B[i]ï¼Œè¡¨ç¤º C çš„ç¬¬ i ä¸ªå…ƒç´ ç­‰äº A çš„ç¬¬ i ä¸ªå…ƒç´ åŠ ä¸Š B çš„ç¬¬ i ä¸ªå…ƒç´ ã€‚ åˆ›å»º PrimFunc:\nfunc = te.create_prim_func([A, B, C]) è¿™è¡Œä»£ç ä½¿ç”¨ te.create_prim_func å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ª PrimFunc å¯¹è±¡ï¼Œå®ƒä»£è¡¨ä¸€ä¸ª TVM çš„åŸºæœ¬è®¡ç®—å‡½æ•°ã€‚te.create_prim_func å‡½æ•°æ¥å—ä¸€ä¸ªå‚æ•°ï¼Œå³å‡½æ•°çš„è¾“å…¥å‚æ•°åˆ—è¡¨ï¼Œè¿™é‡Œä¸º [A, B, C]\nè®¾ç½®å‡½æ•°åç§°:\nfunc = func.with_attr(\u0026#34;global_symbol\u0026#34;, \u0026#34;main\u0026#34;) è¿™è¡Œä»£ç å°†å‡½æ•°çš„åç§°è®¾ç½®ä¸º mainï¼Œwith_attr å‡½æ•°ç”¨äºè®¾ç½®å‡½æ•°çš„å±æ€§ã€‚\nåˆ›å»º IRModule:\nir_mod_from_te = IRModule({\u0026#34;main\u0026#34;: func}) è¿™è¡Œä»£ç åˆ›å»ºäº†ä¸€ä¸ª IRModule å¯¹è±¡ï¼Œå®ƒåŒ…å«äº† func å‡½æ•°ï¼Œå¹¶å°†è¯¥å‡½æ•°å­˜å‚¨åœ¨ IRModule çš„ main å­—æ®µä¸­ã€‚\nTransforming a matrix multiplication program ä¸‹é¢ä»£ç å±•ç¤ºäº†ä¸¤ä¸ª $1024 \\times 1024$ çŸ©é˜µç›¸ä¹˜çš„IRModuleåˆ›å»ºæµç¨‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 M = 1024 K = 1024 N = 1024 # The default tensor type in tvm dtype = \u0026#34;float32\u0026#34; target = \u0026#34;llvm\u0026#34; dev = tvm.device(target, 0) # Algorithm k = te.reduce_axis((0, K), \u0026#34;k\u0026#34;) A = te.placeholder((M, K), name=\u0026#34;A\u0026#34;) B = te.placeholder((K, N), name=\u0026#34;B\u0026#34;) C = te.compute((M, N), lambda m, n: te.sum(A[m, k] * B[k, n], axis=k), name=\u0026#34;C\u0026#34;) # Default schedule func = te.create_prim_func([A, B, C]) func = func.with_attr(\u0026#34;global_symbol\u0026#34;, \u0026#34;main\u0026#34;) ir_module = IRModule({\u0026#34;main\u0026#34;: func}) ir_module.show() func = tvm.build(ir_module, target=\u0026#34;llvm\u0026#34;) # The module for CPU backends. a = tvm.nd.array(np.random.rand(M, K).astype(dtype), dev) b = tvm.nd.array(np.random.rand(K, N).astype(dtype), dev) c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev) func(a, b, c) # Create evaluation function evaluator = func.time_evaluator(func.entry_name, dev, number=1) print(\u0026#34;Baseline: %f\u0026#34; % evaluator(a, b, c).mean) time_evaluator æ˜¯ IRModule ç”¨äºè¯„ä¼°è®¡ç®—å›¾æ‰§è¡Œæ—¶é—´çš„æ–¹æ³•ã€‚å®ƒå¯ä»¥å¸®åŠ©æµ‹é‡ä¸åŒç¡¬ä»¶å¹³å°ä¸Šä¸åŒè®¡ç®—å›¾çš„æ€§èƒ½ï¼Œå¹¶è¿›è¡Œä¼˜åŒ–ã€‚\ntime evaluator 1 IRModule.time_evaluator(func, args, number=1, repeat=1, min_repeat_ms=0, f_type=0) å‚æ•°è§£é‡Š:\nfunc: è¦è¯„ä¼°çš„è®¡ç®—å›¾å‡½æ•°ã€‚ args: è®¡ç®—å›¾å‡½æ•°çš„è¾“å…¥å‚æ•°ï¼Œå¯ä»¥æ˜¯å¼ é‡æˆ–å…¶ä»–æ•°æ®ç»“æ„ã€‚ number: æ¯æ¬¡è¿è¡Œè®¡ç®—å›¾çš„æ¬¡æ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚ repeat: é‡å¤è¿è¡Œè®¡ç®—å›¾çš„æ¬¡æ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚ min_repeat_ms: æœ€å°è¿è¡Œæ—¶é—´ï¼Œå•ä½ä¸ºæ¯«ç§’ã€‚å¦‚æœè®¡ç®—å›¾è¿è¡Œæ—¶é—´å°äº min_repeat_msï¼Œåˆ™ä¼šç»§ç»­è¿è¡Œç›´åˆ°è¾¾åˆ° min_repeat_msã€‚é»˜è®¤å€¼ä¸º 0ã€‚ f_type: è¿è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 0ï¼ˆé»˜è®¤å€¼ï¼‰ã€1 æˆ– 2ã€‚ 0ï¼šæ­£å¸¸è¿è¡Œæ¨¡å¼ã€‚ 1ï¼šä»…æ‰§è¡Œç¼–è¯‘ï¼Œä¸è¿è¡Œè®¡ç®—å›¾ã€‚ 2ï¼šä»…æ‰§è¡Œè¿è¡Œï¼Œä¸ç¼–è¯‘è®¡ç®—å›¾ã€‚ func.time_evaluator çš„è¿”å›å€¼:\nfunc.time_evaluator è¿”å›ä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ä»¥ç”¨æ¥æ‰§è¡Œè¯„ä¼°å¹¶è¿”å›ä¸€ä¸ªåŒ…å«æ€§èƒ½æŒ‡æ ‡çš„å­—å…¸ã€‚\næ€§èƒ½æŒ‡æ ‡:\nmean: å¹³å‡è¿è¡Œæ—¶é—´ï¼Œå•ä½ä¸ºæ¯«ç§’ã€‚ median: ä¸­ä½æ•°è¿è¡Œæ—¶é—´ï¼Œå•ä½ä¸ºæ¯«ç§’ã€‚ min: æœ€å°è¿è¡Œæ—¶é—´ï¼Œå•ä½ä¸ºæ¯«ç§’ã€‚ max: æœ€å¤§è¿è¡Œæ—¶é—´ï¼Œå•ä½ä¸ºæ¯«ç§’ã€‚ std: æ ‡å‡†å·®ï¼Œå•ä½ä¸ºæ¯«ç§’ã€‚ ä»£ç çš„å¤§éƒ¨åˆ†æµç¨‹ç›¸åŒï¼Œæˆ‘ä»¬æ¥çœ‹è®¡ç®—éƒ¨åˆ†ã€‚\nå®šä¹‰çº¦ç®€è½´ (Reduce axis):\nk = te.reduce_axis((0, K), \u0026#34;k\u0026#34;) è¿™è¡Œä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º k çš„çº¦ç®€è½´ï¼Œè¡¨ç¤ºåœ¨çŸ©é˜µä¹˜æ³•æ“ä½œä¸­è¿›è¡Œæ±‚å’Œçš„ç»´åº¦ï¼ŒèŒƒå›´ä¸º (0, K)\nå®šä¹‰è¾“å…¥çŸ©é˜µ (Placeholders):\nA = te.placeholder((M, K), name=\u0026#34;A\u0026#34;)\rB = te.placeholder((K, N), name=\u0026#34;B\u0026#34;) è¿™ä¸¤è¡Œä»£ç å®šä¹‰äº†ä¸¤ä¸ªåä¸º A å’Œ B çš„è¾“å…¥çŸ©é˜µï¼Œå®ƒä»¬åˆ†åˆ«ä»£è¡¨çŸ©é˜µä¹˜æ³•çš„ä¸¤ä¸ªè¾“å…¥çŸ©é˜µã€‚A çš„å½¢çŠ¶ä¸º (M, K)ï¼ŒB çš„å½¢çŠ¶ä¸º (K, N)\nå®šä¹‰è¾“å‡ºçŸ©é˜µ (Compute):\nC = te.compute((M, N), lambda m, n: te.sum(A[m, k] * B[k, n], axis=k), name=\u0026#34;C\u0026#34;) è¿™è¡Œä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º C çš„è¾“å‡ºçŸ©é˜µï¼Œå®ƒè¡¨ç¤ºçŸ©é˜µä¹˜æ³•çš„ç»“æœã€‚C çš„å½¢çŠ¶ä¸º (M, N)ï¼Œé‡‡ç”¨ te.sumè®¡ç®—ç»“æœã€‚\nte.sum 1 te.sum(expr, axis=None, keepdims=False, where=None) å‚æ•°è§£é‡Š:\nexpr: è¦è¿›è¡Œæ±‚å’Œçš„è¡¨è¾¾å¼ï¼Œå¯ä»¥æ˜¯å¼ é‡ã€æ ‡é‡æˆ–å…¶ä»–è¡¨è¾¾å¼ã€‚ axis: è¦è¿›è¡Œæ±‚å’Œçš„è½´ï¼Œå¯ä»¥æ˜¯æ•´æ•°ã€å…ƒç»„æˆ–åˆ—è¡¨ã€‚å¦‚æœ axis ä¸º Noneï¼Œåˆ™å¯¹æ‰€æœ‰è½´è¿›è¡Œæ±‚å’Œã€‚ keepdims: å¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦ä¿ç•™æ±‚å’Œåçš„ç»´åº¦ã€‚å¦‚æœä¸º Trueï¼Œåˆ™ä¿ç•™æ±‚å’Œåçš„ç»´åº¦ï¼Œå¹¶å°†å…¶å¤§å°è®¾ç½®ä¸º 1ã€‚å¦‚æœä¸º Falseï¼Œåˆ™åˆ é™¤æ±‚å’Œåçš„ç»´åº¦ã€‚ where: å¸ƒå°”å€¼å¼ é‡ï¼Œè¡¨ç¤ºè¦è¿›è¡Œæ±‚å’Œçš„å…ƒç´ ã€‚å¦‚æœ where ä¸º Noneï¼Œåˆ™å¯¹æ‰€æœ‰å…ƒç´ è¿›è¡Œæ±‚å’Œã€‚ åˆ›å»ºçš„IRModuleå¦‚ä¸‹æ‰€ç¤ºã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @tvm.script.ir_module class Module: @T.prim_func def main(A: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], B: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], C: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;]) -\u0026gt; None: # function attr dict T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) # body # with T.block(\u0026#34;root\u0026#34;) for i0, i1, i2 in T.grid(1024, 1024, 1024): with T.block(\u0026#34;C\u0026#34;): m, n, k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, i1, i2]) T.reads(A[m, k], B[k, n]) T.writes(C[m, n]) with T.init(): C[m, n] = T.float32(0) C[m, n] = C[m, n] + A[m, k] * B[k, n] æˆ‘ä»¬å¯ä»¥å°†å¾ªç¯æ‹†åˆ†æˆå¤–å±‚å¾ªç¯å’Œå†…å±‚å¾ªç¯å¯ä»¥æé«˜æ•°æ®å±€éƒ¨æ€§ã€‚å†…å±‚å¾ªç¯è®¿é—®çš„æ•°æ®æ›´æ¥è¿‘ï¼Œå¯ä»¥æœ‰æ•ˆåˆ©ç”¨ç¼“å­˜ã€‚ä¸‹é¢ä»£ç çš„ block_size å‚æ•°æ§åˆ¶äº†å†…å±‚å¾ªç¯çš„å¤§å°ï¼Œé€‰æ‹©åˆé€‚çš„å—å¤§å°å¯ä»¥æœ€å¤§ç¨‹åº¦åœ°åˆ©ç”¨ç¼“å­˜ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 sch = tvm.tir.Schedule(ir_module) block_c = sch.get_block(\u0026#34;C\u0026#34;) # Get loops surronding the block (y, x, k) = sch.get_loops(block_c) block_size = 32 yo, yi = sch.split(y, [None, block_size]) xo, xi = sch.split(x, [None, block_size]) sch.reorder(yo, xo, k, yi, xi) sch.mod.show() func = tvm.build(sch.mod, target=\u0026#34;llvm\u0026#34;) # The module for CPU backends. c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev) func(a, b, c) evaluator = func.time_evaluator(func.entry_name, dev, number=1) print(\u0026#34;after transformation: %f\u0026#34; % evaluator(a, b, c).mean) åˆ›å»ºçš„IRModuleå¦‚ä¸‹æ‰€ç¤ºã€‚å®é™…ä¸­æˆ‘ä»¬ä¼šæµ‹è¯•å¾ˆå¤šä¸åŒ block_sizeå¯¹åº”çš„æ‰§è¡Œæ—¶é—´æ¥é€‰æ‹©æœ€åˆé€‚çš„ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @tvm.script.ir_module class Module: @T.prim_func def main(A: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], B: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;], C: T.Buffer[(1024, 1024), \u0026#34;float32\u0026#34;]) -\u0026gt; None: # function attr dict T.func_attr({\u0026#34;global_symbol\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;tir.noalias\u0026#34;: True}) # body # with T.block(\u0026#34;root\u0026#34;) for i0_0, i1_0, i2, i0_1, i1_1 in T.grid(32, 32, 1024, 32, 32): with T.block(\u0026#34;C\u0026#34;): m = T.axis.spatial(1024, i0_0 * 32 + i0_1) n = T.axis.spatial(1024, i1_0 * 32 + i1_1) k = T.axis.reduce(1024, i2) T.reads(A[m, k], B[k, n]) T.writes(C[m, n]) with T.init(): C[m, n] = T.float32(0) C[m, n] = C[m, n] + A[m, k] * B[k, n] ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch1/","summary":"Personal notebook 1.","title":"TVM Learning (1)-Tensor Program Abstraction in Action"},{"content":"IRModule: The key concept in TVM Unity IRModule æ˜¯å¼ é‡å‡½æ•°çš„é›†åˆï¼Œä»£è¡¨æˆ‘ä»¬éœ€è¦åœ¨æ¨¡å‹ä¸­æ‰§è¡Œçš„è®¡ç®—å­é›†ã€‚ä¾‹å¦‚ï¼Œåœ¨ MLC-LLM ä¸­ï¼Œå®ƒå¯ä»¥æ˜¯ä¸€ä¸ª Transformer æ¨¡å—ã€‚ æœºå™¨å­¦ä¹ ç¼–è¯‘æ¡†æ¶ä¸­çš„ IRModule å°±åƒæ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­çš„å¼ é‡ï¼Œæ˜¯ä¸€åˆ‡çš„åŸºç¡€ã€‚åœ¨æ•´ä¸ªç¼–è¯‘æµç¨‹ä¸­ï¼Œæ¨¡å‹å°†ä»¥ IRModule çš„å½¢å¼å¯¼å…¥ï¼Œç„¶åä»¥ IRModule åˆ° IRModule çš„æ–¹å¼è¿›è¡Œè½¬æ¢å’Œä¼˜åŒ–ï¼Œç„¶åæˆ‘ä»¬å°±å¯ä»¥åœ¨ä»»ä½•æ”¯æŒçš„å¹³å°ä¸Šå°† IRModule è½¬åŒ–ä¸ºå¯è¿è¡Œçš„æ¨¡å—ã€‚IRModule å¯ä»¥ç”¨ python æ–¹å¼è®¿é—®ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ python AST çš„å½¢å¼æ˜¾ç¤ºå®ƒï¼Œä»¥ä¾¿æ£€æŸ¥ã€è°ƒæ•´å’Œè°ƒè¯•ã€‚unity çš„ä¸»è¦è®¾è®¡ç›®æ ‡ä¹‹ä¸€æ˜¯å®ç°å•ä¸€æŠ½è±¡ï¼Œå°†æ‰€æœ‰ä¸»è¦å…ƒç´ å°è£…åœ¨åŒä¸€æ¨¡å—ä¸­ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±èƒ½åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæœ‰æœºçš„å¢é‡è½¬æ¢ã€‚\nTVM Unity.png\nTVMScript æ˜¯ IRModule çš„ python AST æ ¼å¼ï¼Œç”¨äºåœ¨æ•´å¥—è½¬æ¢è¿‡ç¨‹ä¸­æ£€æŸ¥ IRModules å¹¶ä¸ä¹‹äº¤äº’ã€‚ä¸ IRModule çš„äº¤äº’éƒ½å¯ä»¥ä½¿ç”¨ TVMScript åœ¨ python ä¸­è¿›è¡Œã€‚ç”¨æˆ·å°† TVMScript è§£æä¸º IRModule å†…éƒ¨ç»“æ„ï¼Œä½¿ç”¨ python API æ“ä½œ IRModuleï¼Œå¹¶å°† IRModule æ‰“å°ä¸º TVMScript æ ¼å¼ã€‚\nTVMScript Examples ç”¨ Pytorch æ¡†æ¶å®ç°çŸ©é˜µä¹˜æ³•ä¸€èˆ¬è°ƒç”¨ torch.matmul æˆ–è€…ä½¿ç”¨ @ ç®—å­ã€‚\n1 2 3 4 5 6 7 8 9 10 import torch a = torch.randn((3, 4)) b = torch.randn((4, 5)) print(torch.matmul(a, b)) \u0026#39;\u0026#39;\u0026#39; tensor([[ 2.5387, 2.2756, -2.2032, 2.5928, -3.6539], [ 2.0151, 0.0628, -0.8041, -1.6947, 0.2884], [-0.8118, -0.0453, 0.0742, -1.2028, 1.3722]]) \u0026#39;\u0026#39;\u0026#39; åœ¨ Relax ä¸­å¯ä»¥ç”¨ IRModule å®ç°ç›¸åŒçš„åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 from tvm.script import ir as I from tvm.script import relax as R @I.ir_module class Module: @R.function def main(A: R.Tensor((3, 4), dtype=\u0026#34;float32\u0026#34;), B: R.Tensor((4, 5), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((3, 5), dtype=\u0026#34;float32\u0026#34;): with R.dataflow(): lv: R.Tensor((3, 5), dtype=\u0026#34;float32\u0026#34;) = R.matmul(A, B, out_dtype=\u0026#34;void\u0026#34;) R.output(lv) return lv é€šè¿‡ä¸Šè¿° TVMScript åˆ›å»ºçš„ IRModule æ˜¯ä¸€ä¸ªå®Œå…¨å›¾çº§åˆ«çš„æŠ½è±¡ï¼ŒåªåŒ…å«ä¸€ä¸ª R.function (Relax å‡½æ•°ï¼š IRModule ä¸­è®¡ç®—å›¾çš„è¡¨ç¤ºå½¢å¼) ä¸Šè¿°ç¤ºä¾‹åŒ…å« Relax å‡½æ•°ä¸­çš„ä¸¤ä¸ªé‡è¦æ¦‚å¿µï¼šé«˜çº§ Relax ç®—å­å’Œæ•°æ®æµå—ã€‚\nRelax å‡½æ•°åŒ…å«é«˜çº§ Relax ç®—å­ R.matmulï¼Œå®ƒæè¿°è®¡ç®—å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œä¸åŒ…å«å…¶åº•å±‚å®ç°çš„ä¿¡æ¯ã€‚ä¸€ä¸ªé«˜çº§ Relax ç®—å­å¯ä»¥æ˜ å°„åˆ°ä¸åŒçš„åº•å±‚å®ç°ï¼ŒTVM Unity çš„ç¼–è¯‘æµç¨‹ä¼šç”Ÿæˆæ€§èƒ½è‰¯å¥½çš„å®ç°ã€‚ R.dataflow() æ˜¯æ•°æ®æµå—çš„ä¸€ä¸ªé‡è¦ä½œç”¨åŸŸæ³¨è§£ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æ•°æ®æµå—å†…ï¼Œæ‰€æœ‰æ“ä½œéƒ½å¿…é¡»æ˜¯ side-effect free. è€Œåœ¨æ•°æ®æµå—ä¹‹å¤–ï¼Œæ“ä½œå¯èƒ½åŒ…å«å‰¯ä½œç”¨ã€‚ A more complex TVMScript example: 2-layer MLP ä¸‹é¢æˆ‘ä»¬ä»¥ä¸€ä¸ªæ›´å¤æ‚çš„ä¸¤å±‚ MLP ä¸ºä¾‹ï¼Œæ¨¡å‹ç»“æ„å¦‚ä¸‹ã€‚\n2-layer MLP\nå…¶å¯¹åº”çš„ Pytoch å®ç°å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 class MLP(torch.nn.Module): def __init__(self, *args, **kwargs) -\u0026gt; None: super(MLP, self).__init__(*args, **kwargs) self.linear1 = torch.nn.Linear(784, 128) self.linear2 = torch.nn.Linear(128, 10) def forward(self, x): x = self.linear1(x) x = torch.nn.functional.relu(x) x = self.linear2(x) return x å¯¹åº”çš„ IRModule çš„ TVMScript è¡¨ç¤ºå¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @I.ir_module class Module: @R.function def main(inp_0: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;), weight1: R.Tensor((128, 784), dtype=\u0026#34;float32\u0026#34;), bias1: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;), weight2: R.Tensor((10, 128), dtype=\u0026#34;float32\u0026#34;), bias2: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): with R.dataflow(): lv: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(weight1, axes=None) lv_1: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.matmul(inp_0, lv, out_dtype=\u0026#34;void\u0026#34;) lv1: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.add(lv_1, bias1) lv2: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.nn.relu(lv1) lv4: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(weight2, axes=None) lv3: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.matmul(lv2, lv4, out_dtype=\u0026#34;void\u0026#34;) lv4_1: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.add(lv3, bias2) R.output(lv4_1) return lv4_1 ä¸Šè¿° Relax å‡½æ•°åªåŒ…å«é«˜çº§ Relax ç®—å­ã€‚åœ¨ pytorch ä¸­ï¼Œtorch.nn.Linear è®¡ç®— $y = xW^T + b$ åœ¨ relax ä¸­ï¼Œè½¬ç½®ç”± permute_dims å®ç°ï¼Œå…¶æ¬¡æ˜¯ çŸ©é˜µä¹˜æ³•å’ŒåŠ æ³•åˆ†åˆ«ç”± R.matmul å’Œ R.add å®ç°ã€‚\nCompilation Flow in TVM Unity å°†æ¨¡å‹å¯¼å…¥ IRModule. å¯¹äºé™æ€æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ pytorch dynamo å°† pytorch ç¨‹åºè·Ÿè¸ªä¸º fx å›¾ï¼Œç„¶åè½¬æ¢ä¸º IRModuleã€‚ç„¶è€Œï¼ŒLLM é€šå¸¸æ˜¯åŠ¨æ€çš„ï¼Œå› ä¸ºåºåˆ—é•¿åº¦å’Œ kv cache é•¿åº¦éƒ½æ˜¯å¯å˜çš„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦ç›´æ¥åœ¨ IRModule ä¸­å»ºç«‹æ¨¡å‹ã€‚ç¬¬ä¸€æ­¥å¯ä»¥æŠ½è±¡ä¸º LLM -\u0026gt; IRModule è½¬æ¢ã€‚ ä¼˜åŒ–æ¨¡å‹ã€‚ä¸ä¼ ç»Ÿç¼–è¯‘å™¨ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ IRModule ä¸Šåº”ç”¨ pass (IRModule åˆ° IRModule çš„å˜æ¢ï¼Œæ”¹å˜è®¡ç®—ä½†ä¿ç•™äº†åŸå§‹ IRModule çš„è¯­ä¹‰)ã€‚åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åŠ é€Ÿæ¨¡å‹è®¡ç®—ã€‚åœ¨æ¶ˆè´¹ç±»è®¾å¤‡ä¸Šä»¥é€‚å½“é€Ÿåº¦è¿è¡Œ LLM çš„å¤§å¤šæ•°å…³é”®æŠ€æœ¯ï¼Œå¦‚é‡åŒ–ã€ç®—å­èåˆå’Œå¼ é‡å‡½æ•°è°ƒåº¦ï¼Œéƒ½æ˜¯åœ¨è¿™ä¸€æ­¥å®ç°çš„ã€‚ åœ¨è®¾å¤‡ä¸Šéƒ¨ç½² IRModuleã€‚å¯¹äºæ¯ä¸ª IRM æ¨¡å—ï¼Œæˆ‘ä»¬éƒ½èƒ½å°†å…¶è½¬åŒ–ä¸ºå¯è¿è¡Œæ¨¡å—ï¼Œå¹¶åœ¨ tvm è¿è¡Œæ—¶æ”¯æŒçš„ä»»ä½•å¹³å°ä¸Šè¿è¡Œã€‚IRModule ä¸Šçš„æ¯ä¸ªå‡½æ•°éƒ½å°†æˆä¸ºç¯å¢ƒä¸­çš„æœ¬åœ°å¯è¿è¡Œå‡½æ•°ã€‚ ä»¥ä¸‹æ˜¯ 2 å±‚ MLP æ¨¡å‹çš„ç¼–è¯‘æµç¨‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 from tvm import relax import tvm from tvm.ir.module import IRModule mod = MLPModule def optimize_and_deploy(mod: IRModule): # step 2. Optimization # Use default graph optimization pipeline mod = relax.pipeline.get_pipeline()(mod) # Use default tensor function scheduling with tvm.target.Target(\u0026#34;cuda\u0026#34;): mod = tvm.tir.transform.DefaultGPUSchedule()(mod) # Step 3. Deploy to GPU ex = relax.build(mod, \u0026#34;cuda\u0026#34;) vm = relax.VirtualMachine(ex, tvm.cuda()) # test correctness import numpy as np input_np = np.random.rand(1, 784).astype(\u0026#34;float32\u0026#34;) weight1_np = np.random.rand(128, 784).astype(\u0026#34;float32\u0026#34;) bias1_np = np.random.rand(1, 128).astype(\u0026#34;float32\u0026#34;) weight2_np = np.random.rand(10, 128).astype(\u0026#34;float32\u0026#34;) bias2_np = np.random.rand(1, 10).astype(\u0026#34;float32\u0026#34;) tvm_nd_arrays = [tvm.nd.array(np_array, device=tvm.cuda()) for np_array in [input_np, weight1_np, bias1_np, weight2_np, bias2_np]] # call into the runnable function converted from IRModule nd_res = vm[\u0026#34;main\u0026#34;](*tvm_nd_arrays) numpy_res = (input_np @ weight1_np.T + bias1_np) @ weight2_np.T + bias2_np np.testing.assert_allclose(numpy_res, nd_res.numpy(), rtol=1e-5) optimize_and_deploy(mod) Build IRModule in Pytorch Style æ„å»º IRModule æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯æ‰‹åŠ¨ç¼–å†™ TVMScriptã€‚è¿™ç§æ–¹æ³•é€‚ç”¨äºå°å‹æ¨¡å‹ï¼Œä½† LLM çš„ IRModule éå¸¸åºå¤§å’Œå¤æ‚ï¼Œæ‰‹å·¥ç¼–å†™å¹¶ä¸ç°å®ã€‚TVM Unity æä¾›äº†å¦ä¸€ä¸ªç±» nn.Moduleï¼Œå¯ä»¥åƒ pytorch æ¨¡å—ä¸€æ ·è½»æ¾æ„å»º IRModule. ç”¨ Pytorch æ‰‹åŠ¨ç¼–å†™çš„ä¸€ä¸ª Linear å±‚å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 class TorchLinear(torch.nn.Module): def __init__(self, in_features, out_features, bias=True): super().__init__() self.in_features = in_features self.out_features = out_features self.weight = torch.nn.Parameter(torch.randn(out_features, in_features)) if bias: self.bias = torch.nn.Parameter(torch.randn(out_features)) else: bias = None def forward(self, x): return x @ self.weight.T + self.bias åœ¨ Relax ä¸­çš„å®ç°å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from tvm.relax.testing import nn class RelaxLinear(nn.Module): def __init__(self, in_features, out_features, dtype: str, bias=True) -\u0026gt; None: super(RelaxLinear, self).__init__() self.in_features = in_features self.out_features = out_features self.weight = nn.Parameter((out_features, in_features), dtype, name=\u0026#34;linear_weight\u0026#34;) if bias: self.bias = nn.Parameter((1, out_features), dtype, name=\u0026#34;linear_bias\u0026#34;) else: self.bias = None def forward(self, x: relax.Expr) -\u0026gt; relax.Var: return nn.emit(relax.op.linear(x, self.weight, self.bias)) ä¸ Pytorch çš„ç»“æ„éå¸¸ç›¸ä¼¼ï¼Œåªæ˜¯å‰å‘å‡½æ•°å®é™…ä¸Šå¹¶ä¸æ‰§è¡Œè®¡ç®—ã€‚å®ƒä½¿ç”¨ä½œä¸ºè¾“å…¥ä¼ é€’çš„å ä½ç¬¦è·Ÿè¸ªç®—å­çš„è®¡ç®—å›¾ã€‚ nn.emit(relax.op.linear(input, self.weight, self.bias)) è¡¨ç¤ºåœ¨æ„å»ºçš„ IRModule ä¸­æ·»åŠ é«˜çº§ linear ç®—å­ã€‚ é€šè¿‡å †å  1 ä¸ªçº¿æ€§å±‚ã€1 ä¸ª relu å±‚å’Œ 1 ä¸ªçº¿æ€§å±‚ï¼Œå°±å¯ä»¥æ„å»ºä¾‹å­ä¸­çš„ MLP.\n1 2 3 4 5 6 7 8 9 10 11 class RelaxMLP(nn.Module): def __init__(self, in_features, hidden_dims, out_features, dtype=\u0026#34;float32\u0026#34;) -\u0026gt; None: super(RelaxMLP, self).__init__() self.linear1 = RelaxLinear(in_features, hidden_dims, dtype) self.lienar2 = RelaxLinear(hidden_dims, out_features, dtype) def forward(self, x: relax.Expr) -\u0026gt; relax.Var: hidden = self.linear1(x) hidden = nn.emit(relax.op.nn.relu(hidden)) out = self.lienar2(hidden) return out ç›´æ¥è°ƒç”¨ nn.Module çš„å‰å‘å‡½æ•°å°±å¯ä»¥ä»£æ›¿åŸå…ˆåœ¨ with bb.dataflow(): ä¸‹çš„æ“ä½œï¼Œå°† nn.Module æ„å»ºæˆ IRModule çš„æ­¥éª¤å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def build_relax(mod: nn.Module): # relax.BlockBuilder can construct end-to-end models step by step in an IRModule that starts empty bb = relax.BlockBuilder() # relax nn.Module model = mod(784, 128, 10) # create a function called \u0026#34;main\u0026#34; in the IRModule with bb.function(\u0026#34;main\u0026#34;): # define input placeholder to the relax nn.Module input = nn.Placeholder((1, 784), dtype=\u0026#34;float32\u0026#34;, name=\u0026#34;input\u0026#34;) # build dataflow block with bb.dataflow(): # call forward function logits = model(input) # The params of the constructed IRModule params = [input] + model.parameters() # return value of the dataflow block gv = bb.emit_output(logits) # return value and params of the Relax function bb.emit_func_output(gv, params) return bb.get() build_relax(RelaxMLP).show() #------------------------------ @I.ir_module class Module: @R.function def main(input: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;), linear_weight: R.Tensor((128, 784), dtype=\u0026#34;float32\u0026#34;), linear_bias: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;), linear_weight_1: R.Tensor((10, 128), dtype=\u0026#34;float32\u0026#34;), linear_bias_1: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): with R.dataflow(): lv: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(linear_weight, axes=None) lv1: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.matmul(input, lv, out_dtype=\u0026#34;void\u0026#34;) lv2: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.add(lv1, linear_bias) lv3: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.nn.relu(lv2) lv4: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(linear_weight_1, axes=None) lv5: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.matmul(lv3, lv4, out_dtype=\u0026#34;void\u0026#34;) lv6: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.add(lv5, linear_bias_1) gv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = lv6 R.output(gv) return gv Custom Operator Support åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è¦è¡¨ç¤ºçš„æ¨¡å‹åŒ…å«ä¸€äº›è‡ªå®šä¹‰è¿ç®—ç¬¦ï¼Œè€Œè¿™äº›è¿ç®—ç¬¦æ²¡æœ‰è¢«æä¾›çš„ Relax è¿ç®—ç¬¦è¦†ç›–ï¼ˆå¦‚ LLaMA ä¸­çš„ Rotary Embeddingï¼‰ï¼Œæˆ–è€…æˆ‘ä»¬è¦è¿›è¡Œåº•å±‚ä¼˜åŒ–ä»¥åŠ é€Ÿå•ä¸ªå†…æ ¸ã€‚ä¸‹é¢ä»‹ç»å¦‚ä½•åœ¨ IRModule ä¸­ç¼–å†™è‡ªå®šä¹‰ç®—å­ã€‚\nTensorIR: Low-level tensor function TVM Unity åœ¨ IRModule TensorIR ä¸­æä¾›äº†åº•å±‚å¼ é‡å‡½æ•°çš„è¡¨ç¤ºæ–¹æ³•ï¼Œç”¨æˆ·å¯ä»¥åœ¨å…¶ä¸­å®šä¹‰è‡ªå®šä¹‰æ“ä½œç¬¦å¹¶æ‰§è¡Œç»†ç²’åº¦è°ƒåº¦ã€‚ ä¸‹é¢å¯¹æ¯”äº†ä¸€ä¸ªçŸ©é˜µä¹˜æ³•ç”Ÿæˆçš„ TVMScript TensorIR ä»£ç å’Œ low-level Pytorch ä»£ç ã€‚@T.prim_funcè£…é¥°å™¨è¡¨ç¤ºä¸‹é¢çš„å‡½æ•°æ˜¯ä¸€ä¸ªåŸå§‹çš„å¼ é‡å‡½æ•°ï¼ŒåŒ…å«è¿ç®—ç¬¦å®ç°çš„åº•å±‚ç»†èŠ‚ã€‚\nDestination Passing T.prim_func é‡‡ç”¨ destination-passing çº¦å®šï¼Œå³åœ¨å‡½æ•°å¤–éƒ¨æ˜ç¡®åˆ†é…è¾“å…¥å’Œè¾“å‡ºç©ºé—´ï¼Œå¹¶å°†å…¶ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚destination-passing çº¦å®šå¯ä»¥å¯¹å†…å­˜åˆ†é…è¿›è¡Œç²¾ç»†è°ƒåº¦ï¼Œä¾‹å¦‚åˆå¹¶ä¸¤ä¸ªå®æ—¶é—´éš”ä¸ç›¸äº¤çš„å˜é‡çš„å†…å­˜åˆ†é…ï¼Œè¿™æ˜¯åœ¨å†…å­˜æœ‰é™çš„è®¾å¤‡ä¸Šè¿è¡Œå¤§å‹æ¨¡å‹çš„å…³é”®ã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from tvm.script import tir as T @T.prim_func def matmul(rxplaceholder: T.Buffer((T.int64(1), T.int64(784)), \u0026#34;float32\u0026#34;), rxplaceholder_1: T.Buffer((T.int64(784), T.int64(128)), \u0026#34;float32\u0026#34;), matmul: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: True}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1, k in T.grid(T.int64(1), T.int64(128), T.int64(784)): with T.block(\u0026#34;matmul\u0026#34;): v_i0, v_i1, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, i1, k]) T.reads(rxplaceholder[v_i0, v_k], rxplaceholder_1[v_k, v_i1]) T.writes(matmul[v_i0, v_i1]) with T.init(): matmul[v_i0, v_i1] = T.float32(0) matmul[v_i0, v_i1] = matmul[v_i0, v_i1] + rxplaceholder[v_i0, v_k] * rxplaceholder_1[v_k, v_i1] def torch_matmul(X: torch.Tensor, W: torch.Tensor): Y = torch.zeros(1, 128, dtype=\u0026#34;float32\u0026#34;) for i in range(1): for j in range(128): for k in range(784): Y[i, j] = Y[i, j] + X[i, k] * W[k, j] return Y Interaction between Relax function and TensorIR ä¸ºäº†æ”¯æŒ T.prim_funcï¼ˆåº•å±‚éƒ¨åˆ†ï¼‰å’Œ R.functionï¼ˆé«˜å±‚éƒ¨åˆ†ï¼‰ä¹‹é—´çš„äº¤äº’ï¼ŒTVM å¼•å…¥äº† call_tir, Relax ä¸­çš„ä¸€ä¸ªç‰¹æ®Šè¿ç®—ç¬¦ï¼Œç”¨äºæè¿°è®¡ç®—å›¾ä¸­çš„èŠ‚ç‚¹åŠå…¶å¼ é‡å‡½æ•°çš„å®ç°ã€‚ torch_call_tir æ˜¯ä¸€ä¸ªå‚è€ƒå®ç°ï¼Œç”¨æ¥è¯´æ˜ call_tir çš„å«ä¹‰ã€‚å®é™…ä¸Šï¼Œå¯ä»¥æœ‰ä¸åŒçš„åº•å±‚æ–¹æ³•æ¥ä¼˜åŒ–æ‰§è¡Œã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šé€‰æ‹©æå‰åˆ†é…æ‰€æœ‰è¾“å‡ºå†…å­˜ï¼Œç„¶åå†è¿è¡Œæ‰§è¡Œã€‚\n1 2 3 4 def torch_call_tir(prim_func, inputs, out_sinfo): res = torch.zeros(*out_sinfo.shape, dtype=out_sinfo.dtype) prim_func(*inputs, res) return res ä¸‹é¢æ˜¯ 2 å±‚ MLP çš„ IRModuleï¼Œæˆ‘ä»¬ä½¿ç”¨ call_tir å’Œå¼ é‡åŸè¯­å‡½æ•° matmul æ¥æ›¿æ¢ Relax è¿ç®—ç¬¦ R.matmul\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @I.ir_module class Module: @T.prim_func def tir_matmul(rxplaceholder: T.Buffer((T.int64(1), T.int64(784)), \u0026#34;float32\u0026#34;), rxplaceholder_1: T.Buffer((T.int64(784), T.int64(128)), \u0026#34;float32\u0026#34;), matmul: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: True}) # with T.block(\u0026#34;root\u0026#34;): for i0, i1, k in T.grid(T.int64(1), T.int64(128), T.int64(784)): with T.block(\u0026#34;matmul\u0026#34;): v_i0, v_i1, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i0, i1, k]) T.reads(rxplaceholder[v_i0, v_k], rxplaceholder_1[v_k, v_i1]) T.writes(matmul[v_i0, v_i1]) with T.init(): matmul[v_i0, v_i1] = T.float32(0) matmul[v_i0, v_i1] = matmul[v_i0, v_i1] + rxplaceholder[v_i0, v_k] * rxplaceholder_1[v_k, v_i1] @R.function def main(inp_0: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;), weight1: R.Tensor((128, 784), dtype=\u0026#34;float32\u0026#34;), bias1: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;), weight2: R.Tensor((10, 128), dtype=\u0026#34;float32\u0026#34;), bias2: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv: R.Tensor((784, 128), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(weight1, axes=None) lv1 = R.call_tir(cls.tir_matmul, [inp_0, lv], out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv2: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.add(lv1, bias1) lv3: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.nn.relu(lv2) lv4: R.Tensor((128, 10), dtype=\u0026#34;float32\u0026#34;) = R.permute_dims(weight2, axes=None) lv5: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.matmul(lv3, lv4, out_dtype=\u0026#34;float32\u0026#34;) lv6: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = R.add(lv5, bias2) gv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = lv6 R.output(gv) return gv Implement Custom TensorIR Function nn.Module ä¸ä»…æ”¯æŒé«˜çº§ Relax è¿ç®—ç¬¦ï¼Œè¿˜æ”¯æŒè‡ªå®šä¹‰ TensorIR å‡½æ•°ã€‚ è¦æ„å»º TensorIR å‡½æ•°å¹¶åœ¨ Relax å›¾ä¸­è°ƒç”¨å®ƒï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ nn.emit_te(f_te_expr,*args)ã€‚\nf_te_expr æ˜¯ä¸€ä¸ªè¿”å›å¼ é‡è¡¨è¾¾å¼ï¼ˆTensor Expressionï¼ŒTEï¼‰çš„å‡½æ•°ï¼Œæ˜¯æè¿°å¼ é‡è®¡ç®—çš„ DSL. args æ˜¯ f_te_expr çš„å‚æ•°ã€‚ åˆ›å»º TE è¡¨è¾¾å¼çš„æ–¹æ³•å¦‚ä¸‹\n1 te.compute(out_shape, f_compute) å®ƒæè¿°å¦‚ä¸‹çš„è®¡ç®—æ¨¡å¼ itertools.product åœ¨ Python çš„ itertools æ¨¡å—ä¸­ï¼Œproduct å‡½æ•°ç”¨äºç”Ÿæˆå¯è¿­ä»£å¯¹è±¡çš„ç¬›å¡å°”ç§¯ã€‚\nproduct å‡½æ•°æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªå¯è¿­ä»£å¯¹è±¡ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼Œè¯¥è¿­ä»£å™¨ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆï¼Œå…¶ä¸­æ¯ä¸ªç»„åˆåŒ…å«æ¥è‡ªæ¯ä¸ªè¾“å…¥å¯è¿­ä»£å¯¹è±¡çš„å•ä¸ªå…ƒç´ ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import itertools letters = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] numbers = [1, 2, 3] for item in itertools.product(letters, numbers): print(item) # outputï¼š # (\u0026#39;a\u0026#39;, 1) # (\u0026#39;a\u0026#39;, 2) # (\u0026#39;a\u0026#39;, 3) # (\u0026#39;b\u0026#39;, 1) # (\u0026#39;b\u0026#39;, 2) # (\u0026#39;b\u0026#39;, 3) product å‡½æ•°è¿˜æ”¯æŒé‡å¤å…ƒç´ ï¼Œå¯ä»¥ä½¿ç”¨ repeat å‚æ•°æŒ‡å®šæ¯ä¸ªå¯è¿­ä»£å¯¹è±¡éœ€è¦é‡å¤çš„æ¬¡æ•°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 letters = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] for item in itertools.product(letters, repeat=3): print(item) # outputï¼š # (\u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;) # (\u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) # (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;) # (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;) # (\u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;) # (\u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) # (\u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;) # (\u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;) product åº”ç”¨åœºæ™¯\nç»„åˆç”Ÿæˆ: ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆï¼Œä¾‹å¦‚å¯†ç ç”Ÿæˆã€å½©ç¥¨å·ç ç”Ÿæˆç­‰ã€‚ å¤šç»´æ•°ç»„éå†: éå†å¤šç»´æ•°ç»„çš„æ‰€æœ‰å…ƒç´ ã€‚ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ: ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›–æ‰€æœ‰å¯èƒ½çš„è¾“å…¥ç»„åˆã€‚ 1 2 3 4 from itertools import product for indices in product(range(s) for s in out_shape): out_tensor[*indices] = f_compute(*indices) ç”¨ emit_te å®ç° Linear å±‚æ¥æ„å»º IRModule çš„ä»£ç å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 from tvm import te class RelaxLinearWithEmitTE(nn.Module): def __init__(self, in_features, out_features, dtype=\u0026#34;float32\u0026#34;, bias=True) -\u0026gt; None: super(RelaxLinearWithEmitTE, self).__init__() self.in_features = in_features self.out_features = out_features self.weight = nn.Parameter((out_features, in_features), dtype, name=\u0026#34;linear_weight\u0026#34;) if bias: self.bias = nn.Parameter((1, out_features), dtype, name=\u0026#34;linear_bias\u0026#34;) else: self.bias = None def forward(self, x: relax.Expr) -\u0026gt; relax.Var: def my_linear(x, w, b=None): out_sinfo = x.shape[:-1] + [self.out_features,] k = te.reduce_axis((0, self.out_features), name=\u0026#34;k\u0026#34;) out = te.compute(out_sinfo, fcompute=lambda i, j: te.sum(x[i, k] * w[j, k], axis=k), name=\u0026#34;matmul\u0026#34;) if b is not None: return out else: return te.compute(out_sinfo, fcompute=lambda i, j: out[i, j] + b[0, j], name=\u0026#34;add_bias\u0026#34;) return nn.emit_te(my_linear, x, self.weight, self.bias) class RelaxMLPwithEmitTE(nn.Module): def __init__(self, in_features, hidden_num, out_features, dtype=\u0026#34;float32\u0026#34;): self.linear1 = RelaxLinearWithEmitTE(in_features, hidden_num, dtype=dtype) self.linear2 = RelaxLinearWithEmitTE(hidden_num, out_features, dtype=dtype) def forward(self, input: relax.Expr) -\u0026gt; relax.Var: hidden = self.linear1(input) hidden = nn.emit(relax.op.nn.relu(hidden)) out = self.linear2(hidden) return out build_relax(RelaxMLPwithEmitTE).show() #---------------------------------------------------- @I.ir_module class Module: @T.prim_func(private=True) def my_linear(input: T.Buffer((T.int64(1), T.int64(784)), \u0026#34;float32\u0026#34;), linear_weight: T.Buffer((T.int64(128), T.int64(784)), \u0026#34;float32\u0026#34;), linear_bias: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;), matmul: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i, j, k in T.grid(T.int64(1), T.int64(128), T.int64(128)): with T.block(\u0026#34;matmul\u0026#34;): v_i, v_j, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) T.reads(input[v_i, v_k], linear_weight[v_j, v_k]) T.writes(matmul[v_i, v_j]) with T.init(): matmul[v_i, v_j] = T.float32(0.0) matmul[v_i, v_j] = matmul[v_i, v_j] + input[v_i, v_k] * linear_weight[v_j, v_k] @T.prim_func(private=True) def my_linear1(lv1: T.Buffer((T.int64(1), T.int64(128)), \u0026#34;float32\u0026#34;), linear_weight: T.Buffer((T.int64(10), T.int64(128)), \u0026#34;float32\u0026#34;), linear_bias: T.Buffer((T.int64(1), T.int64(10)), \u0026#34;float32\u0026#34;), matmul: T.Buffer((T.int64(1), T.int64(10)), \u0026#34;float32\u0026#34;)): T.func_attr({\u0026#34;tir.noalias\u0026#34;: T.bool(True)}) # with T.block(\u0026#34;root\u0026#34;): for i, j, k in T.grid(T.int64(1), T.int64(10), T.int64(10)): with T.block(\u0026#34;matmul\u0026#34;): v_i, v_j, v_k = T.axis.remap(\u0026#34;SSR\u0026#34;, [i, j, k]) T.reads(lv1[v_i, v_k], linear_weight[v_j, v_k]) T.writes(matmul[v_i, v_j]) with T.init(): matmul[v_i, v_j] = T.float32(0.0) matmul[v_i, v_j] = matmul[v_i, v_j] + lv1[v_i, v_k] * linear_weight[v_j, v_k] @R.function def main(input: R.Tensor((1, 784), dtype=\u0026#34;float32\u0026#34;), linear_weight: R.Tensor((128, 784), dtype=\u0026#34;float32\u0026#34;), linear_bias: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;), linear_weight_1: R.Tensor((10, 128), dtype=\u0026#34;float32\u0026#34;), linear_bias_1: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) -\u0026gt; R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;): cls = Module with R.dataflow(): lv = R.call_tir(cls.my_linear, (input, linear_weight, linear_bias), out_sinfo=R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;)) lv1: R.Tensor((1, 128), dtype=\u0026#34;float32\u0026#34;) = R.nn.relu(lv) lv2 = R.call_tir(cls.my_linear1, (lv1, linear_weight_1, linear_bias_1), out_sinfo=R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;)) gv: R.Tensor((1, 10), dtype=\u0026#34;float32\u0026#34;) = lv2 R.output(gv) return gv ","permalink":"http://localhost:1313/blogs/courselearning/tvm/tvm-ch9/","summary":"Add Model Architeture in MLC LLM","title":"TVM Learning (11)-Add Model Architeture in MLC LLM"},{"content":"Hello, I am WITHER.\nğŸ”¬ Research Interests Training and Inference Acceleration LLM Reasoning High Performance Computing ğŸ§‘â€ğŸ“ Education 2019.09 - 2023.06: Bachelor of Communication Engineering, China University of Geoscience, Wuhan, China. 2023.09 - Now: Shanghai Jiao Tong University, Shanghai, China. ğŸ’» Work Experience 2024.06 - Present: Full-time Intern, Shanghai AI Laboratory, Shanghai, China. Research on inference acceleration and graph optimization of Large Language Models. Research on knowlege injection and reasoning of Large Language Models. ğŸ‰ Achievements ğŸ“° Publications ğŸ¤ª Hobbies ğŸ§™ Animations, Comics and Games ","permalink":"http://localhost:1313/about_me/","summary":"\u003cp\u003eHello, I am WITHER.\u003c/p\u003e\n\u003ch2 id=\"-research-interests\"\u003eğŸ”¬ Research Interests\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTraining and Inference Acceleration\u003c/li\u003e\n\u003cli\u003eLLM Reasoning\u003c/li\u003e\n\u003cli\u003eHigh Performance Computing\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"-education\"\u003eğŸ§‘â€ğŸ“ Education\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e2019.09 - 2023.06\u003c/strong\u003e: Bachelor of Communication Engineering, China University of Geoscience, Wuhan, China.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e2023.09 - Now\u003c/strong\u003e: Shanghai Jiao Tong University, Shanghai, China.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"-work-experience\"\u003eğŸ’» Work Experience\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e2024.06 - Present\u003c/strong\u003e: Full-time Intern, Shanghai AI Laboratory, Shanghai, China.\n\u003cul\u003e\n\u003cli\u003eResearch on inference acceleration and graph optimization of Large Language Models.\u003c/li\u003e\n\u003cli\u003eResearch on knowlege injection and reasoning of Large Language Models.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"-achievements\"\u003eğŸ‰ Achievements\u003c/h2\u003e\n\u003ch2 id=\"-publications\"\u003eğŸ“° Publications\u003c/h2\u003e\n\u003ch2 id=\"-hobbies\"\u003eğŸ¤ª Hobbies\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eğŸ§™ Animations, Comics and Games\u003c/li\u003e\n\u003c/ul\u003e","title":"About Me"},{"content":"Basic Transformer Block ç¬¦å·å«ä¹‰è¡¨ç¤ºå¦‚ä¸‹\nSymbol Description Symbol Description a æ³¨æ„åŠ›å¤´æ•° n å¹¶è¡Œåº¦å¤§å° b batchsize s åºåˆ—é•¿åº¦ h éšè—å±‚ç»´åº¦ v è¯æ±‡è¡¨å¤§å° L tranformer layer å±‚æ•°æ•° åŸºæœ¬ transformer block ç»“æ„å¦‚ä¸‹ï¼Œè¾“å…¥æ˜¯å½¢çŠ¶ä¸º (b, s, h) çš„ä¸‰ç»´å¼ é‡ï¼Œå…¶ä¸­ b ä¸º batchsize. æ¯ä¸ªå˜å‹å™¨å±‚ç”±ä¸€ä¸ªå…·æœ‰æ³¨æ„å¤´çš„è‡ªæ³¨æ„å—ç»„æˆï¼Œéšåæ˜¯ä¸€ä¸ªå…·æœ‰ä¸¤å±‚çš„ MLPï¼Œç¬¬ä¸€å±‚å°†éšè—ç»´åº¦å¢åŠ åˆ° 4hï¼Œç„¶ç¬¬äºŒå±‚å°†å…¶å‡å°‘åˆ° h. æ¯ä¸ªå˜å‹å™¨å±‚çš„è¾“å…¥å’Œè¾“å‡ºå…·æœ‰ç›¸åŒçš„å½¢çŠ¶.\nBasic Transformer Architecture Self-attention Block\nModel Parameters QKVO Linear çš„æƒé‡å½¢çŠ¶å‡ä¸º h*h, åç½®å½¢çŠ¶å‡ä¸º h*1ï¼›MLP ä¸¤ä¸ª Linear çš„æƒé‡å½¢åˆ†åˆ«ä¸º h*4h å’Œ 4h*hï¼Œåç½®å½¢çŠ¶åˆ†åˆ«ä¸º 4h*1 å’Œ h*1. å› æ­¤æ¯ä¸ªæ¨¡å‹çš„å‚æ•°é‡ä¸º (12hh+13h)Lï¼Œå ç”¨å¤§å°è¿˜è¦ x2.\nNote\nåœ¨ä¼ ç»Ÿçš„ LLM ä¸­æœ€åè¿˜éœ€è¦ç»è¿‡ logits layerï¼Œå°†éšè—å±‚ç»´åº¦ h è½¬æ¢æˆè¯æ±‡è¡¨å¤§å° vï¼Œå‚æ•°é‡è¿˜è¦åŠ ä¸Š hv.\nFLOPs Calculation å¯¹äºæµ®ç‚¹æ•°è®¡ç®—é‡ (FLOPs)ï¼Œåªè€ƒè™‘å ä¸»è¦éƒ¨åˆ†çš„é€šç”¨çŸ©é˜µä¹˜æ³• (GEMMs). å¯¹äº Attention éƒ¨åˆ†ï¼ŒQKV Linear çš„è®¡ç®—é‡ä¸º 6bshhï¼Œattention matrix (Q@K.T) çš„è®¡ç®—é‡ä¸º 2bssh, attention@V çš„è®¡ç®—é‡ä¸º 2bssh, O Linear çš„è®¡ç®—é‡ä¸º 2bshh. MLP çš„ä¸¤ä¸ªçº¿æ€§å±‚çš„æ¯ä¸€ä¸ªè®¡ç®—é‡éƒ½ä¸º 8shh. ç›¸åŠ åå¾—åˆ°æ­£å‘ä¼ æ’­ä¸­æ€»è®¡ç®—é‡ä¸º (24bshh + 4bssh)L bytes.\nNote\nåœ¨ä¼ ç»Ÿçš„ LLM ä¸­æœ€åè¿˜éœ€è¦ç»è¿‡ logits layerï¼Œå°†éšè—å±‚ç»´åº¦ h è½¬æ¢æˆè¯æ±‡è¡¨å¤§å° vï¼Œå…¶è®¡ç®—é‡ä¸º 2bshv.\nåå‘ä¼ æ’­å› ä¸ºè¦è®¡ç®—è¾“å…¥å’Œæƒé‡çš„æ¢¯åº¦ï¼Œå…¶è®¡ç®—é‡ä¸ºæ­£å‘ä¼ æ’­çš„ä¸¤å€ï¼Œå› æ­¤æ•´ä¸ªæ¨¡å‹çš„è®¡ç®—é‡ä¸º 72BLshh(1+s/(6h)).\nActivation Memory æ¿€æ´»çš„å®šä¹‰ä¸ºåœ¨å‰å‘ä¼ æ’­ä¸­äº§ç”Ÿå¹¶ä¸”éœ€è¦åœ¨åå‘ä¼ æ’­ä¸­è¿›è¡Œæ¢¯åº¦è®¡ç®—çš„å¼ é‡ï¼Œå³ä¸åŒ…æ‹¬æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚å¹¶ä¸”ä¸è€ƒè™‘ç›¸å¯¹éå¸¸å°çš„æ¿€æ´»ã€‚ä¾‹å¦‚ LayerNorm å±‚çš„è¾“å…¥è¿˜éœ€è¦å¼ é‡æ¯ä¸ªé€šé“çš„å‡å€¼å’Œæ–¹å·® (å¤§å°å‡ä¸º bs)ï¼Œç”±äº h å¤§å°é€šå¸¸è¶…è¿‡ 1kï¼Œå› æ­¤åªè€ƒè™‘è¾“å…¥å¼ é‡æ‰€å æ¿€æ´»çš„å¤§å° bshï¼Œå¿½ç•¥æ‰ 2bs. å‡è®¾æ•°æ®æ ¼å¼ä¸º fp16/bf16ï¼Œå³æ¯ä¸ªæ•°æ®å ç”¨ 2 bytes çš„å­˜å‚¨ç©ºé—´ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†çš„æ˜¯ dropout å±‚çš„ makï¼Œæ¯ä¸ªå…ƒç´ å‡ä¸º unsigned intï¼Œåªå ç”¨ 1 byte.\nAttention éƒ¨åˆ†æ¿€æ´»å ç”¨å¦‚ä¸‹ (å…±è®¡ 11bsh + 5bssa)\nQKV Linear: ä¸‰ä¸ªçº¿æ€§å±‚éœ€è¦çš„è¾“å…¥ç›¸åŒï¼Œå ç”¨ 2bsh bytes. Q@K.T: éœ€è¦å­˜å‚¨ Q å’Œ Kï¼Œå ç”¨ 4bsh bytes. Softmax: éœ€è¦å­˜å‚¨å¤§å°ä¸º 2bssa bytes çš„è¾“å…¥ Softmax droppot: éœ€è¦å­˜å‚¨ä¸€ä¸ªå¤§å°ä¸º bssa bytes çš„ mask. attention@V: éœ€è¦å­˜å‚¨ dropout çš„è¾“å‡ºå’Œ Vï¼Œåˆ†åˆ«å ç”¨ 2bssa å’Œ 2bsh bytes. O Linear: éœ€è¦å­˜å‚¨æ³¨æ„åŠ›çš„è¾“å‡ºï¼Œå ç”¨ 2bsh bytes. O dropout éœ€è¦å­˜å‚¨ä¸€ä¸ªå¤§å°ä¸º bsh bytes çš„ mask; MLP (å…±è®¡ 18bsh): ç¬¬ä¸€å±‚å’Œç¬¬äºŒå±‚çš„è¾“å…¥åˆ†åˆ«å ç”¨ 2bsh å’Œ 8bsh bytes. GeLU å±‚éœ€è¦ç¬¬äºŒå±‚çš„è¾“å…¥ç”¨äºåå‘ä¼ æ’­ï¼Œå ç”¨å¤§å°ä¸º 8bsh bytes. dropout éœ€è¦ä¸€ä¸ªå¤§å°ä¸º bsh bytes çš„ mask.\nLayerNorm (å…±è®¡ 4bsh): éœ€è¦å­˜å‚¨è¯¥å±‚çš„è¾“å…¥ï¼Œå ç”¨ 2bsh bytes. ä¸€å…±æœ‰ä¸¤ä¸ª LayerNorm.\nåŠ èµ·æ¥å°±å¯ä»¥å¾—åˆ°æ¯ä¸ª transformer block éœ€è¦æ¿€æ´»å¤§å°ä¸º bsh(34+5sa/h) bytes.\nTensor Parallelsim Megatron å¼ é‡å¹¶è¡Œ çš„æ€æƒ³æ˜¯å°†è¾“å…¥è¿›è¡Œè¿ç»­çš„ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•çš„ç¬¬ä¸€ä¸ªæŒ‰åˆ—åˆ‡åˆ†æˆ t ä»½ï¼Œç¬¬äºŒä¸ªæŒ‰è¡Œåˆ‡åˆ†æˆ t ä»½. åœ¨ Transformer block ä¸­ä½“ç°ä¸ºåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æœ¬èº«çš„å¹¶è¡Œæ€§å°† Attention è®¡ç®—ä¸­çš„ QKV æŒ‰åˆ—è¿›è¡Œåˆ‡åˆ†ï¼ŒO Linear çš„æƒé‡æŒ‰è¡Œè¿›è¡Œåˆ‡åˆ†ï¼›MLP ä¸­ç¬¬ä¸€ä¸ªçº¿æ€§å±‚çš„æƒé‡æŒ‰åˆ—è¿›è¡Œåˆ‡åˆ†ï¼Œç¬¬äºŒä¸ªæƒé‡æŒ‰è¡Œè¿›è¡Œåˆ‡åˆ†ã€‚\nåœ¨è¿™ç§å¹¶è¡Œæ–¹å¼ä¸‹ï¼Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­å‡éœ€è¦è¿›è¡Œ 2 æ¬¡ All-Reduce é€šä¿¡ï¼Œç”±äºæ¯æ¬¡ All-Reduce é€šä¿¡å¯ä»¥çœ‹ä½œ Reduce-Scatter + All-Gather, å› æ­¤æ¯æ¬¡æ¯ä¸ªè®¾å¤‡çš„é€šä¿¡é‡ä¸º 8Î±bsh bytesï¼Œå…¶ä¸­ Î±=(n-1)/n.\nå¯¹äºæ¿€æ´»ï¼Œ2*LayerNorm, QKV Linear çš„è¾“å…¥, O dropout maskï¼ŒMLP ç¬¬ä¸€å±‚çš„è¾“å…¥å’Œ MLP dropout ä¸ä¼šè¢«åˆ‡åˆ†ï¼Œå› æ­¤æ¯ä¸ªè®¾å¤‡æ¯ä¸ª block è¦å ç”¨çš„æ¿€æ´»ä¸º bsh(10+24/n+5as/(hn))\n2D Tensor Parallelsim\n2Då¼ é‡å¹¶è¡Œå°†æ¿€æ´»ç¬¬ä¸€ä¸ªçŸ©é˜µçš„åˆ—åˆ‡åˆ†æˆ m*n ä»½ï¼Œç¬¬äºŒä¸ªæƒé‡ (æƒé‡å½¢çŠ¶ä¸º he) çš„è¡Œè¢«åˆ‡åˆ†æˆ m ä»½ï¼Œåˆ—è¢«åˆ‡åˆ†æˆ n ä»½ã€‚ä»¥ä¸‹å›¾ä¸ºä¾‹ï¼ŒRank0-Rank2ä¸ºé€šä¿¡ç»„ xï¼ŒRank0-Rank1ä¸º é€šä¿¡ç»„ y. ç¬¬ä¸€ä¸ªçŸ©é˜µç»è¿‡ä¸€æ¬¡é€šä¿¡ç»„ y çš„ AllGather åä¸æœ¬è®¾å¤‡ç¬¬äºŒä¸ªçŸ©é˜µè¿›è¡ŒçŸ©é˜µä¹˜ç§¯ï¼Œå¾—åˆ°çš„éƒ¨åˆ†å’Œç»è¿‡ä¸€æ¬¡é€šä¿¡ç»„ x é—´çš„ReduceScatterï¼Œè®¡ç®—å‡ºæ­£ç¡®ç»“æœã€‚ç¬¬ä¸€æ¬¡ AllGather é€šä¿¡æ¯ä¸ªè®¾å¤‡é€šä¿¡çš„å¤§å°ä¸º bsh(n-1)/(mn). ç¬¬äºŒæ¬¡ ReduceScatter é€šä¿¡æ¯ä¸ªè®¾å¤‡é€šä¿¡çš„å¤§å°ä¸º bse(m-1)/n.\nMegatron Sequence Parallelsim Megatron å¼ é‡å¹¶è¡Œä¸­ LayerNorm ä»¥åŠ O Linear å’Œ MLP ä¹‹åçš„ dropouts åœ¨æ¯ä¸ªè®¾å¤‡ä¸­éƒ½æœ‰ä¸€ä¸ªå‰¯æœ¬ã€‚è¿™äº›æ¨¡å—ä¸éœ€è¦å¤§é‡çš„è®¡ç®—ï¼Œä½†éœ€è¦å ç”¨ 10bsh bytes å¤§å°çš„æ¿€æ´»å†…å­˜ã€‚Megatron-SP æ²¿ç€åºåˆ—ç»´åº¦åˆ’åˆ†è¿™äº›æ¨¡å—æ¥å‡å°‘æ¿€æ´»å†…å­˜ï¼Œä½†éœ€è¦é…åˆ TP ä¸€èµ·ä½¿ç”¨ï¼Œæœ¬è´¨ä¸Šæ˜¯å°† TP ä¸­çš„ All-Reduce æ‹†æˆäº†åœ¨ TP å‰è¿›è¡Œ All-Gather å’Œåœ¨ TP åè¿›è¡Œ Reduce-Scatter. ä½†é™¤å»ç¬¬ä¸€ä¸ª LayerNorm å¤–çš„æ¯ä¸€ä¸ªæ¨¡å—çš„æ¿€æ´»éƒ½å¾—åˆ°äº†åˆ‡åˆ†ã€‚Megatron-SP è¿™é‡Œé€‰æ‹©æ¯ä¸ªè®¾å¤‡å­˜å‚¨è‡ªå·±çš„éƒ¨åˆ†å¹¶åœ¨åå‘ä¼ æ’­ä¸­æ’å…¥ä¸€æ¬¡é¢å¤–çš„ All-Gather é€šä¿¡ã€‚å› æ­¤é€šä¿¡é‡ä¸º 10bsh, æ¯ä¸ªè®¾å¤‡æ¯ä¸ª block éœ€è¦å ç”¨çš„æ¿€æ´»ä¸º bsh/n*(34+5as/h)\nTransformer layer with Megatron-SP\nPipeline Parallelsim æµæ°´çº¿å¼ é‡å¹¶è¡Œä»…ä»…å°† L ä¸ª Transformer block å¹³å‡åˆ†åˆ° p ä¸ªè®¾å¤‡ä¸Šï¼Œå¹¶æ²¡æœ‰åˆ’åˆ†æ¿€æ´»æ‰€è¦å ç”¨çš„å†…å­˜ã€‚åœ¨è€ƒè™‘ 1F1B ç­–ç•¥ä¸‹ batchsize è¿›ä¸€æ­¥è¢«åˆ’åˆ†æˆ p ä¸ª micro batch. ç¬¬ä¸€ä¸ª stage å¿…é¡»å­˜å‚¨ p ä¸ª micro batch çš„æ¿€æ´»ã€‚æ¯ä¸ª stage åŒ…å« L/p å±‚ï¼Œæ‰€ä»¥æ— è®ºæµæ°´çº¿å¹¶è¡Œå¤§å° p å¦‚ä½•ï¼Œç¬¬ä¸€ä¸ª stage å¿…é¡»å­˜å‚¨ p Ã— L/p = L å±‚çš„æ¿€æ´»å€¼ã€‚åœ¨ Megatron-LM ä¸­çš„ interleaving schedule éœ€è¦å­˜å‚¨ L(1 + (pâˆ’1)/(pm)) å±‚çš„æ¿€æ´»ï¼Œå…¶ä¸­ m æ˜¯ interleaving çš„æ•°é‡ã€‚\nNote\nåœ¨ä½¿ç”¨ output-tensor-deallocation ä¼˜åŒ– (è¾“å‡ºä¼ åˆ°ä¸‹ä¸€ä¸ª stage åå°±é‡Šæ”¾) çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä¸ºä¸ºæ¯ä¸ªè®¾å¤‡èŠ‚çœ bshr å†…å­˜ï¼Œå…¶ä¸­ r æ˜¯æ¯ä¸ªè®¾å¤‡æ­£åœ¨è¿è¡Œçš„ micro batch çš„æ•°é‡ï¼Œåœ¨ç¬¬ä¸€ä¸ª stage r=p æ—¶è¾¾åˆ°å³°å€¼ã€‚\nDeepseed-Ulysses Sequence Parallel DS-SP ä¹Ÿæ˜¯åˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›çš„å¹¶è¡Œæ€§ï¼Œé¦–å…ˆå°†è¾“å…¥æŒ‰åºåˆ—ç»´åº¦åˆ‡åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œæ¯ä¸ªè®¾å¤‡å æœ‰çš„è¾“å…¥å½¢çŠ¶ä¸º b*(s/n)*h. åœ¨è®¡ç®— Attention ä¹‹å‰å¯¹ QKV è¿›è¡Œ All-to-All é€šä¿¡å˜æˆæŒ‰éšè—å±‚ç»´åº¦åˆ‡åˆ† ((a è¦èƒ½æ•´é™¤ n))ï¼Œé€šä¿¡é‡ä¸º 6Î±bsh/n bytes. è®¡ç®—å®Œ score@v ä¹‹åå†è¿›è¡Œä¸€æ¬¡ All-to-All é€šä¿¡ï¼Œé€šä¿¡é‡ä¸º 2Î±bsh/n bytesï¼Œæ€»è®¡é€šä¿¡é‡ä¸º 8Î±bsh/n bytes. æ¿€æ´»å ç”¨ä¸Š Attention ä¸­ Softmax åŠå…¶ dropout mask å’Œ attention æ²¡æœ‰è¢«åˆ‡åˆ†ï¼Œæ¿€æ´»å ç”¨é‡ä¸º bsh(34/n+5sa/h). å› æ­¤ï¼Œå®ƒä¸é€‚åˆ GQA å’Œ MQA æƒ…å†µ, GQA çš„å¹¶è¡Œåº¦è¢«é™åˆ¶åœ¨äº†ç»„æ•°ï¼ŒMQA åˆ™å®Œå…¨æ²¡æ³•ä½¿ç”¨ã€‚è€Œä¸”ç”±äºå¼ é‡å¹¶è¡Œä¹Ÿéœ€è¦åœ¨ a ç»´åº¦ä¸Šè¿›è¡Œåˆ’åˆ†ï¼ŒSP-Ulysses å’Œ TP æ˜¯å†²çªçš„ã€‚\nRing-Attention Sequence Parallel Ring-SP å®é™…ä¸Šä¸ºç¯çŠ¶çš„ FlashAttentionï¼Œå°†è¾“å…¥æ²¿ç€åºåˆ—ç»´åº¦åˆ‡åˆ†åˆ°æ¯ä¸ªè®¾å¤‡ä¸Šï¼Œåœ¨ Attention è®¡ç®—è¿‡ç¨‹ä¸­æ¯ä¸ªè®¾å¤‡å‘ç›¸é‚»è®¾å¤‡é€šä¿¡ KV å¹¶æ›´æ–°è‡ªå·±çš„ Softmax çŸ©é˜µï¼Œé€šä¿¡é‡ä¸º 4bsh bytes. æ¿€æ´»å ç”¨å’Œ DS-SP ä¸€æ ·ä¸º bsh(34/n+5sa/h).\nUnified Sequence Parallel USP å°† SP è¿›ç¨‹ç»„åˆ†å‰²æˆä¸¤ä¸ªæ­£äº¤çš„è¿›ç¨‹ç»„ï¼šSP-Ring è¿›ç¨‹ç»„å’Œ SP-Ulysses è¿›ç¨‹ç»„ã€‚å¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ª 2D mesh ï¼Œæ¯ä¸€åˆ—ä¸Šè¿è¡Œ SP-Ringï¼Œæ¯ä¸€è¡Œä¸Šè¿è¡Œ SP-Ulysses. å…·ä½“æ–¹æ³•ä¸º QKV çš„åˆ‡åˆ† å’Œ All-to-All å’Œ DS-Ulysses ç›¸åŒï¼Œç„¶åé‡‡ç”¨ Ring-Attention çš„æ–¹å¼è¿›è¡Œè®¡ç®—ã€‚å¦‚æœé‡åˆ°ä½¿ç”¨ casual mask çš„æƒ…å†µéœ€è¦åŠ ä¸Š balance load ç­–ç•¥ï¼ŒæŠŠåºåˆ—é•¿åº¦åˆ†ä¸º 2*(ring_degree) å¤§å°ï¼ŒæŒ‰ç…§ 0-\u0026gt;1-\u0026gt;\u0026hellip;-\u0026gt;(ring_degree-1)-\u0026gt;(ring_degree-1)-\u0026gt;\u0026hellip;-\u0026gt;0 çš„é¡ºåºè¿›è¡Œåˆ†é…ã€‚USP æ¶ˆé™¤äº† SP-ulyssesçš„å¤´æ•°é™åˆ¶ã€‚å¹¶ä¸” USPå¯ä»¥é€šè¿‡è°ƒæ•´ SP-Ulysses è¿›ç¨‹ç»„æ•°ç›®æ¥æ›´å¥½çš„é€‚åº”ä¸åŒå¸¦å®½çš„ç½‘ç»œç»“æ„ï¼Œå¯ä»¥è®© All-to-All æ“ä½œåœ¨é«˜å¸¦å®½ä¸­è¿è¡Œï¼Œè€Œå¼‚æ­¥ P2P é€šä¿¡åœ¨ä½å¸¦å®½éƒ¨åˆ†è¿è¡Œã€‚\nComparsion of Different Parallelsim in Training Communication (FWD+BWD)\rSplit Dim\rMemory\rParam\rCost\rAct\rCost\rP/G\rOS\rAct\rDS-SP\rAllReduce\r12O(hÂ²)\r8*All2All\r(8/N)O(bsh)\ra/s\rP+G\r6P\rA/N\rRing-SP\rAllReduce\r12O(hÂ²)\rP2P\r4O(bsh)\rL/L\rP+G\r6P\rA/N\rDP\rAllReduce\r12O(hÂ²)\r0\r0\rb/b\rP+G\r6P\rA/N\rZeRO1\rAllGather + ReduceScatter\r12O(hÂ²)\r0\r0\ra/s\rP+G\r6P/N A/N\rUSP + ZeRO1\rAllGather + ReduceScatter\r12O(hÂ²)\rP2P + 8*All2All\râ‰¤ 4O(bsh)\ra/s\rP+G\r6P/N\rA/N\rUSP + ZeRO2\rAllGather + ReduceScatter\r12O(hÂ²)\rP2P + 8*All2All\râ‰¤ 4O(bsh)\ra/s\rP+(G/N)\r6P/N\rA/N\rUSP + ZeRO3\r2*AllGather + ReduceScatter\r18O(hÂ²)\rP2P + 8*All2All\râ‰¤ 4O(bsh)\ra/s\r(P+G)/N\r6P/N\rA/N\rTP\r0\r0\r4*AllReduce\r8O(bsh)\ra/h\r(P+G)/N\r6P/N\rÎ±A\rMegatron-SP\r0\r0\r6*AllGather + 4*ReduceScatter\r10O(bsh)\ra/h\r(P+G)/N\r6P/N\rA/N\rAnalysis All2All é€šä¿¡ä½¿å¾— DS-SP çš„é€šä¿¡å¼€é”€å¤§äº DP. ä½¿ç”¨ Ring-SP æ—¶ï¼Œå°½ç®¡å¼‚æ­¥çš„ P2P é€šä¿¡æ˜¯å¯ä»¥é‡å çš„ï¼Œç†æƒ³çš„æ€§èƒ½ä¹Ÿæ˜¯åªä¸ DP ç›¸åŒã€‚å› æ­¤åªæœ‰å½“æ‰¹ batchsize ä¸è¶³ä»¥è¿›è¡Œåˆ‡åˆ†æ—¶æ‰è€ƒè™‘ä½¿ç”¨ SP. Megatron-SP é€šä¿¡é‡é«˜äº DS-SP å’Œ Ring-SP. SP-Ring å¯¹äº KV çš„é€šä¿¡å¯ä»¥ä¸è®¡ç®—é‡å ã€‚Megatron-SP çš„é€šä¿¡é‡ä¸ä¼šéšç€å¹¶è¡Œåº¦çš„å¢åŠ è€Œå‡å°‘ï¼Œè€Œ DS-SP å¯ä»¥åšåˆ°ã€‚ DS-SP å’Œ Ring-SP å…·æœ‰è¾ƒä½çš„æ¿€æ´»é€šä¿¡æˆæœ¬ï¼Œä½†éœ€è¦åŒæ­¥æ¢¯åº¦å’Œå‚æ•°ã€‚ä¸è¿‡å‚æ•°é€šä¿¡é‡ç›¸å¯¹äºæ¿€æ´»é€šä¿¡é‡è¾ƒå°ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—è¿›è¡Œé‡å ã€‚GQA/MQA ä¹Ÿå¯ä»¥é™ä½å®ƒä¿©çš„é€šä¿¡æˆæœ¬ï¼Œè€Œ Megatron-SP ä¸å—å½±å“ã€‚ ç›¸åŒé…ç½®ä¸‹ä½¿ç”¨ USP+Zero3 æ¥ä»£æ›¿ Megatron-SP å¹¶ä¸ä¼šå¢åŠ å¯è®­ç»ƒåºåˆ—çš„é•¿åº¦ã€‚ä½†ä¸ Megatron-SP ç›¸æ¯”ï¼ŒUSP èƒ½åœ¨é€šè¿‡æé«˜å¹¶è¡Œåº¦æ¥å¢åŠ å¯ä»¥è®­ç»ƒçš„åºåˆ—é•¿åº¦ã€‚ Megatron-SP å¹¶è¡Œç»´åº¦å—é™äºæ³¨æ„åŠ›å¤´æ•°ç›®ã€‚USP å¯ä»¥é€šè¿‡æé«˜ Ring-SP çš„å¹¶è¡Œåº¦æ¥æ‰©å±•ï¼Œä»¥åœ¨å¤§è§„æ¨¡é…ç½®ä¸‹è®­ç»ƒæ›´å¤§æ¨¡å‹ã€‚ Sora Inference Modeling Analysis Process æˆ‘ä»¬éœ€è¦å‡†å¤‡æ¨¡å‹çš„è¾“å…¥ï¼š\néšç©ºé—´é‡‡æ ·çš„å™ªå£° zï¼Œå½¢çŠ¶ä¸æƒ³ç”Ÿæˆçš„è§†é¢‘æ—¶å¸¸å’Œåˆ†è¾¨ç‡ç›¸å…³ã€‚ç”Ÿæˆ 1s çš„è§†é¢‘ä¸º 25.5 framesï¼Œç»è¿‡ VAE Encoder åè¾“å‡ºçš„é€šé“æ•°ä¸º 4ï¼Œå¸§æ•°ä¼šè¢«å‹ç¼©åˆ° num_frame*5//17ï¼Œåˆ†è¾¨ç‡çš„é•¿å®½åˆ†åˆ«è¢«å‹ç¼©åˆ°åŸæ¥çš„ 1/8. å› æ­¤ z çš„å½¢çŠ¶åº”è¯¥ä¸º (B, 4, num_frame*5//17, img_size[0]//8, img_size[1]//8). è¾“å…¥çš„ prompt ä¼šç»è¿‡ DeepFloyd/t5-v1_1-xxl ç¼–ç ï¼Œè¯¥ç¼–ç å™¨æœ€å¤§çš„ token æ•°ä¸º 300ï¼Œç¼–ç ç»´åº¦ä¸º 4096ï¼Œæ–‡æœ¬é•¿åº¦ä¸è¶³æ—¶ä¼šå¡«å……åˆ° 300. å› æ­¤ç¼–ç åçš„ prompt çš„å½¢çŠ¶ä¸º (B, 1, 300, 4096). å½“å‰å»å™ªçš„æ—¶é—´æ­¥ tï¼Œå½¢çŠ¶ä¸º (B, ) ç”Ÿæˆè§†é¢‘çš„ fpsï¼Œå½¢çŠ¶ä¸º (1, ) è¿˜éœ€è¦å‡†å¤‡ç›¸å…³çš„æ¨¡å‹é…ç½®ï¼ŒåŒ…æ‹¬ mesh å½¢çŠ¶ï¼Œsub_mesh çš„å½¢çŠ¶ï¼Œå¹¶è¡Œç­–ç•¥ä»¥åŠ stage_ids. å¦‚æœéœ€è¦å°†æ¨¡å‹çš„ transformer block åˆ‡åˆ†æˆå¤šæ®µï¼Œåˆ™éœ€è¦é…ç½® sub_mesh å’Œ stage_ids.\nmesh_shape: (num_x, num_y) submesh_shape: [(num_x, num_y, loc_x, loc_y), ] stage_ids: [(submesh0_start, submesh0_end), ] strategy: å¹¶è¡Œç­–ç•¥ ç„¶ååˆå§‹åŒ–æ¨¡å‹ï¼ŒSora çš„æ•´ä½“ç»“æ„å¦‚ä¸‹ æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ª Pipeline(åŒ…å«æ•´ä¸ªæµç¨‹çš„å‡½æ•°)ï¼Œå®ƒä¼šæœ‰ä¸€ä¸ªæˆ–å¤šä¸ª Stage ç”¨äºä¿å­˜æ¨¡å‹çš„ä¸åŒå±‚ï¼Œä¸ stage_ids ä¸­å¯¹åº”ã€‚æˆ‘ä»¬å°†æ¨¡å‹åˆ†è§£æˆ Embedding_blocks(PatchEmbed3D, TimestepEmbedder, SizeEmbedder, Captionembedder, t_block), STDiT3_blocks å’Œ T2IFinalLayer. å°†è¿™ä¸ªåˆ†è§£å‡½æ•°ä½œä¸º Pipeline çš„ sharding_func.\nOpen-Sora\nInit Pipeline æˆ‘ä»¬éœ€è¦æ ¹æ®é…ç½®ä»¥åŠ PipePatch å¹¶è¡Œåº¦å’Œ SP å¹¶è¡Œåº¦åˆå§‹åŒ– Pipeline. è¿™å…¶ä¸­ä¼šæ ¹æ® stage_ids åˆ†é…æ¯ä¸ª Stage ä¿å­˜æ¨¡å‹çš„å“ªäº›å±‚ä»¥åŠå¯¹åº”çš„ submesh å¤§å°ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def construct_stages(self, submeshes: List[Tuple], stages_ids: List[Tuple]): # construct layers for each stage first_part, module_list, last_part = self.parse_func(self.model) modules = list() num = len(stages_ids) for idx in range(num): submesh = submeshes[idx] stage_id = stages_ids[idx] # get stage layers from user config stage ids in module list layers = list(module_list[stage_id[0]: stage_id[1] + 1]) if idx == 0 and first_part is not None: # concat module first part(if exists) bef module list to stage_0 layers = first_part + layers if idx == num - 1 and last_part is not None: # concat module last part(if exists) aft module list to last stage layers.extend(last_part) modules.append(layers) # deepcopy module for xla device tracing use stage_module = [copy.deepcopy(layer) for layer in layers] self.stages.append( Stage(idx, stage_module, submesh, self, )) return modules Write Sharding Function è¦æ ¹æ®é€‰æ‹©çš„ä¸åŒçš„å¹¶è¡Œç­–ç•¥å¯¹æ¯ä¸ª Stage çš„æ¨¡å‹æƒé‡ï¼Œè¾“å…¥ï¼Œè¾“å‡ºè¿›è¡Œåˆ‡åˆ†ã€‚è¿™é‡ŒåŒæ ·æˆ‘ä»¬å•ç‹¬å¤„ç† Embedding_blocks, STDiT3_blocks å’Œ T2IFinalLayer. è®© stage0 åŒ…æ‹¬å¯¹ Embedding_blocks çš„å¤„ç†ï¼Œstage(N-1) åŒ…æ‹¬å¯¹ T2IFinalLayer çš„å¤„ç†ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ DS-ulysses æˆ‘ä»¬éœ€è¦å¯¹ Q@K.T çš„ç»“æœ å’Œ S@V çš„ç»“æœä¹Ÿè¿›è¡Œåˆ‡åˆ† SPMD æ‰ä¼šæ’å…¥æ­£ç¡®çš„ All2Allï¼Œå› æ­¤è¿™éƒ¨åˆ†åªèƒ½æ”¾åœ¨ç½‘ç»œçš„ forward é‡Œé¢è¿›è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def shard_sora_one_stage(modules, shard_strategy, mesh): total_len = len(modules) # first 5 modules are embedding layers for i in range(0, 5): shard_sora_embedding(modules[i], shard_strategy, mesh) for i in range(5, total_len - 2): shard_sora_block(modules[i][0], shard_strategy, mesh) # shard spatial shard_sora_block(modules[i][1], shard_strategy, mesh) # shard temporal shard_sora_final(modules[-1], shard_strategy, mesh) def shard_sora_first_stage(modules, shard_strategy, mesh): for i in range(0, 5): shard_sora_embedding(modules[i], shard_strategy, mesh) for i in range(5, len(modules)): shard_sora_block(modules[i][0], shard_strategy, mesh) # shard spatial shard_sora_block(modules[i][1], shard_strategy, mesh) # shard temporal def shard_sora_stage(modules, shard_strategy, mesh): for module in modules: shard_sora_block(module[0], shard_strategy, mesh) # shard spatial shard_sora_block(module[1], shard_strategy, mesh) # shard temporal def shard_sora_last_stage(modules, shard_strategy, mesh): total_len = len(modules) for i in range(0, total_len - 2): shard_sora_block(modules[i][0], shard_strategy, mesh) # shard spatial shard_sora_block(modules[i][1], shard_strategy, mesh) # shard temporal # skip norm layer mark sharding shard_sora_final(modules[total_len - 1], shard_strategy, mesh) Construct Pipeline ç„¶åä¸ºäº†å¤„ç†å¤š stage çš„æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æ¯ä¸ª stage çš„è¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶ã€‚è¿™ä¸€æ­¥ç›¸å½“äºæ”¾åˆ° cuda ä¸Šé‡èµ°ä¸€éæ•´ä¸ªæ¨¡å‹çš„ forwardï¼Œè®°å½•ä¸‹æ¯ä¸€å±‚è¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶ï¼Œä¿å­˜ä¸º json ä¸€éã€‚å®é™…ä¸Šå¯¹äºæ¯ä¸ªå›ºå®šç”Ÿæˆå¤§å°çš„è§†é¢‘è¿›è¡Œä¸€æ¬¡å°±è¡Œï¼Œä¸‹æ¬¡ç›´æ¥è¯»å–è¿™ä¸ªæ–‡ä»¶ã€‚å› ä¸ºç°åœ¨éƒ½é‡‡ç”¨ xformers.ops.memory_efficient_attentionï¼Œéœ€è¦è¾“å…¥å¼ é‡åœ¨ cuda ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åœ¨æ¨¡å‹çš„ forward å‡½æ•°ä¸­å†™ä¸€ä¸ª navie çš„ attention è®¡ç®—æµç¨‹å¥½è®© torch_xla èƒ½å¯¹å¼ é‡è¿›è¡Œè·Ÿè¸ªã€‚\nTrace mhlo Graph æ ¹æ®ä¸Šä¸€æ­¥å¾—åˆ°çš„æ¯ä¸ª Stage çš„è¾“å…¥å½¢çŠ¶ï¼Œåˆ›å»ºè¾“å…¥å¼ é‡ï¼Œæ”¾å…¥ xla_device ä¸Šï¼Œæ‰§è¡Œ forward. æœ€åå¯¼å‡ºè¾“å‡ºçš„ mhlo è®¡ç®—å›¾ã€‚è¿™é‡Œéœ€è¦æ³¨æ„ç¬¬ä¸€ä¸ª stage åŒ…å«å¤šä¸ªéè¿ç»­çš„æ¨¡å—ï¼Œå› æ­¤éœ€è¦å•ç‹¬å¤„ç†ï¼Œæœ€åä¸€ä¸ª stage æœ€åä¸€å±‚çš„è¾“å…¥ä¸å…¶ä»– block ä¸åŒï¼Œå› æ­¤ä¹Ÿè¦å•ç‹¬å¤„ç†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def trace_stage_mhlo_graph(self, check_res=False): \u0026#34;\u0026#34;\u0026#34; trace stage nn modules to mhlo graph \u0026#34;\u0026#34;\u0026#34; # (NOTE): construct xla mesh before trace tensors generate, # i.e., before any xla device call to avoid xla computation client construct xla_mesh = None if self.shard_func is not None: xla_mesh = self._construct_stage_xla_mesh() # create mesh from submesh info # Create xla device trace tensors, move module to xla device if self.stage_id == 0: self.trace_tensors = self._generate_trace_tensors() else: z = self.parent_pipeline.stages[self.stage_id -1].outputs y = self.parent_pipeline.stages[0].y_embedded.to(\u0026#39;cpu\u0026#39;).to(xm.xla_device()) t_mlp = self.parent_pipeline.stages[0].t_mlp.to(\u0026#39;cpu\u0026#39;).to(xm.xla_device()) self.trace_tensors = [z, y, t_mlp] for module in self.modules: if isinstance(module, tuple): for mod in module: mod.to(\u0026#39;cpu\u0026#39;).to(xm.xla_device()) # first load to cpu else: module.to(\u0026#39;cpu\u0026#39;).to(xm.xla_device()) # get pipeline exec mode assert self.parent_pipeline is not None exec_mode = self.parent_pipeline.exec_mode # load lora cofifg lora_config = self.parent_pipeline.lora_config print(\u0026#34;Enter trace mhlo graph for stage: \u0026#34;, self.stage_id) # Trigger shard func to mark sharding the model if self.shard_func is not None: self.shard_func(self.modules, self.shard_strategy, xla_mesh) if exec_mode == EXEC_MODE.INFER: # set stage name \u0026amp; dump file path self._set_stage_name_dump_file( exec_mode, \u0026#34;fw\u0026#34;) num_sampling_steps = 30 num_timesteps = 1000 timesteps = [(1.0 - i / num_sampling_steps) * num_timesteps for i in range(num_sampling_steps)] # FIXME: åŸå…ˆæ˜¯ä¸ºæ¯ä¸ªstageå•ç‹¬ç”Ÿæˆtrace_tensor, ç°åœ¨è¦æŠŠä¸Šä¸€ä¸ªçš„ç»“æœä¼ ç»™ä¸‹ä¸€ä¸ª stage #for i in range(30): start = sum(self.parent_pipeline.pipeline_patches_height_list[:self.stage_id - 1]) if self.stage_id != 0 else 0 end = start + self.parent_pipeline.pipeline_patches_height_list[self.stage_id] if self.stage_id == 0: outputs = self._forward([self.trace_tensors[0][...,start:end,:]] + self.trace_tensors[1:], xla_mesh) # outputs is a list else: outputs = self._forward(self.trace_tensors, xla_mesh) if check_res: # check xla results compared to gpu results check_result_error(self.outputs, outputs) else: # use torch xla _get_xla_tensors_hlo interface # to eliminate redundant live tensors as ret values os.environ[\u0026#34;XLA_DUMP_POST_OPTIMIZATIONS\u0026#34;] = \u0026#34;true\u0026#34; torch_xla._XLAC._get_xla_tensors_hlo(outputs) Analyze mhlo Graph æ¥ä¸‹æ¥æˆ‘ä»¬è¦éå†ä¸Šä¸€æ­¥å¾—å‡ºçš„ mhlo å›¾ã€‚\nOpView ä»æ ¹èŠ‚ç‚¹çš„ ir å¼€å§‹éå†ä¸Šä¸€æ­¥å¯¼å‡ºçš„æ•´ä¸ªè®¡ç®—å›¾ã€‚æ ¹æ®ä¼ å…¥ ir çš„ç±»å‹å®šä¹‰è°ƒç”¨å¯¹åº”çš„ visit å‡½æ•°è¯»å–å…¶å±æ€§è¿›è¡Œæ“ä½œã€‚ä¸»è¦é€šè¿‡ rsqrt çš„ä½ç½®æ¥åˆ’åˆ†ä¸€ä¸ª Transformer block ä¸­ç¬¬å‡ ä¸ª dot å’Œ dot_general å¯¹åº”çš„æ˜¯ä»€ä¹ˆæ“ä½œã€‚å¯¹äº Sora æ¥è¯´åˆ’åˆ†æƒ…å†µå¦‚ä¸‹ã€‚è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ mhlo å›¾è®°å½•çš„æ˜¯æ‹“æ‰‘æ’åºçš„é¡ºåºï¼Œä¸æ˜¯ç¨‹åºé¡ºåºæ‰§è¡Œçš„é¡ºåºï¼Œå› æ­¤ç¬¬ä¸€ä¸ª block ä¼šæºæ‚ç€ Embedding_blocks çš„ä¸€äº› dot æ“ä½œã€‚å› æ­¤æˆ‘ä»¬ä»ç¬¬äºŒä¸ª block çš„ç¬¬ä¸€ä¸ª rsqrt ä½ç½®å¼€å§‹ç»Ÿè®¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def collect_rms_ops(self): rms_collector = RMSCollector() rms_collector.visit(self.root_op) self.rms_locs = rms_collector.rms_locs # construct attention block \u0026amp; ffn block ranges # exclude the rsqrt in T2IFinalLayer att_rm_locs = self.rms_locs if len(self.rms_locs) % 2 == 0 else self.rms_locs[:-1] for i in range(8, len(att_rm_locs), 4): # a block has 4 rsqrt, start from 2nd block to avoid embedding self.spt_qkv_ranges.append((att_rm_locs[i+0], att_rm_locs[i+1])) self.spt_attn_ranges.append((att_rm_locs[i+2], att_rm_locs[i+3])) self.cro_attn_ranges.append((att_rm_locs[i+2], att_rm_locs[i+3])) for i in range(8, len(att_rm_locs), 4): # ORG: range(8, len(att_rm_locs), 4): start = self.rms_locs[i+3] if i+4 \u0026gt;= len(self.rms_locs): end = None else: end = self.rms_locs[i+4] self.ffn_ranges.append((start, end)) module operator RMSNorm(x) Self Attention dot(x, qkvLinear.weight) RMSNorm(q) RMSNorm(k) dot_general(q, k) dot_general(s, v) dot(attn, oLinear.weight) Cross Attention dot(x, qLinear.weight) dot(y, kvLinear.weight) dot_general(q, k) dot_general(s, v) dot(attn, oLinear.weight) RMSNorm(x) Feed Forward Network dot(x, upLinear.weight) dot(x, downLinear.weight) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def visit_dot(self, node): dot_lineno = _parse_loc_lineno(node) if self.block_cnt \u0026lt; len(self.spt_attn_ranges): spt_att_range = self.spt_attn_ranges[self.block_cnt] cro_att_range = self.cro_attn_ranges[self.block_cnt] spt_qkv_range = self.spt_qkv_ranges[self.block_cnt] ffn_range = self.ffn_ranges[self.block_cnt] # lie in RMS ops closed attention block if dot_lineno \u0026gt; spt_att_range[0] and dot_lineno \u0026lt; spt_att_range[1]: #import pdb;pdb.set_trace() self.att_block_dots.append(node) self.spt_dot_cnt += 1 elif dot_lineno \u0026gt; cro_att_range[0] and dot_lineno \u0026lt; cro_att_range[1]: self.att_block_dots.append(node) self.cro_att_dot_cnt += 1 # lie ffn block if dot_lineno \u0026gt; spt_qkv_range[0] and dot_lineno \u0026lt; spt_qkv_range[1]: self.spt_qkv_cnt += 1 self.ffn_block_dots.append(node) # pixart pass elif dot_lineno \u0026gt; ffn_range[0]: if ffn_range[1] is not None: if dot_lineno \u0026lt; ffn_range[1]: self.ffn_block_dots.append(node) self.ffn_dot_cnt += 1 else: if self.ffn_dot_cnt \u0026lt; 2: self.ffn_block_dots.append(node) self.ffn_dot_cnt += 1 # Traversal of one block if self.spt_qkv_cnt == 1 and self.spt_att_dot_cnt == 4 and \\ self.spt_dot_cnt == 4 and self.ffn_dot_cnt == 2: self.attention_blocks.append(self.att_block_dots) self.ffn_blocks.append(self.ffn_block_dots) self.block_cnt += 1 # reset each block level counters self.spt_qkv_cnt = 0 self.spt_att_dot_cnt = 0 self.spt_dot_cnt = 0 self.ffn_dot_cnt = 0 self.att_block_dots = [] self.ffn_block_dots = [] self.generic_visit(node) ä¿å­˜å¥½ä¸€ä¸ª Transformer block ä¸­æ¯ä¸ª dot æˆ– dotgeneral å¯¹åº”çš„æ˜¯ä»€ä¹ˆæ“ä½œåï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥è®¿é—®è¿™ä¸ª ir. è¿™é‡Œéœ€è¦æ³¨æ„åªè¦ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µæœ‰ä¸€ä¸ªæ˜¯äºŒç»´å¼ é‡ (æ¯”å¦‚çº¿æ€§å±‚çš„æƒé‡)ï¼Œmhlo éƒ½ä¼šå°†å¦ä¸€ä¸ª reshape æˆäºŒç»´å¼ é‡ã€‚dot ç®—å­ (jaxlib.mlir.dialects._mhlo_ops_gen.DotOp) ä¸¤ä¸ªæ“ä½œæ•°éƒ½æ˜¯äºŒç»´çš„å¼ é‡ï¼ŒqkvLinear å¯¹åº”çš„æ˜¯ç¬¬ä¸€ä¸ª dot æ“ä½œã€‚å·¦æ“ä½œæ•°çš„ shape ä¸º (BST,3C). å½“ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µéƒ½æ˜¯ 3 ç»´åŠä»¥ä¸Šå¼ é‡çš„æ—¶å€™å°±ä¼šç”Ÿæˆ dot_general è¯¥ç®—å­çš„ä¸¤ä¸ªç›¸ä¹˜çš„çŸ©é˜µéƒ½ä¼šè¢« reshape æˆä¸‰ç»´å¼ é‡ã€‚Self-Attention çš„ç¬¬ä¸€ä¸ª dot_general å·¦æ“ä½œæ•°çš„ shape ä¸º (BTN_A,S,C). è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ° BT=(BST)/S, N_A=(BTN_A)/(BT). åŒæ ·æˆ‘ä»¬å¯ä»¥å¾—åˆ° OLinear, FFN ä¸­ upLinear å’Œ downLinear æƒé‡çš„å½¢çŠ¶. ä»¥åŠ Cross-Attention æ¨¡å—çš„å¯¹åº”ä¿¡æ¯ã€‚ç”±äºä¹‹å‰éå†æ˜¯ä»ç¬¬äºŒä¸ª block å¼€å§‹çš„ï¼Œå› æ­¤æ€»å±‚æ•°è¦ ï¼‹1. æœ€åå°†å¾—åˆ°çš„å‚æ•°æ‰“åŒ…æˆä¸€ä¸ªå­—å…¸è¿”å›ã€‚\nCommunication View æˆ‘ä»¬ä»¥åŒæ ·çš„æ–¹å¼å®šä¹‰å„ç§é›†åˆé€šä¿¡ç®—å­çš„ visit å‡½æ•°ç”¨äºè¯„ä¼°è¯¥ç®—å­çš„é€šä¿¡é‡ï¼Œéå†åˆ°å¯¹åº”çš„ ir åè°ƒç”¨å®ƒã€‚\nAllReduce å°†æ‰€æœ‰çš„æ•°æ®é€šè¿‡è§„çº¦æ“ä½œé›†æˆåˆ°å„ä¸ªè®¾å¤‡ä¸­ã€‚\nAllReduce\nåœ¨ Ring-AllReduce çš„ ReduceScatter æ­¥éª¤ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹å‘é€ M ä¸ªå…ƒç´  N-1 æ¬¡ï¼Œæ€»å…±ä¸º M(N-1). åœ¨ AllGather æ­¥éª¤ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹å‘é€å®ƒè®¡ç®—çš„å—çš„ç»“æœã€‚è¿™æ˜¯é¢å¤–çš„ M ä¸ªå…ƒç´ å‘é€äº† N-1 æ¬¡ã€‚æ€»çš„é€šä¿¡é‡åŠ èµ·æ¥æ˜¯ 2M(N-1).\nRing-AllReduce\nAll-Gather ç¤ºæ„å›¾å¦‚ä¸‹ï¼Œæ¯ä¸ªè®¾å¤‡å¼€å§‹æ‹¥æœ‰åˆå§‹çš„ä¸€éƒ¨åˆ†æ•°æ®ï¼Œé€šä¿¡åæ¯ä¸ªè®¾å¤‡éƒ½æœ‰ä¸€ä»½å®Œæ•´çš„æ•°æ®ã€‚æ€»çš„é€šä¿¡é‡ä¸º M(N-1).\nAllGather\nAll2All ç¤ºæ„å›¾å¦‚ä¸‹ï¼Œæ¯ä¸ªè®¾å¤‡æŠŠè‡ªå·±çš„ç¬¬ i å—æ•°æ®å‘é€ç»™ç¬¬ i ä¸ªè®¾å¤‡ã€‚\nAll2All\nåŸºäº Bruck ç®—æ³•çš„ All2All æµç¨‹å¦‚ä¸‹\nå±€éƒ¨å¾ªç¯ç§»ä½ (Local Shift of Data-Blocks) æ¯ä¸ªè¿›ç¨‹å°†å…¶æœ¬åœ°çš„æ•°æ®å—é‡æ–°æ’åˆ—ï¼Œè¿›è¡Œåˆå§‹çš„å¾ªç¯ç§»ä½ã€‚å¯¹äºè¿›ç¨‹ p å’Œæ•°æ®å—ç´¢å¼• i: R[i]=S[(p+i)%P]. å…¶ä¸­ S[i] æ˜¯è¿›ç¨‹æœ¬åœ°åˆå§‹çš„æ•°æ®ï¼ŒR[i] æ˜¯ç§»ä½åçš„æ•°æ®ã€‚ å…¨å±€é€šä¿¡ (Global Communication) ä¸€å…±è¿›è¡Œ log(P) æ¬¡é€šä¿¡ã€‚ æ¯ä¸€æ­¥ä¸­æ¯ä¸ªè¿›ç¨‹å°†ä¸€éƒ¨åˆ†æ•°æ®å‘é€ç»™ç›¸é‚»çš„è¿›ç¨‹ï¼Œå¹¶æ¥æ”¶ç›¸é‚»è¿›ç¨‹å‘é€çš„æ•°æ®ã€‚è‹¥æ•°æ®å—ç´¢å¼• i ç”¨ radix-2 è¡¨ç¤ºçš„ç¬¬ k ä½ä¸º 1ï¼Œåˆ™æ•°æ®å—ä¼šè¢«å‘é€åˆ°ç›®æ ‡è¿›ç¨‹ã€‚ å¯¹äºè¿›ç¨‹ p: å‘é€æ•°æ®åˆ°è¿›ç¨‹ ((p + 2^k) % P)ï¼Œæ¥æ”¶æ¥è‡ªè¿›ç¨‹ ((p - 2^k) % P) çš„æ•°æ®ã€‚ æ¯æ¬¡å‘é€åï¼Œè¿›ç¨‹å°†æ¥æ”¶åˆ°çš„æ•°æ®æ›´æ–°åˆ°å…¶æœ¬åœ°æ•°æ®ä¸­ã€‚ å±€éƒ¨é€†å‘ç§»ä½ (Local Inverse Shift of Data-Blocks) åœ¨å®Œæˆæ‰€æœ‰å…¨å±€é€šä¿¡ä¹‹åï¼Œæ¯ä¸ªè¿›ç¨‹æ‰§è¡Œé€†å‘ç§»ä½ï¼Œä»¥æ¢å¤æ•°æ®å—çš„æ­£ç¡®é¡ºåºã€‚å¯¹äºæ¯ä¸ªæ•°æ®å—ç´¢å¼• i: R[i]=R[(pâˆ’i+P)%P] åœ¨è¿›ç¨‹æ˜¯ 2 æ¬¡å¹‚çš„æƒ…å†µä¸‹æ¯ä¸ªè®¾å¤‡æ¯æ¬¡è¦é€šä¿¡ M*P/2å¤§å°çš„æ•°æ®ï¼Œæ€»å…±ä¸º MPlog(P)/2.\nExample of the Bruck Algorithm with 4 Processes\nTFLOPS View è®¡ç®—é‡ä¸»è¦åˆ†æˆä¸¤ç§ï¼Œelement-wise çš„æ“ä½œè®¡ç®—é‡ä¸ºå…ƒç´ ä¸ªæ•°ã€‚ä¸¤ä¸ªå½¢çŠ¶åˆ†åˆ«ä¸º mxk å’Œ kxn çš„çŸ©é˜µç›¸ä¹˜è®¡ç®—é‡ä¸º 2mkn. è¢«è®¡å…¥ element-wise æ“ä½œçš„ç®—å­æœ‰ add, subtract, multiply, divide, rsqrt, negate, exponential. è¢«è®¡å…¥çŸ©é˜µä¹˜æ³•çš„ç®—å­æœ‰ dot, dot_general.\nPerformance Analysis æˆ‘ä»¬æ ¹æ®æå–å‡ºçš„ Transformer block çš„ä¿¡æ¯é€å…¥æ€§èƒ½åˆ†æå™¨è¿›è¡Œåˆ†æ. tx8 çš„é…ç½®å¦‚ä¸‹\nParameter Value TILE_NUM 16 SRAM (MB) 3 NOC BW (GB/s) 128 DRAM BW (GB/s) 100 DRAM LATENCY (us) 0.1 GEMM (TFLOPS) 8 VECTOR (TOPS) 0.0625 HOP LATENCY (us) 0.01 æ ¹æ®æå–å‡ºçš„ä¿¡æ¯æ„å»ºçš„ STDiT çš„ spt_blk, tmp_blk, cross_blk çš„å‚æ•°å­—å…¸å¦‚ä¸‹.\n1 2 3 4 5 6 7 spatial_config = {\u0026#34;B\u0026#34;: self.config[\u0026#34;B_spt\u0026#34;], \u0026#34;S_Q\u0026#34;: self.config[\u0026#34;S_Q_spt\u0026#34;], \u0026#34;S_KV\u0026#34;: self.config[\u0026#34;S_KV_spt\u0026#34;], \u0026#34;D_QKV\u0026#34;: self.config[\u0026#34;D_QKV\u0026#34;], \u0026#34;H_QKV\u0026#34;: self.config[\u0026#34;H_QKV\u0026#34;], \u0026#34;N_A\u0026#34;: self.config[\u0026#34;N_A\u0026#34;], \u0026#34;H_A\u0026#34;: self.config[\u0026#34;H_A\u0026#34;], \u0026#34;D_O\u0026#34;: self.config[\u0026#34;D_O_spt\u0026#34;], \u0026#34;H_O\u0026#34;: self.config[\u0026#34;H_O_spt\u0026#34;] } temporal_config = {\u0026#34;B\u0026#34;: self.config[\u0026#34;B_tmp\u0026#34;], \u0026#34;S_Q\u0026#34;: self.config[\u0026#34;S_Q_tmp\u0026#34;], \u0026#34;S_KV\u0026#34;: self.config[\u0026#34;S_KV_tmp\u0026#34;], \u0026#34;D_QKV\u0026#34;: self.config[\u0026#34;D_QKV\u0026#34;], \u0026#34;H_QKV\u0026#34;: self.config[\u0026#34;H_QKV\u0026#34;], \u0026#34;N_A\u0026#34;: self.config[\u0026#34;N_A\u0026#34;], \u0026#34;H_A\u0026#34;: self.config[\u0026#34;H_A\u0026#34;], \u0026#34;D_O\u0026#34;: self.config[\u0026#34;D_O_tmp\u0026#34;], \u0026#34;H_O\u0026#34;: self.config[\u0026#34;H_O_tmp\u0026#34;] } cross_config = {\u0026#34;B\u0026#34;: self.config[\u0026#34;B_cro\u0026#34;], \u0026#34;S_Q\u0026#34;: self.config[\u0026#34;S_Q_cro\u0026#34;], \u0026#34;S_KV\u0026#34;: self.config[\u0026#34;S_KV_cro\u0026#34;], \u0026#34;D_QKV\u0026#34;: self.config[\u0026#34;D_QKV\u0026#34;], \u0026#34;H_QKV\u0026#34;: self.config[\u0026#34;H_QKV\u0026#34;],\u0026#34;N_A\u0026#34;: self.config[\u0026#34;N_A\u0026#34;], \u0026#34;H_A\u0026#34;: self.config[\u0026#34;H_A\u0026#34;], \u0026#34;D_O\u0026#34;: self.config[\u0026#34;D_O_cro\u0026#34;], \u0026#34;H_O\u0026#34;: self.config[\u0026#34;H_O_cro\u0026#34;], \u0026#34;D_FU\u0026#34;: self.config[\u0026#34;D_FU\u0026#34;], \u0026#34;H_FU\u0026#34;: self.config[\u0026#34;H_FU\u0026#34;], \u0026#34;D_FD\u0026#34;: self.config[\u0026#34;D_FD\u0026#34;], \u0026#34;H_FD\u0026#34;: self.config[\u0026#34;H_FD\u0026#34;]} æ ¹æ®è¿™äº›å‚æ•°å†æ„å»ºæ¯ä¸ªå±‚çš„è¾“å…¥è¾“å‡ºå½¢çŠ¶ï¼Œè®¡ç®—ç±»å‹å’Œè®¡ç®—é‡ï¼Œä»¥ Gate_ResAdd ä¸ºä¾‹:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 GB = 2**30 class Gate_ResAdd(): \u0026#39;\u0026#39;\u0026#39; Construct each op after MHSA on the config file \u0026#39;\u0026#39;\u0026#39; def __init__(self, config: dict, name: str) -\u0026gt; None: self.config = config self.name = name # {name:{type:\u0026#34;\u0026#34;, size:\u0026#34;\u0026#34;, ishape:[], wshape:[]/None, oshape:[]}} self.ops = {} self.construct_model() def construct_model(self): GB = 2**30 ResAdd_input_shape = [self.config[\u0026#39;B\u0026#39;], self.config[\u0026#39;S_Q\u0026#39;], self.config[\u0026#39;D_O\u0026#39;]] ResAdd_weight_shape = [1, self.config[\u0026#39;D_O\u0026#39;]] ResAdd_output_shape = ResAdd_input_shape ResAdd_compute = 2*ResAdd_input_shape[0]*ResAdd_input_shape[1]*ResAdd_input_shape[2]/GB self.ops[self.name+\u0026#34;_\u0026#34;+\u0026#34;ResAdd\u0026#34;] = {\u0026#34;name\u0026#34;:\u0026#34;ResAdd\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Vector\u0026#34;, \u0026#34;ishape\u0026#34;: ResAdd_input_shape, \u0026#34;wshape\u0026#34;: ResAdd_weight_shape, \u0026#34;oshape\u0026#34;: ResAdd_output_shape, \u0026#34;compute\u0026#34;: ResAdd_compute} å°±åƒè¿™æ ·æ„å»ºæ•´ä¸ª Transformer block çš„æ‰€æœ‰æ“ä½œ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class STDIT2_block(): def __init__(self, config) -\u0026gt; None: self.config = config # {name:{type:\u0026#34;\u0026#34;, size:\u0026#34;\u0026#34;, ishape:[], wshape:[]/None, oshape:[]}} self.ops = {} self.construct_model() def construct_model(self): spatial_config = {\u0026#34;B\u0026#34;: self.config[\u0026#34;B_spt\u0026#34;], \u0026#34;S_Q\u0026#34;: self.config[\u0026#34;S_Q_spt\u0026#34;], \u0026#34;S_KV\u0026#34;: self.config[\u0026#34;S_KV_spt\u0026#34;], \u0026#34;D_QKV\u0026#34;: self.config[\u0026#34;D_QKV\u0026#34;], \u0026#34;H_QKV\u0026#34;: self.config[\u0026#34;H_QKV\u0026#34;], \u0026#34;N_A\u0026#34;: self.config[\u0026#34;N_A\u0026#34;], \u0026#34;H_A\u0026#34;: self.config[\u0026#34;H_A\u0026#34;], \u0026#34;D_O\u0026#34;: self.config[\u0026#34;D_O_spt\u0026#34;], \u0026#34;H_O\u0026#34;: self.config[\u0026#34;H_O_spt\u0026#34;] } temporal_config = {\u0026#34;B\u0026#34;: self.config[\u0026#34;B_tmp\u0026#34;], \u0026#34;S_Q\u0026#34;: self.config[\u0026#34;S_Q_tmp\u0026#34;], \u0026#34;S_KV\u0026#34;: self.config[\u0026#34;S_KV_tmp\u0026#34;], \u0026#34;D_QKV\u0026#34;: self.config[\u0026#34;D_QKV\u0026#34;], \u0026#34;H_QKV\u0026#34;: self.config[\u0026#34;H_QKV\u0026#34;], \u0026#34;N_A\u0026#34;: self.config[\u0026#34;N_A\u0026#34;], \u0026#34;H_A\u0026#34;: self.config[\u0026#34;H_A\u0026#34;], \u0026#34;D_O\u0026#34;: self.config[\u0026#34;D_O_tmp\u0026#34;], \u0026#34;H_O\u0026#34;: self.config[\u0026#34;H_O_tmp\u0026#34;] } cross_config = {\u0026#34;B\u0026#34;: self.config[\u0026#34;B_cro\u0026#34;], \u0026#34;S_Q\u0026#34;: self.config[\u0026#34;S_Q_cro\u0026#34;], \u0026#34;S_KV\u0026#34;: self.config[\u0026#34;S_KV_cro\u0026#34;], \u0026#34;D_QKV\u0026#34;: self.config[\u0026#34;D_QKV\u0026#34;], \u0026#34;H_QKV\u0026#34;: self.config[\u0026#34;H_QKV\u0026#34;],\u0026#34;N_A\u0026#34;: self.config[\u0026#34;N_A\u0026#34;], \u0026#34;H_A\u0026#34;: self.config[\u0026#34;H_A\u0026#34;], \u0026#34;D_O\u0026#34;: self.config[\u0026#34;D_O_cro\u0026#34;], \u0026#34;H_O\u0026#34;: self.config[\u0026#34;H_O_cro\u0026#34;], \u0026#34;D_FU\u0026#34;: self.config[\u0026#34;D_FU\u0026#34;], \u0026#34;H_FU\u0026#34;: self.config[\u0026#34;H_FU\u0026#34;], \u0026#34;D_FD\u0026#34;: self.config[\u0026#34;D_FD\u0026#34;], \u0026#34;H_FD\u0026#34;: self.config[\u0026#34;H_FD\u0026#34;]} self.spatial_modulate = Modulate(spatial_config, name=\u0026#34;spatial\u0026#34;) self.spatial_block = MHSA_block(spatial_config, name=\u0026#34;spatial\u0026#34;) self.spatial_gate_resadd = Gate_ResAdd(spatial_config, name=\u0026#34;spatial\u0026#34;) self.temporal_modulate = Modulate(temporal_config, name=\u0026#34;temporal\u0026#34;) self.temporal_block = MHSA_block(temporal_config, name=\u0026#34;temporal\u0026#34;) self.temporal_gate_resadd = Gate_ResAdd(temporal_config, name=\u0026#34;temporal\u0026#34;) self.cross_block = MHSA_block(cross_config, name=\u0026#34;cross\u0026#34;) self.cross_gate_resadd = Gate_ResAdd(cross_config, name=\u0026#34;cross\u0026#34;) self.mlp_modulate = Modulate(cross_config, name=\u0026#34;mlp\u0026#34;) self.ffn_block = FFN_block(cross_config) self.mlp_gate_resadd = Gate_ResAdd(cross_config, name=\u0026#34;mlp\u0026#34;) op_list = [self.spatial_modulate.ops, self.spatial_block.ops, self.spatial_gate_resadd.ops, self.temporal_modulate.ops, self.temporal_block.ops, self.temporal_gate_resadd.ops, self.cross_block.ops, self.cross_gate_resadd.ops, self.mlp_modulate.ops, self.ffn_block.ops, self.mlp_gate_resadd.ops] for op_dict in op_list: self.ops.update(op_dict) print(self.ops.keys()) ç„¶åå°±å¯ä»¥å°†æ„å»ºå¥½çš„ ops æ”¾å…¥ mapper è¿›è¡Œåˆ†æã€‚åˆšæ‰é‚£äº›æ“ä½œä¼šè¢«åˆ†æˆ 3 ç±» vector_mapper, gemm_auto_opt_mapper å’Œ flashatten_mapper. æˆ‘ä»¬æ ¹æ®æ“ä½œçš„ç±»å‹é€å…¥å¯¹åº”çš„ mapper è¿›è¡Œåˆ†æï¼Œå…·ä½“å¦‚ä¸‹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def STDIT2_mapper(model, arch, QKV_fusion=True, preset=True, details=True): config = model.config Layers = config[\u0026#39;L\u0026#39;] spatial_config = {\u0026#39;B\u0026#39;: config[\u0026#39;B_spt\u0026#39;], \u0026#39;S_Q\u0026#39;: config[\u0026#39;S_Q_spt\u0026#39;], \u0026#39;S_KV\u0026#39;: config[\u0026#39;S_KV_spt\u0026#39;], \u0026#39;H_A\u0026#39;: config[\u0026#39;H_A\u0026#39;], \u0026#39;N_A\u0026#39;: config[\u0026#39;N_A\u0026#39;], \u0026#39;Q\u0026#39;: config[\u0026#39;Q\u0026#39;]} temporal_config = {\u0026#39;B\u0026#39;: config[\u0026#39;B_tmp\u0026#39;], \u0026#39;S_Q\u0026#39;: config[\u0026#39;S_Q_tmp\u0026#39;], \u0026#39;S_KV\u0026#39;: config[\u0026#39;S_KV_tmp\u0026#39;], \u0026#39;H_A\u0026#39;: config[\u0026#39;H_A\u0026#39;], \u0026#39;N_A\u0026#39;: config[\u0026#39;N_A\u0026#39;], \u0026#39;Q\u0026#39;: config[\u0026#39;Q\u0026#39;]} cross_config = {\u0026#39;B\u0026#39;: config[\u0026#39;B_cro\u0026#39;], \u0026#39;S_Q\u0026#39;: config[\u0026#39;S_Q_cro\u0026#39;], \u0026#39;S_KV\u0026#39;: config[\u0026#39;S_KV_cro\u0026#39;], \u0026#39;H_A\u0026#39;: config[\u0026#39;H_A\u0026#39;], \u0026#39;N_A\u0026#39;: config[\u0026#39;N_A\u0026#39;], \u0026#39;Q\u0026#39;: config[\u0026#39;Q\u0026#39;]} ops = model.ops mapping_result = {} \u0026#39;\u0026#39;\u0026#39;========================= == Spatial Branch Mapping == =========================\u0026#39;\u0026#39;\u0026#39; TmTn = [256, 32] if preset else None mapping_result[\u0026#39;spatial_Modulate\u0026#39;] = vector_mapper(ops[\u0026#39;spatial_Modulate\u0026#39;],arch,splits=None,details=details) mapping_result[\u0026#39;spatial_RMSNorm\u0026#39;]= vector_mapper(ops[\u0026#39;spatial_RMSNorm\u0026#39;],arch,splits=None,details=details) mapping_result[\u0026#39;spatial_Q_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;spatial_Q_proj\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;spatial_K_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;spatial_K_proj\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;spatial_V_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;spatial_V_proj\u0026#39;], arch, TmTn=TmTn, details=details) Tx_Ty = [256, 256] if preset else None mapping_result[\u0026#39;spatial_Flashatten\u0026#39;] = flashatten_mapper(spatial_config, arch, Tx_Ty=Tx_Ty, details=details, Head_fused=True) # FIXME mapping_result[\u0026#39;spatial_ResAdd\u0026#39;]=vector_mapper(ops[\u0026#39;spatial_ResAdd\u0026#39;],arch,splits=None,details=details) \u0026#39;\u0026#39;\u0026#39;========================== == Temporal Branch Mapping == ==========================\u0026#39;\u0026#39;\u0026#39; mapping_result[\u0026#39;temporal_Modulate\u0026#39;] = vector_mapper(ops[\u0026#39;temporal_Modulate\u0026#39;],arch,splits=None,details=details) # åˆ‡åˆ† 30 ä»½ä¹Ÿæ— æ³•æ»¡è¶³SRAMè¦æ±‚ mapping_result[\u0026#39;temporal_RMSNorm\u0026#39;]= vector_mapper(ops[\u0026#39;temporal_RMSNorm\u0026#39;],arch,splits=None,details=details) mapping_result[\u0026#39;temporal_Q_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;temporal_Q_proj\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;temporal_K_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;temporal_K_proj\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;temporal_V_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;temporal_V_proj\u0026#39;], arch, TmTn=TmTn, details=details) Tx_Ty = [256, 256] if preset else None mapping_result[\u0026#39;temporal_Flashatten\u0026#39;] = flashatten_mapper(temporal_config, arch, Tx_Ty=Tx_Ty, details=details, Head_fused=True) # FIXME mapping_result[\u0026#39;temporal_ResAdd\u0026#39;]=vector_mapper(ops[\u0026#39;temporal_ResAdd\u0026#39;],arch,splits=None,details=details) \u0026#39;\u0026#39;\u0026#39;==================================== == Cross Branch Mapping 2x per block == ====================================\u0026#39;\u0026#39;\u0026#39; #mapping_result[\u0026#39;spatial_RMSNorm\u0026#39;]= vector_mapper(ops[\u0026#39;spatial_RMSNorm\u0026#39;],arch,splits=None,details=details) mapping_result[\u0026#39;cross_Q_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;cross_Q_proj\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;cross_Q_proj_2\u0026#39;] = mapping_result[\u0026#39;cross_Q_proj\u0026#39;] mapping_result[\u0026#39;cross_K_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;cross_K_proj\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;cross_K_proj_2\u0026#39;] = mapping_result[\u0026#39;cross_K_proj\u0026#39;] mapping_result[\u0026#39;cross_V_proj\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;cross_V_proj\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;cross_V_proj_2\u0026#39;] = mapping_result[\u0026#39;cross_V_proj\u0026#39;] Tx_Ty = [256, 256] if preset else None mapping_result[\u0026#39;cross_Flashatten\u0026#39;] = flashatten_mapper(cross_config, arch, Tx_Ty=Tx_Ty, details=details, Head_fused=True) # FIXME mapping_result[\u0026#39;cross_Flashatten_2\u0026#39;] = mapping_result[\u0026#39;cross_Flashatten\u0026#39;] mapping_result[\u0026#39;cross_ResAdd\u0026#39;] = vector_mapper(ops[\u0026#39;cross_ResAdd\u0026#39;],arch,splits=None,details=details) # HACK: Gate_ResAdd *2 äº†, cross æ— gate è¿™é‡Œæ—  _2 \u0026#39;\u0026#39;\u0026#39;==================================== == Feed Forward Network 2x per block == ====================================\u0026#39;\u0026#39;\u0026#39; mapping_result[\u0026#39;mlp_Modulate\u0026#39;] = vector_mapper(ops[\u0026#39;mlp_Modulate\u0026#39;],arch,splits=None,details=details) mapping_result[\u0026#39;mlp_Modulate_2\u0026#39;] = mapping_result[\u0026#39;mlp_Modulate\u0026#39;] mapping_result[\u0026#39;FFNup\u0026amp;SiLU\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;FFNup\u0026#39;],arch,TmTn=TmTn,fusion_op2=ops[\u0026#39;SiLU\u0026#39;],details=details) mapping_result[\u0026#39;FFNup\u0026amp;SiLU_2\u0026#39;] = mapping_result[\u0026#39;FFNup\u0026amp;SiLU\u0026#39;] # mapping_result[\u0026#39;FFNgate\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;FFNgate\u0026#39;], arch, TmTn=TmTn, details=details) # mapping_result[\u0026#39;Hadamard\u0026#39;] = vector_mapper(ops[\u0026#39;Hadamard\u0026#39;], arch, splits=None) TmTn = [4, 128] if preset else None mapping_result[\u0026#39;FFNdown\u0026#39;] = gemm_auto_opt_mapper(ops[\u0026#39;FFNdown\u0026#39;], arch, TmTn=TmTn, details=details) mapping_result[\u0026#39;FFNdown_2\u0026#39;] = mapping_result[\u0026#39;FFNdown\u0026#39;] mapping_result[\u0026#39;mlp_ResAdd\u0026#39;] = vector_mapper(ops[\u0026#39;mlp_ResAdd\u0026#39;], arch, splits=None, details=details) mapping_result[\u0026#39;mlp_ResAdd_2\u0026#39;] = mapping_result[\u0026#39;mlp_ResAdd\u0026#39;] mapper ä¼šéå†æ‰€æœ‰å¯èƒ½çš„åˆ‡åˆ†ç­–ç•¥æ”¾å…¥ tx8 æ‰§è¡Œå¹¶é€‰æ‹©æœ€å¥½çš„é‚£ä¸€ä¸ªã€‚å¯¹äº vector ç±»å‹çš„ç®—å­åªä¼šæ²¿ç€ sequence ç»´åº¦åˆ‡åˆ†ï¼›å¯¹äº GEMM ç®—å­åˆ™ä¼šæ²¿ç€ m, k, n ç»´åº¦éƒ½è¿›è¡Œåˆ‡åˆ†ï¼›å¯¹äº flash-attention çš„åˆ‡åˆ†åˆ™ä¸åŸç®—æ³•ç›¸åŒï¼Œå¤–å¾ªç¯éå† K, V çš„æ¯ä¸€å—ï¼Œå†…å¾ªç¯éå† Q çš„æ¯ä¸€å—ã€‚è¿™æ ·å°±å¯ä»¥å¾—åˆ°æ¯ä¸ª tx8 ä¸Šæœ€ä¼˜çš„åˆ‡åˆ†æ–¹å¼å¯¹åº”çš„é€šä¿¡ç”¨æ—¶ï¼Œè®¡ç®—ç”¨æ—¶å’Œåˆ©ç”¨ç‡ã€‚å†ç”¨ä¹‹å‰ç»Ÿè®¡å‡ºçš„æ¯ä¸ª die ä¸Šé€šä¿¡é‡é™¤ä»¥ die2die å¸¦å®½å¾—åˆ°é€šä¿¡ç”¨æ—¶ï¼Œç”±æ­¤å¾—åˆ°æ€»çš„æ¨ç†ç”¨æ—¶ã€‚\n","permalink":"http://localhost:1313/blogs/comparsion-of-parallelsim-metods-in-vit/","summary":"Paper reading of","title":"Comparsion of Parallelsim Metods in ViT"},{"content":" luminolt\u0026#39;s Page Cryptography Learner Jonathan523\u0026#39;s Page æ¯ä¸€ä¸ªä¸æ›¾èµ·èˆçš„æ—¥å­, éƒ½æ˜¯å¯¹ç”Ÿå‘½çš„è¾œè´Ÿ ","permalink":"http://localhost:1313/friends/","summary":"\u003cp\u003e\u003ca target=\"_blank\" href=https://luminolt.cn/ title=luminolt\u0026#39;s\u0026#32;Page class=\"friendurl\"\u003e\n  \u003cdiv class=\"frienddiv\"\u003e\n    \u003cdiv class=\"frienddivleft\"\u003e\n      \u003cimg class=\"myfriend\" src=https://luminolt.cn/author/chenghao-chen/avatar_hu15811225952467136947.jpg /\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"frienddivright\"\u003e\n      \u003cdiv class=\"friendname\"\u003eluminolt\u0026#39;s Page\u003c/div\u003e\n      \u003cdiv class=\"friendinfo\"\u003eCryptography Learner\u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/a\u003e\n\u003ca target=\"_blank\" href=https://www.cestlavie.moe/ title=Jonathan523\u0026#39;s\u0026#32;Page class=\"friendurl\"\u003e\n  \u003cdiv class=\"frienddiv\"\u003e\n    \u003cdiv class=\"frienddivleft\"\u003e\n      \u003cimg class=\"myfriend\" src=/imgs/people/Jonathan523.png /\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"frienddivright\"\u003e\n      \u003cdiv class=\"friendname\"\u003eJonathan523\u0026#39;s Page\u003c/div\u003e\n      \u003cdiv class=\"friendinfo\"\u003eæ¯ä¸€ä¸ªä¸æ›¾èµ·èˆçš„æ—¥å­, éƒ½æ˜¯å¯¹ç”Ÿå‘½çš„è¾œè´Ÿ\u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/a\u003e\u003c/p\u003e","title":"Friends"}]