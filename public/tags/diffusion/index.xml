<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Diffusion on WITHER</title>
    <link>http://localhost:57770/tags/diffusion/</link>
    <description>Recent content in Diffusion on WITHER</description>
    <generator>Hugo -- 0.147.7</generator>
    <language>en</language>
    <copyright>2024-2025 WITHER</copyright>
    <lastBuildDate>Fri, 13 Jun 2025 11:39:32 +0800</lastBuildDate>
    <atom:link href="http://localhost:57770/tags/diffusion/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PipeFusion</title>
      <link>http://localhost:57770/blogs/pipefusion/</link>
      <pubDate>Fri, 13 Jun 2025 11:39:32 +0800</pubDate>
      <guid>http://localhost:57770/blogs/pipefusion/</guid>
      <description>Paper Reading of PipeFusion</description>
      <content:encoded><![CDATA[<h1 id="abstract">Abstract</h1>
<p>PipeFusion 是一种利用多 GPU 并行来进行 DiT 模型推理的方法。</p>
<ul>
<li>将图像分割成 patch，并将 Transformer Blocks 分布在多个设备上。</li>
<li>通过重用上一步 (<em>one-step stale</em>) 的特征图作为当前步的上下文，消除了流水线中的等待时间。</li>
</ul>
<h1 id="introduction">Introduction</h1>
<p>由于 Attention 的计算特性，计算时间与序列长度的平方成正比，使得 DiT 模型生成高分辨率图形 (长视觉序列) 的推理延迟非常高。
<a href="https://arxiv.org/abs/2402.19481">DistriFusion</a> 观察到在相邻的扩散时间步中输入和激活存在高度相似性，我们将这种现象称为输入时间冗余 (<em>input temporal redundancy</em>). 它保留所有层 KV 的完整形状。内存开销不会随着计算设备数量的增加而减少，在可扩展性方面表现不佳。</p>
<p>如下图所示，DistriFusion 在 2 个设备上都保存一份 DiT 参数。它将图像分成 2 个小块，并对每一层的激活使用异步 allgather. PipeFusion 将 DiT 参数切分到 2 个设备上，将图像分成 4 个 patch ，两个设备之间采用异步 P2P 通信来传输激活。它只在每个设备上传输初始层的输入激活和最终层的输出激活</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB0b7d56775c290d039aba1c7aab220319?method=download&amp;shareKey=6330f70503af01609e9fe13a35826aab" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB0b7d56775c290d039aba1c7aab220319?method=download&amp;shareKey=6330f70503af01609e9fe13a35826aab" alt="Comparsion Between DistriFusion &amp; PipeFusion">
    </a><figcaption>Comparsion Between DistriFusion &amp; PipeFusion</figcaption></figure></p>
<h1 id="background--related-works">Background &amp; Related Works</h1>
<p>扩散模型通常使用 DNN 预测噪声。给定有噪声的图像 xt，模型 ϵθ 将 xt、去噪时间步 t 和附加条件 c (例如文本、图像) 作为输入，以预测 xt 中相应的噪声ϵt.</p>
<p>扩散模型具有较长的序列长度和较小的模型大小，但在推理过程中通信开销仍然很大。DistriFusion 为 U-Net 为主干的扩散模型引入了位移 patch 并行(displacement patch parallelism)，将模型的输入划分为多个 patch，便于激活的异步通信并且使得通信与计算重叠。然而，当将该方法应用于 DiT 时，内存缓冲区的开销将导致巨大的内存开销。</p>
<h1 id="methods">Methods</h1>
<p>不同并行策略下 DiT 单步扩散过程的比较如下表所示。</p>
<ul>
<li>p: 生成的序列长度 (即隐空间下的像素数量).</li>
<li>hs: 模型的隐藏通道大小。</li>
<li>N: 设备数量。</li>
<li>M: 图像切分的 patch 数量。</li>
<li>L: Transformer Blocks 层数。</li>
<li>P: 模型总参数量。</li>
<li>A: Attention 的过程中的激活大小 (Q, K, V, O 大小一样)</li>
</ul>
<p>名称后面的 * 表示采用异步通信，通信开销可以通过计算隐藏。</p>
<table>
  <thead>
      <tr>
          <th></th>
          <th>attn-KV</th>
          <th>communication cost</th>
          <th>param</th>
          <th>QO Activations</th>
          <th>KV Activations</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Tensor Parallel</td>
          <td>fresh</td>
          <td>4O(p × hs)L</td>
          <td>P/N</td>
          <td>(2/N) A = (1/N) QO</td>
          <td>(2/N) A = (1/N) KV</td>
      </tr>
      <tr>
          <td>DistriFusion*</td>
          <td>stale</td>
          <td>2O(p × hs)L</td>
          <td>P</td>
          <td>A</td>
          <td>2AL = (KV)L</td>
      </tr>
      <tr>
          <td>Ring Seq Parallel*</td>
          <td>fresh</td>
          <td>NA</td>
          <td>P</td>
          <td>A</td>
          <td>A</td>
      </tr>
      <tr>
          <td>Ulysses Seq Parallel</td>
          <td>fresh</td>
          <td>4O(p × hs)L</td>
          <td>P</td>
          <td>(2/N) A = (1/N) QO</td>
          <td>(2/N) A = (1/N) KV</td>
      </tr>
      <tr>
          <td>PipeFusion*</td>
          <td>stale-</td>
          <td>2O(p × hs)</td>
          <td>P/N</td>
          <td>(2/M) A = (1/M) QO</td>
          <td>(2L/N) A = (1/N) (KV)L</td>
      </tr>
  </tbody>
</table>
<h2 id="sequence-parallelism--tensor-parallelism">Sequence Parallelism &amp; Tensor Parallelism</h2>
<p>针对 LLM 提出的张量并行 (tensor parallelism, TP) 和序列并行 (sequence parallelism, SP) 可以应用于 DiT 推理。因为他们的主干都是 Transformer.
在 TP<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 中，权重矩阵按列被切分为 <em>N</em> 份，这样矩阵乘法后激活值也被切分成 <em>N</em> 份，使得每个设备的参数量和激活量均为原来的 1/N. 在 attention 计算和 FFN 层之后都需要进行两次同步 all-reduce 操作，因此每一层通信量为 4O(p × hs).</p>
<p>在 SP 中，可以将输入图像分割成 patch，DiT 中的多头注意模块可以采用 Ring-Attention<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>，DeepSpeed-Ulysses<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>，或者两者的组合。Ulysses SP 并行需要 4 次 all-to-all 操作，因此每一层通信量为 4O(p × hs), 和 TP 相同。</p>
<blockquote>
<p>TP 和 SP 可以在 DiT 推理中一起使用。</p></blockquote>
<h2 id="displaced-patch-parallelism">Displaced Patch Parallelism</h2>
<p>输入时间冗余意味着给定层中激活 patch 的计算并不完全取决于其他 patch 的最新激活。在前一个扩散步骤中加入稍微过时的激活是可行的。该方法将输入图像划分为 N 个patch，每个设备计算其各自 patch 的输出结果。 如下图所示 attention 模块需要具有完整形状的 KV 激活。它采用异步 all-gather 收集上一步扩散步骤的 KV 激活，并用其进行当前步的 attention 计算。</p>
<p>DistriFusion<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> 可以看作是异步 SQ 的一种形式。它通过正向计算扩散步骤来隐藏 KV 通信，但代价是消耗更多内存。DistriFusion 利用 N-1/N 的 T+1 步的 KV 激活和 T 步的 1/N 的局部 KV 激活相结合。与 Ring-Attention 相比，DistriFusion 可以更有效地隐藏通信开销，因为它允许 KV 通信与扩散步骤的整个前向计算重叠，而 Ring-Attention 只允许通信在注意模块内部重叠。</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB9a64239185e8b3604db9a46098203d05?method=download&amp;shareKey=eab8f5ec3cff754ab7711e87333e8797" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB9a64239185e8b3604db9a46098203d05?method=download&amp;shareKey=eab8f5ec3cff754ab7711e87333e8797" alt="DistriFusion vs. Ring-Attention SQ for an Attention Module">
    </a><figcaption>DistriFusion vs. Ring-Attention SQ for an Attention Module</figcaption></figure></p>
<p>在 Ring-Attention中，其通信缓冲区 c × hs 可由图中块大小 c 控制，其值小于 p/N. DistriFusion要求每个计算设备始终保持 KV 的完整形状的通信缓冲区，因此通信开销总共是 AL.</p>
<h2 id="displaced-patch-pipeline-parallelism">Displaced Patch Pipeline Parallelism</h2>
<p>PipeFusion 相比于 DistriFusion 有着更高的内存效率和更低的通信成本。它将输入图像划分为 M 个不重叠的 patch，DiT Blocks 被划分为 N 个阶段，每个阶段按顺序分配给 N 个计算设备。每个设备在其被分配的阶段以流水线方式处理一个 patch 的计算任务。</p>
<blockquote>
<p>DiT 模型中因有许多相同的 transformer block，很容易将去噪网络的工作负载均匀地划分为 N 个部分。然而，U-Net 扩散模型没有这种重复结构。</p></blockquote>
<p>一个 M=4, N=4 的 PipeFusion 例子如下图所示，利用输入时间冗余，设备不需要等待接收到当前步骤的完整形状激活，利用上一步的激活就可以开始自己所处阶段的计算。考虑流水线气泡，流水线的有效计算比为 MS/MS+N−1，其中 S 为扩散步长数。</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB157240ab4733f1ca4cca87a2389a7b08?method=download&amp;shareKey=b0593903312b6da2796d081015a30baa" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB157240ab4733f1ca4cca87a2389a7b08?method=download&amp;shareKey=b0593903312b6da2796d081015a30baa" alt="The Workflow of Displaced Patch Pipeline Parallelism">
    </a><figcaption>The Workflow of Displaced Patch Pipeline Parallelism</figcaption></figure></p>
<p>PipeFusion 在计算设备之间仅传输属于一个阶段的 (连续 transformerl blocks) 的输入和输出的激活，因此通信开销为 2O(p × hs). PipeFusion 通过异步 P2P 传输前一步 Patch 数据和接收后一步骤 Patch 数据来与当前 Patch 计算重叠，从而将通信隐藏在计算中。PipeFusion 中的每个设备仅存储与其特定阶段相关的 1/N 份参数。由于使用陈旧 KV 进行注意力计算，要求每个设备保持其阶段对应的 L/N 层的完整 KV.</p>
<p>PipeDiffusion 理论上优于 DistriFusion，因为它利用了更多的新激活。如图所示，在单个扩散步骤内，PipeDiffusion 中最新激活的占比随着流水线执行而增加。而 DistriFusion 中最新激活的占比一直都是 1/N.</p>
<blockquote>
<p>尽管 DiT 没有采用 GroupNorm 层，但在 PipeFusion 中，U-Net 中 DistriFusion 对 GroupNorm 层的精度保持设计，特别是校正异步群归一化 (Corrected Asynchronous GroupNorm)，可以无缝地应用于 PipeFusion.</p></blockquote>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBf19f26f13cfdf79d2e13e8b012b2954b?method=download&amp;shareKey=9983249909c804bca818835ce2f953ce" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBf19f26f13cfdf79d2e13e8b012b2954b?method=download&amp;shareKey=9983249909c804bca818835ce2f953ce" alt="The Fresh Part of Activations">
    </a><figcaption>The Fresh Part of Activations</figcaption></figure></p>
<p>由于使用输入时间冗余需要一个预热期，DistriFusion 使用了几次同步 path 并行的预热步骤作为预备阶段。为了优化预热开销，可以将预热步骤与其余步骤分开，并将其分配给不同的计算资源。</p>
<h1 id="experiments">Experiments</h1>
<p>我们在 Pixart-α 上进行实验 (0.6B)，它支持分辨率 1024px 的高分辨率图像合成，采用标准的 DiT，并结合交叉注意模块注入文本条件。使用了三个 GPU 集群，包括 4xGPU A100 80GB (PCIe) 集群，8xGPU A100 80GB (NVLink) 集群和 8xGPU L20 40GB (PCIe) 集群。测试的 GPU P2P 带宽分别为23 GB/s、268 GB/s 和 26 GB/s. 切分的 patch 数目 M 从 2,4,8,16,32 中搜索来确定最佳延迟性能。</p>
<ul>
<li>TP: 参考 Megatron-LM实 现了一个 TP DiT.</li>
<li>SP: 采用了两种不同的序列并行，DeepSpeed-Ulysses 和 Ring-Attention.</li>
<li>DistriFusion: 将 U-Net 扩散模型中的官方 DistriFusion 应用于DiT.</li>
<li>Original:在单个 GPU 上的串行实现。</li>
</ul>
<style type="text/css">
     
    .notice {
        --title-color: #fff;
        --title-background-color: #6be;
        --content-color: #444;
        --content-background-color: #e7f2fa;
    }

    .notice.info {
        --title-background-color: #fb7;
        --content-background-color: #fec;
    }

    .notice.tip {
        --title-background-color: #5a5;
        --content-background-color: #efe;
    }

    .notice.warning {
        --title-background-color: #c33;
        --content-background-color: #fee;
    }

     
    @media (prefers-color-scheme:dark) {
        .notice {
            --title-color: #fff;
            --title-background-color: #069;
            --content-color: #ddd;
            --content-background-color: #023;
        }

        .notice.info {
            --title-background-color: #a50;
            --content-background-color: #420;
        }

        .notice.tip {
            --title-background-color: #363;
            --content-background-color: #121;
        }

        .notice.warning {
            --title-background-color: #800;
            --content-background-color: #400;
        }
    }

    body.dark .notice {
        --title-color: #fff;
        --title-background-color: #069;
        --content-color: #ddd;
        --content-background-color: #023;
    }

    body.dark .notice.info {
        --title-background-color: #a50;
        --content-background-color: #420;
    }

    body.dark .notice.tip {
        --title-background-color: #363;
        --content-background-color: #121;
    }

    body.dark .notice.warning {
        --title-background-color: #800;
        --content-background-color: #400;
    }

     
    .notice {
        padding: 18px;
        line-height: 24px;
        margin-bottom: 24px;
        border-radius: 4px;
        color: var(--content-color);
        background: var(--content-background-color);
    }

    .notice p:last-child {
        margin-bottom: 0
    }

     
    .notice-title {
        margin: -18px -18px 12px;
        padding: 4px 18px;
        border-radius: 4px 4px 0 0;
        font-weight: 700;
        color: var(--title-color);
        background: var(--title-background-color);
    }

     
    .icon-notice {
        display: inline-flex;
        align-self: center;
        margin-right: 8px;
    }

    .icon-notice img,
    .icon-notice svg {
        height: 1em;
        width: 1em;
        fill: currentColor;
    }

    .icon-notice img,
    .icon-notice.baseline svg {
        top: .125em;
        position: relative;
    }
</style><div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>在 VAE 中由于卷积算子的临时内存使用会产生内存峰值，因此 VAE 比 DiT 层需要更多的内存。为了缓解这个问题，我们将卷积层的输入图像分成几个块，将单个卷积操作转换为按顺序执行的多个操作的序列。</p></div>

<h2 id="quality-results">Quality Results</h2>
<p>使用 20 步 DPM-Solver，预热步骤为 4 步。当 patch 数为 1 时，PipeFusion 的精度与 DistriFusion 相当。当 patch 数超过 1 时，其精度在理论上比 PipeFusion 更接近原始版本。PipeFusion 在 FID 方面略优于 DistriFusion.</p>
<h2 id="latency-and-memory">Latency and Memory</h2>
<p>20 步 DPM-Solver，预热步骤为 1 步。</p>
<ul>
<li>4xA100 (PCIe)集群上: 对于 8192px 的情况，在，DistriFusion 和 SQ 都会遇到内存不足 (OOM) 问题。</li>
<li>8xL20 (PCIe)集群上: 生成 4096px 分辨率的图像时，DistriFusion 和 SQ 都会遇到 OOM 问题。</li>
<li>8xA100 (NVLink) 集群上: 使用异步通信的 SQ (Ulysses) 的延迟与异步 DistriFusion 非常相似，并且优于 Ring 版本。此外，PixArt-α 在跨 8 个设备部署时面临限制，因为28个DiT层不能在均分，从而导致额外的开销。</li>
</ul>
<h3 id="4x-a100-pcie-集群">4x A100 (PCIe) 集群</h3>
<table>
  <thead>
      <tr>
          <th><strong>Latency</strong></th>
          <th><strong>PipeFusion</strong></th>
          <th><strong>Tensor Parallel</strong></th>
          <th><strong>DistriFusion</strong></th>
          <th><strong>Seq Parallel (Ulysses)</strong></th>
          <th><strong>Seq Parallel (Ring)</strong></th>
          <th>Single-GPU</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1024px</strong></td>
          <td><strong>1.00x</strong></td>
          <td>2.41x</td>
          <td>2.69x</td>
          <td>2.01x</td>
          <td>3.04x</td>
          <td>2.4x</td>
      </tr>
      <tr>
          <td><strong>2048px</strong></td>
          <td><strong>1.00x</strong></td>
          <td>3.02x</td>
          <td>1.79x</td>
          <td>1.48x</td>
          <td>2.06x</td>
          <td>3.02x</td>
      </tr>
      <tr>
          <td><strong>4096px</strong></td>
          <td>1.02x</td>
          <td>1.77x</td>
          <td>1.16x</td>
          <td><strong>1.00x</strong></td>
          <td>1.12x</td>
          <td>3.05x</td>
      </tr>
      <tr>
          <td><strong>8192px</strong></td>
          <td><strong>1.00x</strong></td>
          <td>1.10x</td>
          <td>OOM</td>
          <td>OOM</td>
          <td>OOM</td>
          <td>3.1x</td>
      </tr>
  </tbody>
</table>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB7384a580336eb8b92972343922c549b6?method=download&amp;shareKey=a203914b94020ad72b87708703fd829f" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB7384a580336eb8b92972343922c549b6?method=download&amp;shareKey=a203914b94020ad72b87708703fd829f" alt="Overall Latency on a 4×A100-80GB (PCIe)">
    </a><figcaption>Overall Latency on a 4×A100-80GB (PCIe)</figcaption></figure></p>
<p>内存效率方面，PipeFusion优于除了张量并行的其他方法。虽然张量并行的内存占用最低，但与其他并行化策略相比，由于通信量大会导致更高的延迟。</p>
<table>
  <thead>
      <tr>
          <th><strong>Max Memory</strong></th>
          <th><strong>PipeFusion (Baseline)</strong></th>
          <th><strong>Original</strong></th>
          <th><strong>Tensor Parallel</strong></th>
          <th><strong>DistriFusion</strong></th>
          <th><strong>Seq Parallel (Ulysses)</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1024px</strong></td>
          <td>1.00x</td>
          <td>1.04x</td>
          <td>0.98x</td>
          <td>1.21x</td>
          <td>1.21x</td>
      </tr>
      <tr>
          <td><strong>2048px</strong></td>
          <td>1.00x</td>
          <td>0.98x</td>
          <td>0.90x</td>
          <td>1.54x</td>
          <td>1.33x</td>
      </tr>
      <tr>
          <td><strong>4096px</strong></td>
          <td>1.00x</td>
          <td>1.18x</td>
          <td>0.69x</td>
          <td>2.35x</td>
          <td>1.63x</td>
      </tr>
      <tr>
          <td><strong>8192px</strong></td>
          <td>1.00x</td>
          <td>1.41x</td>
          <td>0.71x</td>
          <td>2.34x</td>
          <td>OOM</td>
      </tr>
  </tbody>
</table>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB27159a6d3fb6cafa4dfc7fbc5883a211?method=download&amp;shareKey=90098eb080c078296e3b0fa0fd260ee6" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB27159a6d3fb6cafa4dfc7fbc5883a211?method=download&amp;shareKey=90098eb080c078296e3b0fa0fd260ee6" alt="Overall GPU Memory on a 4×A100-80GB (PCIe)">
    </a><figcaption>Overall GPU Memory on a 4×A100-80GB (PCIe)</figcaption></figure></p>
<h3 id="8x-l20-pcie-集群">8x L20 (PCIe) 集群</h3>
<table>
  <thead>
      <tr>
          <th><strong>Latency</strong></th>
          <th><strong>PipeFusion</strong></th>
          <th><strong>Tensor Parallel</strong></th>
          <th><strong>DistriFusion</strong></th>
          <th><strong>Seq Parallel (Ulysses)</strong></th>
          <th><strong>Seq Parallel (Ring)</strong></th>
          <th>Single-GPU</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1024px</strong></td>
          <td><strong>1.00x</strong></td>
          <td>2.46x</td>
          <td>3.26x</td>
          <td>1.48x</td>
          <td>4.42x</td>
          <td>2.46x</td>
      </tr>
      <tr>
          <td><strong>2048px</strong></td>
          <td>0.99x</td>
          <td>2.26x</td>
          <td><strong>1.00x</strong></td>
          <td>1.58x</td>
          <td>1.09x</td>
          <td>4.16x</td>
      </tr>
      <tr>
          <td><strong>4096px</strong></td>
          <td><strong>1.00x</strong></td>
          <td>1.16x</td>
          <td>OOM</td>
          <td>1.31x</td>
          <td>4.40x</td>
          <td>4.30x</td>
      </tr>
  </tbody>
</table>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB883bda408bc38824e7bda7425ae4fb51?method=download&amp;shareKey=403004516bb9ff8d9271e0f8ef88a693" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB883bda408bc38824e7bda7425ae4fb51?method=download&amp;shareKey=403004516bb9ff8d9271e0f8ef88a693" alt="Overall latency on a 8×L20 (PCIe)">
    </a><figcaption>Overall latency on a 8×L20 (PCIe)</figcaption></figure></p>
<h3 id="8x-a100-nvlink-集群">8x A100 (NVLink) 集群</h3>
<table>
  <thead>
      <tr>
          <th><strong>Latency</strong></th>
          <th><strong>PipeFusion</strong></th>
          <th><strong>Tensor Parallel</strong></th>
          <th><strong>DistriFusion</strong></th>
          <th><strong>Seq Parallel (Ulysses)</strong></th>
          <th><strong>Seq Parallel (Ring)</strong></th>
          <th>Single-GPU</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1024px</strong></td>
          <td>1.26x</td>
          <td>1.59x</td>
          <td><strong>1.00x</strong></td>
          <td>1.79x</td>
          <td>3.38x</td>
          <td>2.15x</td>
      </tr>
      <tr>
          <td><strong>2048px</strong></td>
          <td>1.64x</td>
          <td>2.85x</td>
          <td><strong>1.00x</strong></td>
          <td><strong>1.00x</strong></td>
          <td>1.43x</td>
          <td>3.99x</td>
      </tr>
      <tr>
          <td><strong>4096px</strong></td>
          <td>1.08x</td>
          <td>1.56x</td>
          <td><strong>1.00x</strong></td>
          <td>1.18x</td>
          <td>1.93x</td>
          <td>7.28x</td>
      </tr>
      <tr>
          <td><strong>8192px</strong></td>
          <td>1.35x</td>
          <td><strong>1.00x</strong></td>
          <td>OOM</td>
          <td>OOM</td>
          <td>OOM</td>
          <td>5.98x</td>
      </tr>
  </tbody>
</table>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBf294c0c56206b35fb2bd495b65caa1f8?method=download&amp;shareKey=a6780d54a1429bba9fa05174f1ab44e8" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBf294c0c56206b35fb2bd495b65caa1f8?method=download&amp;shareKey=a6780d54a1429bba9fa05174f1ab44e8" alt="Overall latency on a 8×A100 (NVLink)">
    </a><figcaption>Overall latency on a 8×A100 (NVLink)</figcaption></figure></p>
<h3 id="scalability">Scalability</h3>
<p>PipeFusion 在 NVLink 和 PCIe 上的时延相似，PCIe 甚至在表现出了轻微的优势。在 PCIe 集群上，对于相同的任务，PipeFusion 总是比 DistriFusion 快。说明 PipeFusion 的通信带宽要求非常低，因此不需要使用 NVLink 等高带宽网络。</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBbd3f234475f8a4dd0831cb0de02c3023?method=download&amp;shareKey=186d86f87e9eaadc6df309ff516b2b1c" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBbd3f234475f8a4dd0831cb0de02c3023?method=download&amp;shareKey=186d86f87e9eaadc6df309ff516b2b1c" alt="Scalability of PipeFusion and DistriFusion on A100 PCIe vs. NVLink cluster">
    </a><figcaption>Scalability of PipeFusion and DistriFusion on A100 PCIe vs. NVLink cluster</figcaption></figure></p>
<h2 id="ablation-studies">Ablation Studies</h2>
<p>随着 patch 数目 M 的增加，内存消耗减少，并且对通信没有影响。但在实践中，M 不应该设置得太高。生成 1024px 和 2048px 图像时，当 M 超过一定阈值时，整体延迟增加。然而，这种现象很少出现在高分辨率图像 4K×4K 的情况下。这是因为过于细粒度的计算分区会导致 GPU 的理论吞吐量下降。</p>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEBeff3ad6b39db3ce27ce5019245deecbc?method=download&amp;shareKey=65604fe4530f3c7236a57f0497d163c4" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEBeff3ad6b39db3ce27ce5019245deecbc?method=download&amp;shareKey=65604fe4530f3c7236a57f0497d163c4" alt="Latency of PipeFusion with various patch numbers M">
    </a><figcaption>Latency of PipeFusion with various patch numbers M</figcaption></figure></p>
<p>绝大多数差异可以忽略不计或接近零，即扩散过程中连续步骤输入之间的高度相似性。</p>
<p>有一些方法可以减轻由预热步骤引起的性能损失: 增加采样步骤，在单独的设备上执行，利用序列或张量并行。</p>
<h1 id="summary">Summary</h1>
<p>我们的方法是先用 Pipeline Parallel 将模型的 transformer block 切分成多个 stage, 再用 Tensor Parallel (Megatron: 切分前一个权重的列，后一个权重的行, Two-dimenson: 切分输入的列，切分权重的行和列)，每一层的 KV 结果需要进行 all-reduce 或者 all-gather + reduce-scatter. 不同 stage 之间是 P2P 通信.</p>
<p>PipeFusion 行为更像单纯的 Pipeline Parallel，利用上一步的 KV 完成当前步的计算，P2P 通信的是自己所处 stage 的激活 (与切分的 patch 数成反比)，与 transformer block 的层数无关。</p>
<p><a href="https://darkenstar.github.io/2024/09/27/xDiT/#Construct-Parallel-Groups">xDiT的分析中</a>提到过将并行维度从小到大可以分为 TP-SP-PP-CFG-DP，其中 CFG 和 DP 实际上是对 数据的 batchsize 维度进行切分，PP 的大小取决于划分的 patch 数，每个 stage 的 transformer block 计算的时候可以进一步再进行 SP 和 TP.</p>
<h1 id="references">References</h1>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://darkenstar.github.io/blogs/MegatronLM/">https://darkenstar.github.io/blogs/MegatronLM/</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://darkenstar.github.io/blogs/ringattention/">https://darkenstar.github.io/blogs/ringattention/</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://darkenstar.github.io/blogs/deepspeedulysses/">https://darkenstar.github.io/blogs/deepspeedulysses/</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://darkenstar.github.io/blogs/distrifusion/">https://darkenstar.github.io/blogs/distrifusion/</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
  </channel>
</rss>
