<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Source Code Reading on WITHER</title>
    <link>http://localhost:57770/categories/source-code-reading/</link>
    <description>Recent content in Source Code Reading on WITHER</description>
    <generator>Hugo -- 0.147.7</generator>
    <language>en</language>
    <copyright>2024-2025 WITHER</copyright>
    <lastBuildDate>Mon, 09 Jun 2025 13:34:39 +0800</lastBuildDate>
    <atom:link href="http://localhost:57770/categories/source-code-reading/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>astra-Sim</title>
      <link>http://localhost:57770/blogs/astra-sim/</link>
      <pubDate>Mon, 09 Jun 2025 13:34:39 +0800</pubDate>
      <guid>http://localhost:57770/blogs/astra-sim/</guid>
      <description>source code reading of astra-sim</description>
      <content:encoded><![CDATA[<h1 id="build-analytical-backend">Build Analytical Backend</h1>
<p><code>build.sh</code> è„šæœ¬æ˜¯æ„å»ºè¿‡ç¨‹çš„é«˜çº§æ§åˆ¶å™¨ã€‚å…¶æ ¸å¿ƒèŒè´£æ˜¯è§£æç”¨æˆ·æ„å›¾ï¼Œæ‰§è¡Œé¢„æ„å»ºæ­¥éª¤ï¼Œå¹¶ä»¥æ­£ç¡®çš„å‚æ•°è°ƒç”¨åº•å±‚çš„ CMake å·¥å…·é“¾ã€‚</p>
<ol>
<li>
<p><strong>é€‰é¡¹è§£æ</strong>: è„šæœ¬é€šè¿‡ <code>getopts</code> å¤„ç†ä»¥ä¸‹å‘½ä»¤è¡Œæ ‡å¿—ï¼š</p>
<ul>
<li><code>-t &lt;target&gt;</code>: æŒ‡å®šç¼–è¯‘ç›®æ ‡ã€‚æœ‰æ•ˆå€¼ä¸º <code>all</code>, <code>congestion_unaware</code>, <code>congestion_aware</code>ã€‚æ­¤å€¼å°†ä½œä¸ºå˜é‡ä¼ é€’ç»™ CMakeã€‚</li>
<li><code>-l</code>: è§¦å‘æ¸…ç† (<code>cleanup</code>) æµç¨‹ï¼Œåˆ é™¤æ‰€æœ‰æ„å»ºäº§ç‰©å¹¶ç»ˆæ­¢è„šæœ¬ã€‚</li>
<li><code>-d</code>: å¯ç”¨è°ƒè¯• (<code>Debug</code>) æ¨¡å¼è¿›è¡Œç¼–è¯‘ã€‚</li>
</ul>
</li>
<li>
<p><strong>ç¯å¢ƒå‡†å¤‡ (<code>setup</code>, <code>compile_chakra_et</code>)</strong>:</p>
<ul>
<li><code>setup</code> å‡½æ•°è´Ÿè´£åˆ›å»ºç”¨äºå­˜æ”¾ä¸­é—´æ–‡ä»¶å’Œæœ€ç»ˆäº§ç‰©çš„ <code>build</code> ç›®å½•ï¼Œç¡®ä¿æºç æ ‘çš„æ¸…æ´ã€‚åŒæ—¶ï¼Œå®ƒä¼šæ ¹æ®ç³»ç»Ÿæ ¸å¿ƒæ•°è®¾ç½®ä¸€ä¸ªä¸Šé™ä¸º 16 çš„å¹¶å‘ç¼–è¯‘çº¿ç¨‹æ•°ï¼Œä»¥ä¼˜åŒ–ç¼–è¯‘æ•ˆç‡ã€‚</li>
<li><code>compile_chakra_et</code> å‡½æ•°è´Ÿè´£å¤„ç† <code>et_def.proto</code> è¿™ä¸€ Protobuf ä¾èµ–ã€‚å®ƒæ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨ï¼Œåˆ™è°ƒç”¨ <code>protoc</code> ç¼–è¯‘å™¨ç”Ÿæˆç›¸åº”çš„ C++ å’Œ Python æºç ã€‚</li>
</ul>
</li>
<li>
<p><strong>æ„å»ºæ‰§è¡Œ (<code>compile_astrasim_analytical</code>, <code>compile_astrasim_analytical_as_debug</code>)</strong>:</p>
<ul>
<li>è¿™ä¸¤ä¸ªå‡½æ•°æ˜¯è„šæœ¬ä¸ CMake äº¤äº’çš„æ ¸å¿ƒã€‚å®ƒä»¬æ ¹æ®ç”¨æˆ·æ˜¯å¦æŒ‡å®š <code>-d</code> æ ‡å¿—ï¼Œå†³å®šæ˜¯æ‰§è¡Œæ ‡å‡† <code>Release</code> æ„å»ºè¿˜æ˜¯ <code>Debug</code> æ„å»ºã€‚å…³é”®åœ¨äºå®ƒä»¬ä¼šå°†ç”¨æˆ·æŒ‡å®šçš„ <code>build_target</code> ä½œä¸º <code>-DBUILDTARGET</code> å‚æ•°ä¼ é€’ç»™ CMakeã€‚</li>
</ul>
</li>
<li>
<p><strong>åå¤„ç† (<code>create_symlink_*</code>)</strong>:</p>
<ul>
<li>ç¼–è¯‘å®Œæˆåï¼Œ<code>create_symlink_congestion_unaware</code> å’Œ <code>create_symlink_congestion_aware</code> ç­‰å‡½æ•°ä¼šä¸ºç”Ÿæˆçš„äºŒè¿›åˆ¶æ–‡ä»¶åˆ›å»ºç¬¦å·é“¾æ¥ã€‚æ­¤ä¸¾æ—¨åœ¨ç»´æŒå¯¹æ—§æ–‡ä»¶è·¯å¾„çš„å‘åå…¼å®¹æ€§ã€‚</li>
</ul>
</li>
</ol>
<hr>
<p><code>CMakeLists.txt</code> æ–‡ä»¶æ˜¯é¡¹ç›®çš„æ„å»ºè“å›¾ï¼Œå®ƒå‘ CMake é˜è¿°äº†é¡¹ç›®çš„ç»“æ„ã€ä¾èµ–å…³ç³»ä»¥åŠç¼–è¯‘è§„åˆ™ã€‚</p>
<ol>
<li>
<p><strong>ç¼–è¯‘ç¯å¢ƒè®¾å®š</strong>:</p>
<ul>
<li><code>cmake_minimum_required(VERSION 3.15)</code>: è§„å®šäº†è¿è¡Œæ­¤é…ç½®æ‰€éœ€çš„æœ€ä½ CMake ç‰ˆæœ¬ã€‚</li>
<li><code>set(CMAKE_CXX_STANDARD 17)</code> å’Œ <code>set(CMAKE_CXX_STANDARD_REQUIRED ON)</code>: å¼ºåˆ¶é¡¹ç›®å¿…é¡»åœ¨æ”¯æŒ C++17 æ ‡å‡†çš„ç¼–è¯‘ç¯å¢ƒä¸­æ„å»ºã€‚</li>
</ul>
</li>
<li>
<p><strong>ç¼–è¯‘æ ‡å¿— (Compiler Flags)</strong>:</p>
<ul>
<li>æ­¤æ–‡ä»¶ä¸ºä¸åŒçš„æ„å»ºç±»å‹ï¼ˆ<code>CMAKE_BUILD_TYPE</code>ï¼‰å®šä¹‰äº†ä¸åŒçš„ç¼–è¯‘å™¨æ ‡å¿—ã€‚</li>
<li><strong><code>Release</code></strong> (é»˜è®¤æ¨¡å¼): <code>set(CMAKE_CXX_FLAGS_RELEASE &quot;-O3&quot;)</code> æŒ‡ç¤ºç¼–è¯‘å™¨è¿›è¡Œé«˜ç­‰çº§ä¼˜åŒ–ï¼Œä»¥è¿½æ±‚æœ€å¤§åŒ–ç¨‹åºæ€§èƒ½ã€‚</li>
<li><strong><code>Debug</code></strong>: <code>set(CMAKE_CXX_FLAGS_DEBUG &quot;...&quot;)</code> åŒ…å«ä¸€ç³»åˆ—ç”¨äºè°ƒè¯•çš„æ ‡å¿—ï¼š
<ul>
<li><code>-O0</code>: å…³é—­æ‰€æœ‰ä¼˜åŒ–ï¼Œç¡®ä¿ç¼–è¯‘åçš„ä»£ç ä¸æºç è¡Œä¸ºä¸€è‡´ã€‚</li>
<li><code>-g</code>: åœ¨å¯æ‰§è¡Œæ–‡ä»¶ä¸­åŒ…å«è°ƒè¯•ç¬¦å·ï¼Œè¿™æ˜¯ GDB ç­‰è°ƒè¯•å™¨å·¥ä½œçš„å‰æã€‚</li>
<li><code>-fsanitize=address,undefined,leak</code>: å¯ç”¨ AddressSanitizerã€UndefinedBehaviorSanitizer å’Œ LeakSanitizerã€‚è¿™äº›æ˜¯å¼ºå¤§çš„è¿è¡Œæ—¶è¯Šæ–­å·¥å…·ï¼Œç”¨äºæ•è·å†…å­˜è®¿é—®é”™è¯¯ã€æœªå®šä¹‰è¡Œä¸ºåŠå†…å­˜æ³„æ¼ã€‚</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>é¡¹ç›®ç»“æ„ä¸ä¾èµ–</strong>:</p>
<ul>
<li><code>project(AstraSim_Analytical)</code>: å£°æ˜é¡¹ç›®åç§°ã€‚</li>
<li><code>add_subdirectory(...)</code>: æ­¤æŒ‡ä»¤æ˜¯ç»„ç»‡é¡¹ç›®çš„å…³é”®ã€‚å®ƒå°† <code>AstraSim</code> æ ¸å¿ƒåº“ã€<code>Analytical</code> ç½‘ç»œåç«¯å’Œ <code>AstraSim_Analytical</code> å‰ç«¯ç­‰å¤šä¸ªå­æ¨¡å—çº³å…¥æ„å»ºè¿‡ç¨‹ã€‚</li>
</ul>
</li>
<li>
<p><strong>ç”¨æˆ·è‡ªå®šä¹‰é€‰é¡¹</strong>:</p>
<ul>
<li><code>set(BUILDTARGET &quot;all&quot; CACHE STRING ...)</code>: æ­¤è¡Œå®šä¹‰äº†ä¸€ä¸ªåä¸º <code>BUILDTARGET</code> çš„å¯ç¼“å­˜å˜é‡ã€‚è¿™ä½¿å¾—ç”¨æˆ·å¯ä»¥é€šè¿‡ <code>cmake -D</code> å‘½ä»¤ä»å¤–éƒ¨æ³¨å…¥è¯¥å˜é‡çš„å€¼ã€‚æ­¤å˜é‡éšåä¼šè¢«å­ç›®å½•ä¸­çš„ <code>CMakeLists.txt</code> æ–‡ä»¶ç”¨æ¥å®ç°æ¡ä»¶ç¼–è¯‘ã€‚</li>
</ul>
</li>
</ol>
<h1 id="build-ns-3-backend">Build ns-3 Backend</h1>
<p>æ„å»ºå‘½ä»¤ä¸º <code>./build/astra_ns3/build.sh -c</code>ï¼Œä»–ä¼šæ‰§è¡Œè¯¥è„šæœ¬é‡Œçš„ compile å‡½æ•°</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="k">function</span> compile <span class="o">{</span>
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> <span class="s2">&#34;</span><span class="si">${</span><span class="nv">NS3_DIR</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">./ns3 configure --enable-mpi
</span></span><span class="line"><span class="cl">./ns3 build AstraSimNetwork -j <span class="m">12</span>
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> <span class="s2">&#34;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="p">:?</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="ns3-configure---enable-mpi"><code>./ns3 configure --enable-mpi</code></h2>
<ol>
<li>å‚æ•°è§£æ (<code>parse_args</code>): è„šæœ¬çš„ <code>argparse</code> æ¨¡å—ä¼šè¯†åˆ«å‡º <code>configure</code> å­å‘½ä»¤å’Œ <code>--enable-mpi</code> é€‰é¡¹ã€‚<code>--enable-mpi</code> æ˜¯ä¸€ä¸ªé¢„å®šä¹‰çš„&quot;On-Off&quot;é€‰é¡¹ï¼Œç”¨äºæ§åˆ¶ MPI (Message Passing Interface) åˆ†å¸ƒå¼ä»¿çœŸåŠŸèƒ½çš„æ”¯æŒã€‚</li>
<li>è¿›å…¥é…ç½®æ­¥éª¤ (<code>configuration_step</code>): ç”±äºæ£€æµ‹åˆ° configure å‘½ä»¤ï¼Œè„šæœ¬ä¼šè°ƒç”¨ <code>configuration_step</code> å‡½æ•°ã€‚</li>
<li>è°ƒç”¨ CMake (<code>configure_cmake</code>): <code>configuration_step</code> å‡½æ•°å†…éƒ¨ä¼šè°ƒç”¨ <code>configure_cmake</code>. è¿™ä¸ªå‡½æ•°æ˜¯ä¼šåŠ¨æ€åœ°æ„å»ºä¸€ä¸ª cmake å‘½ä»¤ã€‚
<ul>
<li>å®ƒä¼šæ£€æµ‹åˆ° <code>--enable-mpi</code> é€‰é¡¹ï¼Œå¹¶é€šè¿‡ <code>on_off_condition</code> å‡½æ•°å°†å…¶è½¬æ¢ä¸º CMake å˜é‡ <code>-DNS3_MPI=ON</code>.</li>
<li>æœ€ç»ˆç»„è£…å‡ºçš„å‘½ä»¤ä¸ºä¸º <code>cmake -S . -B cmake-cache -G &quot;Unix Makefiles&quot; -DCMAKE_BUILD_TYPE=default -DNS3_ASSERT=ON -DNS3_LOG=ON -DNS3_WARNINGS_AS_ERRORS=OFF -DNS3_MPI=ON --warn-uninitialized</code></li>
</ul>
</li>
<li>æ‰§è¡Œé…ç½®: è„šæœ¬é€šè¿‡ <code>subprocess.run()</code> æ‰§è¡Œè¿™æ¡ cmake å‘½ä»¤</li>
</ol>
<h2 id="ns3-build-astrasimnetwork--j-12"><code>./ns3 build AstraSimNetwork -j 12</code></h2>
<ol>
<li>å‚æ•°è§£æ (<code>parse_args</code>): è„šæœ¬è¯†åˆ«å‡º <code>build</code> å­å‘½ä»¤ï¼Œç›®æ ‡ <code>AstraSimNetwork</code>ï¼Œä»¥åŠå¹¶è¡Œä»»åŠ¡æ•° <code>-j 12</code>. å‰è€…ä¼šè¢«å­˜å…¥ <code>args.build</code> åˆ—è¡¨ï¼Œåè€…ä¼šè¢«å­˜å…¥ <code>args.jobs</code>.</li>
<li>è¿›å…¥æ„å»ºæ­¥éª¤ (<code>build_step</code>): è„šæœ¬æ£€æµ‹åˆ° <code>build</code> å‘½ä»¤ï¼Œå¹¶è°ƒç”¨ <code>build_step</code> å‡½æ•°ã€‚</li>
<li>è°ƒç”¨ CMake æ„å»º (<code>cmake_build</code>): <code>build_step</code> å‡½æ•°ä¼šéå† <code>args.build</code> åˆ—è¡¨ä¸­çš„æ‰€æœ‰ç›®æ ‡ã€‚åœ¨è¿™é‡Œï¼Œå®ƒä¼šä¸º <code>AstraSimNetwork</code> è¿™ä¸ªç›®æ ‡è°ƒç”¨ <code>cmake_build</code> å‡½æ•°ã€‚
<ul>
<li>cmake_build å‡½æ•°ä¼šç»„è£…å‡ºä¸€æ¡ <code>cmake --build</code> å‘½ä»¤ã€‚</li>
<li>å°†ç›®æ ‡ AstraSimNetwork è½¬æ¢ä¸º <code>--target AstraSimNetwork</code>.</li>
<li>å°†å¹¶è¡Œä»»åŠ¡æ•° 12 è½¬æ¢ä¸º <code>-j 12</code>.</li>
<li>æœ€ç»ˆç»„è£…å‡ºçš„å‘½ä»¤ä¸º <code>cmake --build cmake-cache --target AstraSimNetwork -j 12</code>.</li>
</ul>
</li>
</ol>
<h1 id="error-when-building-ns-3">Error When Building ns-3</h1>
<h2 id="call-of-overloaded-format-is-ambiguous-">call of overloaded â€˜format(&hellip;)â€™ is ambiguous âŒ</h2>
<h3 id="é—®é¢˜è¯Šæ–­-">é—®é¢˜è¯Šæ–­ ğŸ©º</h3>
<p>é”™è¯¯ä¿¡æ¯ <code>call of overloaded â€˜format(...)â€™ is ambiguous</code> çš„æ„æ€æ˜¯ï¼Œç¼–è¯‘å™¨åœ¨ä½ çš„ä»£ç ä¸­é‡åˆ°äº†ä¸€ä¸ªåä¸º <code>format</code> çš„å‡½æ•°è°ƒç”¨ï¼Œä½†å®ƒæ‰¾åˆ°äº†å¤šä¸ªåŒåçš„ã€å¹¶ä¸”å‚æ•°ç±»å‹éƒ½èƒ½åŒ¹é…çš„ <code>format</code> å‡½æ•°å®šä¹‰ï¼Œå¯¼è‡´ç¼–è¯‘å™¨ä¸çŸ¥é“è¯¥é€‰æ‹©å“ªä¸€ä¸ªï¼Œå› æ­¤äº§ç”Ÿäº†â€œæ­§ä¹‰â€ï¼ˆambiguousï¼‰ã€‚</p>
<p><strong>è¿™ä¸ªæ­§ä¹‰çš„æ¥æºæ˜¯ï¼š</strong></p>
<ol>
<li><strong><code>std::format</code> (æ¥è‡ª C++20 æ ‡å‡†åº“)</strong>: ä½ çš„é¡¹ç›®å¾ˆå¯èƒ½æ­£åœ¨ä½¿ç”¨æ”¯æŒ C++20 æˆ–æ›´é«˜ç‰ˆæœ¬çš„ç°ä»£ç¼–è¯‘å™¨ï¼ˆå¦‚ GCC 11+ï¼‰ã€‚C++20 æ ‡å‡†åº“å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ ¼å¼åŒ–å‡½æ•° <code>std::format</code>ã€‚</li>
<li><strong><code>fmt::format</code> (æ¥è‡ª {fmt} åº“)</strong>: <code>spdlog</code> è¿™ä¸ªæ—¥å¿—åº“æ˜¯åŸºäºä¸€ä¸ªéå¸¸æµè¡Œçš„ç¬¬ä¸‰æ–¹æ ¼å¼åŒ–åº“ <code>{fmt}</code> æ„å»ºçš„ã€‚è¿™ä¸ªåº“ä¹Ÿæä¾›äº†ä¸€ä¸ªåŠŸèƒ½å‡ ä¹å®Œå…¨ç›¸åŒçš„ <code>fmt::format</code> å‡½æ•°ã€‚åœ¨ <code>spdlog</code> çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå®ƒé€šå¸¸å¯ä»¥ç›´æ¥ä»¥ <code>format</code> çš„å½¢å¼è¢«è°ƒç”¨ã€‚</li>
</ol>
<p>å½“ä½ çš„ä»£ç ï¼ˆè¿™é‡Œæ˜¯ <code>spdlog_setup</code> çš„ä¸€éƒ¨åˆ†ï¼‰ç®€å•åœ°è°ƒç”¨ <code>format(...)</code> æ—¶ï¼Œå¦‚æœ C++20 çš„ <code>&lt;format&gt;</code> å¤´æ–‡ä»¶è¢«åŒ…å«ï¼Œç¼–è¯‘å™¨å°±ä¼šåŒæ—¶çœ‹åˆ° <code>std::format</code> å’Œ <code>spdlog</code> å†…éƒ¨çš„ <code>fmt::format</code>ã€‚ç”±äºä¸¤è€…éƒ½èƒ½å¤„ç†å­—ç¬¦ä¸²å­—é¢é‡ (<code>const char[]</code>) å’Œ <code>std::string</code>ï¼Œç¼–è¯‘å™¨æ— æ³•å†³å®šç”¨å“ªä¸ªï¼Œä»è€ŒæŠ¥é”™ã€‚</p>
<hr>
<h3 id="å…³äº-using-fmtformat-ä¸ºä½•ä»ç„¶æ— æ•ˆçš„è§£é‡Š">å…³äº <code>using fmt::format;</code> ä¸ºä½•ä»ç„¶æ— æ•ˆçš„è§£é‡Š</h3>
<p>åŸå› æ˜¯ï¼Œé™¤äº†å¸¸è§„çš„å‘½åç©ºé—´æŸ¥æ‰¾è§„åˆ™ï¼ŒC++ è¿˜æœ‰ä¸€ä¸ªæ›´å¼ºå¤§çš„è§„åˆ™å«åš<strong>å‚æ•°ä¾èµ–æŸ¥æ‰¾ï¼ˆArgument-Dependent Lookup, ADLï¼‰</strong>ï¼Œæœ‰æ—¶ä¹Ÿè¢«ç§°ä¸º Koenig æŸ¥æ‰¾ã€‚</p>
<hr>
<p>æˆ‘ä»¬æ¥æ¢³ç†ä¸€ä¸‹ç¼–è¯‘å™¨åœ¨çœ‹åˆ° <code>format(...)</code> è¿™è¡Œä»£ç æ—¶çš„â€œæ€è€ƒè¿‡ç¨‹â€ï¼š</p>
<ol>
<li>
<p><strong>åœ¨å½“å‰ä½œç”¨åŸŸæŸ¥æ‰¾</strong></p>
<p>ç¼–è¯‘å™¨çœ‹åˆ°äº†ä½ çš„ <code>using fmt::format;</code> å£°æ˜ã€‚å¾ˆå¥½ï¼Œå®ƒåœ¨å½“å‰ä½œç”¨åŸŸé‡Œæ‰¾åˆ°äº†ä¸€ä¸ªå«åš <code>format</code> çš„å‡½æ•°ï¼ˆä¹Ÿå°±æ˜¯ <code>fmt::format</code>ï¼‰ã€‚è¿™æˆä¸ºäº†<strong>å€™é€‰è€… A</strong>ã€‚</p>
</li>
<li>
<p><strong>å‚æ•°ä¾èµ–æŸ¥æ‰¾ (ADL) â€”â€” é—®é¢˜çš„æ ¹æº</strong></p>
<p>æ¥ä¸‹æ¥ï¼Œç¼–è¯‘å™¨ä¼šæ£€æŸ¥ <code>format(...)</code> å‡½æ•°çš„æ‰€æœ‰å‚æ•°ç±»å‹ã€‚åœ¨ä½ çš„é”™è¯¯æ—¥å¿—é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°äº† <code>const std::string&amp;</code> è¿™æ ·çš„å‚æ•°ã€‚</p>
<ul>
<li>ADL è§„åˆ™è§„å®šï¼šå¦‚æœä¸€ä¸ªå‡½æ•°çš„å‚æ•°æ˜¯æŸä¸ªå‘½åç©ºé—´ <code>N</code> ä¸‹çš„ç±»å‹ï¼ˆæ¯”å¦‚ <code>std::string</code> æ˜¯ <code>std</code> å‘½åç©ºé—´ä¸‹çš„ï¼‰ï¼Œé‚£ä¹ˆç¼–è¯‘å™¨<strong>ä¹Ÿå¿…é¡»</strong>å»é‚£ä¸ªå‘½åç©ºé—´ <code>N</code> (è¿™é‡Œæ˜¯ <code>std</code>) é‡Œé¢å»æŸ¥æ‰¾åŒåçš„å‡½æ•°ã€‚</li>
<li>ç”±äº <code>std::string</code> æ˜¯ <code>std</code> å‘½åç©ºé—´çš„æˆå‘˜ï¼ŒADL è§„åˆ™è¢«è§¦å‘ï¼Œç¼–è¯‘å™¨è‡ªåŠ¨åœ°å» <code>std</code> å‘½åç©ºé—´é‡Œå¯»æ‰¾åä¸º <code>format</code> çš„å‡½æ•°ã€‚</li>
<li>å› ä¸ºä½ ä½¿ç”¨äº† C++20 ç¼–è¯‘å™¨ï¼Œå®ƒåœ¨ <code>std</code> å‘½åç©ºé—´é‡ŒæˆåŠŸæ‰¾åˆ°äº† <code>std::format</code>ã€‚è¿™æˆä¸ºäº†<strong>å€™é€‰è€… B</strong>ã€‚</li>
</ul>
</li>
<li>
<p><strong>äº§ç”Ÿæ­§ä¹‰</strong></p>
<p>ç°åœ¨ç¼–è¯‘å™¨é™·å…¥äº†å›°å¢ƒã€‚å®ƒæ‰‹å¤´æœ‰ä¸¤ä¸ªåŒæ ·åŒ¹é…çš„å€™é€‰å‡½æ•°ï¼š</p>
<ul>
<li><strong>å€™é€‰è€… A</strong>: <code>fmt::format</code> (é€šè¿‡ <code>using</code> å£°æ˜æ‰¾åˆ°)</li>
<li><strong>å€™é€‰è€… B</strong>: <code>std::format</code> (é€šè¿‡ ADL åœ¨å‚æ•°çš„å‘½åç©ºé—´é‡Œæ‰¾åˆ°)</li>
</ul>
<p><code>using</code> å£°æ˜åªæ˜¯å°†ä¸€ä¸ªåå­—å¼•å…¥å½“å‰ä½œç”¨åŸŸï¼Œå®ƒå¹¶**æ²¡æœ‰è¶³å¤Ÿçš„â€œç‰¹æƒâ€**å»å‹åˆ¶ä¸€ä¸ªé€šè¿‡ ADL æ‰¾åˆ°çš„åŒæ ·ä¼˜ç§€çš„å€™é€‰è€…ã€‚å› ä¸ºä¸¤ä¸ªå‡½æ•°éƒ½èƒ½å®Œç¾å¤„ç†ä½ ä¼ å…¥çš„å‚æ•°ï¼Œç¼–è¯‘å™¨æ— æ³•åšå‡ºé€‰æ‹©ï¼Œæ‰€ä»¥å®ƒåªèƒ½æ”¾å¼ƒå¹¶æŠ¥å‘Šâ€œè°ƒç”¨æ˜¯æ¨¡ç³Šçš„ (ambiguous)â€ã€‚</p>
</li>
</ol>
<h3 id="ç»“è®ºä¸æœ€ç»ˆè§£å†³æ–¹æ¡ˆ-">ç»“è®ºä¸æœ€ç»ˆè§£å†³æ–¹æ¡ˆ âœ…</h3>
<p>è¿™ä¸ª C++ çš„ç‰¹æ€§æ„å‘³ç€ï¼Œåªè¦ä½ çš„å‡½æ•°å‚æ•°ä¸­åŒ…å«äº† <code>std</code> å‘½åç©ºé—´é‡Œçš„ç±»å‹ï¼ˆå¦‚ <code>std::string</code>, <code>std::vector</code> ç­‰ï¼‰ï¼ŒADL å°±æœ‰å¯èƒ½è¢«è§¦å‘ï¼Œä»è€ŒæŠŠ <code>std</code> é‡Œçš„å‡½æ•°ï¼ˆå¦‚ <code>std::format</code>, <code>std::to_string</code> ç­‰ï¼‰ä¹Ÿæ‹‰å…¥å€™é€‰åˆ—è¡¨ï¼Œé€ æˆæ„æƒ³ä¸åˆ°çš„å†²çªã€‚</p>
<p>å› æ­¤ï¼Œå”¯ä¸€èƒ½ 100% æ¶ˆé™¤æ­§ä¹‰ã€è®©ç¼–è¯‘å™¨åˆ«æ— é€‰æ‹©çš„æ–¹æ³•ï¼Œå°±æ˜¯ä½¿ç”¨<strong>æ˜¾å¼çš„å‘½åç©ºé—´é™å®š</strong>ï¼š</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// è¿™æ ·åšï¼Œæ˜¯åœ¨ç›´æ¥å‘Šè¯‰ç¼–è¯‘å™¨ï¼šâ€œåˆ«å»çŒœäº†ï¼Œæˆ‘å°±æ˜¯è¦è°ƒç”¨ fmt å‘½åç©ºé—´é‡Œçš„è¿™ä¸ª formatï¼â€
</span></span></span><span class="line"><span class="cl"><span class="c1">// è¿™ä¼šå®Œå…¨ç»•è¿‡ ADL å’Œå…¶ä»–æŸ¥æ‰¾è§„åˆ™ï¼Œç›´è¾¾ç›®æ ‡ã€‚
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">fmt</span><span class="o">::</span><span class="n">format</span><span class="p">(...);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="runing-arguments">Runing Arguments</h1>
<p>æ‰§è¡Œä»¿çœŸéœ€è¦ä¼ é€’ä¸€äº›å‚æ•°ï¼Œå‘½ä»¤æ¨¡æ¿å¦‚ä¸‹</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="o">{</span>ASTRA_SIM_BIN<span class="o">}</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --workload-configuration<span class="o">=</span><span class="si">${</span><span class="nv">WORKLOAD_CONFIG</span><span class="si">}</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --system-configuration<span class="o">=</span><span class="si">${</span><span class="nv">SYSTEM_CONFIG</span><span class="si">}</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --network-configuration<span class="o">=</span><span class="si">${</span><span class="nv">NETWORK_CONFIG</span><span class="si">}</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --remote-memory-configuration<span class="o">=</span><span class="si">${</span><span class="nv">REMOTE_MEMORY_CONFIG</span><span class="si">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="workload_config">WORKLOAD_CONFIG</h2>
<p>astra-sim ä½¿ç”¨çš„æ˜¯ Chakra (Execution Trace) ä½œä¸º workload å±‚çš„è¾“å…¥ã€‚å°† chakra ä½œä¸º python package å®‰è£…åæœ‰å‡ ä¸ªå‘½ä»¤é€šè¿‡ pyproject.toml å¯¹åº”åˆ° pythonå‡½æ•°ã€‚</p>
<details class="custom-details">
    <summary class="custom-summary">Explanation of toml file</summary>
    <div><p><code>pyproject.toml</code> æ˜¯ä¸€ä¸ªæ ‡å‡†åŒ–çš„é…ç½®æ–‡ä»¶ï¼Œç”¨äºå®šä¹‰ Python é¡¹ç›®çš„å…ƒæ•°æ®ã€ä¾èµ–å…³ç³»ä»¥åŠæ„å»ºå’Œå¼€å‘å·¥å…·çš„é…ç½®ã€‚</p>
<hr>
<ol>
<li><code>[build-system]</code> æ„å»ºç³»ç»Ÿé…ç½®ï¼Œè¿™éƒ¨åˆ†å®šä¹‰äº†å¦‚ä½•æ„å»ºä½ çš„ Python åŒ…ã€‚</li>
</ol>
<ul>
<li><code>**requires**</code>: åˆ—å‡ºäº†æ„å»ºé¡¹ç›®æœ¬èº«æ‰€å¿…éœ€çš„åŒ…ã€‚è¿™äº›æ˜¯æ„å»ºç¯å¢ƒçš„ä¾èµ–ï¼Œè€Œä¸æ˜¯ä½ ä»£ç è¿è¡Œæ—¶çš„ä¾èµ–ã€‚
<ul>
<li><code>setuptools</code>, <code>setuptools-grpc</code>: è¡¨æ˜æ­¤é¡¹ç›®ä½¿ç”¨ <code>setuptools</code> ä½œä¸ºå…¶æ„å»ºå·¥å…·ï¼Œå¹¶éœ€è¦ <code>setuptools-grpc</code> æ’ä»¶ã€‚</li>
</ul>
</li>
<li><code>**build-backend**</code>: æŒ‡å®šäº†æ„å»ºå·¥å…·ä¸­å®é™…æ‰§è¡Œæ„å»ºè¿‡ç¨‹çš„ Python å¯¹è±¡ï¼ˆå…¥å£ç‚¹ï¼‰ã€‚
<ul>
<li><code>setuptools.build_meta</code>: è¿™æ˜¯ <code>setuptools</code> æä¾›çš„æ ‡å‡†æ„å»ºåç«¯ã€‚</li>
</ul>
</li>
</ul>
<hr>
<ol start="2">
<li><code>[project]</code>ï¼šè¿™éƒ¨åˆ†åŒ…å«äº†é¡¹ç›®çš„åŸºæœ¬ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯ä¼šå±•ç¤ºåœ¨ PyPI (Python Package Index) ä¸Šã€‚</li>
</ol>
<ul>
<li><code>**name**</code>: åŒ…çš„åç§°ï¼Œå³ <code>pip install chakra</code> ä¸­çš„ <code>chakra</code>ã€‚</li>
<li><code>**requires-python**</code>: è¿è¡Œæ­¤åŒ…æ‰€éœ€çš„æœ€ä½ Python ç‰ˆæœ¬ï¼Œè¿™é‡Œæ˜¯ <code>3.7</code> æˆ–æ›´é«˜ã€‚</li>
<li><code>**version**</code>: å½“å‰åŒ…çš„ç‰ˆæœ¬å·ã€‚</li>
<li><code>**readme**</code>: æŒ‡å‘ä¸€ä¸ªæ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶çš„å†…å®¹å°†ä½œä¸ºé¡¹ç›®åœ¨ PyPI ä¸Šçš„è¯¦ç»†æè¿°ã€‚</li>
<li><code>**license**</code>: æŒ‡å‘åŒ…å«è®¸å¯è¯ä¿¡æ¯çš„æ–‡ä»¶ã€‚</li>
<li><code>**authors**</code>ï¼šé¡¹ç›®çš„ä½œè€…ä¿¡æ¯ã€‚</li>
<li><code>**dependencies**</code>: <strong>é¡¹ç›®è¿è¡Œæ—¶çš„ä¾èµ–é¡¹</strong>ã€‚å½“ç”¨æˆ· <code>pip install chakra</code> æ—¶ï¼Œè¿™äº›åŒ…ä¹Ÿä¼šè¢«ä¸€å¹¶å®‰è£…ã€‚
<ul>
<li><code>protobuf==5.*</code>: éœ€è¦ç‰ˆæœ¬ä¸º 5.x çš„ <code>protobuf</code> åº“ã€‚</li>
<li><code>graphviz</code>, <code>networkx</code>, <code>pydot</code>: å…¶ä»–æ ‡å‡†çš„ç¬¬ä¸‰æ–¹åº“ä¾èµ–ã€‚</li>
<li><code>HolisticTraceAnalysis @ git+...</code>: è¿™æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ä¾èµ–ã€‚å®ƒç›´æ¥ä» GitHub ä»“åº“çš„ä¸€ä¸ª<strong>ç‰¹å®š commit</strong> (<code>d731cc...</code>) æ¥å®‰è£…ã€‚è¿™ç¡®ä¿äº†é¡¹ç›®ä¾èµ–äºä¸€ä¸ªç¨³å®šä¸”ä¸ä¼šæ„å¤–å˜åŠ¨çš„ç‰ˆæœ¬ã€‚</li>
</ul>
</li>
</ul>
<hr>
<ol start="3">
<li><code>[project.urls]</code>ï¼šé¡¹ç›®ç›¸å…³é“¾æ¥ï¼Œè¿™äº›é“¾æ¥ä¼šæ˜¾ç¤ºåœ¨ PyPI é¡µé¢çš„ä¾§è¾¹æ ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯çš„å…¥å£ã€‚</li>
</ol>
<ul>
<li><code>**Homepage**</code>, <code>**Documentation**</code>, <code>**Repository**</code>: åˆ†åˆ«æŒ‡å‘é¡¹ç›®ä¸»é¡µã€æ–‡æ¡£å’Œä»£ç ä»“åº“çš„ URLã€‚</li>
</ul>
<hr>
<ol start="4">
<li><code>[tool.setuptools]</code>ï¼šè¿™éƒ¨åˆ†æ˜¯é’ˆå¯¹æ„å»ºå·¥å…· <code>setuptools</code> çš„è¯¦ç»†é…ç½®ã€‚</li>
</ol>
<ul>
<li><code>**package-dir**</code>: å®šä¹‰äº† Python åŒ…åä¸å®é™…æºä»£ç ç›®å½•ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚
<ul>
<li>ä¾‹å¦‚ï¼Œ<code>&quot;chakra.src.converter&quot; = &quot;src/converter&quot;</code> è¡¨ç¤ºå½“ç”¨æˆ· <code>import chakra.src.converter</code> æ—¶ï¼ŒPython ä¼šä» <code>src/converter/</code> ç›®å½•ä¸‹å¯»æ‰¾ä»£ç ã€‚è¿™ä½¿å¾—é¡¹ç›®å¯ä»¥ä½¿ç”¨ <code>src</code> å¸ƒå±€ã€‚</li>
</ul>
</li>
<li><code>**package-data**</code>: æŒ‡å®šéœ€è¦åŒ…å«åœ¨æœ€ç»ˆå‘å¸ƒåŒ…ä¸­çš„é Python æ–‡ä»¶ã€‚
<ul>
<li><code>&quot;chakra.schema.protobuf&quot; = [&quot;et_def.proto&quot;]</code>: è¡¨ç¤ºéœ€è¦å°† <code>et_def.proto</code> è¿™ä¸ªæ–‡ä»¶æ‰“åŒ…åˆ° <code>chakra.schema.protobuf</code> è¿™ä¸ªåŒ…é‡Œã€‚</li>
</ul>
</li>
</ul>
<hr>
<ol start="5">
<li><code>[project.scripts]</code>ï¼šè¿™éƒ¨åˆ†å®šä¹‰äº†åœ¨å®‰è£…åŒ…æ—¶åº”åˆ›å»ºçš„å‘½ä»¤è¡Œå·¥å…·ã€‚</li>
</ol>
<ul>
<li><code>**chakra_converter = &quot;chakra.src.converter.converter:main&quot;**</code>: è¿™è¡Œé…ç½®æ„å‘³ç€ï¼Œå½“ç”¨æˆ·å®‰è£…æ­¤åŒ…åï¼Œä»–ä»¬å¯ä»¥åœ¨ç»ˆç«¯ä¸­ç›´æ¥è¿è¡Œ <code>chakra_converter</code> å‘½ä»¤ã€‚æ‰§è¡Œæ­¤å‘½ä»¤æ—¶ï¼Œç³»ç»Ÿä¼šè°ƒç”¨ <code>chakra.src.converter.converter</code> æ¨¡å—ä¸­çš„ <code>main</code> å‡½æ•°ã€‚</li>
</ul>
<hr>
<ol start="6">
<li><code>[tool.ruff]</code>ï¼šè¿™éƒ¨åˆ†æ˜¯ç”¨äºé…ç½® <code>Ruff</code> é«˜æ€§èƒ½ä»£ç æ£€æŸ¥ï¼ˆLinterï¼‰å’Œæ ¼å¼åŒ–ï¼ˆFormatterï¼‰å·¥å…·ã€‚</li>
</ol>
<ul>
<li><code>**target-version**</code>, <code>**line-length**</code>, <code>**exclude**</code>: åŸºæœ¬é…ç½®ï¼Œå¦‚ç›®æ ‡ Python ç‰ˆæœ¬ã€æ¯è¡Œæœ€å¤§é•¿åº¦å’Œè¦æ’é™¤æ£€æŸ¥çš„æ–‡ä»¶ã€‚</li>
<li><code>**[tool.ruff.lint]**</code>: Linter çš„å…·ä½“é…ç½®ã€‚
<ul>
<li><code>**select**</code>: å¯ç”¨ä¸€ç³»åˆ—ä»£ç è§„åˆ™é›†ï¼ˆä¾‹å¦‚ <code>D</code> ä»£è¡¨æ–‡æ¡£å­—ç¬¦ä¸² <code>pydocstyle</code>ï¼Œ<code>I</code> ä»£è¡¨å¯¼å…¥æ’åº <code>isort</code>ï¼‰ã€‚</li>
<li><code>**ignore**</code>: å…¨å±€ç¦ç”¨çš„ç‰¹å®šè§„åˆ™ã€‚æ³¨é‡Šä¸­è§£é‡Šäº†å¿½ç•¥å®ƒä»¬çš„åŸå› ï¼ˆä¾‹å¦‚ï¼Œè§„åˆ™å†²çªæˆ–å¾…åŠäº‹é¡¹ï¼‰ã€‚</li>
<li><code>**per-file-ignores**</code>: é’ˆå¯¹ç‰¹å®šæ–‡ä»¶æˆ–ç›®å½•ç¦ç”¨è§„åˆ™ã€‚ä¾‹å¦‚ï¼Œ<code>&quot;**/tests/*&quot; = [&quot;D&quot;]</code> è¡¨ç¤ºåœ¨æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ä¸­éƒ½ç¦ç”¨æ–‡æ¡£å­—ç¬¦ä¸²æ£€æŸ¥ã€‚</li>
</ul>
</li>
<li><code>**[tool.ruff.format]**</code>: æ ¼å¼åŒ–å™¨çš„é…ç½®ï¼Œå¦‚ä½¿ç”¨ç©ºæ ¼ä½œä¸ºç¼©è¿›é£æ ¼ã€‚</li>
</ul>
<hr>
<ol start="7">
<li><code>[tool.pyright]</code>ï¼šè¿™éƒ¨åˆ†é…ç½®äº† <code>Pyright</code>ï¼Œä¸€ä¸ªç”±å¾®è½¯å¼€å‘çš„é™æ€ç±»å‹æ£€æŸ¥å·¥å…·ã€‚</li>
</ol>
<ul>
<li><code>**typeCheckingMode**</code>: ç±»å‹æ£€æŸ¥çš„ä¸¥æ ¼ç¨‹åº¦ï¼Œè¿™é‡Œæ˜¯ <code>basic</code>ï¼ˆåŸºç¡€æ¨¡å¼ï¼‰ã€‚</li>
<li><code>**exclude**</code>ï¼šåœ¨è¿›è¡Œç±»å‹æ£€æŸ¥æ—¶è¦å¿½ç•¥çš„æ–‡ä»¶å’Œç›®å½•ã€‚</li>
<li><code>**report...**</code>ï¼šå…³é—­ç‰¹å®šçš„é”™è¯¯æˆ–è­¦å‘ŠæŠ¥å‘Šã€‚</li>
</ul>
<hr>
<ol start="8">
<li><code>[tool.vulture]</code>ï¼šè¿™éƒ¨åˆ†é…ç½®äº† <code>Vulture</code>ï¼Œä¸€ä¸ªç”¨äºå‘ç°é¡¹ç›®ä¸­æœªä½¿ç”¨ï¼ˆ&ldquo;æ­»&rdquo;ï¼‰ä»£ç çš„å·¥å…·ã€‚</li>
</ol>
<ul>
<li><code>**ignore_names**</code>: è®© Vulture å¿½ç•¥æŸäº›ç‰¹å®šçš„å˜é‡åæˆ–å‡½æ•°åï¼Œå³ä½¿å®ƒä»¬çœ‹èµ·æ¥æœªä½¿ç”¨ã€‚</li>
<li><code>**min_confidence**</code>: è®¾ç½®æŠ¥å‘Šé—®é¢˜çš„æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼ã€‚<code>100</code> è¡¨ç¤ºåªæœ‰åœ¨ Vulture 100% ç¡®å®šä»£ç æ˜¯æ— ç”¨çš„æ—¶å€™æ‰ä¼šæŠ¥å‘Šï¼Œè¿™å¯ä»¥æœ‰æ•ˆå‡å°‘è¯¯æŠ¥ã€‚</li>
</ul></div>
</details><br>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-toml" data-lang="toml"><span class="line"><span class="cl"><span class="p">[</span><span class="nx">project</span><span class="p">.</span><span class="nx">scripts</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="nx">chakra_converter</span> <span class="p">=</span> <span class="s2">&#34;chakra.src.converter.converter:main&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nx">chakra_generator</span> <span class="p">=</span> <span class="s2">&#34;chakra.src.generator.generator:main&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nx">chakra_jsonizer</span> <span class="p">=</span> <span class="s2">&#34;chakra.src.jsonizer.jsonizer:main&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nx">chakra_timeline_visualizer</span> <span class="p">=</span> <span class="s2">&#34;chakra.src.timeline_visualizer.timeline_visualizer:main&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nx">chakra_trace_link</span> <span class="p">=</span> <span class="s2">&#34;chakra.src.trace_link.trace_link:main&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nx">chakra_visualizer</span> <span class="p">=</span> <span class="s2">&#34;chakra.src.visualizer.visualizer:main&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="generate-execution-trace">Generate Execution Trace</h3>
<p>ASTRA-sim çš„ ET å‘½åæ ¼å¼ä¸º <code>{path prefix/trace name}.{npu_id}.et</code>. Chakra ET çš„è·å–æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤º<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>ã€‚</p>
<ol>
<li>Collect ET from PyTorch
<ul>
<li>PyTorch ET è´Ÿè´£ CPU ç®—å­ï¼Œå¹¶æ˜ç¡®è¡¨ç¤ºå®ƒä»¬ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚</li>
<li>Kineto Trace ç¼–ç  GPU ç®—å­åŠå…¶å¼€å§‹å’Œç»“æŸæ—¶é—´ã€‚</li>
</ul>
</li>
<li>Merge Trace by <code>chkra_trace_link</code>ï¼šå°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ª PyTorch ET+. è¯¥æ ¼å¼æœ¬è´¨ä¸Šéµå¾ª PyTorch ET çš„æ¨¡å¼ï¼Œä½†åŒæ—¶ä¹Ÿç¼–ç äº† GPU æ“ä½œç¬¦åŠå…¶ä¾èµ–å…³ç³»ã€‚</li>
<li>Convert to Chakra ET by <code>chakra_converter</code>

<figure class="post-figure">
    <a href="https://private-user-images.githubusercontent.com/7621438/294028976-67228699-cec5-4a4d-b03e-e76647a80ce8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1NDQxNDUsIm5iZiI6MTc0OTU0Mzg0NSwicGF0aCI6Ii83NjIxNDM4LzI5NDAyODk3Ni02NzIyODY5OS1jZWM1LTRhNGQtYjAzZS1lNzY2NDdhODBjZTgucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDYxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA2MTBUMDgyNDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OWE4NzAyMGQ0NWQ0MDA2MzIzMmY1MmNhYWU4YWUzNTJiNjI3OTAzZDk2ZDU3NDIwMWJhZTFlMjNjZDhjN2JmMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.-DDH2mackHVASqoCbmyvN2xl8vZemaa73OiLmBER1o0" target="_blank" rel="noopener">
        <img loading="lazy" src="https://private-user-images.githubusercontent.com/7621438/294028976-67228699-cec5-4a4d-b03e-e76647a80ce8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1NDQxNDUsIm5iZiI6MTc0OTU0Mzg0NSwicGF0aCI6Ii83NjIxNDM4LzI5NDAyODk3Ni02NzIyODY5OS1jZWM1LTRhNGQtYjAzZS1lNzY2NDdhODBjZTgucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDYxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA2MTBUMDgyNDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OWE4NzAyMGQ0NWQ0MDA2MzIzMmY1MmNhYWU4YWUzNTJiNjI3OTAzZDk2ZDU3NDIwMWJhZTFlMjNjZDhjN2JmMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.-DDH2mackHVASqoCbmyvN2xl8vZemaa73OiLmBER1o0" alt="Overview of Trace Collection">
    </a><figcaption>Overview of Trace Collection</figcaption></figure></li>
</ol>
<p>å…·ä½“çš„æ•™ç¨‹å’Œä¾‹å­å¯ä»¥åœ¨ <a href="https://github.com/mlcommons/chakra/wiki/Chakra-Execution-Trace-Collection-%E2%80%90-A-Comprehensive-Guide-on-Merging-PyTorch-and-Kineto-Traces#3-from-raw-traces-to-chakra-a-step-by-step-conversion-guide">Conversion Guide</a> å’Œ <a href="https://github.com/mlcommons/chakra/wiki/Chakra-Execution-Trace-Collection-%E2%80%90-A-Comprehensive-Guide-on-Merging-PyTorch-and-Kineto-Traces#3-from-raw-traces-to-chakra-a-step-by-step-conversion-guide">Practical Example</a> æ‰¾åˆ°ã€‚</p>
<h3 id="using-et-converter">Using ET Converter</h3>
<p>å¯ä»¥å°† astra-sim 1.0 çš„æ–‡æœ¬è¾“å…¥è½¬æ¢æˆ Chakra ET.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">cd</span> ./extern/graph_frontend/chakra/
</span></span><span class="line"><span class="cl">pip3 install .
</span></span><span class="line"><span class="cl">chakra_converter Text <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --input ../../../examples/text_converter/text_workloads/Resnet50_DataParallel.txt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --output ../../../examples/text_converter/text_workloads/Resnet50_DataParallel <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --num-npus <span class="m">8</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --num-passes <span class="m">1</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>workload æ–‡æœ¬æ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼Œå…¶ä¸­é€šä¿¡å¤§å°å•ä½æ˜¯å­—èŠ‚ï¼Œè®¡ç®—æ—¶é—´ä»¥å‘¨æœŸæ•°è¡¨ç¤ºã€‚</p>
<ul>
<li>ç¬¬ä¸€è¡Œï¼š(DATA/HYBRID_TRANSFORMER/HYBRID_DLRM)
<ul>
<li>è¯¥è¡ŒæŒ‡å®šè®­ç»ƒå¾ªç¯çš„å¹¶è¡ŒåŒ–ç±»å‹ã€‚DATA è¡¨ç¤ºçº¯æ•°æ®å¹¶è¡Œæ–¹æ³•ï¼ŒHYBRID_TRANSFORMER è¡¨ç¤ºä¸“ä¸º Transformer DNN ç½‘ç»œè®¾è®¡çš„æ··åˆå¹¶è¡Œæ–¹æ³•ï¼Œè€Œ HYBRID_DLRM è¡¨ç¤ºä¸“ä¸º DLRM DNN ç½‘ç»œä¼˜åŒ–çš„æ··åˆå¹¶è¡Œæ–¹æ³•ã€‚</li>
</ul>
</li>
<li>ç¬¬äºŒè¡Œï¼š(int)
<ul>
<li>è¯¥è¡Œè¡¨ç¤º DNN çš„å±‚æ•°ã€‚</li>
</ul>
</li>
<li>åç»­è¡Œï¼šæ¯è¡Œæè¿°ä¸€å±‚ã€‚å±‚çš„æè¿°æ ¼å¼å¦‚ä¸‹ï¼š
<ul>
<li>{(string: å±‚åç§°)</li>
<li>(int: ä¿ç•™å˜é‡)</li>
<li>(int: å‰å‘è®¡ç®—æ—¶é—´)</li>
<li>(ALLREDUCE/ALLGATHER/ALLTOALL: å‰å‘é€šä¿¡ç±»å‹)</li>
<li>(int: å‰å‘é€šä¿¡å¤§å°)</li>
<li>(int: è¾“å…¥æ¢¯åº¦è®¡ç®—æ—¶é—´)</li>
<li>(ALLREDUCE/ALLGATHER/ALLTOALL: è¾“å…¥æ¢¯åº¦é€šä¿¡ç±»å‹)</li>
<li>(int: è¾“å…¥æ¢¯åº¦é€šä¿¡å¤§å°)</li>
<li>(int: æƒé‡æ¢¯åº¦è®¡ç®—æ—¶é—´)</li>
<li>(ALLREDUCE/ALLGATHER/ALLTOALL: æƒé‡æ¢¯åº¦é€šä¿¡ç±»å‹)</li>
<li>(int: æƒé‡æ¢¯åº¦é€šä¿¡å¤§å°)</li>
<li>(é›†åˆé€šä¿¡å®Œæˆåï¼Œæƒé‡/è¾“å…¥/è¾“å‡ºæ›´æ–°çš„å»¶è¿Ÿ)}`</li>
</ul>
</li>
</ul>
<style type="text/css">
     
    .notice {
        --title-color: #fff;
        --title-background-color: #6be;
        --content-color: #444;
        --content-background-color: #e7f2fa;
    }

    .notice.info {
        --title-background-color: #fb7;
        --content-background-color: #fec;
    }

    .notice.tip {
        --title-background-color: #5a5;
        --content-background-color: #efe;
    }

    .notice.warning {
        --title-background-color: #c33;
        --content-background-color: #fee;
    }

     
    @media (prefers-color-scheme:dark) {
        .notice {
            --title-color: #fff;
            --title-background-color: #069;
            --content-color: #ddd;
            --content-background-color: #023;
        }

        .notice.info {
            --title-background-color: #a50;
            --content-background-color: #420;
        }

        .notice.tip {
            --title-background-color: #363;
            --content-background-color: #121;
        }

        .notice.warning {
            --title-background-color: #800;
            --content-background-color: #400;
        }
    }

    body.dark .notice {
        --title-color: #fff;
        --title-background-color: #069;
        --content-color: #ddd;
        --content-background-color: #023;
    }

    body.dark .notice.info {
        --title-background-color: #a50;
        --content-background-color: #420;
    }

    body.dark .notice.tip {
        --title-background-color: #363;
        --content-background-color: #121;
    }

    body.dark .notice.warning {
        --title-background-color: #800;
        --content-background-color: #400;
    }

     
    .notice {
        padding: 18px;
        line-height: 24px;
        margin-bottom: 24px;
        border-radius: 4px;
        color: var(--content-color);
        background: var(--content-background-color);
    }

    .notice p:last-child {
        margin-bottom: 0
    }

     
    .notice-title {
        margin: -18px -18px 12px;
        padding: 4px 18px;
        border-radius: 4px 4px 0 0;
        font-weight: 700;
        color: var(--title-color);
        background: var(--title-background-color);
    }

     
    .icon-notice {
        display: inline-flex;
        align-self: center;
        margin-right: 8px;
    }

    .icon-notice img,
    .icon-notice svg {
        height: 1em;
        width: 1em;
        fill: currentColor;
    }

    .icon-notice img,
    .icon-notice.baseline svg {
        top: .125em;
        position: relative;
    }
</style><div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>æ¯ä¸€å±‚çš„å‚æ•°å†™è¦åœ¨åŒä¸€è¡Œï¼ï¼ï¼</p></div>

<h3 id="enable-communicator-groups">Enable Communicator Groups</h3>
<p>astra-sim 2.0 æ”¯æŒ<a href="https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/communicators.html">é€šä¿¡ç»„</a>ã€‚å¯ä»¥é€šè¿‡æŒ‡å®š <code>--comm-group-configuration</code> JSON æ–‡ä»¶æ¥æŒ‡å®šï¼Œé»˜è®¤åªæœ‰ä¸€ä¸ªé€šä¿¡ç»„ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="c1">// The first/second communicator group, with ID 0/1, includes GPU IDs from 0-3/4-7. 
</span></span></span><span class="line"><span class="cl"><span class="c1">//   &#34;0&#34;: [0, 1, 2, 3],
</span></span></span><span class="line"><span class="cl"><span class="c1">//   &#34;1&#34;: [4, 5, 6, 7]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="nt">&#34;&lt;communicator_group_id&gt;&#34;</span> <span class="p">:</span> <span class="p">[</span><span class="err">gpu_ids</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h2 id="system_config">SYSTEM_CONFIG</h2>
<h1 id="system-layer">System Layer</h1>
<p>Workload å±‚ä¼šéå† Chakra ET ä¸­çš„èŠ‚ç‚¹ï¼Œå¹¶ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ‰€æŒ‡ä»£çš„æ“ä½œå‘å‡ºç›¸åº”çš„å‘½ä»¤ã€‚System å±‚æ¥æ”¶è¿™äº›å‘½ä»¤ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºé€‚åˆç½‘ç»œã€è®¡ç®—æˆ–å†…å­˜åç«¯çš„æ ¼å¼ï¼Œä»è€Œæ­£ç¡®æ¨¡æ‹Ÿæ“ä½œã€‚æ ¹æ®æ“ä½œçš„ç±»å‹ï¼Œç³»ç»Ÿå±‚çš„è¡Œä¸ºä¼šæœ‰æ‰€ä¸åŒï¼Œå…·ä½“å¦‚ä¸‹ï¼š</p>
<ul>
<li>è®¡ç®—æ“ä½œï¼šå‘è®¡ç®—åç«¯å‘å‡ºè°ƒç”¨ï¼Œä»¥æ¨¡æ‹Ÿæ“ä½œçš„æŒç»­æ—¶é—´ã€‚</li>
<li>å†…å­˜æ“ä½œï¼š  å†…å­˜</li>
<li>é€šä¿¡æ“ä½œï¼šå°†é›†åˆé€šä¿¡åˆ†è§£ä¸ºç‚¹å¯¹ç‚¹çš„å‘é€å’Œæ¥æ”¶æ¶ˆæ¯ï¼Œå¹¶å‘ç½‘ç»œåç«¯å‘å‡ºâ€œå‘é€â€æˆ–â€œæ¥æ”¶â€è°ƒç”¨ï¼Œä»¥æ¨¡æ‹Ÿæ¶ˆæ¯çš„ä¼ è¾“è¿‡ç¨‹ã€‚</li>
</ul>
<h2 id="collective-scheduler">Collective Scheduler</h2>
<p>
<figure class="post-figure">
    <a href="https://astra-sim.github.io/astra-sim-docs/_images/system_overview_queue.svg" target="_blank" rel="noopener">
        <img loading="lazy" src="https://astra-sim.github.io/astra-sim-docs/_images/system_overview_queue.svg" alt="Collective Scheduler">
    </a><figcaption>Collective Scheduler</figcaption></figure></p>
<p>æ¯ä¸ªé˜Ÿåˆ—éƒ½æœ‰è®¸å¤š <code>StreamBaseline</code> å¯¹è±¡ (å›¾ä¸­å³ä¸Šè§’)ï¼Œä»£è¡¨äº†æ•´ä¸ªé›†åˆé€šä¿¡çš„æµç¨‹ï¼Œ<code>phase_to_go</code> æ˜¯ä¸€ä¸ªç”¨äºè¡¨ç¤ºè¿™äº›é˜¶æ®µçš„é˜Ÿåˆ—ï¼Œ<code>my_current_phase</code> æ˜¯æŒ‡å‘å½“å‰æ‰§è¡Œé˜¶æ®µçš„æŒ‡é’ˆã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">StreamBaseline</span> <span class="o">:</span> <span class="k">public</span> <span class="n">BaseStream</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">StreamBaseline</span><span class="p">(</span><span class="n">Sys</span><span class="o">*</span> <span class="n">owner</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                   <span class="n">DataSet</span><span class="o">*</span> <span class="n">dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                   <span class="kt">int</span> <span class="n">stream_id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                   <span class="n">std</span><span class="o">::</span><span class="n">list</span><span class="o">&lt;</span><span class="n">CollectivePhase</span><span class="o">&gt;</span> <span class="n">phases_to_go</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                   <span class="kt">int</span> <span class="n">priority</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// my_current_phase[CollectivePhase] is defined in BaseStream
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">init</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">call</span><span class="p">(</span><span class="n">EventType</span> <span class="n">event</span><span class="p">,</span> <span class="n">CallData</span><span class="o">*</span> <span class="n">data</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">consume</span><span class="p">(</span><span class="n">RecvPacketEventHandlerData</span><span class="o">*</span> <span class="n">message</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>å¯¹äºæ¯ä¸ª stream <code>proceed_to_next_vnet_baseline</code> (astra-sim/system/Sys.cc) ç”¨äºæ¨è¿›é€šä¿¡é˜¶æ®µå¹¶ä¸”è´Ÿè´£åœ¨é˜Ÿåˆ—ä¹‹é—´ç§»åŠ¨ stream å¯¹è±¡ã€‚ä»¥ä¸‹å‡ ç§æƒ…å†µä¼šè°ƒç”¨è¯¥å‡½æ•°ï¼š</p>
<ol>
<li>stream ç¬¬ä¸€æ¬¡è¢«ç§»åŠ¨å‡º ready_list å¹¶ä¸”å°†è¢«æ’å…¥åˆ° <code>active_streams</code>.</li>
<li>stream å®Œæˆäº†ä¸€ä¸ªé€šä¿¡é˜¶æ®µå¹¶ä¸”ç­‰å¾…ä¸‹ä¸€ä¸ªé˜¶æ®µã€‚</li>
<li>stream å®Œæˆäº†æ‰€æœ‰çš„é€šä¿¡é˜¶æ®µã€‚</li>
</ol>
<p>(2-1) åˆ° (2-5) æè¿°äº†è¯¥å‡½æ•°çš„è¡Œä¸º</p>
<ol>
<li>
<p>æŸ¥çœ‹å½“å‰æŒæœ‰ stream çš„é˜Ÿåˆ—: ä»é˜Ÿåˆ—ä¸­åˆ é™¤ <code>StreamBaseline</code> å¯¹è±¡ (æµçš„å®Œæˆé¡ºåºå¯èƒ½ä¸å®ƒä»¬å¼€å§‹æ‰§è¡Œçš„é¡ºåºä¸åŒ)ã€‚</p>
</li>
<li>
<p>ä¿®æ”¹ <code>StreamBaseline</code> å¯¹è±¡: å·²å®Œæˆçš„é›†åˆé€šä¿¡é˜¶æ®µä» <code>phases_to_go</code> ä¸­å¼¹å‡ºï¼Œ<code>my_current_phase</code> ç°åœ¨æŒ‡å‘ä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„é˜¶æ®µã€‚</p>
</li>
<li>
<p>ä½¿ç”¨ <code>insert_stream</code> å°† <code>StreamBaseline</code> å¯¹è±¡æ’å…¥åˆ°ä¸‹ä¸€ä¸ªé˜Ÿåˆ—ä¸­ã€‚</p>
</li>
<li>
<p>è°ƒç”¨å‡½æ•° <code>notify_stream_removed</code> å‡½æ•°æŸ¥çœ‹å‰ä¸€ä¸ªé˜Ÿåˆ—çš„å¤´éƒ¨ã€‚ <code>stream_pointer</code> æŒ‡å‘é˜Ÿåˆ—ä¸­ç¬¬ä¸€ä¸ªæœªè¿è¡Œçš„ stream (æ ‡è®°ä¸ºè“è‰²)ã€‚è¯¥å‡½æ•°é€šè¿‡è°ƒç”¨ <code>StreamBaseline::init()</code> æ¥å¯åŠ¨ stream çš„ä¸‹ä¸€ä¸ªé˜¶æ®µçš„æ‰§è¡Œã€‚</p>
</li>
<li>
<p>ä½¿ç”¨ <code>notify_stream_added</code> è§¦å‘æ–°é˜Ÿåˆ—å¤´éƒ¨ stream çš„é€šä¿¡é˜¶æ®µæ‰§è¡Œã€‚</p>
</li>
</ol>
<p>åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œ<code>proceed_to_next_vnet_baseline</code> ä¼šæ‰§è¡Œä¸Šè¿°æ­¥éª¤çš„ä¸€éƒ¨åˆ†ã€‚å…·ä½“å¦‚ä¸‹ï¼š</p>
<ol>
<li>
<p>åˆšä» <code>ready_list</code> ä¸­ç§»é™¤ï¼š<br>
<code>proceed_to_next..</code> ä¼šåˆå§‹åŒ– stream (1-2)ï¼Œå°†å…¶æ’å…¥åˆ°ç¬¬ä¸€ä¸ªé˜Ÿåˆ—ä¸­ (1-3)ï¼Œå¹¶è§¦å‘è¯¥é˜Ÿåˆ—å¤´éƒ¨çš„æµæ‰§è¡Œã€‚</p>
</li>
<li>
<p>stream å®Œæˆï¼š<br>
è¯¥å‡½æ•°ä¼šä»ä¹‹å‰çš„é˜Ÿåˆ—ä¸­åˆ é™¤ stream (3-1)ï¼Œå¹¶è§¦å‘ä¹‹å‰é˜Ÿåˆ—å¤´éƒ¨çš„ stream æ‰§è¡Œã€‚æ­¤å¤–ï¼Œ<code>StreamBaseline</code> å¯¹è±¡ä¼šè¢«åˆ é™¤ï¼Œå¹¶è°ƒç”¨ <code>notify_stream_finished</code>ï¼Œä»¥é€šçŸ¥ <code>Sys</code> å¯¹è±¡ stream å·²ç»ç»“æŸ (3-6)</p>
</li>
</ol>
<h2 id="collective-implementation">Collective Implementation</h2>
<p>
<figure class="post-figure">
    <a href="https://astra-sim.github.io/astra-sim-docs/_images/coll_implementation.svg" target="_blank" rel="noopener">
        <img loading="lazy" src="https://astra-sim.github.io/astra-sim-docs/_images/coll_implementation.svg" alt="Overview of Collective Implementation">
    </a><figcaption>Overview of Collective Implementation</figcaption></figure>
æ¨¡æ‹Ÿå™¨å°†é›†ä½“é€šä¿¡åˆ†è§£ä¸ºå‘é€å’Œæ¥æ”¶æ¶ˆæ¯çš„æ–¹å¼æœ‰ä¸¤ç§ã€‚ç›®å‰æœ€å¸¸ç”¨çš„æ–¹æ³•æ˜¯æ¨¡æ‹Ÿå™¨å®ç°ä¸€ç»„é¢„å®šä¹‰çš„å¸¸è§ç®—æ³• (ä¾‹å¦‚ Ringã€DoubleBinaryã€HalvingDoubling ç­‰)ã€‚è¿™ç§â€œåŸç”Ÿâ€å®ç°é€»è¾‘ä½äºæ¨¡æ‹Ÿå™¨çš„ä»£ç åº“ä¸­ï¼Œå…è®¸ç”¨æˆ·å¿«é€Ÿæ¢ç´¢ä¸€ç»„é¢„å®šä¹‰çš„ç®—æ³•ã€‚</p>
<p>è‡ª 2024 å¹´ 8 æœˆä»¥æ¥ï¼ŒASTRA-sim æ”¯æŒäº†ä¸€ç§æ–°çš„é›†åˆé€šä¿¡ç®—æ³•è¡¨ç¤ºæ–¹å¼ã€‚System å±‚é€šè¿‡æš´éœ²ä¸€ä¸ªé›†ä½“ APIï¼Œå¯ä»¥æ¥æ”¶ä»»æ„é›†ä½“ç®—æ³•çš„å®šä¹‰ã€‚</p>
<p>è¿™ä¸¤ç§æ–¹æ³•éƒ½æ˜¯å¯¹ <code>CollectivePhase::Algorithm</code> å¯¹è±¡çš„å®ç°ï¼Œè¯¥å¯¹è±¡æ˜¯ System å±‚ä¸­çš„è°ƒåº¦å•å…ƒ. <a href="https://github.com/astra-sim/astra-sim/blob/15a4334ade00fe1040fd00495cd13fd1ea5177e4/astra-sim/system/Sys.cc#L1037">generate_collective_phase</a> ä¼šæ ¹æ®ä¸åŒçš„ç®—æ³•åœ¨åˆ›å»º <a href="https://github.com/astra-sim/astra-sim/blob/15a4334ade00fe1040fd00495cd13fd1ea5177e4/astra-sim/system/CollectivePhase.hh#L17">CollectivePhase</a> çš„æ—¶å€™ä¼ å…¥å¯¹åº”çš„ Algorithm.</p>
<h3 id="astra-sim-native-implementation">ASTRA-Sim Native Implementation</h3>
<p>ç›¸å…³çš„å®ç°éƒ½ä½äº<a href="https://github.com/astra-sim/astra-sim/tree/master/astra-sim/system/collective">è¯¥æ–‡ä»¶å¤¹</a>ä¸‹, naive å®ç°çš„é™åˆ¶æ˜¯å½“éœ€è¦æ¨¡æ‹Ÿä¸€ä¸ªæ–°çš„é›†åˆé€šä¿¡ç®—æ³•æ—¶ç®—æ³•ï¼Œå¿…é¡»å®ç°æ•´ä¸ªé›†åˆï¼Ÿéšç€ä¸è§„åˆ™é›†åˆé€šä¿¡ (å¦‚ TACOS(Topology Aware CollectiveS), MSCCLang(åŸºäº DSL)) ä¸­å·¥ä½œçš„å¢åŠ ï¼Œå¿«é€Ÿæ¨¡æ‹Ÿå’Œè¿­ä»£å„ç§ç®—æ³•çš„éœ€æ±‚å˜å¾—è¶Šæ¥è¶Šå¤šã€‚</p>
<h3 id="chakra-based-arbitrary-definition-through-collective-api">Chakra Based Arbitrary Definition Through Collective API</h3>
<p>å› æ­¤ä¸€ä¸ªæ–°çš„ APæ¥æ¥å—ä»»ä½•é›†åˆé€šä¿¡ç®—æ³•çš„å®šä¹‰ï¼Œè€Œä¸å±€é™äºé¢„å®šä¹‰çš„è§„åˆ™é€šä¿¡æ¨¡å¼ã€‚å¯¹äºé€šä¿¡è¡¨ç¤ºï¼Œä½¿ç”¨ Chakra ET æ¨¡å¼ä½œä¸ºå•ç‹¬çš„å›¾ã€‚å°†é›†åˆé€šä¿¡ç®—æ³•è¡¨ç¤ºä¸ºChakra ET æ¨¡å¼ä¸­ COMM_SENDï¼ŒCOMM_RECV èŠ‚ç‚¹çš„å›¾ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒSystem å±‚ä¸æ˜¯å°†é›†åˆé€šä¿¡åˆ†è§£ä¸ºå‘é€å’Œæ¥æ”¶æ¶ˆæ¯ï¼Œè€Œæ˜¯ç®€å•åœ°éµå¾ª Chakra å›¾ä¸­å·²ç»è¡¨ç¤ºçš„åˆ†è§£ã€‚ç”±äºå·²ç»ä½¿ç”¨ Chakra ET æ¥è¡¨ç¤º workloadï¼Œä½¿ç”¨ Chakra ET æ¥é¢å¤–å®šä¹‰é›†åˆé€šä¿¡ç®—æ³•æä¾›äº†ä¸€ç§è½»æ¾ç®€å•çš„æ–¹å¼æ¥éå†æ•´ä¸ªå›¾ã€‚</p>
<p>å¦‚ä¸Šå›¾æ‰€ç¤ºå½“ workload å±‚å‘å‡º AllReduce é›†ä½“æ“ä½œæ—¶ï¼ŒSystem å±‚ä¸ä¼šè¿è¡Œæ¨¡æ‹Ÿå™¨ä»£ç åº“ä¸­å·²æœ‰çš„åŸç”Ÿå®ç°é€»è¾‘ï¼Œè€Œæ˜¯ä¼šéå†é€šè¿‡ API æä¾›çš„ Chakra ETï¼Œè¯¥ ET è¡¨ç¤ºé›†åˆé€šä¿¡ç®—æ³•ã€‚éœ€è¦æ³¨æ„ workload Chakra å›¾å’Œé›†åˆé€šä¿¡ç®—æ³•çš„ Chakra å›¾æ˜¯è§£è€¦çš„ï¼Œå¹¶é€šè¿‡ä¸åŒçš„è¾“å…¥ç‚¹æä¾›ã€‚æœ€ç»ˆï¼Œasytra-sim æ¨¡æ‹Ÿå™¨ä¼šå°†é€šä¿¡èŠ‚ç‚¹æ›¿æ¢ä¸ºé›†ä½“å®ç°ã€‚</p>
<h2 id="input-files-for-collective-api">Input Files for Collective API</h2>
<h3 id="astra-sim-native">ASTRA-sim Native</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="c1">// ...
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="s2">&#34;active-chunks-per-dimension&#34;</span><span class="err">:</span> <span class="mi">1</span><span class="err">,</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;all-reduce-implementation&#34;</span><span class="err">:</span> <span class="p">[</span><span class="s2">&#34;ring&#34;</span><span class="p">]</span><span class="err">,</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;all-gather-implementation&#34;</span><span class="err">:</span> <span class="p">[</span><span class="s2">&#34;ring&#34;</span><span class="p">,</span> <span class="s2">&#34;doubleBinaryTree&#34;</span><span class="p">]</span><span class="err">,</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;all-to-all-implementation&#34;</span><span class="err">:</span> <span class="p">[</span><span class="s2">&#34;ring&#34;</span><span class="p">,</span> <span class="s2">&#34;doubleBinaryTree&#34;</span><span class="p">,</span> <span class="s2">&#34;halvingDoubling&#34;</span><span class="p">]</span><span class="err">,</span>
</span></span><span class="line"><span class="cl"><span class="c1">// ...
</span></span></span></code></pre></div><p><code>all-*-implementation</code> æŒ‡å®šäº†æ¨¡æ‹Ÿå™¨å°†å¦‚ä½•å°†ç»™å®šçš„é›†åˆé€šä¿¡åˆ†è§£ä¸ºå‘é€å’Œæ¥æ”¶æ¶ˆæ¯ã€‚All-Gather æ“ä½œåˆ—è¡¨ä¸­çš„ä¸¤ä¸ªæ¡ç›®è¡¨ç¤ºæ¨¡æ‹Ÿå™¨å°†æŒ‰ä¸¤ä¸ªç»´åº¦åˆ†è§£ â€”â€”ç¬¬ä¸€ä¸ªç»´åº¦ä½¿ç”¨ Ring ç®—æ³•ï¼Œç¬¬äºŒä¸ªç»´åº¦ä½¿ç”¨ doubleBinaryTree ç®—æ³•ã€‚</p>
<blockquote class="quote"><p>Native Implementation Requires That the Dimensions for Collective Algorithms Are Same Across All Collectives.</p></blockquote>
<div class="notice warning" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="126 76.5 300 300">
  <path d="M297.431 324.397v-34.255c0-3.245-2.344-5.95-5.358-5.95h-32.146c-3.014 0-5.358 2.705-5.358 5.95v34.255c0 3.245 2.344 5.95 5.358 5.95h32.146c3.014 0 5.358-2.705 5.358-5.95Zm-.335-67.428 3.014-82.753c0-1.081-.502-2.524-1.674-3.425-1.005-.902-2.512-1.983-4.019-1.983h-36.834c-1.507 0-3.014 1.081-4.019 1.983-1.172.901-1.674 2.704-1.674 3.786l2.846 82.392c0 2.344 2.512 4.146 5.693 4.146h30.975c3.013 0 5.525-1.803 5.692-4.146Zm-2.344-168.39L423.34 342.425c3.683 7.032 3.516 15.686-.335 22.717-3.85 7.031-10.883 11.358-18.417 11.358H147.413c-7.534 0-14.566-4.327-18.417-11.358-3.85-7.031-4.018-15.685-.335-22.716L257.248 88.578C260.93 81.188 268.13 76.5 276 76.5c7.87 0 15.069 4.688 18.752 12.08Z"/>
</svg>

        </span>Warning</p><p><strong>Native å®ç°è¦æ±‚æ‰€æœ‰é›†ä½“æ“ä½œçš„ç»´åº¦å¿…é¡»ç›¸åŒ</strong>ã€‚æ¢å¥è¯è¯´ï¼Œå¦‚æœä¸€ä¸ªé›†åˆé€šä¿¡ç®—æ³•è¢«å®šä¹‰ä¸ºäºŒç»´çš„ï¼Œé‚£ä¹ˆå…¶ä»–é›†åˆé€šä¿¡ç®—æ³•ä¹Ÿå¿…é¡»æ˜¯äºŒç»´æ“ä½œã€‚ä¸Šè¿°åªæ˜¯ä¸€ä¸ªä¾‹å­ã€‚</p></div>

<h3 id="collective-api">Collective API</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="c1">// ...
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="s2">&#34;active-chunks-per-dimension&#34;</span><span class="err">:</span> <span class="mi">1</span><span class="err">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;all-reduce-implementation-chakra&#34;</span><span class="err">:</span> <span class="p">[</span><span class="s2">&#34;/app/hoti2024/demo5/inputs/custom_ring&#34;</span><span class="p">]</span><span class="err">,</span>
</span></span><span class="line"><span class="cl"><span class="c1">// ...
</span></span></span></code></pre></div><p>éœ€è¦æ³¨æ„è¿™é‡Œè¦ä½¿ç”¨ <code>all-*-implementation-chakra</code>ï¼Œè€Œä¸æ˜¯ <code>all-*-implementation</code>. å¦å¤–  Chakra ET æ–‡ä»¶ä¸ä¼ é€’ç»™ workload å±‚çš„æ–‡ä»¶æ˜¯ä¸åŒçš„ï¼Œæ¯ä¸€é¡¹çš„å€¼æ˜¯ Chakra ET æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œä¸åŒ…æ‹¬æœ€åçš„ <code>{rank}.et</code> å­—ç¬¦ä¸² (ç±»ä¼¼äº Workload å±‚è¾“å…¥)ã€‚æ­¤å¤–ï¼Œå³ä½¿æœ‰è®¸å¤šç»´åº¦ï¼Œåˆ—è¡¨ä¹Ÿåªæ¥å—ä¸€ä¸ªå€¼ã€‚è¿™æ˜¯å› ä¸ºè·¨ç»´åº¦é€šä¿¡çš„æ¦‚å¿µå·²ç»åŒ…å«åœ¨ ET ä¸­ã€‚</p>
<div class="github">
    <div class="github_bar">
        <svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" viewBox="0 0 50 50"><path d="M17.791,46.836C18.502,46.53,19,45.823,19,45v-5.4c0-0.197,0.016-0.402,0.041-0.61C19.027,38.994,19.014,38.997,19,39 c0,0-3,0-3.6,0c-1.5,0-2.8-0.6-3.4-1.8c-0.7-1.3-1-3.5-2.8-4.7C8.9,32.3,9.1,32,9.7,32c0.6,0.1,1.9,0.9,2.7,2c0.9,1.1,1.8,2,3.4,2 c2.487,0,3.82-0.125,4.622-0.555C21.356,34.056,22.649,33,24,33v-0.025c-5.668-0.182-9.289-2.066-10.975-4.975 c-3.665,0.042-6.856,0.405-8.677,0.707c-0.058-0.327-0.108-0.656-0.151-0.987c1.797-0.296,4.843-0.647,8.345-0.714 c-0.112-0.276-0.209-0.559-0.291-0.849c-3.511-0.178-6.541-0.039-8.187,0.097c-0.02-0.332-0.047-0.663-0.051-0.999 c1.649-0.135,4.597-0.27,8.018-0.111c-0.079-0.5-0.13-1.011-0.13-1.543c0-1.7,0.6-3.5,1.7-5c-0.5-1.7-1.2-5.3,0.2-6.6 c2.7,0,4.6,1.3,5.5,2.1C21,13.4,22.9,13,25,13s4,0.4,5.6,1.1c0.9-0.8,2.8-2.1,5.5-2.1c1.5,1.4,0.7,5,0.2,6.6c1.1,1.5,1.7,3.2,1.6,5 c0,0.484-0.045,0.951-0.11,1.409c3.499-0.172,6.527-0.034,8.204,0.102c-0.002,0.337-0.033,0.666-0.051,0.999 c-1.671-0.138-4.775-0.28-8.359-0.089c-0.089,0.336-0.197,0.663-0.325,0.98c3.546,0.046,6.665,0.389,8.548,0.689 c-0.043,0.332-0.093,0.661-0.151,0.987c-1.912-0.306-5.171-0.664-8.879-0.682C35.112,30.873,31.557,32.75,26,32.969V33 c2.6,0,5,3.9,5,6.6V45c0,0.823,0.498,1.53,1.209,1.836C41.37,43.804,48,35.164,48,25C48,12.318,37.683,2,25,2S2,12.318,2,25 C2,35.164,8.63,43.804,17.791,46.836z"></path></svg>
        <a class="github_name" href="https://github.com/astra-sim/collectiveapi" target="_blank">Collective API</a>
    </div>
    <div class="github_description">å‚è€ƒè¯¥ä»“åº“å®ç°</div>
    <div class="github_language">
        
    </div>
</div>

<h1 id="network-backend">Network Backend</h1>
<h2 id="analytical-network-backend">Analytical Network Backend</h2>
<p>Analytical Network æ¨¡æ‹Ÿå™¨é€šè¿‡æ•°å­¦æ–¹ç¨‹æ¨¡æ‹Ÿæ‰€æœ‰ç½‘ç»œè¡Œä¸ºã€‚å› æ­¤ï¼Œè¯¥åç«¯æœ€é€‚åˆäºå¤§è§„æ¨¡åˆ†å¸ƒå¼å¹³å°çš„å»ºæ¨¡å’Œä»¿çœŸã€‚ç›®å‰æ”¯æŒä¸¤ç§åˆ†ææ¨¡å¼</p>
<ul>
<li>congestion_<strong>unaware</strong> analytical network simulator</li>
<li>congestion_<strong>aware</strong> analytical network simulator</li>
</ul>
<hr>
<ul>
<li>T<strong>Topology</strong></li>
</ul>
<p>Analytical Network æ”¯æŒä¸‰ç§æ‹“æ‰‘ç»“æ„: Ring, FullConnected, Switch. å¹¶ä¸”å¯ä»¥å †å æ¥è¡¨ç¤ºå¤šç»´ç½‘ç»œã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://astra-sim.github.io/astra-network-analytical-docs/_images/network-building-blocks.svg" target="_blank" rel="noopener">
        <img loading="lazy" src="https://astra-sim.github.io/astra-network-analytical-docs/_images/network-building-blocks.svg" alt="Basic Network Building Block">
    </a><figcaption>Basic Network Building Block</figcaption></figure></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">topology</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="l">Ring, Switch ] </span><span class="w"> </span><span class="c"># 2D topology</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">topology</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="l">Ring, Ring, Ring ] </span><span class="w"> </span><span class="c"># 3D topology</span><span class="w">
</span></span></span></code></pre></div><p>
<figure class="post-figure">
    <a href="https://astra-sim.github.io/astra-network-analytical-docs/_images/multidim-network-example.svg" target="_blank" rel="noopener">
        <img loading="lazy" src="https://astra-sim.github.io/astra-network-analytical-docs/_images/multidim-network-example.svg" alt="Example of 2D &amp; 3D Topologies">
    </a><figcaption>Example of 2D &amp; 3D Topologies</figcaption></figure></p>
<hr>
<ul>
<li><strong>NPUs Count</strong></li>
</ul>
<p>æŒ‡å®šäº†æ¯ä¸ªç»´åº¦ä¸Šçš„è®¾å¤‡æ•°ç›®</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">npus_count</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="p">]</span><span class="w">  </span><span class="c"># 5 NPUs</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">npus_count</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="p">]</span><span class="w">  </span><span class="c"># 4 Ã— 2 = 8 NPUs</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">npus_count</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="p">]</span><span class="w">  </span><span class="c"># 4 Ã— 2 Ã— 2 = 16 NPUs</span><span class="w">
</span></span></span></code></pre></div><p>
<figure class="post-figure">
    <a href="https://astra-sim.github.io/astra-network-analytical-docs/_images/npus-count-example.svg" target="_blank" rel="noopener">
        <img loading="lazy" src="https://astra-sim.github.io/astra-network-analytical-docs/_images/npus-count-example.svg" alt="NPUs Count Example">
    </a><figcaption>NPUs Count Example</figcaption></figure></p>
<hr>
<ul>
<li><strong>Bandwidth</strong> &amp; <strong>Latency</strong></li>
</ul>
<p><code>latency</code> å®šä¹‰äº†æ¯æ¡å•å‘é“¾è·¯çš„å»¶è¿Ÿ (ns).
<code>bandwidth</code> å®šä¹‰äº†æ¯æ¡å•å‘é“¾è·¯çš„å¸¦å®½ (GB/s).</p>
<div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>$1 GB = 2^{30} B$ and $1 s = 10^9 ns$</p></div>

<h2 id="ns3-backend">ns3 backend</h2>
<p>ä¸‹é¢æ˜¯ç”¨ ns3 åç«¯è¿›è¡Œæ–¹é’ˆçš„ä¸€ä¸ªæ‰§è¡Œå‘½ä»¤ã€‚è¿™é‡Œä½¿ç”¨äº† <code>--network-backend</code> å’Œ <code>--logical-topology</code> è¿™ä¸¤ä¸ªå‚æ•°ã€‚éœ€è¦è¯´æ˜çš„æ˜¯ï¼ŒAnalytical Backend ä¸­ä»…ä½¿ç”¨äº†-<code>-network-backend</code> å‚æ•°ï¼Œè¿™æ˜¯å› ä¸ºåˆ†æå‹åç«¯çš„é€»è¾‘æ‹“æ‰‘ä¸ç‰©ç†æ‹“æ‰‘æ˜¯ç›¸åŒçš„ï¼Œè€Œ ns3 åˆ™å…è®¸æˆ‘ä»¬å°†é€»è¾‘æ‹“æ‰‘ä¸ç‰©ç†æ‹“æ‰‘åˆ†ç¦»ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">   <span class="c1"># {NS3_DIR} is the directory of the ns-3 backend. That is, &#39;{ASTRA_SIM_ROOT_DIRECTORY}/extern/network_backend/ns-3&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">cd</span> <span class="s2">&#34;</span><span class="si">${</span><span class="nv">NS3_DIR</span><span class="si">}</span><span class="s2">/build/scratch&#34;</span>
</span></span><span class="line"><span class="cl">    ./ns3.42-AstraSimNetwork-default <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --workload-configuration<span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="p">:?</span><span class="si">}</span><span class="s2">&#34;</span>/../../extern/graph_frontend/chakra/one_comm_coll_node_allgather  <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --system-configuration<span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="p">:?</span><span class="si">}</span><span class="s2">&#34;</span>/../../inputs/system/Switch.json  <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --network-configuration<span class="o">=</span><span class="s2">&#34;../../../ns-3/scratch/config/config.txt&#34;</span>   <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --remote-memory-configuration<span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="p">:?</span><span class="si">}</span><span class="s2">&#34;</span>/../../inputs/remote_memory/analytical/no_memory_expansion.json <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --logical-topology-configuration<span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="p">:?</span><span class="si">}</span><span class="s2">&#34;</span>/../../inputs/network/ns3/sample_8nodes_1D.json   <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --comm-group-configuration<span class="o">=</span><span class="se">\&#34;</span>empty<span class="se">\&#34;</span>
</span></span></code></pre></div><hr>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://github.com/mlcommons/chakra/wiki/Chakra-Execution-Trace-Collection-%E2%80%90-A-Comprehensive-Guide-on-Merging-PyTorch-and-Kineto-Traces#2-overview-of-trace-collection-and-simulation-methodology">Overview of Trace Collection</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>xDiT Principle</title>
      <link>http://localhost:57770/blogs/xdit/</link>
      <pubDate>Sat, 07 Jun 2025 20:44:50 +0800</pubDate>
      <guid>http://localhost:57770/blogs/xdit/</guid>
      <description>This is a brief introduction to the xDiT Principle.</description>
      <content:encoded><![CDATA[<h1 id="parse-config-arguments">Parse Config Arguments</h1>
<p>ä¼šä»å‘½ä»¤è¡Œå‚æ•°ä¸­è·å–æœ‰å…³ Model, Runtime, Parallel Processing &amp; Input æœ‰å…³çš„ä¿¡æ¯ã€‚å‰ä¸‰è€…è¢«åŒ…å«åœ¨ <code>engine_config</code> ä¸­ï¼Œè€Œæœ€åè€…åˆ™è¢«åŒ…å«åœ¨ <code>input_config</code> ä¸­ã€‚åœ¨ <code>create_config()</code> å‡½æ•°ä¸­ï¼Œä¼šåˆå§‹åŒ– <code>_WORLD</code> å…¨å±€å˜é‡ï¼Œå®ƒæ˜¯ä¸€ä¸ª <code>GroupCoordinator</code> å®ä¾‹ã€‚å¾ˆæ˜æ˜¾å®ƒåªæœ‰ä¸€ä¸ªåŒ…å«æ‰€æœ‰çš„è®¾å¤‡è¿›ç¨‹ç»„ã€‚
<details class="custom-details">
    <summary class="custom-summary">GroupCoordinator</summary>
    <div><p><code>GroupCoordinator</code> ç±»æ˜¯ä¸€ä¸ª PyTorch çš„è¿›ç¨‹ç»„å°è£…å™¨ï¼Œä¸»è¦ç”¨äºç®¡ç†ä¸€ç»„è¿›ç¨‹ä¹‹é—´çš„é€šä¿¡ã€‚å®ƒå¯ä»¥æ ¹æ®ä¸åŒçš„é€šä¿¡åç«¯ï¼ˆå¦‚ NCCLã€Glooã€MPI ç­‰ï¼‰æ¥åè°ƒè¿›ç¨‹ä¹‹é—´çš„æ“ä½œã€‚åŒ…å«ä»¥ä¸‹ä¿¡æ¯</p>
<ul>
<li><code>rank</code>: å½“å‰è¿›ç¨‹çš„å…¨å±€ç´¢å¼•ï¼ˆå…¨å±€å”¯ä¸€ï¼‰ã€‚</li>
<li><code>ranks</code>: ç»„å†…æ‰€æœ‰è¿›ç¨‹çš„å…¨å±€ç´¢å¼•åˆ—è¡¨ã€‚</li>
<li><code>world_size</code>: ç»„çš„å¤§å°ï¼Œå³è¿›ç¨‹çš„æ•°é‡ <code>len(ranks)</code></li>
<li><code>local_rank</code>: å½“å‰è¿›ç¨‹åœ¨æœ¬åœ°èŠ‚ç‚¹ä¸­çš„ç´¢å¼•ã€‚</li>
<li><code>rank_in_group</code>: å½“å‰è¿›ç¨‹åœ¨ç»„å†…çš„ç´¢å¼•ã€‚</li>
<li><code>cpu_group</code>: ç”¨äº CPU é€šä¿¡çš„è¿›ç¨‹ç»„ã€‚</li>
<li><code>device_group</code>: ç”¨äºè®¾å¤‡ï¼ˆå¦‚ GPUï¼‰é€šä¿¡çš„è¿›ç¨‹ç»„ã€‚</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">we</span> <span class="n">have</span> <span class="n">a</span> <span class="n">group</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span> <span class="n">across</span> <span class="n">two</span> <span class="n">nodes</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Process</span> <span class="o">|</span> <span class="n">Node</span> <span class="o">|</span> <span class="n">Rank</span> <span class="o">|</span> <span class="n">Local</span> <span class="n">Rank</span> <span class="o">|</span> <span class="n">Rank</span> <span class="ow">in</span> <span class="n">Group</span>
</span></span><span class="line"><span class="cl">  <span class="mi">0</span>     <span class="o">|</span>   <span class="mi">0</span>  <span class="o">|</span>  <span class="mi">0</span>   <span class="o">|</span>     <span class="mi">0</span>      <span class="o">|</span>       <span class="mi">0</span>
</span></span><span class="line"><span class="cl">  <span class="mi">1</span>     <span class="o">|</span>   <span class="mi">0</span>  <span class="o">|</span>  <span class="mi">1</span>   <span class="o">|</span>     <span class="mi">1</span>      <span class="o">|</span>       <span class="mi">1</span>
</span></span><span class="line"><span class="cl">  <span class="mi">2</span>     <span class="o">|</span>   <span class="mi">1</span>  <span class="o">|</span>  <span class="mi">2</span>   <span class="o">|</span>     <span class="mi">0</span>      <span class="o">|</span>       <span class="mi">2</span>
</span></span><span class="line"><span class="cl">  <span class="mi">3</span>     <span class="o">|</span>   <span class="mi">1</span>  <span class="o">|</span>  <span class="mi">3</span>   <span class="o">|</span>     <span class="mi">1</span>      <span class="o">|</span>       <span class="mi">3</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>__init__</code> æ–¹æ³•æ¥æ”¶ä»¥ä¸‹å‚æ•°ï¼š</p>
<ul>
<li><code>group_ranks</code>: ä¸€ä¸ªåŒ…å«å¤šä¸ªè¿›ç¨‹ç´¢å¼•åˆ—è¡¨çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­åˆ—è¡¨è¡¨ç¤ºä¸€ä¸ªè¿›ç¨‹ç»„ã€‚</li>
<li><code>local_rank</code>: å½“å‰è¿›ç¨‹çš„æœ¬åœ°ç´¢å¼•ã€‚</li>
<li><code>torch_distributed_backend</code>: æŒ‡å®šç”¨äºé€šä¿¡çš„åç«¯ç±»å‹ (å¦‚ &ldquo;gloo&rdquo; æˆ– &ldquo;nccl&rdquo;).</li>
</ul>
<p>åˆå§‹åŒ–è¿‡ç¨‹ï¼š</p>
<ol>
<li>ä½¿ç”¨ <code>torch.distributed.get_rank()</code> è·å–å½“å‰è¿›ç¨‹çš„å…¨å±€ç´¢å¼•ã€‚</li>
<li>éå†ä¼ å…¥çš„ <code>group_ranks</code> åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªå­åˆ—è¡¨åˆ›å»ºä¸€ä¸ªæ–°çš„è®¾å¤‡ç»„å’Œ CPU ç»„ã€‚</li>
<li>å¦‚æœå½“å‰è¿›ç¨‹çš„ç´¢å¼•åœ¨å½“å‰å­åˆ—è¡¨ä¸­ï¼Œåˆ™è®¾ç½®è¯¥è¿›ç¨‹çš„ç»„å†…ä¿¡æ¯ (åŒ…æ‹¬ <code>ranks</code>ã€<code>world_size</code> å’Œ <code>rank_in_group</code>).</li>
<li>ç¡®ä¿ CPU ç»„å’Œè®¾å¤‡ç»„éƒ½å·²æˆåŠŸåˆ›å»ºã€‚</li>
<li>æ ¹æ®æ˜¯å¦å¯ç”¨ CUDA è®¾ç½®å½“å‰è®¾å¤‡ä¸º GPU æˆ– CPU.</li>
</ol>
</div>
</details><br></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span> <span class="o">=</span> <span class="n">FlexibleArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&#34;xFuser Arguments&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">args</span> <span class="o">=</span> <span class="n">xFuserArgs</span><span class="o">.</span><span class="n">add_cli_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>  <span class="c1"># Add Command Line Interface (CLI) arguments</span>
</span></span><span class="line"><span class="cl">    <span class="n">engine_args</span> <span class="o">=</span> <span class="n">xFuserArgs</span><span class="o">.</span><span class="n">from_cli_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># Extract CLI args and pass them to xFuserArgs Constructor</span>
</span></span><span class="line"><span class="cl">    <span class="n">engine_config</span><span class="p">,</span> <span class="n">input_config</span> <span class="o">=</span> <span class="n">engine_args</span><span class="o">.</span><span class="n">create_config</span><span class="p">()</span>  <span class="c1"># Init _WORLD. engine_config: model, run_time &amp; parallel infos, input_config: input shape, prompt &amp; sampler infos</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_rank</span> <span class="o">=</span> <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>å…³äºå¯ä»¥æ”¯æŒçš„å¹¶è¡Œç­–ç•¥å¦‚ä¸‹ï¼ŒåŒ…æ‹¬ Data Parallel, Sequence Parallel, Pipefusion Parallel &amp; Tensor Parallel.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">Parallel Processing Options:
</span></span><span class="line"><span class="cl">  --use_cfg_parallel    Use split batch in classifier_free_guidance. cfg_degree will be <span class="m">2</span> <span class="k">if</span> <span class="nb">set</span>
</span></span><span class="line"><span class="cl">  --data_parallel_degree DATA_PARALLEL_DEGREE
</span></span><span class="line"><span class="cl">                        Data parallel degree.
</span></span><span class="line"><span class="cl">  --ulysses_degree ULYSSES_DEGREE
</span></span><span class="line"><span class="cl">                        Ulysses sequence parallel degree. Used in attention layer.
</span></span><span class="line"><span class="cl">  --ring_degree RING_DEGREE
</span></span><span class="line"><span class="cl">                        Ring sequence parallel degree. Used in attention layer.
</span></span><span class="line"><span class="cl">  --pipefusion_parallel_degree PIPEFUSION_PARALLEL_DEGREE
</span></span><span class="line"><span class="cl">                        Pipefusion parallel degree. Indicates the number of pipeline stages.
</span></span><span class="line"><span class="cl">  --num_pipeline_patch NUM_PIPELINE_PATCH
</span></span><span class="line"><span class="cl">                        Number of patches the feature map should be segmented in pipefusion parallel.
</span></span><span class="line"><span class="cl">  --attn_layer_num_for_pp <span class="o">[</span>ATTN_LAYER_NUM_FOR_PP ...<span class="o">]</span>
</span></span><span class="line"><span class="cl">                        List representing the number of layers per stage of the pipeline in pipefusion parallel
</span></span><span class="line"><span class="cl">  --tensor_parallel_degree TENSOR_PARALLEL_DEGREE
</span></span><span class="line"><span class="cl">                        Tensor parallel degree.
</span></span><span class="line"><span class="cl">  --split_scheme SPLIT_SCHEME
</span></span><span class="line"><span class="cl">                        Split scheme <span class="k">for</span> tensor parallel.
</span></span></code></pre></td></tr></table>
</div>
</div><p>ä» CLI è§£æçš„å‚æ•°åä¼šåœ¨ <code>create_config()</code> ä¸­ç»„æˆå¦‚ä¸‹çš„ <a href="https://github.com/xdit-project/xDiT/blob/6f92383e76b5f8bbaf8f45e6863d1e69b0d2f955/xfuser/config/config.py#L185">ParallelConfig</a>.</p>
<ul>
<li><code>DataParallelConfig</code>: æ€»çš„å¹¶è¡Œåº¦ä¸º <code>dp_degree * cfg_degree</code>.
<ul>
<li><code>dp_degree</code>: ç›¸å½“äºå¯¹ batch ç»´åº¦è¿›è¡Œåˆ‡åˆ†ï¼Œ</li>
<li><code>cfg_degree</code>: Class-free Guidance(cfg) ç”¨äºæ§åˆ¶æ— æ¡ä»¶çš„å›¾ç‰‡ç”Ÿæˆ (è‹¥ä½¿ç”¨ç›¸å½“äº <code>batchsize *= 2</code>).</li>
</ul>
</li>
<li><code>SequenceParallelConfig</code>: æ€»çš„å¹¶è¡Œåº¦ä¸º <code>sp_degree = ulysses_degree * ring_degree</code>
<ul>
<li><code>ulysses_degree</code>: ç”¨äºæ§åˆ¶ <a href="https://arxiv.org/abs/2309.14509">DeepSeed-Ulesses</a> çš„åºåˆ—å¹¶è¡Œåº¦ã€‚</li>
<li><code>ring_degree</code>: ç”¨äºæ§åˆ¶è®¡ç®— Ring Attention æ—¶å¯¹ Q K V æ²¿ç€ Sequence ç»´åº¦çš„åˆ‡åˆ†å—æ•°ã€‚</li>
</ul>
</li>
<li><code>TensorParallelConfig</code>: æ€»çš„å¹¶è¡Œåº¦ä¸º <code>tp_degree</code>.
<ul>
<li><code>tp_degree</code>: ç”¨äºæ§åˆ¶ <a href="https://arxiv.org/abs/2104.05343">2D Tensor Parallel</a> çš„å¹¶è¡Œåº¦ã€‚</li>
<li><code>split_scheme</code>: ç”¨äºæ§åˆ¶å¼ é‡åˆ‡åˆ†æ–¹å¼.</li>
</ul>
</li>
<li><code>PipeFusionParallelConfig</code>: æ€»çš„å¹¶è¡Œåº¦ä¸º <code>pp_degree=num_pipeline_patch</code>.
<ul>
<li><code>pp_degree</code>: ç”¨äºæ§åˆ¶ <a href="https://arxiv.org/abs/2112.11446">PipeFusion</a> ä¸­æ¨¡å‹ Transoformer Blocks çš„åˆ‡åˆ†ä¸ªæ•°ã€‚</li>
<li><code>num_pipeline_patch</code>: ç”¨äºæ§åˆ¶å¯¹ latent feature map çš„åˆ‡åˆ†å—æ•°.</li>
<li><code>attn_layer_num_for_pp</code>: æ˜¯ä¸€ä¸ª listï¼Œè¡¨ç¤º <code>pp_degree</code> é‡Œæ¯ä¸ª stage çš„ Transformer å±‚æ•°ã€‚</li>
</ul>
</li>
</ul>
<style type="text/css">
     
    .notice {
        --title-color: #fff;
        --title-background-color: #6be;
        --content-color: #444;
        --content-background-color: #e7f2fa;
    }

    .notice.info {
        --title-background-color: #fb7;
        --content-background-color: #fec;
    }

    .notice.tip {
        --title-background-color: #5a5;
        --content-background-color: #efe;
    }

    .notice.warning {
        --title-background-color: #c33;
        --content-background-color: #fee;
    }

     
    @media (prefers-color-scheme:dark) {
        .notice {
            --title-color: #fff;
            --title-background-color: #069;
            --content-color: #ddd;
            --content-background-color: #023;
        }

        .notice.info {
            --title-background-color: #a50;
            --content-background-color: #420;
        }

        .notice.tip {
            --title-background-color: #363;
            --content-background-color: #121;
        }

        .notice.warning {
            --title-background-color: #800;
            --content-background-color: #400;
        }
    }

    body.dark .notice {
        --title-color: #fff;
        --title-background-color: #069;
        --content-color: #ddd;
        --content-background-color: #023;
    }

    body.dark .notice.info {
        --title-background-color: #a50;
        --content-background-color: #420;
    }

    body.dark .notice.tip {
        --title-background-color: #363;
        --content-background-color: #121;
    }

    body.dark .notice.warning {
        --title-background-color: #800;
        --content-background-color: #400;
    }

     
    .notice {
        padding: 18px;
        line-height: 24px;
        margin-bottom: 24px;
        border-radius: 4px;
        color: var(--content-color);
        background: var(--content-background-color);
    }

    .notice p:last-child {
        margin-bottom: 0
    }

     
    .notice-title {
        margin: -18px -18px 12px;
        padding: 4px 18px;
        border-radius: 4px 4px 0 0;
        font-weight: 700;
        color: var(--title-color);
        background: var(--title-background-color);
    }

     
    .icon-notice {
        display: inline-flex;
        align-self: center;
        margin-right: 8px;
    }

    .icon-notice img,
    .icon-notice svg {
        height: 1em;
        width: 1em;
        fill: currentColor;
    }

    .icon-notice img,
    .icon-notice.baseline svg {
        top: .125em;
        position: relative;
    }
</style><div class="notice warning" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="126 76.5 300 300">
  <path d="M297.431 324.397v-34.255c0-3.245-2.344-5.95-5.358-5.95h-32.146c-3.014 0-5.358 2.705-5.358 5.95v34.255c0 3.245 2.344 5.95 5.358 5.95h32.146c3.014 0 5.358-2.705 5.358-5.95Zm-.335-67.428 3.014-82.753c0-1.081-.502-2.524-1.674-3.425-1.005-.902-2.512-1.983-4.019-1.983h-36.834c-1.507 0-3.014 1.081-4.019 1.983-1.172.901-1.674 2.704-1.674 3.786l2.846 82.392c0 2.344 2.512 4.146 5.693 4.146h30.975c3.013 0 5.525-1.803 5.692-4.146Zm-2.344-168.39L423.34 342.425c3.683 7.032 3.516 15.686-.335 22.717-3.85 7.031-10.883 11.358-18.417 11.358H147.413c-7.534 0-14.566-4.327-18.417-11.358-3.85-7.031-4.018-15.685-.335-22.716L257.248 88.578C260.93 81.188 268.13 76.5 276 76.5c7.87 0 15.069 4.688 18.752 12.08Z"/>
</svg>

        </span>Warning</p><p>å…³äº PipeFusionï¼ŒåŸæ–‡è¯´åˆ‡åˆ†çš„ patch æ•°å’Œ pipeline å¤§å°å¯ä»¥ä¸åŒï¼Œä½†è¿™é‡Œè¦æ±‚ <code>len(attn_layer_num_for_pp)=pp_degree</code></p></div>

<div class="notice info" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="92 59.5 300 300">
  <path d="M292 303.25V272c0-3.516-2.734-6.25-6.25-6.25H267v-100c0-3.516-2.734-6.25-6.25-6.25h-62.5c-3.516 0-6.25 2.734-6.25 6.25V197c0 3.516 2.734 6.25 6.25 6.25H217v62.5h-18.75c-3.516 0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h87.5c3.516 0 6.25-2.734 6.25-6.25Zm-25-175V97c0-3.516-2.734-6.25-6.25-6.25h-37.5c-3.516 0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h37.5c3.516 0 6.25-2.734 6.25-6.25Zm125 81.25c0 82.813-67.188 150-150 150-82.813 0-150-67.188-150-150 0-82.813 67.188-150 150-150 82.813 0 150 67.188 150 150Z"/>
</svg>

        </span>Info</p><p>è®¾å¤‡æ•°å¿…é¡»ç­‰äº <code>dp_degree * cfg_degree * sp_degree * tp_degree * num_pipeline_patch</code>ï¼Œå¹¶ä¸” <code>pp_degree</code> å¿…é¡»å°äºç­‰äºè®¾å¤‡æ•°ã€‚
<code>ulysses_degree</code> å¿…é¡»è¦å¤§äºä¸”èƒ½è¢« attention çš„å¤´æ•°æ•´é™¤ã€‚</p></div>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">parallel_config</span> <span class="o">=</span> <span class="n">ParallelConfig</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">dp_config</span><span class="o">=</span><span class="n">DataParallelConfig</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">dp_degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_parallel_degree</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_cfg_parallel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_cfg_parallel</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">sp_config</span><span class="o">=</span><span class="n">SequenceParallelConfig</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">ulysses_degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ulysses_degree</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">ring_degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ring_degree</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">tp_config</span><span class="o">=</span><span class="n">TensorParallelConfig</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">tp_degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_parallel_degree</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">split_scheme</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split_scheme</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">pp_config</span><span class="o">=</span><span class="n">PipeFusionParallelConfig</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">pp_degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pipefusion_parallel_degree</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_pipeline_patch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pipeline_patch</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">attn_layer_num_for_pp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_layer_num_for_pp</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="construct-pipeline">Construct Pipeline</h1>
<p>è§£æå®Œé…ç½®å‚æ•°å¹¶æ„å»ºäº† <code>engine_config</code> åï¼Œä¸‹ä¸€æ­¥æ˜¯æ„å»ºæ¨¡å‹çš„ pipeline.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="n">pipe</span> <span class="o">=</span> <span class="n">xFuserPixArtAlphaPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>  <span class="c1"># First construct a PixArtAlphaPipeline, then pass it and engine_config to xFuserPipelineBaseWrapper</span>
</span></span><span class="line"><span class="cl">        <span class="n">pretrained_model_name_or_path</span><span class="o">=</span><span class="n">engine_config</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">engine_config</span><span class="o">=</span><span class="n">engine_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;cuda:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">pipe</span><span class="o">.</span><span class="n">prepare_run</span><span class="p">(</span><span class="n">input_config</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>xFuserPixArtAlphaPipeline ç»§æ‰¿è‡ª <a href="https://github.com/xdit-project/xDiT/blob/6f92383e76b5f8bbaf8f45e6863d1e69b0d2f955/xfuser/model_executor/pipelines/base_pipeline.py#L61">xFuserPipelineBaseWrapper</a>ï¼Œ_init_runtime_state å‡½æ•°ç»è¿‡ä¸€ç•ªè°ƒç”¨åä¼šä½¿ç”¨ <a href="https://github.com/xdit-project/xDiT/blob/6f92383e76b5f8bbaf8f45e6863d1e69b0d2f955/xfuser/core/distributed/parallel_state.py#L265">initialize_model_parallel</a> åˆå§‹åŒ– <code>_RUNTIME</code> æœ‰å…³æ¨¡å‹å‚æ•°çš„éƒ¨åˆ†å’Œæ¨¡å‹å¹¶è¡Œçš„å…¨å±€å˜é‡ <code>_DP, _CFG, _PP, _SP, _TP</code>ï¼Œå®ƒæ˜¯ä¸€ä¸ª DiTRuntimeState (ç»§æ‰¿ RuntimeState) å®ä¾‹ï¼Œè®°å½•äº†æ¯ä¸ª Group åŒ…å«çš„è®¾å¤‡ç´¢å¼•ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜åŒ…æ‹¬ PipeFusionParallel ä¸­æœ‰å…³ patch ç´¢å¼•çš„å‚æ•° (åœ¨ç¨å pipeline æ‰§è¡Œçš„æ—¶å€™è®¡ç®—).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">xFuserPipelineBaseWrapper</span><span class="p">(</span><span class="n">xFuserBaseWrapper</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">pipeline</span><span class="p">:</span> <span class="n">DiffusionPipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">engine_config</span><span class="p">:</span> <span class="n">EngineConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">:</span> <span class="n">DiffusionPipeline</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_init_runtime_state</span><span class="p">(</span><span class="n">pipeline</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">engine_config</span><span class="o">=</span><span class="n">engine_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># backbone</span>
</span></span><span class="line"><span class="cl">        <span class="n">transformer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s2">&#34;transformer&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">unet</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s2">&#34;unet&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># vae</span>
</span></span><span class="line"><span class="cl">        <span class="n">vae</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s2">&#34;vae&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># scheduler</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s2">&#34;scheduler&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">transformer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">pipeline</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_transformer_backbone</span><span class="p">(</span><span class="n">transformer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">elif</span> <span class="n">unet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">pipeline</span><span class="o">.</span><span class="n">unet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_unet_backbone</span><span class="p">(</span><span class="n">unet</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">pipeline</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">pipeline</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_convert_transformer_backbone</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">transformer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">				<span class="c1">#...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;Transformer backbone found, paralleling transformer...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wrapper</span> <span class="o">=</span> <span class="o">**</span><span class="n">xFuserTransformerWrappersRegister</span><span class="o">.</span><span class="n">get_wrapper</span><span class="p">(</span><span class="n">transformer</span><span class="p">)</span><span class="o">**</span>
</span></span><span class="line"><span class="cl">            <span class="n">transformer</span> <span class="o">=</span> <span class="n">wrapper</span><span class="p">(</span><span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">transformer</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="initialize_model_parallel">initialize_model_parallel</h2>
<p>è¯¥å‡½æ•°ä¸­ä¼šåˆå§‹åŒ–ä¸€ä¸ª <code>RankGenerator</code>ï¼Œå®ƒæ¥æ”¶æ¯ä¸ªå¹¶è¡Œæ–¹æ³•çš„è®¾å¤‡ç»„å¤§å°å’Œå¹¶è¡Œåº¦å¤§å°é¡ºåºã€‚å…¶ä¸»è¦çš„æ–¹æ³•æ˜¯é€šè¿‡ <a href="https://github.com/xdit-project/xDiT/blob/6f92383e76b5f8bbaf8f45e6863d1e69b0d2f955/xfuser/core/distributed/utils.py#L4">generate_masked_orthogonal_rank_groups</a> å‡½æ•°ç¡®å®šæ¯ä¸ªå¹¶è¡Œç»„ç”±åŒ…å«å“ªäº›è®¾å¤‡ï¼Œå…ˆæŠŠå¹¶è¡Œæ–¹æ³•æŒ‰ç…§å¹¶è¡Œåº¦ä»å°åˆ°å¤§æ’åˆ—æˆ <code>tp-sp-pp-cfg-dp</code>. å†æ ¹æ®è¦ç”Ÿæˆçš„å¹¶è¡Œç»„äº§ç”Ÿå¯¹åº”çš„ <code>mask</code>. å³å¦‚æœè¦ç”Ÿæˆ <code>pp</code> ç»„å¯¹åº”çš„ rankï¼Œé‚£ä¹ˆ <code>mask = [0, 0, 1, 0, 0]</code></p>
<p>è¯¥å‡½æ•°é¦–å…ˆä¼šç”Ÿæˆéœ€è¦ç”Ÿæˆçš„å¹¶è¡Œç»„çš„å¤§å°ç»„æˆçš„ masked_shape å’Œä¸éœ€è¦ç”Ÿæˆçš„ unmasked_shape. é¦–å…ˆè¦ç”¨ prefix_product è®¡ç®— <code>global_stride</code>ï¼Œå³æ¯ä¸ªå¹¶è¡Œåº¦çš„è®¾å¤‡ç»„åŒ…å«å‡ ä¸ªè®¾å¤‡ã€‚å†æ ¹æ® <code>mask</code> å–å‡ºå¯¹åº”çš„ <code>mask_stride</code> å’Œ <code>unmaskd_stride</code>. <code>group_size = mask_stride[-1]</code> å³ä¸ºæœ€å¤§å¹¶è¡Œåº¦çš„ç»„åŒ…å«çš„è®¾å¤‡æ•°ã€‚<code>num_of_group = num_of_device / mask_stride[-1]</code> å³ä¸ºè¦ç”Ÿæˆå‡ ä¸ªå¹¶è¡Œåº¦æœ€å¤§çš„ç»„ã€‚å…ˆéå†è¦ç”Ÿæˆçš„æ¯ä¸ªè®¾å¤‡ç»„ï¼Œå¹¶ç”¨ decompose å‡½æ•°ç¡®å®šè¯¥è®¾å¤‡ç»„åœ¨ä¸éœ€è¦å¹¶è¡Œç»´åº¦ä¸Šçš„ç´¢å¼•ï¼›å†éå†è¯¥ç»„ä¸­çš„æ¯ä¸ªè®¾å¤‡çš„ lock rankï¼Œç¡®å®šè¯¥è®¾å¤‡åœ¨éœ€è¦å¹¶è¡Œç»´åº¦ä¸Šçš„ç´¢å¼•ï¼Œæœ€åç”¨ inner_product ç¡®å®šè¯¥è®¾å¤‡çš„ global rank.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate_masked_orthogonal_rank_groups</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">parallel_size</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">prefix_product</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>  <span class="c1"># Exclusive</span>
</span></span><span class="line"><span class="cl">        <span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="n">init</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">a</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">init</span> <span class="o">=</span> <span class="n">init</span> <span class="o">*</span> <span class="n">v</span>
</span></span><span class="line"><span class="cl">            <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">r</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">inner_product</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">decompose</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># index: ç¬¬å‡ ä¸ªå¹¶è¡Œç»„  # shape: å¹¶è¡Œç»„å¤§å°çš„ list</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        This function solve the math problem below:
</span></span></span><span class="line"><span class="cl"><span class="s2">            There is an equation: index = sum(idx[i] * stride[i])
</span></span></span><span class="line"><span class="cl"><span class="s2">            And given the value of index, stride.
</span></span></span><span class="line"><span class="cl"><span class="s2">            Return the idx.
</span></span></span><span class="line"><span class="cl"><span class="s2">        This function will used to get the pp/dp/pp_rank from group_index and rank_in_group.
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">stride</span> <span class="o">=</span> <span class="n">prefix_product</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">idx</span> <span class="o">=</span> <span class="p">[(</span><span class="n">index</span> <span class="o">//</span> <span class="n">d</span><span class="p">)</span> <span class="o">%</span> <span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">)]</span>  <span class="c1">#  è®¡ç®—åœ¨æ¯ä¸ªå¹¶è¡Œç»´åº¦ä¸Šçš„ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># stride is a prefix_product result. And the value of stride[-1]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># is not used.</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="nb">sum</span><span class="p">([</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">stride</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])])</span> <span class="o">==</span> <span class="n">index</span>
</span></span><span class="line"><span class="cl">        <span class="p">),</span> <span class="s2">&#34;idx </span><span class="si">{}</span><span class="s2"> with shape </span><span class="si">{}</span><span class="s2"> mismatch the return idx </span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">idx</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">masked_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parallel_size</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="k">if</span> <span class="n">m</span><span class="p">]</span>  <span class="c1"># éœ€è¦é‡‡å–å¹¶è¡Œçš„ç»´åº¦</span>
</span></span><span class="line"><span class="cl">    <span class="n">unmasked_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parallel_size</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">m</span><span class="p">]</span>  <span class="c1"># ä¸éœ€è¦çš„</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">global_stride</span> <span class="o">=</span> <span class="n">prefix_product</span><span class="p">(</span><span class="n">parallel_size</span><span class="p">)</span>  <span class="c1"># exclusive å‰ç¼€ç§¯ è¡¨ç¤ºå¤§çš„å¹¶è¡Œç»´åº¦åŒ…æ‹¬å‡ ä¸ªè®¾å¤‡</span>
</span></span><span class="line"><span class="cl">    <span class="n">masked_stride</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">global_stride</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="k">if</span> <span class="n">m</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">unmasked_stride</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">global_stride</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">m</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">group_size</span> <span class="o">=</span> <span class="n">prefix_product</span><span class="p">(</span><span class="n">masked_shape</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># æœ€å¤§çš„ä¸€ä¸ªå¹¶è¡Œç»´åº¦åŒ…æ‹¬å‡ ä¸ªè®¾å¤‡</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_of_group</span> <span class="o">=</span> <span class="n">world_size</span> <span class="o">//</span> <span class="n">group_size</span>  <span class="c1"># åˆ†æˆå‡ ä¸ªå¤§ç»„</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">ranks</span> <span class="o">=</span> <span class="p">[]</span>  
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">group_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_of_group</span><span class="p">):</span>  <span class="c1"># éå†æ¯ä¸ªè®¾å¤‡ç»„</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># get indices from unmaksed for group_index.</span>
</span></span><span class="line"><span class="cl">        <span class="n">decomposed_group_idx</span> <span class="o">=</span> <span class="n">decompose</span><span class="p">(</span><span class="n">group_index</span><span class="p">,</span> <span class="n">unmasked_shape</span><span class="p">)</span>  <span class="c1"># å¾—åˆ°åœ¨ä¸éœ€è¦é‡‡å–å¹¶è¡Œçš„ç»´åº¦ä¸Šçš„ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">rank_in_group</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">group_size</span><span class="p">):</span>  <span class="c1"># éå†è¯¥ç»„ä¸­çš„æ¯ä¸ªè®¾å¤‡ local rank</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># get indices from masked for rank_in_group.</span>
</span></span><span class="line"><span class="cl">            <span class="n">decomposed_rank_idx</span> <span class="o">=</span> <span class="n">decompose</span><span class="p">(</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="n">masked_shape</span><span class="p">)</span>  <span class="c1"># å¾—åˆ°æœ€å¤§å¹¶è¡Œç»„çš„æ¯ä¸ªè®¾å¤‡åœ¨é‡‡å–å¹¶è¡Œçš„ç»´åº¦ä¸Šçš„ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">            <span class="n">rank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>  <span class="o">//</span> <span class="n">ç›¸åŠ å¾—åˆ°å…¨å±€rank</span>
</span></span><span class="line"><span class="cl">                <span class="n">inner_product</span><span class="p">(</span><span class="n">decomposed_rank_idx</span><span class="p">,</span> <span class="n">masked_stride</span><span class="p">)</span>  
</span></span><span class="line"><span class="cl">                <span class="o">+</span> <span class="n">inner_product</span><span class="p">(</span><span class="n">decomposed_group_idx</span><span class="p">,</span> <span class="n">unmasked_stride</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ranks</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="hybrid-parallelsim-design">Hybrid Parallelsim Design</h2>
<p>xDiTæ”¯æŒå››ç§å¹¶è¡Œæ–¹å¼ï¼šPipeFusionã€Sequenceã€Data å’Œ CFG Parallelã€‚å…¶ä¸­ï¼ŒData å’Œ CFG Parallelåœ¨å›¾åƒé—´å¹¶è¡Œç›¸å¯¹ç®€å•ï¼Œè€Œ PipeFusionå’Œ Sequence åœ¨å›¾åƒå†…éƒ¨çš„ä¸åŒ Patch é—´å¹¶è¡Œåˆ™è¾ƒä¸ºå¤æ‚ã€‚èƒ½</p>
<p>PipeFusion åˆ©ç”¨ Input Tempor Redundancyç‰¹ç‚¹ï¼Œä½¿ç”¨è¿‡æ—¶çš„ KVï¼ˆStale KVï¼‰è¿›è¡Œ Attention è®¡ç®—ï¼Œè¿™ä½¿å¾— PipeFusion æ— æ³•åƒå¤§å‹è¯­è¨€æ¨¡å‹é‚£æ ·è½»æ¾åœ°å®ç°å¹¶è¡Œç­–ç•¥çš„æ··åˆã€‚ä½¿ç”¨æ ‡å‡†çš„åºåˆ—å¹¶è¡Œæ¥å£ï¼Œå¦‚RingAttentionã€Ulyssesæˆ– USPï¼Œæ— æ³•æ»¡è¶³ SP ä¸PipeFusionæ··åˆå¹¶è¡Œçš„éœ€æ±‚ã€‚</p>
<p>æˆ‘ä»¬å¯¹è¿™ä¸ªé—®é¢˜å…·ä½“è¯´æ˜ï¼Œä¸‹å›¾å±•ç¤ºäº†pipe_degree=4ï¼Œsp_degree=2çš„æ··åˆå¹¶è¡Œæ–¹æ³•ã€‚è®¾ç½® <code>num_pipeline_patch</code>=4ï¼Œå›¾ç‰‡åˆ‡åˆ†ä¸º M=<code>num_pipeline_patch*sp_degree</code>=8 ä¸ª Patchï¼Œåˆ†åˆ«æ˜¯ P0~P7.</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/xdit-project/xdit_assets/main/methods/hybrid_pp_scheme.png" alt="hybrid process group config"  width="60%">
</div>
<p>Standard SP Attention çš„è¾“å…¥Qï¼ŒKï¼ŒV å’Œè¾“å‡º O éƒ½æ˜¯æ²¿ç€åºåˆ—ç»´åº¦åˆ‡åˆ†ï¼Œä¸”åˆ‡åˆ†æ–¹å¼ä¸€è‡´ã€‚å¦‚æœä¸åŒ rank çš„è¾“å…¥ patch æ²¡æœ‰é‡å ï¼Œæ¯ä¸ª micro step è®¡ç®—å‡º fresh KV æ›´æ–°çš„ä½ç½®åœ¨ä¸åŒ rank é—´ä¹Ÿæ²¡æœ‰é‡å ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œstandard SP çš„ KV Buffer ä¸­é»„è‰²éƒ¨åˆ†æ˜¯ SP0 rank=0 æ‹¥æœ‰çš„ fresh KVï¼Œç»¿è‰²éƒ¨åˆ†æ˜¯ SP1 rank=1 æ‹¥æœ‰çš„fresh KVï¼ŒäºŒè€…å¹¶ä¸ç›¸åŒã€‚åœ¨è¿™ä¸ª diffusion step å†…ï¼Œdevice=0 æ— æ³•æ‹¿åˆ° P1,3,5,7 çš„ fresh KV è¿›è¡Œè®¡ç®—ï¼Œä½†æ˜¯ PipeFusion åˆ™éœ€è¦åœ¨ä¸‹ä¸€ä¸ª diffusion step ä¸­ï¼Œæ‹¥æœ‰ä¸Šä¸€ä¸ªdiffusion step å…¨éƒ¨çš„ KV. standard SP åªæ‹¥æœ‰ 1/sp_degree çš„ fresh kv bufferï¼Œå› æ­¤æ— æ³•è·å¾—æ··åˆå¹¶è¡Œæ¨ç†æ­£ç¡®çš„ç»“æœã€‚</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/xdit-project/xdit_assets/main/methods/hybrid_workflow.png" alt="hybrid parallel workflow">
</div>
<p>xDiTä¸“é—¨å®šåˆ¶äº†åºåˆ—å¹¶è¡Œçš„å®ç°æ–¹å¼ï¼Œä»¥é€‚åº”è¿™ç§æ··åˆå¹¶è¡Œçš„éœ€æ±‚ã€‚xDiTä½¿ç”¨ <code>xFuserLongContextAttention</code> æŠŠSPçš„ä¸­é—´ç»“æœå­˜åœ¨ KV Buffer å†…ã€‚æ•ˆæœå¦‚ä¸‹å›¾ï¼Œæ¯ä¸ª micro-step SP æ‰§è¡Œå®Œæ¯•åï¼ŒSP Group å†…ä¸åŒ rank è®¾å¤‡çš„ fresh KVæ˜¯ replicate çš„ã€‚è¿™æ ·ä¸€ä¸ª diffusion step åï¼ŒSP Group æ‰€æœ‰è®¾å¤‡çš„ KV Buffer éƒ½æ›´æ–°æˆæœ€æ–°ï¼Œä¾›ä¸‹ä¸€ä¸ª Diffusion Step ä½¿ç”¨ã€‚</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/xdit-project/xdit_assets/main/methods/kvbuffer_hybrid.png" alt="kvbuffer in hybrid parallel">
</div>
<div class="notice note" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 128 300 300">
  <path d="M150 128c82.813 0 150 67.188 150 150 0 82.813-67.188 150-150 150C67.187 428 0 360.812 0 278c0-82.813 67.188-150 150-150Zm25 243.555v-37.11c0-3.515-2.734-6.445-6.055-6.445h-37.5c-3.515 0-6.445 2.93-6.445 6.445v37.11c0 3.515 2.93 6.445 6.445 6.445h37.5c3.32 0 6.055-2.93 6.055-6.445Zm-.39-67.188 3.515-121.289c0-1.367-.586-2.734-1.953-3.516-1.172-.976-2.93-1.562-4.688-1.562h-42.968c-1.758 0-3.516.586-4.688 1.563-1.367.78-1.953 2.148-1.953 3.515l3.32 121.29c0 2.734 2.93 4.882 6.64 4.882h36.134c3.515 0 6.445-2.148 6.64-4.883Z"/>
</svg>

        </span>Note</p><p>å‡è®¾ä¸€å…±æœ‰ 16 ä¸ª GPUï¼Œç´¢å¼•è¡¨ç¤ºä¸º g0 &hellip; g15ï¼Œå¹¶è¡Œæ–¹æ³•å’Œå¹¶è¡Œåº¦è®¾ç½®å¦‚ä¸‹</p>
<p><code>dp_degree (2) * cfg_degree (2) * pp_degree (2) * sp_degree (2) = 16</code>.</p>
<p>é‚£ä¹ˆä¸€å…±ä¼šåˆ›å»º 2 data parallel-groups, 8 CFG groups, 8 pipeline-parallel groups &amp; 8 sequence-parallel groups:</p>
<ul>
<li>2 data-parallel groups:
[g0, g1, g2, g3, g4, g5, g6, g7],
[g8, g9, g10, g11, g12, g13, g14, g15]</li>
<li>8 CFG-parallel groups:
[g0, g4], [g1, g5], [g2, g6], [g3, g7],
[g8, g12], [g9, g13], [g10, g14], [g11, g15]</li>
<li>8 pipeline-parallel groups:
[g0, g2], [g4, g6], [g8, g10], [g12, g14],
[g1, g3], [g5, g7], [g9, g11], [g13, g15]</li>
<li>8 sequence-parallel groups:
[g0, g1], [g2, g3], [g4, g5], [g6, g7],
[g8, g9], [g10, g11], [g12, g13], [g14, g15]</li>
</ul></div>

<h2 id="convert-model">Convert Model</h2>
<p><a href="https://github.com/xdit-project/xDiT/blob/6f92383e76b5f8bbaf8f45e6863d1e69b0d2f955/xfuser/model_executor/models/transformers/base_transformer.py#L76">_split_transformer_blocks</a> ä¼šå¯¹ transformer block è¿›è¡Œåˆ†é…ï¼Œå¦‚æœ parallel_config æŒ‡å®šäº† attn_layer_num_for_ppï¼Œå³å­˜æœ‰æ¯ä¸ª pipeFusion çš„è®¾å¤‡è¢«åˆ†é…çš„ transformer block æ•°é‡çš„åˆ—è¡¨ï¼ŒæŒ‰å…¶è¿›è¡Œåˆ†é…ï¼›å¦åˆ™å¹³å‡åˆ†ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_split_transformer_blocks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transformer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># omit</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># transformer layer split</span>
</span></span><span class="line"><span class="cl">    <span class="n">attn_layer_num_for_pp</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># è·å–æ¯ä¸ª pipeFusion çš„è®¾å¤‡è¢«åˆ†é…çš„ transformer block æ•°é‡</span>
</span></span><span class="line"><span class="cl">        <span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">pp_config</span><span class="o">.</span><span class="n">attn_layer_num_for_pp</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">pp_rank</span> <span class="o">=</span> <span class="n">get_pipeline_parallel_rank</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">pp_world_size</span> <span class="o">=</span> <span class="n">get_pipeline_parallel_world_size</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">attn_layer_num_for_pp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">is_pipeline_first_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span><span class="p">[</span> <span class="p">:</span> <span class="n">attn_layer_num_for_pp</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span><span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">attn_layer_num_for_pp</span><span class="p">[:</span> <span class="n">pp_rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="p">:</span> 
</span></span><span class="line"><span class="cl">                                                                            <span class="nb">sum</span><span class="p">(</span><span class="n">attn_layer_num_for_pp</span><span class="p">[:</span><span class="n">pp_rank</span><span class="p">])]</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>  <span class="c1"># æ²¡æœ‰æŒ‡å®šåˆ™å¹³å‡åˆ†</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_blocks_per_stage</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span><span class="p">)</span> <span class="o">+</span> <span class="n">pp_world_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">pp_world_size</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_idx</span> <span class="o">=</span> <span class="n">pp_rank</span> <span class="o">*</span> <span class="n">num_blocks_per_stage</span>
</span></span><span class="line"><span class="cl">        <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">((</span><span class="n">pp_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_blocks_per_stage</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span><span class="p">),)</span>
</span></span><span class="line"><span class="cl">        <span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transformer_blocks</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># position embedding</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_pipeline_first_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">transformer</span><span class="o">.</span><span class="n">pos_embed</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_pipeline_last_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">transformer</span><span class="o">.</span><span class="n">norm_out</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">transformer</span><span class="o">.</span><span class="n">proj_out</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">transformer</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>åŒæ—¶ä¹Ÿä¼š convert åŸå…ˆçš„ transformer backbone ä¸º <a href="https://github.com/xdit-project/xDiT/blob/main/xfuser/model_executor/models/transformers/pixart_transformer_2d.py#L21">xFuserPixArtTransformer2DWrapper</a>ï¼Œå…·ä½“è¡¨ç°ä¸ºåªæœ‰ pipeline çš„ç¬¬ä¸€é˜¶æ®µè¿›è¡Œ position embeddingï¼Œæœ€åä¸€é˜¶æ®µè¿›è¡Œ unpatchify å˜ä¸ºåŸæ¥çš„å›¾åƒå½¢çŠ¶ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@xFuserTransformerWrappersRegister.register</span><span class="p">(</span><span class="n">PixArtTransformer2DModel</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">xFuserPixArtTransformer2DWrapper</span><span class="p">(</span><span class="n">xFuserTransformerBaseWrapper</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">transformer</span><span class="p">:</span> <span class="n">PixArtTransformer2DModel</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">submodule_classes_to_wrap</span><span class="o">=</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">,</span> <span class="n">PatchEmbed</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">submodule_name_to_wrap</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;attn1&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@xFuserBaseWrapper.forward_check_condition</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">encoder_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">added_cond_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">cross_attention_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">encoder_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>  
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">	......
</span></span></span><span class="line"><span class="cl"><span class="s1">	&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">	<span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_patch_height_width</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># * only pp rank 0 needs pos_embed (patchify)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">is_pipeline_first_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">	......
</span></span></span><span class="line"><span class="cl"><span class="s1">	&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="n">is_pipeline_last_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">	......
</span></span></span><span class="line"><span class="cl"><span class="s1">	&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">	<span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">	    <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="p">(</span><span class="n">output</span><span class="p">,)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">Transformer2DModelOutput</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="pipeline-execution">Pipeline Execution</h1>
<p>åœ¨è¿›è¡Œ warm up åä¾¿ä¼šè¿›è¡Œæ¨¡å‹æ¨ç†å’Œé‡‡æ ·å™¨çš„å»å™ªè¿‡ç¨‹ã€‚æ¨¡å‹æ¨ç†é€šè¿‡è°ƒç”¨ pipeline çš„ <code>__call__</code> æ–¹æ³•å®ç°ã€‚åœ¨åŸå…ˆ diffusers åŒ…ä¸­çš„ <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/pixart_alpha/pipeline_pixart_alpha.py">PixaeArtAlphaPipeline</a> åŸºç¡€ä¸Šåšäº†ä¸€äº›ä¿®æ”¹ã€‚æˆ‘ä»¬ç›´æ¥çœ‹ä¿®æ”¹çš„éƒ¨åˆ†ã€‚</p>
<p><code>get_runtime_state()</code> è¿”å› <code>_RUNTIME</code> ï¼Œå†è°ƒç”¨ <code>set_input_parameters</code> æ–¹æ³•ï¼Œè®¾ç½®è¾“å…¥å‚æ•°å’Œè®¡ç®— PipeFusionParallel ä¸­æœ‰å…³ patch ç´¢å¼•çš„å‚æ•°ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">set_input_parameters</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">height</span><span class="o">=</span><span class="n">height</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_inference_steps</span><span class="o">=</span><span class="n">num_inference_steps</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>è¯¥å‡½æ•°ä¼šè®¡ç®—</p>
<ul>
<li>pipeline parallel ä¸­æ¯ä¸ª patch çš„é«˜åº¦ï¼Œå¿…é¡»æ˜¯ <code>patch_size * num_sp_patches</code> çš„æ•´æ•°å€ã€‚</li>
<li>å°†æ¯ä¸ªæµæ°´çº¿é˜¶æ®µçš„ patch é«˜åº¦å‡åŒ€åœ°åˆ†é…ç»™ <code>num_sp_patches</code> ä¸ªåºåˆ—å¹¶è¡Œè®¾å¤‡ï¼Œè®¡ç®—æ¯ä¸ªè®¾å¤‡çš„ patch é«˜åº¦å’Œèµ·å§‹ç´¢å¼•ã€‚</li>
</ul>
<p>ç„¶åä¼šå¯¹ prompt åµŒå…¥åçš„æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬åœ¨ cfg parallel ç»„ä¸­çš„è®¾å¤‡è¿›è¡Œåˆ†å‰², rank 0 è´Ÿæ ·æœ¬ï¼Œrank 1 æ­£æ ·æœ¬ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="n">prompt_embeds</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">    <span class="n">prompt_attention_mask</span><span class="p">,)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_cfg_split_batch</span><span class="p">(</span><span class="n">negative_prompt_embeds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                                            <span class="n">prompt_embeds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                                            <span class="n">negative_prompt_attention_mask</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                                            <span class="n">prompt_attention_mask</span><span class="p">,)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_process_cfg_split_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">concat_group_0_negative</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">concat_group_0</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">concat_group_1_negative</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">concat_group_1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,):</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">get_classifier_free_guidance_world_size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">concat_group_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">concat_group_0_negative</span><span class="p">,</span> <span class="n">concat_group_0</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">concat_group_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">concat_group_1_negative</span><span class="p">,</span> <span class="n">concat_group_1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">elif</span> <span class="n">get_classifier_free_guidance_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">concat_group_0</span> <span class="o">=</span> <span class="n">concat_group_0_negative</span>
</span></span><span class="line"><span class="cl">      <span class="n">concat_group_1</span> <span class="o">=</span> <span class="n">concat_group_1_negative</span>
</span></span><span class="line"><span class="cl">  <span class="k">elif</span> <span class="n">get_classifier_free_guidance_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">concat_group_0</span> <span class="o">=</span> <span class="n">concat_group_0</span>
</span></span><span class="line"><span class="cl">      <span class="n">concat_group_1</span> <span class="o">=</span> <span class="n">concat_group_1</span>
</span></span><span class="line"><span class="cl">  <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;Invalid classifier free guidance rank&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">concat_group_0</span><span class="p">,</span> <span class="n">concat_group_1</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="async-pipeline">Async Pipeline</h1>
<h2 id="initialize-pipeline">Initialize Pipeline</h2>
<p>é¦–å…ˆä¼šåˆå§‹åŒ– pipelineï¼Œrank 0 ä¼šæ¥æ”¶ warmup é˜¶æ®µçš„ latents ç„¶åæ²¿ç€ H ç»´åº¦è¿›è¡Œåˆ†å—ï¼Œrank -1 ä¹Ÿä¼šæ²¿ç€ H ç»´åº¦è¿›è¡Œåˆ†å—ã€‚ç„¶åä¸ºæ¯ä¸ª patch åˆ›å»ºæ¥æ”¶çš„ä»»åŠ¡ï¼Œæ³¨æ„ rank 0 ç¬¬ä¸€æ¬¡æ˜¯ä» warmup é˜¶æ®µæ¥æ”¶ latentsï¼Œæ‰€ä»¥ä»–çš„éœ€è¦æ¥æ”¶çš„ timestep å°‘ä¸€ä¸ªã€‚
<code>patch_latents</code> è¡¨ç¤ºå½“å‰è®¾å¤‡æ­£åœ¨å¤„ç†çš„ patch æ•°æ®ï¼Œå®ƒä¼šåœ¨æµæ°´çº¿çš„æ¯ä¸€é˜¶æ®µè¿›è¡Œå¤„ç†å’Œä¼ é€’ã€‚<code>last_patch_latents</code> åªåœ¨æµæ°´çº¿çš„æœ€åé˜¶æ®µè®¾å¤‡ä¸­ä½¿ç”¨ï¼Œç”¨æ¥å­˜å‚¨æ¯ä¸ª patch çš„æœ€ç»ˆè®¡ç®—ç»“æœã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">latents</span>
</span></span><span class="line"><span class="cl"><span class="n">num_pipeline_patch</span> <span class="o">=</span> <span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">num_pipeline_patch</span>
</span></span><span class="line"><span class="cl"><span class="n">num_pipeline_warmup_steps</span> <span class="o">=</span> <span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">runtime_config</span><span class="o">.</span><span class="n">warmup_steps</span>
</span></span><span class="line"><span class="cl"><span class="n">patch_latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_async_pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_timesteps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">latents</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_pipeline_warmup_steps</span><span class="o">=</span><span class="n">num_pipeline_warmup_steps</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">last_patch_latents</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># æ¯ä¸ª pipeline group æœ€åçš„è®¾å¤‡æ¥æ”¶æ‰€æœ‰çš„ patch</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_pipeline_patch</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">is_pipeline_last_stage</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_init_async_pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_timesteps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">latents</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_pipeline_warmup_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">set_patched_mode</span><span class="p">(</span><span class="n">patch_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">is_pipeline_first_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># get latents computed in warmup stage</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ignore latents after the last timestep</span>
</span></span><span class="line"><span class="cl">        <span class="n">latents</span> <span class="o">=</span> <span class="p">(</span><span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">pipeline_recv</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                  <span class="k">if</span> <span class="n">num_pipeline_warmup_steps</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">                  <span class="k">else</span> <span class="n">latents</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">patch_latents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">latents</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">pp_patches_height</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">is_pipeline_last_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">patch_latents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">latents</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">pp_patches_height</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">patch_latents</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">num_pipeline_patch</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">recv_timesteps</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_timesteps</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">is_pipeline_first_stage</span><span class="p">()</span> <span class="k">else</span> <span class="n">num_timesteps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># construct receive tasks for each patch</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">recv_timesteps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">patch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">num_pipeline_patch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">add_pipeline_recv_task</span><span class="p">(</span><span class="n">patch_idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">patch_latents</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="iterate-over-timesteps">Iterate Over Timesteps</h1>
<p>å¯¹äºæ¯ä¸ª <code>timestep</code>ï¼ˆå³æ¯ä¸ªå»å™ªæ­¥éª¤ï¼‰ï¼Œä¼šå¯¹æ¯ä¸ª patch æ‰§è¡Œï¼š</p>
<ol>
<li>å¦‚æœå½“å‰è®¾å¤‡æ˜¯æµæ°´çº¿çš„æœ€åä¸€é˜¶æ®µ (<code>is_pipeline_last_stage()</code>)ï¼Œå°†å½“å‰ patch çš„æ•°æ®ä¿å­˜åˆ° <code>last_patch_latents</code> ä¸­ã€‚</li>
<li>å¦‚æœä¸æ˜¯ç¬¬ä¸€é˜¶æ®µçš„ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ (<code>i == 0</code>)ï¼Œè°ƒç”¨ <code>recv_next()</code> æ¥å¼‚æ­¥æ¥æ”¶æ¥è‡ªä¸Šä¸€è®¾å¤‡çš„ patch æ•°æ®ï¼ˆéé˜»å¡æ“ä½œï¼Œé€šè¿‡ <code>irecv</code> å®Œæˆï¼‰ã€‚</li>
<li>å¯¹æ¯ä¸ª patch æ‰§è¡Œæ¨¡å‹çš„å‰å‘ä¼ æ’­ <code>_backbone_forward</code>ï¼Œæ ¹æ®å½“å‰æ—¶é—´æ­¥ <code>t</code> è¿›è¡Œæ¨ç†å’Œè®¡ç®—ã€‚</li>
<li>å¦‚æœå½“å‰è®¾å¤‡æ˜¯æœ€åä¸€é˜¶æ®µï¼Œè°ƒç”¨ <code>_scheduler_step</code> æ¥æ ¹æ®å™ªå£°è¿›è¡Œå»å™ªï¼Œå¹¶å°†æ•°æ®å‘é€ç»™ä¸‹ä¸€ä¸ªè®¾å¤‡ <code>pipeline_isend</code>ã€‚</li>
<li>å¯¹äºéæœ€åé˜¶æ®µçš„è®¾å¤‡ï¼Œç»§ç»­å°†å½“å‰ patch çš„è®¡ç®—ç»“æœå‘é€åˆ°ä¸‹ä¸€è®¾å¤‡ã€‚</li>
</ol>
<p><code>get_pp_group().pipeline_isend</code> ç”¨äºå°†å½“å‰ patch å‘é€åˆ°ä¸‹ä¸€ä¸ªè®¾å¤‡ï¼Œä½¿ç”¨çš„æ˜¯ torch.distributed.isendï¼Œè¿™æ˜¯éé˜»å¡å‘é€ã€‚
<code>get_pp_group().recv_next</code> ä¼šå‡†å¤‡å¥½æ¥æ”¶æ¥è‡ªä¸Šä¸€ä¸ªè®¾å¤‡çš„æ•°æ®ï¼Œrecv_buffer ç”¨æ¥å­˜æ”¾æ¥æ”¶åˆ°çš„æ•°æ®ã€‚irecv å®ç°éé˜»å¡æ¥æ”¶ï¼Œå¯ä»¥åœ¨ç­‰å¾…æ•°æ®çš„åŒæ—¶è¿›è¡Œå…¶ä»–æ“ä½œã€‚</p>
<div class="notice warning" >
    <p class="notice-title">
        <span class="icon-notice baseline">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="126 76.5 300 300">
  <path d="M297.431 324.397v-34.255c0-3.245-2.344-5.95-5.358-5.95h-32.146c-3.014 0-5.358 2.705-5.358 5.95v34.255c0 3.245 2.344 5.95 5.358 5.95h32.146c3.014 0 5.358-2.705 5.358-5.95Zm-.335-67.428 3.014-82.753c0-1.081-.502-2.524-1.674-3.425-1.005-.902-2.512-1.983-4.019-1.983h-36.834c-1.507 0-3.014 1.081-4.019 1.983-1.172.901-1.674 2.704-1.674 3.786l2.846 82.392c0 2.344 2.512 4.146 5.693 4.146h30.975c3.013 0 5.525-1.803 5.692-4.146Zm-2.344-168.39L423.34 342.425c3.683 7.032 3.516 15.686-.335 22.717-3.85 7.031-10.883 11.358-18.417 11.358H147.413c-7.534 0-14.566-4.327-18.417-11.358-3.85-7.031-4.018-15.685-.335-22.716L257.248 88.578C260.93 81.188 268.13 76.5 276 76.5c7.87 0 15.069 4.688 18.752 12.08Z"/>
</svg>

        </span>Warning</p><p>scheduler_step åªå¯¹å•ç‹¬çš„ patch è¿›è¡Œï¼ŒåŸå› æœªçŸ¥ã€‚</p></div>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">first_async_recv</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">patch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_pipeline_patch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">is_pipeline_last_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">last_patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">is_pipeline_first_stage</span><span class="p">()</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">pass</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">first_async_recv</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">recv_next</span><span class="p">()</span>  
</span></span><span class="line"><span class="cl">                <span class="n">first_async_recv</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">            <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">get_pipeline_recv_data</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">idx</span><span class="o">=</span><span class="n">patch_idx</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backbone_forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">latents</span><span class="o">=</span><span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">prompt_attention_mask</span><span class="o">=</span><span class="n">prompt_attention_mask</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">added_cond_kwargs</span><span class="o">=</span><span class="n">added_cond_kwargs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">guidance_scale</span><span class="o">=</span><span class="n">guidance_scale</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">is_pipeline_last_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scheduler_step</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">],</span>  <span class="c1"># pred noise</span>
</span></span><span class="line"><span class="cl">                <span class="n">last_patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">],</span>  <span class="c1"># last timestep noise</span>
</span></span><span class="line"><span class="cl">                <span class="n">t</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">extra_step_kwargs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">pipeline_isend</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">],</span> <span class="n">segment_idx</span><span class="o">=</span><span class="n">patch_idx</span>
</span></span><span class="line"><span class="cl">                <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">pipeline_isend</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">],</span> <span class="n">segment_idx</span><span class="o">=</span><span class="n">patch_idx</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">is_pipeline_first_stage</span><span class="p">()</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">pass</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">patch_idx</span> <span class="o">==</span> <span class="n">num_pipeline_patch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">pass</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">recv_next</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">next_patch</span><span class="p">()</span>  <span class="c1"># switch to next: (self.pipeline_patch_idx + 1) % self.num_pipeline_patch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">num_pipeline_warmup_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_warmup_steps</span>
</span></span><span class="line"><span class="cl">        <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">num_pipeline_warmup_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">callback</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&#34;callback not supported in async &#34;</span> <span class="s2">&#34;pipeline&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="ow">and</span> <span class="n">i</span> <span class="o">+</span> <span class="n">num_pipeline_warmup_steps</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">step_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">num_pipeline_warmup_steps</span><span class="p">)</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&#34;order&#34;</span><span class="p">,</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">patch_latents</span><span class="p">[</span><span class="n">patch_idx</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="construct-final-latents">Construct Final Latents</h2>
<p>timestep éå†å®Œæˆåï¼Œä»ç„¶æœ‰æœ€åçš„æ“ä½œè¦è¿›è¡Œï¼Œè¿™äº›æ“ä½œçš„ä¸»è¦ç›®çš„æ˜¯å°†æµæ°´çº¿å¹¶è¡Œä¸­å„ä¸ª patch çš„ç»“æœæ‹¼æ¥èµ·æ¥ï¼Œå½¢æˆå®Œæ•´çš„è¾“å‡ºç»“æœã€‚å°¤å…¶æ˜¯å¯¹äºæœ€åä¸€ä¸ªè®¾å¤‡ï¼Œè¿˜éœ€è¦å¤„ç† åºåˆ—å¹¶è¡Œï¼ˆsequence parallelismï¼‰ çš„åˆå¹¶æ“ä½œã€‚é€šè¿‡ all_gather æ“ä½œå°†æ¯ä¸ªè®¾å¤‡ä¸Šå¤„ç†çš„ patch ç»“æœæ”¶é›†èµ·æ¥ï¼Œç„¶åä»æ¯ä¸ªè®¾å¤‡çš„ <code>sp_latents_list</code> ä¸­ï¼Œæå–å‡ºå¯¹åº”äº <code>pp_patch_idx</code> çš„ patch æ•°æ®å¹¶å°†å®ƒä»¬æ‹¼æ¥èµ·æ¥ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">latents</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">is_pipeline_last_stage</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">latents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">patch_latents</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">get_sequence_parallel_world_size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">sp_degree</span> <span class="o">=</span> <span class="n">get_sequence_parallel_world_size</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">sp_latents_list</span> <span class="o">=</span> <span class="n">get_sp_group</span><span class="p">()</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">latents</span><span class="p">,</span> <span class="n">separate_tensors</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">latents_list</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">pp_patch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">num_pipeline_patch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">latents_list</span> <span class="o">+=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="n">sp_latents_list</span><span class="p">[</span><span class="n">sp_patch_idx</span><span class="p">][</span>
</span></span><span class="line"><span class="cl">                    <span class="o">...</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">pp_patches_start_idx_local</span><span class="p">[</span><span class="n">pp_patch_idx</span><span class="p">]</span> <span class="p">:</span> <span class="n">get_runtime_state</span><span class="p">()</span><span class="o">.</span><span class="n">pp_patches_start_idx_local</span><span class="p">[</span><span class="n">pp_patch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">:,</span>
</span></span><span class="line"><span class="cl">                <span class="p">]</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">sp_patch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sp_degree</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">latents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">latents_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">return</span> <span class="n">latents</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="decode-latents">Decode Latents</h1>
<p>ä¸ºäº†é¿å… VAE ä¸­çš„ <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/autoencoders/vae.py#L185">Decoder</a> åœ¨å¯¹ 8192px åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œ conv2D çš„è¿‡ç¨‹ä¸­å‡ºç° OOM çš„é—®é¢˜ï¼Œ xDiT ä½¿ç”¨äº†åºåˆ—å¹¶è¡Œå’Œ patch å¹¶è¡Œçš„ <a href="https://github.com/xdit-project/DistVAE/blob/a7e7ee7ec222f45af1214984561c8c645be8aece/distvae/models/layers/conv2d.py#L13">PatchConv2d</a> å’Œ <a href="https://github.com/xdit-project/DistVAE/blob/a7e7ee7ec222f45af1214984561c8c645be8aece/distvae/models/layers/normalization.py#L59">PatchGroupNorm</a> æ¥æ›¿æ¢æ‰åŸæœ‰ Decoder ä¸­çš„ <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unets/unet_2d_blocks.py#L2682">UpDecoderBlock2D</a> å¯¹åº”çš„å±‚ã€‚</p>
<h2 id="patchgroupnorm">PatchGroupNorm</h2>
<p>PatchGroupNorm åœ¨ H ç»´åº¦ä¸Šåˆ’åˆ†ä¸ºå¤šä¸ª patchï¼Œæ¯ä¸ªè®¾å¤‡æ±‚è‡ªå·±æ‰€è´Ÿè´£çš„éƒ¨åˆ†å’Œã€‚
<details class="custom-details">
    <summary class="custom-summary">GroupNorm Principles</summary>
    <div>å‡è®¾è¾“å…¥å¼ é‡ x çš„å½¢çŠ¶ä¸º [N, C, H, W]ï¼Œå…¶ä¸­ N è¡¨ç¤ºæ‰¹é‡å¤§å°ï¼ˆBatch Sizeï¼‰ï¼ŒC è¡¨ç¤ºé€šé“æ•°ï¼ˆChannelsï¼‰ï¼ŒH å’Œ W åˆ†åˆ«è¡¨ç¤ºé«˜åº¦å’Œå®½åº¦ã€‚åœ¨ GN ä¸­ï¼Œé€šé“æ•° C è¢«åˆ’åˆ†ä¸º G ç»„ï¼Œæ¯ä¸ªç»„åŒ…å« C/G ä¸ªé€šé“ã€‚è®¡ç®—æ¯ä¸ªç»„å†…å³ [C/G, H, W] ç»´åº¦ä¸Šçš„å‡å€¼å’Œæ–¹å·®ã€‚ç‰¹åˆ«çš„ G=1 æ—¶ï¼ŒGN é€€åŒ–ä¸º BNã€‚G=C æ—¶ï¼ŒGN é€€åŒ–ä¸º LNã€‚</div>
</details><br></p>
<ol>
<li>è·å–é«˜åº¦ä¿¡æ¯</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">PatchGroupNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;&#39;&#39; def __init__(self, ...)&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">height</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">height</span><span class="p">)</span>  <span class="c1"># æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„é«˜åº¦å¹¶æ±‡æ€»ã€‚æœ€ç»ˆæ¯ä¸ªè¿›ç¨‹çš„ height éƒ½å°†è¡¨ç¤ºå…¨å±€çš„é«˜åº¦å’Œã€‚</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>è®¡ç®—æ¯ä¸ªç»„çš„é€šé“æ•°é‡ä»¥åŠæ¯ä¸ªè¿›ç¨‹å†…çš„å…ƒç´ æ•°é‡</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">channels_per_group</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_groups</span>  <span class="c1"># æ¯ä¸ªç»„çš„é€šé“æ•°é‡</span>
</span></span><span class="line"><span class="cl"><span class="n">nelements_rank</span> <span class="o">=</span> <span class="n">channels_per_group</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># å½“å‰è¿›ç¨‹è´Ÿè´£çš„æ¯ä¸ªç»„ä¸­çš„å…ƒç´ æ€»</span>
</span></span><span class="line"><span class="cl"><span class="n">nelements</span> <span class="o">=</span> <span class="n">channels_per_group</span> <span class="o">*</span> <span class="n">height</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># æ‰€æœ‰è¿›ç¨‹çš„æ¯ä¸ªç»„ä¸­çš„å…ƒç´ æ€»æ•°</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="3">
<li>è®¡ç®—æ¯ä¸ªç»„çš„å‡å€¼</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_groups</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1">#  [batch_size, num_groups, channels_per_group, height, width]</span>
</span></span><span class="line"><span class="cl"><span class="n">group_sum</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># å¯¹æ¯ä¸ªç»„çš„æ‰€æœ‰å…ƒç´  (channels_per_group, height, width) æ±‚å¹³å‡</span>
</span></span><span class="line"><span class="cl"><span class="n">group_sum</span> <span class="o">=</span> <span class="n">group_sum</span> <span class="o">*</span> <span class="n">nelements_rank</span>  <span class="c1"># åŠ æƒåçš„å±€éƒ¨å’Œ = å±€éƒ¨å‡å€¼ * å½“å‰è¿›ç¨‹çš„å…ƒç´ æ•°é‡</span>
</span></span><span class="line"><span class="cl"><span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">group_sum</span><span class="p">)</span>  <span class="c1"># æ”¶é›†å¹¶æ±‡æ€»æ‰€æœ‰è¿›ç¨‹çš„å±€éƒ¨å’Œï¼Œå¾—åˆ°å…¨å±€å’Œ</span>
</span></span><span class="line"><span class="cl"><span class="n">E</span> <span class="o">=</span> <span class="p">(</span><span class="n">group_sum</span> <span class="o">/</span> <span class="n">nelements</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>  <span class="c1"># è®¡ç®—å…¨å±€çš„å‡å€¼ E</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="4">
<li>è®¡ç®—æ¯ä¸ªç»„çš„æ–¹å·®</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># å’Œè®¡ç®—å‡å€¼åŒæ ·çš„æ“ä½œ</span>
</span></span><span class="line"><span class="cl"><span class="n">group_var_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_groups</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="n">group_var_sum</span><span class="p">)</span>  
</span></span><span class="line"><span class="cl"><span class="n">group_var_sum</span> <span class="o">=</span> <span class="n">group_var_sum</span> <span class="o">*</span> <span class="n">nelements_rank</span>
</span></span><span class="line"><span class="cl"><span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">group_var_sum</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">var</span> <span class="o">=</span> <span class="p">(</span><span class="n">group_var_sum</span> <span class="o">/</span> <span class="n">nelements</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="5">
<li>å½’ä¸€åŒ–å¹¶ç¼©æ”¾ $y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta$</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">E</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="patchconv2d">PatchConv2d</h2>
<p><code>PatchConv2d</code> å°†æ½œåœ¨ç©ºé—´ä¸­çš„ç‰¹å¾æ˜ å°„åˆ†å‰²æˆå¤šä¸ª patchï¼Œè·¨ä¸åŒè®¾å¤‡è¿›è¡Œåºåˆ—å¹¶è¡Œ VAE è§£ç ã€‚è¿™ç§æŠ€æœ¯å°†ä¸­é—´æ¿€æ´»æ‰€éœ€çš„å³°å€¼å†…å­˜å‡å°‘åˆ° 1/Nï¼Œå…¶ä¸­ N æ˜¯æ‰€ä½¿ç”¨çš„è®¾å¤‡æ•°é‡ã€‚å¯¹äº VAE ä¸­çš„å·ç§¯ç®—å­ï¼Œéœ€è¦å¯¹å¦‚ä¸‹å›¾æ‰€ç¤ºçš„ halo åŒºåŸŸæ•°æ®è¿›è¡Œé€šä¿¡ã€‚</p>
<p>
<figure class="post-figure">
    <a href="https://raw.githubusercontent.com/xdit-project/xdit_assets/main/methods/patchvaeconv.png" target="_blank" rel="noopener">
        <img loading="lazy" src="https://raw.githubusercontent.com/xdit-project/xdit_assets/main/methods/patchvaeconv.png" alt="Patch VAE Conv">
    </a><figcaption>Patch VAE Conv</figcaption></figure></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">PatchConv2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">kernel_size</span><span class="p">:</span> <span class="n">_size_2_t</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">stride</span><span class="p">:</span> <span class="n">_size_2_t</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_size_2_t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">dilation</span><span class="p">:</span> <span class="n">_size_2_t</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">padding_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;zeros&#39;</span><span class="p">,</span>  <span class="c1"># TODO: refine this type</span>
</span></span><span class="line"><span class="cl">        <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="n">dilation</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&#34;dilation is not supported in PatchConv2d&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dilation</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">assert</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&#34;dilation is not supported in PatchConv2d&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">groups</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>_conv_forward</code> å‡½æ•°æ˜¯ <code>PatchConv2d</code> ç±»çš„æ ¸å¿ƒï¼Œå®ƒè´Ÿè´£åœ¨è¾“å…¥å¼ é‡ä¸Šæ‰§è¡Œå·ç§¯æ“ä½œï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ†å¸ƒå¼è®¡ç®—åœºæ™¯ä¸‹å¤„ç†è·¨è¿›ç¨‹çš„è¾“å…¥åˆ‡åˆ†ã€halo åŒºåŸŸçš„ä¼ é€’å’Œè®¡ç®—ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨çš„è¾…åŠ©å‡½æ•°çš„ç®€è¦åŠŸèƒ½è¯´æ˜</p>
<ul>
<li><code>_get_world_size_and_rank </code>ï¼šè·å–å½“å‰åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„è¿›ç¨‹æ€»æ•° <code>world_size</code> å’Œå½“å‰è¿›ç¨‹çš„ç¼–å· <code>rank</code></li>
<li><code>_calc_patch_height_index</code>ï¼šæ ¹æ®æ¯ä¸ªè¿›ç¨‹çš„è¾“å…¥é«˜åº¦ï¼Œè®¡ç®—æ‰€æœ‰è¿›ç¨‹çš„èµ·å§‹å’Œç»“æŸé«˜åº¦ç´¢å¼•ã€‚</li>
<li><code>_calc_halo_width_in_h_dim</code>ï¼šè®¡ç®—å½“å‰è¿›ç¨‹åœ¨ h ç»´åº¦ä¸Šæ‰€éœ€çš„ä¸Šæ–¹å’Œä¸‹æ–¹çš„ halo åŒºåŸŸå®½åº¦ã€‚</li>
<li><code>_calc_bottom_halo_width</code>ï¼šè®¡ç®—å½“å‰è¿›ç¨‹ä»ä¸‹æ–¹ç›¸é‚»è¿›ç¨‹éœ€è¦æ¥æ”¶çš„ halo åŒºåŸŸçš„å®½åº¦ã€‚</li>
<li><code>_calc_top_halo_width</code>ï¼šè®¡ç®—å½“å‰è¿›ç¨‹ä»ä¸Šæ–¹ç›¸é‚»è¿›ç¨‹éœ€è¦æ¥æ”¶çš„ halo åŒºåŸŸçš„å®½åº¦ã€‚</li>
<li><code>_adjust_padding_for_patch</code>ï¼šæ ¹æ®å½“å‰è¿›ç¨‹çš„ <code>rank</code> å’Œæ€»è¿›ç¨‹æ•°è°ƒæ•´è¾“å…¥æ•°æ®çš„å¡«å……æ–¹å¼ï¼Œé˜²æ­¢è¾¹ç•Œé‡å¤è®¡ç®—ã€‚</li>
</ul>
<ol>
<li>è·å–è¾“å…¥ä¿¡æ¯ä»¥åŠé€šä¿¡ç»„ä¿¡æ¯</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_conv_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">        <span class="n">bs</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">world_size</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_world_size_and_rank</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>  <span class="c1"># å¤„ç†éåˆ†å¸ƒå¼æƒ…å†µ</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">!=</span> <span class="s1">&#39;zeros&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reversed_padding_repeated_twice</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                <span class="n">_pair</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                            <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>è·å–è¾“å…¥çš„å…ƒæ•°æ®</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">patch_height_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;cuda:</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())]</span>
</span></span><span class="line"><span class="cl"><span class="n">dist</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">patch_height_list</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">h</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;cuda:</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">))</span>  <span class="c1"># æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„è¾“å…¥é«˜åº¦</span>
</span></span><span class="line"><span class="cl"><span class="n">patch_height_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_patch_height_index</span><span class="p">(</span><span class="n">patch_height_list</span><span class="p">)</span>  <span class="c1"># è®¡ç®—æ¯ä¸ªè¿›ç¨‹å—çš„èµ·å§‹é«˜åº¦å’Œç»“æŸé«˜åº¦çš„ç´¢å¼•</span>
</span></span><span class="line"><span class="cl"><span class="n">halo_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_halo_width_in_h_dim</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">patch_height_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># è®¡ç®—å½“å‰è¿›ç¨‹å—çš„ä¸Šä¸‹ halo åŒºåŸŸçš„å®½åº¦</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="3">
<li>è®¡ç®—ç›¸é‚»è¿›ç¨‹çš„ halo åŒºåŸŸ (ä¹Ÿå°±æ˜¯è‡ªå·±éœ€è¦æ¥å‘é€çš„éƒ¨åˆ†)</li>
</ol>
<p>é€šè¿‡è®¡ç®—å‰ä¸€ä¸ªè¿›ç¨‹çš„ bottom_halo_width å’Œåä¸€ä¸ªè¿›ç¨‹çš„ top_halo_width å¾—å‡ºè‡ªå·±éœ€è¦å‘é€çš„éƒ¨åˆ†</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">prev_bottom_halo_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">next_top_halo_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">prev_bottom_halo_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_bottom_halo_width</span><span class="p">(</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">patch_height_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="n">world_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">next_top_halo_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_top_halo_width</span><span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">patch_height_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">next_top_halo_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">next_top_halo_width</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="4">
<li>è¿›è¡Œ halo åŒºåŸŸçš„å‘é€ä¸æ¥æ”¶</li>
</ol>
<p>å¼‚æ­¥å‘é€ï¼ŒåŒæ­¥æ¥æ”¶</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">to_next</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="n">to_prev</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="n">top_halo_recv</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="n">bottom_halo_recv</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">next_top_halo_width</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">bottom_halo_send</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="n">next_top_halo_width</span><span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">to_next</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">bottom_halo_send</span><span class="p">,</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">halo_width</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># not rank 0</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_halo_recv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">([</span><span class="n">bs</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">halo_width</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">input</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;cuda:</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dist</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">top_halo_recv</span><span class="p">,</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">prev_bottom_halo_width</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># not rank N-1</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_halo_send</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">prev_bottom_halo_width</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">to_prev</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">top_halo_send</span><span class="p">,</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">halo_width</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">bottom_halo_recv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">([</span><span class="n">bs</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">halo_width</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">w</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">input</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;cuda:</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dist</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">bottom_halo_recv</span><span class="p">,</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="5">
<li>æ‹¼æ¥ halo åŒºåŸŸ</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">halo_width</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Remove redundancy at the top of the input</span>
</span></span><span class="line"><span class="cl"><span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="n">halo_width</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">top_halo_recv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># concat the halo region to the input tensor </span>
</span></span><span class="line"><span class="cl">    <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">top_halo_recv</span><span class="p">,</span> <span class="nb">input</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">bottom_halo_recv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">bottom_halo_recv</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="6">
<li>ç­‰å¾…å‘é€å®Œæˆå†å¼€å§‹è®¡ç®—</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">to_next</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">to_next</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">to_prev</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">to_prev</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="7">
<li>è¿›è¡Œå·ç§¯å’Œåå¤„ç†</li>
</ol>
<p>ä¸ºäº†å‡å°‘ memory spike ä¸€æ¬¡è®¡ç®— block_size*block_size çš„åŒºåŸŸï¼Œå¹¶å°†ç»“æœæ‹¼æ¥èµ·æ¥</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">padding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_adjust_padding_for_patch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reversed_padding_repeated_twice</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="n">h</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="ow">and</span> <span class="n">w</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">!=</span> <span class="s1">&#39;zeros&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">conv_res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                            <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">_pair</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">conv_res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                            <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">conv_res</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">!=</span> <span class="s2">&#34;zeros&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;constant&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_chunks_in_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">h</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>  <span class="c1"># h ç»´åº¦çš„ block æ•°é‡</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_chunks_in_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>  <span class="c1"># w ...</span>
</span></span><span class="line"><span class="cl">    <span class="n">unit_chunk_size_h</span> <span class="o">=</span> <span class="n">h</span> <span class="o">//</span> <span class="n">num_chunks_in_h</span>
</span></span><span class="line"><span class="cl">    <span class="n">unit_chunk_size_w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">//</span> <span class="n">num_chunks_in_w</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl"><span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">idx_h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_chunks_in_h</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">inner_output</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">idx_w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_chunks_in_w</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_w</span> <span class="o">=</span> <span class="n">idx_w</span> <span class="o">*</span> <span class="n">unit_chunk_size_w</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_h</span> <span class="o">=</span> <span class="n">idx_h</span> <span class="o">*</span> <span class="n">unit_chunk_size_h</span>
</span></span><span class="line"><span class="cl">        <span class="n">end_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx_w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">unit_chunk_size_w</span>
</span></span><span class="line"><span class="cl">        <span class="n">end_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx_h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">unit_chunk_size_h</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># è®¡ç®—æ¯ä¸ªå—çš„å¼€å§‹å’Œç»“æŸç´¢å¼•ï¼Œè°ƒæ•´å—çš„è¾¹ç•Œ</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># å¯¹å½“å‰å—æ‰§è¡Œå·ç§¯æ“ä½œ</span>
</span></span><span class="line"><span class="cl">        <span class="n">inner_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="nb">input</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">start_h</span><span class="p">:</span><span class="n">end_h</span><span class="p">,</span> <span class="n">start_w</span><span class="p">:</span><span class="n">end_w</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">weight</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">bias</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">inner_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div>]]></content:encoded>
    </item>
    <item>
      <title>VLLM Sourse Code Reading</title>
      <link>http://localhost:57770/blogs/vllm/</link>
      <pubDate>Sat, 07 Jun 2025 18:15:55 +0800</pubDate>
      <guid>http://localhost:57770/blogs/vllm/</guid>
      <description>vllm structure</description>
      <content:encoded><![CDATA[<h1 id="basic">Basic</h1>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">vllm</span> <span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Sample prompts.</span>
</span></span><span class="line"><span class="cl"><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;Hello, my name is&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;The president of the United States is&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;The capital of France is&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;The future of AI is&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Create a sampling params object.</span>
</span></span><span class="line"><span class="cl"><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create an LLM.</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&#34;facebook/opt-125m&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Generate texts from the prompts. The output is a list of RequestOutput objects</span>
</span></span><span class="line"><span class="cl"><span class="c1"># that contain the prompt, generated text, and other information.</span>
</span></span><span class="line"><span class="cl"><span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Print the outputs.</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">prompt</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">prompt</span>
</span></span><span class="line"><span class="cl">    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">!r}</span><span class="s2">, Generated text: </span><span class="si">{</span><span class="n">generated_text</span><span class="si">!r}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="architecture">Architecture</h1>
<p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB713ed0d773cac101706cdaa862d71dda?method=download&amp;shareKey=09c7c358d0427427384e027f0ced662a" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB713ed0d773cac101706cdaa862d71dda?method=download&amp;shareKey=09c7c358d0427427384e027f0ced662a" alt="VLLM Architecture Overview">
    </a><figcaption>VLLM Architecture Overview</figcaption></figure></p>
<ul>
<li>LLM: æœ€ä¸Šå±‚çš„ç±»ï¼Œæ„é€ å‡½æ•°ä¸­ä¼šæ ¹æ®ä¼ å…¥çš„å‚æ•°æ„å»º EngineArgs ç„¶ååˆ›å»º LLMEngine å¯¹è±¡ã€‚</li>
<li>LLMEngine: åŒ…å«ä¸€äº›ç»„ä»¶ InputPreprocessor, ExecutorBase è´Ÿè´£æ¨¡å‹æ¨ç†çš„æœ€ä¸Šå±‚çš„ç±»</li>
<li>ExecutorBase ä¼šåˆå§‹åŒ– N ä¸ª WorkerWrapperBase (åŒ…è£…å®é™…çš„ workerï¼Œç±»æ¯”æˆ GPU)
<ul>
<li>Worker: åœ¨ GPU ä¸Šæ‰§è¡Œ (ä¸€éƒ¨åˆ†) æ¨¡å‹æ¨ç†ã€‚æ¯ä¸ª worker ä¸ä¸€ä¸ª GPU ç›¸å…³è”ï¼Œè´Ÿè´£ç»´æŠ¤ KV Cache å¹¶åœ¨ GPU ä¸Šæ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚åœ¨åˆ†å¸ƒå¼æ¨ç†çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸ª worker è¢«åˆ†é…æ¨¡å‹çš„ä¸€éƒ¨åˆ†ã€‚
<ul>
<li>ModelRunner:  æ‰§è¡Œæ¨¡å‹æ¨ç†å¹¶è´Ÿè´£é‡‡æ ·æ–° token.</li>
<li>CacheEngine: è´Ÿè´£åˆå§‹åŒ–å’Œç®¡ç† GPU å’Œ CPU KV Cache. è¿˜æä¾›äº†å¯¹ KV Cache è¿›è¡Œæ“ä½œçš„æ–¹æ³•ã€‚é€šè¿‡ <code>initialize_cache()</code> åˆå§‹åŒ–ã€‚</li>
</ul>
</li>
</ul>
</li>
<li>Scheduler: è´Ÿè´£æ¨ç†æ—¶å€™å¯¹è¯·æ±‚çš„è°ƒåº¦ã€‚ç»„ä»¶åŒ…æ‹¬ä¸€ä¸ª BlockSpaceManager (KV Cache blocks ç®¡ç†çš„æ ¸å¿ƒç±») ä»¥åŠä¸‰ä¸ªé˜Ÿåˆ— waiting, running &amp; swapped.</li>
</ul>
<h1 id="llmengine--initialization">LLMEngine  Initialization</h1>
<ul>
<li>InputPreprocessor: ä¸»è¦æ˜¯åœ¨ <code>add_request()</code> æ–¹æ³•ä¸­å°†è¾“å…¥çš„ prompt æ”¾å…¥ tokenizer è¿›è¡Œå¤„ç†ã€‚</li>
<li>InputRegistry: æ ¹æ®ç›®æ ‡æ¨¡å‹å¯¹ InputPreprocessor ä¹‹åçš„æ•°æ®è¿›è¡Œå¤„ç†ã€‚</li>
</ul>
<h2 id="init-executor">Init Executor</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DistributedExecutorBase</span><span class="p">(</span><span class="n">ExecutorBase</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Abstract superclass of distributed executor implementations.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># This is non-None when the execute model loop is running</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># in the parallel workers. It&#39;s a coroutine in the AsyncLLMEngine case.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">parallel_worker_tasks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Awaitable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ExecutorBase çš„æ„é€ å‡½æ•°ä¸­ä¼šè°ƒç”¨ <code>self._init_executor()</code> å¯¹åº”åˆ°å…·ä½“å­ç±»çš„å‡½æ•°ã€‚å¦‚æœé‡‡ç”¨ TP æˆ– PP çš„è¯ å¯¹åº”åˆ°çš„æ˜¯ RayDistributedExecutorï¼Œå¦åˆ™å¯¹åº”åˆ°çš„æ˜¯ UniProcExecutor. ä¸‹é¢ä»¥åè€…ä¸ºä¾‹ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">UniProcExecutor</span><span class="p">(</span><span class="n">ExecutorBase</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">uses_ray</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_init_executor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Initialize the worker and load the model.
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">driver_worker</span> <span class="o">=</span> <span class="n">WorkerWrapperBase</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                               <span class="n">rpc_rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span> <span class="o">=</span> <span class="n">get_distributed_init_method</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">get_ip</span><span class="p">(),</span> <span class="n">get_open_port</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># set local rank as the device index if specified</span>
</span></span><span class="line"><span class="cl">        <span class="n">device_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">device_config</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="fm">__str__</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">device_info</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">device_info</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">vllm_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">distributed_init_method</span><span class="o">=</span><span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">is_driver_worker</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="ow">or</span> <span class="p">(</span><span class="n">rank</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">tensor_parallel_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">collective_rpc</span><span class="p">(</span><span class="s2">&#34;init_worker&#34;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">([</span><span class="n">kwargs</span><span class="p">],</span> <span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">collective_rpc</span><span class="p">(</span><span class="s2">&#34;init_device&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">collective_rpc</span><span class="p">(</span><span class="s2">&#34;load_model&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">collective_rpc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                       <span class="n">method</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                       <span class="n">timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                       <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(),</span>
</span></span><span class="line"><span class="cl">                       <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">        <span class="n">answer</span> <span class="o">=</span> <span class="n">run_method</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">driver_worker</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># åˆå§‹åŒ– Worker</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="n">answer</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>Executor: åˆå§‹åŒ–å…·ä½“çš„ç»§æ‰¿è‡ª ExecutorBase çš„å¯¹è±¡ï¼Œè¯¥å¯¹è±¡çš„åˆå§‹åŒ–è¿‡ç¨‹ä¸­ä¼šè°ƒç”¨ <code>init_worker()</code> åˆå§‹åŒ– Worker (è¢« WorkerWrapperBase åŒ…è£…)ï¼Œè°ƒç”¨ <code>init_device()</code> åˆå§‹åŒ–è®¾å¤‡ï¼Œå’Œè°ƒç”¨å…·ä½“ Worker å¯¹è±¡çš„ model_runner çš„ <code>load_model()</code> å°†æ¨¡å‹åŠ è½½åˆ°è®¾å¤‡ä¸Šã€‚
<ul>
<li>Worker: æ„é€ å‡½æ•°ä¸­ä¼šåˆå§‹åŒ– <code>GPUModelRunnerBase</code> å¯¹è±¡ï¼Œç¡®å®šè®¡ç®— attention ä½¿ç”¨çš„ backend è¿˜æœ‰ CUDAGraphRunner ç”¨äºå°†æ¨¡å‹çš„è®¡ç®—è¿‡ç¨‹è®°å½•ä¸ºä¸€ä¸ªé™æ€å›¾ï¼Œåœ¨åç»­çš„æ¨ç†ä¸­ï¼Œé€šè¿‡ç›´æ¥ replay è¿™ä¸ªé™æ€å›¾æ¥é¿å…åŠ¨æ€è°ƒåº¦å’Œé‡å¤çš„å†…æ ¸å¯åŠ¨å¼€é”€ã€‚</li>
</ul>
</li>
</ul>
<h2 id="initialize_kv_caches">initialize_kv_caches</h2>
<p>LLMEngine æ„é€ å‡½æ•°åœ¨åˆå§‹åŒ– ExecutorBase åä¼šè°ƒç”¨ <code>initialize_kv_caches()</code> æ¥åˆå§‹åŒ– Worker ä¸­çš„ KV Cacheï¼Œæµç¨‹å¦‚ä¸‹:</p>
<ol>
<li>è¯¥å‡½æ•°ä¼šé¦–å…ˆé€šè¿‡ <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/worker/neuron_worker.py#L69">Worker.determine_num_available_blocks()</a> ç¡®å®š GPU å’Œ CPU å¯ç”¨çš„ block æ•°é‡ã€‚åè€…åœ¨ <code>memory_profiling</code> ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œ <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/worker/model_runner.py#L1239">profile_run()</a> æ¨¡æ‹Ÿæ¨¡å‹åœ¨æœ€å¤§è´Ÿè½½ (max_num_batched_tokens å’Œ max_num_seqs) ä¸‹æ‰§è¡Œä¸€æ¬¡æ¨ç†ã€‚æµ‹é‡å†…å­˜ä½¿ç”¨å¹¶åˆ†è§£ä¸ºæƒé‡ã€æ¿€æ´»å¼ é‡å’Œé PyTorch éƒ¨åˆ†ã€‚ç•™ç»™ KV Cache çš„å†…å­˜å¤§å°ä¸º <code>total_mem * max_utilization - weight_mem - act_mem - nontorch_mem</code>.  å†é™¤ä»¥æ¯ä¸€ä¸ª block èƒ½å­˜å‚¨çš„çš„ KV Cache å¤§å° <code>cache_size = Cache_config.block_size * num_attention_layers * 2*num_heads*head_size</code> å³å¯å¾—åˆ°æœ€å¤šèƒ½åˆ†é…å¤šå°‘ä¸ª GPU block. è€Œ CPU block æ•°é‡ç”±é¢„è®¾çš„ <code>swap_size // cache_size</code> æ‰€ç¡®å®šã€‚</li>
<li>ç¡®å®šäº† GPU å’Œ CPU çš„ block æ•°é‡åä¼šè°ƒç”¨ <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/worker/worker.py#L285">Worker.initialize_cache()</a> æ–¹æ³•ï¼Œé‡Œé¢é¦–å…ˆä¼šè°ƒç”¨ <code>Worker._init_cache_engine()</code> æ ¹æ®ä¼ å…¥çš„ GPU block ä¸ªæ•°åˆå§‹åŒ– CacheEngine (åˆå§‹åŒ– attn_backendï¼Œè°ƒç”¨ <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/worker/cache_engine.py#L68">CacheEngine._allocate_kv_cache()</a> ä¸ºæ¨¡å‹çš„æ¯ä¸€å±‚ transformer å¼€è¾Ÿ CPU å’Œ GPU çš„ KV Cache å†…å­˜)ï¼Œç„¶åä¼šè°ƒç”¨ <a href="https://github.com/vllm-project/vllm/blob/main/vllm/utils.py#L2163">bind_kv_cache()</a> å°† GPU KV Cache Tensor ç»‘å®šåˆ°å¯¹åº”çš„æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ï¼Œå®ƒç­›é€‰éœ€è¦ KV Cache çš„æ³¨æ„åŠ›å±‚ï¼ŒæŒ‰å±‚ç´¢å¼•æ’åºå¹¶å»é‡åä¸ºæ¯ä¸ªè®¾å¤‡ç»‘å®šå¯¹åº”çš„ Tensor.</li>
<li>é¢„çƒ­ä¹‹åè¿›è¡Œ capture_model è®°å½•è®¡ç®—å›¾ã€‚</li>
</ol>
<h2 id="init-scheduler">Init Scheduler</h2>
<p>æ„é€ å‡½æ•°ä¸­ä¼šåˆå§‹åŒ– <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/core/block_manager.py#L61">BlockSpaceManager</a>. é¦–å…ˆä¼šåˆ›å»ºä¸€ä¸ª <code>CpuGpuBlockAllocator</code>ï¼Œä¸º CPU å’Œ GPU å—ç»´æŠ¤å•ç‹¬çš„å†…å­˜æ± ï¼Œå¹¶å…è®¸åœ¨è¿™äº›å†…å­˜æ± ä¸­åˆ†é…ã€é‡Šæ”¾ã€åˆ†å‰å’Œäº¤æ¢å—ã€‚å®ƒä¼šä¸º CPU å’Œ GPU ä¸­çš„ blocks åˆ†åˆ«åˆ›å»ºä¸€ä¸ª <code>BlockAlloctor</code>. è¿˜ä¼šåˆå§‹åŒ–ä¸€ä¸ªç©ºçš„ <code>Dict[SeqId, BlockTable]</code>ï¼Œ è¡¨ç¤ºå¯¹åº” seq çš„ KV Cache æ‰€ä½¿ç”¨çš„ç‰©ç†å†…å­˜å—ã€‚è¿˜ä¼šåˆå§‹åŒ–ä¸€äº›è°ƒåº¦æ—¶æ‰€éœ€è¦çš„æ•°æ®ï¼Œåæ–‡å†è°ˆã€‚</p>
<p>è¿˜ä¼šåˆå§‹åŒ– waiting(åŒ…å«æ–°çš„æˆ– preempted prefill è¯·æ±‚), running &amp; swapped(è¢«æ¢å‡ºçš„ decoding è¯·æ±‚), å®ƒä»¬æ˜¯ <code>Deque[SequenceGroup]</code>ï¼Œå…¶ä¸­ <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/sequence.py#L633">SequenceGroup(SG)</a> æ˜¯ä¸€ç»„ç”±åŒä¸€ä¸ª prompt ç”Ÿæˆçš„ Sequences å’Œå¯¹åº”çš„é‡‡æ ·å‚æ•°ã€‚</p>
<ul>
<li>SequenceGroupOutputProcessor: æŠ½è±¡åŸºç±»å€Ÿæ¥å£ï¼Œä¼šåˆ†ä¸º SingleStepOutputProcessor (æ”¯æŒ beam seaching) å’Œ MultiStepOutputProcessor (æ”¯æŒ speculatice decoding)</li>
</ul>
<h1 id="llm-generate">LLM Generate</h1>
<h2 id="_validate_and_add_requests">_validate_and_add_requests</h2>
<p>é‡Œé¢ä¼šè°ƒç”¨ <code>_add_request()</code> ç»™ prompt åˆ†é… reqest_id åä¼šè°ƒç”¨ <code>LLMEngine.add_request()</code> å°†å…¶æ·»åŠ åˆ°è¯·æ±‚æ± ä¸­ï¼Œå¹¶å°†åœ¨è°ƒç”¨ <code>LLMEngine.step()</code> æ—¶ç”±è°ƒåº¦å™¨å¤„ç†ã€‚ç¡®åˆ‡çš„è°ƒåº¦ç­–ç•¥ç”±è°ƒåº¦ç¨‹åºç¡®å®šã€‚ä¸»è¦å°±æ˜¯è¿›è¡Œ tokenizeï¼Œç„¶åæ‰“åŒ…æˆ SG ååŠ å…¥ waiting.</p>
<h2 id="__run_engine">__run_engine</h2>
<p>è°ƒç”¨ generate æ—¶é¦–å…ˆä¼šå°† prompt åŒ…è£…æˆ SGï¼Œå®ƒæ˜¯åŒ…å«æŸä¸ª prompt ç”Ÿæˆçš„æ‰€æœ‰ Sequenceï¼Œä»¥åŠä¸€äº›å…¶ä»–åœ¨è°ƒåº¦æ—¶éœ€è¦çš„ä¿¡æ¯çš„ç»“æ„ã€‚Scheduler é‡Œé¢åŒ…å«ä¸‰ä¸ª <code>Deque[SequenceGroup]</code>: waiting, running &amp; swapped.
generate() &ndash;&gt; _run_engine() &ndash;&gt; step() &ndash;&gt; Scheduler.schedule() &ndash;&gt; Scheduler._schedule()
Scheduler çš„ä¸€äº›æ“ä½œä¸ BlockManager æ¯æ¯ç›¸å…³ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢å…ˆç®€è¦è¯´æ˜é€»è¾‘ï¼Œæœ‰å…³å…¶å…·ä½“ç»“æ„å’Œæ“ä½œæµç¨‹åœ¨åæ–‡ä¸­è§£é‡Šã€‚</p>
<h2 id="step">step</h2>
<p>æ‰§è¡Œä¸€æ¬¡ decoding è¿­ä»£å¹¶è¿”å›æ–°ç”Ÿæˆçš„ç»“æœã€‚

<figure class="post-figure">
    <a href="https://i.imgur.com/sv2HssD.png" target="_blank" rel="noopener">
        <img loading="lazy" src="https://i.imgur.com/sv2HssD.png" alt="Overview of the step function">
    </a><figcaption>Overview of the step function</figcaption></figure>
ä¸»è¦æµç¨‹å¦‚ä¸‹</p>
<ol>
<li>è°ƒåº¦è¦åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­æ‰§è¡Œçš„ seq å’Œè¦äº¤æ¢å…¥/å‡º/å¤åˆ¶çš„ä»¤ç‰Œå—ã€‚æ ¹æ®è°ƒåº¦ç­–ç•¥ï¼ŒSequences å¯èƒ½è¢«æŠ¢å /é‡æ–°æ’åºã€‚</li>
<li>è°ƒç”¨åˆ†å¸ƒå¼æ‰§è¡Œå™¨æ¥æ‰§è¡Œæ¨¡å‹ã€‚</li>
<li>å¤„ç†æ¨¡å‹è¾“å‡ºã€‚ä¸»è¦åŒ…æ‹¬ï¼š decoding ç›¸å…³è¾“å‡ºï¼Œä½¿ç”¨ _beam_search ä¸å¦çš„æ¨¡å‹è¾“å‡ºæ›´æ–°è°ƒåº¦ seq ç»„å’Œé‡Šæ”¾å·²å®Œæˆçš„ seq ç»„ã€‚</li>
<li>è¯»å–ä¸Šä¸€æ¬¡è°ƒåº¦çš„å…ƒæ•°æ®å’Œè¾“å‡º</li>
<li>å¦‚æœæ²¡æœ‰å‰©ä½™æ­¥éª¤ä¸”ï¼Œè°ƒç”¨ <code>Scheduler.schedule()</code> æ‰§è¡Œæ–°è°ƒåº¦ï¼Œç”Ÿæˆ seq ç»„å…ƒæ•°æ®ã€è°ƒåº¦è¾“å‡ºå’Œå¼‚æ­¥æ ‡å¿—ã€‚</li>
<li>è·å–å¹¶é‡ç½®å·²å®Œæˆè¯·æ±‚ IDï¼Œæ¸…ç†å†…å­˜</li>
<li>å¦‚æœä¸å…è®¸å¼‚æ­¥ä¸”æœ‰è¾“å‡ºé˜Ÿåˆ—ï¼Œå¤„ç†æ¨¡å‹è¾“å‡ºã€‚</li>
<li>ä» Cache è·å–ä¸Šä¸€æ¬¡è¿­ä»£çš„ sampled_token_idsï¼Œæ„é€  ExecuteModelRequest åè°ƒç”¨ <code>Executor.execute_model()</code> (æœ€åæ˜¯ç”± ModelRunner) æ‰§è¡Œæ¨¡å‹æ¨ç†ï¼Œè·å–è¾“å‡ºã€‚</li>
</ol>
<h2 id="_schedule_prefill">_schedule_prefill()</h2>
<ol>
<li>æ£€æŸ¥ budget æ˜¯å¦è€—å°½</li>
<li>å–å‡ºé˜Ÿåˆ—head éƒ¨çš„ SequenceGroup (prefill é˜¶æ®µ SequenceGroup åªæœ‰ä¸€ä¸ªåˆå§‹ prompt Sequence)</li>
<li>è®¡ç®— uncached å’Œ cached çš„æ–° token æ•°</li>
<li>è°ƒç”¨ <code>BlockSpaceManager.can_allocate()</code> æ£€æŸ¥æ˜¯å¦èƒ½åˆ†é…è¶³å¤Ÿå†…å­˜ã€‚</li>
<li>è‹¥èƒ½æ»¡è¶³ budgetï¼Œä» waiting ä¸­ç§»é™¤ SequenceGroup. è°ƒç”¨ <code>_allocate_and_set_running()</code> åˆ†é…å†…å­˜å¹¶è®¾ç½®ä¸º RUNNING çŠ¶æ€ã€‚</li>
</ol>
<h2 id="_schedule_running">_schedule_running()</h2>
<ol>
<li>å–å‡ºé˜Ÿåˆ—head éƒ¨ SequenceGroup å¹¶è®¡ç®—å…¶åŒ…å« seq çš„ #uncached_token. è¿™é‡Œä¸éœ€è¦ #cached_token å› ä¸ºè‹¥ä½¿ç”¨ chunked prefillï¼Œè¯¥ä¿¡æ¯å·²ç»åœ¨ç¬¬ä¸€æ¬¡ prefill æ—¶ä½¿ç”¨ï¼Œå¦‚æœä¸ä½¿ç”¨é‚£ä¹ˆä»–å°±æ˜¯è¿›è¡Œ decoding çš„ seq ï¼Œä¸éœ€è¦ç”¨åˆ°è¿™ä¸ªä¿¡æ¯ã€‚</li>
<li>ä» running ç§»é™¤è¯¥ SequenceGroup. å¾ªç¯è°ƒç”¨ <code>Scheduler._can_append_slots()</code> æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç©ºé—´å­˜å‚¨è¯¥ SequenceGroup çš„ KV Cacheï¼Œè‹¥ä¸èƒ½ï¼Œè¿›å…¥æŠ¢å é€»è¾‘</li>
<li>ä» budget ä¸­å‡å»å½“å‰ SequenceGroup çš„ token å’Œ seq æ•°</li>
<li>è‹¥ running æœ‰å…¶ä»– SequenceGroupï¼ŒæŠ¢å æœ€ä½ä¼˜å…ˆçº§ï¼ˆé˜Ÿåˆ—å°¾éƒ¨ï¼‰çš„ï¼Œè‹¥è¯¥ SequenceGroup åªæœ‰ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„ Sequence åˆ™æŠ¢å æ¨¡å¼ä¸º RECOMPUTE åŠ å…¥åˆ° <code>preempted</code>ï¼Œå¦åˆ™ä¸º SWAP åŠ å…¥åˆ° <code>swapped_out</code>.</li>
<li>åˆ†é… slot å¹¶æ›´æ–° blocks_to_copyï¼Œæ ¹æ®è¯¥ Sequence å¤„äº decoding(ç”Ÿæˆ 1 ä¸ª token çš„ KV Cache ) æˆ–è€… prefill(ç”Ÿæˆ #uncached_token çš„ KV Cache) åŠ å…¥åˆ° <code>prefill_seq_group</code> æˆ–è€… <code>decode_seq_groups</code>ï¼Œå¹¶æ›´æ–° budget.</li>
<li>è¿”å› decode_seq_groupsï¼šå­˜å‚¨ decoding  SequenceGroup. prefill_seq_groupsï¼šå­˜å‚¨åˆ†å— prefill  SequenceGroup. preemptedï¼šè¢«æŠ¢å éœ€é‡æ–°è®¡ç®—çš„ SequenceGroup. swapped_outï¼šè¢«äº¤æ¢åˆ° CPU çš„ SequenceGroup. keys_to_swap_out å’Œ keys_to_copyï¼šå†…å­˜å—äº¤æ¢å’Œå¤åˆ¶çš„æ˜ å°„</li>
</ol>
<h2 id="_schedule_swapepd">_schedule_swapepd()</h2>
<ol>
<li>å¾ªç¯éå† swapped é˜Ÿåˆ—ï¼Œå–å‡ºé˜Ÿåˆ—head éƒ¨çš„ SequenceGroupï¼Œè°ƒç”¨ <code>BlockManager.can_swap_in()</code> (å®é™…ä¸Šæ˜¯ SWAPPED çŠ¶æ€çš„ <code>can_swap</code>)</li>
<li>è·å– SequenceGroup ä¸­å¤„äº SWAPPED çš„ Sequence ä¸ªæ•°å’Œ token ä¸ªæ•°ï¼Œæ˜¯å¦æ»¡è¶³é¢„ç®—ã€‚</li>
<li>è°ƒç”¨ <code>_swap_in</code>(å®é™…ä¸Šæ˜¯ <code>BlockManager.swap_in()</code>) æ‰§è¡Œäº¤æ¢ï¼Œæ›´æ–° blocks_to_swap_inï¼Œå°† Sequence çŠ¶æ€ç”± SWAPPED å˜ä¸º RUNNING.</li>
<li>è°ƒç”¨ <code>_append_slots</code> ç»™è¢«æ¢å…¥çš„ Sequence åˆ†é… block.</li>
<li>æ ¹æ® SequenceGroup çš„çŠ¶æ€æ·»åŠ åˆ°ä¸åŒé˜Ÿåˆ—ã€‚</li>
<li>è¿”å›blocks_to_swap_inï¼šè®°å½•éœ€è¦ä» CPU äº¤æ¢åˆ° GPU çš„å—æ˜ å°„ã€‚blocks_to_copyï¼šè®°å½•éœ€è¦å¤åˆ¶çš„å—æ˜ å°„ï¼ˆä¾‹å¦‚å†™æ—¶å¤åˆ¶ï¼‰ã€‚decode_seq_groups å’Œ prefill_seq_groupsï¼šåˆ†åˆ«å­˜å‚¨ decoding å’Œ prefill  SequenceGroup. infeasible_seq_groupsï¼šå­˜å‚¨æ— æ³•è°ƒåº¦çš„ SequenceGroup. swapped_queueï¼šå¼•ç”¨äº¤æ¢é˜Ÿåˆ—ã€‚leftover_swappedï¼šæš‚å­˜æ— æ³•ç«‹å³è°ƒåº¦çš„ SequenceGroup.</li>
</ol>
<h2 id="_schedule_chunked_prefill">_schedule_chunked_prefill()</h2>
<p>ä¸»è¦æ€æƒ³æ˜¯: 1.å®‰æ’å°½å¯èƒ½å¤šçš„ decoding è¯·æ±‚ã€‚2.è°ƒåº¦æœªå®Œæˆçš„ prefill è¯·æ±‚ã€‚3.è°ƒåº¦äº¤æ¢è¯·æ±‚ã€‚4.å®‰æ’æ–°çš„ prefill è¯·æ±‚ã€‚</p>
<ol>
<li>åˆå§‹åŒ– budgetï¼Œé™åˆ¶æœ€å¤§æ‰¹å¤„ç† token æ•°å’Œ seq æ•°ã€‚</li>
<li>ä» running å’Œ waiting ç”Ÿæˆ <code>PartialPrefillMetadata</code></li>
</ol>
<ul>
<li>prefills: running å’Œ waiting ä¸­æœªå®Œæˆ prefill çš„ #SequenceGroup.</li>
<li>long_prefills: running ä¸­éœ€è¦è¿›è¡Œ prefill çš„ token æ•°å¾ˆå¤šçš„ #SequenceGroup.</li>
<li>waiting_long_prefills: waiting ä¸­éœ€è¦è¿›è¡Œä¸”èƒ½è¿›è¡Œçš„ (æœªè¶…è¿‡ ScheduleConfig é™åˆ¶) prefill çš„ token æ•°å¾ˆå¤šçš„ #SequenceGroup.</li>
</ul>
<ol start="3">
<li>è°ƒç”¨ <code>_schedule_running</code>.</li>
<li>åœ¨ running è°ƒåº¦è¿”å›ä¸­æ— æ— æŠ¢å æˆ–äº¤æ¢æ—¶(è¯´æ˜æœ‰è¶³å¤Ÿç©ºé—´) æ‰§è¡Œ <code>_schedule_swapped</code></li>
<li>è°ƒç”¨ <code>_schedule_prefills</code>.</li>
<li>æ›´æ–° waitingï¼Œæ·»åŠ  running è°ƒåº¦ä¸­è¿”å›çš„è¢«æŠ¢å çš„ seq  <code>running_scheduled.preempted</code>.</li>
<li>æŒ‰ä¼˜å…ˆçº§æ›´æ–° running.</li>
<li>swapped_in.decode_seq_groupsï¼šäº¤æ¢å›æ¥çš„ decoding è¯·æ±‚ã€‚</li>
<li>swapped_in.prefill_seq_groupsï¼šäº¤æ¢å›æ¥çš„ prefill è¯·æ±‚ã€‚</li>
<li>running_scheduled.decode_seq_groupsï¼šè¿è¡Œä¸­çš„ decoding è¯·æ±‚ã€‚</li>
<li>running_scheduled.prefill_seq_groupsï¼ˆæŒ‰å®Œæˆé¡ºåºï¼‰ï¼šæœªå®Œæˆçš„åˆ†å— prefill ã€‚ä½¿ç”¨ _order_finishing_prefills_first ç¡®ä¿å³å°†å®Œæˆçš„ prefill ä¼˜å…ˆï¼Œä¾¿äºä¸‹ä¸€è½®è½¬ä¸º decoding.</li>
<li>prefills.seq_groupsï¼šæ–° prefill è¯·æ±‚ã€‚</li>
<li>å°†è¿è¡Œé˜Ÿåˆ—ä¸­äº¤æ¢å‡ºå»çš„ <code>running_scheduled.swapped_out</code> æ·»åŠ åˆ° swapped.</li>
<li>æŒ‰é¡ºåºç»„åˆæ‰€æœ‰è°ƒåº¦çš„ SequenceGroup: prefill ä¼˜å…ˆï¼ˆæ»¡è¶³æ³¨æ„åŠ›æœºåˆ¶å‡è®¾ï¼‰ï¼Œdecoding æ¬¡ä¹‹ã€‚</li>
<li>è°ƒæ•´ lookahead_slots æ•°é‡ã€‚è‹¥æ‰€æœ‰è¢«è°ƒåº¦çš„å‡ä¸º prefill ä¸”æœªå¯ç”¨å¤šæ­¥è°ƒåº¦ï¼Œè®¾ç½® num_lookahead_slots = 0(é¿å…æ¨æµ‹ decoding è·¯å¾„). å¦åˆ™ï¼Œä½¿ç”¨ running è®¡ç®—çš„ lookaheadh slots æ•°é‡ã€‚</li>
</ol>
<h2 id="_schedule_default">_schedule_default</h2>
<p>å°½å¯èƒ½å¤šåœ°æ‰¹å¤„ç† prefill è¯·æ±‚ï¼Œç„¶åè°ƒåº¦ decoding è¯·æ±‚. åœ¨ GPU å†…å­˜å‹åŠ›ä¸‹ï¼Œéœ€è¦ preempt æˆ– swap out è¿è¡Œä¸­çš„ decoding è¯·æ±‚ã€‚</p>
<ol>
<li>swapped ä¸ºç©ºåˆ™è¿›è¡Œ <code>_schedule_prefills</code>.</li>
<li>å¦‚æœæ²¡æœ‰è°ƒåº¦ä»»ä½• prefill è¯·æ±‚ï¼Œè°ƒç”¨ <code>_schedule_running</code>.</li>
<li>å¦‚æœ running è°ƒåº¦ç»“æœä¸­æ²¡æœ‰å‘ç”ŸæŠ¢å æˆ–æ¢å‡ºæ—¶ (å¦åˆ™è¯´æ˜èµ„æºä¸å¤Ÿ)ï¼Œæ‰§è¡Œ <code>_schedule_swapped</code>.</li>
<li>æ›´æ–° waiting, running &amp; swapped ä¸‰ä¸ªé˜Ÿåˆ—ã€‚</li>
</ol>
<h2 id="after-schedule">After schedule</h2>
<p>è°ƒåº¦ç»“æœè¿”å›åï¼Œ</p>
<ol>
<li>éå†è°ƒåº¦ç»“æœä¸­çš„ SequenceGroup</li>
<li>éå†è¯¥ SequenceGroup ä¸­çŠ¶æ€ä¸º RUNNING çš„ Sequence. è·å–å…¶æ•°æ®ï¼Œå¯¹åº”çš„ BlockID åˆ—è¡¨ï¼Œå¹¶æ›´æ–°å…¶è®¿é—®æ—¶é—´ã€‚è‹¥ä½¿ç”¨ prefix_caching, åˆ™è°ƒç”¨ <code>BlockManager.get_common_computed_block_ids()</code> è·å–å…±äº«çš„å·²è®¡ç®—çš„éƒ¨åˆ†çš„ BlockID åˆ—è¡¨ã€‚</li>
<li>å¦‚æœè¯¥ SequenceGroup å¤„äº prefill é˜¶æ®µï¼Œåˆ™åˆ¤æ–­è¿™æ¬¡è°ƒåº¦åæ˜¯å¦èƒ½å®Œæˆ prefill.</li>
<li>æ„é€ è¿”å›ç»“æœï¼Œæ ‡è®°æ‰€æœ‰è°ƒåº¦ SequenceGroup çš„ blocks ä¸ºå·²è®¡ç®—ã€‚</li>
</ol>
<h1 id="blockspacemanager">BlockSpaceManager</h1>
<p>ç”¨äºå°† SequenceGroup æ“ä½œæ˜ å°„åˆ°å…¶åŒ…å«çš„å¯¹åº”ç»„ä»¶çš„æ“ä½œã€‚</p>
<ul>
<li>CpuGpuBlockAlloctor: æ ¹æ®æ˜¯å¦é‡‡ç”¨ prefix caching åˆ†åˆ«ä¸º CPU å’Œ GPU åˆå§‹åŒ–ä¸€ä¸ª Alloctor
<ul>
<li><a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/core/block/prefix_caching_block.py#L53">PrefixCachingBlockAlloctor</a>: åŸºäºå“ˆå¸Œå€¼ç»´æŠ¤ block çš„Cache)é‡ç”¨å…·æœ‰ç›¸åŒå“ˆå¸Œå€¼çš„ blockï¼Œä»¥é¿å…å†—ä½™çš„å†…å­˜åˆ†é…ã€‚
<ul>
<li><code>Dict[PrefixHash, BlockId]</code> å°†ç”¨äº prefix caching blocks çš„å“ˆå¸Œå€¼ä¸å…¶ BlockID å¯¹åº”ã€‚</li>
<li><code>Dict[BlockId, BlockTracker]</code> ä¸ºæ¯ä¸ªç‰©ç† block åˆå§‹åŒ–ä¸€ä¸ª BlockTracker.</li>
<li><a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/core/block/naive_block.py#L13">NaiveBlockAllocator</a> ç”¨äºåˆ†é…ä¸ä½œä¸º prefix caching çš„ blocks. æœ‰ä¸€ä¸ª <code>RefCounter</code> è¡¨ç¤ºæŸä¸ªç‰©ç† block è¢«å¤šå°‘é€»è¾‘ block æŒ‡å‘ã€‚</li>
<li><code>Evictor</code> é‡‡ç”¨ LRU ç­–ç•¥é©±é€å·²ç»Cache) blocks.</li>
<li><code>CopyOnWriterTracker</code> ç”¨äºå°†åŸå…ˆçš„ block ID æ˜ å°„åˆ°ç›®çš„ block ID.</li>
</ul>
</li>
</ul>
</li>
<li>Dict[SeqId, BlockTable]: <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/core/block/block_table.py#L11">BlockTable</a> ç”¨äºå°†å•ä¸ª seq çš„ KV Cache æ˜ å°„åˆ°ç‰©ç†å†…å­˜åˆ†é…ã€‚ä¼šåœ¨è°ƒç”¨ <a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/core/block_manager.py#L148">_allocate_sequence()</a> æ—¶è¢«åˆå§‹åŒ–ã€‚åŒ…å«ä¸€ä¸ª <a href="https://github.com/vllm-project/vllm/blob/main/vllm/core/block/common.py#L231">BlockList</a> (block åˆ—è¡¨å’Œä¸€ä¸ªè¡¨ç¤ºå¯¹åº” ID çš„ int åˆ—è¡¨) å’Œ BlockpaceManager çš„ BlockAllocator.</li>
<li>ComputedBlocksTracker: ç»´æŠ¤ä¸€ä¸ª <code>Dict[SeqId, List[int]]</code> ( seq idåˆ° seq å—å“ˆå¸Œåˆ—è¡¨çš„æ˜ å°„)ã€‚Cache)ä¸ª seq çš„å®Œæ•´å— (å—å…¨éƒ¨è¢«å æ»¡) çš„å“ˆå¸Œå€¼ã€‚å½“ä¸€ä¸ª seq è¿›è¡Œ decoding æ—¶ï¼Œä¹Ÿç›¸åº”æ›´æ–° seq çš„å“ˆå¸Œå€¼ã€‚è¿˜æœ‰ä¸€ä¸ª <code>Dict[int, int]</code> ( seq idåˆ°å·²è®¡ç®— token æ•°çš„æ˜ å°„)</li>
</ul>
<h2 id="can_allocate">can_allocate</h2>
<p>åœ¨ <code>_schedule_prefills</code> ä¸­è¢«è°ƒç”¨ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">can_allocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">seq_group</span><span class="p">:</span> <span class="n">SequenceGroup</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">num_lookahead_slots</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AllocStatus</span><span class="p">:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>å–å‡ºè¯¥ SequenceGroup ä¸­å¤„äº WAITING çŠ¶æ€çš„ç¬¬ä¸€ä¸ª Sequence (i.e. prompt).</li>
<li>è°ƒç”¨ <code>BlockTable.get_num_required_blocks()</code> è®¡ç®—å­˜å‚¨ token å’Œ lookahead slots æ‰€éœ€çš„æœ€å° block æ•° (å‡è®¾æ—  prefix caching), i.e. <code>cdiv(len(token_ids) + num_lookahead_slots, block_size)</code>.</li>
<li>è°ƒç”¨ <code>BlockAlloctor.get_num_free_blocks()</code> è·å– GPU ä¸Šç©ºé—²çš„ block æ•° (é prefix_caching ä¸­çš„ç©ºé—²ä¸ªæ•° + å¯ä»¥è¢«é©±é€çš„ä¸ªæ•°).</li>
<li>è¿”å›åˆ†é…çŠ¶æ€</li>
</ol>
<ul>
<li>NEVER: <code>#total - #required &lt; #watermark</code></li>
<li>OK: <code>#free  - #required &gt;= #watermark</code></li>
<li>LATER: <code>#free  - #required &lt; #watermark</code></li>
</ul>
<h2 id="allocate">allocate</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">allocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_group</span><span class="p">:</span> <span class="n">SequenceGroup</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>åœ¨ <code>_schedule_prefills</code> ä¸­æ­¥éª¤ 4 ä¸­è°ƒç”¨çš„ <code>_allocate_and_set_running</code> å†…éƒ¨è¢«è°ƒç”¨ã€‚</p>
<ol>
<li>å–å‡ºè¯¥ SequenceGroup ä¸­å¤„äº WAITING çŠ¶æ€çš„ç¬¬ä¸€ä¸ª Sequence (i.e. prompt).</li>
<li>è°ƒç”¨ <code>BlockManager._allocate_sequence()</code> åˆ›å»ºä¸€ä¸ª BlockTableï¼Œåœ¨è·å– token_ids åˆ—è¡¨åè°ƒç”¨ <code>BlockTable.allocate()</code> ä¸ºè¯¥ Sequence åˆ†é… blocks.</li>
<li>å°† token_ids æŒ‰ _block_size å¤§å°è¿›è¡Œåˆ†å—ã€‚æœ€åä¸€å—å¯èƒ½ä¸èƒ½å æ»¡ä¸€ä¸ª block.</li>
<li>å¯¹äºèƒ½å¤Ÿå æ»¡ä¸€ä¸ª block çš„ token_ids åˆ†å—ï¼Œè°ƒç”¨ <code>BlockAlloctor.allocate_immutable_block()</code>. è¯¥å‡½æ•°ä¼˜å…ˆä»Cache)æŸ¥æ‰¾æ˜¯å¦å·²æœ‰ç›¸åŒå†…å®¹çš„å—ï¼Œè‹¥æœ‰åˆ™ç›´æ¥å¤ç”¨è¯¥å—å¹¶å¢åŠ å…¶å¼•ç”¨è®¡æ•°ï¼›å¦åˆ™è°ƒç”¨ <code>BlockAlloctor.allocate_mutable_blocks()</code> åˆ†é…ä¸€ä¸ªæ–°çš„ blockï¼Œå¹¶å°† token_ids æ·»åŠ åˆ°è¯¥ block ä¸­. è¯¥å‡½æ•°ä¼šå°è¯•ä»é prefix caching blocks ä¸­åˆ†é…ä¸€ä¸ª block_idï¼Œè‹¥æ²¡æ‰¾åˆ°åˆ™ä¼šé©±é€ä¸€ä¸ªã€‚</li>
<li>å¯¹äºæœ€åä¸€ä¸ªå¯èƒ½è¢«æ²¡å æ»¡çš„ block è°ƒç”¨ <code>BlockAlloctor.allocate_mutable_blocks()</code>.</li>
</ol>
<h2 id="can_append_slots">can_append_slots</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">can_append_slots</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_group</span><span class="p">:</span> <span class="n">SequenceGroup</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">num_lookahead_slots</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ç¡®å®š GPU KV Cache ä¸­æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç©ºé—´æ¥ç»§ç»­ç”ŸæˆæŒ‡å®šçš„ SequenceGroup. ä¸Šå±‚æ¥å£ä¸º <code>Scheduler._can_append_slots()</code>ï¼Œåœ¨ <code>_schedule_running</code> ä¸­æ­¥éª¤ 2 ä¸­ç¡®å®šæ˜¯å¦éœ€è¦è¿›è¡ŒæŠ¢å æ—¶è¢«è°ƒç”¨ã€‚</p>
<ol>
<li>éå†è¯¥ Sequence Group ä¸­å¤„äº RUNNING çŠ¶æ€çš„ Sequence å¯¹åº”çš„ BlockTable</li>
<li>è°ƒç”¨ <code>BlockTable.get_unseen_token_ids()</code> è·å–è¯¥ Sequence è¿˜æœªè¢«Cache) token éƒ¨åˆ†ã€‚</li>
<li>è°ƒç”¨ <code>BlockTable.get_num_blocks_touched_by_append_slots()</code> è·å–Cache)ä½™éƒ¨åˆ†å’Œ lookahead éƒ¨åˆ†éœ€è¦å‡ ä¸ª block.</li>
<li>è°ƒç”¨ <code>BlockAlloctor.get_num_free_blocks()</code> è·å– GPU ä¸Šç©ºé—²çš„ block æ•°.</li>
<li>éœ€è¦ä¸ªæ•°å°äºç©ºé—²ä¸ªæ•°è¿”å› True.</li>
</ol>
<h2 id="append_slots">append_slots</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">append_slots</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_lookahead_slots</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ä¸Šå±‚æ¥å£ä¸º <code>Scheduler._append_slots()</code>. åœ¨ <code>_schedule_running</code> ä¸­æ£€æŸ¥åˆ°æœ‰ç©ºé—´æ·»åŠ ï¼Œ<code>_schedule_swapped</code> ä¸­æœ‰ budget è¿›è¡Œæ¢å…¥ï¼Œ<code>_schedule_prefills</code> ä¸­å…è®¸è¿›è¡Œ chunked prefill æ—¶è¢«è°ƒç”¨ã€‚</p>
<ol>
<li>è°ƒç”¨ <code>BlockTable.append_token_ids()</code>. è¯¥æ–¹æ³•å°† tokens æ·»åŠ åˆ° BlockTable ä¸­çš„ç°æœ‰ block ä¸­ã€‚ä¼šè°ƒç”¨ <code>BlockTable.ensure_num_empty_slots()</code>ï¼Œ å®ƒæŸ¥çœ‹å½“å‰èƒ½å¤Ÿå®¹çº³å¤šå°‘ä¸ª token. å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ç©ºé—´ï¼Œåˆ™ä½¿ç”¨ <code>BlockAlloctor.allocate_mutable_block()</code> æ–¹æ³•åˆ†é…æ–° block.</li>
<li>è°ƒç”¨ <code>BlockAllocator.clear_copy_on_writes()</code> è¿”å›ä¸€ä¸ªæ˜ å°„æº block ID åˆ°å½“å‰ COW çš„ç›®æ ‡ block ID çš„å…ƒç»„çš„åˆ—è¡¨.</li>
</ol>
<h2 id="_can_swap">_can_swap</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_can_swap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">              <span class="n">seq_group</span><span class="p">:</span> <span class="n">SequenceGroup</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">              <span class="n">device</span><span class="p">:</span> <span class="n">Device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">              <span class="n">status</span><span class="p">:</span> <span class="n">SequenceStatus</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">              <span class="n">num_lookahead_slots</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AllocStatus</span><span class="p">:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>æ ¹æ® status åŒºåˆ†ä¸Šå±‚æ¥å£: RUNNING/SWAPPED è¡¨ç¤ºéœ€è¦æŠŠè¯¥ SequenceGroup å¤„äº RUNNING/SWAPPED çŠ¶æ€çš„ Sequence å¯¹åº”çš„ blocks ä» GPU/CPU æ¢åˆ° CPU/GPU.</p>
<ol>
<li>è·å– SequenceGroup ä¸­ç¬¦åˆæŒ‡å®šçŠ¶æ€çš„ seq  Sequenceï¼Œç„¶åæ ¹æ® SeqID è·å–å¯¹åº”çš„ BlockTable.</li>
<li>è°ƒç”¨ <code>BlockTable.get_num_blocks_touched_by_append_slots()</code> è®¡ç®—æ·»åŠ æœªå­˜å‚¨ token åŠ ä¸Š lookahead_slots æ‰€éœ€çš„ block æ•°é‡ã€‚</li>
<li>è°ƒç”¨ <code>BlockAlloctor.get_num_full_blocks_touched()</code> è·å–å½“å‰æœ‰è¢«ä½¿ç”¨çš„ block æ•°é‡ã€‚</li>
<li>å¦‚æœæ€»å—æ•°å°äºè¢«ä½¿ç”¨çš„åŠ ä¸Šéœ€è¦çš„ block æ•°é‡ è¿”å› Never. å¦‚æœç©ºé—²å—å‡å» è¢«ä½¿ç”¨çš„åŠ ä¸Šéœ€è¦çš„ block æ•°é‡åä»å¤§äºç­‰äº watermark_blocksï¼Œè¿”å› OK. å¦åˆ™ä¸º LATER.</li>
</ol>
<h2 id="swap_in">swap_in</h2>
<p>è°ƒç”¨çš„æ˜¯  <code>self.block_allocator.swap(blocks=blocks, src_device=Device.CPU, dst_device=Device.GPU)</code>ï¼Œå³ blocks ä»åŸè®¾å¤‡çš„æ¢å‡ºï¼Œæ¢å…¥åˆ°ç›®çš„è®¾å¤‡ã€‚
è¿›ä¸€æ­¥åˆ™æ˜¯ <code>BlockAlloctor.swap_in()</code>ï¼Œè¯¥å‡½æ•°éå†ä¼ å…¥çš„ blocksï¼Œè‹¥å·²ç»è¢«å æ»¡è°ƒç”¨ <code>BlockAlloctor.allocate_immutable_block()</code>. å¦åˆ™è°ƒç”¨ <code>BlockAlloctor.allocate_mutable_blocks()</code> åˆ†é…ä¸€ä¸ªæ–°çš„ block åå°†åŸ blockçš„ token æ•°æ®è¿½åŠ åˆ°æ–° block.</p>
<h2 id="swap_out">swap_out</h2>
<p>åŒä¸Šï¼Œæœ€ç»ˆè°ƒç”¨çš„æ˜¯ <code>BlockAlloctor.swap_out()</code>. è¯¥å‡½æ•°å¯¹ä¼ å…¥çš„æ¯ä¸ª block è°ƒç”¨ <code>_free_block_id</code>ï¼Œé€ä¸ªå¤„ç†é‡Šæ”¾é€»è¾‘ã€‚è‹¥ block æœ‰å“ˆå¸Œå€¼ï¼Œrefcount -1ï¼Œè‹¥å‡å»åä¸º 0 åˆ™å°† block ä¿¡æ¯æ·»åŠ åˆ° evictor ä¸­ï¼Œä»è·Ÿè¸ªç³»ç»Ÿä¸­ç§»é™¤ï¼Œç„¶åè®¾ç½® BlockId ä¸º None. å¦åˆ™å°±ç›´æ¥è®¾ç½®ä¸º None. è‹¥æ— å“ˆå¸Œå€¼åˆ™é‡Šæ”¾ BlockIdï¼Œå‡å»å¯¹åº”çš„ refcountï¼Œä½†ä¿ç•™ block å¯¹è±¡æœ¬èº«.</p>
<h1 id="attention">Attention</h1>
<p><a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/attention/backends/xformers.py#L354">XFormersImpl</a> ä¸­ä½¿ç”¨äº† vllm è‡ªå·±å†™çš„ PagedAttention kernel.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">XFormersImpl</span><span class="p">(</span><span class="n">AttentionImpl</span><span class="p">[</span><span class="n">XFormersMetadata</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">head_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">num_kv_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">alibi_slopes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">      <span class="n">sliding_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">      <span class="n">kv_cache_dtype</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">blocksparse_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">logits_soft_cap</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">attn_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">AttentionType</span><span class="o">.</span><span class="n">DECODER</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>å…¶ä¸­ <code>attn_type</code> åˆ†ä¸ºå››ç§ï¼Œä¸‹é¢æˆ‘ä»¬ä¸»è¦åˆ†æ DECODER çš„æƒ…å†µã€‚</p>
<ul>
<li>DECODER: ä½¿ç”¨ decoding å™¨çš„ self-attention block table æ¥Cache)KV(GPT).</li>
<li>ENCODER: ä¸è¿›è¡Œ KV Cache)ç”¨äº Encoder-Decoder æ¨¡ç¼–ç å™¨åˆ†æ”¯ã€‚ç¼–ç å™¨é€šå¸¸ä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªè¾“å…¥ seq ã€‚</li>
<li>ENCODER-ONLY: ä¸è¿›è¡Œ KV Cache)BERT).</li>
<li>ENCODER_DECODER: ç”¨äºç¼–ç å™¨- decoding å™¨æ¨¡å‹ä¸­çš„äº¤å‰æ³¨æ„åŠ›éƒ¨åˆ†ï¼Œå…¶ä¸­ KV  seq é•¿åº¦ä¸ç¼–ç å™¨ seq é•¿åº¦ä¸€è‡´(T5).</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">layer</span><span class="p">:</span> <span class="n">AttentionLayer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">query</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># [num_tokens, num_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>  <span class="c1"># [num_tokens, num_kv_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>  <span class="c1"># [num_tokens, num_kv_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">kv_cache</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># [2, num_blocks, block_size * num_kv_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">attn_metadata</span><span class="p">:</span> <span class="s2">&#34;XFormersMetadata&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><a href="https://github.com/vllm-project/vllm/blob/5eeabc2a4400fde9b030f2f72746a2b03db059bd/vllm/attention/backends/.py#L104">AttentionMetadata</a> ç±»å®šä¹‰å¦‚ä¸‹</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dataclass</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">AttentionMetadata</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Attention metadata for prefill and decode batched together.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_prefills</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># prefill è¯·æ±‚çš„æ€»æ•°</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_prefill_tokens</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># æ‰€æœ‰ prefill è¯·æ±‚ä¸­çš„ token æ€»æ•°ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_decode_tokens</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># decodeing token çš„æ•°é‡ï¼Œç­‰åŒäº decoding è¯·æ±‚çš„æ•°é‡</span>
</span></span><span class="line"><span class="cl">    <span class="n">slot_mapping</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>  <span class="c1"># (num_tokens,)ï¼ŒæŒ‡å®šæ¯ä¸ªè¾“å…¥ token å­˜å‚¨åˆ° KV cache ä¸­çš„ slot ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># block_idx = x // block_size, block_offset = x % block_size</span>
</span></span><span class="line"><span class="cl">    <span class="n">multi_modal_placeholder_index_maps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="nb">str</span><span class="p">,</span> <span class="n">MultiModalPlaceholderMap</span><span class="o">.</span><span class="n">IndexMap</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">    <span class="n">enable_kv_scales_calculation</span><span class="p">:</span> <span class="nb">bool</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>forward æ–¹æ³•å¦‚ä¸‹ï¼Œç®€åŒ–äº†æˆäº† DECODER æƒ…å†µçš„é€»è¾‘ã€‚
ä¸»è¦æµç¨‹ä¸º</p>
<ol>
<li>è°ƒç”¨ <code>PagedAttention.split_kv_cache</code> åˆ†ç¦»å¹¶ reshape KV Cache å¼ é‡å è°ƒç”¨ PagedAttention.write_to_paged_cache`
å†™å…¥å½“å‰ key å’Œ value åˆ°Cache)ã€‚</li>
<li>åˆ†ç¦» prefill å’Œ decoding çš„ tokenï¼Œåˆå§‹åŒ–è¾“å‡ºã€‚å¯¹äº prefill éƒ¨åˆ†æ ¹æ®æ˜¯å¦é‡‡ç”¨äº† prefix_caching è°ƒç”¨ <code>self._run_memory_efficient_xformers_forward</code> æˆ– <code>PagedAttention.forward_prefix</code> è®¡ç®—æ³¨æ„åŠ›ã€‚</li>
<li>è°ƒç”¨ <code>get_seq_len_block_table_args</code> è·å– decoding Sequence å¯¹åº”çš„ BlockTableåè°ƒç”¨ <code>PagedAttention.forward_decode</code> è®¡ç®—æ³¨æ„åŠ›ã€‚</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">layer</span><span class="p">:</span> <span class="n">AttentionLayer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">query</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># [num_tokens, num_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>    <span class="c1"># [num_tokens, num_kv_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># [num_tokens, num_kv_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">kv_cache</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># [2, num_blocks, block_size * num_kv_heads * head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">attn_metadata</span><span class="p">:</span> <span class="s2">&#34;XFormersMetadata&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">    <span class="c1"># å°† query é‡å¡‘ä¸º [num_tokens, num_heads, head_size]</span>
</span></span><span class="line"><span class="cl">    <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># key å’Œ value å¿…é¡»éç©ºï¼ˆè‡ªæ³¨æ„åŠ›è¦æ±‚ï¼‰ï¼Œé‡å¡‘ä¸º [num_tokens, num_kv_heads, head_size]</span>
</span></span><span class="line"><span class="cl">    <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># å¦‚æœ KV Cache)ç©ºï¼Œå¤„ç†Cache)è¾‘</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">kv_cache</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ä» kv_cache åˆ†ç¦»å‡º key_cache å’Œ value_cache</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># key_cache: [num_blocks, num_kv_heads, head_size/x, block_size, x]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># value_cache: [num_blocks, num_kv_heads, head_size, block_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">key_cache</span><span class="p">,</span> <span class="n">value_cache</span> <span class="o">=</span> <span class="n">PagedAttention</span><span class="o">.</span><span class="n">split_kv_cache</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">kv_cache</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># æ›´æ–°è‡ªæ³¨æ„åŠ›çš„ KV Cache)        # ä½¿ç”¨ attn_metadata.slot_mapping æŒ‡å®š token å­˜å‚¨ä½ç½®</span>
</span></span><span class="line"><span class="cl">        <span class="n">PagedAttention</span><span class="o">.</span><span class="n">write_to_paged_cache</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">key_cache</span><span class="p">,</span> <span class="n">value_cache</span><span class="p">,</span> <span class="n">attn_metadata</span><span class="o">.</span><span class="n">slot_mapping</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">kv_cache_dtype</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">_k_scale</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">_v_scale</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># è·å– prefill å’Œ decoding é˜¶æ®µçš„ token æ•°é‡</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="n">num_prefill_query_tokens</span><span class="p">,</span> <span class="n">num_prefill_kv_tokens</span><span class="p">,</span> <span class="n">num_decode_query_tokens</span><span class="p">)</span> <span class="o">=</span> \
</span></span><span class="line"><span class="cl">        <span class="n">get_num_prefill_decode_query_kv_tokens</span><span class="p">(</span><span class="n">attn_metadata</span><span class="p">,</span> <span class="n">AttentionType</span><span class="o">.</span><span class="n">DECODER</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># åˆ›å»ºè¾“å‡ºå¼ é‡ä¸ query ç›¸åŒ</span>
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># åˆ†ç¦» prefill å’Œ decoding çš„ QKV</span>
</span></span><span class="line"><span class="cl">    <span class="n">decode_query</span> <span class="o">=</span> <span class="n">query</span><span class="p">[</span><span class="n">num_prefill_query_tokens</span><span class="p">:]</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">    <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="p">[:</span><span class="n">num_prefill_query_tokens</span><span class="p">]</span>     
</span></span><span class="line"><span class="cl">    <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[:</span><span class="n">num_prefill_kv_tokens</span><span class="p">]</span>             
</span></span><span class="line"><span class="cl">    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="n">num_prefill_kv_tokens</span><span class="p">]</span>         
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># å¤„ç† prefill é˜¶æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">prefill_meta</span> <span class="o">:=</span> <span class="n">attn_metadata</span><span class="o">.</span><span class="n">prefill_metadata</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">kv_cache</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">prefill_meta</span><span class="o">.</span><span class="n">block_tables</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># æ™®é€šæ³¨æ„åŠ›ï¼ˆæ— Cache)ç¼€ï¼‰</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_memory_efficient_xformers_forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">prefill_meta</span><span class="p">,</span> <span class="n">attn_type</span><span class="o">=</span><span class="n">AttentionType</span><span class="o">.</span><span class="n">DECODER</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span><span class="p">[:</span><span class="n">num_prefill_query_tokens</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># å‰ç¼€Cache)æ„åŠ›</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="n">PagedAttention</span><span class="o">.</span><span class="n">forward_prefix</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kv_cache_dtype</span><span class="p">,</span> <span class="n">key_cache</span><span class="p">,</span> <span class="n">value_cache</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">prefill_meta</span><span class="o">.</span><span class="n">block_tables</span><span class="p">,</span> <span class="n">prefill_meta</span><span class="o">.</span><span class="n">query_start_loc</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">prefill_meta</span><span class="o">.</span><span class="n">seq_lens_tensor</span><span class="p">,</span> <span class="n">prefill_meta</span><span class="o">.</span><span class="n">max_query_len</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">alibi_slopes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sliding_window</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">_k_scale</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">_v_scale</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span><span class="p">[:</span><span class="n">num_prefill_query_tokens</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># å¤„ç† decoding é˜¶æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">decode_meta</span> <span class="o">:=</span> <span class="n">attn_metadata</span><span class="o">.</span><span class="n">decode_metadata</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># è·å– decoding æ‰€éœ€çš„ seq é•¿åº¦å’Œ BlockTable å‚æ•°</span>
</span></span><span class="line"><span class="cl">        <span class="n">seq_lens_arg</span><span class="p">,</span> <span class="n">max_seq_len_arg</span><span class="p">,</span> <span class="n">block_tables_arg</span> <span class="o">=</span> \
</span></span><span class="line"><span class="cl">            <span class="n">get_seq_len_block_table_args</span><span class="p">(</span><span class="n">decode_meta</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">AttentionType</span><span class="o">.</span><span class="n">DECODER</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># è¿è¡Œ decoding æ³¨æ„åŠ›</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span><span class="p">[</span><span class="n">num_prefill_query_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">PagedAttention</span><span class="o">.</span><span class="n">forward_decode</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">decode_query</span><span class="p">,</span> <span class="n">key_cache</span><span class="p">,</span> <span class="n">value_cache</span><span class="p">,</span> <span class="n">block_tables_arg</span><span class="p">,</span> <span class="n">seq_lens_arg</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">max_seq_len_arg</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kv_cache_dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">alibi_slopes</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">_k_scale</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">_v_scale</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># å°†è¾“å‡º reshape ä¸º [num_tokens, num_heads * head_size]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="write_to_paged_cache">write_to_paged_cache</h2>
<p>è°ƒç”¨çš„æ˜¯å·²ç»æ³¨å†Œåˆ° torch.ops ä¸­çš„ CUDA å‡½æ•°ã€‚å…¶å¯¹åº”çš„ host å‡½æ•°ä¸ºæ¯ä¸ª token åˆ†é…ä¸€ä¸ª CUDA blockï¼Œæ¯ä¸ª CUDA block çš„çº¿ç¨‹æ•°è¢«é™åˆ¶åœ¨æœ€å¤š 512 ä¸ªã€‚ä¸»è¦çš„ kernel å‡½æ•°å¦‚ä¸‹ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="c1">// scalar_t: è¾“å…¥ key å’Œ value çš„æ•°æ®ç±»å‹ï¼ˆå¦‚ floatã€halfï¼‰
</span></span></span><span class="line"><span class="cl"><span class="c1">// cache_t: Cache)key_cache å’Œ value_cache çš„æ•°æ®ç±»å‹ï¼ˆå¦‚ halfã€uint8_tï¼‰
</span></span></span><span class="line"><span class="cl"><span class="c1">// kv_dt: KV Cache) FP8 æ•°æ®ç±»å‹ï¼ˆå¦‚ kAuto æˆ–å…·ä½“ FP8 æ ¼å¼ï¼‰
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">template</span> <span class="o">&lt;</span><span class="kr">typename</span> <span class="kt">scalar_t</span><span class="p">,</span> <span class="kr">typename</span> <span class="kt">cache_t</span><span class="p">,</span> <span class="n">Fp8KVCacheDataType</span> <span class="n">kv_dt</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reshape_and_cache_kernel</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">scalar_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">key</span><span class="p">,</span>    <span class="c1">// [num_tokens, num_heads, head_size]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">scalar_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">value</span><span class="p">,</span>  <span class="c1">// [num_tokens, num_heads, head_size]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">cache_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">key_cache</span><span class="p">,</span>     <span class="c1">// [num_blocks, num_heads, head_size/x, block_size, x]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">cache_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">value_cache</span><span class="p">,</span>   <span class="c1">// [num_blocks, num_heads, head_size, block_size]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int64_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">slot_mapping</span><span class="p">,</span>  <span class="c1">// [num_tokens]ï¼ŒæŒ‡å®šæ¯ä¸ª token çš„Cache)ç½®
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">key_stride</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">value_stride</span><span class="p">,</span>  <span class="c1">// key å’Œ value åœ¨ token ç»´çš„æ­¥å¹…
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">num_heads</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">head_size</span><span class="p">,</span>      <span class="c1">// æ³¨æ„åŠ›head æ•°å’Œæ¯ä¸ªhead çš„ç»´åº¦
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">block_size</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">x</span><span class="p">,</span>             <span class="c1">// Cache)å¤§å°å’Œ key_cache ä¸­ head_size çš„æ‹†åˆ†å› å­
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">float</span><span class="o">*</span> <span class="n">k_scale</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span><span class="o">*</span> <span class="n">v_scale</span><span class="p">)</span>    <span class="c1">// key å’Œ value çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ•°æ®ç±»å‹è½¬æ¢
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">token_idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>  <span class="c1">// host å‡½æ•°å®šä¹‰ block ä¸ªæ•°ä¸ token ä¸ªæ•°ç›¸åŒ
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">slot_idx</span> <span class="o">=</span> <span class="n">slot_mapping</span><span class="p">[</span><span class="n">token_idx</span><span class="p">];</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="c1">// Cache Block
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">block_idx</span> <span class="o">=</span> <span class="n">slot_idx</span> <span class="o">/</span> <span class="n">block_size</span><span class="p">;</span>  <span class="c1">// å—ç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">block_offset</span> <span class="o">=</span> <span class="n">slot_idx</span> <span class="o">%</span> <span class="n">block_size</span><span class="p">;</span>  <span class="c1">// å—å†…åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="n">head_size</span><span class="p">;</span>  <span class="c1">// æ¯ä¸ª token çš„ç»´åº¦æ•°ç›®
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// CUDA Block çº§åˆ«å¹¶è¡Œï¼Œæ¯ä¸ªçº¿ç¨‹å¤„ç†token çš„ä¸€ä¸ªç»´åº¦
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>  
</span></span><span class="line"><span class="cl">    <span class="c1">// è®¡ç®—è¾“å…¥ key å’Œ value çš„æºç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">src_key_idx</span> <span class="o">=</span> <span class="n">token_idx</span> <span class="o">*</span> <span class="n">key_stride</span> <span class="o">+</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">src_value_idx</span> <span class="o">=</span> <span class="n">token_idx</span> <span class="o">*</span> <span class="n">value_stride</span> <span class="o">+</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// è®¡ç®—å½“å‰å¤„ç†çš„head ç´¢å¼•å’Œhead å†…åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">head_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">head_size</span><span class="p">;</span>      <span class="c1">// ç¬¬å‡ ä¸ªhead 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">head_offset</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">head_size</span><span class="p">;</span>   <span class="c1">// head å†…çš„ç¬¬å‡ ä¸ªå…ƒç´ 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">// å°† head_offset æ‹†åˆ†ä¸º x_idx å’Œ x_offsetï¼ˆä»…ç”¨äº key_cacheï¼‰
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">x_idx</span> <span class="o">=</span> <span class="n">head_offset</span> <span class="o">/</span> <span class="n">x</span><span class="p">;</span>       <span class="c1">// head_size/x ç»´çš„ç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">x_offset</span> <span class="o">=</span> <span class="n">head_offset</span> <span class="o">%</span> <span class="n">x</span><span class="p">;</span>    <span class="c1">// x ç»´çš„åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">// è®¡ç®— key_cache çš„ç›®æ ‡ç´¢å¼•ï¼ŒæŒ‰ç»´åº¦é€æ­¥åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">tgt_key_idx</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_idx</span> <span class="o">*</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="p">(</span><span class="n">head_size</span> <span class="o">/</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span>  <span class="c1">// å—åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">head_idx</span> <span class="o">*</span> <span class="p">(</span><span class="n">head_size</span> <span class="o">/</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span>               <span class="c1">// head åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">x_idx</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span>                                    <span class="c1">// head_size/x åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">block_offset</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x_offset</span><span class="p">;</span>                                <span class="c1">// å—å†…å’Œ x åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">// è®¡ç®— value_cache çš„ç›®æ ‡ç´¢å¼•ï¼ŒæŒ‰ç»´åº¦é€æ­¥åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">tgt_value_idx</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_idx</span> <span class="o">*</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="n">head_size</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">+</span>            <span class="c1">// å—åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">head_idx</span> <span class="o">*</span> <span class="n">head_size</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">+</span>                         <span class="c1">// head åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">head_offset</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">+</span>                                  <span class="c1">// head_size åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">block_offset</span><span class="p">;</span>                                               <span class="c1">// å—å†…åç§»
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">// ä»è¾“å…¥å¼ é‡è¯»å–å½“å‰å…ƒç´ 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">scalar_t</span> <span class="n">tgt_key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="n">src_key_idx</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="kt">scalar_t</span> <span class="n">tgt_value</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">src_value_idx</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// æ ¹æ® kv_dt ç±»å‹å†³å®šå­˜å‚¨æ–¹å¼
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="nf">constexpr</span> <span class="p">(</span><span class="n">kv_dt</span> <span class="o">==</span> <span class="n">Fp8KVCacheDataType</span><span class="o">::</span><span class="n">kAuto</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// å¦‚æœæ˜¯ kAutoï¼Œç›´æ¥å­˜å‚¨ï¼Œä¸è¿›è¡Œç±»å‹è½¬æ¢
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="n">key_cache</span><span class="p">[</span><span class="n">tgt_key_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tgt_key</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="n">value_cache</span><span class="p">[</span><span class="n">tgt_value_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tgt_value</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// å¦åˆ™ï¼Œä½¿ç”¨ scaled_convert è¿›è¡Œç±»å‹è½¬æ¢ï¼ˆå¦‚ FP8 é‡åŒ–ï¼‰
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="n">key_cache</span><span class="p">[</span><span class="n">tgt_key_idx</span><span class="p">]</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">          <span class="n">fp8</span><span class="o">::</span><span class="n">scaled_convert</span><span class="o">&lt;</span><span class="kt">cache_t</span><span class="p">,</span> <span class="kt">scalar_t</span><span class="p">,</span> <span class="n">kv_dt</span><span class="o">&gt;</span><span class="p">(</span><span class="n">tgt_key</span><span class="p">,</span> <span class="o">*</span><span class="n">k_scale</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="n">value_cache</span><span class="p">[</span><span class="n">tgt_value_idx</span><span class="p">]</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">          <span class="n">fp8</span><span class="o">::</span><span class="n">scaled_convert</span><span class="o">&lt;</span><span class="kt">cache_t</span><span class="p">,</span> <span class="kt">scalar_t</span><span class="p">,</span> <span class="n">kv_dt</span><span class="o">&gt;</span><span class="p">(</span><span class="n">tgt_value</span><span class="p">,</span> <span class="o">*</span><span class="n">v_scale</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="_run_memory_efficient_xformers_forward">_run_memory_efficient_xformers_forward</h2>
<p>ä¹ŸåŒæ ·ç®€åŒ–æˆ DECODER çš„é€»è¾‘çš„æƒ…å†µ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_run_memory_efficient_xformers_forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">query</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># [num_prefill_tokens, num_heads, head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>    <span class="c1"># [num_prefill_tokens, num_kv_heads, head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># [num_prefill_tokens, num_kv_heads, head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">attn_metadata</span><span class="p">:</span> <span class="s2">&#34;XFormersMetadata&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">original_query</span> <span class="o">=</span> <span class="n">query</span>  <span class="c1"># ä¿å­˜åŸå§‹ queryï¼Œç”¨äºæœ€å reshape è¾“å‡º</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># å¤„ç† GQA/MQA</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># reshape Q to [num_prefill_tokens, num_kv_heads, num_queries_per_kv, head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                           <span class="bp">self</span><span class="o">.</span><span class="n">num_queries_per_kv</span><span class="p">,</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># expand K to [num_prefill_tokens, num_kv_heads, num_queries_per_kv, head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                        <span class="bp">self</span><span class="o">.</span><span class="n">num_queries_per_kv</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># expand V to  [num_prefill_tokens, num_kv_heads, num_queries_per_kv, head_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="bp">self</span><span class="o">.</span><span class="n">num_queries_per_kv</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># è·å–æˆ–è®¾ç½® attention bias</span>
</span></span><span class="line"><span class="cl">    <span class="n">attn_bias</span> <span class="o">=</span> <span class="n">_get_attn_bias</span><span class="p">(</span><span class="n">attn_metadata</span><span class="p">,</span> <span class="n">AttentionType</span><span class="o">.</span><span class="n">DECODER</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">attn_bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">attn_metadata</span><span class="o">.</span><span class="n">seq_lens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>  <span class="c1"># ç¡®ä¿ seq é•¿åº¦ä¿¡æ¯å­˜åœ¨</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alibi_slopes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># åˆ›å»º causal mask</span>
</span></span><span class="line"><span class="cl">            <span class="n">attn_bias</span> <span class="o">=</span> <span class="n">BlockDiagonalCausalMask</span><span class="o">.</span><span class="n">from_seqlens</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">attn_metadata</span><span class="o">.</span><span class="n">seq_lens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">query</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sliding_window</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># å¦‚æœæœ‰æ»‘åŠ¨çª—å£ï¼Œåº”ç”¨å±€éƒ¨æ³¨æ„åŠ›</span>
</span></span><span class="line"><span class="cl">                <span class="n">attn_bias</span> <span class="o">=</span> <span class="n">attn_bias</span><span class="o">.</span><span class="n">make_local_attention</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sliding_window</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">attn_bias</span> <span class="o">=</span> <span class="p">[</span><span class="n">attn_bias</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># ä½¿ç”¨ ALiBi åç½®ï¼ˆçº¿æ€§åç½®æ³¨æ„åŠ›ï¼‰</span>
</span></span><span class="line"><span class="cl">            <span class="n">attn_bias</span> <span class="o">=</span> <span class="n">_make_alibi_bias</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alibi_slopes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">query</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">attn_metadata</span><span class="o">.</span><span class="n">seq_lens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_set_attn_bias</span><span class="p">(</span><span class="n">attn_metadata</span><span class="p">,</span> <span class="n">attn_bias</span><span class="p">,</span> <span class="n">AttentionType</span><span class="o">.</span><span class="n">DECODER</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># æ‰§è¡Œ xFormers é«˜æ•ˆæ³¨æ„åŠ›è®¡ç®—</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alibi_slopes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ä¸º QKV æ·»åŠ  batch</span>
</span></span><span class="line"><span class="cl">        <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">xops</span><span class="o">.</span><span class="n">memory_efficient_attention_forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">attn_bias</span><span class="o">=</span><span class="n">attn_bias</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ALiBi æ¨¡å¼ç›´æ¥ä½¿ç”¨ attn_bias</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">attn_metadata</span><span class="o">.</span><span class="n">seq_lens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">original_query</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># xformers ä¸æ”¯æŒåœ¨è‡ªå®šä¹‰ bias çš„æƒ…å†µä¸‹æ¯ä¸ª seq çš„é•¿åº¦ä¸åŒ</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">seq_len</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">attn_metadata</span><span class="o">.</span><span class="n">seq_lens</span><span class="p">):</span> 
</span></span><span class="line"><span class="cl">            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">seq_len</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="n">xops</span><span class="o">.</span><span class="n">memory_efficient_attention_forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">query</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">key</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">value</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">attn_bias</span><span class="o">=</span><span class="n">attn_bias</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">original_query</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">            <span class="n">start</span> <span class="o">+=</span> <span class="n">seq_len</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># å°†è¾“å‡º reshape ä¸ºåŸå§‹ query </span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">original_query</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="forward_prefix">forward_prefix</h2>
<p>ä¸è€ƒè™‘ ALiBi çš„æƒ…å†µè°ƒç”¨çš„æ˜¯ triton ç¼–å†™çš„ <a href="https://github.com/vllm-project/vllm/blob/d1695758b2f65fd314d1aee71ba2469ceba67a5b/vllm/attention/ops/prefix_prefill.py#L22">_fwd_kernel()</a> æ¯ä¸ªçº¿ç¨‹å—ç‹¬ç«‹å¤„ç†ä¸€ä¸ª Q çš„ä¸€éƒ¨åˆ†ï¼Œå¯¹ KV Cache å’Œ å½“å‰ KV åˆ†åˆ«é‡‡å– flash-attention çš„è®¡ç®—ç­–ç•¥ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span><span class="lnt">255
</span><span class="lnt">256
</span><span class="lnt">257
</span><span class="lnt">258
</span><span class="lnt">259
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">triton</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">triton.language</span> <span class="k">as</span> <span class="nn">tl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@triton.jit</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_fwd_kernel</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># --- è¾“å…¥å¼ é‡ ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">Q</span><span class="p">,</span>  <span class="c1">#  Query å¼ é‡: [total_seq_len, num_heads, head_dim]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># total_seq_len æ˜¯æ‰€æœ‰ batch  seq é•¿åº¦çš„æ€»å’Œï¼Œå½“å‰å—ä¸º [BLOCK_M, BLOCK_DMODEL_PADDED]</span>
</span></span><span class="line"><span class="cl">    <span class="n">K</span><span class="p">,</span>  <span class="c1"># é”®å¼ é‡ï¼ˆå½“å‰è¾“å…¥ï¼‰: [total_seq_len, num_kv_heads, head_dim]</span>
</span></span><span class="line"><span class="cl">    <span class="n">V</span><span class="p">,</span>  <span class="c1"># å€¼å¼ é‡ï¼ˆå½“å‰è¾“å…¥ï¼‰: [total_seq_len, num_kv_heads, head_dim]</span>
</span></span><span class="line"><span class="cl">    <span class="n">K_cache</span><span class="p">,</span>  <span class="c1"># é”®Cache) [num_blocks, num_kv_heads, head_dim, block_size, x]</span>
</span></span><span class="line"><span class="cl">              <span class="c1"># ç”¨äºå­˜å‚¨ä¸Šä¸‹æ–‡éƒ¨åˆ†çš„ K</span>
</span></span><span class="line"><span class="cl">    <span class="n">V_cache</span><span class="p">,</span>  <span class="c1"># å€¼Cache) [num_blocks, num_kv_heads, head_dim, block_size]</span>
</span></span><span class="line"><span class="cl">              <span class="c1"># ç”¨äºå­˜å‚¨ä¸Šä¸‹æ–‡éƒ¨åˆ†çš„ V</span>
</span></span><span class="line"><span class="cl">    <span class="n">B_Loc</span><span class="p">,</span>  <span class="c1"># å—ç´¢å¼•è¡¨: [batch_size, max_seq_len // block_size]</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># è®°å½•æ¯ä¸ª batch ä¸­æ¯ä¸ªå—çš„å—ç¼–å·</span>
</span></span><span class="line"><span class="cl">    <span class="n">sm_scale</span><span class="p">,</span>  <span class="c1"># softmax ç¼©æ”¾å› å­ï¼Œé€šå¸¸ä¸º 1/sqrt(head_dim)</span>
</span></span><span class="line"><span class="cl">    <span class="n">k_scale</span><span class="p">,</span>  <span class="c1"># ç”¨äº FP8 ç²¾åº¦è½¬æ¢çš„ç¼©æ”¾å› å­</span>
</span></span><span class="line"><span class="cl">    <span class="n">v_scale</span><span class="p">,</span>  <span class="c1"># ç”¨äº FP8 ç²¾åº¦è½¬æ¢çš„ç¼©æ”¾å› å­</span>
</span></span><span class="line"><span class="cl">    <span class="n">B_Start_Loc</span><span class="p">,</span>  <span class="c1">#  batch èµ·å§‹ä½ç½®: [batch_size + 1]</span>
</span></span><span class="line"><span class="cl">                  <span class="c1"># æ¯ä¸ª batch çš„å…¨å±€ seq èµ·å§‹ç´¢å¼•ï¼Œæœ€åä¸€ä¸ªå…ƒç´ æ˜¯æ€»é•¿åº¦</span>
</span></span><span class="line"><span class="cl">    <span class="n">B_Seqlen</span><span class="p">,</span>  <span class="c1">#  batch  seq é•¿åº¦: [batch_size]</span>
</span></span><span class="line"><span class="cl">               <span class="c1"># æ¯ä¸ª batch çš„æ€» seq é•¿åº¦ï¼ˆä¸Šä¸‹æ–‡ +  Query ï¼‰</span>
</span></span><span class="line"><span class="cl">    <span class="n">block_size</span><span class="p">,</span>  <span class="c1"># æ¯ä¸ªCache)çš„å¤§å°</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span><span class="p">,</span>  <span class="c1"># K_cache çš„é¢å¤–ç»´åº¦åˆ†ç‰‡å› å­ï¼ˆé€šå¸¸ä¸º 1 æˆ–å°æ•´æ•°ï¼‰</span>
</span></span><span class="line"><span class="cl">    <span class="n">Out</span><span class="p">,</span>  <span class="c1"># è¾“å‡ºå¼ é‡: [total_seq_len, num_heads, head_dim]</span>
</span></span><span class="line"><span class="cl">          <span class="c1"># å­˜å‚¨æ³¨æ„åŠ›è®¡ç®—ç»“æœ</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># --- æ­¥å¹…å‚æ•° ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_b_loc_b</span><span class="p">,</span>  <span class="c1"># B_Loc çš„ batch æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_b_loc_s</span><span class="p">,</span>  <span class="c1"># B_Loc çš„ seq å—æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_qbs</span><span class="p">,</span>  <span class="c1"># Q çš„ batch / seq æ­¥å¹…ï¼Œé€šå¸¸ä¸º num_heads * head_dim</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_qh</span><span class="p">,</span>   <span class="c1"># Q çš„head æ­¥å¹…ï¼Œé€šå¸¸ä¸º head_dim</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_qd</span><span class="p">,</span>   <span class="c1"># Q çš„head_sizeæ­¥å¹…ï¼Œé€šå¸¸ä¸º 1</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_kbs</span><span class="p">,</span>  <span class="c1"># K çš„ batch / seq æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_kh</span><span class="p">,</span>   <span class="c1"># K çš„head æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_kd</span><span class="p">,</span>   <span class="c1"># K çš„head_sizeæ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_vbs</span><span class="p">,</span>  <span class="c1"># V çš„ batch / seq æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_vh</span><span class="p">,</span>   <span class="c1"># V çš„head æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_vd</span><span class="p">,</span>   <span class="c1"># V çš„head_sizeæ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_obs</span><span class="p">,</span>  <span class="c1"># Out çš„ batch / seq æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_oh</span><span class="p">,</span>   <span class="c1"># Out çš„head æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_od</span><span class="p">,</span>   <span class="c1"># Out çš„head_sizeæ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_k_cache_bs</span><span class="p">,</span>  <span class="c1"># K_cache çš„å—æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_k_cache_h</span><span class="p">,</span>   <span class="c1"># K_cache çš„head æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_k_cache_d</span><span class="p">,</span>   <span class="c1"># K_cache çš„head_sizeæ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_k_cache_bl</span><span class="p">,</span>  <span class="c1"># K_cache çš„å—å†…åç§»æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_k_cache_x</span><span class="p">,</span>   <span class="c1"># K_cache çš„é¢å¤–ç»´åº¦æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_v_cache_bs</span><span class="p">,</span>  <span class="c1"># V_cache çš„å—æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_v_cache_h</span><span class="p">,</span>   <span class="c1"># V_cache çš„head æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_v_cache_d</span><span class="p">,</span>   <span class="c1"># V_cache çš„head_sizeæ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_v_cache_bl</span><span class="p">,</span>  <span class="c1"># V_cache çš„å—å†…åç§»æ­¥å¹…</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># --- è¶…å‚æ•° ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_queries_per_kv</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>  <span class="c1"># æ¯ä¸ª KV head å¯¹åº”çš„ Query head æ•°é‡</span>
</span></span><span class="line"><span class="cl">    <span class="n">IN_PRECISION</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1"># è¾“å…¥ç²¾åº¦ï¼ˆä¾‹å¦‚ tl.float32ï¼‰</span>
</span></span><span class="line"><span class="cl">    <span class="n">BLOCK_M</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1">#  Query å—å¤§å°</span>
</span></span><span class="line"><span class="cl">    <span class="n">BLOCK_DMODEL</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1"># head ç»´åº¦å¤§å°</span>
</span></span><span class="line"><span class="cl">    <span class="n">BLOCK_DMODEL_PADDED</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1"># head ç»´åº¦å¡«å……åˆ° 2 çš„å¹‚æ¬¡</span>
</span></span><span class="line"><span class="cl">    <span class="n">BLOCK_N</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1"># KV å—å¤§å°</span>
</span></span><span class="line"><span class="cl">    <span class="n">SLIDING_WINDOW</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1"># æ»‘åŠ¨çª—å£å¤§å°ï¼Œ0 è¡¨ç¤ºæ— çª—å£</span>
</span></span><span class="line"><span class="cl">    <span class="n">SKIP_DECODE</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1"># æ˜¯å¦è·³è¿‡è§£ç ï¼ˆä»…å¤„ç†ä¸Šä¸‹æ–‡ï¼‰</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># --- ç½‘æ ¼å®šä¹‰ ---</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># grid = (batch_size, num_heads, max_seq_len // BLOCK_M)</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_batch</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># å½“å‰ batch ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_head</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># å½“å‰head ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">    <span class="n">start_m</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>    <span class="c1"># å½“å‰ Query å—ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- è®¡ç®— KV head ç´¢å¼• ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_kv_head</span> <span class="o">=</span> <span class="n">cur_head</span> <span class="o">//</span> <span class="n">num_queries_per_kv</span>  <span class="c1"># å½“å‰ KV head ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- åŠ è½½ batch ä¿¡æ¯ ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_batch_seq_len</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">B_Seqlen</span> <span class="o">+</span> <span class="n">cur_batch</span><span class="p">)</span>  <span class="c1"># å½“å‰ batch æ€» seq é•¿åº¦</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_batch_in_all_start_index</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">B_Start_Loc</span> <span class="o">+</span> <span class="n">cur_batch</span><span class="p">)</span>  <span class="c1"># å½“å‰ batch å…¨å±€èµ·å§‹ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_batch_in_all_stop_index</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">B_Start_Loc</span> <span class="o">+</span> <span class="n">cur_batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># ä¸‹ä¸€ batch èµ·å§‹ç´¢å¼•</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_batch_query_len</span> <span class="o">=</span> <span class="p">(</span><span class="n">cur_batch_in_all_stop_index</span> <span class="o">-</span> 
</span></span><span class="line"><span class="cl">                          <span class="n">cur_batch_in_all_start_index</span><span class="p">)</span>  <span class="c1"># å½“å‰ batch  Query é•¿åº¦</span>
</span></span><span class="line"><span class="cl">    <span class="n">cur_batch_ctx_len</span> <span class="o">=</span> <span class="n">cur_batch_seq_len</span> <span class="o">-</span> <span class="n">cur_batch_query_len</span>  <span class="c1"># ä¸Šä¸‹æ–‡é•¿åº¦</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- è®¡ç®— Query å—èµ·å§‹ä½ç½® ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">block_start_loc</span> <span class="o">=</span> <span class="n">BLOCK_M</span> <span class="o">*</span> <span class="n">start_m</span>  <span class="c1"># å½“å‰ Query å—çš„èµ·å§‹ä½ç½®</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- åˆå§‹åŒ–ç´¢å¼•èŒƒå›´ ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">offs_n</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">)</span>  <span class="c1"># KV å—å†…åç§»: [0, BLOCK_N)</span>
</span></span><span class="line"><span class="cl">    <span class="n">offs_d</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">BLOCK_DMODEL_PADDED</span><span class="p">)</span>  <span class="c1"># head_size åç§»: [0, BLOCK_DMODEL_PADDED)</span>
</span></span><span class="line"><span class="cl">    <span class="n">offs_m</span> <span class="o">=</span> <span class="n">start_m</span> <span class="o">*</span> <span class="n">BLOCK_M</span> <span class="o">+</span> <span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">BLOCK_M</span><span class="p">)</span>  <span class="c1">#  Query å—å†…åç§»: [start_m * BLOCK_M, (start_m + 1) * BLOCK_M)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- è®¡ç®— Q çš„åç§»é‡ ---</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># off_q: [BLOCK_M, BLOCK_DMODEL_PADDED]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># å®šä½å½“å‰ Query å—åœ¨ Q å¼ é‡ä¸­çš„å†…å­˜åœ°å€</span>
</span></span><span class="line"><span class="cl">    <span class="n">off_q</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="n">cur_batch_in_all_start_index</span> <span class="o">+</span> <span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">*</span> <span class="n">stride_qbs</span> <span class="o">+</span>  <span class="c1">#  batch å’Œ seq åç§»</span>
</span></span><span class="line"><span class="cl">        <span class="n">cur_head</span> <span class="o">*</span> <span class="n">stride_qh</span> <span class="o">+</span>  <span class="c1"># head åç§»</span>
</span></span><span class="line"><span class="cl">        <span class="n">offs_d</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">stride_qd</span>  <span class="c1"># head_sizeåç§»</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ç¤ºä¾‹: å‡è®¾ Q [100, 4, 64], stride_qbs=256, stride_qh=64, stride_qd=1</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># cur_batch_in_all_start_index=20, cur_head=1, start_m=1, BLOCK_M=16</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># offs_m=[16, 17, ..., 31], offs_d=[0, 1, ..., 63]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># off_q[0, 0] = (20 + 16) * 256 + 1 * 64 + 0 * 1 = 9216 + 64 = 9280</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># off_q[0, 1] = (20 + 16) * 256 + 1 * 64 + 1 * 1 = 9281</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- åˆ›å»ºhead_sizeç»´åº¦æ©ç  ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">dim_mask</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">BLOCK_DMODEL_PADDED</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">BLOCK_DMODEL</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">int1</span><span class="p">)</span>  <span class="c1"># [BLOCK_DMODEL_PADDED]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># å±è”½å¡«å……éƒ¨åˆ†ï¼Œä¾‹å¦‚ BLOCK_DMODEL=64, BLOCK_DMODEL_PADDED=128ï¼Œåˆ™å 64 ä¸ªå€¼ä¸º 0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- åŠ è½½ Q æ•°æ® ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">q</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Q</span> <span class="o">+</span> <span class="n">off_q</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">mask</span><span class="o">=</span><span class="n">dim_mask</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">cur_batch_query_len</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">other</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>  <span class="c1"># [BLOCK_M, BLOCK_DMODEL_PADDED]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># åŠ è½½å½“å‰ Query å—ï¼Œæ©ç ç¡®ä¿ä¸åŠ è½½è¶…å‡º Query é•¿åº¦å’Œå¡«å……ç»´åº¦çš„æ•°æ®</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- åˆå§‹åŒ–online softmax å˜é‡ ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">m_i</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&#34;inf&#34;</span><span class="p">)</span>  <span class="c1"># æœ€å¤§å€¼</span>
</span></span><span class="line"><span class="cl">    <span class="n">l_i</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># å½’ä¸€åŒ–å› å­</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">BLOCK_DMODEL_PADDED</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># æ³¨æ„åŠ›ç´¯åŠ </span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- è®¡ç®—ä¸Šä¸‹æ–‡æ³¨æ„åŠ›ï¼ˆQ å¯¹ KV Cache) ---</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">start_n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">cur_batch_ctx_len</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_n</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">multiple_of</span><span class="p">(</span><span class="n">start_n</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">)</span>  <span class="c1"># ç¡®ä¿ start_n æ˜¯ BLOCK_N çš„å€æ•°</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># --- åŠ è½½ Cache ç´¢å¼• ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">bn</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">B_Loc</span> <span class="o">+</span> <span class="n">cur_batch</span> <span class="o">*</span> <span class="n">stride_b_loc_b</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                     <span class="p">((</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">)</span> <span class="o">//</span> <span class="n">block_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_b_loc_s</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                     <span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">cur_batch_ctx_len</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                     <span class="n">other</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [BLOCK_N]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># bn æ˜¯å½“å‰ KV Cacheçš„å—ç¼–å·</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ç¤ºä¾‹: B_Loc=[0, 1, 2, ...], cur_batch=0, start_n=16, block_size=16, offs_n=[0, 1, 2, 3]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># bn = B_Loc[0, 1]ï¼ˆè‹¥ stride_b_loc_b=8, stride_b_loc_s=1ï¼Œåˆ™åœ°å€ä¸º 0*8 + 1*1 = 1ï¼‰</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- è®¡ç®— K_cache åç§»é‡ ---</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># off_k: [BLOCK_DMODEL_PADDED, BLOCK_N]</span>
</span></span><span class="line"><span class="cl">        <span class="n">off_k</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">bn</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">stride_k_cache_bs</span> <span class="o">+</span>  <span class="c1"># å—åç§»</span>
</span></span><span class="line"><span class="cl">            <span class="n">cur_kv_head</span> <span class="o">*</span> <span class="n">stride_k_cache_h</span> <span class="o">+</span>   <span class="c1"># head åç§»</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="n">offs_d</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">//</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_k_cache_d</span> <span class="o">+</span>  <span class="c1"># head_sizeåç§»ï¼ˆåˆ†ç‰‡ï¼‰</span>
</span></span><span class="line"><span class="cl">            <span class="p">((</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">%</span> <span class="n">block_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_k_cache_bl</span> <span class="o">+</span>  <span class="c1"># å—å†…åç§»</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="n">offs_d</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">%</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_k_cache_x</span>  <span class="c1"># é¢å¤–ç»´åº¦åç§»</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ç¤ºä¾‹: bn=[1], cur_kv_head=1, stride_k_cache_bs=4096, stride_k_cache_h=1024, stride_k_cache_d=16</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># offs_d=[0, 1, ..., 63], start_n=16, offs_n=[0, 1, 2, 3], block_size=16, x=1</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># off_k[0, 0] = 1*4096 + 1*1024 + (0//1)*16 + (16+0)%16*256 + (0%1)*1 = 4096 + 1024 = 5120</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- åŠ è½½ K_cache æ•°æ® ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">k_load</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">K_cache</span> <span class="o">+</span> <span class="n">off_k</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">mask</span><span class="o">=</span><span class="n">dim_mask</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&amp;</span> <span class="p">((</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">&lt;</span> <span class="n">cur_batch_ctx_len</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                         <span class="n">other</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>  <span class="c1"># [BLOCK_DMODEL_PADDED, BLOCK_N]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># å¤„ç† FP8 ç²¾åº¦</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">k_load</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_fp8</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="n">k_load</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">k_scale</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">k</span> <span class="o">=</span> <span class="n">k_load</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- è®¡ç®— QK æ³¨æ„åŠ›åˆ†æ•° ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">acc</span><span class="o">=</span><span class="n">qk</span><span class="p">,</span> <span class="n">input_precision</span><span class="o">=</span><span class="n">IN_PRECISION</span><span class="p">)</span>  <span class="c1"># [BLOCK_M, BLOCK_N]</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">&lt;</span> <span class="n">cur_batch_ctx_len</span><span class="p">,</span> <span class="n">qk</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&#34;-inf&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">*=</span> <span class="n">sm_scale</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">SLIDING_WINDOW</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">cur_batch_ctx_len</span> <span class="o">+</span> <span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">-</span> 
</span></span><span class="line"><span class="cl">                          <span class="p">(</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">&lt;</span> <span class="n">SLIDING_WINDOW</span><span class="p">,</span> <span class="n">qk</span><span class="p">,</span> <span class="o">-</span><span class="mi">10000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- online softmax æ›´æ–° ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">m_ij</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">qk</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [BLOCK_M]</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">qk</span> <span class="o">-</span> <span class="n">m_ij</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>  <span class="c1"># [BLOCK_M, BLOCK_N]</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_ij</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [BLOCK_M]</span>
</span></span><span class="line"><span class="cl">        <span class="n">m_i_new</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">m_i</span><span class="p">,</span> <span class="n">m_ij</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">alpha</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">m_i</span> <span class="o">-</span> <span class="n">m_i_new</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">beta</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">m_ij</span> <span class="o">-</span> <span class="n">m_i_new</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_i_new</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l_i</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">l_ij</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- æ›´æ–°ç´¯åŠ å™¨ ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">p_scale</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">/</span> <span class="n">l_i_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">p_scale</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc_scale</span> <span class="o">=</span> <span class="n">l_i</span> <span class="o">/</span> <span class="n">l_i_new</span> <span class="o">*</span> <span class="n">alpha</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">*</span> <span class="n">acc_scale</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># åŠ è½½ V_cache</span>
</span></span><span class="line"><span class="cl">        <span class="n">off_v</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">bn</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">stride_v_cache_bs</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">            <span class="n">cur_kv_head</span> <span class="o">*</span> <span class="n">stride_v_cache_h</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">            <span class="n">offs_d</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">stride_v_cache_d</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">%</span> <span class="n">block_size</span> <span class="o">*</span> <span class="n">stride_v_cache_bl</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">v_load</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">V_cache</span> <span class="o">+</span> <span class="n">off_v</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">mask</span><span class="o">=</span><span class="n">dim_mask</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&amp;</span> <span class="p">((</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">cur_batch_ctx_len</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                         <span class="n">other</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>  <span class="c1"># [BLOCK_N, BLOCK_DMODEL_PADDED]</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">v_load</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_fp8</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">v</span> <span class="o">=</span> <span class="p">(</span><span class="n">v_load</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">v_scale</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">v</span> <span class="o">=</span> <span class="n">v_load</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">acc</span><span class="o">=</span><span class="n">acc</span><span class="p">,</span> <span class="n">input_precision</span><span class="o">=</span><span class="n">IN_PRECISION</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># æ›´æ–° m_i å’Œ l_i</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_i</span> <span class="o">=</span> <span class="n">l_i_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">m_i</span> <span class="o">=</span> <span class="n">m_i_new</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼ˆQ å¯¹å½“å‰ K å’Œ Vï¼‰ ---</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># è®¡ç®— K å’Œ V çš„åˆå§‹åç§»</span>
</span></span><span class="line"><span class="cl">    <span class="n">off_k</span> <span class="o">=</span> <span class="p">(</span><span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">stride_kbs</span> <span class="o">+</span> <span class="n">cur_kv_head</span> <span class="o">*</span> <span class="n">stride_kh</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">             <span class="n">offs_d</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">stride_kd</span><span class="p">)</span>  <span class="c1"># [BLOCK_DMODEL_PADDED, BLOCK_N]</span>
</span></span><span class="line"><span class="cl">    <span class="n">off_v</span> <span class="o">=</span> <span class="p">(</span><span class="n">offs_n</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">stride_vbs</span> <span class="o">+</span> <span class="n">cur_kv_head</span> <span class="o">*</span> <span class="n">stride_vh</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">             <span class="n">offs_d</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">stride_vd</span><span class="p">)</span>  <span class="c1"># [BLOCK_N, BLOCK_DMODEL_PADDED]</span>
</span></span><span class="line"><span class="cl">    <span class="n">k_ptrs</span> <span class="o">=</span> <span class="n">K</span> <span class="o">+</span> <span class="n">off_k</span>  <span class="c1"># åˆå§‹æŒ‡é’ˆ</span>
</span></span><span class="line"><span class="cl">    <span class="n">v_ptrs</span> <span class="o">=</span> <span class="n">V</span> <span class="o">+</span> <span class="n">off_v</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># æ£€æŸ¥å½“å‰ Query å—æ˜¯å¦æœ‰æ•ˆ</span>
</span></span><span class="line"><span class="cl">    <span class="n">block_mask</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">block_start_loc</span> <span class="o">&lt;</span> <span class="n">cur_batch_query_len</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># éå†å½“å‰è¾“å…¥çš„ K å’Œ V</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">start_n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">block_mask</span> <span class="o">*</span> <span class="p">(</span><span class="n">start_m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_n</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">multiple_of</span><span class="p">(</span><span class="n">start_n</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># --- åŠ è½½ K æ•°æ® ---</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># å…¨å±€åç§»: (cur_batch_in_all_start_index + start_n) * stride_kbs å®šä½ batch å’Œ seq å—</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ç¤ºä¾‹: K [100, 4, 64], stride_kbs=256, cur_batch_in_all_start_index=20, start_n=8</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># åŸºåœ°å€åç§» = (20 + 8) * 256 = 7168</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># k_ptrs[0, 0] = K + 0 + 1*64 + 0*1 + 7168 = K + 7232</span>
</span></span><span class="line"><span class="cl">        <span class="n">k</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">k_ptrs</span> <span class="o">+</span> <span class="p">(</span><span class="n">cur_batch_in_all_start_index</span> <span class="o">+</span> <span class="n">start_n</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_kbs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">mask</span><span class="o">=</span><span class="n">dim_mask</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&amp;</span> <span class="p">((</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">&lt;</span> <span class="n">cur_batch_query_len</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">other</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>  <span class="c1"># [BLOCK_DMODEL_PADDED, BLOCK_N]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- è®¡ç®— QK æ³¨æ„åŠ›åˆ†æ•° ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">acc</span><span class="o">=</span><span class="n">qk</span><span class="p">,</span> <span class="n">input_precision</span><span class="o">=</span><span class="n">IN_PRECISION</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">*=</span> <span class="n">sm_scale</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># åº”ç”¨å› æœæ©ç </span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">qk</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&#34;-inf&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">SLIDING_WINDOW</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">&lt;</span> <span class="n">SLIDING_WINDOW</span><span class="p">,</span> <span class="n">qk</span><span class="p">,</span> <span class="o">-</span><span class="mi">10000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- online softmax æ›´æ–° ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">m_ij</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">qk</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">qk</span> <span class="o">-</span> <span class="n">m_ij</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_ij</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">m_i_new</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">m_i</span><span class="p">,</span> <span class="n">m_ij</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">alpha</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">m_i</span> <span class="o">-</span> <span class="n">m_i_new</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">beta</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">m_ij</span> <span class="o">-</span> <span class="n">m_i_new</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_i_new</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l_i</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">l_ij</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- æ›´æ–°ç´¯åŠ å™¨ ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">p_scale</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">/</span> <span class="n">l_i_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">p_scale</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc_scale</span> <span class="o">=</span> <span class="n">l_i</span> <span class="o">/</span> <span class="n">l_i_new</span> <span class="o">*</span> <span class="n">alpha</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">*</span> <span class="n">acc_scale</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">v</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">v_ptrs</span> <span class="o">+</span> <span class="p">(</span><span class="n">cur_batch_in_all_start_index</span> <span class="o">+</span> <span class="n">start_n</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_vbs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">mask</span><span class="o">=</span><span class="n">dim_mask</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&amp;</span> <span class="p">((</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">cur_batch_query_len</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">other</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>  <span class="c1"># [BLOCK_N, BLOCK_DMODEL_PADDED]</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">acc</span><span class="o">=</span><span class="n">acc</span><span class="p">,</span> <span class="n">input_precision</span><span class="o">=</span><span class="n">IN_PRECISION</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># æ›´æ–° m_i å’Œ l_i</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_i</span> <span class="o">=</span> <span class="n">l_i_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">m_i</span> <span class="o">=</span> <span class="n">m_i_new</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --- å­˜å‚¨è¾“å‡º ---</span>
</span></span><span class="line"><span class="cl">    <span class="n">off_o</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="n">cur_batch_in_all_start_index</span> <span class="o">+</span> <span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">*</span> <span class="n">stride_obs</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">        <span class="n">cur_head</span> <span class="o">*</span> <span class="n">stride_oh</span> <span class="o">+</span> <span class="n">offs_d</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">stride_od</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out_ptrs</span> <span class="o">=</span> <span class="n">Out</span> <span class="o">+</span> <span class="n">off_o</span>
</span></span><span class="line"><span class="cl">    <span class="n">tl</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">out_ptrs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">             <span class="n">mask</span><span class="o">=</span><span class="n">dim_mask</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">cur_batch_query_len</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="forward_decode">forward_decode</h2>
<p>è°ƒç”¨çš„æ˜¯ <a href="https://github.com/vllm-project/vllm/blob/400d483e87b71315bbb73edb0da9fd629212ca82/csrc/attention/attention_kernels.cuh#L90">paged_atention_kernel</a>
gridDim = (num_heads, num_seqs, 1). decode çš„æ—¶å€™æ¯ä¸ª seq çš„ Query çš„ toekn æ•°ç›®éƒ½æ˜¯ 1ï¼Œ</p>
<ul>
<li>gridDim = (num_heads, num_seqs, 1): æ¯ä¸ªçº¿ç¨‹å—è´Ÿè´£ä¸€ä¸ª seq çš„ ä¸€ä¸ª headï¼Œå‡½æ•°å®šä¹‰å¦‚ä¸‹</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="n">template</span> <span class="o">&lt;</span><span class="kr">typename</span> <span class="kt">scalar_t</span><span class="p">,</span> <span class="kr">typename</span> <span class="kt">cache_t</span><span class="p">,</span> <span class="kt">int</span> <span class="n">HEAD_SIZE</span><span class="p">,</span> <span class="kt">int</span> <span class="n">BLOCK_SIZE</span><span class="p">,</span>  <span class="c1">// default 16
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>          <span class="kt">int</span> <span class="n">NUM_THREADS</span> <span class="cm">/*=128*/</span><span class="p">,</span> <span class="n">vllm</span><span class="o">::</span><span class="n">Fp8KVCacheDataType</span> <span class="n">KV_DTYPE</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">          <span class="kt">bool</span> <span class="n">IS_BLOCK_SPARSE</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">          <span class="kt">int</span> <span class="n">PARTITION_SIZE</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span>  <span class="c1">// Zero means no partitioning.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__device__</span> <span class="kt">void</span> <span class="nf">paged_attention_kernel</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="kt">float</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">exp_sums</span><span class="p">,</span>  <span class="c1">// [num_seqs, num_heads, max_num_partitions]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">float</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">max_logits</span><span class="p">,</span>  <span class="c1">// [num_seqs, num_heads,
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                                     <span class="c1">// max_num_partitions]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">scalar_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">out</span><span class="p">,</span>  <span class="c1">// [num_seqs, num_heads, max_num_partitions, head_size]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">scalar_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">q</span><span class="p">,</span>       <span class="c1">// [num_seqs, num_heads, head_size]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">cache_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">k_cache</span><span class="p">,</span>  <span class="c1">// [num_blocks, num_kv_heads, head_size/x, block_size, x]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">cache_t</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">v_cache</span><span class="p">,</span>  <span class="c1">// [num_blocks, num_kv_heads, head_size, block_size]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">num_kv_heads</span><span class="p">,</span>               <span class="c1">// [num_heads]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">float</span> <span class="n">scale</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">block_tables</span><span class="p">,</span>  <span class="c1">// [num_seqs, max_num_blocks_per_seq]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">seq_lens</span><span class="p">,</span>      <span class="c1">// [num_seqs]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">max_num_blocks_per_seq</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">float</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">alibi_slopes</span><span class="p">,</span>  <span class="c1">// [num_heads]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// çŸ©é˜µæ¯ä¸€ç»´åº¦çš„ strideï¼Œä¾¿äºç§»åŠ¨æŒ‡é’ˆ
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">q_stride</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">kv_block_stride</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">kv_head_stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">float</span><span class="o">*</span> <span class="n">k_scale</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span><span class="o">*</span> <span class="n">v_scale</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">tp_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int</span> <span class="n">blocksparse_local_blocks</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">blocksparse_vert_stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int</span> <span class="n">blocksparse_block_size</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">blocksparse_head_sliding_step</span><span class="p">)</span> 
</span></span></code></pre></td></tr></table>
</div>
</div><p>é¦–å…ˆå…ˆè®¡ç®—ä¸€ä¸‹å½“å‰çº¿ç¨‹å¯¹åº”çš„å„ç§å‚æ•°ï¼Œè¿™é‡Œæ ¹æ®æ¨¡æ¿å‡½æ•°å®šä¹‰ä¸ä½¿ç”¨ PARTITIONING.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="c1">// grid = (num_heads, num_seqs, 1) ä¸€ä¸ª thread block å¤„ç†ä¸€ä¸ª seq çš„ ä¸€ä¸ª head
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">seq_idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">partition_idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">max_num_partitions</span> <span class="o">=</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>  <span class="c1">// 1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_lens</span><span class="p">[</span><span class="n">seq_idx</span><span class="p">];</span>  <span class="c1">// è¯¥ seq token æ•°
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">  <span class="c1">// è®¡ç®—å—èŒƒå›´å’Œ token èŒƒå›´
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_seq_blocks</span> <span class="o">=</span> <span class="nf">DIVIDE_ROUND_UP</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">BLOCK_SIZE</span><span class="p">);</span>  <span class="c1">// seq è¦åˆ†å‡ å—è¯»å–
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_blocks_per_partition</span> <span class="o">=</span>  <span class="n">num_seq_blocks</span><span class="p">;</span>  <span class="c1">// åˆ†äº†å‡ å—
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">start_block_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>  <span class="c1">// èµ·å§‹å—ç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">end_block_idx</span> <span class="o">=</span> <span class="n">num_seq_blocks</span><span class="p">;</span>  <span class="c1">// ç»“æŸå—ç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_blocks</span> <span class="o">=</span> <span class="n">end_block_idx</span> <span class="o">-</span> <span class="n">start_block_idx</span><span class="p">;</span>  <span class="c1">// å½“å‰åˆ†åŒºå—æ•°
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">start_token_idx</span> <span class="o">=</span> <span class="n">start_block_idx</span> <span class="o">*</span> <span class="n">BLOCK_SIZE</span><span class="p">;</span>  <span class="c1">// èµ·å§‹ token ç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">end_token_idx</span> <span class="o">=</span> <span class="nf">MIN</span><span class="p">(</span><span class="n">start_token_idx</span> <span class="o">+</span> <span class="n">num_blocks</span> <span class="o">*</span> <span class="n">BLOCK_SIZE</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">);</span>  <span class="c1">// ç»“æŸ token ç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">end_token_idx</span> <span class="o">-</span> <span class="n">start_token_idx</span><span class="p">;</span>  <span class="c1">// å½“å‰åˆ†åŒº token æ•°
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">  <span class="c1">// çº¿ç¨‹ç»„ç»‡å‚æ•°
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">constexpr</span> <span class="kt">int</span> <span class="n">THREAD_GROUP_SIZE</span> <span class="o">=</span> <span class="nf">MAX</span><span class="p">(</span><span class="n">WARP_SIZE</span> <span class="o">/</span> <span class="n">BLOCK_SIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>  <span class="c1">// å‡ ä¸ª thread å¤„ç†ä¸€ä¸ª token 32/16=2
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">constexpr</span> <span class="kt">int</span> <span class="n">NUM_THREAD_GROUPS</span> <span class="o">=</span> <span class="n">NUM_THREADS</span> <span class="o">/</span> <span class="n">THREAD_GROUP_SIZE</span><span class="p">;</span>  <span class="c1">// ä¸€ä¸ª thread block è¢«åˆ†æˆå‡ ç»„ 128/2=64
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">constexpr</span> <span class="kt">int</span> <span class="n">NUM_TOKENS_PER_THREAD_GROUP</span> <span class="o">=</span> <span class="nf">DIVIDE_ROUND_UP</span><span class="p">(</span><span class="n">BLOCK_SIZE</span><span class="p">,</span> <span class="n">WARP_SIZE</span><span class="p">);</span>  <span class="c1">// æ¯çº¿ç¨‹å¤„ç†çš„ token æ•° 16/32=1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">constexpr</span> <span class="kt">int</span> <span class="n">NUM_WARPS</span> <span class="o">=</span> <span class="n">NUM_THREADS</span> <span class="o">/</span> <span class="n">WARP_SIZE</span><span class="p">;</span>  <span class="c1">// warp ä¸ªæ•° 128/32=4
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">thread_idx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>  <span class="c1">// çº¿ç¨‹ç´¢å¼•
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">warp_idx</span> <span class="o">=</span> <span class="n">thread_idx</span> <span class="o">/</span> <span class="n">WARP_SIZE</span><span class="p">;</span>  <span class="c1">// çº¿ç¨‹ä½äºç¬¬å‡ ä¸ª warp
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">lane</span> <span class="o">=</span> <span class="n">thread_idx</span> <span class="o">%</span> <span class="n">WARP_SIZE</span><span class="p">;</span>  <span class="c1">// çº¿ç¨‹æ˜¯è¯¥ warp ä¸­çš„ç¬¬å‡ ä¸ª
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">head_idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// è€ƒè™‘ GQA MQA
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_queries_per_kv</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="o">/</span> <span class="n">num_kv_heads</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">kv_head_idx</span> <span class="o">=</span> <span class="n">head_idx</span> <span class="o">/</span> <span class="n">num_queries_per_kv</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">float</span> <span class="n">alibi_slope</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">      <span class="n">alibi_slopes</span> <span class="o">==</span> <span class="n">nullptr</span> <span class="o">?</span> <span class="mf">0.f</span> <span class="o">:</span> <span class="n">alibi_slopes</span><span class="p">[</span><span class="n">head_idx</span><span class="p">];</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>å®šä¹‰ thread group ï¼Œä¿è¯å…¶ä¸€æ¬¡è®¿é—®çš„æ•°æ®ä¸º 16 Bytesï¼Œéœ€è¦è®¡ç®—å…¶ä¸­æ¯ä¸ª thread å¤„ç†å‡ ä¸ªå…ƒç´ ã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="c1">// VEC_SIZE å³ä¸ºä¸€ä¸ª thread group ä¸­æ¯ä¸ªçº¿ç¨‹éœ€è¦å¤„ç†å…ƒç´ ä¸ªæ•°ï¼Œ
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">constexpr</span> <span class="kt">int</span> <span class="n">VEC_SIZE</span> <span class="o">=</span> <span class="nf">MAX</span><span class="p">(</span><span class="mi">16</span> <span class="o">/</span> <span class="p">(</span><span class="n">THREAD_GROUP_SIZE</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">scalar_t</span><span class="p">)),</span> <span class="mi">1</span><span class="p">);</span>  <span class="c1">// 16/2/2=4 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">using</span> <span class="n">K_vec</span> <span class="o">=</span> <span class="kr">typename</span> <span class="n">Vec</span><span class="o">&lt;</span><span class="kt">scalar_t</span><span class="p">,</span> <span class="n">VEC_SIZE</span><span class="o">&gt;::</span><span class="n">Type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">using</span> <span class="n">Q_vec</span> <span class="o">=</span> <span class="kr">typename</span> <span class="n">Vec</span><span class="o">&lt;</span><span class="kt">scalar_t</span><span class="p">,</span> <span class="n">VEC_SIZE</span><span class="o">&gt;::</span><span class="n">Type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">using</span> <span class="n">Quant_vec</span> <span class="o">=</span> <span class="kr">typename</span> <span class="n">Vec</span><span class="o">&lt;</span><span class="kt">cache_t</span><span class="p">,</span> <span class="n">VEC_SIZE</span><span class="o">&gt;::</span><span class="n">Type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">constexpr</span> <span class="kt">int</span> <span class="n">NUM_ELEMS_PER_THREAD</span> <span class="o">=</span> <span class="n">HEAD_SIZE</span> <span class="o">/</span> <span class="n">THREAD_GROUP_SIZE</span><span class="p">;</span>  <span class="c1">// æ¯ä¸ª thread å¤„ç†å‡ ä¸ªå…ƒç´  64/2=32
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">constexpr</span> <span class="kt">int</span> <span class="n">NUM_VECS_PER_THREAD</span> <span class="o">=</span> <span class="n">NUM_ELEMS_PER_THREAD</span> <span class="o">/</span> <span class="n">VEC_SIZE</span><span class="p">;</span>  <span class="c1">// è¿™å‡ ä¸ªå…ƒç´ ç›¸å½“äºå‡ ä¸ªå‘é‡  32/4=8
</span></span></span><span class="line"><span class="cl"><span class="c1">// thread_idx = thread_group_idx * THREAD_GROUP_SIZE + thread_group_offset
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">const</span> <span class="kt">int</span> <span class="n">thread_group_idx</span> <span class="o">=</span> <span class="n">thread_idx</span> <span class="o">/</span> <span class="n">THREAD_GROUP_SIZE</span><span class="p">;</span>  <span class="c1">// çº¿ç¨‹ä½äºç¬¬å‡ ä¸ª thread group
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">const</span> <span class="kt">int</span> <span class="n">thread_group_offset</span> <span class="o">=</span> <span class="n">thread_idx</span> <span class="o">%</span> <span class="n">THREAD_GROUP_SIZE</span><span class="p">;</span>  <span class="c1">// çº¿ç¨‹æ˜¯è¯¥ thread group ä¸­ç¬¬å‡ ä¸ªçº¿ç¨‹
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>ä¸‹é¢å°† Q åŠ è½½è¿›å…±äº«å†…å­˜ã€‚

<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB7a7b85b64fbddcf13d703135a4bf6d32?method=download&amp;shareKey=6ca032c977b9f14a0864999633e8e08f" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB7a7b85b64fbddcf13d703135a4bf6d32?method=download&amp;shareKey=6ca032c977b9f14a0864999633e8e08f" alt="loadQ">
    </a><figcaption>loadQ</figcaption></figure></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">scalar_t</span><span class="o">*</span> <span class="n">q_ptr</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="n">seq_idx</span> <span class="o">*</span> <span class="n">q_stride</span> <span class="o">+</span> <span class="n">head_idx</span> <span class="o">*</span> <span class="n">HEAD_SIZE</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">__shared__</span> <span class="n">Q_vec</span> <span class="n">q_vecs</span><span class="p">[</span><span class="n">THREAD_GROUP_SIZE</span><span class="p">][</span><span class="n">NUM_VECS_PER_THREAD</span><span class="p">];</span>  <span class="c1">// HEAD_SIZE * VEC_SIZE * sizeof(scalar_t) å¤§å°
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="cp">#pragma unroll
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">thread_group_idx</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM_VECS_PER_THREAD</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">NUM_THREAD_GROUPS</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// NUM_ELEMS_PER_THREAD / VEC_SIZE
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// ä½¿å¾—æ¯ä¸ª thread group çš„çº¿ç¨‹è®¿é—®ç›¸é‚»çš„ vec
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">int</span> <span class="n">vec_idx</span> <span class="o">=</span> <span class="n">thread_group_offset</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">THREAD_GROUP_SIZE</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">q_vecs</span><span class="p">[</span><span class="n">thread_group_offset</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">        <span class="o">*</span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">Q_vec</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">q_ptr</span> <span class="o">+</span> <span class="n">vec_idx</span> <span class="o">*</span> <span class="n">VEC_SIZE</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="nf">__syncthreads</span><span class="p">();</span> 
</span></span></code></pre></td></tr></table>
</div>
</div><p>å‡è®¾å—ä¸ç¨€ç–å¹¶ä¸”æŠŠä¸é‡‡ç”¨é‡åŒ–ï¼ŒåŠ è½½ K å¹¶è®¡ç®— <a href="mailto:Q@K.T">Q@K.T</a>. æ ¸å¿ƒæ€æƒ³æ˜¯ä¸€ä¸ª thread group è®¿é—® 16 Bytes. ä¸€ä¸ª thread è®¿é—®ä¸€ä¸ª vecï¼Œä¸€ä¸ªå‘é‡åŒ…å«çš„å…ƒç´ ä¸ªæ•° <code>VEC_SIZE = 16 / sizeof (scalar_t) / THREAD_GROUP_SIZE</code></p>
<ol>
<li>1st for å¾ªç¯ç¡®å®šçš„æ˜¯æ¯æ¬¡è¿­ä»£ä¸­æ¯ä¸ª warp å¤„ç†çš„æ˜¯å“ªä¸€ä¸ª blockï¼Œä¸€å…±è¦å¾ªç¯ num_seq_blocks / NUM_WARPS æ¬¡</li>
<li>2nd for å¾ªç¯ç¡®å®šçš„æ˜¯è¯¥ warp ä¸­çš„æ¯ä¸ª thread group è®¿é—®çš„æ˜¯è¯¥ block çš„ç¬¬å‡ ä¸ª token. å³æ¯ä¸ªçº¿ç¨‹ç»„å¤„ç†ä¸€ä¸ª token.</li>
<li>3rd for å¾ªç¯ç¡®å®šçš„æ˜¯è¯¥ thread group ä¸­çš„æ¯ä¸ª thread è®¿é—®çš„æ˜¯ç¬¬å‡ ä¸ª vec. è¯¥å¾ªç¯ä½¿å¾—è¯¥ thread group é‡Œé¢çš„çº¿ç¨‹è¯»å–ä¸€ä¸ªå®Œæ•´çš„ headsize. ä¸€æ¬¡è¿­ä»£è¯»å–çš„å¤§å°ä¸º 16 Bytes.</li>
</ol>
<p>é¦–å…ˆå°† block_table æŒ‡é’ˆç§»åŠ¨åˆ°å­˜å‚¨è¯¥ kv cache çš„é¦–ä¸ª blockID å¤„ï¼Œå–å‡ºå®é™…çš„ç‰©ç†å— IDï¼Œç”¨åœ¨ç¬¬ä¸‰ä¸ª for å¾ªç¯ä¸­å°†æŒ‡é’ˆç§»åŠ¨åˆ°è¯¥ K cache block èµ·å§‹å¤„. ç”±äº
k_cache çš„ shape æ˜¯ <code>[num_blocks, num_kv_heads, head_size/x, block_size, x]</code>ï¼Œåœ¨ç¬¬ä¸‰ä¸ª for å¾ªç¯ä¸­ k_ptr è¢«ç§»åŠ¨åˆ°äº†è¯¥ thread_group è¦è¯»å–çš„ block çš„ token çš„ head å¤„ã€‚<code>vec_idx * VEC_SIZE</code> å³ä¸º thread è¦è¯»å–çš„å…ƒç´ å¼€å§‹ä½ç½®ï¼Œ/x è¡¨ç¤ºå¯¹åº”çš„æ˜¯ç¬¬å‡ ä¸ª 16Bytes åˆ’åˆ†, offset1 ç§»åŠ¨çš„æ˜¯ dim3ï¼Œoffset2 ç§»åŠ¨çš„ åˆ™æ˜¯ dim4.</p>
<p>3rd loop ç»“æŸåå·²ç»è¯»å–äº†ä¸€ä¸ª K cache çš„å®Œæ•´ head_size åˆ°å¯„å­˜å™¨ä¸­ï¼Œå› æ­¤ qk ä¸ºä¸€ä¸ª token çš„ä¸€ä¸ª head çš„ Score Matrix. æ ¹æ® token_idx ç”±æ¯ä¸ª thread group é‡Œçš„ ç¬¬ä¸€ä¸ªçº¿ç¨‹è´Ÿè´£å°†ç´¯åŠ å’Œåˆ° logits ä¸­å¹¶æ›´æ–° qk_maxã€‚</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl">  <span class="c1">// Memory planning.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">extern</span> <span class="n">__shared__</span> <span class="kt">char</span> <span class="n">shared_mem</span><span class="p">[];</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// NOTE(woosuk): We use FP32 for the softmax logits for better accuracy.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="kt">float</span><span class="o">*</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">shared_mem</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Workspace for reduction.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">__shared__</span> <span class="kt">float</span> <span class="n">red_smem</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">NUM_WARPS</span><span class="p">];</span>  <span class="c1">// å‰ä¸€åŠç”¨äºå­˜å‚¨ qk_max åä¸€åŠç”¨äºå­˜å‚¨ exp_sum
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">  <span class="c1">// x == THREAD_GROUP_SIZE * VEC_SIZE
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// æ¯æ¬¡ thread group ä¸€æ¬¡å–çš„å…ƒç´ æ•°é‡ ä¿è¯ä¸º 16 bytes
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">constexpr</span> <span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">16</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">cache_t</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float</span> <span class="n">qk_max</span> <span class="o">=</span> <span class="o">-</span><span class="n">FLT_MAX</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">// æŒ‡é’ˆç§»åŠ¨åˆ°å½“å‰ seq å¯¹åº”çš„é¦–ä¸ª blockID
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">int</span><span class="o">*</span> <span class="n">block_table</span> <span class="o">=</span> <span class="n">block_tables</span> <span class="o">+</span> <span class="n">seq_idx</span> <span class="o">*</span> <span class="n">max_num_blocks_per_seq</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">block_idx</span> <span class="o">=</span> <span class="n">start_block_idx</span> <span class="o">+</span> <span class="n">warp_idx</span><span class="p">;</span> <span class="n">block_idx</span> <span class="o">&lt;</span> <span class="n">end_block_idx</span><span class="p">;</span> <span class="n">block_idx</span> <span class="o">+=</span> <span class="n">NUM_WARPS</span><span class="p">)</span> <span class="p">{</span>  
</span></span><span class="line"><span class="cl">    <span class="c1">// æ¯ä¸ª warp å¤„ç†ä¸€ä¸ª block
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">physical_block_number</span> <span class="o">=</span> <span class="n">static_cast</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">block_table</span><span class="p">[</span><span class="n">block_idx</span><span class="p">]);</span>  <span class="c1">// è¯¥ warp å½“å‰å¤„ç†çš„ block å¯¹åº”çš„ id
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Load a key to registers.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM_TOKENS_PER_THREAD_GROUP</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// BLOCK_SIZE(16) / WARP_SIZE(32) = 1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">const</span> <span class="kt">int</span> <span class="n">physical_block_offset</span> <span class="o">=</span> <span class="p">(</span><span class="n">thread_group_idx</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">WARP_SIZE</span><span class="p">)</span> <span class="o">%</span> <span class="n">BLOCK_SIZE</span><span class="p">;</span>  <span class="c1">// thread group å¤„ç†çš„æ˜¯è¯¥ block çš„ç¬¬å‡ ä¸ª token
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">const</span> <span class="kt">int</span> <span class="n">token_idx</span> <span class="o">=</span> <span class="n">block_idx</span> <span class="o">*</span> <span class="n">BLOCK_SIZE</span> <span class="o">+</span> <span class="n">physical_block_offset</span><span class="p">;</span>  <span class="c1">// è¯¥ token æ˜¯è¯¥ seq çš„ç¬¬å‡ ä¸ª
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="n">K_vec</span> <span class="n">k_vecs</span><span class="p">[</span><span class="n">NUM_VECS_PER_THREAD</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="cp">#pragma unroll
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>      <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">NUM_VECS_PER_THREAD</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// NUM_ELEMS_PER_THREAD(32) / VEC_SIZE(4) = 8
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">const</span> <span class="kt">cache_t</span><span class="o">*</span> <span class="n">k_ptr</span> <span class="o">=</span> <span class="n">k_cache</span> <span class="o">+</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">physical_block_number</span> <span class="o">*</span> <span class="n">kv_block_stride</span> <span class="o">+</span>  <span class="c1">// ç§»åŠ¨åˆ°è¯¥ block èµ·å§‹å¤„
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                                <span class="n">kv_head_idx</span> <span class="o">*</span> <span class="n">kv_head_stride</span> <span class="o">+</span>  <span class="c1">// ç§»åŠ¨åˆ°å¯¹åº”çš„ head å¤„
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                                <span class="n">physical_block_offset</span> <span class="o">*</span> <span class="n">x</span><span class="p">;</span>  <span class="c1">// ç§»åŠ¨åˆ°å¯¹åº”çš„ token å¤„
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">const</span> <span class="kt">int</span> <span class="n">vec_idx</span> <span class="o">=</span> <span class="n">thread_group_offset</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="n">THREAD_GROUP_SIZE</span><span class="p">;</span>  <span class="c1">// è¯¥ thread è¦è¯»å– head_size åˆ’åˆ†æˆçš„ç¬¬å‡ ä¸ª vec
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">const</span> <span class="kt">int</span> <span class="n">offset1</span> <span class="o">=</span> <span class="p">(</span><span class="n">vec_idx</span> <span class="o">*</span> <span class="n">VEC_SIZE</span><span class="p">)</span> <span class="o">/</span> <span class="n">x</span><span class="p">;</span>  <span class="c1">// ç¬¬å‡ ä¸ª 16Bytes åˆ’åˆ†
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">const</span> <span class="kt">int</span> <span class="n">offset2</span> <span class="o">=</span> <span class="p">(</span><span class="n">vec_idx</span> <span class="o">*</span> <span class="n">VEC_SIZE</span><span class="p">)</span> <span class="o">%</span> <span class="n">x</span><span class="p">;</span>  <span class="c1">// åˆ’åˆ†çš„ç¬¬å‡ ä¸ªå…ƒç´ 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nf">constexpr</span> <span class="p">(</span><span class="n">KV_DTYPE</span> <span class="o">==</span> <span class="n">Fp8KVCacheDataType</span><span class="o">::</span><span class="n">kAuto</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">          <span class="n">k_vecs</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="o">*</span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">K_vec</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">k_ptr</span> <span class="o">+</span> <span class="n">offset1</span> <span class="o">*</span> <span class="n">BLOCK_SIZE</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">offset2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1">// Compute dot product.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="c1">// This includes a reduction across the threads in the same thread group.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="kt">float</span> <span class="n">qk</span> <span class="o">=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">Qk_dot</span><span class="o">&lt;</span><span class="kt">scalar_t</span><span class="p">,</span> <span class="n">THREAD_GROUP_SIZE</span><span class="o">&gt;::</span><span class="nf">dot</span><span class="p">(</span><span class="n">q_vecs</span><span class="p">[</span><span class="n">thread_group_offset</span><span class="p">],</span> <span class="n">k_vecs</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Add the ALiBi bias if slopes are given.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="n">qk</span> <span class="o">+=</span> <span class="p">(</span><span class="n">alibi_slope</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">?</span> <span class="n">alibi_slope</span> <span class="o">*</span> <span class="p">(</span><span class="n">token_idx</span> <span class="o">-</span> <span class="n">seq_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">:</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="p">(</span><span class="n">thread_group_offset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// æ¯ä¸ªçº¿ç¨‹ç»„çš„ç¬¬ä¸€ä¸ªçº¿ç¨‹è¿›è¡Œæ›´æ–° max
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="c1">// Store the partial reductions to shared memory.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="c1">// NOTE(woosuk): It is required to zero out the masked logits.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">const</span> <span class="kt">bool</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">token_idx</span> <span class="o">&gt;=</span> <span class="n">seq_len</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span><span class="p">[</span><span class="n">token_idx</span> <span class="o">-</span> <span class="n">start_token_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">?</span> <span class="mf">0.f</span> <span class="o">:</span> <span class="n">qk</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// Update the max value.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">qk_max</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">?</span> <span class="nl">qk_max</span> <span class="p">:</span> <span class="nf">fmaxf</span><span class="p">(</span><span class="n">qk_max</span><span class="p">,</span> <span class="n">qk</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>
<figure class="post-figure">
    <a href="https://note.youdao.com/yws/api/personal/file/WEB36d66a13612972c7f567ed8f20600664?method=download&amp;shareKey=9a305814befc64b17e64feb1c8d76b17" target="_blank" rel="noopener">
        <img loading="lazy" src="https://note.youdao.com/yws/api/personal/file/WEB36d66a13612972c7f567ed8f20600664?method=download&amp;shareKey=9a305814befc64b17e64feb1c8d76b17" alt="load k &amp; QK Mul">
    </a><figcaption>load k &amp; QK Mul</figcaption></figure></p>
<p>ä¸Šé¢è¿™ä¸€æ®µç»“æŸåä¸‹é¢æ¯ä¸ª warp å†… thread group ä¸­çš„ç¬¬ä¸€ä¸ªçº¿ç¨‹å·²ç»è®°å½•äº†è¯¥ group çš„ qk_max. ä¸‹ä¸€æ­¥åˆ™æ˜¯åœ¨ warp å†…è¿›è¡Œ qk_max å½’çº¦ï¼Œå­˜å‚¨åœ¨å…±äº«å†…å­˜ red_smem ä¸­ã€‚ ç”±äºä¸€ä¸ª warp å¤„ç†çš„æ˜¯ä¸€ä¸ª blockï¼Œç›¸å½“äºç°åœ¨ red_smem æ¯ä¸ªå…ƒç´ å­˜å‚¨äº†å¯¹åº” block å†…çš„ qk_max.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="cp">#pragma unroll
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">WARP_SIZE</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span> <span class="n">mask</span> <span class="o">&gt;=</span> <span class="n">THREAD_GROUP_SIZE</span><span class="p">;</span> <span class="n">mask</span> <span class="o">/=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">qk_max</span> <span class="o">=</span> <span class="nf">fmaxf</span><span class="p">(</span><span class="n">qk_max</span><span class="p">,</span> <span class="nf">VLLM_SHFL_XOR_SYNC</span><span class="p">(</span><span class="n">qk_max</span><span class="p">,</span> <span class="n">mask</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">lane</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">red_smem</span><span class="p">[</span><span class="n">warp_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">qk_max</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="nf">__syncthreads</span><span class="p">();</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ä¸‹ä¸€æ­¥åˆ™æ˜¯åœ¨ thread block å†…å¯¹æ‰€æœ‰ warp è¿›è¡Œè§„çº¦ï¼Œå¾—åˆ°è¯¥ seq æœ€åçš„ qk_max. ç„¶åå¹¿æ’­åˆ°æ‰€æœ‰çº¿ç¨‹ä¸­ã€‚ä¹‹åæ¯ä¸ªçº¿ç¨‹è®¡ç®— exp å­˜å…¥ logitsï¼Œæ¯ä¸ª warp å†…çš„ exp æ±‚å’Œç»“æœå­˜å‚¨åœ¨ red_smem çš„åä¸€åŠä¸­ã€‚æœ€ååˆ™æ˜¯è®¡ç®— softmax å­˜åˆ° logits.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl">  <span class="n">qk_max</span> <span class="o">=</span> <span class="n">lane</span> <span class="o">&lt;</span> <span class="n">NUM_WARPS</span> <span class="o">?</span> <span class="n">red_smem</span><span class="p">[</span><span class="n">lane</span><span class="p">]</span> <span class="o">:</span> <span class="o">-</span><span class="n">FLT_MAX</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="cp">#pragma unroll
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">NUM_WARPS</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span> <span class="n">mask</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">mask</span> <span class="o">/=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">qk_max</span> <span class="o">=</span> <span class="nf">fmaxf</span><span class="p">(</span><span class="n">qk_max</span><span class="p">,</span> <span class="nf">VLLM_SHFL_XOR_SYNC</span><span class="p">(</span><span class="n">qk_max</span><span class="p">,</span> <span class="n">mask</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Broadcast the max qk value to all threads.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">qk_max</span> <span class="o">=</span> <span class="nf">VLLM_SHFL_SYNC</span><span class="p">(</span><span class="n">qk_max</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// Get the sum of the exp values.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="kt">float</span> <span class="n">exp_sum</span> <span class="o">=</span> <span class="mf">0.f</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">thread_idx</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_tokens</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">NUM_THREADS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">float</span> <span class="n">val</span> <span class="o">=</span> <span class="nf">__expf</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">qk_max</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">exp_sum</span> <span class="o">+=</span> <span class="n">val</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="n">exp_sum</span> <span class="o">=</span> <span class="n">block_sum</span><span class="o">&lt;</span><span class="n">NUM_WARPS</span><span class="o">&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">red_smem</span><span class="p">[</span><span class="n">NUM_WARPS</span><span class="p">],</span> <span class="n">exp_sum</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">// Compute softmax.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">const</span> <span class="kt">float</span> <span class="n">inv_sum</span> <span class="o">=</span> <span class="nf">__fdividef</span><span class="p">(</span><span class="mf">1.f</span><span class="p">,</span> <span class="n">exp_sum</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="n">f</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">thread_idx</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_tokens</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">NUM_THREADS</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="n">inv_sum</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="nf">__syncthreads</span><span class="p">();</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>åŠ è½½ v çš„é€»è¾‘ä¸ k ç›¸åŒï¼Œä½†æ²¡æœ‰ä½¿ç”¨ thread group æ¦‚å¿µï¼Œè€Œæ˜¯è®©ä¸€ä¸ª thread ä¸€æ¬¡åŠ è½½ 16 Bytes.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
