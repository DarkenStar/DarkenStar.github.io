<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Paper Reading | WITHER</title>
<meta name="keywords" content="">
<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/categories/paper-reading/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fb932412828c9f2d49266af65be261a7367e82206ad4a3b92eab398b3f348294.css" integrity="sha256-&#43;5MkEoKMny1JJmr2W&#43;JhpzZ&#43;giBq1KO5Lqs5iz80gpQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/categories/paper-reading/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:1313/categories/paper-reading/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]  
    }
  };
</script>
<meta property="og:url" content="http://localhost:1313/categories/paper-reading/">
  <meta property="og:site_name" content="WITHER">
  <meta property="og:title" content="Paper Reading">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Paper Reading">
<meta name="twitter:description" content="">

</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="WITHER (Alt + H)">WITHER</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="http://localhost:1313/zh/" title="简体中文"
                            aria-label="简体中文">简体中文</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about_me/" title="About Me">
                    <span>About Me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blogs/" title="Blogs">
                    <span>Blogs</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/friends/" title="Friends">
                    <span>Friends</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header"><div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/categories/">Categories</a></div>
  <h1>
    Paper Reading
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">SGG Repository Code Reading
    </h2>
  </header>
  <div class="entry-content">
    <p>Dataset Description Visual Genome 数据集包括 108,077 张带有注释对象 (entities) 和两两配对的关系 (predicates) 的图像组成，然后由 Li Fei-Fei 进行后处理以创建 Scene Graph, 它们使用最常见的150个实体类和50个谓词类来过滤注释。
...</p>
  </div>
  <footer class="entry-footer">24 min&nbsp;·&nbsp;11936 words</footer>
  <a class="entry-link" aria-label="post link to SGG Repository Code Reading" href="http://localhost:1313/posts/sgg_repo/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Transformer Family
    </h2>
  </header>
  <div class="entry-content">
    <p>Origin of Transformer Transformer 由谷歌研于 2017 年在一篇名为 Attention is All You Need 的论文中提出。与 RNN 的输入仅为一个 token 不同，Transformer 一次性可以输入一整个完整的序列。总体结构如下图所示，包含一个 Encoder 和一个 Decoder.
...</p>
  </div>
  <footer class="entry-footer">6 min&nbsp;·&nbsp;2648 words</footer>
  <a class="entry-link" aria-label="post link to Transformer Family" href="http://localhost:1313/posts/transformer-family/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">TX8 Oplib Reading
    </h2>
  </header>
  <div class="entry-content">
    <p>Common Use Data Type 常用数据类型的定义在 common_base.h，
// common_base.h typedef enum { LAYOUT_Tuple = 13, LAYOUT_TENSOR = 0, // Flatten tensor for anyshape, include vector LAYOUT_Cx = 32_&#43; 1, // Channel last Tensor HWC LAYOUT_NTENSOR = 32_&#43; 2, // Batched(N) Tensor NCHW LAYOUT_NCx = 32_&#43; 3, // Channel last batched(N) Tensor NHWC LAYOUT_MODE_END } LAYOUT_MODE; # define MAX_SHAPE_DIM 6 // NHWCXX // instr_def.h typedef typedef enum Data_Format { Fmt_INT8, Fmt_INT16, Fmt_FP16, Fmt_BF16, Fmt_INT32_ Fmt_FP32_ Fmt_TF32_ Fmt_BOOL, // 1/8 BYTE Fmt_UINT8, Fmt_UINT16, Fmt_UINT32_ Fmt_INT64_ Fmt_UINT64_ Fmt_UNUSED, }Data Format; // comm_func.h #define DATA_TYPE Data_Format // common_tensor.h typedef struct common_tensor_info { // MAX_SHAPE_DIM = 6 int32_t shape[MAX_SHAPE_DIM]; // Array represents size in each dim, 1 for int32_t stride[MAX_SHAPE_DIM]; // stride int32_t real_dim; // #dim of tensor uint64_t batch_real_num; uint64_t batch_num; uint64_t batch_mem_size, // T0D0:if Tensor/Cx,not include shape[0] uint64_t total_num; uint64_t total_mem_size; // tensor size in Bytes uint64_t start_addr; LAYOUT_MODE layout; DATA_TYPE dtype; } common_tensor_info_t; // common_trnsor.c void common_tensor_info_generate(const int32_t *shape, int32_t dim, LAYOUT_MODE layout, uint64_t address, DATA_TYPE dtype, common_tensor_info_t *tensor info) uint32_t common_get_spm_addr_by_offset(uint64_t *start_spm_offset) // Get L1 SPM offset: L1SPM_ADDR_START &#43; offset(ALIGN to XNPU_BANK_BYTE(256)) xnpu_config_def.h 地址范围 (Address Ranges): 这些宏定义了不同模块 (如 NCC、DTE、SCONFIG、PMU、DDR) 的内存地址范围，用于内存映射或硬件寄存器访问。 内存大小 (Memory Sizes): 定义了不同模块的内存大小，例如 L1SPM_SIZE 是 3MB，DDR_SIZE 是 512MB。TOTAL_SPM_HEAP_SIZE 的定义可能有误，计算结果 (192GB) 在嵌入式系统中不合理，可能是代码错误。 SPM 地址范围 (SPM Address Range): SPM (Scratchpad Memory) 总大小为 3MB，前后各 64KB 用作缓冲区 (buffer) ，用于存储 barrier 信息 (同步或内存屏障相关数据) 。 硬件对齐和配置 (Hardware Alignment and Configuration) ： 定义了内存对齐和硬件参数，例如 SPM_ALIGN_BIT (96 Bytes 对齐), XNPU_BANK_BYTE (每个 bank 256 Bytes), XNPU_MAC_NUM_IC (输入通道的 MAC 单元数量为 64) 。 XNPU MAC 配置 (XNPU MAC Configuration): XNPU_MAC_NUM_W、XNPU_MAC_NUM_H 等定义了 XNPU (可能是 “X Neural Processing Unit”) 中 MAC (乘累加) 单元的数量，用于并行计算。 XNPU 维度位宽 (Bitwidth for XNPU Dimensions) XNPU_C_BITWIDTH, XNPU_H_BITWIDTH, XNPU_W_BITWIDTH：定义了 XNPU 在通道 (C).高度 (H).宽度 (W).度上的位宽，均为 12 位。意味着每个维度最大可以表示 2^12 = 4096。 XNPU_MAX_C_SIZE, XNPU_MAX_H_SIZE, XNPU_MAX_W_SIZE：根据位宽计算最大尺寸：1 « 12 = 4096. 表示 XNPU 支持的最大通道数、高度和宽度均为 4096。 总线宽度和相关参数 (Bus Width and Related Parameters) BUS_WIDTH &amp; XNPU_BUS_WIDTH：定义了总线宽度为 16 位，XNPU 的总线宽度也为 16 位。总线宽度决定了每次传输的数据量. OUTSTANDING：表示支持的未完成事务 (outstanding transactions).量为 16. 在硬件中，这通常指可以同时处理的事务数量 (例如 AXI 总线支持的并发请求). DMA_BURST_LEN：定义了 DMA (直接内存访问). 突发长度为 16。突发长度是指一次 DMA 传输中连续传输的数据块数量. 总线延迟 (Bus Latency) BUS_LATENCY：定义了总线延迟的基础值为 0。注释 (600 &#43; rand() % 400) 表明在测试中可能会添加随机延迟 (600 到 1000 之间的随机值).可能是为了模拟实际硬件的延迟。 时钟频率 (Clock Frequencies) AXI_CLK 和 XNPU_CLK：定义了 AXI 总线和 XNPU 的时钟频率均为 500 MHz. DDR 区域大小 (DDR Region Size) DDR_REGION_SIZE：定义了 DDR 内存区域的大小为 2GB (2 * 1024 * 1024 * 1024 字节). UL 表示无符号长整型 (unsigned long).确保数值不会溢出。 数据形状相关 (Data Shape Parameters) DATA_SHAPE_MAX：定义了数据形状的最大值为 32_67. 注释提到 “Data Shape=结构体内为 uint16，支持 int16 量化”，表明数据使用 16 位无符号整数 (uint16).储，但支持 int16 量化。int16 的范围是 -32_68 到 32_67，因此最大值为 32_67。 DATA_SHAPE_SLICE：定义了数据形状的切片大小为 16384. 注释 “算子内部已切分” 表明这是内部数据切分的大小，可能是为了优化内存访问或计算效率 (16384 = 2^14). 芯片 ID 枚举 (Chip ID Enumeration) CHIP_ID 枚举：定义了一个芯片 ID 枚举，目前只支持 CHIP_ID_TX81 (值为 0). CHIP_ID_END 作为结束标志，用于范围检查 (例如，验证芯片 ID 是否有效). // Memory address ranges for different modules #define NCC_ADDR 0x01000000 // Starting address of Neural Compute Core (NCC) #define NCC_ADDR_END 0x013FFFFF // Ending address of Neural Compute Core (NCC) #define NCC_WORKER_ID0_ADDR 0x01000000 // Base address for NCC Worker ID0 (first worker unit in NCC) #define NCC_WORKER_ID1_ADDR 0x01100000 // Base address for NCC Worker ID1 (second worker unit in NCC) #define NCC_WORKER_ID2_ADDR 0x01200000 // Base address for NCC Worker ID2 (third worker unit in NCC) #define DTE_ADDR 0x00400000 // Starting address of Data Transfer Engine (DTE) #define DTE_ADDR_END 0x004FFFFF // Ending address of Data Transfer Engine (DTE) #define SCONFIG_ADDR 0x00500000 // Starting address of System Configuration (SCONFIG) #define SCONFIG_ADDR_END 0x0057FFFF // Ending address of System Configuration (SCONFIG) #define NCC_PMU_ADDR 0x00590000 // Starting address of NCC Performance Monitoring Unit (PMU) #define NCC_PMU_ADDR_END 0x0059FFFF // Ending address of NCC Performance Monitoring Unit (PMU) #define DDR_ADDR 0x80000000 // Starting address of DDR memory (main memory) #define DDR_ADDR_END 0x7FFEFFFF // Ending address of DDR memory (main memory) #define DDR_ADDR_RDMA 0x801EE000 // Starting address for Read DMA (Direct Memory Access) in DDR, used for case-pressure testing #define DDR_ADDR_WDMA 0x80200000 // Starting address for Write DMA (Direct Memory Access) in DDR, used for case-pressure testing // Memory sizes for different modules #define L1SPM_SIZE (3 * 1024 * 1024) // Size of Level 1 Scratchpad Memory (L1SPM): 3MB #define NCC_SIZE (1 * 128 * 1024) // Size of NCC memory: 128KB #define DTE_SIZE (1 * 1024 * 1024) // Size of DTE memory: 1MB #define DDR_SIZE (512 * 1024 * 1024) // Size of DDR memory: 512MB // Total SPM heap size #define TOTAL_SPM_HEAP_SIZE (3 * 1024 * 1024 - * 64 * 1024) // Total SPM heap size (3MB - 64KB for buffer) // SPM address range (3MB total, with 64KB at the start and end reserved as buffer for barrier info) #define L1SPM_ADDR_START (0) // Starting address of L1SPM (relative to SPM base address) #define L1SPM_ADDR_END (3 * 1024 * 1024 - 64 * 1024) // Ending address of L1SPM (3MB - 64KB for buffer) // Hardware alignment and configuration parameters #define SPM_ALIGN_BIT (256 * 3) // SPM alignment in bits: 768 bits (96 bytes) #define XNPU_BANK_BYTE 256 // Size of each XNPU bank: 256 bytes #define SPM_BANK_INC XNPU_BANK_BYTE // SPM bank increment: 256 bytes (same as XNPU_BANK_BYTE) #define SPM_BANK_NUM 8 // # of banks in SPM: 8 #define CK_ALIGN_NUM_INT 128 // Alignment requirement for integers: 128 bytes #define CK_ALIGN_NUM_FP 64 // Alignment requirement for floating-point numbers: 64 bytes #define XNPU_DDR_BANK_SIZE 4096 // Size of each XNPU DDR bank: 4096 bytes (4KB) #define XNPU_DDR_BANK_NUM 8 // # of banks in XNPU DDR: 8 // XNPU MAC (Multiply-Accumulate) unit configuration #define XNPU_MAC_NUM_W 1 // # of MAC units for width (W) dimension: 1 #define XNPU_MAC_NUM_H 1 // # of MAC units for height (H) dimension: 1 #define XNPU_MAC_NUM_IC 64 // # of MAC units for input channels (IC): 64 #define XNPU_MAC_NUM_OC 64 // # of MAC units for output channels (OC): 64 #define XNPU_MIN_SLICE_H XNPU_MAC_NUM_H // Minimum slice height for XNPU: same as XNPU_MAC_NUM_H (1) // Bitwidth definitions for XNPU dimensions (C: channels, H: height, W: width) #define XNPU_C_BITWIDTH 12 // Bitwidth for XNPU channels (C): 12 bits #define XNPU_H_BITWIDTH 12 // Bitwidth for XNPU height (H): 12 bits #define XNPU_W_BITWIDTH 12 // Bitwidth for XNPU width (W): 12 bits // Maximum sizes for XNPU dimensions based on bitwidth (2^12 = 4096) #define XNPU_MAX_C_SIZE (1 &lt;&lt; XNPU_C_BITWIDTH) // Maximum channel size: 2^12 = 4096 #define XNPU_MAX_H_SIZE (1 &lt;&lt; XNPU_H_BITWIDTH) // Maximum height size: 2^12 = 4096 #define XNPU_MAX_W_SIZE (1 &lt;&lt; XNPU_W_BITWIDTH) // Maximum width size: 2^12 = 4096 // Bus width definitions #define BUS_WIDTH 16 // Bus width: 16 bits #define OUTSTANDING 16 // Number of outstanding transactions supported: 16 #define DMA_BURST_LEN 16 // DMA burst length: 16 (number of data transfers in a single burst) #define XNPU_BUS_WIDTH 16 // XNPU bus width: 16 bits // Bus latency (simulated with randomness for testing) #define BUS_LATENCY 0 // Base bus latency: 0 (may add random delay: 600 &#43; rand() % 400) // Clock frequencies #define AXI_CLK 500 // AXI clock frequency: 500 MHz #define XNPU_CLK 500 // XNPU clock frequency: 500 MHz // DDR region size #define DDR_REGION_SIZE (2*1024*1024*1024UL) // DDR region size: 2GB (2 * 1024 * 1024 * 1024 bytes) // Maximum data shape size (for uint16 data, assuming int16 quantization) #define DATA_SHAPE_MAX 32_67 // Maximum data shape size: 32_67 (likely for int16 data, as 2^15 - 1 = 32_67) // Data shape slice size (for internal slicing) #define DATA_SHAPE_SLICE 16384 // Data shape slice size: 16384 (likely for internal data partitioning) // Chip ID enumeration typedef enum { CHIP_ID_TX81 = 0, // Chip ID for TX81: 0 CHIP_ID_END // End marker for chip ID enumeration } CHIP_ID; common_func.c uint32_t get_chip_aligned_ck(uint32_t channel, DATA_TYPE dtype, CHIP_ID chip) 根据输入的通道数 channel、数据类型 dtype 和芯片 ID chip，计算并返回一个对齐后的通道数 (aligned channel)，以满足芯片 TX81 的硬件对齐要求。INT8/UINT8 采用 128 位对齐，其余采用 64 位对齐。
...</p>
  </div>
  <footer class="entry-footer">14 min&nbsp;·&nbsp;6962 words</footer>
  <a class="entry-link" aria-label="post link to TX8 Oplib Reading" href="http://localhost:1313/posts/tx8_oplib_reading/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">USP-A Unified Sequence Parallelism Approach for Long Context Generative AI
    </h2>
  </header>
  <div class="entry-content">
    <p>Abstract 我们结合 DeepSpeed-Ulysses 和 Ring-Attention 提出了一种统一的 SP 方法，该方法对 Transformer 结构和网络硬件拓扑具有更强的鲁棒性。我们使用 SP 对序列长度为 208K 的LLAMA3-8B 模型进行训练，在两个8x A800 节点上实现了 47% 的MFU.
...</p>
  </div>
  <footer class="entry-footer">8 min&nbsp;·&nbsp;3686 words</footer>
  <a class="entry-link" aria-label="post link to USP-A Unified Sequence Parallelism Approach for Long Context Generative AI" href="http://localhost:1313/posts/usp-a-unified-sequence-parallelism-approach-for-long-context-generative-ai/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">VLLM Sourse Code Reading
    </h2>
  </header>
  <div class="entry-content">
    <p>Basic from vllm import LLM, SamplingParams # Sample prompts. prompts = [ &#34;Hello, my name is&#34;, &#34;The president of the United States is&#34;, &#34;The capital of France is&#34;, &#34;The future of AI is&#34;, ] # Create a sampling params object. sampling_params = SamplingParams(temperature=0.8, top_p=0.95) # Create an LLM. llm = LLM(model=&#34;facebook/opt-125m&#34;) # Generate texts from the prompts. The output is a list of RequestOutput objects # that contain the prompt, generated text, and other information. outputs = llm.generate(prompts, sampling_params) # Print the outputs. for output in outputs: prompt = output.prompt generated_text = output.outputs[0].text print(f&#34;Prompt: {prompt!r}, Generated text: {generated_text!r}&#34;) Architecture ...</p>
  </div>
  <footer class="entry-footer">23 min&nbsp;·&nbsp;11244 words</footer>
  <a class="entry-link" aria-label="post link to VLLM Sourse Code Reading" href="http://localhost:1313/posts/vllm/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Wafer-scale Computing Advancements, Challenges, and Future Perspectives
    </h2>
  </header>
  <div class="entry-content">
    <p>{% mathjax ‘{ “conversion”: { “em”: 14 }, “tex”: { “tags”: “ams” }, “svg”: { “exFactor”: 0.03 } }’ %} \frac{1}{x^2-1} {% endmathjax %}
Abstract 随着人工智能的计算需求不断增长，硬件计算能力的增长却未能跟上。这已经成为制约人工智能发展的重要因素。硬件计算能力的增加主要是由晶体管密度和芯片面积的增加推动的。前者会因摩尔定律和登纳德缩放的失效而受到制约，后者受到现有颠覆性的制造设备和工艺的影响，直到新的技术达到或超越旧有工艺的性能标准。
...</p>
  </div>
  <footer class="entry-footer">19 min&nbsp;·&nbsp;9307 words</footer>
  <a class="entry-link" aria-label="post link to Wafer-scale Computing Advancements, Challenges, and Future Perspectives" href="http://localhost:1313/posts/wafer-scale-computing/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">ZeRO, ZeRO-Offload, ZeRO-Infinity
    </h2>
  </header>
  <div class="entry-content">
    <p>ZeRO Zero 用于优化内存，极大地提高了训练速度，同时增加了可以训练的模型大小。ZeRO 消除了数据和模型并行训练中的内存冗余，同时保持了低通信量和高计算粒度，能够以持续的高效率按设备数量等比例扩展可训练模型的大小。
...</p>
  </div>
  <footer class="entry-footer">18 min&nbsp;·&nbsp;8891 words</footer>
  <a class="entry-link" aria-label="post link to ZeRO, ZeRO-Offload, ZeRO-Infinity" href="http://localhost:1313/posts/zero/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="http://localhost:1313/categories/paper-reading/">
      «&nbsp;Prev&nbsp;1/2
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>© 2024-2025 WITHER</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
